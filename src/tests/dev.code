<BoC> <TAB> def title ( self ) : <NEWLINE> <TAB> <NEWLINE> return asarray ( title ( self ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def score ( self , x , y , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> kwargs = self . filter_sk_params ( Sequential . evaluate , kwargs ) <NEWLINE> loss = self . model . evaluate ( x , y , ** kwargs ) <NEWLINE> if isinstance ( loss , list ) : <NEWLINE> <TAB> return - loss [ <NUMBER> ] <NEWLINE> <UNTAB> return - loss <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _reroute_t ( t0 , t1 , consumers1 , can_modify = None , cannot_modify = None ) : <NEWLINE> <TAB> <NEWLINE> nb_update_inputs = <NUMBER> <NEWLINE> if can_modify is not None : <NEWLINE> <TAB> consumers1 &= can_modify <NEWLINE> <UNTAB> if cannot_modify is not None : <NEWLINE> <TAB> consumers1 -= cannot_modify <NEWLINE> <UNTAB> consumers1_indices = { } <NEWLINE> for consumer1 in consumers1 : <NEWLINE> <TAB> consumers1_indices [ consumer1 ] = [ i for i , t in enumerate ( consumer1 . inputs ) <NEWLINE> if t is t1 ] <NEWLINE> <UNTAB> for consumer1 in consumers1 : <NEWLINE> <TAB> for i in consumers1_indices [ consumer1 ] : <NEWLINE> <TAB> consumer1 . _update_input ( i , t0 ) <NEWLINE> nb_update_inputs += <NUMBER> <NEWLINE> <UNTAB> <UNTAB> return nb_update_inputs <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ cbook . deprecated ( <STRING> ) <NEWLINE> def binary_repr ( number , max_length = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> shifts = map ( operator . rshift , max_length * [ number ] , <NEWLINE> range ( max_length - <NUMBER> , - <NUMBER> , - <NUMBER> ) ) <NEWLINE> digits = list ( map ( operator . mod , shifts , max_length * [ <NUMBER> ] ) ) <NEWLINE> if not digits . count ( <NUMBER> ) : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> digits = digits [ digits . index ( <NUMBER> ) : ] <NEWLINE> return <STRING> . join ( map ( repr , digits ) ) . replace ( <STRING> , <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_weight_sparsity_map ( self ) : <NEWLINE> <TAB> <NEWLINE> weight_sparsity_map = { } <NEWLINE> val_list = self . _spec . weight_sparsity_map <NEWLINE> filtered_val_list = [ l for l in val_list if l ] <NEWLINE> for val in filtered_val_list : <NEWLINE> <TAB> weight_name , sparsity = val . split ( <STRING> ) <NEWLINE> if float ( sparsity ) >= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> weight_sparsity_map [ weight_name ] = float ( sparsity ) <NEWLINE> <NEWLINE> <UNTAB> return weight_sparsity_map <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def open_http ( self , url , data = None ) : <NEWLINE> <TAB> <NEWLINE> return self . _open_generic_http ( http . client . HTTPConnection , url , data ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def symmetrize ( F , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> allowed_flags ( args , [ <STRING> , <STRING> ] ) <NEWLINE> <NEWLINE> iterable = True <NEWLINE> <NEWLINE> if not hasattr ( F , <STRING> ) : <NEWLINE> <TAB> iterable = False <NEWLINE> F = [ F ] <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> F , opt = parallel_poly_from_expr ( F , * gens , ** args ) <NEWLINE> <UNTAB> except PolificationFailed as exc : <NEWLINE> <TAB> result = [ ] <NEWLINE> <NEWLINE> for expr in exc . exprs : <NEWLINE> <TAB> if expr . is_Number : <NEWLINE> <TAB> result . append ( ( expr , S . Zero ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ComputationFailed ( <STRING> , len ( F ) , exc ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if not iterable : <NEWLINE> <TAB> result , = result <NEWLINE> <NEWLINE> <UNTAB> if not exc . opt . formal : <NEWLINE> <TAB> return result <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if iterable : <NEWLINE> <TAB> return result , [ ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return result + ( [ ] , ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> polys , symbols = [ ] , opt . symbols <NEWLINE> gens , dom = opt . gens , opt . domain <NEWLINE> <NEWLINE> for i in range ( len ( gens ) ) : <NEWLINE> <TAB> poly = symmetric_poly ( i + <NUMBER> , gens , polys = True ) <NEWLINE> polys . append ( ( next ( symbols ) , poly . set_domain ( dom ) ) ) <NEWLINE> <NEWLINE> <UNTAB> indices = list ( range ( len ( gens ) - <NUMBER> ) ) <NEWLINE> weights = list ( range ( len ( gens ) , <NUMBER> , - <NUMBER> ) ) <NEWLINE> <NEWLINE> result = [ ] <NEWLINE> <NEWLINE> for f in F : <NEWLINE> <TAB> symmetric = [ ] <NEWLINE> <NEWLINE> if not f . is_homogeneous : <NEWLINE> <TAB> symmetric . append ( f . TC ( ) ) <NEWLINE> f -= f . TC ( ) <NEWLINE> <NEWLINE> <UNTAB> while f : <NEWLINE> <TAB> _height , _monom , _coeff = - <NUMBER> , None , None <NEWLINE> <NEWLINE> for i , ( monom , coeff ) in enumerate ( f . terms ( ) ) : <NEWLINE> <TAB> if all ( monom [ i ] >= monom [ i + <NUMBER> ] for i in indices ) : <NEWLINE> <TAB> height = max ( [ n * m for n , m in zip ( weights , monom ) ] ) <NEWLINE> <NEWLINE> if height > _height : <NEWLINE> <TAB> _height , _monom , _coeff = height , monom , coeff <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if _height != - <NUMBER> : <NEWLINE> <TAB> monom , coeff = _monom , _coeff <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <UNTAB> exponents = [ ] <NEWLINE> <NEWLINE> for m1 , m2 in zip ( monom , monom [ <NUMBER> : ] + ( <NUMBER> , ) ) : <NEWLINE> <TAB> exponents . append ( m1 - m2 ) <NEWLINE> <NEWLINE> <UNTAB> term = [ s ** n for ( s , _ ) , n in zip ( polys , exponents ) ] <NEWLINE> poly = [ p ** n for ( _ , p ) , n in zip ( polys , exponents ) ] <NEWLINE> <NEWLINE> symmetric . append ( Mul ( coeff , * term ) ) <NEWLINE> product = poly [ <NUMBER> ] . mul ( coeff ) <NEWLINE> <NEWLINE> for p in poly [ <NUMBER> : ] : <NEWLINE> <TAB> product = product . mul ( p ) <NEWLINE> <NEWLINE> <UNTAB> f -= product <NEWLINE> <NEWLINE> <UNTAB> result . append ( ( Add ( * symmetric ) , f . as_expr ( ) ) ) <NEWLINE> <NEWLINE> <UNTAB> polys = [ ( s , p . as_expr ( ) ) for s , p in polys ] <NEWLINE> <NEWLINE> if not opt . formal : <NEWLINE> <TAB> for i , ( sym , non_sym ) in enumerate ( result ) : <NEWLINE> <TAB> result [ i ] = ( sym . subs ( polys ) , non_sym ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not iterable : <NEWLINE> <TAB> result , = result <NEWLINE> <NEWLINE> <UNTAB> if not opt . formal : <NEWLINE> <TAB> return result <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if iterable : <NEWLINE> <TAB> return result , polys <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return result + ( polys , ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_attrs ( self ) : <NEWLINE> <TAB> <NEWLINE> self . encoding = _ensure_encoding ( getattr ( self . attrs , <STRING> , None ) ) <NEWLINE> self . errors = getattr ( self . attrs , <STRING> , <STRING> ) <NEWLINE> for n in self . attributes : <NEWLINE> <TAB> setattr ( self , n , _ensure_decoded ( getattr ( self . attrs , n , None ) ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit ( self , X , y , coef_init = None , intercept_init = None ) : <NEWLINE> <TAB> <NEWLINE> self . _validate_params ( ) <NEWLINE> lr = <STRING> if self . loss == <STRING> else <STRING> <NEWLINE> return self . _fit ( X , y , alpha = <NUMBER> , C = self . C , <NEWLINE> loss = <STRING> , learning_rate = lr , <NEWLINE> coef_init = coef_init , intercept_init = intercept_init ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def compute_boundary_ts ( ops ) : <NEWLINE> <TAB> <NEWLINE> ops = util . make_list_of_op ( ops ) <NEWLINE> input_ts = _get_input_ts ( ops ) <NEWLINE> output_ts = _get_output_ts ( ops ) <NEWLINE> output_ts_set = frozenset ( output_ts ) <NEWLINE> ops_set = frozenset ( ops ) <NEWLINE> <NEWLINE> <NEWLINE> inside_ts = [ ] <NEWLINE> only_inside_ts = [ ] <NEWLINE> for t in input_ts : <NEWLINE> <NEWLINE> <TAB> if t not in output_ts_set : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> inside_ts . append ( t ) <NEWLINE> <NEWLINE> consumers = frozenset ( t . consumers ( ) ) <NEWLINE> if consumers - ops_set : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> only_inside_ts . append ( t ) <NEWLINE> <NEWLINE> <UNTAB> inside_ts_set = frozenset ( inside_ts ) <NEWLINE> only_inside_ts_set = frozenset ( only_inside_ts ) <NEWLINE> outside_output_ts = [ t for t in output_ts if t not in only_inside_ts_set ] <NEWLINE> outside_input_ts = [ t for t in input_ts if t not in inside_ts_set ] <NEWLINE> return outside_input_ts , outside_output_ts , inside_ts <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def reset_display_options ( ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> pd . reset_option ( <STRING> , silent = True ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def transform ( f , p , q ) : <NEWLINE> <TAB> <NEWLINE> if f . lev : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> lev , dom , per , P , Q = p . unify ( q ) <NEWLINE> lev , dom , per , F , P = f . unify ( per ( P , dom , lev ) ) <NEWLINE> lev , dom , per , F , Q = per ( F , dom , lev ) . unify ( per ( Q , dom , lev ) ) <NEWLINE> <NEWLINE> if not lev : <NEWLINE> <TAB> return per ( dup_transform ( F , P , Q , dom ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def convert ( self , values , nan_rep , encoding , errors ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if values . dtype . fields is not None : <NEWLINE> <TAB> values = values [ self . cname ] <NEWLINE> <NEWLINE> <UNTAB> values = _maybe_convert ( values , self . kind , encoding , errors ) <NEWLINE> <NEWLINE> kwargs = dict ( ) <NEWLINE> if self . freq is not None : <NEWLINE> <TAB> kwargs [ <STRING> ] = _ensure_decoded ( self . freq ) <NEWLINE> <UNTAB> if self . index_name is not None : <NEWLINE> <TAB> kwargs [ <STRING> ] = _ensure_decoded ( self . index_name ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> self . values = Index ( values , ** kwargs ) <NEWLINE> <UNTAB> except : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if <STRING> in kwargs : <NEWLINE> <TAB> kwargs [ <STRING> ] = None <NEWLINE> <UNTAB> self . values = Index ( values , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> self . values = _set_tz ( self . values , self . tz ) <NEWLINE> <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( <STRING> , <STRING> ) <NEWLINE> def decode_video ( contents ) : <NEWLINE> <TAB> <NEWLINE> return gen_decode_video_op_py . decode_video ( contents ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def swaplevel ( self , i = - <NUMBER> , j = - <NUMBER> , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> axis = self . _get_axis_number ( axis ) <NEWLINE> result = self . copy ( ) <NEWLINE> labels = result . _data . axes [ axis ] <NEWLINE> result . _data . set_axis ( axis , labels . swaplevel ( i , j ) ) <NEWLINE> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_powers_dict ( self ) : <NEWLINE> <TAB> <NEWLINE> d = defaultdict ( int ) <NEWLINE> d . update ( dict ( [ self . as_base_exp ( ) ] ) ) <NEWLINE> return d <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __hash__ ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> dinv = pow ( self . _denominator , _PyHASH_MODULUS - <NUMBER> , _PyHASH_MODULUS ) <NEWLINE> if not dinv : <NEWLINE> <TAB> hash_ = _PyHASH_INF <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> hash_ = abs ( self . _numerator ) * dinv % _PyHASH_MODULUS <NEWLINE> <UNTAB> result = hash_ if self >= <NUMBER> else - hash_ <NEWLINE> return - <NUMBER> if result == - <NUMBER> else result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def intersection ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( other , ( AccumBounds , FiniteSet ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( other , FiniteSet ) : <NEWLINE> <TAB> fin_set = S . EmptySet <NEWLINE> for i in other : <NEWLINE> <TAB> if i in self : <NEWLINE> <TAB> fin_set = fin_set + FiniteSet ( i ) <NEWLINE> <UNTAB> <UNTAB> return fin_set <NEWLINE> <NEWLINE> <UNTAB> if self . max < other . min or self . min > other . max : <NEWLINE> <TAB> return S . EmptySet <NEWLINE> <NEWLINE> <UNTAB> if self . min <= other . min : <NEWLINE> <TAB> if self . max <= other . max : <NEWLINE> <TAB> return AccumBounds ( other . min , self . max ) <NEWLINE> <UNTAB> if self . max > other . max : <NEWLINE> <TAB> return other <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if other . min <= self . min : <NEWLINE> <TAB> if other . max < self . max : <NEWLINE> <TAB> return AccumBounds ( self . min , other . max ) <NEWLINE> <UNTAB> if other . max > self . max : <NEWLINE> <TAB> return self <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gf_trace_map ( a , b , c , n , f , p , K ) : <NEWLINE> <TAB> <NEWLINE> u = gf_compose_mod ( a , b , f , p , K ) <NEWLINE> v = b <NEWLINE> <NEWLINE> if n & <NUMBER> : <NEWLINE> <TAB> U = gf_add ( a , u , p , K ) <NEWLINE> V = b <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> U = a <NEWLINE> V = c <NEWLINE> <NEWLINE> <UNTAB> n >>= <NUMBER> <NEWLINE> <NEWLINE> while n : <NEWLINE> <TAB> u = gf_add ( u , gf_compose_mod ( u , v , f , p , K ) , p , K ) <NEWLINE> v = gf_compose_mod ( v , v , f , p , K ) <NEWLINE> <NEWLINE> if n & <NUMBER> : <NEWLINE> <TAB> U = gf_add ( U , gf_compose_mod ( u , V , f , p , K ) , p , K ) <NEWLINE> V = gf_compose_mod ( v , V , f , p , K ) <NEWLINE> <NEWLINE> <UNTAB> n >>= <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> return gf_compose_mod ( a , V , f , p , K ) , U <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _initial_nodes_a ( n , k ) : <NEWLINE> <TAB> <NEWLINE> tauk = _compute_tauk ( n , k ) <NEWLINE> sigk = cos ( <NUMBER> * tauk ) ** <NUMBER> <NEWLINE> a = n % <NUMBER> - <NUMBER> <NEWLINE> nu = <NUMBER> * floor ( n / <NUMBER> ) + <NUMBER> * a + <NUMBER> <NEWLINE> <NEWLINE> xksq = nu * sigk - <NUMBER> / ( <NUMBER> * nu ) * ( <NUMBER> / ( <NUMBER> * ( <NUMBER> - sigk ) ** <NUMBER> ) - <NUMBER> / ( <NUMBER> - sigk ) - <NUMBER> ) <NEWLINE> return xksq <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _resample ( self , lutsize ) : <NEWLINE> <TAB> <NEWLINE> colors = self ( np . linspace ( <NUMBER> , <NUMBER> , lutsize ) ) <NEWLINE> return ListedColormap ( colors , name = self . name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sort_schedule_fn ( * cmps ) : <NEWLINE> <TAB> <NEWLINE> dependence = make_dependence_cmp ( ) <NEWLINE> cmps = ( dependence , ) + cmps <NEWLINE> <NEWLINE> def schedule ( fgraph ) : <NEWLINE> <TAB> <NEWLINE> return sort_apply_nodes ( fgraph . inputs , fgraph . outputs , cmps ) <NEWLINE> <UNTAB> return schedule <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def as_common_dtype ( * vars ) : <NEWLINE> <TAB> <NEWLINE> dtype = upcast ( * [ v . dtype for v in vars ] ) <NEWLINE> return ( v . astype ( dtype ) for v in vars ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def upcast ( * args ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> t = _upcast_memo . get ( hash ( args ) ) <NEWLINE> if t is not None : <NEWLINE> <TAB> return t <NEWLINE> <NEWLINE> <UNTAB> upcast = np . find_common_type ( args , [ ] ) <NEWLINE> <NEWLINE> for t in supported_dtypes : <NEWLINE> <TAB> if np . can_cast ( upcast , t ) : <NEWLINE> <TAB> _upcast_memo [ hash ( args ) ] = t <NEWLINE> return t <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> raise TypeError ( <STRING> % ( args , ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def intersecting_product ( a , b ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not a or not b : <NEWLINE> <TAB> return [ ] <NEWLINE> <NEWLINE> <UNTAB> a , b = a [ : ] , b [ : ] <NEWLINE> n = max ( len ( a ) , len ( b ) ) <NEWLINE> <NEWLINE> if n & ( n - <NUMBER> ) : <NEWLINE> <TAB> n = <NUMBER> ** n . bit_length ( ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> a += [ S . Zero ] * ( n - len ( a ) ) <NEWLINE> b += [ S . Zero ] * ( n - len ( b ) ) <NEWLINE> <NEWLINE> a , b = mobius_transform ( a , subset = False ) , mobius_transform ( b , subset = False ) <NEWLINE> a = [ expand_mul ( x * y ) for x , y in zip ( a , b ) ] <NEWLINE> a = inverse_mobius_transform ( a , subset = False ) <NEWLINE> <NEWLINE> return a <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def guess_spatial_dimensions ( image ) : <NEWLINE> <TAB> <NEWLINE> if image . ndim == <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> if image . ndim == <NUMBER> and image . shape [ - <NUMBER> ] != <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> if image . ndim == <NUMBER> and image . shape [ - <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> if image . ndim == <NUMBER> and image . shape [ - <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % image . ndim ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_categorical ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . inferred_type in [ <STRING> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def master ( self , task_type = None , task_index = None ) : <NEWLINE> <TAB> <NEWLINE> if task_type and task_index : <NEWLINE> <TAB> return self . cluster_spec ( ) . task_address ( task_type , task_index ) <NEWLINE> <NEWLINE> <UNTAB> return self . _master <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _wrap_result ( result , is_complex , shape = None ) : <NEWLINE> <TAB> <NEWLINE> if is_complex : <NEWLINE> <TAB> z = _real2complex ( result ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> z = result <NEWLINE> <UNTAB> if shape is not None : <NEWLINE> <TAB> z = z . reshape ( shape ) <NEWLINE> <UNTAB> return z <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def undefine_macro ( self , name ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> i = self . _find_macro ( name ) <NEWLINE> if i is not None : <NEWLINE> <TAB> del self . macros [ i ] <NEWLINE> <NEWLINE> <UNTAB> undefn = ( name , ) <NEWLINE> self . macros . append ( undefn ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def orderings ( self , fgraph , ordered = True ) : <NEWLINE> <TAB> <NEWLINE> if ordered : <NEWLINE> <TAB> set_type = OrderedSet <NEWLINE> rval = OrderedDict ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> set_type = set <NEWLINE> rval = dict ( ) <NEWLINE> <NEWLINE> <UNTAB> if self . destroyers : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> droot , impact , __ignore = self . refresh_droot_impact ( ) <NEWLINE> <NEWLINE> <NEWLINE> illegal_destroy = [ r for r in droot if <NEWLINE> getattr ( r . tag , <STRING> , False ) or <NEWLINE> isinstance ( r , graph . Constant ) ] <NEWLINE> if illegal_destroy : <NEWLINE> <TAB> raise InconsistencyError ( <NEWLINE> <STRING> % <NEWLINE> illegal_destroy ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for app in self . destroyers : <NEWLINE> <NEWLINE> <TAB> root_clients = set_type ( ) <NEWLINE> <NEWLINE> for output_idx , input_idx_list in iteritems ( app . op . destroy_map ) : <NEWLINE> <TAB> destroyed_idx = input_idx_list [ <NUMBER> ] <NEWLINE> destroyed_variable = app . inputs [ destroyed_idx ] <NEWLINE> root = droot [ destroyed_variable ] <NEWLINE> root_impact = impact [ root ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> tolerate_same = getattr ( app . op , <NEWLINE> <STRING> , [ ] ) <NEWLINE> assert isinstance ( tolerate_same , list ) <NEWLINE> tolerated = set ( idx1 for idx0 , idx1 in tolerate_same <NEWLINE> if idx0 == destroyed_idx ) <NEWLINE> tolerated . add ( destroyed_idx ) <NEWLINE> tolerate_aliased = getattr ( <NEWLINE> app . op , <STRING> , [ ] ) <NEWLINE> assert isinstance ( tolerate_aliased , list ) <NEWLINE> ignored = set ( idx1 for idx0 , idx1 in tolerate_aliased <NEWLINE> if idx0 == destroyed_idx ) <NEWLINE> for i , input in enumerate ( app . inputs ) : <NEWLINE> <TAB> if i in ignored : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> if input in root_impact and ( i not in tolerated or <NEWLINE> input is not destroyed_variable ) : <NEWLINE> <TAB> raise InconsistencyError ( <STRING> <NEWLINE> % ( app , destroyed_idx , i ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for r in root_impact : <NEWLINE> <TAB> assert not [ a for a , c in self . clients [ r ] . items ( ) if not c ] <NEWLINE> root_clients . update ( [ a for a , c in self . clients [ r ] . items ( ) if c ] ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> root_clients . remove ( app ) <NEWLINE> if root_clients : <NEWLINE> <TAB> rval [ app ] = root_clients <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return rval <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __add__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( other , SeqBase ) : <NEWLINE> <TAB> raise TypeError ( <STRING> % type ( other ) ) <NEWLINE> <UNTAB> return SeqAdd ( self , other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rand ( * args ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( args [ <NUMBER> ] , tuple ) : <NEWLINE> <TAB> args = args [ <NUMBER> ] <NEWLINE> <UNTAB> return asmatrix ( np . random . rand ( * args ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def mod_check ( x , y ) : <NEWLINE> <TAB> <NEWLINE> if ( ( as_tensor_variable ( x ) . dtype in complex_dtypes or <NEWLINE> as_tensor_variable ( y ) . dtype in complex_dtypes ) ) : <NEWLINE> <NEWLINE> <TAB> raise scal . Mod . complex_error <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return mod ( x , y ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def select ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . condition is not None : <NEWLINE> <TAB> return self . table . table . read_where ( self . condition . format ( ) , <NEWLINE> start = self . start , <NEWLINE> stop = self . stop ) <NEWLINE> <UNTAB> elif self . coordinates is not None : <NEWLINE> <TAB> return self . table . table . read_coordinates ( self . coordinates ) <NEWLINE> <UNTAB> return self . table . table . read ( start = self . start , stop = self . stop ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def load_breast_cancer ( return_X_y = False ) : <NEWLINE> <TAB> <NEWLINE> module_path = dirname ( __file__ ) <NEWLINE> data , target , target_names = load_data ( module_path , <STRING> ) <NEWLINE> csv_filename = join ( module_path , <STRING> , <STRING> ) <NEWLINE> <NEWLINE> with open ( join ( module_path , <STRING> , <STRING> ) ) as rst_file : <NEWLINE> <TAB> fdescr = rst_file . read ( ) <NEWLINE> <NEWLINE> <UNTAB> feature_names = np . array ( [ <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> ] ) <NEWLINE> <NEWLINE> if return_X_y : <NEWLINE> <TAB> return data , target <NEWLINE> <NEWLINE> <UNTAB> return Bunch ( data = data , target = target , <NEWLINE> target_names = target_names , <NEWLINE> DESCR = fdescr , <NEWLINE> feature_names = feature_names , <NEWLINE> filename = csv_filename ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def start_rasterizing ( self ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tc . returns ( core . LabeledTensor ) <NEWLINE> @ tc . accepts ( <NEWLINE> tc . Union ( np . ndarray , list , tuple , core . Scalar ) , <NEWLINE> tc . Optional ( dtypes . DType ) , <NEWLINE> tc . Optional ( <NEWLINE> tc . Union ( core . Axes , tc . Collection ( <NEWLINE> tc . Union ( string_types , core . AxisLike ) ) ) ) , tc . Optional ( string_types ) ) <NEWLINE> def constant ( value , dtype = None , axes = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ value ] ) as scope : <NEWLINE> <NEWLINE> <TAB> if axes is None : <NEWLINE> <TAB> axes = [ ] <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( axes , core . Axes ) : <NEWLINE> <TAB> axes = axes . values ( ) <NEWLINE> <NEWLINE> <UNTAB> if any ( isinstance ( ax , string_types ) for ax in axes ) : <NEWLINE> <NEWLINE> <TAB> shape = None <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> axes = [ core . as_axis ( a ) for a in axes ] <NEWLINE> shape = [ a . size for a in axes ] <NEWLINE> <NEWLINE> <UNTAB> op = array_ops . constant ( value , dtype = dtype , shape = shape , name = scope ) <NEWLINE> return core . LabeledTensor ( op , axes ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def radon ( image , theta = None , circle = None ) : <NEWLINE> <TAB> <NEWLINE> if image . ndim != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if theta is None : <NEWLINE> <TAB> theta = np . arange ( <NUMBER> ) <NEWLINE> <UNTAB> if circle is None : <NEWLINE> <TAB> warn ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> circle = False <NEWLINE> <NEWLINE> <UNTAB> if circle : <NEWLINE> <TAB> radius = min ( image . shape ) // <NUMBER> <NEWLINE> c0 , c1 = np . ogrid [ <NUMBER> : image . shape [ <NUMBER> ] , <NUMBER> : image . shape [ <NUMBER> ] ] <NEWLINE> reconstruction_circle = ( ( c0 - image . shape [ <NUMBER> ] // <NUMBER> ) ** <NUMBER> <NEWLINE> + ( c1 - image . shape [ <NUMBER> ] // <NUMBER> ) ** <NUMBER> ) <NEWLINE> reconstruction_circle = reconstruction_circle <= radius ** <NUMBER> <NEWLINE> if not np . all ( reconstruction_circle | ( image == <NUMBER> ) ) : <NEWLINE> <TAB> warn ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> slices = [ ] <NEWLINE> for d in ( <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> if image . shape [ d ] > min ( image . shape ) : <NEWLINE> <TAB> excess = image . shape [ d ] - min ( image . shape ) <NEWLINE> slices . append ( slice ( int ( np . ceil ( excess / <NUMBER> ) ) , <NEWLINE> int ( np . ceil ( excess / <NUMBER> ) <NEWLINE> + min ( image . shape ) ) ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> slices . append ( slice ( None ) ) <NEWLINE> <UNTAB> <UNTAB> slices = tuple ( slices ) <NEWLINE> padded_image = image [ slices ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> diagonal = np . sqrt ( <NUMBER> ) * max ( image . shape ) <NEWLINE> pad = [ int ( np . ceil ( diagonal - s ) ) for s in image . shape ] <NEWLINE> new_center = [ ( s + p ) // <NUMBER> for s , p in zip ( image . shape , pad ) ] <NEWLINE> old_center = [ s // <NUMBER> for s in image . shape ] <NEWLINE> pad_before = [ nc - oc for oc , nc in zip ( old_center , new_center ) ] <NEWLINE> pad_width = [ ( pb , p - pb ) for pb , p in zip ( pad_before , pad ) ] <NEWLINE> padded_image = np . pad ( image , pad_width , mode = <STRING> , <NEWLINE> constant_values = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> assert padded_image . shape [ <NUMBER> ] == padded_image . shape [ <NUMBER> ] <NEWLINE> radon_image = np . zeros ( ( padded_image . shape [ <NUMBER> ] , len ( theta ) ) ) <NEWLINE> center = padded_image . shape [ <NUMBER> ] // <NUMBER> <NEWLINE> <NEWLINE> shift0 = np . array ( [ [ <NUMBER> , <NUMBER> , - center ] , <NEWLINE> [ <NUMBER> , <NUMBER> , - center ] , <NEWLINE> [ <NUMBER> , <NUMBER> , <NUMBER> ] ] ) <NEWLINE> shift1 = np . array ( [ [ <NUMBER> , <NUMBER> , center ] , <NEWLINE> [ <NUMBER> , <NUMBER> , center ] , <NEWLINE> [ <NUMBER> , <NUMBER> , <NUMBER> ] ] ) <NEWLINE> <NEWLINE> def build_rotation ( theta ) : <NEWLINE> <TAB> T = np . deg2rad ( theta ) <NEWLINE> R = np . array ( [ [ np . cos ( T ) , np . sin ( T ) , <NUMBER> ] , <NEWLINE> [ - np . sin ( T ) , np . cos ( T ) , <NUMBER> ] , <NEWLINE> [ <NUMBER> , <NUMBER> , <NUMBER> ] ] ) <NEWLINE> return shift1 . dot ( R ) . dot ( shift0 ) <NEWLINE> <NEWLINE> <UNTAB> for i in range ( len ( theta ) ) : <NEWLINE> <TAB> rotated = _warp_fast ( padded_image , build_rotation ( theta [ i ] ) ) <NEWLINE> radon_image [ : , i ] = rotated . sum ( <NUMBER> ) <NEWLINE> <UNTAB> return radon_image <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dmp_sub ( f , g , u , K ) : <NEWLINE> <TAB> <NEWLINE> if not u : <NEWLINE> <TAB> return dup_sub ( f , g , K ) <NEWLINE> <NEWLINE> <UNTAB> df = dmp_degree ( f , u ) <NEWLINE> <NEWLINE> if df < <NUMBER> : <NEWLINE> <TAB> return dmp_neg ( g , u , K ) <NEWLINE> <NEWLINE> <UNTAB> dg = dmp_degree ( g , u ) <NEWLINE> <NEWLINE> if dg < <NUMBER> : <NEWLINE> <TAB> return f <NEWLINE> <NEWLINE> <UNTAB> v = u - <NUMBER> <NEWLINE> <NEWLINE> if df == dg : <NEWLINE> <TAB> return dmp_strip ( [ dmp_sub ( a , b , v , K ) for a , b in zip ( f , g ) ] , u ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> k = abs ( df - dg ) <NEWLINE> <NEWLINE> if df > dg : <NEWLINE> <TAB> h , f = f [ : k ] , f [ k : ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> h , g = dmp_neg ( g [ : k ] , u , K ) , g [ k : ] <NEWLINE> <NEWLINE> <UNTAB> return h + [ dmp_sub ( a , b , v , K ) for a , b in zip ( f , g ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def graphviz_layout ( G , prog = <STRING> , root = None , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> return pydot_layout ( G = G , prog = prog , root = root , ** kwds ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_placeholder ( x ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return x . op . type == <STRING> <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _find_reasonable_pivot_naive ( col , iszerofunc = _iszero , simpfunc = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> indeterminates = [ ] <NEWLINE> for i , col_val in enumerate ( col ) : <NEWLINE> <TAB> col_val_is_zero = iszerofunc ( col_val ) <NEWLINE> if col_val_is_zero == False : <NEWLINE> <NEWLINE> <TAB> return i , col_val , False , [ ] <NEWLINE> <UNTAB> elif col_val_is_zero is None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> indeterminates . append ( ( i , col_val ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if len ( indeterminates ) == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return None , None , False , [ ] <NEWLINE> <NEWLINE> <UNTAB> if simpfunc is None : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return indeterminates [ <NUMBER> ] [ <NUMBER> ] , indeterminates [ <NUMBER> ] [ <NUMBER> ] , True , [ ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> newly_determined = [ ] <NEWLINE> for i , col_val in indeterminates : <NEWLINE> <TAB> tmp_col_val = simpfunc ( col_val ) <NEWLINE> if id ( col_val ) != id ( tmp_col_val ) : <NEWLINE> <NEWLINE> <TAB> newly_determined . append ( ( i , tmp_col_val ) ) <NEWLINE> if iszerofunc ( tmp_col_val ) == False : <NEWLINE> <NEWLINE> <TAB> return i , tmp_col_val , False , newly_determined <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return indeterminates [ <NUMBER> ] [ <NUMBER> ] , indeterminates [ <NUMBER> ] [ <NUMBER> ] , True , newly_determined <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def kern ( self ) : <NEWLINE> <TAB> <NEWLINE> new_children = [ ] <NEWLINE> num_children = len ( self . children ) <NEWLINE> if num_children : <NEWLINE> <TAB> for i in range ( num_children ) : <NEWLINE> <TAB> elem = self . children [ i ] <NEWLINE> if i < num_children - <NUMBER> : <NEWLINE> <TAB> next = self . children [ i + <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> next = None <NEWLINE> <NEWLINE> <UNTAB> new_children . append ( elem ) <NEWLINE> kerning_distance = elem . get_kerning ( next ) <NEWLINE> if kerning_distance != <NUMBER> : <NEWLINE> <TAB> kern = Kern ( kerning_distance ) <NEWLINE> new_children . append ( kern ) <NEWLINE> <UNTAB> <UNTAB> self . children = new_children <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def chain ( * brules ) : <NEWLINE> <TAB> <NEWLINE> def chain_brl ( expr ) : <NEWLINE> <TAB> if not brules : <NEWLINE> <TAB> yield expr <NEWLINE> return <NEWLINE> <NEWLINE> <UNTAB> head , tail = brules [ <NUMBER> ] , brules [ <NUMBER> : ] <NEWLINE> for nexpr in head ( expr ) : <NEWLINE> <TAB> for nnexpr in chain ( * tail ) ( nexpr ) : <NEWLINE> <TAB> yield nnexpr <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return chain_brl <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def copy_op_handler ( info , op , new_inputs , copy_shape = False , nodedef_fn = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if isinstance ( new_inputs , bool ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> node_def_ = deepcopy ( op . node_def ) <NEWLINE> <NEWLINE> <NEWLINE> name_ = info . new_name ( op . name ) <NEWLINE> name_ = info . graph_ . unique_name ( name_ ) <NEWLINE> node_def_ . name = name_ <NEWLINE> <NEWLINE> <NEWLINE> if nodedef_fn is not None : <NEWLINE> <TAB> node_def_ = nodedef_fn ( node_def_ ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> output_types_ = op . _output_types [ : ] <NEWLINE> input_types_ = op . _input_types [ : ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> op_def_ = deepcopy ( op . op_def ) <NEWLINE> <NEWLINE> <NEWLINE> op_ = tf_ops . Operation ( node_def_ , info . graph_ , new_inputs , output_types_ , <NEWLINE> [ ] , input_types_ , None , op_def_ ) <NEWLINE> <NEWLINE> <NEWLINE> if copy_shape : <NEWLINE> <TAB> for t , t_ in zip ( op . outputs , op_ . outputs ) : <NEWLINE> <TAB> t_ . set_shape ( t . get_shape ( ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if op . _original_op : <NEWLINE> <TAB> op_ . _original_op = op . _original_op <NEWLINE> <NEWLINE> <UNTAB> return op_ , op_ . outputs <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def glsl_code ( expr , assign_to = None , ** settings ) : <NEWLINE> <TAB> <NEWLINE> return GLSLPrinter ( settings ) . doprint ( expr , assign_to ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <NEWLINE> <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecation . deprecated_endpoints ( <STRING> ) <NEWLINE> def cholesky_solve ( chol , rhs , name = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> with ops . name_scope ( name , <STRING> , [ chol , rhs ] ) : <NEWLINE> <TAB> y = gen_linalg_ops . matrix_triangular_solve ( <NEWLINE> chol , rhs , adjoint = False , lower = True ) <NEWLINE> x = gen_linalg_ops . matrix_triangular_solve ( <NEWLINE> chol , y , adjoint = True , lower = True ) <NEWLINE> return x <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def col ( name = None , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> if dtype is None : <NEWLINE> <TAB> dtype = config . floatX <NEWLINE> <UNTAB> type = TensorType ( dtype , ( False , True ) ) <NEWLINE> return type ( name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def fowlkes_mallows_score ( labels_true , labels_pred , sparse = False ) : <NEWLINE> <TAB> <NEWLINE> labels_true , labels_pred = check_clusterings ( labels_true , labels_pred ) <NEWLINE> n_samples , = labels_true . shape <NEWLINE> <NEWLINE> c = contingency_matrix ( labels_true , labels_pred , <NEWLINE> sparse = True ) . astype ( np . int64 ) <NEWLINE> tk = np . dot ( c . data , c . data ) - n_samples <NEWLINE> pk = np . sum ( np . asarray ( c . sum ( axis = <NUMBER> ) ) . ravel ( ) ** <NUMBER> ) - n_samples <NEWLINE> qk = np . sum ( np . asarray ( c . sum ( axis = <NUMBER> ) ) . ravel ( ) ** <NUMBER> ) - n_samples <NEWLINE> return np . sqrt ( tk / pk ) * np . sqrt ( tk / qk ) if tk != <NUMBER> else <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> def generalized_degree ( G , nodes = None ) : <NEWLINE> <TAB> <NEWLINE> if nodes in G : <NEWLINE> <TAB> return next ( _triangles_and_degree_iter ( G , nodes ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> return { v : gd for v , d , t , gd in _triangles_and_degree_iter ( G , nodes ) } <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def initsysfonts_darwin ( ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if exists ( <STRING> ) : <NEWLINE> <TAB> fonts = initsysfonts_unix ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif exists ( <STRING> ) : <NEWLINE> <TAB> fonts = initsysfonts_unix ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> fonts = { } <NEWLINE> <NEWLINE> <UNTAB> return fonts <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _iterable_not_string ( obj ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return ( isinstance ( obj , collections . Iterable ) and <NEWLINE> not isinstance ( obj , string_types ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __rfloordiv__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return floor_divide ( other , self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def convert_variable ( self , var ) : <NEWLINE> <TAB> <NEWLINE> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_count ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . count <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rgba2rgb ( rgba , background = ( <NUMBER> , <NUMBER> , <NUMBER> ) ) : <NEWLINE> <TAB> <NEWLINE> arr = _prepare_rgba_array ( rgba ) <NEWLINE> if isinstance ( background , tuple ) and len ( background ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> . format ( len ( background ) ) ) <NEWLINE> <NEWLINE> <UNTAB> alpha = arr [ ... , - <NUMBER> ] <NEWLINE> channels = arr [ ... , : - <NUMBER> ] <NEWLINE> out = np . empty_like ( channels ) <NEWLINE> <NEWLINE> for ichan in range ( channels . shape [ - <NUMBER> ] ) : <NEWLINE> <TAB> out [ ... , ichan ] = np . clip ( <NEWLINE> ( <NUMBER> - alpha ) * background [ ichan ] + alpha * channels [ ... , ichan ] , <NEWLINE> a_min = <NUMBER> , a_max = <NUMBER> ) <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def AddValue ( self , val ) : <NEWLINE> <TAB> <NEWLINE> if val . name in self . _values : <NEWLINE> <NEWLINE> <TAB> result = self . _external_values . get ( val . name ) <NEWLINE> return val if result is None else result <NEWLINE> <NEWLINE> <UNTAB> result = val <NEWLINE> self . _values . add ( val . name ) <NEWLINE> if self . _outer_context : <NEWLINE> <TAB> result = self . _outer_context . AddValue ( val ) <NEWLINE> self . _values . add ( result . name ) <NEWLINE> <NEWLINE> <UNTAB> self . _external_values [ val . name ] = result <NEWLINE> <NEWLINE> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_categorical ( arr ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return isinstance ( arr , ABCCategorical ) or is_categorical_dtype ( arr ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def fake_quant_with_min_max_vars_gradient ( gradients , inputs , min , max , num_bits = <NUMBER> , narrow_range = False , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if num_bits is None : <NEWLINE> <TAB> num_bits = <NUMBER> <NEWLINE> <UNTAB> num_bits = _execute . make_int ( num_bits , <STRING> ) <NEWLINE> if narrow_range is None : <NEWLINE> <TAB> narrow_range = False <NEWLINE> <UNTAB> narrow_range = _execute . make_bool ( narrow_range , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , gradients = gradients , inputs = inputs , <NEWLINE> min = min , max = max , num_bits = num_bits , narrow_range = narrow_range , <NEWLINE> name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result = _FakeQuantWithMinMaxVarsGradientOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , gradients , inputs , min , max , <NEWLINE> <STRING> , num_bits , <STRING> , narrow_range ) <NEWLINE> _result = _FakeQuantWithMinMaxVarsGradientOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return fake_quant_with_min_max_vars_gradient_eager_fallback ( <NEWLINE> gradients , inputs , min , max , num_bits = num_bits , <NEWLINE> narrow_range = narrow_range , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def voronoi_cells ( G , center_nodes , weight = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> paths = nx . multi_source_dijkstra_path ( G , center_nodes , weight = weight ) <NEWLINE> <NEWLINE> nearest = { v : p [ <NUMBER> ] for v , p in paths . items ( ) } <NEWLINE> <NEWLINE> <NEWLINE> cells = groups ( nearest ) <NEWLINE> <NEWLINE> unreachable = set ( G ) - set ( nearest ) <NEWLINE> if unreachable : <NEWLINE> <TAB> cells [ <STRING> ] = unreachable <NEWLINE> <UNTAB> return cells <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_window_extent ( self , renderer = None , dpi = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not self . get_visible ( ) : <NEWLINE> <TAB> return Bbox . unit ( ) <NEWLINE> <UNTAB> if dpi is not None : <NEWLINE> <TAB> dpi_orig = self . figure . dpi <NEWLINE> self . figure . dpi = dpi <NEWLINE> <UNTAB> if self . get_text ( ) == <STRING> : <NEWLINE> <TAB> tx , ty = self . _get_xy_display ( ) <NEWLINE> return Bbox . from_bounds ( tx , ty , <NUMBER> , <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> if renderer is not None : <NEWLINE> <TAB> self . _renderer = renderer <NEWLINE> <UNTAB> if self . _renderer is None : <NEWLINE> <TAB> self . _renderer = self . figure . _cachedRenderer <NEWLINE> <UNTAB> if self . _renderer is None : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> bbox , info , descent = self . _get_layout ( self . _renderer ) <NEWLINE> x , y = self . get_unitless_position ( ) <NEWLINE> x , y = self . get_transform ( ) . transform_point ( ( x , y ) ) <NEWLINE> bbox = bbox . translated ( x , y ) <NEWLINE> if dpi is not None : <NEWLINE> <TAB> self . figure . dpi = dpi_orig <NEWLINE> <UNTAB> return bbox <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _wrap_output ( self , output , index , names = None ) : <NEWLINE> <TAB> <NEWLINE> output = output [ self . _selection_name ] <NEWLINE> <NEWLINE> if names is not None : <NEWLINE> <TAB> return DataFrame ( output , index = index , columns = names ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> name = self . _selection_name <NEWLINE> if name is None : <NEWLINE> <TAB> name = self . _selected_obj . name <NEWLINE> <UNTAB> return Series ( output , index = index , name = name ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def julian2num ( j ) : <NEWLINE> <TAB> <NEWLINE> if cbook . iterable ( j ) : <NEWLINE> <TAB> j = np . asarray ( j ) <NEWLINE> <UNTAB> return j - JULIAN_OFFSET <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_constrained_layout ( self , constrained ) : <NEWLINE> <TAB> <NEWLINE> self . _constrained_layout_pads = dict ( ) <NEWLINE> self . _constrained_layout_pads [ <STRING> ] = None <NEWLINE> self . _constrained_layout_pads [ <STRING> ] = None <NEWLINE> self . _constrained_layout_pads [ <STRING> ] = None <NEWLINE> self . _constrained_layout_pads [ <STRING> ] = None <NEWLINE> if constrained is None : <NEWLINE> <TAB> constrained = rcParams [ <STRING> ] <NEWLINE> <UNTAB> self . _constrained = bool ( constrained ) <NEWLINE> if isinstance ( constrained , dict ) : <NEWLINE> <TAB> self . set_constrained_layout_pads ( ** constrained ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . set_constrained_layout_pads ( ) <NEWLINE> <NEWLINE> <UNTAB> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def safe_min ( X ) : <NEWLINE> <TAB> <NEWLINE> if sparse . issparse ( X ) : <NEWLINE> <TAB> if len ( X . data ) == <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> m = X . data . min ( ) <NEWLINE> return m if X . getnnz ( ) == X . size else min ( m , <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return X . min ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def arr_to_chars ( arr ) : <NEWLINE> <TAB> <NEWLINE> dims = list ( arr . shape ) <NEWLINE> if not dims : <NEWLINE> <TAB> dims = [ <NUMBER> ] <NEWLINE> <UNTAB> dims . append ( int ( arr . dtype . str [ <NUMBER> : ] ) ) <NEWLINE> arr = np . ndarray ( shape = dims , <NEWLINE> dtype = arr_dtype_number ( arr , <NUMBER> ) , <NEWLINE> buffer = arr ) <NEWLINE> empties = [ arr == <STRING> ] <NEWLINE> if not np . any ( empties ) : <NEWLINE> <TAB> return arr <NEWLINE> <UNTAB> arr = arr . copy ( ) <NEWLINE> arr [ empties ] = <STRING> <NEWLINE> return arr <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def polyval3d ( x , y , z , c ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> x , y , z = np . array ( ( x , y , z ) , copy = <NUMBER> ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> c = polyval ( x , c ) <NEWLINE> c = polyval ( y , c , tensor = False ) <NEWLINE> c = polyval ( z , c , tensor = False ) <NEWLINE> return c <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _maybe_coerce_values ( self , values ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( values , ( ABCIndexClass , ABCSeries ) ) : <NEWLINE> <TAB> values = values . _values <NEWLINE> <UNTAB> return values <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_ring ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . field . to_ring ( ) . to_domain ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def flatten_structured_array ( a ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def flatten_sequence ( iterable ) : <NEWLINE> <TAB> <NEWLINE> for elm in iter ( iterable ) : <NEWLINE> <TAB> if hasattr ( elm , <STRING> ) : <NEWLINE> <TAB> for f in flatten_sequence ( elm ) : <NEWLINE> <TAB> yield f <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> yield elm <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> a = np . asanyarray ( a ) <NEWLINE> inishape = a . shape <NEWLINE> a = a . ravel ( ) <NEWLINE> if isinstance ( a , MaskedArray ) : <NEWLINE> <TAB> out = np . array ( [ tuple ( flatten_sequence ( d . item ( ) ) ) for d in a . _data ] ) <NEWLINE> out = out . view ( MaskedArray ) <NEWLINE> out . _mask = np . array ( [ tuple ( flatten_sequence ( d . item ( ) ) ) <NEWLINE> for d in getmaskarray ( a ) ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> out = np . array ( [ tuple ( flatten_sequence ( d . item ( ) ) ) for d in a ] ) <NEWLINE> <UNTAB> if len ( inishape ) > <NUMBER> : <NEWLINE> <TAB> newshape = list ( out . shape ) <NEWLINE> newshape [ <NUMBER> ] = inishape <NEWLINE> out . shape = tuple ( flatten_sequence ( newshape ) ) <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __getitem__ ( self , v ) : <NEWLINE> <TAB> <NEWLINE> return self . unif . get ( v , ( v , None ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def compare_mse ( im1 , im2 ) : <NEWLINE> <TAB> <NEWLINE> _assert_compatible ( im1 , im2 ) <NEWLINE> im1 , im2 = _as_floats ( im1 , im2 ) <NEWLINE> return np . mean ( np . square ( im1 - im2 ) , dtype = np . float64 ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def maybe_upcast_putmask ( result , mask , other ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if mask . any ( ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if is_datetimelike ( result . dtype ) : <NEWLINE> <TAB> if is_scalar ( other ) : <NEWLINE> <TAB> if isna ( other ) : <NEWLINE> <TAB> other = result . dtype . type ( <STRING> ) <NEWLINE> <UNTAB> elif is_integer ( other ) : <NEWLINE> <TAB> other = np . array ( other , dtype = result . dtype ) <NEWLINE> <UNTAB> <UNTAB> elif is_integer_dtype ( other ) : <NEWLINE> <TAB> other = np . array ( other , dtype = result . dtype ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def changeit ( ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> om = other [ mask ] <NEWLINE> om_at = om . astype ( result . dtype ) <NEWLINE> if ( om == om_at ) . all ( ) : <NEWLINE> <TAB> new_result = result . values . copy ( ) <NEWLINE> new_result [ mask ] = om_at <NEWLINE> result [ : ] = new_result <NEWLINE> return result , False <NEWLINE> <UNTAB> <UNTAB> except Exception : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> r , _ = maybe_upcast ( result , fill_value = other , copy = True ) <NEWLINE> np . place ( r , mask , other ) <NEWLINE> <NEWLINE> return r , True <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> new_dtype , _ = maybe_promote ( result . dtype , other ) <NEWLINE> if new_dtype != result . dtype : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if ( is_scalar ( other ) or <NEWLINE> ( isinstance ( other , np . ndarray ) and other . ndim < <NUMBER> ) ) : <NEWLINE> <TAB> if isna ( other ) : <NEWLINE> <TAB> return changeit ( ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> if isna ( other [ mask ] ) . any ( ) : <NEWLINE> <TAB> return changeit ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> try : <NEWLINE> <TAB> np . place ( result , mask , other ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> return changeit ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return result , False <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def make_c_thunk ( self , node , storage_map , compute_map , no_recycling ) : <NEWLINE> <TAB> <NEWLINE> node_input_storage = [ storage_map [ r ] for r in node . inputs ] <NEWLINE> node_output_storage = [ storage_map [ r ] for r in node . outputs ] <NEWLINE> <NEWLINE> e = FunctionGraph ( node . inputs , node . outputs ) <NEWLINE> e_no_recycling = [ new_o <NEWLINE> for ( new_o , old_o ) in zip ( e . outputs , node . outputs ) <NEWLINE> if old_o in no_recycling ] <NEWLINE> cl = theano . gof . cc . CLinker ( ) . accept ( e , <NEWLINE> no_recycling = e_no_recycling ) <NEWLINE> <NEWLINE> <NEWLINE> if not getattr ( self , <STRING> , False ) : <NEWLINE> <TAB> def is_f16 ( t ) : <NEWLINE> <TAB> return getattr ( t , <STRING> , <STRING> ) == <STRING> <NEWLINE> <NEWLINE> <UNTAB> if ( any ( is_f16 ( i . type ) for i in node . inputs ) or <NEWLINE> any ( is_f16 ( o . type ) for o in node . outputs ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> cl . get_dynamic_module ( ) <NEWLINE> print ( <STRING> <NEWLINE> <STRING> % ( self , ) ) <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> _logger . debug ( <STRING> ) <NEWLINE> outputs = cl . make_thunk ( input_storage = node_input_storage , <NEWLINE> output_storage = node_output_storage ) <NEWLINE> thunk , node_input_filters , node_output_filters = outputs <NEWLINE> <NEWLINE> def rval ( ) : <NEWLINE> <TAB> thunk ( ) <NEWLINE> for o in node . outputs : <NEWLINE> <TAB> compute_map [ o ] [ <NUMBER> ] = True <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> rval . thunk = thunk <NEWLINE> rval . cthunk = thunk . cthunk <NEWLINE> rval . inputs = node_input_storage <NEWLINE> rval . outputs = node_output_storage <NEWLINE> rval . lazy = False <NEWLINE> return rval <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def iget ( self , i , fastpath = True ) : <NEWLINE> <TAB> <NEWLINE> block = self . blocks [ self . _blknos [ i ] ] <NEWLINE> values = block . iget ( self . _blklocs [ i ] ) <NEWLINE> if not fastpath or not block . _box_to_block_values or values . ndim != <NUMBER> : <NEWLINE> <TAB> return values <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return SingleBlockManager ( <NEWLINE> [ block . make_block_same_class ( values , <NEWLINE> placement = slice ( <NUMBER> , len ( values ) ) , <NEWLINE> ndim = <NUMBER> ) ] , <NEWLINE> self . axes [ <NUMBER> ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( None , <STRING> ) <NEWLINE> def infer_real_valued_columns_from_input_fn ( input_fn ) : <NEWLINE> <TAB> <NEWLINE> with ops . Graph ( ) . as_default ( ) : <NEWLINE> <TAB> features , _ = input_fn ( ) <NEWLINE> return layers . infer_real_valued_columns ( features ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def run ( self , show_loop_exception_msg = True ) : <NEWLINE> <TAB> <NEWLINE> if self . _done : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> os . makedirs ( self . out ) <NEWLINE> <UNTAB> except OSError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> extension_order = sorted ( <NEWLINE> self . _extensions . keys ( ) , <NEWLINE> key = lambda name : self . _extensions [ name ] . priority , reverse = True ) <NEWLINE> extensions = [ ( name , self . _extensions [ name ] ) <NEWLINE> for name in extension_order ] <NEWLINE> <NEWLINE> self . _start_at = _get_time ( ) <NEWLINE> <NEWLINE> <NEWLINE> for _ , entry in extensions : <NEWLINE> <TAB> initializer = getattr ( entry . extension , <STRING> , None ) <NEWLINE> if initializer : <NEWLINE> <TAB> initializer ( self ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> update = self . updater . update <NEWLINE> reporter = self . reporter <NEWLINE> stop_trigger = self . stop_trigger <NEWLINE> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> while not stop_trigger ( self ) : <NEWLINE> <TAB> self . observation = { } <NEWLINE> with reporter . scope ( self . observation ) : <NEWLINE> <TAB> update ( ) <NEWLINE> for name , entry in extensions : <NEWLINE> <TAB> if entry . trigger ( self ) : <NEWLINE> <TAB> entry . extension ( self ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> except Exception as e : <NEWLINE> <TAB> if show_loop_exception_msg : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> f = sys . stderr <NEWLINE> f . write ( <STRING> . format ( e ) ) <NEWLINE> f . write ( <STRING> ) <NEWLINE> traceback . print_tb ( sys . exc_info ( ) [ <NUMBER> ] ) <NEWLINE> f . write ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> six . reraise ( * sys . exc_info ( ) ) <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> for _ , entry in extensions : <NEWLINE> <TAB> finalize = getattr ( entry . extension , <STRING> , None ) <NEWLINE> if finalize : <NEWLINE> <TAB> finalize ( ) <NEWLINE> <UNTAB> <UNTAB> self . updater . finalize ( ) <NEWLINE> <NEWLINE> <UNTAB> self . _final_elapsed_time = self . elapsed_time <NEWLINE> self . _done = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def unquote_plus ( string , encoding = <STRING> , errors = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> string = string . replace ( <STRING> , <STRING> ) <NEWLINE> return unquote ( string , encoding , errors ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def median ( input , labels = None , index = None ) : <NEWLINE> <TAB> <NEWLINE> return _select ( input , labels , index , find_median = True ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def decision_function ( self , X ) : <NEWLINE> <TAB> <NEWLINE> dec = self . _decision_function ( X ) <NEWLINE> if self . decision_function_shape == <STRING> and len ( self . classes_ ) > <NUMBER> : <NEWLINE> <TAB> return _ovr_decision_function ( dec < <NUMBER> , - dec , len ( self . classes_ ) ) <NEWLINE> <UNTAB> return dec <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def eccentricity ( G , v = None , sp = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> order = G . order ( ) <NEWLINE> <NEWLINE> e = { } <NEWLINE> for n in G . nbunch_iter ( v ) : <NEWLINE> <TAB> if sp is None : <NEWLINE> <TAB> length = networkx . single_source_shortest_path_length ( G , n ) <NEWLINE> L = len ( length ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> length = sp [ n ] <NEWLINE> L = len ( length ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> raise networkx . NetworkXError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> if L != order : <NEWLINE> <TAB> if G . is_directed ( ) : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> raise networkx . NetworkXError ( msg ) <NEWLINE> <NEWLINE> <UNTAB> e [ n ] = max ( length . values ( ) ) <NEWLINE> <NEWLINE> <UNTAB> if v in G : <NEWLINE> <TAB> return e [ v ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return e <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def send_signal ( self , sig ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if self . returncode is None : <NEWLINE> <TAB> os . kill ( self . pid , sig ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def restore ( self , restored_tensors , unused_restored_shapes ) : <NEWLINE> <TAB> <NEWLINE> with ops . control_dependencies ( [ self . _create_op ] ) : <NEWLINE> <TAB> return gen_model_ops . tree_deserialize ( <NEWLINE> self . _tree_handle , <NEWLINE> restored_tensors [ <NUMBER> ] , <NEWLINE> params = self . params . serialized_params_proto ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def permuteFwd ( self , perm ) : <NEWLINE> <TAB> <NEWLINE> return self . permute_rows ( perm , direction = <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ docstring . dedent_interpd <NEWLINE> def __init__ ( self , verts , sizes = None , closed = True , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> Collection . __init__ ( self , ** kwargs ) <NEWLINE> self . set_sizes ( sizes ) <NEWLINE> self . set_verts ( verts , closed ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def compare ( self , other , ** kw ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return ( <NEWLINE> isinstance ( other , BinaryExpression ) and <NEWLINE> self . operator == other . operator and <NEWLINE> ( <NEWLINE> self . left . compare ( other . left , ** kw ) and <NEWLINE> self . right . compare ( other . right , ** kw ) or <NEWLINE> ( <NEWLINE> operators . is_commutative ( self . operator ) and <NEWLINE> self . left . compare ( other . right , ** kw ) and <NEWLINE> self . right . compare ( other . left , ** kw ) <NEWLINE> ) <NEWLINE> ) <NEWLINE> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def mul ( self , a , b ) : <NEWLINE> <TAB> <NEWLINE> return a * b <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def colorbar_factory ( cax , mappable , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if ( isinstance ( mappable , contour . ContourSet ) <NEWLINE> and any ( hatch is not None for hatch in mappable . hatches ) ) : <NEWLINE> <TAB> cb = ColorbarPatch ( cax , mappable , ** kwargs ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cb = Colorbar ( cax , mappable , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> cid = mappable . callbacksSM . connect ( <STRING> , cb . on_mappable_changed ) <NEWLINE> mappable . colorbar = cb <NEWLINE> mappable . colorbar_cid = cid <NEWLINE> <NEWLINE> return cb <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> def gnm_random_graph ( n , m , seed = None , directed = False ) : <NEWLINE> <TAB> <NEWLINE> if directed : <NEWLINE> <TAB> G = nx . DiGraph ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> G = nx . Graph ( ) <NEWLINE> <UNTAB> G . add_nodes_from ( range ( n ) ) <NEWLINE> <NEWLINE> if n == <NUMBER> : <NEWLINE> <TAB> return G <NEWLINE> <UNTAB> max_edges = n * ( n - <NUMBER> ) <NEWLINE> if not directed : <NEWLINE> <TAB> max_edges /= <NUMBER> <NEWLINE> <UNTAB> if m >= max_edges : <NEWLINE> <TAB> return complete_graph ( n , create_using = G ) <NEWLINE> <NEWLINE> <UNTAB> nlist = list ( G ) <NEWLINE> edge_count = <NUMBER> <NEWLINE> while edge_count < m : <NEWLINE> <NEWLINE> <TAB> u = seed . choice ( nlist ) <NEWLINE> v = seed . choice ( nlist ) <NEWLINE> if u == v or G . has_edge ( u , v ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> G . add_edge ( u , v ) <NEWLINE> edge_count = edge_count + <NUMBER> <NEWLINE> <UNTAB> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def unique ( self ) : <NEWLINE> <TAB> <NEWLINE> from pandas import unique <NEWLINE> <NEWLINE> uniques = unique ( self . astype ( object ) ) <NEWLINE> return self . _from_sequence ( uniques ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _intersect_interval ( self , other ) : <NEWLINE> <TAB> <NEWLINE> interval = Intersection ( self . interval , other . interval ) <NEWLINE> return interval . inf , interval . sup <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def tiecorrect ( rankvals ) : <NEWLINE> <TAB> <NEWLINE> arr = np . sort ( rankvals ) <NEWLINE> idx = np . nonzero ( np . r_ [ True , arr [ <NUMBER> : ] != arr [ : - <NUMBER> ] , True ] ) [ <NUMBER> ] <NEWLINE> cnt = np . diff ( idx ) . astype ( np . float64 ) <NEWLINE> <NEWLINE> size = np . float64 ( arr . size ) <NEWLINE> return <NUMBER> if size < <NUMBER> else <NUMBER> - ( cnt ** <NUMBER> - cnt ) . sum ( ) / ( size ** <NUMBER> - size ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def build_nccl_all_reduce ( input_tensors , red_op , un_op = None ) : <NEWLINE> <TAB> <NEWLINE> if red_op == math_ops . add : <NEWLINE> <TAB> output_tensors = nccl_ops . all_sum ( input_tensors ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> , red_op ) <NEWLINE> <UNTAB> if un_op : <NEWLINE> <TAB> un_op_wrapped = [ ] <NEWLINE> for t in output_tensors : <NEWLINE> <TAB> with ops . colocate_with ( t ) : <NEWLINE> <TAB> un_op_wrapped . append ( un_op ( t ) ) <NEWLINE> <UNTAB> <UNTAB> output_tensors = un_op_wrapped <NEWLINE> <UNTAB> return output_tensors <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _clone ( self ) : <NEWLINE> <TAB> <NEWLINE> c = self . __class__ . __new__ ( self . __class__ ) <NEWLINE> c . __dict__ = self . __dict__ . copy ( ) <NEWLINE> ClauseElement . _cloned_set . _reset ( c ) <NEWLINE> ColumnElement . comparator . _reset ( c ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> c . _is_clone_of = self <NEWLINE> <NEWLINE> return c <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def getValue ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . data . item ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sigmoid_binary_crossentropy ( output , target ) : <NEWLINE> <TAB> <NEWLINE> def grad ( inputs , out_grads ) : <NEWLINE> <TAB> ( output , target ) , ( out_grad , ) = inputs , out_grads <NEWLINE> g_output = out_grad * ( sigmoid ( output ) - target ) <NEWLINE> g_target = out_grad * ( - output ) <NEWLINE> return [ g_output , g_target ] <NEWLINE> <UNTAB> inp = [ output , target ] <NEWLINE> outp = softplus ( - abs ( output ) ) + output * ( ( output > <NUMBER> ) - target ) <NEWLINE> return theano . OpFromGraph ( inp , [ outp ] , grad_overrides = grad , inline = True , <NEWLINE> name = <STRING> ) ( * inp ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def coeff ( self , element ) : <NEWLINE> <TAB> <NEWLINE> if element == <NUMBER> : <NEWLINE> <TAB> return self . _get_coeff ( self . ring . zero_monom ) <NEWLINE> <UNTAB> elif isinstance ( element , self . ring . dtype ) : <NEWLINE> <TAB> terms = list ( element . iterterms ( ) ) <NEWLINE> if len ( terms ) == <NUMBER> : <NEWLINE> <TAB> monom , coeff = terms [ <NUMBER> ] <NEWLINE> if coeff == self . ring . domain . one : <NEWLINE> <TAB> return self . _get_coeff ( monom ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> raise ValueError ( <STRING> % element ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def moveaxis ( x , source , destination ) : <NEWLINE> <TAB> <NEWLINE> return Moveaxis ( source , destination ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ deprecation . deprecated ( None , <STRING> ) <NEWLINE> def set_from_map ( self , values_map ) : <NEWLINE> <TAB> <NEWLINE> return self . override_from_dict ( values_dict = values_map ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _is_c_order ( row , col ) : <NEWLINE> <TAB> <NEWLINE> if row . shape != col . shape : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if row . ndim != <NUMBER> : <NEWLINE> <TAB> for i in range ( row . shape [ <NUMBER> ] ) : <NEWLINE> <TAB> if not _is_c_order ( row [ i ] , col [ i ] ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> xp = backend . get_array_module ( row ) <NEWLINE> _row = row [ col >= <NUMBER> ] <NEWLINE> _col = col [ row >= <NUMBER> ] <NEWLINE> if _row [ _row < <NUMBER> ] . size > <NUMBER> or _col [ _col < <NUMBER> ] . size : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if _row . shape [ <NUMBER> ] <= <NUMBER> : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> row_diff = xp . zeros ( _row . shape , dtype = _row . dtype ) <NEWLINE> row_diff [ <NUMBER> : ] = _row [ <NUMBER> : ] - _row [ : - <NUMBER> ] <NEWLINE> if xp . amin ( row_diff ) < <NUMBER> : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> col_diff = xp . zeros ( _col . shape , dtype = _col . dtype ) <NEWLINE> col_diff [ <NUMBER> : ] = _col [ <NUMBER> : ] - _col [ : - <NUMBER> ] <NEWLINE> col_diff [ ( row_diff > <NUMBER> ) ] = <NUMBER> <NEWLINE> return xp . amin ( col_diff ) >= <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_RealField ( K1 , a , K0 ) : <NEWLINE> <TAB> <NEWLINE> p , q = K0 . to_rational ( a ) <NEWLINE> return PythonRational ( int ( p ) , int ( q ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_powerlimits ( self , lims ) : <NEWLINE> <TAB> <NEWLINE> if len ( lims ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> self . _powerlimits = lims <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def half ( self ) : <NEWLINE> <TAB> <NEWLINE> return type ( self ) ( self . data . half ( ) , self . batch_sizes ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def parallel_dict_from_expr ( exprs , ** args ) : <NEWLINE> <TAB> <NEWLINE> reps , opt = _parallel_dict_from_expr ( exprs , build_options ( args ) ) <NEWLINE> return reps , opt . gens <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def get_unicode_index ( symbol , math = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not math : <NEWLINE> <TAB> return ord ( symbol ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if symbol == <STRING> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> return ord ( symbol ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> return tex2uni [ symbol . strip ( <STRING> ) ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> . format ( symbol ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_pickradius ( self , d ) : <NEWLINE> <TAB> <NEWLINE> self . pickradius = d <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def count_contains ( self , vertices ) : <NEWLINE> <TAB> <NEWLINE> if len ( vertices ) == <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> vertices = np . asarray ( vertices ) <NEWLINE> with np . errstate ( invalid = <STRING> ) : <NEWLINE> <TAB> return ( ( ( self . min < vertices ) & <NEWLINE> ( vertices < self . max ) ) . all ( axis = <NUMBER> ) . sum ( ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def integrate ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> from sympy . integrals import integrate <NEWLINE> return integrate ( self , * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def getI ( self ) : <NEWLINE> <TAB> <NEWLINE> M , N = self . shape <NEWLINE> if M == N : <NEWLINE> <TAB> from numpy . dual import inv as func <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> from numpy . dual import pinv as func <NEWLINE> <UNTAB> return asmatrix ( func ( self ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_transform ( self , t ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def deletecommand ( self , name ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . tk . deletecommand ( name ) <NEWLINE> try : <NEWLINE> <TAB> self . _tclCommands . remove ( name ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_chief_queue_runner ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _gradients_applied is False : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return self . _chief_queue_runner <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def mode ( self , df , scale ) : <NEWLINE> <TAB> <NEWLINE> dim , df , scale = self . _process_parameters ( df , scale ) <NEWLINE> out = self . _mode ( dim , df , scale ) <NEWLINE> return _squeeze_output ( out ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def collections_to_dsk ( collections , optimize_graph = True , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> optimizations = ( kwargs . pop ( <STRING> , None ) or <NEWLINE> config . get ( <STRING> , [ ] ) ) <NEWLINE> <NEWLINE> if optimize_graph : <NEWLINE> <TAB> groups = groupby ( optimization_function , collections ) <NEWLINE> groups = { opt : _extract_graph_and_keys ( val ) <NEWLINE> for opt , val in groups . items ( ) } <NEWLINE> <NEWLINE> for opt in optimizations : <NEWLINE> <TAB> groups = { k : ( opt ( dsk , keys ) , keys ) <NEWLINE> for k , ( dsk , keys ) in groups . items ( ) } <NEWLINE> <NEWLINE> <UNTAB> dsk = merge ( * map ( ensure_dict , [ opt ( dsk , keys , ** kwargs ) <NEWLINE> for opt , ( dsk , keys ) in groups . items ( ) ] ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dsk , _ = _extract_graph_and_keys ( collections ) <NEWLINE> <NEWLINE> <UNTAB> return dsk <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_variable_names ( self ) : <NEWLINE> <TAB> <NEWLINE> _check_checkpoint_available ( self . model_dir ) <NEWLINE> with context . graph_mode ( ) : <NEWLINE> <TAB> return [ name for name , _ in training . list_variables ( self . model_dir ) ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_first_op_from_collection ( self , key ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> op_list = ops . get_collection ( key ) <NEWLINE> if len ( op_list ) > <NUMBER> : <NEWLINE> <TAB> logging . info ( <STRING> , <NEWLINE> len ( op_list ) , key ) <NEWLINE> <UNTAB> if op_list : <NEWLINE> <TAB> return op_list [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> except LookupError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _numeric_methods ( ufunc , name ) : <NEWLINE> <TAB> <NEWLINE> return ( _binary_method ( ufunc , name ) , <NEWLINE> _reflected_binary_method ( ufunc , name ) , <NEWLINE> _inplace_binary_method ( ufunc , name ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _is_lexical_equivalent ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return self . _cloned_set . intersection ( other . _cloned_set ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_metadata_path ( self , key ) : <NEWLINE> <TAB> <NEWLINE> return <STRING> . format ( group = self . group . _v_pathname , <NEWLINE> key = key ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def LUdecompositionFF ( self ) : <NEWLINE> <TAB> <NEWLINE> from sympy . matrices import SparseMatrix <NEWLINE> zeros = SparseMatrix . zeros <NEWLINE> eye = SparseMatrix . eye <NEWLINE> <NEWLINE> n , m = self . rows , self . cols <NEWLINE> U , L , P = self . as_mutable ( ) , eye ( n ) , eye ( n ) <NEWLINE> DD = zeros ( n , n ) <NEWLINE> oldpivot = <NUMBER> <NEWLINE> <NEWLINE> for k in range ( n - <NUMBER> ) : <NEWLINE> <TAB> if U [ k , k ] == <NUMBER> : <NEWLINE> <TAB> for kpivot in range ( k + <NUMBER> , n ) : <NEWLINE> <TAB> if U [ kpivot , k ] : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> U [ k , k : ] , U [ kpivot , k : ] = U [ kpivot , k : ] , U [ k , k : ] <NEWLINE> L [ k , : k ] , L [ kpivot , : k ] = L [ kpivot , : k ] , L [ k , : k ] <NEWLINE> P [ k , : ] , P [ kpivot , : ] = P [ kpivot , : ] , P [ k , : ] <NEWLINE> <UNTAB> L [ k , k ] = Ukk = U [ k , k ] <NEWLINE> DD [ k , k ] = oldpivot * Ukk <NEWLINE> for i in range ( k + <NUMBER> , n ) : <NEWLINE> <TAB> L [ i , k ] = Uik = U [ i , k ] <NEWLINE> for j in range ( k + <NUMBER> , m ) : <NEWLINE> <TAB> U [ i , j ] = ( Ukk * U [ i , j ] - U [ k , j ] * Uik ) / oldpivot <NEWLINE> <UNTAB> U [ i , k ] = <NUMBER> <NEWLINE> <UNTAB> oldpivot = Ukk <NEWLINE> <UNTAB> DD [ n - <NUMBER> , n - <NUMBER> ] = oldpivot <NEWLINE> return P , L , DD , U <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def deprecated ( version , message = None , add_deprecation_to_docstring = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if add_deprecation_to_docstring : <NEWLINE> <TAB> header = <STRING> % ( version , ( message or <STRING> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> header = None <NEWLINE> <NEWLINE> <UNTAB> if message is None : <NEWLINE> <TAB> message = <STRING> <NEWLINE> <NEWLINE> <UNTAB> def decorate ( fn ) : <NEWLINE> <TAB> return _decorate_with_warning ( <NEWLINE> fn , exc . SADeprecationWarning , <NEWLINE> message % dict ( func = fn . __name__ ) , header ) <NEWLINE> <UNTAB> return decorate <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def append_prefix ( self , clause ) : <NEWLINE> <TAB> <NEWLINE> clause = _literal_as_text ( clause ) <NEWLINE> self . _prefixes = self . _prefixes + ( clause , ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def image_quad_norm ( inarray ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if inarray . shape [ - <NUMBER> ] != inarray . shape [ - <NUMBER> ] : <NEWLINE> <TAB> return ( <NUMBER> * np . sum ( np . sum ( np . abs ( inarray ) ** <NUMBER> , axis = - <NUMBER> ) , axis = - <NUMBER> ) - <NEWLINE> np . sum ( np . abs ( inarray [ ... , <NUMBER> ] ) ** <NUMBER> , axis = - <NUMBER> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return np . sum ( np . sum ( np . abs ( inarray ) ** <NUMBER> , axis = - <NUMBER> ) , axis = - <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def isspmatrix_csr ( x ) : <NEWLINE> <TAB> <NEWLINE> return isinstance ( x , csr_matrix ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , left , right ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> ratio = self . ratio <NEWLINE> xdistance = left . rect . centerx - right . rect . centerx <NEWLINE> ydistance = left . rect . centery - right . rect . centery <NEWLINE> distancesquared = xdistance ** <NUMBER> + ydistance ** <NUMBER> <NEWLINE> <NEWLINE> if hasattr ( left , <STRING> ) : <NEWLINE> <TAB> leftradius = left . radius * ratio <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> leftrect = left . rect <NEWLINE> leftradius = ratio * <NUMBER> * ( ( leftrect . width ** <NUMBER> + leftrect . height ** <NUMBER> ) ** <NUMBER> ) <NEWLINE> <NEWLINE> setattr ( left , <STRING> , leftradius ) <NEWLINE> <NEWLINE> <UNTAB> if hasattr ( right , <STRING> ) : <NEWLINE> <TAB> rightradius = right . radius * ratio <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rightrect = right . rect <NEWLINE> rightradius = ratio * <NUMBER> * ( ( rightrect . width ** <NUMBER> + rightrect . height ** <NUMBER> ) ** <NUMBER> ) <NEWLINE> <NEWLINE> setattr ( right , <STRING> , rightradius ) <NEWLINE> <NEWLINE> <UNTAB> return distancesquared <= ( leftradius + rightradius ) ** <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rmatmul ( self , rhs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> rhs = _preprocess_rhs ( self , rhs ) <NEWLINE> return chainer . functions . matmul ( rhs , self ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _separate ( eq , dep , others ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> terms = set ( ) <NEWLINE> for term in eq . args : <NEWLINE> <TAB> if term . is_Mul : <NEWLINE> <TAB> for i in term . args : <NEWLINE> <TAB> if i . is_Derivative and not i . has ( * others ) : <NEWLINE> <TAB> terms . add ( term ) <NEWLINE> continue <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif term . is_Derivative and not term . has ( * others ) : <NEWLINE> <TAB> terms . add ( term ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> div = set ( ) <NEWLINE> for term in terms : <NEWLINE> <TAB> ext , sep = term . expand ( ) . as_independent ( dep ) <NEWLINE> <NEWLINE> if sep . has ( * others ) : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> div . add ( ext ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if len ( div ) > <NUMBER> : <NEWLINE> <TAB> final = <NUMBER> <NEWLINE> for term in eq . args : <NEWLINE> <TAB> eqn = <NUMBER> <NEWLINE> for i in div : <NEWLINE> <TAB> eqn += term / i <NEWLINE> <UNTAB> final += simplify ( eqn ) <NEWLINE> <UNTAB> eq = final <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> div = set ( ) <NEWLINE> lhs = rhs = <NUMBER> <NEWLINE> for term in eq . args : <NEWLINE> <NEWLINE> <TAB> if not term . has ( * others ) : <NEWLINE> <TAB> lhs += term <NEWLINE> continue <NEWLINE> <NEWLINE> <UNTAB> temp , sep = term . expand ( ) . as_independent ( dep ) <NEWLINE> <NEWLINE> if sep . has ( * others ) : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> div . add ( sep ) <NEWLINE> rhs -= term . expand ( ) <NEWLINE> <NEWLINE> <UNTAB> fulldiv = reduce ( operator . add , div ) <NEWLINE> lhs = simplify ( lhs / fulldiv ) . expand ( ) <NEWLINE> rhs = simplify ( rhs / fulldiv ) . expand ( ) <NEWLINE> <NEWLINE> if lhs . has ( * others ) or rhs . has ( dep ) : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> return [ lhs , rhs ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _dt64_to_ordinalf ( d ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> extra = d - d . astype ( <STRING> ) . astype ( d . dtype ) <NEWLINE> extra = extra . astype ( <STRING> ) <NEWLINE> t0 = np . datetime64 ( <STRING> ) . astype ( <STRING> ) <NEWLINE> dt = ( d . astype ( <STRING> ) - t0 ) . astype ( np . float64 ) <NEWLINE> dt += extra . astype ( np . float64 ) / <NUMBER> <NEWLINE> dt = dt / SEC_PER_DAY + <NUMBER> <NEWLINE> <NEWLINE> NaT_int = np . datetime64 ( <STRING> ) . astype ( np . int64 ) <NEWLINE> d_int = d . astype ( np . int64 ) <NEWLINE> try : <NEWLINE> <TAB> dt [ d_int == NaT_int ] = np . nan <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> if d_int == NaT_int : <NEWLINE> <TAB> dt = np . nan <NEWLINE> <UNTAB> <UNTAB> return dt <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def argmin ( x , axis = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return math_ops . argmin ( x , axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _check_engine ( engine ) : <NEWLINE> <TAB> <NEWLINE> from pandas . core . computation . check import _NUMEXPR_INSTALLED <NEWLINE> <NEWLINE> if engine is None : <NEWLINE> <TAB> if _NUMEXPR_INSTALLED : <NEWLINE> <TAB> engine = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> engine = <STRING> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if engine not in _engines : <NEWLINE> <TAB> valid = list ( _engines . keys ( ) ) <NEWLINE> raise KeyError ( <STRING> <NEWLINE> <STRING> . format ( engine = engine , valid = valid ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if engine == <STRING> : <NEWLINE> <TAB> if not _NUMEXPR_INSTALLED : <NEWLINE> <TAB> raise ImportError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return engine <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_longitude_grid_ends ( self , degrees ) : <NEWLINE> <TAB> <NEWLINE> self . _longitude_cap = np . deg2rad ( degrees ) <NEWLINE> self . _xaxis_pretransform . clear ( ) . scale ( <NUMBER> , self . _longitude_cap * <NUMBER> ) . translate ( <NUMBER> , - self . _longitude_cap ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def minor ( self , i , j , method = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if self . rows != self . cols or self . rows < <NUMBER> : <NEWLINE> <TAB> raise NonSquareMatrixError ( ) <NEWLINE> <NEWLINE> <UNTAB> return self . minor_submatrix ( i , j ) . det ( method = method ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def setName ( self , name ) : <NEWLINE> <TAB> <NEWLINE> self . name = name <NEWLINE> self . errmsg = <STRING> + self . name <NEWLINE> if hasattr ( self , <STRING> ) : <NEWLINE> <TAB> self . exception . msg = self . errmsg <NEWLINE> <UNTAB> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _add_control_dependencies_to_lock ( self , created_ops , lock_op ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> all_args = set ( [ input_ . op for op in created_ops for input_ in op . inputs ] ) <NEWLINE> all_args . update ( <NEWLINE> input_op for op in created_ops for input_op in op . control_inputs ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> all_args_dict = dict ( ( op . _id , op ) for op in all_args ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for op in created_ops : <NEWLINE> <TAB> all_args_dict . pop ( op . _id , None ) <NEWLINE> <UNTAB> for op in lock_op . control_inputs : <NEWLINE> <TAB> all_args_dict . pop ( op . _id , None ) <NEWLINE> <UNTAB> for input_ in lock_op . inputs : <NEWLINE> <TAB> all_args_dict . pop ( input_ . op . _id , None ) <NEWLINE> <UNTAB> all_args_dict . pop ( lock_op . _id , None ) <NEWLINE> <NEWLINE> all_args = all_args_dict . values ( ) <NEWLINE> <NEWLINE> if not all_args : <NEWLINE> <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> all_args = control_flow_ops . group ( * all_args ) <NEWLINE> <NEWLINE> lock_op . _add_control_input ( all_args ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def make_list_of_t ( ts , check_graph = True , allow_graph = True , ignore_ops = False ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( ts , tf_ops . Graph ) : <NEWLINE> <TAB> if allow_graph : <NEWLINE> <TAB> return get_tensors ( ts ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if not is_iterable ( ts ) : <NEWLINE> <TAB> ts = [ ts ] <NEWLINE> <UNTAB> if not ts : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> if check_graph : <NEWLINE> <TAB> check_types = None if ignore_ops else tf_ops . Tensor <NEWLINE> get_unique_graph ( ts , check_types = check_types ) <NEWLINE> <UNTAB> return [ t for t in ts if isinstance ( t , tf_ops . Tensor ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def ode_2nd_power_series_regular ( eq , func , order , match ) : <NEWLINE> <TAB> <NEWLINE> x = func . args [ <NUMBER> ] <NEWLINE> f = func . func <NEWLINE> C0 , C1 = get_numbered_constants ( eq , num = <NUMBER> ) <NEWLINE> n = Dummy ( <STRING> ) <NEWLINE> m = Dummy ( <STRING> ) <NEWLINE> s = Wild ( <STRING> ) <NEWLINE> k = Wild ( <STRING> , exclude = [ x ] ) <NEWLINE> x0 = match . get ( <STRING> ) <NEWLINE> terms = match . get ( <STRING> , <NUMBER> ) <NEWLINE> p = match [ <STRING> ] <NEWLINE> q = match [ <STRING> ] <NEWLINE> <NEWLINE> <NEWLINE> indicial = [ ] <NEWLINE> for term in [ p , q ] : <NEWLINE> <TAB> if not term . has ( x ) : <NEWLINE> <TAB> indicial . append ( term ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> term = series ( term , n = <NUMBER> , x0 = x0 ) <NEWLINE> if isinstance ( term , Order ) : <NEWLINE> <TAB> indicial . append ( S ( <NUMBER> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for arg in term . args : <NEWLINE> <TAB> if not arg . has ( x ) : <NEWLINE> <TAB> indicial . append ( arg ) <NEWLINE> break <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> p0 , q0 = indicial <NEWLINE> sollist = solve ( m * ( m - <NUMBER> ) + m * p0 + q0 , m ) <NEWLINE> if sollist and isinstance ( sollist , list ) and all ( <NEWLINE> [ sol . is_real for sol in sollist ] ) : <NEWLINE> <TAB> serdict1 = { } <NEWLINE> serdict2 = { } <NEWLINE> if len ( sollist ) == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> m1 = m2 = sollist . pop ( ) <NEWLINE> if terms - m1 - <NUMBER> <= <NUMBER> : <NEWLINE> <TAB> return Eq ( f ( x ) , Order ( terms ) ) <NEWLINE> <UNTAB> serdict1 = _frobenius ( terms - m1 - <NUMBER> , m1 , p0 , q0 , p , q , x0 , x , C0 ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> m1 = sollist [ <NUMBER> ] <NEWLINE> m2 = sollist [ <NUMBER> ] <NEWLINE> if m1 < m2 : <NEWLINE> <TAB> m1 , m2 = m2 , m1 <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> serdict1 = _frobenius ( terms - m1 - <NUMBER> , m1 , p0 , q0 , p , q , x0 , x , C0 ) <NEWLINE> if not ( m1 - m2 ) . is_integer : <NEWLINE> <NEWLINE> <TAB> serdict2 = _frobenius ( terms - m2 - <NUMBER> , m2 , p0 , q0 , p , q , x0 , x , C1 ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> serdict2 = _frobenius ( terms - m2 - <NUMBER> , m2 , p0 , q0 , p , q , x0 , x , C1 , check = m1 ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if serdict1 : <NEWLINE> <TAB> finalseries1 = C0 <NEWLINE> for key in serdict1 : <NEWLINE> <TAB> power = int ( key . name [ <NUMBER> : ] ) <NEWLINE> finalseries1 += serdict1 [ key ] * ( x - x0 ) ** power <NEWLINE> <UNTAB> finalseries1 = ( x - x0 ) ** m1 * finalseries1 <NEWLINE> finalseries2 = S ( <NUMBER> ) <NEWLINE> if serdict2 : <NEWLINE> <TAB> for key in serdict2 : <NEWLINE> <TAB> power = int ( key . name [ <NUMBER> : ] ) <NEWLINE> finalseries2 += serdict2 [ key ] * ( x - x0 ) ** power <NEWLINE> <UNTAB> finalseries2 += C1 <NEWLINE> finalseries2 = ( x - x0 ) ** m2 * finalseries2 <NEWLINE> <UNTAB> return Eq ( f ( x ) , collect ( finalseries1 + finalseries2 , <NEWLINE> [ C0 , C1 ] ) + Order ( x ** terms ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_build_architecture ( ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> prefix = <STRING> <NEWLINE> i = sys . version . find ( prefix ) <NEWLINE> if i == - <NUMBER> : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> j = sys . version . find ( <STRING> , i ) <NEWLINE> return sys . version [ i + len ( prefix ) : j ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def save_weights ( self , filepath , overwrite = True , save_format = None ) : <NEWLINE> <TAB> <NEWLINE> filepath_is_h5 = _is_hdf5_filepath ( filepath ) <NEWLINE> if save_format is None : <NEWLINE> <TAB> if filepath_is_h5 : <NEWLINE> <TAB> save_format = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> save_format = <STRING> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> user_format = save_format . lower ( ) . strip ( ) <NEWLINE> if user_format in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> save_format = <STRING> <NEWLINE> <UNTAB> elif user_format in ( <STRING> , <STRING> , <STRING> ) : <NEWLINE> <TAB> save_format = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % ( <NEWLINE> save_format , ) ) <NEWLINE> <UNTAB> <UNTAB> if save_format == <STRING> and filepath_is_h5 : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> % filepath ) <NEWLINE> <NEWLINE> <UNTAB> if save_format == <STRING> and h5py is None : <NEWLINE> <TAB> raise ImportError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if save_format == <STRING> : <NEWLINE> <TAB> check_filepath = filepath + <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> check_filepath = filepath <NEWLINE> <NEWLINE> <UNTAB> if not overwrite and os . path . isfile ( check_filepath ) : <NEWLINE> <TAB> proceed = ask_to_proceed_with_overwrite ( check_filepath ) <NEWLINE> if not proceed : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> <UNTAB> if save_format == <STRING> : <NEWLINE> <TAB> with h5py . File ( filepath , <STRING> ) as f : <NEWLINE> <TAB> saving . save_weights_to_hdf5_group ( f , self . layers ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if context . executing_eagerly ( ) : <NEWLINE> <TAB> session = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> session = backend . get_session ( ) <NEWLINE> <UNTAB> optimizer = getattr ( self , <STRING> , None ) <NEWLINE> if ( optimizer <NEWLINE> and not isinstance ( optimizer , checkpointable . CheckpointableBase ) ) : <NEWLINE> <TAB> logging . warning ( <NEWLINE> ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> % ( optimizer , ) ) <NEWLINE> <UNTAB> self . _checkpointable_saver . save ( filepath , session = session ) <NEWLINE> <NEWLINE> checkpoint_management . update_checkpoint_state ( <NEWLINE> save_dir = os . path . dirname ( filepath ) , <NEWLINE> model_checkpoint_path = filepath , <NEWLINE> all_model_checkpoint_paths = [ filepath ] ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def vander ( x , n = None ) : <NEWLINE> <TAB> <NEWLINE> _vander = np . vander ( x , n ) <NEWLINE> m = getmask ( x ) <NEWLINE> if m is not nomask : <NEWLINE> <TAB> _vander [ m ] = <NUMBER> <NEWLINE> <UNTAB> return _vander <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def var ( a , axis = None , dtype = None , out = None , ddof = <NUMBER> , keepdims = np . _NoValue ) : <NEWLINE> <TAB> <NEWLINE> kwargs = { } <NEWLINE> if keepdims is not np . _NoValue : <NEWLINE> <TAB> kwargs [ <STRING> ] = keepdims <NEWLINE> <NEWLINE> <UNTAB> if type ( a ) is not mu . ndarray : <NEWLINE> <TAB> try : <NEWLINE> <TAB> var = a . var <NEWLINE> <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return var ( axis = axis , dtype = dtype , out = out , ddof = ddof , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return _methods . _var ( a , axis = axis , dtype = dtype , out = out , ddof = ddof , <NEWLINE> ** kwargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def crop_and_resize ( image , boxes , box_ind , crop_size , method = <STRING> , extrapolation_value = <NUMBER> , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if method is None : <NEWLINE> <TAB> method = <STRING> <NEWLINE> <UNTAB> method = _execute . make_str ( method , <STRING> ) <NEWLINE> if extrapolation_value is None : <NEWLINE> <TAB> extrapolation_value = <NUMBER> <NEWLINE> <UNTAB> extrapolation_value = _execute . make_float ( extrapolation_value , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , image = image , boxes = boxes , box_ind = box_ind , <NEWLINE> crop_size = crop_size , method = method , <NEWLINE> extrapolation_value = extrapolation_value , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) , <NEWLINE> <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , image , boxes , <NEWLINE> box_ind , crop_size , <STRING> , method , <STRING> , <NEWLINE> extrapolation_value ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return crop_and_resize_eager_fallback ( <NEWLINE> image , boxes , box_ind , crop_size , method = method , <NEWLINE> extrapolation_value = extrapolation_value , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_loc ( self , key , method = None ) : <NEWLINE> <TAB> <NEWLINE> self . _check_method ( method ) <NEWLINE> <NEWLINE> original_key = key <NEWLINE> key = self . _maybe_cast_indexed ( key ) <NEWLINE> <NEWLINE> if self . is_non_overlapping_monotonic : <NEWLINE> <TAB> if isinstance ( key , Interval ) : <NEWLINE> <TAB> left = self . _maybe_cast_slice_bound ( key . left , <STRING> , None ) <NEWLINE> right = self . _maybe_cast_slice_bound ( key . right , <STRING> , None ) <NEWLINE> key = Interval ( left , right , key . closed ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> key = self . _maybe_cast_slice_bound ( key , <STRING> , None ) <NEWLINE> <NEWLINE> <UNTAB> start , stop = self . _find_non_overlapping_monotonic_bounds ( key ) <NEWLINE> <NEWLINE> if start is None or stop is None : <NEWLINE> <TAB> return slice ( start , stop ) <NEWLINE> <UNTAB> elif start + <NUMBER> == stop : <NEWLINE> <TAB> return start <NEWLINE> <UNTAB> elif start < stop : <NEWLINE> <TAB> return slice ( start , stop ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise KeyError ( original_key ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> if isinstance ( key , Interval ) : <NEWLINE> <TAB> left , right = _get_interval_closed_bounds ( key ) <NEWLINE> return self . _engine . get_loc_interval ( left , right ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . _engine . get_loc ( key ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sin ( x ) : <NEWLINE> <TAB> <NEWLINE> return tf . sin ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def get_num_build_jobs ( ) : <NEWLINE> <TAB> <NEWLINE> from numpy . distutils . core import get_distribution <NEWLINE> envjobs = int ( os . environ . get ( <STRING> , <NUMBER> ) ) <NEWLINE> dist = get_distribution ( ) <NEWLINE> <NEWLINE> if dist is None : <NEWLINE> <TAB> return envjobs <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> cmdattr = ( getattr ( dist . get_command_obj ( <STRING> ) , <STRING> , None ) , <NEWLINE> getattr ( dist . get_command_obj ( <STRING> ) , <STRING> , None ) , <NEWLINE> getattr ( dist . get_command_obj ( <STRING> ) , <STRING> , None ) ) <NEWLINE> if all ( x is None for x in cmdattr ) : <NEWLINE> <TAB> return envjobs <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return max ( x for x in cmdattr if x is not None ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def transform ( self , values ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> values = np . asanyarray ( values ) <NEWLINE> ndim = values . ndim <NEWLINE> values = values . reshape ( ( - <NUMBER> , self . input_dims ) ) <NEWLINE> <NEWLINE> <NEWLINE> res = self . transform_affine ( self . transform_non_affine ( values ) ) <NEWLINE> <NEWLINE> <NEWLINE> if ndim == <NUMBER> : <NEWLINE> <TAB> assert not np . ma . is_masked ( res ) <NEWLINE> return res [ <NUMBER> , <NUMBER> ] <NEWLINE> <UNTAB> if ndim == <NUMBER> : <NEWLINE> <TAB> return res . reshape ( - <NUMBER> ) <NEWLINE> <UNTAB> elif ndim == <NUMBER> : <NEWLINE> <TAB> return res <NEWLINE> <UNTAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( dims = self . input_dims ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _placeholder_from_tensor ( t , default_batch_size = None ) : <NEWLINE> <TAB> <NEWLINE> batch_shape = tensor_shape . TensorShape ( [ default_batch_size ] ) <NEWLINE> shape = batch_shape . concatenate ( t . get_shape ( ) [ <NUMBER> : ] ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> name = t . op . name <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> name = None <NEWLINE> <NEWLINE> <UNTAB> return array_ops . placeholder ( dtype = t . dtype , shape = shape , name = name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _anderson_ksamp_midrank ( samples , Z , Zstar , k , n , N ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> A2akN = <NUMBER> <NEWLINE> Z_ssorted_left = Z . searchsorted ( Zstar , <STRING> ) <NEWLINE> if N == Zstar . size : <NEWLINE> <TAB> lj = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> lj = Z . searchsorted ( Zstar , <STRING> ) - Z_ssorted_left <NEWLINE> <UNTAB> Bj = Z_ssorted_left + lj / <NUMBER> <NEWLINE> for i in arange ( <NUMBER> , k ) : <NEWLINE> <TAB> s = np . sort ( samples [ i ] ) <NEWLINE> s_ssorted_right = s . searchsorted ( Zstar , side = <STRING> ) <NEWLINE> Mij = s_ssorted_right . astype ( float ) <NEWLINE> fij = s_ssorted_right - s . searchsorted ( Zstar , <STRING> ) <NEWLINE> Mij -= fij / <NUMBER> <NEWLINE> inner = lj / float ( N ) * ( N * Mij - Bj * n [ i ] ) ** <NUMBER> / ( Bj * ( N - Bj ) - N * lj / <NUMBER> ) <NEWLINE> A2akN += inner . sum ( ) / n [ i ] <NEWLINE> <UNTAB> A2akN *= ( N - <NUMBER> ) / N <NEWLINE> return A2akN <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def on_import ( self , fgraph , app , reason ) : <NEWLINE> <TAB> <NEWLINE> if app in self . debug_all_apps : <NEWLINE> <TAB> raise ProtocolError ( <STRING> ) <NEWLINE> <UNTAB> self . debug_all_apps . add ( app ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> dmap = getattr ( app . op , <STRING> , None ) <NEWLINE> vmap = getattr ( app . op , <STRING> , { } ) <NEWLINE> if dmap : <NEWLINE> <TAB> self . destroyers . add ( app ) <NEWLINE> if self . algo == <STRING> : <NEWLINE> <TAB> self . fast_destroy ( app , reason ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for o_idx , i_idx_list in iteritems ( vmap ) : <NEWLINE> <TAB> if len ( i_idx_list ) > <NUMBER> : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> , <NEWLINE> ( app . op ) ) <NEWLINE> <UNTAB> o = app . outputs [ o_idx ] <NEWLINE> i = app . inputs [ i_idx_list [ <NUMBER> ] ] <NEWLINE> self . view_i [ o ] = i <NEWLINE> self . view_o . setdefault ( i , OrderedSet ( ) ) . add ( o ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for i , input in enumerate ( app . inputs ) : <NEWLINE> <TAB> self . clients . setdefault ( input , OrderedDict ( ) ) . setdefault ( app , <NUMBER> ) <NEWLINE> self . clients [ input ] [ app ] += <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> for i , output in enumerate ( app . outputs ) : <NEWLINE> <TAB> self . clients . setdefault ( output , OrderedDict ( ) ) <NEWLINE> <NEWLINE> <UNTAB> self . stale_droot = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def subplot_tool ( targetfig = None ) : <NEWLINE> <TAB> <NEWLINE> tbar = rcParams [ <STRING> ] <NEWLINE> rcParams [ <STRING> ] = <STRING> <NEWLINE> if targetfig is None : <NEWLINE> <TAB> manager = get_current_fig_manager ( ) <NEWLINE> targetfig = manager . canvas . figure <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> for manager in _pylab_helpers . Gcf . _activeQue : <NEWLINE> <TAB> if manager . canvas . figure == targetfig : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> toolfig = figure ( figsize = ( <NUMBER> , <NUMBER> ) ) <NEWLINE> toolfig . subplots_adjust ( top = <NUMBER> ) <NEWLINE> ret = SubplotTool ( targetfig , toolfig ) <NEWLINE> rcParams [ <STRING> ] = tbar <NEWLINE> _pylab_helpers . Gcf . set_active ( manager ) <NEWLINE> return ret <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def constant_ ( tensor , val ) : <NEWLINE> <TAB> <NEWLINE> with torch . no_grad ( ) : <NEWLINE> <TAB> return tensor . fill_ ( val ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def swaplevel ( self , i = - <NUMBER> , j = - <NUMBER> , copy = True ) : <NEWLINE> <TAB> <NEWLINE> new_index = self . index . swaplevel ( i , j ) <NEWLINE> return self . _constructor ( self . _values , index = new_index , <NEWLINE> copy = copy ) . __finalize__ ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def remove ( self , keys , name = None ) : <NEWLINE> <TAB> <NEWLINE> if keys . dtype != self . _key_dtype : <NEWLINE> <TAB> raise TypeError ( <STRING> % <NEWLINE> ( self . _key_dtype , keys . dtype ) ) <NEWLINE> <NEWLINE> <UNTAB> with ops . name_scope ( <NEWLINE> name , <STRING> % self . name , <NEWLINE> ( self . resource_handle , keys , self . _default_value ) ) as name : <NEWLINE> <NEWLINE> <TAB> op = gen_lookup_ops . lookup_table_remove_v2 ( <NEWLINE> self . resource_handle , keys , name = name ) <NEWLINE> <NEWLINE> <UNTAB> return op <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def crossed_column ( keys , hash_bucket_size , hash_key = None ) : <NEWLINE> <TAB> <NEWLINE> if not hash_bucket_size or hash_bucket_size < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( hash_bucket_size ) ) <NEWLINE> <UNTAB> if not keys or len ( keys ) < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> . format ( keys ) ) <NEWLINE> <UNTAB> for key in keys : <NEWLINE> <TAB> if ( not isinstance ( key , six . string_types ) and <NEWLINE> not isinstance ( key , _CategoricalColumn ) ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( key ) ) <NEWLINE> <UNTAB> if isinstance ( key , _HashedCategoricalColumn ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( key ) ) <NEWLINE> <UNTAB> <UNTAB> return _CrossedColumn ( <NEWLINE> keys = tuple ( keys ) , hash_bucket_size = hash_bucket_size , <NEWLINE> hash_key = hash_key ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def forward ( self , x ) : <NEWLINE> <TAB> <NEWLINE> out1 = self . conv1 ( x ) <NEWLINE> out3 = self . conv3 ( relu . relu ( self . proj3 ( x ) ) ) <NEWLINE> out5 = self . conv5 ( relu . relu ( self . proj5 ( x ) ) ) <NEWLINE> pool = self . projp ( max_pooling_2d . max_pooling_2d ( <NEWLINE> x , <NUMBER> , stride = <NUMBER> , pad = <NUMBER> ) ) <NEWLINE> y = relu . relu ( concat . concat ( ( out1 , out3 , out5 , pool ) , axis = <NUMBER> ) ) <NEWLINE> return y <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def merge_from ( self , dev ) : <NEWLINE> <TAB> <NEWLINE> if dev . job is not None : <NEWLINE> <TAB> self . job = dev . job <NEWLINE> <UNTAB> if dev . replica is not None : <NEWLINE> <TAB> self . replica = dev . replica <NEWLINE> <UNTAB> if dev . task is not None : <NEWLINE> <TAB> self . task = dev . task <NEWLINE> <UNTAB> if dev . device_type is not None : <NEWLINE> <TAB> self . device_type = dev . device_type <NEWLINE> <UNTAB> if dev . device_index is not None : <NEWLINE> <TAB> self . device_index = dev . device_index <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def isolates ( G ) : <NEWLINE> <TAB> <NEWLINE> return ( n for n , d in G . degree ( ) if d == <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _sum_of_squares ( a , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> a , axis = _chk_asarray ( a , axis ) <NEWLINE> return np . sum ( a * a , axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def delete_recursively ( dirname ) : <NEWLINE> <TAB> <NEWLINE> with errors . raise_exception_on_not_ok_status ( ) as status : <NEWLINE> <TAB> pywrap_tensorflow . DeleteRecursively ( compat . as_bytes ( dirname ) , status ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def vsplit ( ary , indices_or_sections ) : <NEWLINE> <TAB> <NEWLINE> if _nx . ndim ( ary ) < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return split ( ary , indices_or_sections , <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def to_int64 ( x , name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return cast ( x , dtypes . int64 , name = name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def solve_continuous_are ( a , b , q , r , e = None , s = None , balanced = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> a , b , q , r , e , s , m , n , r_or_c , gen_are = _are_validate_args ( <NEWLINE> a , b , q , r , e , s , <STRING> ) <NEWLINE> <NEWLINE> H = np . empty ( ( <NUMBER> * m + n , <NUMBER> * m + n ) , dtype = r_or_c ) <NEWLINE> H [ : m , : m ] = a <NEWLINE> H [ : m , m : <NUMBER> * m ] = <NUMBER> <NEWLINE> H [ : m , <NUMBER> * m : ] = b <NEWLINE> H [ m : <NUMBER> * m , : m ] = - q <NEWLINE> H [ m : <NUMBER> * m , m : <NUMBER> * m ] = - a . conj ( ) . T <NEWLINE> H [ m : <NUMBER> * m , <NUMBER> * m : ] = <NUMBER> if s is None else - s <NEWLINE> H [ <NUMBER> * m : , : m ] = <NUMBER> if s is None else s . conj ( ) . T <NEWLINE> H [ <NUMBER> * m : , m : <NUMBER> * m ] = b . conj ( ) . T <NEWLINE> H [ <NUMBER> * m : , <NUMBER> * m : ] = r <NEWLINE> <NEWLINE> if gen_are and e is not None : <NEWLINE> <TAB> J = block_diag ( e , e . conj ( ) . T , np . zeros_like ( r , dtype = r_or_c ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> J = block_diag ( np . eye ( <NUMBER> * m ) , np . zeros_like ( r , dtype = r_or_c ) ) <NEWLINE> <NEWLINE> <UNTAB> if balanced : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> M = np . abs ( H ) + np . abs ( J ) <NEWLINE> M [ np . diag_indices_from ( M ) ] = <NUMBER> <NEWLINE> _ , ( sca , _ ) = matrix_balance ( M , separate = <NUMBER> , permute = <NUMBER> ) <NEWLINE> <NEWLINE> if not np . allclose ( sca , np . ones_like ( sca ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> sca = np . log2 ( sca ) <NEWLINE> <NEWLINE> s = np . round ( ( sca [ m : <NUMBER> * m ] - sca [ : m ] ) / <NUMBER> ) <NEWLINE> sca = <NUMBER> ** np . r_ [ s , - s , sca [ <NUMBER> * m : ] ] <NEWLINE> <NEWLINE> elwisescale = sca [ : , None ] * np . reciprocal ( sca ) <NEWLINE> H *= elwisescale <NEWLINE> J *= elwisescale <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> q , r = qr ( H [ : , - n : ] ) <NEWLINE> H = q [ : , n : ] . conj ( ) . T . dot ( H [ : , : <NUMBER> * m ] ) <NEWLINE> J = q [ : <NUMBER> * m , n : ] . conj ( ) . T . dot ( J [ : <NUMBER> * m , : <NUMBER> * m ] ) <NEWLINE> <NEWLINE> <NEWLINE> out_str = <STRING> if r_or_c == float else <STRING> <NEWLINE> <NEWLINE> _ , _ , _ , _ , _ , u = ordqz ( H , J , sort = <STRING> , overwrite_a = True , <NEWLINE> overwrite_b = True , check_finite = False , <NEWLINE> output = out_str ) <NEWLINE> <NEWLINE> <NEWLINE> if e is not None : <NEWLINE> <TAB> u , _ = qr ( np . vstack ( ( e . dot ( u [ : m , : m ] ) , u [ m : , : m ] ) ) ) <NEWLINE> <UNTAB> u00 = u [ : m , : m ] <NEWLINE> u10 = u [ m : , : m ] <NEWLINE> <NEWLINE> <NEWLINE> up , ul , uu = lu ( u00 ) <NEWLINE> if <NUMBER> / cond ( uu ) < np . spacing ( <NUMBER> ) : <NEWLINE> <TAB> raise LinAlgError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> x = solve_triangular ( ul . conj ( ) . T , <NEWLINE> solve_triangular ( uu . conj ( ) . T , <NEWLINE> u10 . conj ( ) . T , <NEWLINE> lower = True ) , <NEWLINE> unit_diagonal = True , <NEWLINE> ) . conj ( ) . T . dot ( up . conj ( ) . T ) <NEWLINE> if balanced : <NEWLINE> <TAB> x *= sca [ : m , None ] * sca [ : m ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> u_sym = u00 . conj ( ) . T . dot ( u10 ) <NEWLINE> n_u_sym = norm ( u_sym , <NUMBER> ) <NEWLINE> u_sym = u_sym - u_sym . conj ( ) . T <NEWLINE> sym_threshold = np . max ( [ np . spacing ( <NUMBER> ) , <NUMBER> * n_u_sym ] ) <NEWLINE> <NEWLINE> if norm ( u_sym , <NUMBER> ) > sym_threshold : <NEWLINE> <TAB> raise LinAlgError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return ( x + x . conj ( ) . T ) / <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def decons_obs_group_ids ( comp_ids , obs_ids , shape , labels , xnull ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not xnull : <NEWLINE> <TAB> lift = np . fromiter ( ( ( a == - <NUMBER> ) . any ( ) for a in labels ) , dtype = <STRING> ) <NEWLINE> shape = np . asarray ( shape , dtype = <STRING> ) + lift <NEWLINE> <NEWLINE> <UNTAB> if not is_int64_overflow_possible ( shape ) : <NEWLINE> <NEWLINE> <TAB> out = decons_group_index ( obs_ids , shape ) <NEWLINE> return out if xnull or not lift . any ( ) else [ x - y for x , y in zip ( out , lift ) ] <NEWLINE> <NEWLINE> <UNTAB> i = unique_label_indices ( comp_ids ) <NEWLINE> i8copy = lambda a : a . astype ( <STRING> , subok = False , copy = True ) <NEWLINE> return [ i8copy ( lab [ i ] ) for lab in labels ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def mycielski_graph ( n ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if n == <NUMBER> : <NEWLINE> <TAB> return nx . empty_graph ( <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return mycielskian ( nx . path_graph ( <NUMBER> ) , n - <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def findtext ( self , path , default = None , namespaces = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if path [ : <NUMBER> ] == <STRING> : <NEWLINE> <TAB> path = <STRING> + path <NEWLINE> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % path , <NEWLINE> FutureWarning , stacklevel = <NUMBER> <NEWLINE> ) <NEWLINE> <UNTAB> return self . _root . findtext ( path , default , namespaces ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ contextlib . contextmanager <NEWLINE> def _constrain_devices_and_set_default ( self , sess , use_gpu , force_gpu ) : <NEWLINE> <TAB> <NEWLINE> if context . executing_eagerly ( ) : <NEWLINE> <TAB> yield None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> with sess . graph . as_default ( ) , sess . as_default ( ) : <NEWLINE> <TAB> if force_gpu : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> gpu_name = gpu_device_name ( ) <NEWLINE> if not gpu_name : <NEWLINE> <TAB> gpu_name = <STRING> <NEWLINE> <UNTAB> with sess . graph . device ( gpu_name ) : <NEWLINE> <TAB> yield sess <NEWLINE> <UNTAB> <UNTAB> elif use_gpu : <NEWLINE> <TAB> yield sess <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> with sess . graph . device ( <STRING> ) : <NEWLINE> <TAB> yield sess <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_children ( self ) : <NEWLINE> <TAB> <NEWLINE> return list ( self . _cells . values ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def write_char ( self , arr , codec = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if arr . size == <NUMBER> or np . all ( arr == <STRING> ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> shape = ( <NUMBER> , ) * np . max ( [ arr . ndim , <NUMBER> ] ) <NEWLINE> self . write_header ( shape , mxCHAR_CLASS ) <NEWLINE> self . write_smalldata_element ( arr , miUTF8 , <NUMBER> ) <NEWLINE> return <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> arr = arr_to_chars ( arr ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> shape = arr . shape <NEWLINE> self . write_header ( shape , mxCHAR_CLASS ) <NEWLINE> if arr . dtype . kind == <STRING> and arr . size : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> n_chars = np . product ( shape ) <NEWLINE> st_arr = np . ndarray ( shape = ( ) , <NEWLINE> dtype = arr_dtype_number ( arr , n_chars ) , <NEWLINE> buffer = arr . T . copy ( ) ) <NEWLINE> <NEWLINE> st = st_arr . item ( ) . encode ( codec ) <NEWLINE> <NEWLINE> arr = np . ndarray ( shape = ( len ( st ) , ) , <NEWLINE> dtype = <STRING> , <NEWLINE> buffer = st ) <NEWLINE> <UNTAB> self . write_element ( arr , mdtype = miUTF8 ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pause ( interval ) : <NEWLINE> <TAB> <NEWLINE> manager = _pylab_helpers . Gcf . get_active ( ) <NEWLINE> if manager is not None : <NEWLINE> <TAB> canvas = manager . canvas <NEWLINE> if canvas . figure . stale : <NEWLINE> <TAB> canvas . draw_idle ( ) <NEWLINE> <UNTAB> show ( block = False ) <NEWLINE> canvas . start_event_loop ( interval ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> time . sleep ( interval ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ abc . abstractmethod <NEWLINE> def _inputs ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def exists ( self , path ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if sys . version_info [ <NUMBER> ] >= <NUMBER> : <NEWLINE> <TAB> from urllib . request import urlopen <NEWLINE> from urllib . error import URLError <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> from urllib2 import urlopen <NEWLINE> from urllib2 import URLError <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if os . path . exists ( path ) : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> upath = self . abspath ( path ) <NEWLINE> if os . path . exists ( upath ) : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . _isurl ( path ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> netfile = urlopen ( path ) <NEWLINE> netfile . close ( ) <NEWLINE> del ( netfile ) <NEWLINE> return True <NEWLINE> <UNTAB> except URLError : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def linkage ( y , method = <STRING> , metric = <STRING> , optimal_ordering = False ) : <NEWLINE> <TAB> <NEWLINE> if method not in _LINKAGE_METHODS : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( method ) ) <NEWLINE> <NEWLINE> <UNTAB> y = _convert_to_double ( np . asarray ( y , order = <STRING> ) ) <NEWLINE> <NEWLINE> if y . ndim == <NUMBER> : <NEWLINE> <TAB> distance . is_valid_y ( y , throw = True , name = <STRING> ) <NEWLINE> [ y ] = _copy_arrays_if_base_present ( [ y ] ) <NEWLINE> <UNTAB> elif y . ndim == <NUMBER> : <NEWLINE> <TAB> if method in _EUCLIDEAN_METHODS and metric != <STRING> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( method ) ) <NEWLINE> <UNTAB> if y . shape [ <NUMBER> ] == y . shape [ <NUMBER> ] and np . allclose ( np . diag ( y ) , <NUMBER> ) : <NEWLINE> <TAB> if np . all ( y >= <NUMBER> ) and np . allclose ( y , y . T ) : <NEWLINE> <TAB> _warning ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> y = distance . pdist ( y , metric ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if not np . all ( np . isfinite ( y ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> n = int ( distance . num_obs_y ( y ) ) <NEWLINE> method_code = _LINKAGE_METHODS [ method ] <NEWLINE> <NEWLINE> if method == <STRING> : <NEWLINE> <TAB> result = _hierarchy . mst_single_linkage ( y , n ) <NEWLINE> <UNTAB> elif method in [ <STRING> , <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> result = _hierarchy . nn_chain ( y , n , method_code ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result = _hierarchy . fast_linkage ( y , n , method_code ) <NEWLINE> <NEWLINE> <UNTAB> if optimal_ordering : <NEWLINE> <TAB> return optimal_leaf_ordering ( result , y ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gf_sub ( f , g , p , K ) : <NEWLINE> <TAB> <NEWLINE> if not g : <NEWLINE> <TAB> return f <NEWLINE> <UNTAB> if not f : <NEWLINE> <TAB> return gf_neg ( g , p , K ) <NEWLINE> <NEWLINE> <UNTAB> df = gf_degree ( f ) <NEWLINE> dg = gf_degree ( g ) <NEWLINE> <NEWLINE> if df == dg : <NEWLINE> <TAB> return gf_strip ( [ ( a - b ) % p for a , b in zip ( f , g ) ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> k = abs ( df - dg ) <NEWLINE> <NEWLINE> if df > dg : <NEWLINE> <TAB> h , f = f [ : k ] , f [ k : ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> h , g = gf_neg ( g [ : k ] , p , K ) , g [ k : ] <NEWLINE> <NEWLINE> <UNTAB> return h + [ ( a - b ) % p for a , b in zip ( f , g ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def leg2poly ( c ) : <NEWLINE> <TAB> <NEWLINE> from . polynomial import polyadd , polysub , polymulx <NEWLINE> <NEWLINE> [ c ] = pu . as_series ( [ c ] ) <NEWLINE> n = len ( c ) <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> return c <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> c0 = c [ - <NUMBER> ] <NEWLINE> c1 = c [ - <NUMBER> ] <NEWLINE> <NEWLINE> for i in range ( n - <NUMBER> , <NUMBER> , - <NUMBER> ) : <NEWLINE> <TAB> tmp = c0 <NEWLINE> c0 = polysub ( c [ i - <NUMBER> ] , ( c1 * ( i - <NUMBER> ) ) / i ) <NEWLINE> c1 = polyadd ( tmp , ( polymulx ( c1 ) * ( <NUMBER> * i - <NUMBER> ) ) / i ) <NEWLINE> <UNTAB> return polyadd ( c0 , polymulx ( c1 ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_color ( self , c ) : <NEWLINE> <TAB> <NEWLINE> self . set_edgecolor ( c ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_ordered ( self , inplace = False ) : <NEWLINE> <TAB> <NEWLINE> inplace = validate_bool_kwarg ( inplace , <STRING> ) <NEWLINE> return self . set_ordered ( True , inplace = inplace ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def is_math_text ( s , usetex = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if usetex is None : <NEWLINE> <TAB> usetex = rcParams [ <STRING> ] <NEWLINE> <UNTAB> if usetex : <NEWLINE> <TAB> if s == <STRING> : <NEWLINE> <TAB> s = <STRING> <NEWLINE> <UNTAB> return s , <STRING> <NEWLINE> <NEWLINE> <UNTAB> if cbook . is_math_text ( s ) : <NEWLINE> <TAB> return s , True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return s . replace ( <STRING> , <STRING> ) , False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def isin ( self , values ) : <NEWLINE> <TAB> <NEWLINE> from pandas . core . series import _sanitize_array <NEWLINE> if not is_list_like ( values ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> <NEWLINE> . format ( values_type = type ( values ) . __name__ ) ) <NEWLINE> <UNTAB> values = _sanitize_array ( values , None , None ) <NEWLINE> null_mask = np . asarray ( isna ( values ) ) <NEWLINE> code_values = self . categories . get_indexer ( values ) <NEWLINE> code_values = code_values [ null_mask | ( code_values >= <NUMBER> ) ] <NEWLINE> return algorithms . isin ( self . codes , code_values ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _prepend_edge ( arr , pad_amt , axis = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if pad_amt == <NUMBER> : <NEWLINE> <TAB> return arr <NEWLINE> <NEWLINE> <UNTAB> edge_slice = tuple ( slice ( None ) if i != axis else <NUMBER> <NEWLINE> for ( i , x ) in enumerate ( arr . shape ) ) <NEWLINE> <NEWLINE> <NEWLINE> pad_singleton = tuple ( x if i != axis else <NUMBER> <NEWLINE> for ( i , x ) in enumerate ( arr . shape ) ) <NEWLINE> edge_arr = arr [ edge_slice ] . reshape ( pad_singleton ) <NEWLINE> return np . concatenate ( ( edge_arr . repeat ( pad_amt , axis = axis ) , arr ) , <NEWLINE> axis = axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def scatter_sub ( self , sparse_delta , use_locking = False , name = None ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def grow ( self ) : <NEWLINE> <TAB> <NEWLINE> self . size -= <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _mean ( self , dim , df , scale ) : <NEWLINE> <TAB> <NEWLINE> return df * scale <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def cosine_distances ( X , Y = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> S = cosine_similarity ( X , Y ) <NEWLINE> S *= - <NUMBER> <NEWLINE> S += <NUMBER> <NEWLINE> np . clip ( S , <NUMBER> , <NUMBER> , out = S ) <NEWLINE> if X is Y or Y is None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> S [ np . diag_indices_from ( S ) ] = <NUMBER> <NEWLINE> <UNTAB> return S <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def general_k_edge_subgraphs ( G , k ) : <NEWLINE> <TAB> <NEWLINE> if k < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> find_ccs = partial ( _high_degree_components , k = k ) <NEWLINE> <NEWLINE> <NEWLINE> if G . number_of_nodes ( ) < k : <NEWLINE> <TAB> for node in G . nodes ( ) : <NEWLINE> <TAB> yield G . subgraph ( [ node ] ) . copy ( ) <NEWLINE> <UNTAB> return <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> R0 = { G . subgraph ( cc ) . copy ( ) for cc in find_ccs ( G ) } <NEWLINE> <NEWLINE> while R0 : <NEWLINE> <TAB> G1 = R0 . pop ( ) <NEWLINE> if G1 . number_of_nodes ( ) == <NUMBER> : <NEWLINE> <TAB> yield G1 <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> cut_edges = nx . minimum_edge_cut ( G1 ) <NEWLINE> cut_value = len ( cut_edges ) <NEWLINE> if cut_value < k : <NEWLINE> <NEWLINE> <TAB> G1 . remove_edges_from ( cut_edges ) <NEWLINE> for cc in find_ccs ( G1 ) : <NEWLINE> <TAB> R0 . add ( G1 . subgraph ( cc ) . copy ( ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> yield G1 <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _eval_add ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( other , SparseMatrix ) : <NEWLINE> <TAB> return self + self . _new ( other ) <NEWLINE> <NEWLINE> <UNTAB> smat = { } <NEWLINE> zero = self . _sympify ( <NUMBER> ) <NEWLINE> for key in set ( ) . union ( self . _smat . keys ( ) , other . _smat . keys ( ) ) : <NEWLINE> <TAB> sum = self . _smat . get ( key , zero ) + other . _smat . get ( key , zero ) <NEWLINE> if sum != <NUMBER> : <NEWLINE> <TAB> smat [ key ] = sum <NEWLINE> <UNTAB> <UNTAB> return self . _new ( self . rows , self . cols , smat ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def exp ( x , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , x = x , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , x ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return exp_eager_fallback ( <NEWLINE> x , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def tocoo ( self , copy = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> M , N = self . shape <NEWLINE> R , C = self . blocksize <NEWLINE> <NEWLINE> indptr_diff = np . diff ( self . indptr ) <NEWLINE> if indptr_diff . dtype . itemsize > np . dtype ( np . intp ) . itemsize : <NEWLINE> <NEWLINE> <TAB> indptr_diff_limited = indptr_diff . astype ( np . intp ) <NEWLINE> if np . any ( indptr_diff_limited != indptr_diff ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> indptr_diff = indptr_diff_limited <NEWLINE> <NEWLINE> <UNTAB> row = ( R * np . arange ( M // R ) ) . repeat ( indptr_diff ) <NEWLINE> row = row . repeat ( R * C ) . reshape ( - <NUMBER> , R , C ) <NEWLINE> row += np . tile ( np . arange ( R ) . reshape ( - <NUMBER> , <NUMBER> ) , ( <NUMBER> , C ) ) <NEWLINE> row = row . reshape ( - <NUMBER> ) <NEWLINE> <NEWLINE> col = ( C * self . indices ) . repeat ( R * C ) . reshape ( - <NUMBER> , R , C ) <NEWLINE> col += np . tile ( np . arange ( C ) , ( R , <NUMBER> ) ) <NEWLINE> col = col . reshape ( - <NUMBER> ) <NEWLINE> <NEWLINE> data = self . data . reshape ( - <NUMBER> ) <NEWLINE> <NEWLINE> if copy : <NEWLINE> <TAB> data = data . copy ( ) <NEWLINE> <NEWLINE> <UNTAB> from . coo import coo_matrix <NEWLINE> return coo_matrix ( ( data , ( row , col ) ) , shape = self . shape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def grid_forget ( self ) : <NEWLINE> <TAB> <NEWLINE> self . tk . call ( <STRING> , <STRING> , self . _w ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> def dense_gnm_random_graph ( n , m , seed = None ) : <NEWLINE> <TAB> <NEWLINE> mmax = n * ( n - <NUMBER> ) / <NUMBER> <NEWLINE> if m >= mmax : <NEWLINE> <TAB> G = complete_graph ( n ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> G = empty_graph ( n ) <NEWLINE> <NEWLINE> <UNTAB> if n == <NUMBER> or m >= mmax : <NEWLINE> <TAB> return G <NEWLINE> <NEWLINE> <UNTAB> u = <NUMBER> <NEWLINE> v = <NUMBER> <NEWLINE> t = <NUMBER> <NEWLINE> k = <NUMBER> <NEWLINE> while True : <NEWLINE> <TAB> if seed . randrange ( mmax - t ) < m - k : <NEWLINE> <TAB> G . add_edge ( u , v ) <NEWLINE> k += <NUMBER> <NEWLINE> if k == m : <NEWLINE> <TAB> return G <NEWLINE> <UNTAB> <UNTAB> t += <NUMBER> <NEWLINE> v += <NUMBER> <NEWLINE> if v == n : <NEWLINE> <TAB> u += <NUMBER> <NEWLINE> v = u + <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , trainer ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( v1 = [ <STRING> ] ) <NEWLINE> @ tf_should_use . should_use_result <NEWLINE> @ deprecated ( <STRING> , <STRING> ) <NEWLINE> def initialize_all_variables ( ) : <NEWLINE> <TAB> <NEWLINE> return global_variables_initializer ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def estimate_densities ( self , bw , cut , scale , scale_hue , gridsize ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if self . hue_names is None : <NEWLINE> <TAB> support = [ ] <NEWLINE> density = [ ] <NEWLINE> counts = np . zeros ( len ( self . plot_data ) ) <NEWLINE> max_density = np . zeros ( len ( self . plot_data ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> support = [ [ ] for _ in self . plot_data ] <NEWLINE> density = [ [ ] for _ in self . plot_data ] <NEWLINE> size = len ( self . group_names ) , len ( self . hue_names ) <NEWLINE> counts = np . zeros ( size ) <NEWLINE> max_density = np . zeros ( size ) <NEWLINE> <NEWLINE> <UNTAB> for i , group_data in enumerate ( self . plot_data ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if self . plot_hues is None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> kde_data = remove_na ( group_data ) <NEWLINE> <NEWLINE> <NEWLINE> if kde_data . size == <NUMBER> : <NEWLINE> <TAB> support . append ( np . array ( [ ] ) ) <NEWLINE> density . append ( np . array ( [ <NUMBER> ] ) ) <NEWLINE> counts [ i ] = <NUMBER> <NEWLINE> max_density [ i ] = <NUMBER> <NEWLINE> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif np . unique ( kde_data ) . size == <NUMBER> : <NEWLINE> <TAB> support . append ( np . unique ( kde_data ) ) <NEWLINE> density . append ( np . array ( [ <NUMBER> ] ) ) <NEWLINE> counts [ i ] = <NUMBER> <NEWLINE> max_density [ i ] = <NUMBER> <NEWLINE> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> kde , bw_used = self . fit_kde ( kde_data , bw ) <NEWLINE> <NEWLINE> <NEWLINE> support_i = self . kde_support ( kde_data , bw_used , cut , gridsize ) <NEWLINE> density_i = kde . evaluate ( support_i ) <NEWLINE> <NEWLINE> <NEWLINE> support . append ( support_i ) <NEWLINE> density . append ( density_i ) <NEWLINE> counts [ i ] = kde_data . size <NEWLINE> max_density [ i ] = density_i . max ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for j , hue_level in enumerate ( self . hue_names ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if not group_data . size : <NEWLINE> <TAB> support [ i ] . append ( np . array ( [ ] ) ) <NEWLINE> density [ i ] . append ( np . array ( [ <NUMBER> ] ) ) <NEWLINE> counts [ i , j ] = <NUMBER> <NEWLINE> max_density [ i , j ] = <NUMBER> <NEWLINE> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> hue_mask = self . plot_hues [ i ] == hue_level <NEWLINE> <NEWLINE> <NEWLINE> kde_data = remove_na ( group_data [ hue_mask ] ) <NEWLINE> <NEWLINE> <NEWLINE> if kde_data . size == <NUMBER> : <NEWLINE> <TAB> support [ i ] . append ( np . array ( [ ] ) ) <NEWLINE> density [ i ] . append ( np . array ( [ <NUMBER> ] ) ) <NEWLINE> counts [ i , j ] = <NUMBER> <NEWLINE> max_density [ i , j ] = <NUMBER> <NEWLINE> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif np . unique ( kde_data ) . size == <NUMBER> : <NEWLINE> <TAB> support [ i ] . append ( np . unique ( kde_data ) ) <NEWLINE> density [ i ] . append ( np . array ( [ <NUMBER> ] ) ) <NEWLINE> counts [ i , j ] = <NUMBER> <NEWLINE> max_density [ i , j ] = <NUMBER> <NEWLINE> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> kde , bw_used = self . fit_kde ( kde_data , bw ) <NEWLINE> <NEWLINE> <NEWLINE> support_ij = self . kde_support ( kde_data , bw_used , <NEWLINE> cut , gridsize ) <NEWLINE> density_ij = kde . evaluate ( support_ij ) <NEWLINE> <NEWLINE> <NEWLINE> support [ i ] . append ( support_ij ) <NEWLINE> density [ i ] . append ( density_ij ) <NEWLINE> counts [ i , j ] = kde_data . size <NEWLINE> max_density [ i , j ] = density_ij . max ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if scale == <STRING> : <NEWLINE> <TAB> self . scale_area ( density , max_density , scale_hue ) <NEWLINE> <NEWLINE> <UNTAB> elif scale == <STRING> : <NEWLINE> <TAB> self . scale_width ( density ) <NEWLINE> <NEWLINE> <UNTAB> elif scale == <STRING> : <NEWLINE> <TAB> self . scale_count ( density , counts , scale_hue ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( scale ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . support = support <NEWLINE> self . density = density <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _execcmd ( self , cmdstr ) : <NEWLINE> <TAB> <NEWLINE> frame = self . parent_frame <NEWLINE> print ( <STRING> , repr ( cmdstr ) , <STRING> , end = <STRING> ) <NEWLINE> sys . stdout . flush ( ) <NEWLINE> exec ( cmdstr , frame . f_globals , frame . f_locals ) <NEWLINE> print ( <STRING> ) <NEWLINE> sys . stdout . flush ( ) <NEWLINE> return <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def allclose ( x , y , rtol = <NUMBER> , atol = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> for xi , yi in zip ( x , y ) : <NEWLINE> <TAB> if not ( abs ( xi - yi ) <= atol + rtol * abs ( yi ) ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _lucas_extrastrong_params ( n ) : <NEWLINE> <TAB> <NEWLINE> from sympy . core import igcd <NEWLINE> from sympy . ntheory . residue_ntheory import jacobi_symbol <NEWLINE> P , Q , D = <NUMBER> , <NUMBER> , <NUMBER> <NEWLINE> while True : <NEWLINE> <TAB> g = igcd ( D , n ) <NEWLINE> if g > <NUMBER> and g != n : <NEWLINE> <TAB> return ( <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> if jacobi_symbol ( D , n ) == - <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> P += <NUMBER> <NEWLINE> D = P * P - <NUMBER> <NEWLINE> <UNTAB> return _int_tuple ( D , P , Q ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def replace ( self , * , name = _void , kind = _void , <NEWLINE> annotation = _void , default = _void ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if name is _void : <NEWLINE> <TAB> name = self . _name <NEWLINE> <NEWLINE> <UNTAB> if kind is _void : <NEWLINE> <TAB> kind = self . _kind <NEWLINE> <NEWLINE> <UNTAB> if annotation is _void : <NEWLINE> <TAB> annotation = self . _annotation <NEWLINE> <NEWLINE> <UNTAB> if default is _void : <NEWLINE> <TAB> default = self . _default <NEWLINE> <NEWLINE> <UNTAB> return type ( self ) ( name , kind , default = default , annotation = annotation ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def extract_patches ( arr , patch_shape = <NUMBER> , extraction_step = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> arr_ndim = arr . ndim <NEWLINE> <NEWLINE> if isinstance ( patch_shape , numbers . Number ) : <NEWLINE> <TAB> patch_shape = tuple ( [ patch_shape ] * arr_ndim ) <NEWLINE> <UNTAB> if isinstance ( extraction_step , numbers . Number ) : <NEWLINE> <TAB> extraction_step = tuple ( [ extraction_step ] * arr_ndim ) <NEWLINE> <NEWLINE> <UNTAB> patch_strides = arr . strides <NEWLINE> <NEWLINE> slices = tuple ( slice ( None , None , st ) for st in extraction_step ) <NEWLINE> indexing_strides = arr [ slices ] . strides <NEWLINE> <NEWLINE> patch_indices_shape = ( ( np . array ( arr . shape ) - np . array ( patch_shape ) ) // <NEWLINE> np . array ( extraction_step ) ) + <NUMBER> <NEWLINE> <NEWLINE> shape = tuple ( list ( patch_indices_shape ) + list ( patch_shape ) ) <NEWLINE> strides = tuple ( list ( indexing_strides ) + list ( patch_strides ) ) <NEWLINE> <NEWLINE> patches = as_strided ( arr , shape = shape , strides = strides ) <NEWLINE> return patches <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _currenttobest1 ( self , candidate , samples ) : <NEWLINE> <TAB> <NEWLINE> r0 , r1 = samples [ : <NUMBER> ] <NEWLINE> bprime = ( self . population [ candidate ] + self . scale * <NEWLINE> ( self . population [ <NUMBER> ] - self . population [ candidate ] + <NEWLINE> self . population [ r0 ] - self . population [ r1 ] ) ) <NEWLINE> return bprime <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _cast_to_array_dtype ( in1 , in2 ) : <NEWLINE> <TAB> <NEWLINE> if numpy . issubdtype ( in2 . dtype , numpy . float ) : <NEWLINE> <NEWLINE> <TAB> in1 = in1 . real . astype ( in2 . dtype ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> in1 = in1 . astype ( in2 . dtype ) <NEWLINE> <NEWLINE> <UNTAB> return in1 <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def asmatrix ( data , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> return matrix ( data , dtype = dtype , copy = False ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def argmax ( x , axis = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return math_ops . argmax ( x , axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def quantized_mul ( x , y , min_x , max_x , min_y , max_y , Toutput = _dtypes . qint32 , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if Toutput is None : <NEWLINE> <TAB> Toutput = _dtypes . qint32 <NEWLINE> <UNTAB> Toutput = _execute . make_type ( Toutput , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , x = x , y = y , min_x = min_x , max_x = max_x , min_y = min_y , <NEWLINE> max_y = max_y , Toutput = Toutput , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result = _QuantizedMulOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , x , y , min_x , max_x , min_y , <NEWLINE> max_y , <STRING> , Toutput ) <NEWLINE> _result = _QuantizedMulOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return quantized_mul_eager_fallback ( <NEWLINE> x , y , min_x , max_x , min_y , max_y , Toutput = Toutput , name = name , <NEWLINE> ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_directed_class ( self ) : <NEWLINE> <TAB> <NEWLINE> return nx . DiGraph <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _ixs ( self , i , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> values = self . _values <NEWLINE> if isinstance ( values , np . ndarray ) : <NEWLINE> <TAB> return libindex . get_value_at ( values , i ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return values [ i ] <NEWLINE> <UNTAB> <UNTAB> except IndexError : <NEWLINE> <TAB> raise <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> if isinstance ( i , slice ) : <NEWLINE> <TAB> indexer = self . index . _convert_slice_indexer ( i , kind = <STRING> ) <NEWLINE> return self . _get_values ( indexer ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> label = self . index [ i ] <NEWLINE> if isinstance ( label , Index ) : <NEWLINE> <TAB> return self . take ( i , axis = axis , convert = True ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return libindex . get_value_at ( self , i ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _freeze_graph_with_def_protos ( input_graph_def , output_node_names , <NEWLINE> initializer_names , shared_init_op_name , <NEWLINE> input_saver_def , input_checkpoint ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> with _ops . Graph ( ) . as_default ( ) : <NEWLINE> <TAB> _ = _importer . import_graph_def ( input_graph_def , name = <STRING> ) <NEWLINE> <NEWLINE> with _session . Session ( ) as sess : <NEWLINE> <TAB> saver = _saver_lib . Saver ( saver_def = input_saver_def ) <NEWLINE> saver . restore ( sess , input_checkpoint ) <NEWLINE> output_graph_def = _graph_util . convert_variables_to_constants ( <NEWLINE> sess , input_graph_def , output_node_names + initializer_names ) <NEWLINE> _connect_to_shared_init_op ( output_graph_def , shared_init_op_name , <NEWLINE> initializer_names ) <NEWLINE> <UNTAB> <UNTAB> return output_graph_def <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def flush ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _resource is not None : <NEWLINE> <TAB> return self . _flush ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __lt__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> other = as_dimension ( other ) <NEWLINE> if self . _value is None or other . value is None : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . _value < other . value <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def traverse ( self , obj ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return traverse ( obj , self . __traverse_options__ , self . _visitor_dict ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_autoscaley_on ( self , b ) : <NEWLINE> <TAB> <NEWLINE> self . _autoscaleYon = b <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _setroot ( self , element ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . _root = element <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def replace ( self , r , new_r , reason = None , verbose = None ) : <NEWLINE> <TAB> <NEWLINE> if verbose is None : <NEWLINE> <TAB> verbose = config . optimizer_verbose <NEWLINE> <UNTAB> if verbose : <NEWLINE> <TAB> print ( reason , r , new_r ) <NEWLINE> <UNTAB> if hasattr ( r , <STRING> ) and r . fgraph is not self : <NEWLINE> <TAB> raise Exception ( <STRING> <NEWLINE> <STRING> % r , str ( reason ) ) <NEWLINE> <UNTAB> if r . type != new_r . type : <NEWLINE> <TAB> new_r2 = r . type . convert_variable ( new_r ) <NEWLINE> <NEWLINE> if new_r2 is None or new_r2 . type != r . type : <NEWLINE> <TAB> done = dict ( ) <NEWLINE> used_ids = dict ( ) <NEWLINE> old = theano . compile . debugmode . debugprint ( <NEWLINE> r , prefix = <STRING> , depth = <NUMBER> , <NEWLINE> file = StringIO ( ) , done = done , <NEWLINE> print_type = True , <NEWLINE> used_ids = used_ids ) . getvalue ( ) <NEWLINE> new = theano . compile . debugmode . debugprint ( <NEWLINE> new_r , prefix = <STRING> , depth = <NUMBER> , <NEWLINE> file = StringIO ( ) , done = done , <NEWLINE> print_type = True , <NEWLINE> used_ids = used_ids ) . getvalue ( ) <NEWLINE> raise toolbox . BadOptimization ( <NEWLINE> r , new_r , None , None , str ( reason ) + <NEWLINE> <STRING> , old , new ) <NEWLINE> <UNTAB> new_r = new_r2 <NEWLINE> <UNTAB> if r not in self . variables : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> if theano . config . compute_test_value != <STRING> : <NEWLINE> <TAB> try : <NEWLINE> <TAB> tval = theano . gof . op . get_test_value ( r ) <NEWLINE> new_tval = theano . gof . op . get_test_value ( new_r ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> tval_shape = getattr ( tval , <STRING> , None ) <NEWLINE> new_tval_shape = getattr ( new_tval , <STRING> , None ) <NEWLINE> if tval_shape != new_tval_shape : <NEWLINE> <TAB> raise AssertionError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> % ( tval_shape , new_tval_shape ) , <NEWLINE> r , new_r , str ( reason ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> for node , i in list ( r . clients ) : <NEWLINE> <TAB> assert ( node == <STRING> and self . outputs [ i ] is r ) or ( node . inputs [ i ] is r ) <NEWLINE> self . change_input ( node , i , new_r , reason = reason ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def filled ( self , fill_value = None ) : <NEWLINE> <TAB> <NEWLINE> return asarray ( self ) . filled ( fill_value ) [ ( ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def batch_completed ( self , batch_size , duration ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def load_data ( label_mode = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if label_mode not in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> dirname = <STRING> <NEWLINE> origin = <STRING> <NEWLINE> path = get_file ( dirname , origin = origin , untar = True ) <NEWLINE> <NEWLINE> fpath = os . path . join ( path , <STRING> ) <NEWLINE> x_train , y_train = load_batch ( fpath , label_key = label_mode + <STRING> ) <NEWLINE> <NEWLINE> fpath = os . path . join ( path , <STRING> ) <NEWLINE> x_test , y_test = load_batch ( fpath , label_key = label_mode + <STRING> ) <NEWLINE> <NEWLINE> y_train = np . reshape ( y_train , ( len ( y_train ) , <NUMBER> ) ) <NEWLINE> y_test = np . reshape ( y_test , ( len ( y_test ) , <NUMBER> ) ) <NEWLINE> <NEWLINE> if K . image_data_format ( ) == <STRING> : <NEWLINE> <TAB> x_train = x_train . transpose ( <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> x_test = x_test . transpose ( <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> return ( x_train , y_train ) , ( x_test , y_test ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> def gn_graph ( n , kernel = None , create_using = None , seed = None ) : <NEWLINE> <TAB> <NEWLINE> G = empty_graph ( <NUMBER> , create_using , default = nx . DiGraph ) <NEWLINE> if not G . is_directed ( ) : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if kernel is None : <NEWLINE> <TAB> def kernel ( x ) : return x <NEWLINE> <NEWLINE> <UNTAB> if n == <NUMBER> : <NEWLINE> <TAB> return G <NEWLINE> <NEWLINE> <UNTAB> G . add_edge ( <NUMBER> , <NUMBER> ) <NEWLINE> ds = [ <NUMBER> , <NUMBER> ] <NEWLINE> <NEWLINE> for source in range ( <NUMBER> , n ) : <NEWLINE> <NEWLINE> <TAB> dist = [ kernel ( d ) for d in ds ] <NEWLINE> <NEWLINE> target = discrete_sequence ( <NUMBER> , distribution = dist , seed = seed ) [ <NUMBER> ] <NEWLINE> G . add_edge ( source , target ) <NEWLINE> ds . append ( <NUMBER> ) <NEWLINE> ds [ target ] += <NUMBER> <NEWLINE> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def execute ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . select ( ) . execute ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def create ( self , name , data , shape = None , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> with phil : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if not isinstance ( data , Empty ) : <NEWLINE> <TAB> data = numpy . asarray ( data , order = <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if shape is None : <NEWLINE> <TAB> shape = data . shape <NEWLINE> <NEWLINE> <UNTAB> use_htype = None <NEWLINE> <NEWLINE> <NEWLINE> if isinstance ( dtype , Datatype ) : <NEWLINE> <TAB> use_htype = dtype . id <NEWLINE> dtype = dtype . dtype <NEWLINE> <UNTAB> elif dtype is None : <NEWLINE> <TAB> dtype = data . dtype <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dtype = numpy . dtype ( dtype ) <NEWLINE> <NEWLINE> <UNTAB> original_dtype = dtype <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if dtype . subdtype is not None : <NEWLINE> <NEWLINE> <TAB> subdtype , subshape = dtype . subdtype <NEWLINE> <NEWLINE> <NEWLINE> if shape [ - len ( subshape ) : ] != subshape : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( subshape , shape ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> shape = shape [ <NUMBER> : len ( shape ) - len ( subshape ) ] <NEWLINE> dtype = subdtype <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> if shape is not None and numpy . product ( shape ) != numpy . product ( data . shape ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if shape != data . shape : <NEWLINE> <TAB> data = data . reshape ( shape ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not isinstance ( data , Empty ) : <NEWLINE> <TAB> data = numpy . asarray ( data , dtype = dtype ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if use_htype is None : <NEWLINE> <TAB> htype = h5t . py_create ( original_dtype , logical = True ) <NEWLINE> htype2 = h5t . py_create ( original_dtype ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> htype = use_htype <NEWLINE> htype2 = None <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( data , Empty ) : <NEWLINE> <TAB> space = h5s . create ( h5s . NULL ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> space = h5s . create_simple ( shape ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> tempname = uuid . uuid4 ( ) . hex <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> attr = h5a . create ( self . _id , self . _e ( tempname ) , htype , space ) <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> raise <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> if not isinstance ( data , Empty ) : <NEWLINE> <TAB> attr . write ( data , mtype = htype2 ) <NEWLINE> <UNTAB> <UNTAB> except : <NEWLINE> <TAB> attr . close ( ) <NEWLINE> h5a . delete ( self . _id , self . _e ( tempname ) ) <NEWLINE> raise <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <NEWLINE> <TAB> if h5a . exists ( self . _id , self . _e ( name ) ) : <NEWLINE> <TAB> h5a . delete ( self . _id , self . _e ( name ) ) <NEWLINE> <UNTAB> h5a . rename ( self . _id , self . _e ( tempname ) , self . _e ( name ) ) <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> attr . close ( ) <NEWLINE> h5a . delete ( self . _id , self . _e ( tempname ) ) <NEWLINE> raise <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def call_for_each_replica ( self , fn , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> _require_cross_replica_context ( self ) <NEWLINE> return self . _call_for_each_replica ( fn , * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_children ( self , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return [ ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _eval_expand_func ( self , ** hints ) : <NEWLINE> <TAB> <NEWLINE> n = self . args [ <NUMBER> ] <NEWLINE> if n . is_Number : <NEWLINE> <TAB> return binomial ( * self . args ) <NEWLINE> <NEWLINE> <UNTAB> k = self . args [ <NUMBER> ] <NEWLINE> if k . is_Add and n in k . args : <NEWLINE> <TAB> k = n - k <NEWLINE> <NEWLINE> <UNTAB> if k . is_Integer : <NEWLINE> <TAB> if k == S . Zero : <NEWLINE> <TAB> return S . One <NEWLINE> <UNTAB> elif k < <NUMBER> : <NEWLINE> <TAB> return S . Zero <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> n , result = self . args [ <NUMBER> ] , <NUMBER> <NEWLINE> for i in range ( <NUMBER> , k + <NUMBER> ) : <NEWLINE> <TAB> result *= n - k + i <NEWLINE> result /= i <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return binomial ( * self . args ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ abstractmethod <NEWLINE> def __add__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _ensure_float ( arr ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if issubclass ( arr . dtype . type , ( np . integer , np . bool_ ) ) : <NEWLINE> <TAB> arr = arr . astype ( float ) <NEWLINE> <UNTAB> return arr <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __new__ ( cls , expr , func = None , x = None , auto = True , quadratic = False ) : <NEWLINE> <TAB> <NEWLINE> coeff , poly = cls . _transform ( expr , x ) <NEWLINE> <NEWLINE> if not poly . is_univariate : <NEWLINE> <TAB> raise MultivariatePolynomialError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if func is None : <NEWLINE> <TAB> func = Lambda ( poly . gen , poly . gen ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> is_func = func . is_Function <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> is_func = False <NEWLINE> <NEWLINE> <UNTAB> if is_func and <NUMBER> in func . nargs : <NEWLINE> <TAB> if not isinstance ( func , Lambda ) : <NEWLINE> <TAB> func = Lambda ( poly . gen , func ( poly . gen ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % func ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> var , expr = func . variables [ <NUMBER> ] , func . expr <NEWLINE> <NEWLINE> if coeff is not S . One : <NEWLINE> <TAB> expr = expr . subs ( var , coeff * var ) <NEWLINE> <NEWLINE> <UNTAB> deg = poly . degree ( ) <NEWLINE> <NEWLINE> if not expr . has ( var ) : <NEWLINE> <TAB> return deg * expr <NEWLINE> <NEWLINE> <UNTAB> if expr . is_Add : <NEWLINE> <TAB> add_const , expr = expr . as_independent ( var ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> add_const = S . Zero <NEWLINE> <NEWLINE> <UNTAB> if expr . is_Mul : <NEWLINE> <TAB> mul_const , expr = expr . as_independent ( var ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> mul_const = S . One <NEWLINE> <NEWLINE> <UNTAB> func = Lambda ( var , expr ) <NEWLINE> <NEWLINE> rational = cls . _is_func_rational ( poly , func ) <NEWLINE> factors , terms = _pure_factors ( poly ) , [ ] <NEWLINE> <NEWLINE> for poly , k in factors : <NEWLINE> <TAB> if poly . is_linear : <NEWLINE> <TAB> term = func ( roots_linear ( poly ) [ <NUMBER> ] ) <NEWLINE> <UNTAB> elif quadratic and poly . is_quadratic : <NEWLINE> <TAB> term = sum ( map ( func , roots_quadratic ( poly ) ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if not rational or not auto : <NEWLINE> <TAB> term = cls . _new ( poly , func , auto ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> term = cls . _rational_case ( poly , func ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> terms . append ( k * term ) <NEWLINE> <NEWLINE> <UNTAB> return mul_const * Add ( * terms ) + deg * add_const <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __invert__ ( self ) : <NEWLINE> <TAB> <NEWLINE> return Not ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def chebvander ( x , deg ) : <NEWLINE> <TAB> <NEWLINE> ideg = int ( deg ) <NEWLINE> if ideg != deg : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if ideg < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> x = np . array ( x , copy = <NUMBER> , ndmin = <NUMBER> ) + <NUMBER> <NEWLINE> dims = ( ideg + <NUMBER> , ) + x . shape <NEWLINE> dtyp = x . dtype <NEWLINE> v = np . empty ( dims , dtype = dtyp ) <NEWLINE> <NEWLINE> v [ <NUMBER> ] = x * <NUMBER> + <NUMBER> <NEWLINE> if ideg > <NUMBER> : <NEWLINE> <TAB> x2 = <NUMBER> * x <NEWLINE> v [ <NUMBER> ] = x <NEWLINE> for i in range ( <NUMBER> , ideg + <NUMBER> ) : <NEWLINE> <TAB> v [ i ] = v [ i - <NUMBER> ] * x2 - v [ i - <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> return np . moveaxis ( v , <NUMBER> , - <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def eye ( N , chunks , M = None , k = <NUMBER> , dtype = float ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( chunks , Integral ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> token = tokenize ( N , chunk , M , k , dtype ) <NEWLINE> name_eye = <STRING> + token <NEWLINE> <NEWLINE> eye = { } <NEWLINE> if M is None : <NEWLINE> <TAB> M = N <NEWLINE> <NEWLINE> <UNTAB> vchunks = [ chunks ] * ( N // chunks ) <NEWLINE> if N % chunks != <NUMBER> : <NEWLINE> <TAB> vchunks . append ( N % chunks ) <NEWLINE> <UNTAB> hchunks = [ chunks ] * ( M // chunks ) <NEWLINE> if M % chunks != <NUMBER> : <NEWLINE> <TAB> hchunks . append ( M % chunks ) <NEWLINE> <NEWLINE> <UNTAB> for i , vchunk in enumerate ( vchunks ) : <NEWLINE> <TAB> for j , hchunk in enumerate ( hchunks ) : <NEWLINE> <TAB> if ( j - i - <NUMBER> ) * chunks <= k <= ( j - i + <NUMBER> ) * chunks : <NEWLINE> <TAB> eye [ name_eye , i , j ] = ( np . eye , vchunk , hchunk , k - ( j - i ) * chunks , dtype ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> eye [ name_eye , i , j ] = ( np . zeros , ( vchunk , hchunk ) , dtype ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return Array ( eye , name_eye , shape = ( N , M ) , <NEWLINE> chunks = ( chunks , chunks ) , dtype = dtype ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_dense ( self ) : <NEWLINE> <TAB> <NEWLINE> return np . asarray ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def external_values ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . values . astype ( <STRING> ) . values <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _transpose_vectorized ( M ) : <NEWLINE> <TAB> <NEWLINE> return np . transpose ( M , [ <NUMBER> , <NUMBER> , <NUMBER> ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def linear ( input , weight , bias = None ) : <NEWLINE> <TAB> <NEWLINE> if input . dim ( ) == <NUMBER> and bias is not None : <NEWLINE> <NEWLINE> <TAB> return torch . addmm ( bias , input , weight . t ( ) ) <NEWLINE> <NEWLINE> <UNTAB> output = input . matmul ( weight . t ( ) ) <NEWLINE> if bias is not None : <NEWLINE> <TAB> output += bias <NEWLINE> <UNTAB> return output <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def zeta_eager_fallback ( x , q , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ x , q ] , _ctx ) <NEWLINE> ( x , q ) = _inputs_T <NEWLINE> _inputs_flat = [ x , q ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _check_ndim ( self , values , ndim ) : <NEWLINE> <TAB> <NEWLINE> if ndim is None : <NEWLINE> <TAB> ndim = values . ndim <NEWLINE> <NEWLINE> <UNTAB> if self . _validate_ndim and values . ndim != ndim : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> raise ValueError ( msg . format ( values . ndim , ndim ) ) <NEWLINE> <NEWLINE> <UNTAB> return ndim <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _centre ( x , oshape ) : <NEWLINE> <TAB> <NEWLINE> start = ( np . array ( x . shape ) - np . array ( oshape ) ) // <NUMBER> + <NUMBER> <NEWLINE> out = x [ tuple ( slice ( s , s + n ) for s , n in zip ( start , oshape ) ) ] <NEWLINE> return out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rate ( nper , pmt , pv , fv , when = <STRING> , guess = None , tol = None , maxiter = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> when = _convert_when ( when ) <NEWLINE> default_type = Decimal if isinstance ( pmt , Decimal ) else float <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if guess is None : <NEWLINE> <TAB> guess = default_type ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if tol is None : <NEWLINE> <TAB> tol = default_type ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> ( nper , pmt , pv , fv , when ) = map ( np . asarray , [ nper , pmt , pv , fv , when ] ) <NEWLINE> <NEWLINE> rn = guess <NEWLINE> iterator = <NUMBER> <NEWLINE> close = False <NEWLINE> while ( iterator < maxiter ) and not close : <NEWLINE> <TAB> rnp1 = rn - _g_div_gp ( rn , nper , pmt , pv , fv , when ) <NEWLINE> diff = abs ( rnp1 - rn ) <NEWLINE> close = np . all ( diff < tol ) <NEWLINE> iterator += <NUMBER> <NEWLINE> rn = rnp1 <NEWLINE> <UNTAB> if not close : <NEWLINE> <NEWLINE> <TAB> return np . nan + rn <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return rn <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def reorder_categories ( self , new_categories , ordered = None , inplace = False ) : <NEWLINE> <TAB> <NEWLINE> inplace = validate_bool_kwarg ( inplace , <STRING> ) <NEWLINE> if set ( self . dtype . categories ) != set ( new_categories ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> return self . set_categories ( new_categories , ordered = ordered , <NEWLINE> inplace = inplace ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_cached_func_info ( self , path ) : <NEWLINE> <TAB> <NEWLINE> return { <STRING> : os . path . join ( self . location , * path ) } <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def And ( * args ) : <NEWLINE> <TAB> <NEWLINE> def reduce_and ( cmp_intervala , cmp_intervalb ) : <NEWLINE> <TAB> if cmp_intervala [ <NUMBER> ] is False or cmp_intervalb [ <NUMBER> ] is False : <NEWLINE> <TAB> first = False <NEWLINE> <UNTAB> elif cmp_intervala [ <NUMBER> ] is None or cmp_intervalb [ <NUMBER> ] is None : <NEWLINE> <TAB> first = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> first = True <NEWLINE> <UNTAB> if cmp_intervala [ <NUMBER> ] is False or cmp_intervalb [ <NUMBER> ] is False : <NEWLINE> <TAB> second = False <NEWLINE> <UNTAB> elif cmp_intervala [ <NUMBER> ] is None or cmp_intervalb [ <NUMBER> ] is None : <NEWLINE> <TAB> second = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> second = True <NEWLINE> <UNTAB> return ( first , second ) <NEWLINE> <UNTAB> return reduce ( reduce_and , args ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def validate_bool ( b ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( b , str ) : <NEWLINE> <TAB> b = b . lower ( ) <NEWLINE> <UNTAB> if b in ( <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <NUMBER> , True ) : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> elif b in ( <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <NUMBER> , False ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % b ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def leaky_relu ( features , alpha = <NUMBER> , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ features , alpha ] ) as name : <NEWLINE> <TAB> features = ops . convert_to_tensor ( features , name = <STRING> ) <NEWLINE> if features . dtype . is_integer : <NEWLINE> <TAB> features = math_ops . to_float ( features ) <NEWLINE> <UNTAB> if compat . forward_compatible ( <NUMBER> , <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> if isinstance ( alpha , np . ndarray ) : <NEWLINE> <TAB> alpha = np . asscalar ( alpha ) <NEWLINE> <UNTAB> return gen_nn_ops . leaky_relu ( features , alpha = alpha , name = name ) <NEWLINE> <UNTAB> alpha = ops . convert_to_tensor ( alpha , dtype = features . dtype , name = <STRING> ) <NEWLINE> return math_ops . maximum ( alpha * features , features , name = name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gradients ( loss , variables ) : <NEWLINE> <TAB> <NEWLINE> return tf . gradients ( loss , variables , colocate_gradients_with_ops = True ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def densify ( self ) : <NEWLINE> <TAB> <NEWLINE> msg = <STRING> <NEWLINE> check_is_fitted ( self , <STRING> , msg = msg ) <NEWLINE> if sp . issparse ( self . coef_ ) : <NEWLINE> <TAB> self . coef_ = self . coef_ . toarray ( ) <NEWLINE> <UNTAB> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _to_dense ( self ) : <NEWLINE> <TAB> <NEWLINE> logging . warn ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> if self . batch_shape . is_fully_defined ( ) : <NEWLINE> <TAB> batch_shape = self . batch_shape <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> batch_shape = self . batch_shape_tensor ( ) <NEWLINE> <NEWLINE> <UNTAB> dim_value = tensor_shape . dimension_value ( self . domain_dimension ) <NEWLINE> if dim_value is not None : <NEWLINE> <TAB> n = dim_value <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> n = self . domain_dimension_tensor ( ) <NEWLINE> <NEWLINE> <UNTAB> eye = linalg_ops . eye ( num_rows = n , batch_shape = batch_shape , dtype = self . dtype ) <NEWLINE> return self . matmul ( eye ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def path_to_str ( path ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( path , <STRING> ) : <NEWLINE> <TAB> path = as_str_any ( path . __fspath__ ( ) ) <NEWLINE> <UNTAB> return path <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _metrics ( self , eval_loss , predictions , labels , weights ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( <STRING> , values = ( <NEWLINE> [ eval_loss , labels , weights ] + list ( six . itervalues ( predictions ) ) ) ) : <NEWLINE> <TAB> classes = predictions [ prediction_key . PredictionKey . CLASSES ] <NEWLINE> logistic = predictions [ prediction_key . PredictionKey . LOGISTIC ] <NEWLINE> <NEWLINE> metrics = { _summary_key ( self . head_name , mkey . LOSS ) : <NEWLINE> metrics_lib . mean ( eval_loss ) } <NEWLINE> <NEWLINE> <NEWLINE> metrics [ _summary_key ( self . head_name , mkey . ACCURACY ) ] = ( <NEWLINE> metrics_lib . accuracy ( labels , classes , weights ) ) <NEWLINE> metrics [ _summary_key ( self . head_name , mkey . PREDICTION_MEAN ) ] = ( <NEWLINE> _predictions_streaming_mean ( logistic , weights ) ) <NEWLINE> metrics [ _summary_key ( self . head_name , mkey . LABEL_MEAN ) ] = ( <NEWLINE> _indicator_labels_streaming_mean ( labels , weights ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> metrics [ _summary_key ( self . head_name , mkey . ACCURACY_BASELINE ) ] = ( <NEWLINE> _indicator_labels_streaming_mean ( labels , weights ) ) <NEWLINE> metrics [ _summary_key ( self . head_name , mkey . AUC ) ] = ( <NEWLINE> _streaming_auc ( logistic , labels , weights ) ) <NEWLINE> metrics [ _summary_key ( self . head_name , mkey . AUC_PR ) ] = ( <NEWLINE> _streaming_auc ( logistic , labels , weights , curve = <STRING> ) ) <NEWLINE> <NEWLINE> for threshold in self . _thresholds : <NEWLINE> <TAB> metrics [ _summary_key ( <NEWLINE> self . head_name , mkey . ACCURACY_MEAN % threshold ) ] = ( <NEWLINE> _streaming_accuracy_at_threshold ( logistic , labels , weights , <NEWLINE> threshold ) ) <NEWLINE> <NEWLINE> metrics [ _summary_key ( <NEWLINE> self . head_name , mkey . PRECISION_MEAN % threshold ) ] = ( <NEWLINE> _streaming_precision_at_threshold ( logistic , labels , weights , <NEWLINE> threshold ) ) <NEWLINE> <NEWLINE> metrics [ _summary_key ( <NEWLINE> self . head_name , mkey . RECALL_MEAN % threshold ) ] = ( <NEWLINE> _streaming_recall_at_threshold ( logistic , labels , weights , <NEWLINE> threshold ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return metrics <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def count_nonzero ( X , axis = None , sample_weight = None ) : <NEWLINE> <TAB> <NEWLINE> if axis == - <NUMBER> : <NEWLINE> <TAB> axis = <NUMBER> <NEWLINE> <UNTAB> elif axis == - <NUMBER> : <NEWLINE> <TAB> axis = <NUMBER> <NEWLINE> <UNTAB> elif X . format != <STRING> : <NEWLINE> <TAB> raise TypeError ( <STRING> . format ( X . format ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if axis is None : <NEWLINE> <TAB> if sample_weight is None : <NEWLINE> <TAB> return X . nnz <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return np . dot ( np . diff ( X . indptr ) , sample_weight ) <NEWLINE> <UNTAB> <UNTAB> elif axis == <NUMBER> : <NEWLINE> <TAB> out = np . diff ( X . indptr ) <NEWLINE> if sample_weight is None : <NEWLINE> <TAB> return out <NEWLINE> <UNTAB> return out * sample_weight <NEWLINE> <UNTAB> elif axis == <NUMBER> : <NEWLINE> <TAB> if sample_weight is None : <NEWLINE> <TAB> return np . bincount ( X . indices , minlength = X . shape [ <NUMBER> ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> weights = np . repeat ( sample_weight , np . diff ( X . indptr ) ) <NEWLINE> return np . bincount ( X . indices , minlength = X . shape [ <NUMBER> ] , <NEWLINE> weights = weights ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( axis ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __enter__ ( self ) : <NEWLINE> <TAB> <NEWLINE> _reporters . append ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def generic_repr ( obj , additional_kw = ( ) , to_inspect = None , omit_kwarg = ( ) ) : <NEWLINE> <TAB> <NEWLINE> if to_inspect is None : <NEWLINE> <TAB> to_inspect = [ obj ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> to_inspect = _collections . to_list ( to_inspect ) <NEWLINE> <NEWLINE> <UNTAB> missing = object ( ) <NEWLINE> <NEWLINE> pos_args = [ ] <NEWLINE> kw_args = _collections . OrderedDict ( ) <NEWLINE> vargs = None <NEWLINE> for i , insp in enumerate ( to_inspect ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> ( _args , _vargs , vkw , defaults ) = compat . inspect_getargspec ( insp . __init__ ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> default_len = defaults and len ( defaults ) or <NUMBER> <NEWLINE> if i == <NUMBER> : <NEWLINE> <TAB> if _vargs : <NEWLINE> <TAB> vargs = _vargs <NEWLINE> <UNTAB> if default_len : <NEWLINE> <TAB> pos_args . extend ( _args [ <NUMBER> : - default_len ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pos_args . extend ( _args [ <NUMBER> : ] ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> kw_args . update ( [ <NEWLINE> ( arg , missing ) for arg in _args [ <NUMBER> : - default_len ] <NEWLINE> ] ) <NEWLINE> <NEWLINE> <UNTAB> if default_len : <NEWLINE> <TAB> kw_args . update ( [ <NEWLINE> ( arg , default ) <NEWLINE> for arg , default <NEWLINE> in zip ( _args [ - default_len : ] , defaults ) <NEWLINE> ] ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> output = [ ] <NEWLINE> <NEWLINE> output . extend ( repr ( getattr ( obj , arg , None ) ) for arg in pos_args ) <NEWLINE> <NEWLINE> if vargs is not None and hasattr ( obj , vargs ) : <NEWLINE> <TAB> output . extend ( [ repr ( val ) for val in getattr ( obj , vargs ) ] ) <NEWLINE> <NEWLINE> <UNTAB> for arg , defval in kw_args . items ( ) : <NEWLINE> <TAB> if arg in omit_kwarg : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> val = getattr ( obj , arg , missing ) <NEWLINE> if val is not missing and val != defval : <NEWLINE> <TAB> output . append ( <STRING> % ( arg , val ) ) <NEWLINE> <UNTAB> <UNTAB> except Exception : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if additional_kw : <NEWLINE> <TAB> for arg , defval in additional_kw : <NEWLINE> <TAB> try : <NEWLINE> <TAB> val = getattr ( obj , arg , missing ) <NEWLINE> if val is not missing and val != defval : <NEWLINE> <TAB> output . append ( <STRING> % ( arg , val ) ) <NEWLINE> <UNTAB> <UNTAB> except Exception : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return <STRING> % ( obj . __class__ . __name__ , <STRING> . join ( output ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def import_event ( tensor , name = None ) : <NEWLINE> <TAB> <NEWLINE> return gen_summary_ops . import_event ( <NEWLINE> context . context ( ) . summary_writer_resource , tensor , name = name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def sqrt_mod_iter ( a , p , domain = int ) : <NEWLINE> <TAB> <NEWLINE> from sympy . polys . galoistools import gf_crt1 , gf_crt2 <NEWLINE> from sympy . polys . domains import ZZ <NEWLINE> a , p = as_int ( a ) , abs ( as_int ( p ) ) <NEWLINE> if isprime ( p ) : <NEWLINE> <TAB> a = a % p <NEWLINE> if a == <NUMBER> : <NEWLINE> <TAB> res = _sqrt_mod1 ( a , p , <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> res = _sqrt_mod_prime_power ( a , p , <NUMBER> ) <NEWLINE> <UNTAB> if res : <NEWLINE> <TAB> if domain is ZZ : <NEWLINE> <TAB> for x in res : <NEWLINE> <TAB> yield x <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for x in res : <NEWLINE> <TAB> yield domain ( x ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> f = factorint ( p ) <NEWLINE> v = [ ] <NEWLINE> pv = [ ] <NEWLINE> for px , ex in f . items ( ) : <NEWLINE> <TAB> if a % px == <NUMBER> : <NEWLINE> <TAB> rx = _sqrt_mod1 ( a , px , ex ) <NEWLINE> if not rx : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> rx = _sqrt_mod_prime_power ( a , px , ex ) <NEWLINE> if not rx : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> <UNTAB> v . append ( rx ) <NEWLINE> pv . append ( px ** ex ) <NEWLINE> <UNTAB> mm , e , s = gf_crt1 ( pv , ZZ ) <NEWLINE> if domain is ZZ : <NEWLINE> <TAB> for vx in _product ( * v ) : <NEWLINE> <TAB> r = gf_crt2 ( vx , pv , mm , e , s , ZZ ) <NEWLINE> yield r <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for vx in _product ( * v ) : <NEWLINE> <TAB> r = gf_crt2 ( vx , pv , mm , e , s , ZZ ) <NEWLINE> yield domain ( r ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def neg ( f ) : <NEWLINE> <TAB> <NEWLINE> return f . per ( dmp_neg ( f . num , f . lev , f . dom ) , f . den , cancel = False ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def moments_central ( image , center = None , cc = None , order = <NUMBER> , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if cc is not None : <NEWLINE> <TAB> message = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> warn ( message ) <NEWLINE> if <STRING> in kwargs and center is None : <NEWLINE> <TAB> center = ( kwargs [ <STRING> ] , cc ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> center = ( center , cc ) <NEWLINE> <UNTAB> return moments_central ( image , center = center , order = order ) . T <NEWLINE> <UNTAB> if center is None : <NEWLINE> <TAB> center = centroid ( image ) <NEWLINE> <UNTAB> calc = image . astype ( float ) <NEWLINE> for dim , dim_length in enumerate ( image . shape ) : <NEWLINE> <TAB> delta = np . arange ( dim_length , dtype = float ) - center [ dim ] <NEWLINE> powers_of_delta = delta [ : , np . newaxis ] ** np . arange ( order + <NUMBER> ) <NEWLINE> calc = np . rollaxis ( calc , dim , image . ndim ) <NEWLINE> calc = np . dot ( calc , powers_of_delta ) <NEWLINE> calc = np . rollaxis ( calc , - <NUMBER> , dim ) <NEWLINE> <UNTAB> return calc <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ Substitution ( name = <STRING> ) <NEWLINE> @ Appender ( _doc_template ) <NEWLINE> def resample ( self , rule , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> from pandas . core . resample import get_resampler_for_grouping <NEWLINE> return get_resampler_for_grouping ( self , rule , * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def recover_last_checkpoints ( self , checkpoint_paths ) : <NEWLINE> <TAB> <NEWLINE> mtimes = checkpoint_management . get_checkpoint_mtimes ( checkpoint_paths ) <NEWLINE> self . set_last_checkpoints_with_time ( list ( zip ( checkpoint_paths , mtimes ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def smallest_angle_between ( l1 , l2 ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( l1 , LinearEntity ) and not isinstance ( l2 , LinearEntity ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> v1 , v2 = l1 . direction , l2 . direction <NEWLINE> return acos ( abs ( v1 . dot ( v2 ) ) / ( abs ( v1 ) * abs ( v2 ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def exponential ( x ) : <NEWLINE> <TAB> <NEWLINE> return K . exp ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , A , structure = None , use_exact_onenorm = False ) : <NEWLINE> <TAB> <NEWLINE> self . A = A <NEWLINE> self . _A2 = None <NEWLINE> self . _A4 = None <NEWLINE> self . _A6 = None <NEWLINE> self . _A8 = None <NEWLINE> self . _A10 = None <NEWLINE> self . _d4_exact = None <NEWLINE> self . _d6_exact = None <NEWLINE> self . _d8_exact = None <NEWLINE> self . _d10_exact = None <NEWLINE> self . _d4_approx = None <NEWLINE> self . _d6_approx = None <NEWLINE> self . _d8_approx = None <NEWLINE> self . _d10_approx = None <NEWLINE> self . ident = _ident_like ( A ) <NEWLINE> self . structure = structure <NEWLINE> self . use_exact_onenorm = use_exact_onenorm <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def nP ( n , k = None , replacement = False ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> n = as_int ( n ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> return Integer ( _nP ( _multiset_histogram ( n ) , k , replacement ) ) <NEWLINE> <UNTAB> return Integer ( _nP ( n , k , replacement ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_metadata ( self , path ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> item_path = os . path . join ( self . location , * path ) <NEWLINE> filename = os . path . join ( item_path , <STRING> ) <NEWLINE> with self . _open_item ( filename , <STRING> ) as f : <NEWLINE> <TAB> return json . loads ( f . read ( ) . decode ( <STRING> ) ) <NEWLINE> <UNTAB> <UNTAB> except : <NEWLINE> <TAB> return { } <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def needs_i8_conversion ( arr_or_dtype ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if arr_or_dtype is None : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> return ( is_datetime_or_timedelta_dtype ( arr_or_dtype ) or <NEWLINE> is_datetime64tz_dtype ( arr_or_dtype ) or <NEWLINE> is_period_dtype ( arr_or_dtype ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def chi2_kernel ( X , Y = None , gamma = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> K = additive_chi2_kernel ( X , Y ) <NEWLINE> K *= gamma <NEWLINE> return np . exp ( K , K ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def cut_size ( G , S , T = None , weight = None ) : <NEWLINE> <TAB> <NEWLINE> edges = nx . edge_boundary ( G , S , T , data = weight , default = <NUMBER> ) <NEWLINE> if G . is_directed ( ) : <NEWLINE> <TAB> edges = chain ( edges , nx . edge_boundary ( G , T , S , data = weight , default = <NUMBER> ) ) <NEWLINE> <UNTAB> return sum ( weight for u , v , weight in edges ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def translate ( self , x = <NUMBER> , y = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return Point ( self . x + x , self . y + y ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def deepmap ( func , * seqs ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( seqs [ <NUMBER> ] , ( list , Iterator ) ) : <NEWLINE> <TAB> return [ deepmap ( func , * items ) for items in zip ( * seqs ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return func ( * seqs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def concatenate ( inputs , axis = - <NUMBER> , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return Concatenate ( axis = axis , ** kwargs ) ( inputs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_sympy ( self , a ) : <NEWLINE> <TAB> <NEWLINE> return self . ring . from_expr ( a ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def params ( self , * optionaldict , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return self . _params ( False , optionaldict , kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def real_roots ( f , multiple = True , radicals = True ) : <NEWLINE> <TAB> <NEWLINE> reals = sympy . polys . rootoftools . CRootOf . real_roots ( f , radicals = radicals ) <NEWLINE> <NEWLINE> if multiple : <NEWLINE> <TAB> return reals <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return group ( reals , multiple = False ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _attempt_YYYYMMDD ( arg , errors ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def calc ( carg ) : <NEWLINE> <NEWLINE> <TAB> carg = carg . astype ( object ) <NEWLINE> parsed = parsing . try_parse_year_month_day ( carg / <NUMBER> , <NEWLINE> carg / <NUMBER> % <NUMBER> , <NEWLINE> carg % <NUMBER> ) <NEWLINE> return tslib . array_to_datetime ( parsed , errors = errors ) <NEWLINE> <NEWLINE> <UNTAB> def calc_with_mask ( carg , mask ) : <NEWLINE> <TAB> result = np . empty ( carg . shape , dtype = <STRING> ) <NEWLINE> iresult = result . view ( <STRING> ) <NEWLINE> iresult [ ~ mask ] = tslib . iNaT <NEWLINE> result [ mask ] = calc ( carg [ mask ] . astype ( np . float64 ) . astype ( np . int64 ) ) . astype ( <STRING> ) <NEWLINE> return result <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> return calc ( arg . astype ( np . int64 ) ) <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> carg = arg . astype ( np . float64 ) <NEWLINE> return calc_with_mask ( carg , notna ( carg ) ) <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> mask = ~ algorithms . isin ( arg , list ( tslib . nat_strings ) ) <NEWLINE> return calc_with_mask ( arg , mask ) <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> return None <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def krackhardt_kite_graph ( create_using = None ) : <NEWLINE> <TAB> <NEWLINE> description = [ <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <NUMBER> , <NEWLINE> [ [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> , <NUMBER> ] , <NEWLINE> [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , [ <NUMBER> ] ] <NEWLINE> ] <NEWLINE> G = make_small_undirected_graph ( description , create_using ) <NEWLINE> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def read_zfile ( file_handle ) : <NEWLINE> <TAB> <NEWLINE> file_handle . seek ( <NUMBER> ) <NEWLINE> header_length = len ( _ZFILE_PREFIX ) + _MAX_LEN <NEWLINE> length = file_handle . read ( header_length ) <NEWLINE> length = length [ len ( _ZFILE_PREFIX ) : ] <NEWLINE> length = int ( length , <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> next_byte = file_handle . read ( <NUMBER> ) <NEWLINE> if next_byte != <STRING> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> file_handle . seek ( header_length ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> data = zlib . decompress ( file_handle . read ( ) , <NUMBER> , length ) <NEWLINE> assert len ( data ) == length , ( <NEWLINE> <STRING> <NEWLINE> <STRING> % file_handle ) <NEWLINE> return data <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def negative_sampling ( x , t , W , sampler , sample_size , reduce = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return ( <NEWLINE> NegativeSamplingFunction ( sampler , sample_size , reduce ) <NEWLINE> . apply ( ( x , t , W ) ) <NEWLINE> ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit ( self , X , y = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> X = check_array ( X , accept_sparse = <STRING> , copy = self . copy , estimator = self , <NEWLINE> dtype = FLOAT_DTYPES , force_all_finite = <STRING> ) <NEWLINE> <NEWLINE> q_min , q_max = self . quantile_range <NEWLINE> if not <NUMBER> <= q_min <= q_max <= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % <NEWLINE> str ( self . quantile_range ) ) <NEWLINE> <NEWLINE> <UNTAB> if self . with_centering : <NEWLINE> <TAB> if sparse . issparse ( X ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> self . center_ = nanmedian ( X , axis = <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . center_ = None <NEWLINE> <NEWLINE> <UNTAB> if self . with_scaling : <NEWLINE> <TAB> quantiles = [ ] <NEWLINE> for feature_idx in range ( X . shape [ <NUMBER> ] ) : <NEWLINE> <TAB> if sparse . issparse ( X ) : <NEWLINE> <TAB> column_nnz_data = X . data [ X . indptr [ feature_idx ] : <NEWLINE> X . indptr [ feature_idx + <NUMBER> ] ] <NEWLINE> column_data = np . zeros ( shape = X . shape [ <NUMBER> ] , dtype = X . dtype ) <NEWLINE> column_data [ : len ( column_nnz_data ) ] = column_nnz_data <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> column_data = X [ : , feature_idx ] <NEWLINE> <NEWLINE> <UNTAB> quantiles . append ( nanpercentile ( column_data , <NEWLINE> self . quantile_range ) ) <NEWLINE> <NEWLINE> <UNTAB> quantiles = np . transpose ( quantiles ) <NEWLINE> <NEWLINE> self . scale_ = quantiles [ <NUMBER> ] - quantiles [ <NUMBER> ] <NEWLINE> self . scale_ = _handle_zeros_in_scale ( self . scale_ , copy = False ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . scale_ = None <NEWLINE> <NEWLINE> <UNTAB> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def str_match ( arr , pat , case = True , flags = <NUMBER> , na = np . nan , as_indexer = None ) : <NEWLINE> <TAB> <NEWLINE> if not case : <NEWLINE> <TAB> flags |= re . IGNORECASE <NEWLINE> <NEWLINE> <UNTAB> regex = re . compile ( pat , flags = flags ) <NEWLINE> <NEWLINE> if ( as_indexer is False ) and ( regex . groups > <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> elif as_indexer is not None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> , <NEWLINE> FutureWarning , stacklevel = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> dtype = bool <NEWLINE> f = lambda x : bool ( regex . match ( x ) ) <NEWLINE> <NEWLINE> return _na_map ( f , arr , na , dtype = dtype ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , * system , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> dt = kwargs . pop ( <STRING> , True ) <NEWLINE> super ( dlti , self ) . __init__ ( * system , ** kwargs ) <NEWLINE> <NEWLINE> self . dt = dt <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def maximum ( x , y ) : <NEWLINE> <TAB> <NEWLINE> return math_ops . maximum ( x , y ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _can_hold_element ( self , element ) : <NEWLINE> <TAB> <NEWLINE> dtype = self . values . dtype . type <NEWLINE> tipo = maybe_infer_dtype_type ( element ) <NEWLINE> if tipo is not None : <NEWLINE> <TAB> return issubclass ( tipo . type , dtype ) <NEWLINE> <UNTAB> return isinstance ( element , dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _process_parameters ( self , dim ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if dim is None or not np . isscalar ( dim ) or dim <= <NUMBER> or dim != int ( dim ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return dim <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _bell_incomplete_poly ( n , k , symbols ) : <NEWLINE> <TAB> <NEWLINE> if ( n == <NUMBER> ) and ( k == <NUMBER> ) : <NEWLINE> <TAB> return S . One <NEWLINE> <UNTAB> elif ( n == <NUMBER> ) or ( k == <NUMBER> ) : <NEWLINE> <TAB> return S . Zero <NEWLINE> <UNTAB> s = S . Zero <NEWLINE> a = S . One <NEWLINE> for m in range ( <NUMBER> , n - k + <NUMBER> ) : <NEWLINE> <TAB> s += a * bell . _bell_incomplete_poly ( <NEWLINE> n - m , k - <NUMBER> , symbols ) * symbols [ m - <NUMBER> ] <NEWLINE> a = a * ( n - m ) / m <NEWLINE> <UNTAB> return expand_mul ( s ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rank_order ( image ) : <NEWLINE> <TAB> <NEWLINE> flat_image = image . ravel ( ) <NEWLINE> sort_order = flat_image . argsort ( ) . astype ( np . uint32 ) <NEWLINE> flat_image = flat_image [ sort_order ] <NEWLINE> sort_rank = np . zeros_like ( sort_order ) <NEWLINE> is_different = flat_image [ : - <NUMBER> ] != flat_image [ <NUMBER> : ] <NEWLINE> np . cumsum ( is_different , out = sort_rank [ <NUMBER> : ] ) <NEWLINE> original_values = np . zeros ( ( sort_rank [ - <NUMBER> ] + <NUMBER> , ) , image . dtype ) <NEWLINE> original_values [ <NUMBER> ] = flat_image [ <NUMBER> ] <NEWLINE> original_values [ <NUMBER> : ] = flat_image [ <NUMBER> : ] [ is_different ] <NEWLINE> int_image = np . zeros_like ( sort_order ) <NEWLINE> int_image [ sort_order ] = sort_rank <NEWLINE> return ( int_image . reshape ( image . shape ) , original_values ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def validate_data_columns ( self , data_columns , min_itemsize ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not len ( self . non_index_axes ) : <NEWLINE> <TAB> return [ ] <NEWLINE> <NEWLINE> <UNTAB> axis , axis_labels = self . non_index_axes [ <NUMBER> ] <NEWLINE> info = self . info . get ( axis , dict ( ) ) <NEWLINE> if info . get ( <STRING> ) == <STRING> and data_columns : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( axis , data_columns ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if data_columns is True : <NEWLINE> <TAB> data_columns = list ( axis_labels ) <NEWLINE> <UNTAB> elif data_columns is None : <NEWLINE> <TAB> data_columns = [ ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( min_itemsize , dict ) : <NEWLINE> <NEWLINE> <TAB> existing_data_columns = set ( data_columns ) <NEWLINE> data_columns . extend ( [ <NEWLINE> k for k in min_itemsize . keys ( ) <NEWLINE> if k != <STRING> and k not in existing_data_columns <NEWLINE> ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return [ c for c in data_columns if c in axis_labels ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def ode_Riccati_special_minus2 ( eq , func , order , match ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> x = func . args [ <NUMBER> ] <NEWLINE> f = func . func <NEWLINE> r = match <NEWLINE> a2 , b2 , c2 , d2 = [ r [ r [ s ] ] for s in <STRING> . split ( ) ] <NEWLINE> C1 = get_numbered_constants ( eq , num = <NUMBER> ) <NEWLINE> mu = sqrt ( <NUMBER> * d2 * b2 - ( a2 - c2 ) ** <NUMBER> ) <NEWLINE> return Eq ( f ( x ) , ( a2 - c2 - mu * tan ( mu / ( <NUMBER> * a2 ) * log ( x ) + C1 ) ) / ( <NUMBER> * b2 * x ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def eval ( self , expr , inplace = False , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> from pandas . core . computation . eval import eval as _eval <NEWLINE> <NEWLINE> inplace = validate_bool_kwarg ( inplace , <STRING> ) <NEWLINE> resolvers = kwargs . pop ( <STRING> , None ) <NEWLINE> kwargs [ <STRING> ] = kwargs . pop ( <STRING> , <NUMBER> ) + <NUMBER> <NEWLINE> if resolvers is None : <NEWLINE> <TAB> index_resolvers = self . _get_index_resolvers ( ) <NEWLINE> resolvers = dict ( self . iteritems ( ) ) , index_resolvers <NEWLINE> <UNTAB> if <STRING> not in kwargs : <NEWLINE> <TAB> kwargs [ <STRING> ] = self <NEWLINE> <UNTAB> kwargs [ <STRING> ] = kwargs . get ( <STRING> , ( ) ) + tuple ( resolvers ) <NEWLINE> return _eval ( expr , inplace = inplace , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_monotonic ( expression , interval = S . Reals , symbol = None ) : <NEWLINE> <TAB> <NEWLINE> expression = sympify ( expression ) <NEWLINE> <NEWLINE> free = expression . free_symbols <NEWLINE> if symbol is None and len ( free ) > <NUMBER> : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> ) <NEWLINE> <NEWLINE> <UNTAB> x = symbol or ( free . pop ( ) if free else Symbol ( <STRING> ) ) <NEWLINE> turning_points = solveset ( expression . diff ( x ) , x , interval ) <NEWLINE> return interval . intersection ( turning_points ) is S . EmptySet <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def ambiguities ( signatures ) : <NEWLINE> <TAB> <NEWLINE> signatures = list ( map ( tuple , signatures ) ) <NEWLINE> return set ( [ ( a , b ) for a in signatures for b in signatures <NEWLINE> if hash ( a ) < hash ( b ) <NEWLINE> and ambiguous ( a , b ) <NEWLINE> and not any ( supercedes ( c , a ) and supercedes ( c , b ) <NEWLINE> for c in signatures ) ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def hamming ( M , sym = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return general_hamming ( M , <NUMBER> , sym ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_slot_names ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return self . _opt . get_slot_names ( * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _clean_event ( self , event ) : <NEWLINE> <TAB> <NEWLINE> if event . xdata is None : <NEWLINE> <TAB> event = self . _prev_event <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> event = copy . copy ( event ) <NEWLINE> <UNTAB> event . xdata , event . ydata = self . _get_data ( event ) <NEWLINE> <NEWLINE> self . _prev_event = event <NEWLINE> return event <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def assertMultiLineEqual ( self , first , second , msg = None ) : <NEWLINE> <TAB> <NEWLINE> self . assertIsInstance ( first , str , <STRING> ) <NEWLINE> self . assertIsInstance ( second , str , <STRING> ) <NEWLINE> <NEWLINE> if first != second : <NEWLINE> <NEWLINE> <TAB> if ( len ( first ) > self . _diffThreshold or <NEWLINE> len ( second ) > self . _diffThreshold ) : <NEWLINE> <TAB> self . _baseAssertEqual ( first , second , msg ) <NEWLINE> <UNTAB> firstlines = first . splitlines ( keepends = True ) <NEWLINE> secondlines = second . splitlines ( keepends = True ) <NEWLINE> if len ( firstlines ) == <NUMBER> and first . strip ( <STRING> ) == first : <NEWLINE> <TAB> firstlines = [ first + <STRING> ] <NEWLINE> secondlines = [ second + <STRING> ] <NEWLINE> <UNTAB> standardMsg = <STRING> % _common_shorten_repr ( first , second ) <NEWLINE> diff = <STRING> + <STRING> . join ( difflib . ndiff ( firstlines , secondlines ) ) <NEWLINE> standardMsg = self . _truncateMessage ( standardMsg , diff ) <NEWLINE> self . fail ( self . _formatMessage ( msg , standardMsg ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def vring ( symbols , domain , order = lex ) : <NEWLINE> <TAB> <NEWLINE> _ring = PolyRing ( symbols , domain , order ) <NEWLINE> pollute ( [ sym . name for sym in _ring . symbols ] , _ring . gens ) <NEWLINE> return _ring <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ add_arg_scope <NEWLINE> def dense_to_sparse ( tensor , eos_token = <NUMBER> , outputs_collections = None , scope = None ) : <NEWLINE> <TAB> <NEWLINE> with variable_scope . variable_scope ( scope , <STRING> , [ tensor ] ) as sc : <NEWLINE> <TAB> tensor = ops . convert_to_tensor ( tensor ) <NEWLINE> indices = array_ops . where ( <NEWLINE> math_ops . not_equal ( tensor , constant_op . constant ( eos_token , <NEWLINE> tensor . dtype ) ) ) <NEWLINE> values = array_ops . gather_nd ( tensor , indices ) <NEWLINE> shape = array_ops . shape ( tensor , out_type = dtypes . int64 ) <NEWLINE> outputs = sparse_tensor . SparseTensor ( indices , values , shape ) <NEWLINE> return utils . collect_named_outputs ( outputs_collections , sc . name , outputs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def pinv_solve ( self , B , arbitrary_matrix = None ) : <NEWLINE> <TAB> <NEWLINE> from sympy . matrices import eye <NEWLINE> A = self <NEWLINE> A_pinv = self . pinv ( ) <NEWLINE> if arbitrary_matrix is None : <NEWLINE> <TAB> rows , cols = A . cols , B . cols <NEWLINE> w = symbols ( <STRING> . format ( rows , cols ) , cls = Dummy ) <NEWLINE> arbitrary_matrix = self . __class__ ( cols , rows , w ) . T <NEWLINE> <UNTAB> return A_pinv * B + ( eye ( A . cols ) - A_pinv * A ) * arbitrary_matrix <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_gegenbauer ( n , a , K ) : <NEWLINE> <TAB> <NEWLINE> seq = [ [ K . one ] , [ K ( <NUMBER> ) * a , K . zero ] ] <NEWLINE> <NEWLINE> for i in range ( <NUMBER> , n + <NUMBER> ) : <NEWLINE> <TAB> f1 = K ( <NUMBER> ) * ( i + a - K . one ) / i <NEWLINE> f2 = ( i + K ( <NUMBER> ) * a - K ( <NUMBER> ) ) / i <NEWLINE> p1 = dup_mul_ground ( dup_lshift ( seq [ - <NUMBER> ] , <NUMBER> , K ) , f1 , K ) <NEWLINE> p2 = dup_mul_ground ( seq [ - <NUMBER> ] , f2 , K ) <NEWLINE> seq . append ( dup_sub ( p1 , p2 , K ) ) <NEWLINE> <NEWLINE> <UNTAB> return seq [ n ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def idealfourths ( data , axis = None ) : <NEWLINE> <TAB> <NEWLINE> def _idf ( data ) : <NEWLINE> <TAB> x = data . compressed ( ) <NEWLINE> n = len ( x ) <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> return [ np . nan , np . nan ] <NEWLINE> <UNTAB> ( j , h ) = divmod ( n / <NUMBER> + <NUMBER> / <NUMBER> , <NUMBER> ) <NEWLINE> j = int ( j ) <NEWLINE> qlo = ( <NUMBER> - h ) * x [ j - <NUMBER> ] + h * x [ j ] <NEWLINE> k = n - j <NEWLINE> qup = ( <NUMBER> - h ) * x [ k ] + h * x [ k - <NUMBER> ] <NEWLINE> return [ qlo , qup ] <NEWLINE> <UNTAB> data = ma . sort ( data , axis = axis ) . view ( MaskedArray ) <NEWLINE> if ( axis is None ) : <NEWLINE> <TAB> return _idf ( data ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return ma . apply_along_axis ( _idf , axis , data ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def scatter_update ( self , sparse_delta , use_locking = False , name = None ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def UnixCCompiler__compile ( self , obj , src , ext , cc_args , extra_postargs , pp_opts ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> ccomp = self . compiler_so <NEWLINE> if ccomp [ <NUMBER> ] == <STRING> : <NEWLINE> <NEWLINE> <TAB> if <STRING> in ccomp : <NEWLINE> <TAB> ccomp . remove ( <STRING> ) <NEWLINE> <UNTAB> if <STRING> in ccomp : <NEWLINE> <TAB> ccomp . remove ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> ccomp += [ <STRING> ] <NEWLINE> self . compiler_so = ccomp <NEWLINE> <NEWLINE> <UNTAB> if <STRING> in os . environ : <NEWLINE> <TAB> from distutils . sysconfig import get_config_vars <NEWLINE> opt = <STRING> . join ( os . environ [ <STRING> ] . split ( ) ) <NEWLINE> gcv_opt = <STRING> . join ( get_config_vars ( <STRING> ) [ <NUMBER> ] . split ( ) ) <NEWLINE> ccomp_s = <STRING> . join ( self . compiler_so ) <NEWLINE> if opt not in ccomp_s : <NEWLINE> <TAB> ccomp_s = ccomp_s . replace ( gcv_opt , opt ) <NEWLINE> self . compiler_so = ccomp_s . split ( ) <NEWLINE> <UNTAB> llink_s = <STRING> . join ( self . linker_so ) <NEWLINE> if opt not in llink_s : <NEWLINE> <TAB> self . linker_so = llink_s . split ( ) + opt . split ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> display = <STRING> % ( os . path . basename ( self . compiler_so [ <NUMBER> ] ) , src ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if getattr ( self , <STRING> , False ) : <NEWLINE> <TAB> deps = [ <STRING> , <STRING> , obj + <STRING> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> deps = [ ] <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> self . spawn ( self . compiler_so + cc_args + [ src , <STRING> , obj ] + deps + <NEWLINE> extra_postargs , display = display ) <NEWLINE> <UNTAB> except DistutilsExecError : <NEWLINE> <TAB> msg = str ( get_exception ( ) ) <NEWLINE> raise CompileError ( msg ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> with open ( obj + <STRING> , <STRING> ) as f : <NEWLINE> <TAB> f . write ( _commandline_dep_string ( cc_args , extra_postargs , pp_opts ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def gcd ( f , g ) : <NEWLINE> <TAB> <NEWLINE> lev , dom , per , F , G = f . unify ( g ) <NEWLINE> return per ( dmp_gcd ( F , G , lev , dom ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def convert ( self , argument ) : <NEWLINE> <TAB> <NEWLINE> if _is_integer_type ( argument ) : <NEWLINE> <TAB> return argument <NEWLINE> <UNTAB> elif isinstance ( argument , six . string_types ) : <NEWLINE> <TAB> base = <NUMBER> <NEWLINE> if len ( argument ) > <NUMBER> and argument [ <NUMBER> ] == <STRING> : <NEWLINE> <TAB> if argument [ <NUMBER> ] == <STRING> : <NEWLINE> <TAB> base = <NUMBER> <NEWLINE> <UNTAB> elif argument [ <NUMBER> ] == <STRING> : <NEWLINE> <TAB> base = <NUMBER> <NEWLINE> <UNTAB> <UNTAB> return int ( argument , base ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> . format ( <NEWLINE> type ( argument ) ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ abstractmethod <NEWLINE> def __le__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def do_begin_twophase ( self , connection , xid ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( v1 = [ <STRING> , <STRING> ] ) <NEWLINE> def local_variables_initializer ( ) : <NEWLINE> <TAB> <NEWLINE> if context . executing_eagerly ( ) : <NEWLINE> <TAB> return control_flow_ops . no_op ( name = <STRING> ) <NEWLINE> <UNTAB> return variables_initializer ( local_variables ( ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_artist ( self , artist , clip = False ) : <NEWLINE> <TAB> <NEWLINE> artist . set_figure ( self ) <NEWLINE> self . artists . append ( artist ) <NEWLINE> artist . _remove_method = self . artists . remove <NEWLINE> <NEWLINE> if not artist . is_transform_set ( ) : <NEWLINE> <TAB> artist . set_transform ( self . transFigure ) <NEWLINE> <NEWLINE> <UNTAB> if clip : <NEWLINE> <TAB> artist . set_clip_path ( self . patch ) <NEWLINE> <NEWLINE> <UNTAB> self . stale = True <NEWLINE> return artist <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def rem ( self , a , b ) : <NEWLINE> <TAB> <NEWLINE> return a % b <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _default_encoded_fill_value ( self ) : <NEWLINE> <TAB> <NEWLINE> nc_type = REVERSE [ self . typecode ( ) , self . itemsize ( ) ] <NEWLINE> return FILLMAP [ nc_type ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _getAssertEqualityFunc ( self , first , second ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if type ( first ) is type ( second ) : <NEWLINE> <TAB> asserter = self . _type_equality_funcs . get ( type ( first ) ) <NEWLINE> if asserter is not None : <NEWLINE> <TAB> if isinstance ( asserter , str ) : <NEWLINE> <TAB> asserter = getattr ( self , asserter ) <NEWLINE> <UNTAB> return asserter <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return self . _baseAssertEqual <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecation . deprecated ( None , <NEWLINE> <STRING> ) <NEWLINE> def enumerate_dataset ( start = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return enumerate_ops . enumerate_dataset ( start ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def astype ( value , types = None ) : <NEWLINE> <TAB> <NEWLINE> if types is None : <NEWLINE> <TAB> types = int , float , bytes2str <NEWLINE> <UNTAB> for typ in types : <NEWLINE> <TAB> try : <NEWLINE> <TAB> return typ ( value ) <NEWLINE> <UNTAB> except ( ValueError , TypeError , UnicodeEncodeError ) : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> return value <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def create_global_step ( graph = None ) : <NEWLINE> <TAB> <NEWLINE> graph = graph or ops . get_default_graph ( ) <NEWLINE> if get_global_step ( graph ) is not None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if context . executing_eagerly ( ) : <NEWLINE> <TAB> with ops . device ( <STRING> ) : <NEWLINE> <TAB> return variable_scope . get_variable ( <NEWLINE> ops . GraphKeys . GLOBAL_STEP , <NEWLINE> shape = [ ] , <NEWLINE> dtype = dtypes . int64 , <NEWLINE> initializer = init_ops . zeros_initializer ( ) , <NEWLINE> trainable = False , <NEWLINE> aggregation = variables . VariableAggregation . ONLY_FIRST_REPLICA , <NEWLINE> collections = [ ops . GraphKeys . GLOBAL_VARIABLES , <NEWLINE> ops . GraphKeys . GLOBAL_STEP ] ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> with graph . as_default ( ) as g , g . name_scope ( None ) : <NEWLINE> <TAB> return variable_scope . get_variable ( <NEWLINE> ops . GraphKeys . GLOBAL_STEP , <NEWLINE> shape = [ ] , <NEWLINE> dtype = dtypes . int64 , <NEWLINE> initializer = init_ops . zeros_initializer ( ) , <NEWLINE> trainable = False , <NEWLINE> aggregation = variables . VariableAggregation . ONLY_FIRST_REPLICA , <NEWLINE> collections = [ ops . GraphKeys . GLOBAL_VARIABLES , <NEWLINE> ops . GraphKeys . GLOBAL_STEP ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit ( self , X , y ) : <NEWLINE> <TAB> <NEWLINE> X , y = check_X_y ( X , y , [ <STRING> , <STRING> ] , y_numeric = True , <NEWLINE> ensure_min_samples = <NUMBER> , estimator = self ) <NEWLINE> X = as_float_array ( X , copy = False ) <NEWLINE> n_samples , n_features = X . shape <NEWLINE> <NEWLINE> X , y , X_offset , y_offset , X_scale = self . _preprocess_data ( X , y , self . fit_intercept , self . normalize ) <NEWLINE> <NEWLINE> estimator_func , params = self . _make_estimator_and_params ( X , y ) <NEWLINE> memory = self . memory <NEWLINE> if memory is None : <NEWLINE> <TAB> memory = Memory ( cachedir = None , verbose = <NUMBER> ) <NEWLINE> <UNTAB> elif isinstance ( memory , six . string_types ) : <NEWLINE> <TAB> memory = Memory ( cachedir = memory , verbose = <NUMBER> ) <NEWLINE> <UNTAB> elif not isinstance ( memory , Memory ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( <NEWLINE> type ( memory ) ) ) <NEWLINE> <NEWLINE> <UNTAB> scores_ = memory . cache ( <NEWLINE> _resample_model , ignore = [ <STRING> , <STRING> , <STRING> ] <NEWLINE> ) ( <NEWLINE> estimator_func , X , y , <NEWLINE> scaling = self . scaling , n_resampling = self . n_resampling , <NEWLINE> n_jobs = self . n_jobs , verbose = self . verbose , <NEWLINE> pre_dispatch = self . pre_dispatch , random_state = self . random_state , <NEWLINE> sample_fraction = self . sample_fraction , ** params ) <NEWLINE> <NEWLINE> if scores_ . ndim == <NUMBER> : <NEWLINE> <TAB> scores_ = scores_ [ : , np . newaxis ] <NEWLINE> <UNTAB> self . all_scores_ = scores_ <NEWLINE> self . scores_ = np . max ( self . all_scores_ , axis = <NUMBER> ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def equals ( self , other ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not isinstance ( other , Point ) or len ( self ) != len ( other ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> return all ( a . equals ( b ) for a , b in zip ( self , other ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _maybe_assert_valid_sample ( self , counts ) : <NEWLINE> <TAB> <NEWLINE> if not self . validate_args : <NEWLINE> <TAB> return counts <NEWLINE> <UNTAB> counts = distribution_util . embed_check_nonnegative_integer_form ( counts ) <NEWLINE> return control_flow_ops . with_dependencies ( [ <NEWLINE> check_ops . assert_less_equal ( <NEWLINE> counts , self . total_count , <NEWLINE> message = <STRING> ) , <NEWLINE> ] , counts ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_prs_resultant ( f , g , u , K ) : <NEWLINE> <TAB> <NEWLINE> if not u : <NEWLINE> <TAB> return dup_prs_resultant ( f , g , K ) <NEWLINE> <NEWLINE> <UNTAB> if dmp_zero_p ( f , u ) or dmp_zero_p ( g , u ) : <NEWLINE> <TAB> return ( dmp_zero ( u - <NUMBER> ) , [ ] ) <NEWLINE> <NEWLINE> <UNTAB> R , S = dmp_inner_subresultants ( f , g , u , K ) <NEWLINE> <NEWLINE> if dmp_degree ( R [ - <NUMBER> ] , u ) > <NUMBER> : <NEWLINE> <TAB> return ( dmp_zero ( u - <NUMBER> ) , R ) <NEWLINE> <NEWLINE> <UNTAB> return S [ - <NUMBER> ] , R <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _cudnn_to_tf_biases ( self , * cu_biases ) : <NEWLINE> <TAB> <NEWLINE> b_wi , b_wf , b_wc , b_wo , b_ri , b_rf , b_rc , b_ro = cu_biases <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> B_i = b_wi + b_ri <NEWLINE> B_f = b_wf + b_rf <NEWLINE> B_c = b_wc + b_rc <NEWLINE> B_o = b_wo + b_ro <NEWLINE> <NEWLINE> reordered = self . _cudnn_to_tf_gate_params ( * [ B_i , B_f , B_c , B_o ] ) <NEWLINE> return ( array_ops . concat ( reordered , axis = <NUMBER> ) , ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _unpack_index ( self , index ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> from . base import spmatrix <NEWLINE> if ( isinstance ( index , ( spmatrix , np . ndarray ) ) and <NEWLINE> ( index . ndim == <NUMBER> ) and index . dtype . kind == <STRING> ) : <NEWLINE> <TAB> return index . nonzero ( ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> index = self . _check_ellipsis ( index ) <NEWLINE> <NEWLINE> <NEWLINE> if isinstance ( index , tuple ) : <NEWLINE> <TAB> if len ( index ) == <NUMBER> : <NEWLINE> <TAB> row , col = index <NEWLINE> <UNTAB> elif len ( index ) == <NUMBER> : <NEWLINE> <TAB> row , col = index [ <NUMBER> ] , slice ( None ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise IndexError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> row , col = index , slice ( None ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> row , col = self . _check_boolean ( row , col ) <NEWLINE> return row , col <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def digit ( n , k , base ) : <NEWLINE> <TAB> <NEWLINE> return n // base ** k % base <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dtype_short_repr ( dtype ) : <NEWLINE> <TAB> <NEWLINE> if dtype . names is not None : <NEWLINE> <NEWLINE> <TAB> return str ( dtype ) <NEWLINE> <UNTAB> elif issubclass ( dtype . type , flexible ) : <NEWLINE> <NEWLINE> <TAB> return <STRING> % str ( dtype ) <NEWLINE> <NEWLINE> <UNTAB> typename = dtype . name <NEWLINE> <NEWLINE> if typename and not ( typename [ <NUMBER> ] . isalpha ( ) and typename . isalnum ( ) ) : <NEWLINE> <TAB> typename = repr ( typename ) <NEWLINE> <NEWLINE> <UNTAB> return typename <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def SimpleQueue ( self ) : <NEWLINE> <TAB> <NEWLINE> from . queues import SimpleQueue <NEWLINE> return SimpleQueue ( ctx = self . get_context ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_referent ( self , table ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return table . corresponding_column ( self . column ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def call ( self , inputs , state ) : <NEWLINE> <TAB> <NEWLINE> num_proj = self . _num_units if self . _num_proj is None else self . _num_proj <NEWLINE> sigmoid = math_ops . sigmoid <NEWLINE> <NEWLINE> if self . _state_is_tuple : <NEWLINE> <TAB> ( c_prev , m_prev ) = state <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> c_prev = array_ops . slice ( state , [ <NUMBER> , <NUMBER> ] , [ - <NUMBER> , self . _num_units ] ) <NEWLINE> m_prev = array_ops . slice ( state , [ <NUMBER> , self . _num_units ] , [ - <NUMBER> , num_proj ] ) <NEWLINE> <NEWLINE> <UNTAB> input_size = inputs . get_shape ( ) . with_rank ( <NUMBER> ) . dims [ <NUMBER> ] <NEWLINE> if input_size . value is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> lstm_matrix = math_ops . matmul ( <NEWLINE> array_ops . concat ( [ inputs , m_prev ] , <NUMBER> ) , self . _masked_kernel ) <NEWLINE> lstm_matrix = nn_ops . bias_add ( lstm_matrix , self . _bias ) <NEWLINE> <NEWLINE> i , j , f , o = array_ops . split ( <NEWLINE> value = lstm_matrix , num_or_size_splits = <NUMBER> , axis = <NUMBER> ) <NEWLINE> <NEWLINE> if self . _use_peepholes : <NEWLINE> <TAB> c = ( <NEWLINE> sigmoid ( f + self . _forget_bias + self . _w_f_diag * c_prev ) * c_prev + <NEWLINE> sigmoid ( i + self . _w_i_diag * c_prev ) * self . _activation ( j ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> c = ( <NEWLINE> sigmoid ( f + self . _forget_bias ) * c_prev + <NEWLINE> sigmoid ( i ) * self . _activation ( j ) ) <NEWLINE> <NEWLINE> <UNTAB> if self . _cell_clip is not None : <NEWLINE> <NEWLINE> <TAB> c = clip_ops . clip_by_value ( c , - self . _cell_clip , self . _cell_clip ) <NEWLINE> <NEWLINE> <UNTAB> if self . _use_peepholes : <NEWLINE> <TAB> m = sigmoid ( o + self . _w_o_diag * c ) * self . _activation ( c ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> m = sigmoid ( o ) * self . _activation ( c ) <NEWLINE> <NEWLINE> <UNTAB> if self . _num_proj is not None : <NEWLINE> <TAB> m = math_ops . matmul ( m , self . _proj_kernel ) <NEWLINE> <NEWLINE> if self . _proj_clip is not None : <NEWLINE> <NEWLINE> <TAB> m = clip_ops . clip_by_value ( m , - self . _proj_clip , self . _proj_clip ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> new_state = ( <NEWLINE> tf_rnn . LSTMStateTuple ( c , m ) <NEWLINE> if self . _state_is_tuple else array_ops . concat ( [ c , m ] , <NUMBER> ) ) <NEWLINE> return m , new_state <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ util . dependencies ( <STRING> ) <NEWLINE> def replace_selectable ( self , sqlutil , old , alias ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return sqlutil . ClauseAdapter ( alias ) . traverse ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_matlab_compatible ( self ) : <NEWLINE> <TAB> <NEWLINE> self . mat_dtype = True <NEWLINE> self . squeeze_me = False <NEWLINE> self . chars_as_strings = False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def keep_t_if_possible_handler ( info , t ) : <NEWLINE> <TAB> <NEWLINE> if info . graph is info . graph_ : <NEWLINE> <TAB> return t <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return replace_t_with_placeholder_handler ( info , t ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _multiset_histogram ( n ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( n , dict ) : <NEWLINE> <TAB> if not all ( isinstance ( v , int ) and v >= <NUMBER> for v in n . values ( ) ) : <NEWLINE> <TAB> raise ValueError <NEWLINE> <UNTAB> tot = sum ( n . values ( ) ) <NEWLINE> items = sum ( <NUMBER> for k in n if n [ k ] > <NUMBER> ) <NEWLINE> return _MultisetHistogram ( [ n [ k ] for k in n if n [ k ] > <NUMBER> ] + [ items , tot ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> n = list ( n ) <NEWLINE> s = set ( n ) <NEWLINE> if len ( s ) == len ( n ) : <NEWLINE> <TAB> n = [ <NUMBER> ] * len ( n ) <NEWLINE> n . extend ( [ len ( n ) , len ( n ) ] ) <NEWLINE> return _MultisetHistogram ( n ) <NEWLINE> <UNTAB> m = dict ( zip ( s , range ( len ( s ) ) ) ) <NEWLINE> d = dict ( zip ( range ( len ( s ) ) , [ <NUMBER> ] * len ( s ) ) ) <NEWLINE> for i in n : <NEWLINE> <TAB> d [ m [ i ] ] += <NUMBER> <NEWLINE> <UNTAB> return _multiset_histogram ( d ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _swap ( self , x ) : <NEWLINE> <TAB> <NEWLINE> return x [ <NUMBER> ] , x [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def lp2hp_zpk ( z , p , k , wo = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> z = atleast_1d ( z ) <NEWLINE> p = atleast_1d ( p ) <NEWLINE> wo = float ( wo ) <NEWLINE> <NEWLINE> degree = _relative_degree ( z , p ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> z_hp = wo / z <NEWLINE> p_hp = wo / p <NEWLINE> <NEWLINE> <NEWLINE> z_hp = append ( z_hp , zeros ( degree ) ) <NEWLINE> <NEWLINE> <NEWLINE> k_hp = k * real ( prod ( - z ) / prod ( - p ) ) <NEWLINE> <NEWLINE> return z_hp , p_hp , k_hp <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def ndim ( a ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return a . ndim <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> return asarray ( a ) . ndim <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def expand_paths_if_needed ( paths , mode , num , fs , name_function ) : <NEWLINE> <TAB> <NEWLINE> expanded_paths = [ ] <NEWLINE> paths = list ( paths ) <NEWLINE> if <STRING> in mode and sum ( [ <NUMBER> for p in paths if <STRING> in p ] ) > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> for curr_path in paths : <NEWLINE> <TAB> if <STRING> in curr_path : <NEWLINE> <TAB> if <STRING> in mode : <NEWLINE> <NEWLINE> <TAB> expanded_paths . extend ( _expand_paths ( curr_path , name_function , num ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> expanded_paths . extend ( fs . glob ( curr_path ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> expanded_paths . append ( curr_path ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if <STRING> in mode and len ( expanded_paths ) > num : <NEWLINE> <TAB> expanded_paths = expanded_paths [ : num ] <NEWLINE> <UNTAB> return expanded_paths <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _chirp_phase ( t , f0 , t1 , f1 , method = <STRING> , vertex_zero = True ) : <NEWLINE> <TAB> <NEWLINE> t = asarray ( t ) <NEWLINE> f0 = float ( f0 ) <NEWLINE> t1 = float ( t1 ) <NEWLINE> f1 = float ( f1 ) <NEWLINE> if method in [ <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> beta = ( f1 - f0 ) / t1 <NEWLINE> phase = <NUMBER> * pi * ( f0 * t + <NUMBER> * beta * t * t ) <NEWLINE> <NEWLINE> <UNTAB> elif method in [ <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> beta = ( f1 - f0 ) / ( t1 ** <NUMBER> ) <NEWLINE> if vertex_zero : <NEWLINE> <TAB> phase = <NUMBER> * pi * ( f0 * t + beta * t ** <NUMBER> / <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> phase = <NUMBER> * pi * ( f1 * t + beta * ( ( t1 - t ) ** <NUMBER> - t1 ** <NUMBER> ) / <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif method in [ <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> if f0 * f1 <= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if f0 == f1 : <NEWLINE> <TAB> phase = <NUMBER> * pi * f0 * t <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> beta = t1 / log ( f1 / f0 ) <NEWLINE> phase = <NUMBER> * pi * beta * f0 * ( pow ( f1 / f0 , t / t1 ) - <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif method in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> if f0 == <NUMBER> or f1 == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if f0 == f1 : <NEWLINE> <NEWLINE> <TAB> phase = <NUMBER> * pi * f0 * t <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> sing = - f1 * t1 / ( f0 - f1 ) <NEWLINE> phase = <NUMBER> * pi * ( - sing * f0 ) * log ( np . abs ( <NUMBER> - t / sing ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> % method ) <NEWLINE> <NEWLINE> <UNTAB> return phase <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def attrprint ( d , delimiter = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return delimiter . join ( <STRING> % item for item in sorted ( d . items ( ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def inplace_swap_column ( X , m , n ) : <NEWLINE> <TAB> <NEWLINE> if m < <NUMBER> : <NEWLINE> <TAB> m += X . shape [ <NUMBER> ] <NEWLINE> <UNTAB> if n < <NUMBER> : <NEWLINE> <TAB> n += X . shape [ <NUMBER> ] <NEWLINE> <UNTAB> if isinstance ( X , sp . csc_matrix ) : <NEWLINE> <TAB> inplace_swap_row_csr ( X , m , n ) <NEWLINE> <UNTAB> elif isinstance ( X , sp . csr_matrix ) : <NEWLINE> <TAB> inplace_swap_row_csc ( X , m , n ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> _raise_typeerror ( X ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def single_source_bellman_ford_path_length ( G , source , weight = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> weight = _weight_function ( G , weight ) <NEWLINE> return _bellman_ford ( G , [ source ] , weight ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _is_fromfile_compatible ( stream ) : <NEWLINE> <TAB> <NEWLINE> if sys . version_info [ <NUMBER> ] < <NUMBER> : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <UNTAB> bad_cls = [ ] <NEWLINE> try : <NEWLINE> <TAB> import gzip <NEWLINE> bad_cls . append ( gzip . GzipFile ) <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> import bz2 <NEWLINE> bad_cls . append ( bz2 . BZ2File ) <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> bad_cls = tuple ( bad_cls ) <NEWLINE> return not isinstance ( stream , bad_cls ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_summary_op ( self ) : <NEWLINE> <TAB> <NEWLINE> summary_op = None <NEWLINE> if self . _summary_op is not None : <NEWLINE> <TAB> summary_op = self . _summary_op <NEWLINE> <UNTAB> elif self . _scaffold . summary_op is not None : <NEWLINE> <TAB> summary_op = self . _scaffold . summary_op <NEWLINE> <NEWLINE> <UNTAB> if summary_op is None : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> if not isinstance ( summary_op , list ) : <NEWLINE> <TAB> return [ summary_op ] <NEWLINE> <UNTAB> return summary_op <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def parse_graphml ( graphml_string , node_type = str ) : <NEWLINE> <TAB> <NEWLINE> reader = GraphMLReader ( node_type = node_type ) <NEWLINE> <NEWLINE> glist = list ( reader ( string = graphml_string ) ) <NEWLINE> if len ( glist ) == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> header = <STRING> <NEWLINE> new_string = graphml_string . replace ( <STRING> , header ) <NEWLINE> glist = list ( reader ( string = new_string ) ) <NEWLINE> if len ( glist ) == <NUMBER> : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> return glist [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dump ( value , filename , compress = <NUMBER> , protocol = None , cache_size = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if Path is not None and isinstance ( filename , Path ) : <NEWLINE> <TAB> filename = str ( filename ) <NEWLINE> <NEWLINE> <UNTAB> is_filename = isinstance ( filename , _basestring ) <NEWLINE> is_fileobj = hasattr ( filename , <STRING> ) <NEWLINE> <NEWLINE> compress_method = <STRING> <NEWLINE> if compress is True : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> compress_level = None <NEWLINE> <UNTAB> elif isinstance ( compress , tuple ) : <NEWLINE> <NEWLINE> <TAB> if len ( compress ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> . format ( compress ) ) <NEWLINE> <UNTAB> compress_method , compress_level = compress <NEWLINE> <UNTAB> elif isinstance ( compress , _basestring ) : <NEWLINE> <TAB> compress_method = compress <NEWLINE> compress_level = None <NEWLINE> compress = ( compress_method , compress_level ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> compress_level = compress <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if compress_method == <STRING> and lz4 is None and PY3_OR_LATER : <NEWLINE> <TAB> raise ValueError ( LZ4_NOT_INSTALLED_ERROR ) <NEWLINE> <NEWLINE> <UNTAB> if ( compress_level is not None and <NEWLINE> compress_level is not False and <NEWLINE> compress_level not in range ( <NUMBER> ) ) : <NEWLINE> <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( compress_level , list ( range ( <NUMBER> ) ) ) ) <NEWLINE> <NEWLINE> <UNTAB> if compress_method not in _COMPRESSORS : <NEWLINE> <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( compress_method , _COMPRESSORS ) ) <NEWLINE> <NEWLINE> <UNTAB> if not is_filename and not is_fileobj : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> % ( filename , type ( filename ) ) <NEWLINE> ) <NEWLINE> <NEWLINE> <UNTAB> if is_filename and not isinstance ( compress , tuple ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> compress_method = None <NEWLINE> for name , compressor in _COMPRESSORS . items ( ) : <NEWLINE> <TAB> if filename . endswith ( compressor . extension ) : <NEWLINE> <TAB> compress_method = name <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if compress_method in _COMPRESSORS and compress_level == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> compress_level = None <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not PY3_OR_LATER and compress_method in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( compress_method , <NEWLINE> sys . version_info [ <NUMBER> ] , <NEWLINE> sys . version_info [ <NUMBER> ] ) ) <NEWLINE> <NEWLINE> <UNTAB> if cache_size is not None : <NEWLINE> <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( cache_size ) , <NEWLINE> DeprecationWarning , stacklevel = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> if compress_level != <NUMBER> : <NEWLINE> <TAB> with _write_fileobject ( filename , compress = ( compress_method , <NEWLINE> compress_level ) ) as f : <NEWLINE> <TAB> NumpyPickler ( f , protocol = protocol ) . dump ( value ) <NEWLINE> <UNTAB> <UNTAB> elif is_filename : <NEWLINE> <TAB> with open ( filename , <STRING> ) as f : <NEWLINE> <TAB> NumpyPickler ( f , protocol = protocol ) . dump ( value ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> NumpyPickler ( filename , protocol = protocol ) . dump ( value ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if is_fileobj : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return [ filename ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def flag_type ( self ) : <NEWLINE> <TAB> <NEWLINE> return <STRING> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _find_matching_indices ( tree , bin_X , left_mask , right_mask ) : <NEWLINE> <TAB> <NEWLINE> left_index = np . searchsorted ( tree , bin_X & left_mask ) <NEWLINE> right_index = np . searchsorted ( tree , bin_X | right_mask , <NEWLINE> side = <STRING> ) <NEWLINE> return left_index , right_index <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _serialize_model ( model , f , include_optimizer = True ) : <NEWLINE> <TAB> <NEWLINE> def get_json_type ( obj ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if hasattr ( obj , <STRING> ) : <NEWLINE> <TAB> return { <STRING> : obj . __class__ . __name__ , <NEWLINE> <STRING> : obj . get_config ( ) } <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if type ( obj ) . __module__ == np . __name__ : <NEWLINE> <TAB> if isinstance ( obj , np . ndarray ) : <NEWLINE> <TAB> return obj . tolist ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return obj . item ( ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if callable ( obj ) : <NEWLINE> <TAB> return obj . __name__ <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if type ( obj ) . __name__ == type . __name__ : <NEWLINE> <TAB> return obj . __name__ <NEWLINE> <NEWLINE> <UNTAB> raise TypeError ( <STRING> % ( obj , ) ) <NEWLINE> <NEWLINE> <UNTAB> from . . import __version__ as keras_version <NEWLINE> <NEWLINE> f [ <STRING> ] = str ( keras_version ) . encode ( <STRING> ) <NEWLINE> f [ <STRING> ] = K . backend ( ) . encode ( <STRING> ) <NEWLINE> <NEWLINE> model_config = { } <NEWLINE> model_config [ <STRING> ] = model . __class__ . __name__ <NEWLINE> model_config [ <STRING> ] = model . get_config ( ) <NEWLINE> model_config = json . dumps ( model_config , default = get_json_type ) <NEWLINE> model_config = model_config . encode ( <STRING> ) <NEWLINE> f [ <STRING> ] = model_config <NEWLINE> <NEWLINE> model_weights_group = f [ <STRING> ] <NEWLINE> model_layers = model . layers <NEWLINE> model_weights_group [ <STRING> ] = [ layer . name . encode ( <STRING> ) <NEWLINE> for layer in model_layers ] <NEWLINE> model_weights_group [ <STRING> ] = K . backend ( ) . encode ( <STRING> ) <NEWLINE> model_weights_group [ <STRING> ] = str ( keras_version ) . encode ( <STRING> ) <NEWLINE> for layer in model_layers : <NEWLINE> <TAB> layer_group = model_weights_group [ layer . name ] <NEWLINE> symbolic_weights = layer . weights <NEWLINE> weight_values = K . batch_get_value ( symbolic_weights ) <NEWLINE> weight_names = [ ] <NEWLINE> for i , ( w , val ) in enumerate ( zip ( symbolic_weights , weight_values ) ) : <NEWLINE> <TAB> if hasattr ( w , <STRING> ) and w . name : <NEWLINE> <TAB> name = str ( w . name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> name = <STRING> + str ( i ) <NEWLINE> <UNTAB> if name in weight_names : <NEWLINE> <TAB> idx = <NUMBER> <NEWLINE> unique_name = name + <STRING> <NEWLINE> while unique_name in weight_names : <NEWLINE> <TAB> unique_name = name + <STRING> + str ( idx ) <NEWLINE> idx += <NUMBER> <NEWLINE> <UNTAB> name = unique_name <NEWLINE> <UNTAB> weight_names . append ( name . encode ( <STRING> ) ) <NEWLINE> <UNTAB> layer_group [ <STRING> ] = weight_names <NEWLINE> for name , val in zip ( weight_names , weight_values ) : <NEWLINE> <TAB> layer_group [ name ] = val <NEWLINE> <UNTAB> <UNTAB> if include_optimizer and model . optimizer : <NEWLINE> <TAB> if isinstance ( model . optimizer , optimizers . TFOptimizer ) : <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> f [ <STRING> ] = json . dumps ( { <NEWLINE> <STRING> : { <NEWLINE> <STRING> : model . optimizer . __class__ . __name__ , <NEWLINE> <STRING> : model . optimizer . get_config ( ) <NEWLINE> } , <NEWLINE> <STRING> : model . loss , <NEWLINE> <STRING> : model . metrics , <NEWLINE> <STRING> : model . sample_weight_mode , <NEWLINE> <STRING> : model . loss_weights , <NEWLINE> } , default = get_json_type ) . encode ( <STRING> ) <NEWLINE> symbolic_weights = getattr ( model . optimizer , <STRING> ) <NEWLINE> if symbolic_weights : <NEWLINE> <TAB> optimizer_weights_group = f [ <STRING> ] <NEWLINE> weight_values = K . batch_get_value ( symbolic_weights ) <NEWLINE> weight_names = [ ] <NEWLINE> for i , ( w , val ) in enumerate ( zip ( symbolic_weights , <NEWLINE> weight_values ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if K . backend ( ) == <STRING> or K . backend ( ) == <STRING> : <NEWLINE> <TAB> if hasattr ( w , <STRING> ) : <NEWLINE> <TAB> if w . name . split ( <STRING> ) [ - <NUMBER> ] == <STRING> : <NEWLINE> <TAB> name = str ( w . name ) + <STRING> + str ( i ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> name = str ( w . name ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> name = <STRING> + str ( i ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if hasattr ( w , <STRING> ) and w . name : <NEWLINE> <TAB> name = str ( w . name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> name = <STRING> + str ( i ) <NEWLINE> <UNTAB> <UNTAB> if name in weight_names : <NEWLINE> <TAB> idx = <NUMBER> <NEWLINE> unique_name = name + <STRING> <NEWLINE> while unique_name in weight_names : <NEWLINE> <TAB> unique_name = name + <STRING> + str ( idx ) <NEWLINE> idx += <NUMBER> <NEWLINE> <UNTAB> name = unique_name <NEWLINE> <UNTAB> weight_names . append ( name . encode ( <STRING> ) ) <NEWLINE> <UNTAB> optimizer_weights_group [ <STRING> ] = weight_names <NEWLINE> for name , val in zip ( weight_names , weight_values ) : <NEWLINE> <TAB> optimizer_weights_group [ name ] = val <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_eval_in ( f , a , j , u , K ) : <NEWLINE> <TAB> <NEWLINE> if j < <NUMBER> or j > u : <NEWLINE> <TAB> raise IndexError ( <STRING> % ( u , j ) ) <NEWLINE> <NEWLINE> <UNTAB> return _rec_eval_in ( f , a , u , <NUMBER> , j , K ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _process_parameters ( self , dim , mean , cov ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if dim is None : <NEWLINE> <TAB> if mean is None : <NEWLINE> <TAB> if cov is None : <NEWLINE> <TAB> dim = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cov = np . asarray ( cov , dtype = float ) <NEWLINE> if cov . ndim < <NUMBER> : <NEWLINE> <TAB> dim = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dim = cov . shape [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> mean = np . asarray ( mean , dtype = float ) <NEWLINE> dim = mean . size <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if not np . isscalar ( dim ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if mean is None : <NEWLINE> <TAB> mean = np . zeros ( dim ) <NEWLINE> <UNTAB> mean = np . asarray ( mean , dtype = float ) <NEWLINE> <NEWLINE> if cov is None : <NEWLINE> <TAB> cov = <NUMBER> <NEWLINE> <UNTAB> cov = np . asarray ( cov , dtype = float ) <NEWLINE> <NEWLINE> if dim == <NUMBER> : <NEWLINE> <TAB> mean . shape = ( <NUMBER> , ) <NEWLINE> cov . shape = ( <NUMBER> , <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> if mean . ndim != <NUMBER> or mean . shape [ <NUMBER> ] != dim : <NEWLINE> <TAB> raise ValueError ( <STRING> % dim ) <NEWLINE> <UNTAB> if cov . ndim == <NUMBER> : <NEWLINE> <TAB> cov = cov * np . eye ( dim ) <NEWLINE> <UNTAB> elif cov . ndim == <NUMBER> : <NEWLINE> <TAB> cov = np . diag ( cov ) <NEWLINE> <UNTAB> elif cov . ndim == <NUMBER> and cov . shape != ( dim , dim ) : <NEWLINE> <TAB> rows , cols = cov . shape <NEWLINE> if rows != cols : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> % str ( cov . shape ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> msg = msg % ( str ( cov . shape ) , len ( mean ) ) <NEWLINE> <UNTAB> raise ValueError ( msg ) <NEWLINE> <UNTAB> elif cov . ndim > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % cov . ndim ) <NEWLINE> <NEWLINE> <UNTAB> return dim , mean , cov <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def setitem ( self , indexer , value , mgr = None ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( indexer , tuple ) : <NEWLINE> <NEWLINE> <TAB> indexer = indexer [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> check_setitem_lengths ( indexer , value , self . values ) <NEWLINE> self . values [ indexer ] = value <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , x , pos = None ) : <NEWLINE> <TAB> <NEWLINE> return self . fmt % x <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_shape_info ( self , obj ) : <NEWLINE> <TAB> <NEWLINE> return obj . shape <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sh_chebyu ( n , monic = False ) : <NEWLINE> <TAB> <NEWLINE> base = sh_jacobi ( n , <NUMBER> , <NUMBER> , monic = monic ) <NEWLINE> if monic : <NEWLINE> <TAB> return base <NEWLINE> <UNTAB> factor = <NUMBER> ** n <NEWLINE> base . _scale ( factor ) <NEWLINE> return base <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _dynamic_max_trials ( n_inliers , n_samples , min_samples , probability ) : <NEWLINE> <TAB> <NEWLINE> inlier_ratio = n_inliers / float ( n_samples ) <NEWLINE> nom = max ( _EPSILON , <NUMBER> - probability ) <NEWLINE> denom = max ( _EPSILON , <NUMBER> - inlier_ratio ** min_samples ) <NEWLINE> if nom == <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> if denom == <NUMBER> : <NEWLINE> <TAB> return float ( <STRING> ) <NEWLINE> <UNTAB> return abs ( float ( np . ceil ( np . log ( nom ) / np . log ( denom ) ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , * mdargs ) : <NEWLINE> <TAB> <NEWLINE> for a in mdargs : <NEWLINE> <TAB> if not isinstance ( a , ( int , str ) ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> self . mdargs = mdargs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def rename_axis ( self , mapper , axis = <NUMBER> , copy = True , inplace = False ) : <NEWLINE> <TAB> <NEWLINE> inplace = validate_bool_kwarg ( inplace , <STRING> ) <NEWLINE> non_mapper = is_scalar ( mapper ) or ( is_list_like ( mapper ) and not <NEWLINE> is_dict_like ( mapper ) ) <NEWLINE> if non_mapper : <NEWLINE> <TAB> return self . _set_axis_name ( mapper , axis = axis , inplace = inplace ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> warnings . warn ( msg , FutureWarning , stacklevel = <NUMBER> ) <NEWLINE> axis = self . _get_axis_name ( axis ) <NEWLINE> d = { <STRING> : copy , <STRING> : inplace } <NEWLINE> d [ axis ] = mapper <NEWLINE> return self . rename ( ** d ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def with_options ( self , options ) : <NEWLINE> <TAB> <NEWLINE> return _OptionsDataset ( self , options ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def load_iris ( return_X_y = False ) : <NEWLINE> <TAB> <NEWLINE> module_path = dirname ( __file__ ) <NEWLINE> data , target , target_names = load_data ( module_path , <STRING> ) <NEWLINE> iris_csv_filename = join ( module_path , <STRING> , <STRING> ) <NEWLINE> <NEWLINE> with open ( join ( module_path , <STRING> , <STRING> ) ) as rst_file : <NEWLINE> <TAB> fdescr = rst_file . read ( ) <NEWLINE> <NEWLINE> <UNTAB> if return_X_y : <NEWLINE> <TAB> return data , target <NEWLINE> <NEWLINE> <UNTAB> return Bunch ( data = data , target = target , <NEWLINE> target_names = target_names , <NEWLINE> DESCR = fdescr , <NEWLINE> feature_names = [ <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> ] , <NEWLINE> filename = iris_csv_filename ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_library ( self , name , sources , ** build_info ) : <NEWLINE> <TAB> <NEWLINE> self . _add_library ( name , sources , None , build_info ) <NEWLINE> <NEWLINE> dist = self . get_distribution ( ) <NEWLINE> if dist is not None : <NEWLINE> <TAB> self . warn ( <STRING> <STRING> + name ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def solve_rational_inequalities ( eqs ) : <NEWLINE> <TAB> <NEWLINE> result = S . EmptySet <NEWLINE> <NEWLINE> for _eqs in eqs : <NEWLINE> <TAB> if not _eqs : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> global_intervals = [ Interval ( S . NegativeInfinity , S . Infinity ) ] <NEWLINE> <NEWLINE> for ( numer , denom ) , rel in _eqs : <NEWLINE> <TAB> numer_intervals = solve_poly_inequality ( numer * denom , rel ) <NEWLINE> denom_intervals = solve_poly_inequality ( denom , <STRING> ) <NEWLINE> <NEWLINE> intervals = [ ] <NEWLINE> <NEWLINE> for numer_interval in numer_intervals : <NEWLINE> <TAB> for global_interval in global_intervals : <NEWLINE> <TAB> interval = numer_interval . intersect ( global_interval ) <NEWLINE> <NEWLINE> if interval is not S . EmptySet : <NEWLINE> <TAB> intervals . append ( interval ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> global_intervals = intervals <NEWLINE> <NEWLINE> intervals = [ ] <NEWLINE> <NEWLINE> for global_interval in global_intervals : <NEWLINE> <TAB> for denom_interval in denom_intervals : <NEWLINE> <TAB> global_interval -= denom_interval <NEWLINE> <NEWLINE> <UNTAB> if global_interval is not S . EmptySet : <NEWLINE> <TAB> intervals . append ( global_interval ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> global_intervals = intervals <NEWLINE> <NEWLINE> if not global_intervals : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for interval in global_intervals : <NEWLINE> <TAB> result = result . union ( interval ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dup_root_lower_bound ( f , K ) : <NEWLINE> <TAB> <NEWLINE> bound = dup_root_upper_bound ( dup_reverse ( f ) , K ) <NEWLINE> <NEWLINE> if bound is not None : <NEWLINE> <TAB> return <NUMBER> / bound <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _fft_helper ( x , win , detrend_func , nperseg , noverlap , nfft , sides ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if nperseg == <NUMBER> and noverlap == <NUMBER> : <NEWLINE> <TAB> result = x [ ... , np . newaxis ] <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> step = nperseg - noverlap <NEWLINE> shape = x . shape [ : - <NUMBER> ] + ( ( x . shape [ - <NUMBER> ] - noverlap ) // step , nperseg ) <NEWLINE> strides = x . strides [ : - <NUMBER> ] + ( step * x . strides [ - <NUMBER> ] , x . strides [ - <NUMBER> ] ) <NEWLINE> result = np . lib . stride_tricks . as_strided ( x , shape = shape , <NEWLINE> strides = strides ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> result = detrend_func ( result ) <NEWLINE> <NEWLINE> <NEWLINE> result = win * result <NEWLINE> <NEWLINE> <NEWLINE> if sides == <STRING> : <NEWLINE> <TAB> func = fftpack . fft <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result = result . real <NEWLINE> func = np . fft . rfft <NEWLINE> <UNTAB> result = func ( result , n = nfft ) <NEWLINE> <NEWLINE> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _trim ( x , axes , boundary , block_info ) : <NEWLINE> <TAB> <NEWLINE> axes = [ axes . get ( i , <NUMBER> ) for i in range ( x . ndim ) ] <NEWLINE> axes_back = ( - ax if ax else None for ax in axes ) <NEWLINE> <NEWLINE> trim_front = ( <NEWLINE> <NUMBER> if ( chunk_location == <NUMBER> and <NEWLINE> boundary . get ( i , <STRING> ) == <STRING> ) else ax <NEWLINE> for i , ( chunk_location , ax ) in enumerate ( <NEWLINE> zip ( block_info [ <NUMBER> ] [ <STRING> ] , axes ) ) ) <NEWLINE> trim_back = ( <NEWLINE> None if ( chunk_location == chunks - <NUMBER> and <NEWLINE> boundary . get ( i , <STRING> ) == <STRING> ) else ax <NEWLINE> for i , ( chunks , chunk_location , ax ) in enumerate ( zip ( <NEWLINE> block_info [ <NUMBER> ] [ <STRING> ] , <NEWLINE> block_info [ <NUMBER> ] [ <STRING> ] , <NEWLINE> axes_back ) ) ) <NEWLINE> <NEWLINE> return x [ tuple ( slice ( front , back ) <NEWLINE> for front , back in zip ( trim_front , trim_back ) ) ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def to_rgba ( c , alpha = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if _is_nth_color ( c ) : <NEWLINE> <TAB> from matplotlib import rcParams <NEWLINE> prop_cycler = rcParams [ <STRING> ] <NEWLINE> colors = prop_cycler . by_key ( ) . get ( <STRING> , [ <STRING> ] ) <NEWLINE> c = colors [ int ( c [ <NUMBER> ] ) % len ( colors ) ] <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> rgba = _colors_full_map . cache [ c , alpha ] <NEWLINE> <UNTAB> except ( KeyError , TypeError ) : <NEWLINE> <TAB> rgba = _to_rgba_no_colorcycle ( c , alpha ) <NEWLINE> try : <NEWLINE> <TAB> _colors_full_map . cache [ c , alpha ] = rgba <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> return rgba <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def markInputline ( self , markerString = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> line_str = self . line <NEWLINE> line_column = self . column - <NUMBER> <NEWLINE> if markerString : <NEWLINE> <TAB> line_str = <STRING> . join ( ( line_str [ : line_column ] , <NEWLINE> markerString , line_str [ line_column : ] ) ) <NEWLINE> <UNTAB> return line_str . strip ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _restore_slot_variable ( self , slot_name , variable , slot_variable ) : <NEWLINE> <TAB> <NEWLINE> variable_key = _var_key ( variable ) <NEWLINE> deferred_restorations = self . _deferred_slot_restorations . get ( <NEWLINE> slot_name , { } ) . pop ( variable_key , [ ] ) <NEWLINE> <NEWLINE> <NEWLINE> deferred_restorations . sort ( key = lambda position : position . restore_uid , <NEWLINE> reverse = True ) <NEWLINE> for checkpoint_position in deferred_restorations : <NEWLINE> <TAB> checkpoint_position . restore ( slot_variable ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def reconstruct_path ( source , target , predecessors ) : <NEWLINE> <TAB> <NEWLINE> if source == target : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> prev = predecessors [ source ] <NEWLINE> curr = prev [ target ] <NEWLINE> path = [ target , curr ] <NEWLINE> while curr != source : <NEWLINE> <TAB> curr = prev [ curr ] <NEWLINE> path . append ( curr ) <NEWLINE> <UNTAB> return list ( reversed ( path ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def roots_hermite ( n , mu = False ) : <NEWLINE> <TAB> <NEWLINE> m = int ( n ) <NEWLINE> if n < <NUMBER> or n != m : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> mu0 = np . sqrt ( np . pi ) <NEWLINE> if n <= <NUMBER> : <NEWLINE> <TAB> an_func = lambda k : <NUMBER> * k <NEWLINE> bn_func = lambda k : np . sqrt ( k / <NUMBER> ) <NEWLINE> f = cephes . eval_hermite <NEWLINE> df = lambda n , x : <NUMBER> * n * cephes . eval_hermite ( n - <NUMBER> , x ) <NEWLINE> return _gen_roots_and_weights ( m , mu0 , an_func , bn_func , f , df , True , mu ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nodes , weights = _roots_hermite_asy ( m ) <NEWLINE> if mu : <NEWLINE> <TAB> return nodes , weights , mu0 <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return nodes , weights <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def generate_involutions ( n ) : <NEWLINE> <TAB> <NEWLINE> idx = list ( range ( n ) ) <NEWLINE> for p in permutations ( idx ) : <NEWLINE> <TAB> for i in idx : <NEWLINE> <TAB> if p [ p [ i ] ] != i : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> yield p <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def pprint_styles ( cls ) : <NEWLINE> <TAB> <NEWLINE> return _pprint_styles ( cls . _style_list ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def julian_datetime ( julianday , milisecond = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if julianday <= <NUMBER> : <NEWLINE> <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> a = julianday + <NUMBER> <NEWLINE> if a > <NUMBER> : <NEWLINE> <TAB> alpha = math . trunc ( ( a - <NUMBER> ) / <NUMBER> ) <NEWLINE> a += <NUMBER> + alpha - alpha // <NUMBER> <NEWLINE> <UNTAB> b = a + ( <NUMBER> if a > <NUMBER> else <NUMBER> ) <NEWLINE> c = math . trunc ( ( b - <NUMBER> ) / <NUMBER> ) <NEWLINE> d = math . trunc ( <NUMBER> * c ) <NEWLINE> e = math . trunc ( ( b - d ) / <NUMBER> ) <NEWLINE> <NEWLINE> day = b - d - math . trunc ( <NUMBER> * e ) <NEWLINE> month = e - ( <NUMBER> if e < <NUMBER> else <NUMBER> ) <NEWLINE> year = c - ( <NUMBER> if month > <NUMBER> else <NUMBER> ) <NEWLINE> <NEWLINE> hour , milisecond = divmod ( milisecond , <NUMBER> * <NUMBER> * <NUMBER> ) <NEWLINE> minute , milisecond = divmod ( milisecond , <NUMBER> * <NUMBER> ) <NEWLINE> second , milisecond = divmod ( milisecond , <NUMBER> ) <NEWLINE> <NEWLINE> return datetime . datetime ( year , month , day , <NEWLINE> hour , minute , second , milisecond ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def dialect_impl ( self , dialect ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return dialect . _type_memos [ self ] [ <STRING> ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> return self . _dialect_info ( dialect ) [ <STRING> ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __getitem__ ( self , key ) : <NEWLINE> <TAB> <NEWLINE> return self . _dict [ sympify ( key ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ if_delegate_has_method ( delegate = ( <STRING> , <STRING> ) ) <NEWLINE> def decision_function ( self , X ) : <NEWLINE> <TAB> <NEWLINE> self . _check_is_fitted ( <STRING> ) <NEWLINE> return self . best_estimator_ . decision_function ( X ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def generic ( name , tensor , metadata = None , family = None , step = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def function ( tag , scope ) : <NEWLINE> <TAB> if metadata is None : <NEWLINE> <TAB> serialized_metadata = constant_op . constant ( <STRING> ) <NEWLINE> <UNTAB> elif hasattr ( metadata , <STRING> ) : <NEWLINE> <TAB> serialized_metadata = constant_op . constant ( metadata . SerializeToString ( ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> serialized_metadata = metadata <NEWLINE> <NEWLINE> <UNTAB> return gen_summary_ops . write_summary ( <NEWLINE> context . context ( ) . summary_writer_resource , <NEWLINE> _choose_step ( step ) , <NEWLINE> array_ops . identity ( tensor ) , <NEWLINE> tag , <NEWLINE> serialized_metadata , <NEWLINE> name = scope ) <NEWLINE> <UNTAB> return summary_writer_function ( name , tensor , function , family = family ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def lp2hp ( b , a , wo = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> a , b = map ( atleast_1d , ( a , b ) ) <NEWLINE> try : <NEWLINE> <TAB> wo = float ( wo ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> wo = float ( wo [ <NUMBER> ] ) <NEWLINE> <UNTAB> d = len ( a ) <NEWLINE> n = len ( b ) <NEWLINE> if wo != <NUMBER> : <NEWLINE> <TAB> pwo = pow ( wo , numpy . arange ( max ( ( d , n ) ) ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pwo = numpy . ones ( max ( ( d , n ) ) , b . dtype . char ) <NEWLINE> <UNTAB> if d >= n : <NEWLINE> <TAB> outa = a [ : : - <NUMBER> ] * pwo <NEWLINE> outb = resize ( b , ( d , ) ) <NEWLINE> outb [ n : ] = <NUMBER> <NEWLINE> outb [ : n ] = b [ : : - <NUMBER> ] * pwo [ : n ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> outb = b [ : : - <NUMBER> ] * pwo <NEWLINE> outa = resize ( a , ( n , ) ) <NEWLINE> outa [ d : ] = <NUMBER> <NEWLINE> outa [ : d ] = a [ : : - <NUMBER> ] * pwo [ : d ] <NEWLINE> <NEWLINE> <UNTAB> return normalize ( outb , outa ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def isin ( self , values ) : <NEWLINE> <TAB> <NEWLINE> result = algorithms . isin ( self , values ) <NEWLINE> return self . _constructor ( result , index = self . index ) . __finalize__ ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def initialize ( self , connection ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_intel64 ( self ) : <NEWLINE> <TAB> <NEWLINE> intel64 . check_ideep_available ( ) <NEWLINE> array = self . array <NEWLINE> if array is not None : <NEWLINE> <TAB> if isinstance ( array , cuda . ndarray ) : <NEWLINE> <NEWLINE> <TAB> array = array . get ( ) <NEWLINE> <UNTAB> if ( isinstance ( array , numpy . ndarray ) and array . ndim in ( <NUMBER> , <NUMBER> , <NUMBER> ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> array = intel64 . ideep . array ( <NEWLINE> array , itype = intel64 . ideep . wgt_array ) <NEWLINE> <UNTAB> self . _data = [ array ] <NEWLINE> <NEWLINE> <UNTAB> if self . _grad_var is not None : <NEWLINE> <TAB> self . _grad_var . to_intel64 ( ) <NEWLINE> <NEWLINE> <UNTAB> node = self . _node <NEWLINE> if node . _data is not None : <NEWLINE> <TAB> node . retain_data ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def from_bounds ( x0 , y0 , width , height ) : <NEWLINE> <TAB> <NEWLINE> return Bbox . from_extents ( x0 , y0 , x0 + width , y0 + height ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ _replace_by ( <STRING> ) <NEWLINE> def reverse_bitorder ( data ) : <NEWLINE> <TAB> <NEWLINE> table = ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> try : <NEWLINE> <TAB> view = data . view ( <STRING> ) <NEWLINE> numpy . take ( numpy . fromstring ( table , dtype = <STRING> ) , view , out = view ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> return data . translate ( table ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def query ( self , x , k = <NUMBER> , eps = <NUMBER> , p = <NUMBER> , distance_upper_bound = np . inf ) : <NEWLINE> <TAB> <NEWLINE> x = np . asarray ( x ) <NEWLINE> if np . shape ( x ) [ - <NUMBER> ] != self . m : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( self . m , np . shape ( x ) ) ) <NEWLINE> <UNTAB> if p < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> retshape = np . shape ( x ) [ : - <NUMBER> ] <NEWLINE> if retshape != ( ) : <NEWLINE> <TAB> if k is None : <NEWLINE> <TAB> dd = np . empty ( retshape , dtype = object ) <NEWLINE> ii = np . empty ( retshape , dtype = object ) <NEWLINE> <UNTAB> elif k > <NUMBER> : <NEWLINE> <TAB> dd = np . empty ( retshape + ( k , ) , dtype = float ) <NEWLINE> dd . fill ( np . inf ) <NEWLINE> ii = np . empty ( retshape + ( k , ) , dtype = int ) <NEWLINE> ii . fill ( self . n ) <NEWLINE> <UNTAB> elif k == <NUMBER> : <NEWLINE> <TAB> dd = np . empty ( retshape , dtype = float ) <NEWLINE> dd . fill ( np . inf ) <NEWLINE> ii = np . empty ( retshape , dtype = int ) <NEWLINE> ii . fill ( self . n ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> for c in np . ndindex ( retshape ) : <NEWLINE> <TAB> hits = self . __query ( x [ c ] , k = k , eps = eps , p = p , distance_upper_bound = distance_upper_bound ) <NEWLINE> if k is None : <NEWLINE> <TAB> dd [ c ] = [ d for ( d , i ) in hits ] <NEWLINE> ii [ c ] = [ i for ( d , i ) in hits ] <NEWLINE> <UNTAB> elif k > <NUMBER> : <NEWLINE> <TAB> for j in range ( len ( hits ) ) : <NEWLINE> <TAB> dd [ c + ( j , ) ] , ii [ c + ( j , ) ] = hits [ j ] <NEWLINE> <UNTAB> <UNTAB> elif k == <NUMBER> : <NEWLINE> <TAB> if len ( hits ) > <NUMBER> : <NEWLINE> <TAB> dd [ c ] , ii [ c ] = hits [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dd [ c ] = np . inf <NEWLINE> ii [ c ] = self . n <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return dd , ii <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> hits = self . __query ( x , k = k , eps = eps , p = p , distance_upper_bound = distance_upper_bound ) <NEWLINE> if k is None : <NEWLINE> <TAB> return [ d for ( d , i ) in hits ] , [ i for ( d , i ) in hits ] <NEWLINE> <UNTAB> elif k == <NUMBER> : <NEWLINE> <TAB> if len ( hits ) > <NUMBER> : <NEWLINE> <TAB> return hits [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return np . inf , self . n <NEWLINE> <UNTAB> <UNTAB> elif k > <NUMBER> : <NEWLINE> <TAB> dd = np . empty ( k , dtype = float ) <NEWLINE> dd . fill ( np . inf ) <NEWLINE> ii = np . empty ( k , dtype = int ) <NEWLINE> ii . fill ( self . n ) <NEWLINE> for j in range ( len ( hits ) ) : <NEWLINE> <TAB> dd [ j ] , ii [ j ] = hits [ j ] <NEWLINE> <UNTAB> return dd , ii <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gray ( ) : <NEWLINE> <TAB> <NEWLINE> set_cmap ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def size ( self ) : <NEWLINE> <TAB> <NEWLINE> return stat ( self . __name ) . length <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def create ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _step1 ( state ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> state . C -= state . C . min ( axis = <NUMBER> ) [ : , np . newaxis ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for i , j in zip ( * np . where ( state . C == <NUMBER> ) ) : <NEWLINE> <TAB> if state . col_uncovered [ j ] and state . row_uncovered [ i ] : <NEWLINE> <TAB> state . marked [ i , j ] = <NUMBER> <NEWLINE> state . col_uncovered [ j ] = False <NEWLINE> state . row_uncovered [ i ] = False <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> state . _clear_covers ( ) <NEWLINE> return _step3 <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _lucas_selfridge_params ( n ) : <NEWLINE> <TAB> <NEWLINE> from sympy . core import igcd <NEWLINE> from sympy . ntheory . residue_ntheory import jacobi_symbol <NEWLINE> D = <NUMBER> <NEWLINE> while True : <NEWLINE> <TAB> g = igcd ( abs ( D ) , n ) <NEWLINE> if g > <NUMBER> and g != n : <NEWLINE> <TAB> return ( <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> if jacobi_symbol ( D , n ) == - <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> if D > <NUMBER> : <NEWLINE> <TAB> D = - D - <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> D = - D + <NUMBER> <NEWLINE> <UNTAB> <UNTAB> return _int_tuple ( D , <NUMBER> , ( <NUMBER> - D ) / <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def autolevel ( image , selem , out = None , mask = None , shift_x = False , shift_y = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return _apply_scalar_per_pixel ( generic_cy . _autolevel , image , selem , <NEWLINE> out = out , mask = mask , <NEWLINE> shift_x = shift_x , shift_y = shift_y ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , <NEWLINE> worker_devices , <NEWLINE> num_gpus_per_worker , <NEWLINE> all_reduce_spec = ( <STRING> , <NUMBER> , - <NUMBER> ) , <NEWLINE> num_packs = <NUMBER> , <NEWLINE> agg_small_grads_max_bytes = <NUMBER> , <NEWLINE> agg_small_grads_max_group = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> self . _worker_devices = worker_devices <NEWLINE> self . _num_gpus_per_worker = num_gpus_per_worker <NEWLINE> super ( MultiWorkerAllReduce , self ) . __init__ ( <NEWLINE> num_packs = num_packs , <NEWLINE> agg_small_grads_max_bytes = agg_small_grads_max_bytes , <NEWLINE> agg_small_grads_max_group = agg_small_grads_max_group ) <NEWLINE> <NEWLINE> def validate_and_complete_spec ( spec ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not isinstance ( spec , tuple ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % all_reduce_spec ) <NEWLINE> <UNTAB> if not spec or len ( spec ) > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % spec ) <NEWLINE> <UNTAB> if len ( spec ) == <NUMBER> : <NEWLINE> <TAB> return AllReduceSpecTuple ( spec [ <NUMBER> ] , <NUMBER> , - <NUMBER> ) <NEWLINE> <UNTAB> elif len ( spec ) == <NUMBER> : <NEWLINE> <TAB> return AllReduceSpecTuple ( spec [ <NUMBER> ] , spec [ <NUMBER> ] , - <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return AllReduceSpecTuple ( * spec ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . _all_reduce_spec = [ ] <NEWLINE> if isinstance ( all_reduce_spec , six . string_types ) : <NEWLINE> <TAB> self . _all_reduce_spec . append ( AllReduceSpecTuple ( all_reduce_spec , <NUMBER> , - <NUMBER> ) ) <NEWLINE> <UNTAB> elif isinstance ( all_reduce_spec , tuple ) : <NEWLINE> <TAB> self . _all_reduce_spec . append ( validate_and_complete_spec ( all_reduce_spec ) ) <NEWLINE> <UNTAB> elif isinstance ( all_reduce_spec , list ) : <NEWLINE> <TAB> self . _all_reduce_spec = [ <NEWLINE> validate_and_complete_spec ( spec ) for spec in all_reduce_spec <NEWLINE> ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def factor ( self , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> from sympy . polys import factor <NEWLINE> return factor ( self , * gens , ** args ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_tensor ( self , tensor_index , value ) : <NEWLINE> <TAB> <NEWLINE> self . _interpreter . SetTensor ( tensor_index , value ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def clear ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> to_clear = set ( ) <NEWLINE> for dispatcher in self . _clslevel . values ( ) : <NEWLINE> <TAB> to_clear . update ( dispatcher ) <NEWLINE> dispatcher . clear ( ) <NEWLINE> <UNTAB> registry . _clear ( self , to_clear ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def first_connect ( self , dbapi_con , con_record ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _centered_bias_step ( centered_bias , batch_size , labels , loss_fn , weights ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( None , <STRING> , ( labels , ) ) as name : <NEWLINE> <TAB> logits_dimension = array_ops . shape ( centered_bias ) [ <NUMBER> ] <NEWLINE> logits = array_ops . reshape ( <NEWLINE> array_ops . tile ( centered_bias , ( batch_size , ) ) , <NEWLINE> ( batch_size , logits_dimension ) ) <NEWLINE> with ops . name_scope ( None , <STRING> , ( labels , logits ) ) : <NEWLINE> <TAB> centered_bias_loss = math_ops . reduce_mean ( <NEWLINE> loss_fn ( labels , logits , weights ) , name = <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return training . AdagradOptimizer ( <NUMBER> ) . minimize ( <NEWLINE> centered_bias_loss , var_list = ( centered_bias , ) , name = name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _linesearch_powell ( func , p , xi , tol = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> def myfunc ( alpha ) : <NEWLINE> <TAB> return func ( p + alpha * xi ) <NEWLINE> <UNTAB> alpha_min , fret , iter , num = brent ( myfunc , full_output = <NUMBER> , tol = tol ) <NEWLINE> xi = alpha_min * xi <NEWLINE> return squeeze ( fret ) , p + xi , xi <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def deprecated_endpoints ( * args ) : <NEWLINE> <TAB> <NEWLINE> def deprecated_wrapper ( func ) : <NEWLINE> <NEWLINE> <TAB> if <STRING> in func . __dict__ : <NEWLINE> <TAB> raise DeprecatedNamesAlreadySet ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ( <NEWLINE> func . __name__ , str ( args ) , str ( func . _tf_deprecated_api_names ) ) ) <NEWLINE> <UNTAB> func . _tf_deprecated_api_names = args <NEWLINE> <NEWLINE> return func <NEWLINE> <UNTAB> return deprecated_wrapper <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_concat_axis ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _is_series : <NEWLINE> <TAB> if self . axis == <NUMBER> : <NEWLINE> <TAB> indexes = [ x . index for x in self . objs ] <NEWLINE> <UNTAB> elif self . ignore_index : <NEWLINE> <TAB> idx = com . _default_index ( len ( self . objs ) ) <NEWLINE> return idx <NEWLINE> <UNTAB> elif self . keys is None : <NEWLINE> <TAB> names = [ None ] * len ( self . objs ) <NEWLINE> num = <NUMBER> <NEWLINE> has_names = False <NEWLINE> for i , x in enumerate ( self . objs ) : <NEWLINE> <TAB> if not isinstance ( x , Series ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> <NEWLINE> . format ( type = type ( x ) . __name__ ) ) <NEWLINE> <UNTAB> if x . name is not None : <NEWLINE> <TAB> names [ i ] = x . name <NEWLINE> has_names = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> names [ i ] = num <NEWLINE> num += <NUMBER> <NEWLINE> <UNTAB> <UNTAB> if has_names : <NEWLINE> <TAB> return Index ( names ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return com . _default_index ( len ( self . objs ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return _ensure_index ( self . keys ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> indexes = [ x . _data . axes [ self . axis ] for x in self . objs ] <NEWLINE> <NEWLINE> <UNTAB> if self . ignore_index : <NEWLINE> <TAB> idx = com . _default_index ( sum ( len ( i ) for i in indexes ) ) <NEWLINE> return idx <NEWLINE> <NEWLINE> <UNTAB> if self . keys is None : <NEWLINE> <TAB> concat_axis = _concat_indexes ( indexes ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> concat_axis = _make_concat_multiindex ( indexes , self . keys , <NEWLINE> self . levels , self . names ) <NEWLINE> <NEWLINE> <UNTAB> self . _maybe_check_integrity ( concat_axis ) <NEWLINE> <NEWLINE> return concat_axis <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def reduce ( args ) : <NEWLINE> <TAB> <NEWLINE> new_args = True <NEWLINE> while ( new_args ) : <NEWLINE> <TAB> for id1 , s in enumerate ( args ) : <NEWLINE> <TAB> new_args = False <NEWLINE> for id2 , t in enumerate ( args ) : <NEWLINE> <TAB> if id1 == id2 : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> new_seq = s . _add ( t ) <NEWLINE> <NEWLINE> <NEWLINE> if new_seq is not None : <NEWLINE> <TAB> new_args = [ a for a in args if a not in ( s , t ) ] <NEWLINE> new_args . append ( new_seq ) <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> if new_args : <NEWLINE> <TAB> args = new_args <NEWLINE> break <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if len ( args ) == <NUMBER> : <NEWLINE> <TAB> return args . pop ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return SeqAdd ( args , evaluate = False ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def depthwise_conv2d_native_eager_fallback ( input , filter , strides , padding , data_format = <STRING> , dilations = [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> if not isinstance ( strides , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % strides ) <NEWLINE> <UNTAB> strides = [ _execute . make_int ( _i , <STRING> ) for _i in strides ] <NEWLINE> padding = _execute . make_str ( padding , <STRING> ) <NEWLINE> if data_format is None : <NEWLINE> <TAB> data_format = <STRING> <NEWLINE> <UNTAB> data_format = _execute . make_str ( data_format , <STRING> ) <NEWLINE> if dilations is None : <NEWLINE> <TAB> dilations = [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] <NEWLINE> <UNTAB> if not isinstance ( dilations , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % dilations ) <NEWLINE> <UNTAB> dilations = [ _execute . make_int ( _i , <STRING> ) for _i in dilations ] <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ input , filter ] , _ctx ) <NEWLINE> ( input , filter ) = _inputs_T <NEWLINE> _inputs_flat = [ input , filter ] <NEWLINE> _attrs = ( <STRING> , _attr_T , <STRING> , strides , <STRING> , padding , <NEWLINE> <STRING> , data_format , <STRING> , dilations ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ cbook . deprecated ( <STRING> ) <NEWLINE> def prctile_rank ( x , p ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not cbook . iterable ( p ) : <NEWLINE> <TAB> p = np . arange ( <NUMBER> / p , <NUMBER> , <NUMBER> / p ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> p = np . asarray ( p ) <NEWLINE> <NEWLINE> <UNTAB> if p . max ( ) <= <NUMBER> or p . min ( ) < <NUMBER> or p . max ( ) > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> ptiles = prctile ( x , p ) <NEWLINE> return np . searchsorted ( ptiles , x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def max_err ( self , g_pt , abs_tol , rel_tol ) : <NEWLINE> <TAB> <NEWLINE> pos = [ ] <NEWLINE> errs = [ ] <NEWLINE> abs_errs = [ ] <NEWLINE> rel_errs = [ ] <NEWLINE> <NEWLINE> abs_rel_errs = self . abs_rel_errors ( g_pt ) <NEWLINE> for abs_err , rel_err in abs_rel_errs : <NEWLINE> <TAB> if not np . all ( np . isfinite ( abs_err ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> , repr ( abs_err ) ) <NEWLINE> <UNTAB> if not np . all ( np . isfinite ( rel_err ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> , repr ( rel_err ) ) <NEWLINE> <UNTAB> scaled_err = np . minimum ( abs_err / abs_tol , rel_err / rel_tol ) <NEWLINE> max_i = scaled_err . argmax ( ) <NEWLINE> <NEWLINE> pos . append ( max_i ) <NEWLINE> errs . append ( scaled_err . flatten ( ) [ max_i ] ) <NEWLINE> abs_errs . append ( abs_err . flatten ( ) [ max_i ] ) <NEWLINE> rel_errs . append ( rel_err . flatten ( ) [ max_i ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> max_arg = np . argmax ( errs ) <NEWLINE> max_pos = pos [ max_arg ] <NEWLINE> return ( max_arg , max_pos , abs_errs [ max_arg ] , rel_errs [ max_arg ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _parse_values ( s ) : <NEWLINE> <TAB> <NEWLINE> if not _RE_NONTRIVIAL_DATA . search ( s ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return [ None if s in ( <STRING> , <STRING> ) else s <NEWLINE> for s in next ( csv . reader ( [ s ] ) ) ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> values , errors = zip ( * _RE_DENSE_VALUES . findall ( <STRING> + s ) ) <NEWLINE> if not any ( errors ) : <NEWLINE> <TAB> return [ _unquote ( v ) for v in values ] <NEWLINE> <UNTAB> if _RE_SPARSE_LINE . match ( s ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> return { int ( k ) : _unquote ( v ) <NEWLINE> for k , v in _RE_SPARSE_KEY_VALUES . findall ( s ) } <NEWLINE> <UNTAB> except ValueError as exc : <NEWLINE> <NEWLINE> <TAB> for match in _RE_SPARSE_KEY_VALUES . finditer ( s ) : <NEWLINE> <TAB> if not match . group ( <NUMBER> ) : <NEWLINE> <TAB> raise BadLayout ( <STRING> % match . group ( ) ) <NEWLINE> <UNTAB> <UNTAB> raise BadLayout ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> for match in _RE_DENSE_VALUES . finditer ( s ) : <NEWLINE> <TAB> if match . group ( <NUMBER> ) : <NEWLINE> <TAB> raise BadLayout ( <STRING> % match . group ( ) ) <NEWLINE> <UNTAB> <UNTAB> raise BadLayout ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , bysecond = None , interval = <NUMBER> , tz = None ) : <NEWLINE> <TAB> <NEWLINE> if bysecond is None : <NEWLINE> <TAB> bysecond = range ( <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> rule = rrulewrapper ( SECONDLY , bysecond = bysecond , interval = interval ) <NEWLINE> RRuleLocator . __init__ ( self , rule , tz ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _recursive_fill_value ( dtype , f ) : <NEWLINE> <TAB> <NEWLINE> if dtype . names : <NEWLINE> <TAB> vals = tuple ( _recursive_fill_value ( dtype [ name ] , f ) for name in dtype . names ) <NEWLINE> return np . array ( vals , dtype = dtype ) [ ( ) ] <NEWLINE> <UNTAB> elif dtype . subdtype : <NEWLINE> <TAB> subtype , shape = dtype . subdtype <NEWLINE> subval = _recursive_fill_value ( subtype , f ) <NEWLINE> return np . full ( shape , subval ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return f ( dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def initial_seed ( ) : <NEWLINE> <TAB> <NEWLINE> _lazy_init ( ) <NEWLINE> return _C . _cuda_initialSeed ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _rand2 ( self , samples ) : <NEWLINE> <TAB> <NEWLINE> r0 , r1 , r2 , r3 , r4 = samples <NEWLINE> bprime = ( self . population [ r0 ] + self . scale * <NEWLINE> ( self . population [ r1 ] + self . population [ r2 ] - <NEWLINE> self . population [ r3 ] - self . population [ r4 ] ) ) <NEWLINE> <NEWLINE> return bprime <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def tricontour ( ax , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> kwargs [ <STRING> ] = False <NEWLINE> return TriContourSet ( ax , * args , ** kwargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def transform_non_affine ( self , values ) : <NEWLINE> <TAB> <NEWLINE> return values <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_float_dtype ( arr_or_dtype ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if arr_or_dtype is None : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> tipo = _get_dtype_type ( arr_or_dtype ) <NEWLINE> return issubclass ( tipo , np . floating ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __next__ ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . iter . coords , next ( self . iter ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def print_latex ( expr , ** settings ) : <NEWLINE> <TAB> <NEWLINE> print ( latex ( expr , ** settings ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def gisinf ( x ) : <NEWLINE> <TAB> <NEWLINE> from numpy . core import isinf , errstate <NEWLINE> with errstate ( invalid = <STRING> ) : <NEWLINE> <TAB> st = isinf ( x ) <NEWLINE> if isinstance ( st , type ( NotImplemented ) ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> return st <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _getboolean ( self , string ) : <NEWLINE> <TAB> <NEWLINE> if string : <NEWLINE> <TAB> return self . tk . getboolean ( string ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _auto_set_column_width ( self , col , renderer ) : <NEWLINE> <TAB> <NEWLINE> cells = [ key for key in self . _cells if key [ <NUMBER> ] == col ] <NEWLINE> <NEWLINE> <NEWLINE> width = <NUMBER> <NEWLINE> for cell in cells : <NEWLINE> <TAB> c = self . _cells [ cell ] <NEWLINE> width = max ( c . get_required_width ( renderer ) , width ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for cell in cells : <NEWLINE> <TAB> self . _cells [ cell ] . set_width ( width ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def graph_atlas_g ( ) : <NEWLINE> <TAB> <NEWLINE> return list ( _generate_graphs ( ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def sinh ( x , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , x = x , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , x ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return sinh_eager_fallback ( <NEWLINE> x , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def lcm ( self , a , b ) : <NEWLINE> <TAB> <NEWLINE> return a . lcm ( b ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def inverse ( self , argindex = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return log <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def tanh ( x ) : <NEWLINE> <TAB> <NEWLINE> return tf . nn . tanh ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def ufft2 ( inarray ) : <NEWLINE> <TAB> <NEWLINE> return ufftn ( inarray , <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _slice ( self , slicer ) : <NEWLINE> <TAB> <NEWLINE> return self . get_values ( ) [ slicer ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , marker = None , fillstyle = None ) : <NEWLINE> <TAB> <NEWLINE> self . _marker_function = None <NEWLINE> self . set_fillstyle ( fillstyle ) <NEWLINE> self . set_marker ( marker ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rpartition ( a , sep ) : <NEWLINE> <TAB> <NEWLINE> return _to_string_or_unicode_array ( <NEWLINE> _vec_string ( a , object_ , <STRING> , ( sep , ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _tf_to_cudnn_biases ( self , * tf_biases ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> b_ir , b_wh , b_rh = tf_biases <NEWLINE> bi , br = b_ir * <NUMBER> , b_ir * <NUMBER> <NEWLINE> b_wi , b_wr = array_ops . split ( bi , <NUMBER> , axis = <NUMBER> ) <NEWLINE> b_ri , b_rr = array_ops . split ( br , <NUMBER> , axis = <NUMBER> ) <NEWLINE> return b_wi , b_wr , b_wh , b_ri , b_rr , b_rh <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def build_flow_dict ( G , R ) : <NEWLINE> <TAB> <NEWLINE> flow_dict = { } <NEWLINE> for u in G : <NEWLINE> <TAB> flow_dict [ u ] = { v : <NUMBER> for v in G [ u ] } <NEWLINE> flow_dict [ u ] . update ( ( v , attr [ <STRING> ] ) for v , attr in R [ u ] . items ( ) <NEWLINE> if attr [ <STRING> ] > <NUMBER> ) <NEWLINE> <UNTAB> return flow_dict <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def generate_dequeue_op ( self , tpu_device = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> self . freeze ( ) <NEWLINE> if self . _generated_dequeue_op : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> self . _generated_dequeue_op = True <NEWLINE> full_name = <STRING> % self . _name <NEWLINE> sharded_shapes = [ <NEWLINE> policy . get_sharded_shape ( shape ) <NEWLINE> for ( shape , policy ) in zip ( self . _tuple_shapes , self . _sharding_policies ) <NEWLINE> ] <NEWLINE> if tpu_device is not None : <NEWLINE> <TAB> with ops . device ( tpu . core ( tpu_device ) ) : <NEWLINE> <TAB> return tpu_ops . infeed_dequeue_tuple ( <NEWLINE> dtypes = self . _tuple_types , shapes = sharded_shapes , name = full_name ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return tpu_ops . infeed_dequeue_tuple ( <NEWLINE> dtypes = self . _tuple_types , shapes = sharded_shapes , name = full_name ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def tensor_shape_from_node_def_name ( graph , input_name ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if <STRING> not in input_name : <NEWLINE> <TAB> canonical_name = input_name + <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> canonical_name = input_name <NEWLINE> <UNTAB> tensor = graph . get_tensor_by_name ( canonical_name ) <NEWLINE> shape = tensor . get_shape ( ) <NEWLINE> return shape <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def mood ( x , y , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> x = np . asarray ( x , dtype = float ) <NEWLINE> y = np . asarray ( y , dtype = float ) <NEWLINE> <NEWLINE> if axis is None : <NEWLINE> <TAB> x = x . flatten ( ) <NEWLINE> y = y . flatten ( ) <NEWLINE> axis = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> res_shape = tuple ( [ x . shape [ ax ] for ax in range ( len ( x . shape ) ) if ax != axis ] ) <NEWLINE> if not ( res_shape == tuple ( [ y . shape [ ax ] for ax in range ( len ( y . shape ) ) if <NEWLINE> ax != axis ] ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> n = x . shape [ axis ] <NEWLINE> m = y . shape [ axis ] <NEWLINE> N = m + n <NEWLINE> if N < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> xy = np . concatenate ( ( x , y ) , axis = axis ) <NEWLINE> if axis != <NUMBER> : <NEWLINE> <TAB> xy = np . rollaxis ( xy , axis ) <NEWLINE> <NEWLINE> <UNTAB> xy = xy . reshape ( xy . shape [ <NUMBER> ] , - <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> all_ranks = np . zeros_like ( xy ) <NEWLINE> for j in range ( xy . shape [ <NUMBER> ] ) : <NEWLINE> <TAB> all_ranks [ : , j ] = stats . rankdata ( xy [ : , j ] ) <NEWLINE> <NEWLINE> <UNTAB> Ri = all_ranks [ : n ] <NEWLINE> M = np . sum ( ( Ri - ( N + <NUMBER> ) / <NUMBER> ) ** <NUMBER> , axis = <NUMBER> ) <NEWLINE> <NEWLINE> mnM = n * ( N * N - <NUMBER> ) / <NUMBER> <NEWLINE> varM = m * n * ( N + <NUMBER> ) * ( N + <NUMBER> ) * ( N - <NUMBER> ) / <NUMBER> <NEWLINE> z = ( M - mnM ) / sqrt ( varM ) <NEWLINE> <NEWLINE> <NEWLINE> z_pos = z > <NUMBER> <NEWLINE> pval = np . zeros_like ( z ) <NEWLINE> pval [ z_pos ] = <NUMBER> * distributions . norm . sf ( z [ z_pos ] ) <NEWLINE> pval [ ~ z_pos ] = <NUMBER> * distributions . norm . cdf ( z [ ~ z_pos ] ) <NEWLINE> <NEWLINE> if res_shape == ( ) : <NEWLINE> <NEWLINE> <TAB> z = z [ <NUMBER> ] <NEWLINE> pval = pval [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> z . shape = res_shape <NEWLINE> pval . shape = res_shape <NEWLINE> <NEWLINE> <UNTAB> return z , pval <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _munp ( self , n ) : <NEWLINE> <TAB> <NEWLINE> integrals = ( self . _hbins [ <NUMBER> : ] ** ( n + <NUMBER> ) - self . _hbins [ : - <NUMBER> ] ** ( n + <NUMBER> ) ) / ( n + <NUMBER> ) <NEWLINE> return np . sum ( self . _hpdf [ <NUMBER> : - <NUMBER> ] * integrals ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _dmp_rr_trivial_gcd ( f , g , u , K ) : <NEWLINE> <TAB> <NEWLINE> zero_f = dmp_zero_p ( f , u ) <NEWLINE> zero_g = dmp_zero_p ( g , u ) <NEWLINE> if_contain_one = dmp_one_p ( f , u , K ) or dmp_one_p ( g , u , K ) <NEWLINE> <NEWLINE> if zero_f and zero_g : <NEWLINE> <TAB> return tuple ( dmp_zeros ( <NUMBER> , u , K ) ) <NEWLINE> <UNTAB> elif zero_f : <NEWLINE> <TAB> if K . is_nonnegative ( dmp_ground_LC ( g , u , K ) ) : <NEWLINE> <TAB> return g , dmp_zero ( u ) , dmp_one ( u , K ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return dmp_neg ( g , u , K ) , dmp_zero ( u ) , dmp_ground ( - K . one , u ) <NEWLINE> <UNTAB> <UNTAB> elif zero_g : <NEWLINE> <TAB> if K . is_nonnegative ( dmp_ground_LC ( f , u , K ) ) : <NEWLINE> <TAB> return f , dmp_one ( u , K ) , dmp_zero ( u ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return dmp_neg ( f , u , K ) , dmp_ground ( - K . one , u ) , dmp_zero ( u ) <NEWLINE> <UNTAB> <UNTAB> elif if_contain_one : <NEWLINE> <TAB> return dmp_one ( u , K ) , f , g <NEWLINE> <UNTAB> elif query ( <STRING> ) : <NEWLINE> <TAB> return _dmp_simplify_gcd ( f , g , u , K ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def parse_legacy_select ( self , arg ) : <NEWLINE> <TAB> <NEWLINE> if arg in ( None , False ) : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> nowait = read = False <NEWLINE> if arg == <STRING> : <NEWLINE> <TAB> nowait = True <NEWLINE> <UNTAB> elif arg == <STRING> : <NEWLINE> <TAB> read = True <NEWLINE> <UNTAB> elif arg == <STRING> : <NEWLINE> <TAB> read = nowait = True <NEWLINE> <UNTAB> elif arg is not True : <NEWLINE> <TAB> raise exc . ArgumentError ( <STRING> % arg ) <NEWLINE> <NEWLINE> <UNTAB> return ForUpdateArg ( read = read , nowait = nowait ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def call ( self , inputs , state ) : <NEWLINE> <TAB> <NEWLINE> cur_state_pos = <NUMBER> <NEWLINE> cur_inp = inputs <NEWLINE> new_states = [ ] <NEWLINE> for i , cell in enumerate ( self . _cells ) : <NEWLINE> <TAB> with vs . variable_scope ( <STRING> % i ) : <NEWLINE> <TAB> if self . _state_is_tuple : <NEWLINE> <TAB> if not nest . is_sequence ( state ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % <NEWLINE> ( len ( self . state_size ) , state ) ) <NEWLINE> <UNTAB> cur_state = state [ i ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cur_state = array_ops . slice ( state , [ <NUMBER> , cur_state_pos ] , <NEWLINE> [ - <NUMBER> , cell . state_size ] ) <NEWLINE> cur_state_pos += cell . state_size <NEWLINE> <UNTAB> cur_inp , new_state = cell ( cur_inp , cur_state ) <NEWLINE> new_states . append ( new_state ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> new_states = ( tuple ( new_states ) if self . _state_is_tuple else <NEWLINE> array_ops . concat ( new_states , <NUMBER> ) ) <NEWLINE> <NEWLINE> return cur_inp , new_states <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_coeffs ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . tck [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def cs_diff ( x , a , b , period = None , _cache = _cache ) : <NEWLINE> <TAB> <NEWLINE> tmp = asarray ( x ) <NEWLINE> if iscomplexobj ( tmp ) : <NEWLINE> <TAB> return cs_diff ( tmp . real , a , b , period ) + <NUMBER> * cs_diff ( tmp . imag , a , b , period ) <NEWLINE> <UNTAB> if period is not None : <NEWLINE> <TAB> a = a * <NUMBER> * pi / period <NEWLINE> b = b * <NUMBER> * pi / period <NEWLINE> <UNTAB> n = len ( x ) <NEWLINE> omega = _cache . get ( ( n , a , b ) ) <NEWLINE> if omega is None : <NEWLINE> <TAB> if len ( _cache ) > <NUMBER> : <NEWLINE> <TAB> while _cache : <NEWLINE> <TAB> _cache . popitem ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def kernel ( k , a = a , b = b ) : <NEWLINE> <TAB> if k : <NEWLINE> <TAB> return - cosh ( a * k ) / sinh ( b * k ) <NEWLINE> <UNTAB> return <NUMBER> <NEWLINE> <UNTAB> omega = convolve . init_convolution_kernel ( n , kernel , d = <NUMBER> ) <NEWLINE> _cache [ ( n , a , b ) ] = omega <NEWLINE> <UNTAB> overwrite_x = _datacopied ( tmp , x ) <NEWLINE> return convolve . convolve ( tmp , omega , swap_real_imag = <NUMBER> , overwrite_x = overwrite_x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _add_numeric_methods_binary ( cls ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def _make_evaluate_binop ( op , step = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def _evaluate_numeric_binop ( self , other ) : <NEWLINE> <TAB> if isinstance ( other , ABCSeries ) : <NEWLINE> <TAB> return NotImplemented <NEWLINE> <UNTAB> elif isinstance ( other , ABCTimedeltaIndex ) : <NEWLINE> <NEWLINE> <TAB> return NotImplemented <NEWLINE> <UNTAB> elif isinstance ( other , ( timedelta , np . timedelta64 ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return op ( self . _int64index , other ) <NEWLINE> <NEWLINE> <UNTAB> other = self . _validate_for_numeric_binop ( other , op ) <NEWLINE> attrs = self . _get_attributes_dict ( ) <NEWLINE> attrs = self . _maybe_update_attributes ( attrs ) <NEWLINE> <NEWLINE> left , right = self , other <NEWLINE> <NEWLINE> try : <NEWLINE> <NEWLINE> <TAB> if step : <NEWLINE> <TAB> with np . errstate ( all = <STRING> ) : <NEWLINE> <TAB> rstep = step ( left . _step , right ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if not is_integer ( rstep ) or not rstep : <NEWLINE> <TAB> raise ValueError <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> rstep = left . _step <NEWLINE> <NEWLINE> <UNTAB> with np . errstate ( all = <STRING> ) : <NEWLINE> <TAB> rstart = op ( left . _start , right ) <NEWLINE> rstop = op ( left . _stop , right ) <NEWLINE> <NEWLINE> <UNTAB> result = RangeIndex ( rstart , <NEWLINE> rstop , <NEWLINE> rstep , <NEWLINE> ** attrs ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if not all ( is_integer ( x ) for x in <NEWLINE> [ rstart , rstop , rstep ] ) : <NEWLINE> <TAB> result = result . astype ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return result <NEWLINE> <NEWLINE> <UNTAB> except ( ValueError , TypeError , ZeroDivisionError ) : <NEWLINE> <NEWLINE> <TAB> return op ( self . _int64index , other ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return _evaluate_numeric_binop <NEWLINE> <NEWLINE> <UNTAB> cls . __add__ = _make_evaluate_binop ( operator . add ) <NEWLINE> cls . __radd__ = _make_evaluate_binop ( ops . radd ) <NEWLINE> cls . __sub__ = _make_evaluate_binop ( operator . sub ) <NEWLINE> cls . __rsub__ = _make_evaluate_binop ( ops . rsub ) <NEWLINE> cls . __mul__ = _make_evaluate_binop ( operator . mul , step = operator . mul ) <NEWLINE> cls . __rmul__ = _make_evaluate_binop ( ops . rmul , step = ops . rmul ) <NEWLINE> cls . __truediv__ = _make_evaluate_binop ( operator . truediv , <NEWLINE> step = operator . truediv ) <NEWLINE> cls . __rtruediv__ = _make_evaluate_binop ( ops . rtruediv , <NEWLINE> step = ops . rtruediv ) <NEWLINE> if not compat . PY3 : <NEWLINE> <TAB> cls . __div__ = _make_evaluate_binop ( operator . div , step = operator . div ) <NEWLINE> cls . __rdiv__ = _make_evaluate_binop ( ops . rdiv , step = ops . rdiv ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def prob ( self , value , name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return self . _call_prob ( value , name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _RecordLastCheckpoint ( self , latest_save_path ) : <NEWLINE> <TAB> <NEWLINE> if not self . saver_def . max_to_keep : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> for p in self . _last_checkpoints : <NEWLINE> <TAB> if latest_save_path == self . _CheckpointFilename ( p ) : <NEWLINE> <TAB> self . _last_checkpoints . remove ( p ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . _last_checkpoints . append ( ( latest_save_path , time . time ( ) ) ) <NEWLINE> <NEWLINE> <NEWLINE> if len ( self . _last_checkpoints ) > self . saver_def . max_to_keep : <NEWLINE> <TAB> self . _checkpoints_to_be_deleted . append ( self . _last_checkpoints . pop ( <NUMBER> ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def rmdir ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _closed : <NEWLINE> <TAB> self . _raise_closed ( ) <NEWLINE> <UNTAB> self . _accessor . rmdir ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def update_ticks ( self ) : <NEWLINE> <TAB> <NEWLINE> ax = self . ax <NEWLINE> <NEWLINE> <NEWLINE> locator , formatter = self . _get_ticker_locator_formatter ( ) <NEWLINE> <NEWLINE> if self . orientation == <STRING> : <NEWLINE> <TAB> long_axis , short_axis = ax . yaxis , ax . xaxis <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> long_axis , short_axis = ax . xaxis , ax . yaxis <NEWLINE> <NEWLINE> <UNTAB> if self . _use_auto_colorbar_locator ( ) : <NEWLINE> <TAB> _log . debug ( <STRING> ) <NEWLINE> _log . debug ( <STRING> , locator ) <NEWLINE> long_axis . set_major_locator ( locator ) <NEWLINE> long_axis . set_major_formatter ( formatter ) <NEWLINE> if type ( self . norm ) == colors . LogNorm : <NEWLINE> <TAB> long_axis . set_minor_locator ( _ColorbarLogLocator ( self , <NEWLINE> base = <NUMBER> , subs = <STRING> ) ) <NEWLINE> long_axis . set_minor_formatter ( <NEWLINE> ticker . LogFormatterSciNotation ( ) <NEWLINE> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> _log . debug ( <STRING> ) <NEWLINE> ticks , ticklabels , offset_string = self . _ticker ( locator , formatter ) <NEWLINE> long_axis . set_ticks ( ticks ) <NEWLINE> long_axis . set_ticklabels ( ticklabels ) <NEWLINE> long_axis . get_major_formatter ( ) . set_offset_string ( offset_string ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def items ( self ) : <NEWLINE> <TAB> <NEWLINE> return [ ( f , self [ f ] ) for f in self . files ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ abstractmethod <NEWLINE> def fit ( self , X , y ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def locator_params ( self , axis = <STRING> , tight = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> _x = axis in [ <STRING> , <STRING> ] <NEWLINE> _y = axis in [ <STRING> , <STRING> ] <NEWLINE> if _x : <NEWLINE> <TAB> self . xaxis . get_major_locator ( ) . set_params ( ** kwargs ) <NEWLINE> <UNTAB> if _y : <NEWLINE> <TAB> self . yaxis . get_major_locator ( ) . set_params ( ** kwargs ) <NEWLINE> <UNTAB> self . autoscale_view ( tight = tight , scalex = _x , scaley = _y ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def clarkson_woodruff_transform ( input_matrix , sketch_size , seed = None ) : <NEWLINE> <TAB> <NEWLINE> S = cwt_matrix ( sketch_size , input_matrix . shape [ <NUMBER> ] , seed ) <NEWLINE> return np . dot ( S , input_matrix ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def format_call ( func , args , kwargs , object_name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> path , signature = format_signature ( func , * args , ** kwargs ) <NEWLINE> msg = <STRING> % ( <NUMBER> * <STRING> , object_name , <NEWLINE> path , signature ) <NEWLINE> return msg <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def pct_change ( self , periods = <NUMBER> , fill_method = <STRING> , limit = None , freq = None ) : <NEWLINE> <TAB> <NEWLINE> filled = getattr ( self , fill_method ) ( limit = limit ) <NEWLINE> shifted = filled . shift ( periods = periods , freq = freq ) <NEWLINE> <NEWLINE> return ( filled / shifted ) - <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def assertLessEqual ( self , a , b , msg = None ) : <NEWLINE> <TAB> <NEWLINE> if not a <= b : <NEWLINE> <TAB> standardMsg = <STRING> % ( safe_repr ( a ) , safe_repr ( b ) ) <NEWLINE> self . fail ( self . _formatMessage ( msg , standardMsg ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def kaiser ( M , beta ) : <NEWLINE> <TAB> <NEWLINE> from numpy . dual import i0 <NEWLINE> if M == <NUMBER> : <NEWLINE> <TAB> return np . array ( [ <NUMBER> ] ) <NEWLINE> <UNTAB> n = arange ( <NUMBER> , M ) <NEWLINE> alpha = ( M - <NUMBER> ) / <NUMBER> <NEWLINE> return i0 ( beta * sqrt ( <NUMBER> - ( ( n - alpha ) / alpha ) ** <NUMBER> ) ) / i0 ( float ( beta ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def expand_environment_variables ( config ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( config , Mapping ) : <NEWLINE> <TAB> return { k : expand_environment_variables ( v ) for k , v in config . items ( ) } <NEWLINE> <UNTAB> elif isinstance ( config , str ) : <NEWLINE> <TAB> return os . path . expandvars ( config ) <NEWLINE> <UNTAB> elif isinstance ( config , ( list , tuple , builtins . set ) ) : <NEWLINE> <TAB> return type ( config ) ( [ expand_environment_variables ( v ) for v in config ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return config <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_dpi ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . dpi <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def he_uniform ( seed = None ) : <NEWLINE> <TAB> <NEWLINE> return VarianceScaling ( <NEWLINE> scale = <NUMBER> , mode = <STRING> , distribution = <STRING> , seed = seed ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def combine_paths ( * args , ** kws ) : <NEWLINE> <TAB> <NEWLINE> r = [ ] <NEWLINE> for a in args : <NEWLINE> <TAB> if not a : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> if is_string ( a ) : <NEWLINE> <TAB> a = [ a ] <NEWLINE> <UNTAB> r . append ( a ) <NEWLINE> <UNTAB> args = r <NEWLINE> if not args : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> if len ( args ) == <NUMBER> : <NEWLINE> <TAB> result = reduce ( lambda a , b : a + b , map ( glob , args [ <NUMBER> ] ) , [ ] ) <NEWLINE> <UNTAB> elif len ( args ) == <NUMBER> : <NEWLINE> <TAB> result = [ ] <NEWLINE> for a0 in args [ <NUMBER> ] : <NEWLINE> <TAB> for a1 in args [ <NUMBER> ] : <NEWLINE> <TAB> result . extend ( glob ( os . path . join ( a0 , a1 ) ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> result = combine_paths ( * ( combine_paths ( args [ <NUMBER> ] , args [ <NUMBER> ] ) + args [ <NUMBER> : ] ) ) <NEWLINE> <UNTAB> log . debug ( <STRING> , <STRING> . join ( result ) ) <NEWLINE> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def flag_dict_to_args ( flag_map ) : <NEWLINE> <TAB> <NEWLINE> for key , value in six . iteritems ( flag_map ) : <NEWLINE> <TAB> if value is None : <NEWLINE> <TAB> yield <STRING> % key <NEWLINE> <UNTAB> elif isinstance ( value , bool ) : <NEWLINE> <TAB> if value : <NEWLINE> <TAB> yield <STRING> % key <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> yield <STRING> % key <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( value , ( bytes , type ( <STRING> ) ) ) : <NEWLINE> <NEWLINE> <TAB> yield <STRING> % ( key , value ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> yield <STRING> % ( key , <STRING> . join ( str ( item ) for item in value ) ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <NEWLINE> <TAB> yield <STRING> % ( key , value ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def matrix2numpy ( m , dtype = object ) : <NEWLINE> <TAB> <NEWLINE> from numpy import empty <NEWLINE> a = empty ( m . shape , dtype ) <NEWLINE> for i in range ( m . rows ) : <NEWLINE> <TAB> for j in range ( m . cols ) : <NEWLINE> <TAB> a [ i , j ] = m [ i , j ] <NEWLINE> <UNTAB> <UNTAB> return a <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def groebner ( F , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> return GroebnerBasis ( F , * gens , ** args ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def master ( self , task_type = None , task_index = None ) : <NEWLINE> <TAB> <NEWLINE> if task_type and task_index : <NEWLINE> <TAB> return self . cluster_spec ( ) . task_address ( task_type , task_index ) <NEWLINE> <NEWLINE> <UNTAB> return self . _cluster_resolvers [ <NUMBER> ] . master ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def task_done ( self ) : <NEWLINE> <TAB> <NEWLINE> with self . all_tasks_done : <NEWLINE> <TAB> unfinished = self . unfinished_tasks - <NUMBER> <NEWLINE> if unfinished <= <NUMBER> : <NEWLINE> <TAB> if unfinished < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> self . all_tasks_done . notify_all ( ) <NEWLINE> <UNTAB> self . unfinished_tasks = unfinished <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _pad_ref ( arr , pad_amt , method , axis = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if pad_amt [ <NUMBER> ] == <NUMBER> and pad_amt [ <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> return arr <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> ref_slice = tuple ( slice ( None ) if i != axis else slice ( pad_amt [ <NUMBER> ] , <NUMBER> , - <NUMBER> ) <NEWLINE> for ( i , x ) in enumerate ( arr . shape ) ) <NEWLINE> <NEWLINE> ref_chunk1 = arr [ ref_slice ] <NEWLINE> <NEWLINE> <NEWLINE> pad_singleton = tuple ( x if i != axis else <NUMBER> <NEWLINE> for ( i , x ) in enumerate ( arr . shape ) ) <NEWLINE> if pad_amt [ <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> ref_chunk1 = ref_chunk1 . reshape ( pad_singleton ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if <STRING> in method and pad_amt [ <NUMBER> ] > <NUMBER> : <NEWLINE> <TAB> edge_slice1 = tuple ( slice ( None ) if i != axis else <NUMBER> <NEWLINE> for ( i , x ) in enumerate ( arr . shape ) ) <NEWLINE> edge_chunk = arr [ edge_slice1 ] . reshape ( pad_singleton ) <NEWLINE> ref_chunk1 = <NUMBER> * edge_chunk - ref_chunk1 <NEWLINE> del edge_chunk <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> start = arr . shape [ axis ] - pad_amt [ <NUMBER> ] - <NUMBER> <NEWLINE> end = arr . shape [ axis ] - <NUMBER> <NEWLINE> ref_slice = tuple ( slice ( None ) if i != axis else slice ( start , end ) <NEWLINE> for ( i , x ) in enumerate ( arr . shape ) ) <NEWLINE> rev_idx = tuple ( slice ( None ) if i != axis else slice ( None , None , - <NUMBER> ) <NEWLINE> for ( i , x ) in enumerate ( arr . shape ) ) <NEWLINE> ref_chunk2 = arr [ ref_slice ] [ rev_idx ] <NEWLINE> <NEWLINE> if pad_amt [ <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> ref_chunk2 = ref_chunk2 . reshape ( pad_singleton ) <NEWLINE> <NEWLINE> <UNTAB> if <STRING> in method : <NEWLINE> <TAB> edge_slice2 = tuple ( slice ( None ) if i != axis else - <NUMBER> <NEWLINE> for ( i , x ) in enumerate ( arr . shape ) ) <NEWLINE> edge_chunk = arr [ edge_slice2 ] . reshape ( pad_singleton ) <NEWLINE> ref_chunk2 = <NUMBER> * edge_chunk - ref_chunk2 <NEWLINE> del edge_chunk <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return np . concatenate ( ( ref_chunk1 , arr , ref_chunk2 ) , axis = axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def dot ( self , V ) : <NEWLINE> <TAB> <NEWLINE> assert V . shape == ( self . m , ) <NEWLINE> return np . bincount ( self . rows , <NEWLINE> weights = self . vals * V [ self . cols ] , <NEWLINE> minlength = self . m ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _invert ( eq , * symbols , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> eq = sympify ( eq ) <NEWLINE> free = eq . free_symbols <NEWLINE> if not symbols : <NEWLINE> <TAB> symbols = free <NEWLINE> <UNTAB> if not free & set ( symbols ) : <NEWLINE> <TAB> return eq , S . Zero <NEWLINE> <NEWLINE> <UNTAB> dointpow = bool ( kwargs . get ( <STRING> , False ) ) <NEWLINE> <NEWLINE> lhs = eq <NEWLINE> rhs = S . Zero <NEWLINE> while True : <NEWLINE> <TAB> was = lhs <NEWLINE> while True : <NEWLINE> <TAB> indep , dep = lhs . as_independent ( * symbols ) <NEWLINE> <NEWLINE> <NEWLINE> if lhs . is_Add : <NEWLINE> <NEWLINE> <TAB> if indep is S . Zero : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <UNTAB> lhs = dep <NEWLINE> rhs -= indep <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> if indep is S . One : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <UNTAB> lhs = dep <NEWLINE> rhs /= indep <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if lhs . is_Add : <NEWLINE> <TAB> terms = { } <NEWLINE> for a in lhs . args : <NEWLINE> <TAB> i , d = a . as_independent ( * symbols ) <NEWLINE> terms . setdefault ( d , [ ] ) . append ( i ) <NEWLINE> <UNTAB> if any ( len ( v ) > <NUMBER> for v in terms . values ( ) ) : <NEWLINE> <TAB> args = [ ] <NEWLINE> for d , i in terms . items ( ) : <NEWLINE> <TAB> if len ( i ) > <NUMBER> : <NEWLINE> <TAB> args . append ( Add ( * i ) * d ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> args . append ( i [ <NUMBER> ] * d ) <NEWLINE> <UNTAB> <UNTAB> lhs = Add ( * args ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if lhs . is_Add and not rhs and len ( lhs . args ) == <NUMBER> and not lhs . is_polynomial ( * symbols ) : <NEWLINE> <TAB> a , b = ordered ( lhs . args ) <NEWLINE> ai , ad = a . as_independent ( * symbols ) <NEWLINE> bi , bd = b . as_independent ( * symbols ) <NEWLINE> if any ( _ispow ( i ) for i in ( ad , bd ) ) : <NEWLINE> <TAB> a_base , a_exp = ad . as_base_exp ( ) <NEWLINE> b_base , b_exp = bd . as_base_exp ( ) <NEWLINE> if a_base == b_base : <NEWLINE> <NEWLINE> <TAB> lhs = powsimp ( powdenest ( ad / bd ) ) <NEWLINE> rhs = - bi / ai <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rat = ad / bd <NEWLINE> _lhs = powsimp ( ad / bd ) <NEWLINE> if _lhs != rat : <NEWLINE> <TAB> lhs = _lhs <NEWLINE> rhs = - bi / ai <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif ai == - bi : <NEWLINE> <TAB> if isinstance ( ad , Function ) and ad . func == bd . func : <NEWLINE> <TAB> if len ( ad . args ) == len ( bd . args ) == <NUMBER> : <NEWLINE> <TAB> lhs = ad . args [ <NUMBER> ] - bd . args [ <NUMBER> ] <NEWLINE> <UNTAB> elif len ( ad . args ) == len ( bd . args ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> elif lhs . is_Mul and any ( _ispow ( a ) for a in lhs . args ) : <NEWLINE> <TAB> lhs = powsimp ( powdenest ( lhs ) ) <NEWLINE> <NEWLINE> <UNTAB> if lhs . is_Function : <NEWLINE> <TAB> if hasattr ( lhs , <STRING> ) and len ( lhs . args ) == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> rhs = lhs . inverse ( ) ( rhs ) <NEWLINE> lhs = lhs . args [ <NUMBER> ] <NEWLINE> <UNTAB> elif isinstance ( lhs , atan2 ) : <NEWLINE> <TAB> y , x = lhs . args <NEWLINE> lhs = <NUMBER> * atan ( y / ( sqrt ( x ** <NUMBER> + y ** <NUMBER> ) + x ) ) <NEWLINE> <UNTAB> elif lhs . func == rhs . func : <NEWLINE> <TAB> if len ( lhs . args ) == len ( rhs . args ) == <NUMBER> : <NEWLINE> <TAB> lhs = lhs . args [ <NUMBER> ] <NEWLINE> rhs = rhs . args [ <NUMBER> ] <NEWLINE> <UNTAB> elif len ( lhs . args ) == len ( rhs . args ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if rhs and lhs . is_Pow and lhs . exp . is_Integer and lhs . exp < <NUMBER> : <NEWLINE> <TAB> lhs = <NUMBER> / lhs <NEWLINE> rhs = <NUMBER> / rhs <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if lhs . is_Pow and ( <NEWLINE> lhs . exp . is_Integer and dointpow or not lhs . exp . is_Integer and <NEWLINE> len ( symbols ) > <NUMBER> and len ( lhs . base . free_symbols & set ( symbols ) ) > <NUMBER> ) : <NEWLINE> <TAB> rhs = rhs ** ( <NUMBER> / lhs . exp ) <NEWLINE> lhs = lhs . base <NEWLINE> <NEWLINE> <UNTAB> if lhs == was : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> return rhs , lhs <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_offset ( self , xy ) : <NEWLINE> <TAB> <NEWLINE> self . _offset = xy <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def fuzzy_and ( args ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> rv = True <NEWLINE> for ai in args : <NEWLINE> <TAB> ai = fuzzy_bool ( ai ) <NEWLINE> if ai is False : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> if rv : <NEWLINE> <TAB> rv = ai <NEWLINE> <UNTAB> <UNTAB> return rv <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def cov ( x , y = None , rowvar = True , bias = False , allow_masked = True , ddof = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if ddof is not None and ddof != int ( ddof ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if ddof is None : <NEWLINE> <TAB> if bias : <NEWLINE> <TAB> ddof = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ddof = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> ( x , xnotmask , rowvar ) = _covhelper ( x , y , rowvar , allow_masked ) <NEWLINE> if not rowvar : <NEWLINE> <TAB> fact = np . dot ( xnotmask . T , xnotmask ) * <NUMBER> - ddof <NEWLINE> result = ( dot ( x . T , x . conj ( ) , strict = False ) / fact ) . squeeze ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> fact = np . dot ( xnotmask , xnotmask . T ) * <NUMBER> - ddof <NEWLINE> result = ( dot ( x , x . T . conj ( ) , strict = False ) / fact ) . squeeze ( ) <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_rowcount ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> def double_edge_swap ( G , nswap = <NUMBER> , max_tries = <NUMBER> , seed = None ) : <NEWLINE> <TAB> <NEWLINE> if G . is_directed ( ) : <NEWLINE> <TAB> raise nx . NetworkXError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if nswap > max_tries : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <UNTAB> if len ( G ) < <NUMBER> : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> n = <NUMBER> <NEWLINE> swapcount = <NUMBER> <NEWLINE> keys , degrees = zip ( * G . degree ( ) ) <NEWLINE> cdf = nx . utils . cumulative_distribution ( degrees ) <NEWLINE> discrete_sequence = nx . utils . discrete_sequence <NEWLINE> while swapcount < nswap : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> ( ui , xi ) = discrete_sequence ( <NUMBER> , cdistribution = cdf , seed = seed ) <NEWLINE> if ui == xi : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> u = keys [ ui ] <NEWLINE> x = keys [ xi ] <NEWLINE> <NEWLINE> v = seed . choice ( list ( G [ u ] ) ) <NEWLINE> y = seed . choice ( list ( G [ x ] ) ) <NEWLINE> if v == y : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> if ( x not in G [ u ] ) and ( y not in G [ v ] ) : <NEWLINE> <TAB> G . add_edge ( u , x ) <NEWLINE> G . add_edge ( v , y ) <NEWLINE> G . remove_edge ( u , v ) <NEWLINE> G . remove_edge ( x , y ) <NEWLINE> swapcount += <NUMBER> <NEWLINE> <UNTAB> if n >= max_tries : <NEWLINE> <TAB> e = ( <STRING> % n + <NEWLINE> <STRING> % nswap ) <NEWLINE> raise nx . NetworkXAlgorithmError ( e ) <NEWLINE> <UNTAB> n += <NUMBER> <NEWLINE> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def initialized_value ( self ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def update_scalarmappable ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _A is None : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> if self . _A . ndim > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if not self . check_update ( <STRING> ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> if self . _is_filled : <NEWLINE> <TAB> self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) <NEWLINE> <UNTAB> elif self . _is_stroked : <NEWLINE> <TAB> self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) <NEWLINE> <UNTAB> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def product ( iterable ) : <NEWLINE> <TAB> <NEWLINE> prod = <NUMBER> <NEWLINE> for i in iterable : <NEWLINE> <TAB> prod *= i <NEWLINE> <UNTAB> return prod <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_interpolation ( self , s ) : <NEWLINE> <TAB> <NEWLINE> if s is not None and s not in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> AxesImage . set_interpolation ( self , s ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def read_file ( filename , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , filename = filename , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = None <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , filename ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return read_file_eager_fallback ( <NEWLINE> filename , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __rmod__ ( b , a ) : <NEWLINE> <TAB> <NEWLINE> div = a // b <NEWLINE> return a - b * div <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def neg ( x , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , x = x , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , x ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return neg_eager_fallback ( <NEWLINE> x , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def grid ( self , b = None , which = <STRING> , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if len ( kwargs ) : <NEWLINE> <TAB> b = True <NEWLINE> <UNTAB> which = which . lower ( ) <NEWLINE> gridkw = { <STRING> + item [ <NUMBER> ] : item [ <NUMBER> ] for item in kwargs . items ( ) } <NEWLINE> if which in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> if b is None : <NEWLINE> <TAB> self . _gridOnMinor = not self . _gridOnMinor <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _gridOnMinor = b <NEWLINE> <UNTAB> self . set_tick_params ( which = <STRING> , gridOn = self . _gridOnMinor , <NEWLINE> ** gridkw ) <NEWLINE> <UNTAB> if which in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> if b is None : <NEWLINE> <TAB> self . _gridOnMajor = not self . _gridOnMajor <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _gridOnMajor = b <NEWLINE> <UNTAB> self . set_tick_params ( which = <STRING> , gridOn = self . _gridOnMajor , <NEWLINE> ** gridkw ) <NEWLINE> <UNTAB> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_inputs ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if <STRING> in kwargs : <NEWLINE> <TAB> return [ <NEWLINE> self . _inputs . add ( arg , name = name ) <NEWLINE> for arg , name in zip ( args , kwargs [ <STRING> ] ) <NEWLINE> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return [ self . _inputs . add ( arg ) for arg in args ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _process_unit_info ( self , xdata = None , ydata = None , kwargs = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def _process_single_axis ( data , axis , unit_name , kwargs ) : <NEWLINE> <NEWLINE> <TAB> if axis is None : <NEWLINE> <TAB> return kwargs <NEWLINE> <NEWLINE> <UNTAB> if data is not None : <NEWLINE> <NEWLINE> <TAB> if not axis . have_units ( ) : <NEWLINE> <TAB> axis . update_units ( data ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if kwargs is not None : <NEWLINE> <TAB> units = kwargs . pop ( unit_name , axis . units ) <NEWLINE> if self . name == <STRING> : <NEWLINE> <TAB> polar_units = { <STRING> : <STRING> , <STRING> : <STRING> } <NEWLINE> units = kwargs . pop ( polar_units [ unit_name ] , units ) <NEWLINE> <NEWLINE> <UNTAB> if units != axis . units : <NEWLINE> <TAB> axis . set_units ( units ) <NEWLINE> <NEWLINE> <NEWLINE> if data is not None : <NEWLINE> <TAB> axis . update_units ( data ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return kwargs <NEWLINE> <NEWLINE> <UNTAB> kwargs = _process_single_axis ( xdata , self . xaxis , <STRING> , kwargs ) <NEWLINE> kwargs = _process_single_axis ( ydata , self . yaxis , <STRING> , kwargs ) <NEWLINE> return kwargs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def extended ( self , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> self_to_dict = { self . fields [ i ] : self . types [ i ] for i in range ( self . length ) } <NEWLINE> self_to_dict . update ( kwargs ) <NEWLINE> return ParamsType ( ** self_to_dict ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __array_wrap__ ( self , result , context = None ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( context , tuple ) and len ( context ) == <NUMBER> : <NEWLINE> <TAB> ufunc , args , domain = context <NEWLINE> args = [ getattr ( a , <STRING> , a ) for a in args ] <NEWLINE> with np . errstate ( all = <STRING> ) : <NEWLINE> <TAB> fill_value = ufunc ( self . fill_value , * args [ <NUMBER> : ] ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> fill_value = self . fill_value <NEWLINE> <NEWLINE> <UNTAB> return self . _constructor ( result , index = self . index , <NEWLINE> sparse_index = self . sp_index , <NEWLINE> fill_value = fill_value , <NEWLINE> copy = False ) . __finalize__ ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _get_distinct_objs ( objs ) : <NEWLINE> <TAB> <NEWLINE> ids = set ( ) <NEWLINE> res = [ ] <NEWLINE> for obj in objs : <NEWLINE> <TAB> if not id ( obj ) in ids : <NEWLINE> <TAB> ids . add ( id ( obj ) ) <NEWLINE> res . append ( obj ) <NEWLINE> <UNTAB> <UNTAB> return res <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def to_pydot ( N ) : <NEWLINE> <TAB> <NEWLINE> pydot = _import_pydot ( ) <NEWLINE> <NEWLINE> <NEWLINE> if N . is_directed ( ) : <NEWLINE> <TAB> graph_type = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> graph_type = <STRING> <NEWLINE> <UNTAB> strict = nx . number_of_selfloops ( N ) == <NUMBER> and not N . is_multigraph ( ) <NEWLINE> <NEWLINE> name = N . name <NEWLINE> graph_defaults = N . graph . get ( <STRING> , { } ) <NEWLINE> if name is <STRING> : <NEWLINE> <TAB> P = pydot . Dot ( <STRING> , graph_type = graph_type , strict = strict , <NEWLINE> ** graph_defaults ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> P = pydot . Dot ( <STRING> % name , graph_type = graph_type , strict = strict , <NEWLINE> ** graph_defaults ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> P . set_node_defaults ( ** N . graph [ <STRING> ] ) <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> P . set_edge_defaults ( ** N . graph [ <STRING> ] ) <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> for n , nodedata in N . nodes ( data = True ) : <NEWLINE> <TAB> str_nodedata = dict ( ( k , make_str ( v ) ) for k , v in nodedata . items ( ) ) <NEWLINE> p = pydot . Node ( make_str ( n ) , ** str_nodedata ) <NEWLINE> P . add_node ( p ) <NEWLINE> <NEWLINE> <UNTAB> if N . is_multigraph ( ) : <NEWLINE> <TAB> for u , v , key , edgedata in N . edges ( data = True , keys = True ) : <NEWLINE> <TAB> str_edgedata = dict ( ( k , make_str ( v ) ) for k , v in edgedata . items ( ) <NEWLINE> if k != <STRING> ) <NEWLINE> edge = pydot . Edge ( make_str ( u ) , make_str ( v ) , <NEWLINE> key = make_str ( key ) , ** str_edgedata ) <NEWLINE> P . add_edge ( edge ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for u , v , edgedata in N . edges ( data = True ) : <NEWLINE> <TAB> str_edgedata = dict ( ( k , make_str ( v ) ) for k , v in edgedata . items ( ) ) <NEWLINE> edge = pydot . Edge ( make_str ( u ) , make_str ( v ) , ** str_edgedata ) <NEWLINE> P . add_edge ( edge ) <NEWLINE> <UNTAB> <UNTAB> return P <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def stack ( seq , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> n = len ( seq ) <NEWLINE> ndim = len ( seq [ <NUMBER> ] . shape ) <NEWLINE> if axis < <NUMBER> : <NEWLINE> <TAB> axis = ndim + axis + <NUMBER> <NEWLINE> <UNTAB> if axis > ndim : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % <NEWLINE> ( ndim , axis ) ) <NEWLINE> <UNTAB> if not all ( x . shape == seq [ <NUMBER> ] . shape for x in seq ) : <NEWLINE> <TAB> idx = np . where ( np . asanyarray ( [ x . shape for x in seq ] ) != seq [ <NUMBER> ] . shape ) [ <NUMBER> ] <NEWLINE> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( idx [ <NUMBER> ] , <NEWLINE> seq [ <NUMBER> ] . shape , <NEWLINE> idx [ <NUMBER> ] + <NUMBER> , <NEWLINE> seq [ idx [ <NUMBER> ] ] . shape ) ) <NEWLINE> <NEWLINE> <UNTAB> ind = list ( range ( ndim ) ) <NEWLINE> uc_args = list ( concat ( ( x , ind ) for x in seq ) ) <NEWLINE> _ , seq = unify_chunks ( * uc_args ) <NEWLINE> <NEWLINE> dt = reduce ( np . promote_types , [ a . dtype for a in seq ] ) <NEWLINE> seq = [ x . astype ( dt ) for x in seq ] <NEWLINE> <NEWLINE> assert len ( set ( a . chunks for a in seq ) ) == <NUMBER> <NEWLINE> chunks = ( seq [ <NUMBER> ] . chunks [ : axis ] + ( ( <NUMBER> , ) * n , ) + seq [ <NUMBER> ] . chunks [ axis : ] ) <NEWLINE> <NEWLINE> names = [ a . name for a in seq ] <NEWLINE> name = <STRING> + tokenize ( names , axis ) <NEWLINE> keys = list ( product ( [ name ] , * [ range ( len ( bd ) ) for bd in chunks ] ) ) <NEWLINE> <NEWLINE> inputs = [ ( names [ key [ axis + <NUMBER> ] ] , ) + key [ <NUMBER> : axis + <NUMBER> ] + key [ axis + <NUMBER> : ] <NEWLINE> for key in keys ] <NEWLINE> values = [ ( getitem , inp , ( slice ( None , None , None ) , ) * axis + <NEWLINE> ( None , ) + ( slice ( None , None , None ) , ) * ( ndim - axis ) ) <NEWLINE> for inp in inputs ] <NEWLINE> <NEWLINE> dsk = dict ( zip ( keys , values ) ) <NEWLINE> dsk2 = sharedict . merge ( ( name , dsk ) , * [ a . dask for a in seq ] , <NEWLINE> dependencies = { name : { a . name for a in seq } } ) <NEWLINE> <NEWLINE> return Array ( dsk2 , name , chunks , dtype = dt ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _update ( self , other , only_propagate = True ) : <NEWLINE> <TAB> <NEWLINE> for ls in other . _event_descriptors : <NEWLINE> <TAB> if isinstance ( ls , _EmptyListener ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> getattr ( self , ls . name ) . for_modify ( self ) . _update ( ls , only_propagate = only_propagate ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def library_option ( self , lib ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def configure_gcs ( session , credentials = None , block_cache = None , device = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def configure ( credentials , block_cache ) : <NEWLINE> <TAB> <NEWLINE> if credentials : <NEWLINE> <TAB> if isinstance ( credentials , dict ) : <NEWLINE> <TAB> credentials = json . dumps ( credentials ) <NEWLINE> <UNTAB> placeholder = array_ops . placeholder ( dtypes . string ) <NEWLINE> op = gen_gcs_config_ops . gcs_configure_credentials ( placeholder ) <NEWLINE> session . run ( op , feed_dict = { placeholder : credentials } ) <NEWLINE> <UNTAB> if block_cache : <NEWLINE> <TAB> op = gen_gcs_config_ops . gcs_configure_block_cache ( <NEWLINE> max_cache_size = block_cache . max_bytes , <NEWLINE> block_size = block_cache . block_size , <NEWLINE> max_staleness = block_cache . max_staleness ) <NEWLINE> session . run ( op ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if device : <NEWLINE> <TAB> with ops . device ( device ) : <NEWLINE> <TAB> return configure ( credentials , block_cache ) <NEWLINE> <UNTAB> <UNTAB> return configure ( credentials , block_cache ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def run ( self , fetches , feed_dict = None , options = None , run_metadata = None ) : <NEWLINE> <TAB> <NEWLINE> return self . _sess . run ( fetches , <NEWLINE> feed_dict = feed_dict , <NEWLINE> options = options , <NEWLINE> run_metadata = run_metadata ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def create_operator ( matrix ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> linear_operator = collections . namedtuple ( <NEWLINE> <STRING> , [ <STRING> , <STRING> , <STRING> , <STRING> ] ) <NEWLINE> <NEWLINE> <NEWLINE> shape = matrix . get_shape ( ) <NEWLINE> if shape . is_fully_defined ( ) : <NEWLINE> <TAB> shape = shape . as_list ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> shape = array_ops . shape ( matrix ) <NEWLINE> <UNTAB> return linear_operator ( <NEWLINE> shape = shape , <NEWLINE> dtype = matrix . dtype , <NEWLINE> apply = lambda v : math_ops . matmul ( matrix , v , adjoint_a = False ) , <NEWLINE> apply_adjoint = lambda v : math_ops . matmul ( matrix , v , adjoint_a = True ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dmp_validate ( f , K = None ) : <NEWLINE> <TAB> <NEWLINE> levels = _rec_validate ( f , f , <NUMBER> , K ) <NEWLINE> <NEWLINE> u = levels . pop ( ) <NEWLINE> <NEWLINE> if not levels : <NEWLINE> <TAB> return _rec_strip ( f , u ) , u <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def numel ( x , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return chunk . sum ( np . ones_like ( x ) , ** kwargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def choose ( self , choices , out = None , mode = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return theano . tensor . basic . choose ( self , choices , out = None , mode = <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _run_with_monitors ( session , step , tensors , feed_dict , monitors ) : <NEWLINE> <TAB> <NEWLINE> for monitor in monitors : <NEWLINE> <TAB> tensors += monitor . step_begin ( step ) <NEWLINE> <UNTAB> tensors = list ( set ( tensors ) ) <NEWLINE> <NEWLINE> outputs = session . run ( tensors , feed_dict = feed_dict ) <NEWLINE> outputs = dict ( zip ( <NEWLINE> [ t . name if isinstance ( t , ops . Tensor ) else t for t in tensors ] , <NEWLINE> outputs ) ) <NEWLINE> <NEWLINE> should_stop = False <NEWLINE> for monitor in monitors : <NEWLINE> <TAB> induce_stop = monitor . step_end ( step , outputs ) <NEWLINE> should_stop = should_stop or induce_stop <NEWLINE> <UNTAB> return outputs , should_stop <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def connection_memoize ( key ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> @ util . decorator <NEWLINE> def decorated ( fn , self , connection ) : <NEWLINE> <TAB> connection = connection . connect ( ) <NEWLINE> try : <NEWLINE> <TAB> return connection . info [ key ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> connection . info [ key ] = val = fn ( self , connection ) <NEWLINE> return val <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return decorated <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def check_embedded_msvcr_match_linked ( msver ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> maj = msvc_runtime_major ( ) <NEWLINE> if maj : <NEWLINE> <TAB> if not maj == int ( msver ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <STRING> <STRING> % ( int ( msver ) , maj ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def replace ( self , parameters = _void , return_annotation = _void ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if parameters is _void : <NEWLINE> <TAB> parameters = self . parameters . values ( ) <NEWLINE> <NEWLINE> <UNTAB> if return_annotation is _void : <NEWLINE> <TAB> return_annotation = self . _return_annotation <NEWLINE> <NEWLINE> <UNTAB> return type ( self ) ( parameters , <NEWLINE> return_annotation = return_annotation ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def tostring ( self , encoding ) : <NEWLINE> <TAB> <NEWLINE> if self . kind == <STRING> : <NEWLINE> <TAB> if encoding is not None : <NEWLINE> <TAB> return self . converted <NEWLINE> <UNTAB> return <STRING> . format ( converted = self . converted ) <NEWLINE> <UNTAB> elif self . kind == <STRING> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return repr ( self . converted ) <NEWLINE> <UNTAB> return self . converted <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def unit_circle_righthalf ( cls ) : <NEWLINE> <TAB> <NEWLINE> if cls . _unit_circle_righthalf is None : <NEWLINE> <TAB> MAGIC = <NUMBER> <NEWLINE> SQRTHALF = np . sqrt ( <NUMBER> ) <NEWLINE> MAGIC45 = SQRTHALF * MAGIC <NEWLINE> <NEWLINE> vertices = np . array ( <NEWLINE> [ [ <NUMBER> , - <NUMBER> ] , <NEWLINE> <NEWLINE> [ MAGIC , - <NUMBER> ] , <NEWLINE> [ SQRTHALF - MAGIC45 , - SQRTHALF - MAGIC45 ] , <NEWLINE> [ SQRTHALF , - SQRTHALF ] , <NEWLINE> <NEWLINE> [ SQRTHALF + MAGIC45 , - SQRTHALF + MAGIC45 ] , <NEWLINE> [ <NUMBER> , - MAGIC ] , <NEWLINE> [ <NUMBER> , <NUMBER> ] , <NEWLINE> <NEWLINE> [ <NUMBER> , MAGIC ] , <NEWLINE> [ SQRTHALF + MAGIC45 , SQRTHALF - MAGIC45 ] , <NEWLINE> [ SQRTHALF , SQRTHALF ] , <NEWLINE> <NEWLINE> [ SQRTHALF - MAGIC45 , SQRTHALF + MAGIC45 ] , <NEWLINE> [ MAGIC , <NUMBER> ] , <NEWLINE> [ <NUMBER> , <NUMBER> ] , <NEWLINE> <NEWLINE> [ <NUMBER> , - <NUMBER> ] ] , <NEWLINE> <NEWLINE> float ) <NEWLINE> <NEWLINE> codes = cls . CURVE4 * np . ones ( <NUMBER> ) <NEWLINE> codes [ <NUMBER> ] = cls . MOVETO <NEWLINE> codes [ - <NUMBER> ] = cls . CLOSEPOLY <NEWLINE> <NEWLINE> cls . _unit_circle_righthalf = cls ( vertices , codes , readonly = True ) <NEWLINE> <UNTAB> return cls . _unit_circle_righthalf <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def terminate ( self ) : <NEWLINE> <TAB> <NEWLINE> super ( MultiprocessingBackend , self ) . terminate ( ) <NEWLINE> if self . JOBLIB_SPAWNED_PROCESS in os . environ : <NEWLINE> <TAB> del os . environ [ self . JOBLIB_SPAWNED_PROCESS ] <NEWLINE> <NEWLINE> <UNTAB> self . reset_batch_stats ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def normal ( random_state , size = None , avg = <NUMBER> , std = <NUMBER> , ndim = None , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> avg = tensor . as_tensor_variable ( avg ) <NEWLINE> std = tensor . as_tensor_variable ( std ) <NEWLINE> if dtype is None : <NEWLINE> <TAB> dtype = tensor . scal . upcast ( theano . config . floatX , avg . dtype , std . dtype ) <NEWLINE> <UNTAB> ndim , size , bcast = _infer_ndim_bcast ( ndim , size , avg , std ) <NEWLINE> op = RandomFunction ( <STRING> , <NEWLINE> tensor . TensorType ( dtype = dtype , broadcastable = bcast ) ) <NEWLINE> return op ( random_state , size , avg , std ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def copy ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> new_store = EagerVariableStore ( ) <NEWLINE> for key , var in iteritems ( self . _store . _vars ) : <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> index = var . name . index ( <STRING> ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> stripped_var_name = var . name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> stripped_var_name = var . name [ : index ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> new_var = resource_variable_ops . ResourceVariable ( <NEWLINE> var . read_value ( ) , <NEWLINE> name = stripped_var_name , <NEWLINE> trainable = var . trainable ) <NEWLINE> new_store . _store . _vars [ key ] = new_var <NEWLINE> <UNTAB> return new_store <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_masked ( x ) : <NEWLINE> <TAB> <NEWLINE> m = getmask ( x ) <NEWLINE> if m is nomask : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> elif m . any ( ) : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> return False <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def square ( x ) : <NEWLINE> <TAB> <NEWLINE> return tf . square ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def row_swap ( self , i , j ) : <NEWLINE> <TAB> <NEWLINE> for k in range ( <NUMBER> , self . cols ) : <NEWLINE> <TAB> self [ i , k ] , self [ j , k ] = self [ j , k ] , self [ i , k ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , data = None ) : <NEWLINE> <TAB> <NEWLINE> self . _mapping = OrderedDict ( ) <NEWLINE> self . _counter = itertools . count ( ) <NEWLINE> if data is not None : <NEWLINE> <TAB> self . update ( data ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def read_full ( self ) : <NEWLINE> <TAB> <NEWLINE> reader = self . _get_reader ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> filename_queue , epoch_limiter = self . _get_filename_queue ( epoch_limit = <NUMBER> ) <NEWLINE> epoch_reset_op = state_ops . assign ( epoch_limiter , <NUMBER> ) <NEWLINE> with ops . control_dependencies ( [ epoch_reset_op ] ) : <NEWLINE> <TAB> first_key , first_value = reader . read_up_to ( filename_queue , <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> def _while_condition ( <NEWLINE> current_key , current_value , current_index , collected_records ) : <NEWLINE> <TAB> del current_value , current_index , collected_records <NEWLINE> return math_ops . not_equal ( array_ops . squeeze ( current_key , axis = <NUMBER> ) , <NEWLINE> array_ops . squeeze ( first_key , axis = <NUMBER> ) ) <NEWLINE> <NEWLINE> <UNTAB> def _while_body ( <NEWLINE> current_key , current_value , current_index , collected_records ) : <NEWLINE> <TAB> del current_key <NEWLINE> new_key , new_value = reader . read_up_to ( filename_queue , <NUMBER> ) <NEWLINE> new_key . set_shape ( [ <NUMBER> ] ) <NEWLINE> new_value . set_shape ( [ <NUMBER> ] ) <NEWLINE> return ( new_key , <NEWLINE> new_value , <NEWLINE> current_index + <NUMBER> , <NEWLINE> collected_records . write ( current_index , current_value ) ) <NEWLINE> <UNTAB> _ , _ , _ , records_ta = control_flow_ops . while_loop ( <NEWLINE> _while_condition , <NEWLINE> _while_body , <NEWLINE> [ constant_op . constant ( [ <STRING> ] ) , first_value , <NEWLINE> <NUMBER> , <NEWLINE> tensor_array_ops . TensorArray ( <NEWLINE> dtype = dtypes . string , size = <NUMBER> , dynamic_size = True ) ] ) <NEWLINE> records = records_ta . concat ( ) <NEWLINE> <NEWLINE> <NEWLINE> with ops . control_dependencies ( [ records ] ) : <NEWLINE> <TAB> reader_reset_op = reader . reset ( ) <NEWLINE> <UNTAB> with ops . control_dependencies ( [ reader_reset_op ] ) : <NEWLINE> <TAB> records = array_ops . identity ( records ) <NEWLINE> <UNTAB> return self . _process_records ( records ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def is_built_with_cuda ( ) : <NEWLINE> <TAB> <NEWLINE> return _test_util . IsGoogleCudaEnabled ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def row ( self , i ) : <NEWLINE> <TAB> <NEWLINE> return self [ i , : ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _finish_log_prob_for_one_fiber ( self , y , x , ildj , event_ndims ) : <NEWLINE> <TAB> <NEWLINE> x = self . _maybe_rotate_dims ( x , rotate_right = True ) <NEWLINE> log_prob = self . distribution . log_prob ( x ) <NEWLINE> if self . _is_maybe_event_override : <NEWLINE> <TAB> log_prob = math_ops . reduce_sum ( log_prob , self . _reduce_event_indices ) <NEWLINE> <UNTAB> log_prob += math_ops . cast ( ildj , log_prob . dtype ) <NEWLINE> if self . _is_maybe_event_override and isinstance ( event_ndims , int ) : <NEWLINE> <TAB> log_prob . set_shape ( <NEWLINE> array_ops . broadcast_static_shape ( <NEWLINE> y . get_shape ( ) . with_rank_at_least ( <NUMBER> ) [ : - event_ndims ] , <NEWLINE> self . batch_shape ) ) <NEWLINE> <UNTAB> return log_prob <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def capture_stdout ( f ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> @ wraps ( f ) <NEWLINE> def wrapper ( * args , ** kwargs ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> sys . stdout = StringIO ( ) <NEWLINE> f ( * args , ** kwargs ) <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> sys . stdout = sys . __stdout__ <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return wrapper <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def compute_mask ( self , inputs , mask = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> input_shape = K . int_shape ( inputs ) <NEWLINE> if input_shape [ <NUMBER> ] : <NEWLINE> <NEWLINE> <TAB> return mask <NEWLINE> <UNTAB> inner_mask = mask <NEWLINE> if inner_mask is not None : <NEWLINE> <TAB> inner_mask_shape = self . _get_shape_tuple ( ( - <NUMBER> , ) , mask , <NUMBER> ) <NEWLINE> inner_mask = K . reshape ( inner_mask , inner_mask_shape ) <NEWLINE> <UNTAB> input_uid = generic_utils . object_list_uid ( inputs ) <NEWLINE> inner_inputs = self . _input_map . get ( input_uid , inputs ) <NEWLINE> output_mask = self . layer . compute_mask ( inner_inputs , inner_mask ) <NEWLINE> if output_mask is None : <NEWLINE> <TAB> if mask is None : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> output_mask = mask <NEWLINE> for _ in range ( <NUMBER> , len ( K . int_shape ( mask ) ) ) : <NEWLINE> <TAB> output_mask = K . any ( output_mask , axis = - <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> input_length = input_shape [ <NUMBER> ] <NEWLINE> if not input_length : <NEWLINE> <TAB> input_length = K . shape ( inputs ) [ <NUMBER> ] <NEWLINE> <UNTAB> output_mask_int_shape = K . int_shape ( output_mask ) <NEWLINE> if output_mask_int_shape is None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if mask is not None : <NEWLINE> <TAB> output_mask_int_shape = K . int_shape ( mask ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> output_mask_int_shape = K . compute_output_shape ( input_shape ) [ : - <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> output_mask_shape = self . _get_shape_tuple ( <NEWLINE> ( - <NUMBER> , input_length ) , output_mask , <NUMBER> , output_mask_int_shape [ <NUMBER> : ] ) <NEWLINE> output_mask = K . reshape ( output_mask , output_mask_shape ) <NEWLINE> <UNTAB> return output_mask <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def correspond_on_equivalents ( self , column , equivalents ) : <NEWLINE> <TAB> <NEWLINE> col = self . corresponding_column ( column , require_embedded = True ) <NEWLINE> if col is None and col in equivalents : <NEWLINE> <TAB> for equiv in equivalents [ col ] : <NEWLINE> <TAB> nc = self . corresponding_column ( equiv , require_embedded = True ) <NEWLINE> if nc : <NEWLINE> <TAB> return nc <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return col <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_copy ( f ) : <NEWLINE> <TAB> <NEWLINE> return list ( f ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_quad_residue ( a , p ) : <NEWLINE> <TAB> <NEWLINE> a , p = as_int ( a ) , as_int ( p ) <NEWLINE> if p < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if a >= p or a < <NUMBER> : <NEWLINE> <TAB> a = a % p <NEWLINE> <UNTAB> if a < <NUMBER> or p < <NUMBER> : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> if not isprime ( p ) : <NEWLINE> <TAB> if p % <NUMBER> and jacobi_symbol ( a , p ) == - <NUMBER> : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> r = sqrt_mod ( a , p ) <NEWLINE> if r is None : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return pow ( a , ( p - <NUMBER> ) // <NUMBER> , p ) == <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def Dwm ( n ) : <NEWLINE> <TAB> <NEWLINE> return Cm ( n , [ <NUMBER> , <NUMBER> ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rgb2yiq ( rgb ) : <NEWLINE> <TAB> <NEWLINE> return _convert ( yiq_from_rgb , rgb ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def mathml ( expr , printer = <STRING> , ** settings ) : <NEWLINE> <TAB> <NEWLINE> if printer == <STRING> : <NEWLINE> <TAB> return MathMLPresentationPrinter ( settings ) . doprint ( expr ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return MathMLContentPrinter ( settings ) . doprint ( expr ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def open_file ( path_arg , mode = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> @ decorator <NEWLINE> def _open_file ( func_to_be_decorated , * args , ** kwargs ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> path = args [ path_arg ] <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> path = kwargs [ path_arg ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise nx . NetworkXError ( msg . format ( path_arg ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> is_kwarg = True <NEWLINE> <UNTAB> <UNTAB> except IndexError : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise nx . NetworkXError ( msg ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> is_kwarg = False <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if is_string_like ( path ) : <NEWLINE> <TAB> ext = splitext ( path ) [ <NUMBER> ] <NEWLINE> fobj = _dispatch_dict [ ext ] ( path , mode = mode ) <NEWLINE> close_fobj = True <NEWLINE> <UNTAB> elif hasattr ( path , <STRING> ) : <NEWLINE> <NEWLINE> <TAB> fobj = path <NEWLINE> close_fobj = False <NEWLINE> <UNTAB> elif Path is not None and isinstance ( path , Path ) : <NEWLINE> <NEWLINE> <TAB> fobj = _dispatch_dict [ path . suffix ] ( str ( path ) , mode = mode ) <NEWLINE> close_fobj = True <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> fobj = path <NEWLINE> close_fobj = False <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if is_kwarg : <NEWLINE> <TAB> new_args = args <NEWLINE> kwargs [ path_arg ] = fobj <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> new_args = list ( args ) <NEWLINE> new_args [ path_arg ] = fobj <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> result = func_to_be_decorated ( * new_args , ** kwargs ) <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> if close_fobj : <NEWLINE> <TAB> fobj . close ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return result <NEWLINE> <NEWLINE> <UNTAB> return _open_file <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def urljoin ( base , url , allow_fragments = True ) : <NEWLINE> <TAB> <NEWLINE> if not base : <NEWLINE> <TAB> return url <NEWLINE> <UNTAB> if not url : <NEWLINE> <TAB> return base <NEWLINE> <NEWLINE> <UNTAB> base , url , _coerce_result = _coerce_args ( base , url ) <NEWLINE> bscheme , bnetloc , bpath , bparams , bquery , bfragment = urlparse ( base , <STRING> , allow_fragments ) <NEWLINE> scheme , netloc , path , params , query , fragment = urlparse ( url , bscheme , allow_fragments ) <NEWLINE> <NEWLINE> if scheme != bscheme or scheme not in uses_relative : <NEWLINE> <TAB> return _coerce_result ( url ) <NEWLINE> <UNTAB> if scheme in uses_netloc : <NEWLINE> <TAB> if netloc : <NEWLINE> <TAB> return _coerce_result ( urlunparse ( ( scheme , netloc , path , <NEWLINE> params , query , fragment ) ) ) <NEWLINE> <UNTAB> netloc = bnetloc <NEWLINE> <NEWLINE> <UNTAB> if not path and not params : <NEWLINE> <TAB> path = bpath <NEWLINE> params = bparams <NEWLINE> if not query : <NEWLINE> <TAB> query = bquery <NEWLINE> <UNTAB> return _coerce_result ( urlunparse ( ( scheme , netloc , path , <NEWLINE> params , query , fragment ) ) ) <NEWLINE> <NEWLINE> <UNTAB> base_parts = bpath . split ( <STRING> ) <NEWLINE> if base_parts [ - <NUMBER> ] != <STRING> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> del base_parts [ - <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if path [ : <NUMBER> ] == <STRING> : <NEWLINE> <TAB> segments = path . split ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> segments = base_parts + path . split ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> segments [ <NUMBER> : - <NUMBER> ] = filter ( None , segments [ <NUMBER> : - <NUMBER> ] ) <NEWLINE> <NEWLINE> <UNTAB> resolved_path = [ ] <NEWLINE> <NEWLINE> for seg in segments : <NEWLINE> <TAB> if seg == <STRING> : <NEWLINE> <TAB> try : <NEWLINE> <TAB> resolved_path . pop ( ) <NEWLINE> <UNTAB> except IndexError : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> elif seg == <STRING> : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> resolved_path . append ( seg ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if segments [ - <NUMBER> ] in ( <STRING> , <STRING> ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> resolved_path . append ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return _coerce_result ( urlunparse ( ( scheme , netloc , <STRING> . join ( <NEWLINE> resolved_path ) or <STRING> , params , query , fragment ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _get_frame_op_default_axis ( name ) : <NEWLINE> <TAB> <NEWLINE> if name . replace ( <STRING> , <STRING> ) in [ <STRING> , <STRING> , <STRING> ] : <NEWLINE> <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> elif name . startswith ( <STRING> ) : <NEWLINE> <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def notna ( obj ) : <NEWLINE> <TAB> <NEWLINE> res = isna ( obj ) <NEWLINE> if is_scalar ( res ) : <NEWLINE> <TAB> return not res <NEWLINE> <UNTAB> return ~ res <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , byweekday = <NUMBER> , interval = <NUMBER> , tz = None ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( byweekday , np . ndarray ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> [ x . item ( ) for x in byweekday . astype ( int ) ] <NEWLINE> <NEWLINE> <UNTAB> rule = rrulewrapper ( DAILY , byweekday = byweekday , <NEWLINE> interval = interval , ** self . hms0d ) <NEWLINE> RRuleLocator . __init__ ( self , rule , tz ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _verify_setup ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if not self . _is_chief : <NEWLINE> <TAB> for op in self . _graph . get_operations ( ) : <NEWLINE> <TAB> if op . type in [ <STRING> , <STRING> ] and not op . device : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % op ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def swapcase ( a ) : <NEWLINE> <TAB> <NEWLINE> a_arr = numpy . asarray ( a ) <NEWLINE> return _vec_string ( a_arr , a_arr . dtype , <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def max_pool3d_eager_fallback ( input , ksize , strides , padding , data_format = <STRING> , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> if not isinstance ( ksize , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ksize ) <NEWLINE> <UNTAB> ksize = [ _execute . make_int ( _i , <STRING> ) for _i in ksize ] <NEWLINE> if not isinstance ( strides , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % strides ) <NEWLINE> <UNTAB> strides = [ _execute . make_int ( _i , <STRING> ) for _i in strides ] <NEWLINE> padding = _execute . make_str ( padding , <STRING> ) <NEWLINE> if data_format is None : <NEWLINE> <TAB> data_format = <STRING> <NEWLINE> <UNTAB> data_format = _execute . make_str ( data_format , <STRING> ) <NEWLINE> _attr_T , ( input , ) = _execute . args_to_matching_eager ( [ input ] , _ctx ) <NEWLINE> _inputs_flat = [ input ] <NEWLINE> _attrs = ( <STRING> , ksize , <STRING> , strides , <STRING> , padding , <NEWLINE> <STRING> , data_format , <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _shallow_annotate ( element , annotations ) : <NEWLINE> <TAB> <NEWLINE> element = element . _annotate ( annotations ) <NEWLINE> element . _copy_internals ( ) <NEWLINE> return element <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> def connected_components ( G ) : <NEWLINE> <TAB> <NEWLINE> seen = set ( ) <NEWLINE> for v in G : <NEWLINE> <TAB> if v not in seen : <NEWLINE> <TAB> c = set ( _plain_bfs ( G , v ) ) <NEWLINE> yield c <NEWLINE> seen . update ( c ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ allow_rasterization <NEWLINE> def draw ( self , renderer = None , inframe = False ) : <NEWLINE> <TAB> <NEWLINE> if renderer is None : <NEWLINE> <TAB> renderer = self . _cachedRenderer <NEWLINE> <NEWLINE> <UNTAB> if renderer is None : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> if not self . get_visible ( ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> renderer . open_group ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> self . _stale = True <NEWLINE> locator = self . get_axes_locator ( ) <NEWLINE> if locator : <NEWLINE> <TAB> pos = locator ( self , renderer ) <NEWLINE> self . apply_aspect ( pos ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . apply_aspect ( ) <NEWLINE> <NEWLINE> <UNTAB> artists = self . get_children ( ) <NEWLINE> artists . remove ( self . patch ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if not ( self . axison and self . _frameon ) : <NEWLINE> <TAB> for spine in self . spines . values ( ) : <NEWLINE> <TAB> artists . remove ( spine ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . _update_title_position ( renderer ) <NEWLINE> <NEWLINE> if not self . axison or inframe : <NEWLINE> <TAB> for _axis in self . _get_axis_list ( ) : <NEWLINE> <TAB> artists . remove ( _axis ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if inframe : <NEWLINE> <TAB> artists . remove ( self . title ) <NEWLINE> artists . remove ( self . _left_title ) <NEWLINE> artists . remove ( self . _right_title ) <NEWLINE> <NEWLINE> <UNTAB> if not self . figure . canvas . is_saving ( ) : <NEWLINE> <TAB> artists = [ a for a in artists <NEWLINE> if not a . get_animated ( ) or a in self . images ] <NEWLINE> <UNTAB> artists = sorted ( artists , key = attrgetter ( <STRING> ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> rasterization_zorder = self . _rasterization_zorder <NEWLINE> <NEWLINE> if ( rasterization_zorder is not None and <NEWLINE> artists and artists [ <NUMBER> ] . zorder < rasterization_zorder ) : <NEWLINE> <TAB> renderer . start_rasterizing ( ) <NEWLINE> artists_rasterized = [ a for a in artists <NEWLINE> if a . zorder < rasterization_zorder ] <NEWLINE> artists = [ a for a in artists <NEWLINE> if a . zorder >= rasterization_zorder ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> artists_rasterized = [ ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . axison and self . _frameon : <NEWLINE> <TAB> self . patch . draw ( renderer ) <NEWLINE> <NEWLINE> <UNTAB> if artists_rasterized : <NEWLINE> <TAB> for a in artists_rasterized : <NEWLINE> <TAB> a . draw ( renderer ) <NEWLINE> <UNTAB> renderer . stop_rasterizing ( ) <NEWLINE> <NEWLINE> <UNTAB> mimage . _draw_list_compositing_images ( renderer , self , artists ) <NEWLINE> <NEWLINE> renderer . close_group ( <STRING> ) <NEWLINE> self . _cachedRenderer = renderer <NEWLINE> self . stale = False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def scharr_h ( image , mask = None ) : <NEWLINE> <TAB> <NEWLINE> assert_nD ( image , <NUMBER> ) <NEWLINE> image = img_as_float ( image ) <NEWLINE> result = convolve ( image , HSCHARR_WEIGHTS ) <NEWLINE> return _mask_filter_result ( result , mask ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_shape ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . shape <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_nodes_from ( self , nodes_for_adding , ** attr ) : <NEWLINE> <TAB> <NEWLINE> for n in nodes_for_adding : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> if n not in self . _node : <NEWLINE> <TAB> self . _adj [ n ] = self . adjlist_inner_dict_factory ( ) <NEWLINE> self . _node [ n ] = attr . copy ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _node [ n ] . update ( attr ) <NEWLINE> <UNTAB> <UNTAB> except TypeError : <NEWLINE> <TAB> nn , ndict = n <NEWLINE> if nn not in self . _node : <NEWLINE> <TAB> self . _adj [ nn ] = self . adjlist_inner_dict_factory ( ) <NEWLINE> newdict = attr . copy ( ) <NEWLINE> newdict . update ( ndict ) <NEWLINE> self . _node [ nn ] = newdict <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> olddict = self . _node [ nn ] <NEWLINE> olddict . update ( attr ) <NEWLINE> olddict . update ( ndict ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def check_gcc_function_attribute ( cmd , attribute , name ) : <NEWLINE> <TAB> <NEWLINE> cmd . _check_compiler ( ) <NEWLINE> body = " " " 
 # p r a g m a   G C C   d i a g n o s t i c   e r r o r   " - W a t t r i b u t e s " 
 # p r a g m a   c l a n g   d i a g n o s t i c   e r r o r   " - W a t t r i b u t e s " 
 
 i n t   % s   % s ( v o i d * ) ; 
 
 i n t 
 m a i n ( ) 
 { 
         r e t u r n   0 ; 
 } 
 " " " % ( attribute , name ) <NEWLINE> return cmd . try_compile ( body , None , None ) != <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def amax ( a , axis = None , out = None , keepdims = np . _NoValue ) : <NEWLINE> <TAB> <NEWLINE> kwargs = { } <NEWLINE> if keepdims is not np . _NoValue : <NEWLINE> <TAB> kwargs [ <STRING> ] = keepdims <NEWLINE> <NEWLINE> <UNTAB> if type ( a ) is not mu . ndarray : <NEWLINE> <TAB> try : <NEWLINE> <TAB> amax = a . max <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return amax ( axis = axis , out = out , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return _methods . _amax ( a , axis = axis , <NEWLINE> out = out , ** kwargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def fdiff ( self , argindex = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if argindex == <NUMBER> : <NEWLINE> <TAB> return sign ( self . args [ <NUMBER> ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ArgumentIndexError ( self , argindex ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __ne__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return self . _comparison ( other , operator . ne ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pack ( o , stream , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> packer = Packer ( ** kwargs ) <NEWLINE> stream . write ( packer . pack ( o ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def compressed ( x ) : <NEWLINE> <TAB> <NEWLINE> return asanyarray ( x ) . compressed ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def winfo_vrootx ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . tk . getint ( <NEWLINE> self . tk . call ( <STRING> , <STRING> , self . _w ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def infer_objects ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> return self . _constructor ( <NEWLINE> self . _data . convert ( datetime = True , numeric = False , <NEWLINE> timedelta = True , coerce = False , <NEWLINE> copy = True ) ) . __finalize__ ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_full_log_prob ( self , input , head_output ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> out = input . new_empty ( ( head_output . size ( <NUMBER> ) , self . n_classes ) ) <NEWLINE> head_logprob = log_softmax ( head_output , dim = <NUMBER> ) <NEWLINE> <NEWLINE> out [ : , : self . shortlist_size ] = head_logprob [ : , : self . shortlist_size ] <NEWLINE> <NEWLINE> for i , ( start_idx , stop_idx ) in enumerate ( zip ( self . cutoffs , self . cutoffs [ <NUMBER> : ] ) ) : <NEWLINE> <TAB> cluster_output = self . tail [ i ] ( input ) <NEWLINE> cluster_logprob = log_softmax ( cluster_output , dim = <NUMBER> ) <NEWLINE> output_logprob = cluster_logprob + head_logprob [ : , self . shortlist_size + i ] . unsqueeze ( <NUMBER> ) <NEWLINE> <NEWLINE> out [ : , start_idx : stop_idx ] = output_logprob <NEWLINE> <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _get_jacobian ( tris_pts ) : <NEWLINE> <TAB> <NEWLINE> a = np . array ( tris_pts [ : , <NUMBER> , : ] - tris_pts [ : , <NUMBER> , : ] ) <NEWLINE> b = np . array ( tris_pts [ : , <NUMBER> , : ] - tris_pts [ : , <NUMBER> , : ] ) <NEWLINE> J = _to_matrix_vectorized ( [ [ a [ : , <NUMBER> ] , a [ : , <NUMBER> ] ] , <NEWLINE> [ b [ : , <NUMBER> ] , b [ : , <NUMBER> ] ] ] ) <NEWLINE> return J <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_ideep_available ( ) : <NEWLINE> <TAB> <NEWLINE> return _ideep_version is not None and _ideep_version == <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_ZZ_gmpy ( K1 , a , K0 ) : <NEWLINE> <TAB> <NEWLINE> return GMPYRational ( a ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ estimator_export ( <STRING> ) <NEWLINE> def train_and_evaluate ( estimator , train_spec , eval_spec ) : <NEWLINE> <TAB> <NEWLINE> _assert_eval_spec ( eval_spec ) <NEWLINE> <NEWLINE> executor = _TrainingExecutor ( <NEWLINE> estimator = estimator , train_spec = train_spec , eval_spec = eval_spec ) <NEWLINE> config = estimator . config <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if distribute_coordinator_training . should_run_distribute_coordinator ( config ) : <NEWLINE> <TAB> logging . info ( <STRING> ) <NEWLINE> distribute_coordinator_training . train_and_evaluate ( <NEWLINE> estimator , train_spec , eval_spec , _TrainingExecutor ) <NEWLINE> return <NEWLINE> <NEWLINE> <UNTAB> if ( config . task_type == run_config_lib . TaskType . EVALUATOR and <NEWLINE> config . task_id > <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( config . task_id ) ) <NEWLINE> <NEWLINE> <UNTAB> return executor . run ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def roberts ( image , mask = None ) : <NEWLINE> <TAB> <NEWLINE> assert_nD ( image , <NUMBER> ) <NEWLINE> out = np . sqrt ( roberts_pos_diag ( image , mask ) ** <NUMBER> + <NEWLINE> roberts_neg_diag ( image , mask ) ** <NUMBER> ) <NEWLINE> out /= np . sqrt ( <NUMBER> ) <NEWLINE> return out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ contextlib . contextmanager <NEWLINE> def open_file_cm ( path_or_file , mode = <STRING> , encoding = None ) : <NEWLINE> <TAB> <NEWLINE> fh , opened = to_filehandle ( path_or_file , mode , True , encoding ) <NEWLINE> if opened : <NEWLINE> <TAB> with fh : <NEWLINE> <TAB> yield fh <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> yield fh <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def serialize ( self ) : <NEWLINE> <TAB> <NEWLINE> if not self . serializer : <NEWLINE> <TAB> raise _exceptions . Error ( <NEWLINE> <STRING> % self . name ) <NEWLINE> <UNTAB> if self . value is None : <NEWLINE> <TAB> return <STRING> <NEWLINE> <NEWLINE> <UNTAB> s = <STRING> <NEWLINE> <NEWLINE> multi_value = self . value <NEWLINE> <NEWLINE> for self . value in multi_value : <NEWLINE> <TAB> if s : s += <STRING> <NEWLINE> s += Flag . serialize ( self ) <NEWLINE> <NEWLINE> <UNTAB> self . value = multi_value <NEWLINE> <NEWLINE> return s <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __rsub__ ( self , a ) : <NEWLINE> <TAB> <NEWLINE> return a . __sub__ ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _refine_complexes ( cls , complexes ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for i , ( u , f , k ) in enumerate ( complexes ) : <NEWLINE> <TAB> for j , ( v , g , m ) in enumerate ( complexes [ i + <NUMBER> : ] ) : <NEWLINE> <TAB> u , v = u . refine_disjoint ( v ) <NEWLINE> complexes [ i + j + <NUMBER> ] = ( v , g , m ) <NEWLINE> <NEWLINE> <UNTAB> complexes [ i ] = ( u , f , k ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> complexes = cls . _refine_imaginary ( complexes ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for i , ( u , f , k ) in enumerate ( complexes ) : <NEWLINE> <TAB> while u . ay * u . by <= <NUMBER> : <NEWLINE> <TAB> u = u . refine ( ) <NEWLINE> <UNTAB> complexes [ i ] = u , f , k <NEWLINE> <UNTAB> return complexes <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_metadata ( self , metadata ) : <NEWLINE> <TAB> <NEWLINE> if metadata is not None : <NEWLINE> <TAB> metadata = np . array ( metadata , copy = False ) . ravel ( ) <NEWLINE> <UNTAB> self . metadata = metadata <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def register_cmap ( name = None , cmap = None , data = None , lut = None ) : <NEWLINE> <TAB> <NEWLINE> if name is None : <NEWLINE> <TAB> try : <NEWLINE> <TAB> name = cmap . name <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not isinstance ( name , str ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( cmap , colors . Colormap ) : <NEWLINE> <TAB> cmap_d [ name ] = cmap <NEWLINE> return <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if lut is None : <NEWLINE> <TAB> lut = mpl . rcParams [ <STRING> ] <NEWLINE> <UNTAB> cmap = colors . LinearSegmentedColormap ( name , data , lut ) <NEWLINE> cmap_d [ name ] = cmap <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def read_cz_lsm_time_stamps ( fh ) : <NEWLINE> <TAB> <NEWLINE> size , count = struct . unpack ( <STRING> , fh . read ( <NUMBER> ) ) <NEWLINE> if size != ( <NUMBER> + <NUMBER> * count ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return fh . read_array ( <STRING> , count = count ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_yaxis_text2_transform ( self , pad_points ) : <NEWLINE> <TAB> <NEWLINE> labels_align = matplotlib . rcParams [ <STRING> ] <NEWLINE> <NEWLINE> return ( self . get_yaxis_transform ( which = <STRING> ) + <NEWLINE> mtransforms . ScaledTranslation ( pad_points / <NUMBER> , <NUMBER> , <NEWLINE> self . figure . dpi_scale_trans ) , <NEWLINE> labels_align , <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def avg_pool ( value , ksize , strides , padding , data_format = <STRING> , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if not isinstance ( ksize , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ksize ) <NEWLINE> <UNTAB> ksize = [ _execute . make_int ( _i , <STRING> ) for _i in ksize ] <NEWLINE> if not isinstance ( strides , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % strides ) <NEWLINE> <UNTAB> strides = [ _execute . make_int ( _i , <STRING> ) for _i in strides ] <NEWLINE> padding = _execute . make_str ( padding , <STRING> ) <NEWLINE> if data_format is None : <NEWLINE> <TAB> data_format = <STRING> <NEWLINE> <UNTAB> data_format = _execute . make_str ( data_format , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , value = value , ksize = ksize , strides = strides , padding = padding , <NEWLINE> data_format = data_format , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) , <NEWLINE> <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , value , <STRING> , ksize , <NEWLINE> <STRING> , strides , <STRING> , padding , <STRING> , data_format ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return avg_pool_eager_fallback ( <NEWLINE> value , ksize = ksize , strides = strides , padding = padding , <NEWLINE> data_format = data_format , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def dimshuffle ( self , * pattern ) : <NEWLINE> <TAB> <NEWLINE> if ( len ( pattern ) == <NUMBER> ) and ( isinstance ( pattern [ <NUMBER> ] , ( list , tuple ) ) ) : <NEWLINE> <TAB> pattern = pattern [ <NUMBER> ] <NEWLINE> <UNTAB> op = theano . tensor . basic . DimShuffle ( list ( self . type . broadcastable ) , <NEWLINE> pattern ) <NEWLINE> return op ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def reset_cache ( cls ) : <NEWLINE> <TAB> <NEWLINE> cls . _cache = { } <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_store ( path , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> , <NEWLINE> FutureWarning , <NEWLINE> stacklevel = <NUMBER> ) <NEWLINE> <NEWLINE> return HDFStore ( path , ** kwargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_ZZ_python ( K1 , a , K0 = None ) : <NEWLINE> <TAB> <NEWLINE> return K1 . dtype ( K1 . dom . from_ZZ_python ( a , K0 ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def primitive_root ( p ) : <NEWLINE> <TAB> <NEWLINE> p = as_int ( p ) <NEWLINE> if p < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if p <= <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> f = factorint ( p ) <NEWLINE> if len ( f ) > <NUMBER> : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> if len ( f ) == <NUMBER> : <NEWLINE> <TAB> if <NUMBER> not in f or f [ <NUMBER> ] > <NUMBER> : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for p1 , e1 in f . items ( ) : <NEWLINE> <TAB> if p1 != <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> i = <NUMBER> <NEWLINE> while i < p : <NEWLINE> <TAB> i += <NUMBER> <NEWLINE> if i % p1 == <NUMBER> : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> if is_primitive_root ( i , p ) : <NEWLINE> <TAB> return i <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if <NUMBER> in f : <NEWLINE> <TAB> if p == <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> return None <NEWLINE> <UNTAB> p1 , n = list ( f . items ( ) ) [ <NUMBER> ] <NEWLINE> if n > <NUMBER> : <NEWLINE> <NEWLINE> <TAB> g = primitive_root ( p1 ) <NEWLINE> if is_primitive_root ( g , p1 ** <NUMBER> ) : <NEWLINE> <TAB> return g <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for i in range ( <NUMBER> , g + p1 + <NUMBER> ) : <NEWLINE> <TAB> if igcd ( i , p ) == <NUMBER> and is_primitive_root ( i , p ) : <NEWLINE> <TAB> return i <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> return next ( _primitive_root_prime_iter ( p ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def partition ( self , sep ) : <NEWLINE> <TAB> <NEWLINE> return asarray ( partition ( self , sep ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def clip_grad_norm_ ( parameters , max_norm , norm_type = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( parameters , torch . Tensor ) : <NEWLINE> <TAB> parameters = [ parameters ] <NEWLINE> <UNTAB> parameters = list ( filter ( lambda p : p . grad is not None , parameters ) ) <NEWLINE> max_norm = float ( max_norm ) <NEWLINE> norm_type = float ( norm_type ) <NEWLINE> if norm_type == inf : <NEWLINE> <TAB> total_norm = max ( p . grad . data . abs ( ) . max ( ) for p in parameters ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> total_norm = <NUMBER> <NEWLINE> for p in parameters : <NEWLINE> <TAB> param_norm = p . grad . data . norm ( norm_type ) <NEWLINE> total_norm += param_norm . item ( ) ** norm_type <NEWLINE> <UNTAB> total_norm = total_norm ** ( <NUMBER> / norm_type ) <NEWLINE> <UNTAB> clip_coef = max_norm / ( total_norm + <NUMBER> ) <NEWLINE> if clip_coef < <NUMBER> : <NEWLINE> <TAB> for p in parameters : <NEWLINE> <TAB> p . grad . data . mul_ ( clip_coef ) <NEWLINE> <UNTAB> <UNTAB> return total_norm <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def deprecated_arg_values ( date , instructions , warn_once = True , <NEWLINE> ** deprecated_kwargs ) : <NEWLINE> <TAB> <NEWLINE> _validate_deprecation_args ( date , instructions ) <NEWLINE> if not deprecated_kwargs : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> def deprecated_wrapper ( func ) : <NEWLINE> <TAB> <NEWLINE> decorator_utils . validate_callable ( func , <STRING> ) <NEWLINE> @ functools . wraps ( func ) <NEWLINE> def new_func ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if _PRINT_DEPRECATION_WARNINGS : <NEWLINE> <TAB> named_args = tf_inspect . getcallargs ( func , * args , ** kwargs ) <NEWLINE> for arg_name , arg_value in deprecated_kwargs . items ( ) : <NEWLINE> <TAB> if arg_name in named_args and named_args [ arg_name ] == arg_value : <NEWLINE> <TAB> if ( func , arg_name ) not in _PRINTED_WARNING : <NEWLINE> <TAB> if warn_once : <NEWLINE> <TAB> _PRINTED_WARNING [ ( func , arg_name ) ] = True <NEWLINE> <UNTAB> logging . warning ( <NEWLINE> <STRING> <NEWLINE> <STRING> , <NEWLINE> _call_location ( ) , decorator_utils . get_qualified_name ( func ) , <NEWLINE> func . __module__ , arg_name , arg_value , <STRING> <NEWLINE> if date is None else ( <STRING> % date ) , instructions ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> return func ( * args , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> doc = _add_deprecated_arg_value_notice_to_docstring ( <NEWLINE> func . __doc__ , date , instructions , deprecated_kwargs ) <NEWLINE> return tf_decorator . make_decorator ( func , new_func , <STRING> , doc ) <NEWLINE> <NEWLINE> <UNTAB> return deprecated_wrapper <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def reduce ( self , target , axis = <NUMBER> , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> tclass = get_masked_subclass ( target ) <NEWLINE> m = getmask ( target ) <NEWLINE> t = filled ( target , self . filly ) <NEWLINE> if t . shape == ( ) : <NEWLINE> <TAB> t = t . reshape ( <NUMBER> ) <NEWLINE> if m is not nomask : <NEWLINE> <TAB> m = make_mask ( m , copy = <NUMBER> ) <NEWLINE> m . shape = ( <NUMBER> , ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if m is nomask : <NEWLINE> <TAB> tr = self . f . reduce ( t , axis ) <NEWLINE> mr = nomask <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> tr = self . f . reduce ( t , axis , dtype = dtype or t . dtype ) <NEWLINE> mr = umath . logical_and . reduce ( m , axis ) <NEWLINE> <NEWLINE> <UNTAB> if not tr . shape : <NEWLINE> <TAB> if mr : <NEWLINE> <TAB> return masked <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return tr <NEWLINE> <UNTAB> <UNTAB> masked_tr = tr . view ( tclass ) <NEWLINE> masked_tr . _mask = mr <NEWLINE> return masked_tr <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __eq__ ( a , b ) : <NEWLINE> <TAB> <NEWLINE> if type ( b ) is int : <NEWLINE> <TAB> return a . _numerator == b and a . _denominator == <NUMBER> <NEWLINE> <UNTAB> if isinstance ( b , numbers . Rational ) : <NEWLINE> <TAB> return ( a . _numerator == b . numerator and <NEWLINE> a . _denominator == b . denominator ) <NEWLINE> <UNTAB> if isinstance ( b , numbers . Complex ) and b . imag == <NUMBER> : <NEWLINE> <TAB> b = b . real <NEWLINE> <UNTAB> if isinstance ( b , float ) : <NEWLINE> <TAB> if math . isnan ( b ) or math . isinf ( b ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return <NUMBER> == b <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return a == a . from_float ( b ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return NotImplemented <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def sign ( self , e ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> dfs_stack = [ e ] <NEWLINE> <NEWLINE> old_ref = defaultdict ( lambda : None ) <NEWLINE> <NEWLINE> while dfs_stack : <NEWLINE> <TAB> e = dfs_stack . pop ( ) <NEWLINE> <NEWLINE> if self . ref [ e ] is not None : <NEWLINE> <TAB> dfs_stack . append ( e ) <NEWLINE> dfs_stack . append ( self . ref [ e ] ) <NEWLINE> old_ref [ e ] = self . ref [ e ] <NEWLINE> self . ref [ e ] = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . side [ e ] *= self . side [ old_ref [ e ] ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return self . side [ e ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_unique_graph ( tops , check_types = None , none_if_empty = False ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( tops , tf_ops . Graph ) : <NEWLINE> <TAB> return tops <NEWLINE> <UNTAB> if not is_iterable ( tops ) : <NEWLINE> <TAB> raise TypeError ( <STRING> . format ( type ( tops ) ) ) <NEWLINE> <UNTAB> if check_types is None : <NEWLINE> <TAB> check_types = ( tf_ops . Operation , tf_ops . Tensor ) <NEWLINE> <UNTAB> elif not is_iterable ( check_types ) : <NEWLINE> <TAB> check_types = ( check_types , ) <NEWLINE> <UNTAB> g = None <NEWLINE> for op in tops : <NEWLINE> <TAB> if not isinstance ( op , check_types ) : <NEWLINE> <TAB> raise TypeError ( <STRING> . format ( <STRING> . join ( [ str ( <NEWLINE> t ) for t in check_types ] ) , type ( op ) ) ) <NEWLINE> <UNTAB> if g is None : <NEWLINE> <TAB> g = op . graph <NEWLINE> <UNTAB> elif g is not op . graph : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( op ) ) <NEWLINE> <UNTAB> <UNTAB> if g is None and not none_if_empty : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return g <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ docstring . dedent_interpd <NEWLINE> def __init__ ( self , xy , width , height , angle = <NUMBER> , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> Patch . __init__ ( self , ** kwargs ) <NEWLINE> <NEWLINE> self . _x0 = xy [ <NUMBER> ] <NEWLINE> self . _y0 = xy [ <NUMBER> ] <NEWLINE> <NEWLINE> self . _width = width <NEWLINE> self . _height = height <NEWLINE> <NEWLINE> self . _x1 = self . _x0 + self . _width <NEWLINE> self . _y1 = self . _y0 + self . _height <NEWLINE> <NEWLINE> self . angle = float ( angle ) <NEWLINE> <NEWLINE> self . _rect_transform = transforms . IdentityTransform ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _run ( self , handle , fetches , feed_dict , options , run_metadata ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def _feed_fn ( feed , feed_val ) : <NEWLINE> <TAB> for tensor_type , _ , feed_fn , _ in _REGISTERED_EXPANSIONS : <NEWLINE> <TAB> if isinstance ( feed , tensor_type ) : <NEWLINE> <TAB> return feed_fn ( feed , feed_val ) <NEWLINE> <UNTAB> <UNTAB> raise TypeError ( <STRING> % ( feed , <NEWLINE> type ( feed ) ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . _closed : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> if self . graph . version == <NUMBER> : <NEWLINE> <TAB> raise RuntimeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> feed_dict_tensor = { } <NEWLINE> feed_map = { } <NEWLINE> <NEWLINE> <NEWLINE> feed_handles = { } <NEWLINE> if feed_dict : <NEWLINE> <TAB> feed_dict = nest . flatten_dict_items ( feed_dict ) <NEWLINE> for feed , feed_val in feed_dict . items ( ) : <NEWLINE> <TAB> for subfeed , subfeed_val in _feed_fn ( feed , feed_val ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> subfeed_t = self . graph . as_graph_element ( <NEWLINE> subfeed , allow_tensor = True , allow_operation = False ) <NEWLINE> <UNTAB> except Exception as e : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> + e . args [ <NUMBER> ] ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( subfeed_val , ops . Tensor ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> + <NEWLINE> str ( feed_val ) + <STRING> <NEWLINE> <STRING> + str ( feed ) + <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> subfeed_dtype = subfeed_t . dtype . as_numpy_dtype <NEWLINE> if isinstance ( subfeed_val , int ) and _convert_to_numpy_obj ( <NEWLINE> subfeed_dtype , subfeed_val ) != subfeed_val : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> + str ( subfeed_val ) + <STRING> + str ( <NEWLINE> type ( subfeed_val ) ) + <NEWLINE> <STRING> + str ( subfeed_dtype ) + <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> is_tensor_handle_feed = isinstance ( subfeed_val , <NEWLINE> session_ops . TensorHandle ) <NEWLINE> if is_tensor_handle_feed : <NEWLINE> <TAB> np_val = subfeed_val . to_numpy_array ( ) <NEWLINE> feed_handles [ subfeed_t ] = subfeed_val <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> np_val = np . asarray ( subfeed_val , dtype = subfeed_dtype ) <NEWLINE> <NEWLINE> <UNTAB> if ( not is_tensor_handle_feed and <NEWLINE> not subfeed_t . get_shape ( ) . is_compatible_with ( np_val . shape ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % <NEWLINE> ( np_val . shape , subfeed_t . name , <NEWLINE> str ( subfeed_t . get_shape ( ) ) ) ) <NEWLINE> <UNTAB> if not self . graph . is_feedable ( subfeed_t ) : <NEWLINE> <TAB> raise ValueError ( <STRING> % subfeed_t ) <NEWLINE> <NEWLINE> <UNTAB> feed_dict_tensor [ subfeed_t ] = np_val <NEWLINE> feed_map [ compat . as_bytes ( subfeed_t . name ) ] = ( subfeed_t , subfeed_val ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> fetch_handler = _FetchHandler ( <NEWLINE> self . _graph , fetches , feed_dict_tensor , feed_handles = feed_handles ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> _ = self . _update_with_movers ( feed_dict_tensor , feed_map ) <NEWLINE> final_fetches = fetch_handler . fetches ( ) <NEWLINE> final_targets = fetch_handler . targets ( ) <NEWLINE> <NEWLINE> <NEWLINE> if final_fetches or final_targets or ( handle and feed_dict_tensor ) : <NEWLINE> <TAB> results = self . _do_run ( handle , final_targets , final_fetches , <NEWLINE> feed_dict_tensor , options , run_metadata ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> results = [ ] <NEWLINE> <UNTAB> return fetch_handler . build_results ( self , results ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _cart2polar_2pi ( x , y ) : <NEWLINE> <TAB> <NEWLINE> r , t = np . hypot ( x , y ) , np . arctan2 ( y , x ) <NEWLINE> t += np . where ( t < <NUMBER> , <NUMBER> * np . pi , <NUMBER> ) <NEWLINE> return r , t <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def make_vjp ( f , params = None , persistent = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def decorated ( * args , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> parameter_positions = _get_arg_spec ( f , params , args ) <NEWLINE> assert not kwds , <STRING> <NEWLINE> this_tape = tape . push_new_tape ( persistent = persistent ) <NEWLINE> try : <NEWLINE> <TAB> sources = [ ] <NEWLINE> args = [ <NEWLINE> ops . convert_to_tensor ( args [ i ] ) <NEWLINE> if i in parameter_positions else args [ i ] <NEWLINE> for i in range ( len ( args ) ) <NEWLINE> ] <NEWLINE> args = _ensure_unique_tensor_objects ( parameter_positions , args ) <NEWLINE> for i in parameter_positions : <NEWLINE> <TAB> sources . append ( args [ i ] ) <NEWLINE> tape . watch ( this_tape , args [ i ] ) <NEWLINE> <UNTAB> result = f ( * args ) <NEWLINE> if result is None : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( <NEWLINE> f . __name__ ) ) <NEWLINE> <UNTAB> flat_result = nest . flatten ( result ) <NEWLINE> flat_result = [ gen_array_ops . identity ( x ) for x in flat_result ] <NEWLINE> result = nest . pack_sequence_as ( result , flat_result ) <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> tape . pop_tape ( this_tape ) <NEWLINE> <UNTAB> def vjp ( dy = None ) : <NEWLINE> <TAB> if dy is not None : <NEWLINE> <TAB> dy = [ ops . convert_to_tensor ( x ) for x in nest . flatten ( dy ) ] <NEWLINE> <UNTAB> return imperative_grad . imperative_grad ( <NEWLINE> this_tape , nest . flatten ( result ) , sources , output_gradients = dy ) <NEWLINE> <NEWLINE> <UNTAB> return result , vjp <NEWLINE> <NEWLINE> <UNTAB> return decorated <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def onmove ( self , event ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if not self . ignore ( event ) : <NEWLINE> <TAB> event = self . _clean_event ( event ) <NEWLINE> self . _onmove ( event ) <NEWLINE> return True <NEWLINE> <UNTAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fail ( self , msg = None ) : <NEWLINE> <TAB> <NEWLINE> raise self . failureException ( msg ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_task_info ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _job_name , self . _task_index <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_offset_position ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _offset_position <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def SameNamedtuples ( o1 , o2 ) : <NEWLINE> <TAB> <NEWLINE> return _pywrap_tensorflow_internal . SameNamedtuples ( o1 , o2 ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_extension_lengths ( self , frac , automin , automax , default = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> extendlength = np . array ( [ default , default ] ) <NEWLINE> if isinstance ( frac , str ) : <NEWLINE> <TAB> if frac . lower ( ) == <STRING> : <NEWLINE> <NEWLINE> <TAB> extendlength [ : ] = [ automin , automax ] <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> elif frac is not None : <NEWLINE> <TAB> try : <NEWLINE> <NEWLINE> <TAB> extendlength [ : ] = frac <NEWLINE> <NEWLINE> <NEWLINE> if np . isnan ( extendlength ) . any ( ) : <NEWLINE> <TAB> raise ValueError ( ) <NEWLINE> <UNTAB> <UNTAB> except ( TypeError , ValueError ) : <NEWLINE> <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> return extendlength <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _call_model_fn ( self , features , labels , mode , config ) : <NEWLINE> <TAB> <NEWLINE> model_fn_args = function_utils . fn_args ( self . _model_fn ) <NEWLINE> kwargs = { } <NEWLINE> if <STRING> in model_fn_args : <NEWLINE> <TAB> kwargs [ <STRING> ] = labels <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if labels is not None : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> if <STRING> in model_fn_args : <NEWLINE> <TAB> kwargs [ <STRING> ] = mode <NEWLINE> <UNTAB> if <STRING> in model_fn_args : <NEWLINE> <TAB> kwargs [ <STRING> ] = self . params <NEWLINE> <UNTAB> if <STRING> in model_fn_args : <NEWLINE> <TAB> kwargs [ <STRING> ] = config <NEWLINE> <NEWLINE> <UNTAB> logging . info ( <STRING> ) <NEWLINE> model_fn_results = self . _model_fn ( features = features , ** kwargs ) <NEWLINE> logging . info ( <STRING> ) <NEWLINE> <NEWLINE> if not isinstance ( model_fn_results , model_fn_lib . EstimatorSpec ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return model_fn_results <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _basis ( G , ring ) : <NEWLINE> <TAB> <NEWLINE> order = ring . order <NEWLINE> <NEWLINE> leading_monomials = [ g . LM for g in G ] <NEWLINE> candidates = [ ring . zero_monom ] <NEWLINE> basis = [ ] <NEWLINE> <NEWLINE> while candidates : <NEWLINE> <TAB> t = candidates . pop ( ) <NEWLINE> basis . append ( t ) <NEWLINE> <NEWLINE> new_candidates = [ _incr_k ( t , k ) for k in range ( ring . ngens ) <NEWLINE> if all ( monomial_div ( _incr_k ( t , k ) , lmg ) is None <NEWLINE> for lmg in leading_monomials ) ] <NEWLINE> candidates . extend ( new_candidates ) <NEWLINE> candidates . sort ( key = lambda m : order ( m ) , reverse = True ) <NEWLINE> <NEWLINE> <UNTAB> basis = list ( set ( basis ) ) <NEWLINE> <NEWLINE> return sorted ( basis , key = lambda m : order ( m ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def threshold_triangle ( image , nbins = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> hist , bin_centers = histogram ( image . ravel ( ) , nbins ) <NEWLINE> nbins = len ( hist ) <NEWLINE> <NEWLINE> <NEWLINE> arg_peak_height = np . argmax ( hist ) <NEWLINE> peak_height = hist [ arg_peak_height ] <NEWLINE> arg_low_level , arg_high_level = np . where ( hist > <NUMBER> ) [ <NUMBER> ] [ [ <NUMBER> , - <NUMBER> ] ] <NEWLINE> <NEWLINE> <NEWLINE> flip = arg_peak_height - arg_low_level < arg_high_level - arg_peak_height <NEWLINE> if flip : <NEWLINE> <TAB> hist = hist [ : : - <NUMBER> ] <NEWLINE> arg_low_level = nbins - arg_high_level - <NUMBER> <NEWLINE> arg_peak_height = nbins - arg_peak_height - <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> del ( arg_high_level ) <NEWLINE> <NEWLINE> <NEWLINE> width = arg_peak_height - arg_low_level <NEWLINE> x1 = np . arange ( width ) <NEWLINE> y1 = hist [ x1 + arg_low_level ] <NEWLINE> <NEWLINE> <NEWLINE> norm = np . sqrt ( peak_height ** <NUMBER> + width ** <NUMBER> ) <NEWLINE> peak_height /= norm <NEWLINE> width /= norm <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> length = peak_height * x1 - width * y1 <NEWLINE> arg_level = np . argmax ( length ) + arg_low_level <NEWLINE> <NEWLINE> if flip : <NEWLINE> <TAB> arg_level = nbins - arg_level - <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> return bin_centers [ arg_level ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def broadcast_coalesced ( tensors , devices , buffer_size = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return torch . _C . _broadcast_coalesced ( tensors , devices , buffer_size ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def construct_from_string ( cls , string ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( string , compat . string_types ) : <NEWLINE> <TAB> return cls ( string ) <NEWLINE> <UNTAB> msg = <STRING> <NEWLINE> raise TypeError ( msg . format ( typ = type ( string ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def align_ylabels ( self , axs = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if axs is None : <NEWLINE> <TAB> axs = self . axes <NEWLINE> <UNTAB> axs = np . asarray ( axs ) . ravel ( ) <NEWLINE> for ax in axs : <NEWLINE> <TAB> _log . debug ( <STRING> , ax . get_ylabel ( ) ) <NEWLINE> ss = ax . get_subplotspec ( ) <NEWLINE> nrows , ncols , row0 , row1 , col0 , col1 = ss . get_rows_columns ( ) <NEWLINE> same = [ ax ] <NEWLINE> labpo = ax . yaxis . get_label_position ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for axc in axs : <NEWLINE> <TAB> if axc != ax : <NEWLINE> <TAB> if axc . yaxis . get_label_position ( ) == labpo : <NEWLINE> <TAB> ss = axc . get_subplotspec ( ) <NEWLINE> nrows , ncols , row0 , row1 , colc0 , colc1 = ss . get_rows_columns ( ) <NEWLINE> if ( labpo == <STRING> and colc0 == col0 or <NEWLINE> labpo == <STRING> and colc1 == col1 ) : <NEWLINE> <NEWLINE> <TAB> self . _align_ylabel_grp . join ( ax , axc ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def print_tensor ( x , message = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return tf . Print ( x , [ x ] , message ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def plot3d_parametric_line ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> args = list ( map ( sympify , args ) ) <NEWLINE> show = kwargs . pop ( <STRING> , True ) <NEWLINE> series = [ ] <NEWLINE> plot_expr = check_arguments ( args , <NUMBER> , <NUMBER> ) <NEWLINE> series = [ Parametric3DLineSeries ( * arg , ** kwargs ) for arg in plot_expr ] <NEWLINE> plots = Plot ( * series , ** kwargs ) <NEWLINE> if show : <NEWLINE> <TAB> plots . show ( ) <NEWLINE> <UNTAB> return plots <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _reindex_output ( self , result ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> groupings = self . grouper . groupings <NEWLINE> if groupings is None : <NEWLINE> <TAB> return result <NEWLINE> <UNTAB> elif len ( groupings ) == <NUMBER> : <NEWLINE> <TAB> return result <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif self . observed : <NEWLINE> <TAB> return result <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif not any ( isinstance ( ping . grouper , ( Categorical , CategoricalIndex ) ) <NEWLINE> for ping in groupings ) : <NEWLINE> <TAB> return result <NEWLINE> <NEWLINE> <UNTAB> levels_list = [ ping . group_index for ping in groupings ] <NEWLINE> index , _ = MultiIndex . from_product ( <NEWLINE> levels_list , names = self . grouper . names ) . sortlevel ( ) <NEWLINE> <NEWLINE> if self . as_index : <NEWLINE> <TAB> d = { self . obj . _get_axis_name ( self . axis ) : index , <STRING> : False } <NEWLINE> return result . reindex ( ** d ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> in_axis_grps = [ ( i , ping . name ) for ( i , ping ) <NEWLINE> in enumerate ( groupings ) if ping . in_axis ] <NEWLINE> g_nums , g_names = zip ( * in_axis_grps ) <NEWLINE> <NEWLINE> result = result . drop ( labels = list ( g_names ) , axis = <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> result = result . set_index ( self . grouper . result_index <NEWLINE> ) . reindex ( index , copy = False ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> result = result . reset_index ( level = g_nums ) <NEWLINE> <NEWLINE> return result . reset_index ( drop = True ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _raise_typeerror ( X ) : <NEWLINE> <TAB> <NEWLINE> input_type = X . format if sp . issparse ( X ) else type ( X ) <NEWLINE> err = <STRING> % input_type <NEWLINE> raise TypeError ( err ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def http_error_default ( self , url , fp , errcode , errmsg , headers ) : <NEWLINE> <TAB> <NEWLINE> return addinfourl ( fp , headers , <STRING> + url , errcode ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_filterrad ( self , filterrad ) : <NEWLINE> <TAB> <NEWLINE> r = float ( filterrad ) <NEWLINE> if r <= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> self . _filterrad = r <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def zoneout ( h , x , ratio = <NUMBER> , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if kwargs : <NEWLINE> <TAB> argument . check_unexpected_kwargs ( <NEWLINE> kwargs , train = <STRING> <NEWLINE> <STRING> ) <NEWLINE> argument . assert_kwargs_empty ( kwargs ) <NEWLINE> <NEWLINE> <UNTAB> if configuration . config . train : <NEWLINE> <TAB> return Zoneout ( ratio ) . apply ( ( h , x ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> return x <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _point_along_a_line ( x0 , y0 , x1 , y1 , d ) : <NEWLINE> <TAB> <NEWLINE> dx , dy = x0 - x1 , y0 - y1 <NEWLINE> ff = d / ( dx * dx + dy * dy ) ** <NUMBER> <NEWLINE> x2 , y2 = x0 - ff * dx , y0 - ff * dy <NEWLINE> <NEWLINE> return x2 , y2 <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def foldl ( fn , elems , initializer = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> return functional_ops . foldl ( fn , elems , initializer = initializer , name = name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_artist ( self , a ) : <NEWLINE> <TAB> <NEWLINE> a . axes = self <NEWLINE> self . artists . append ( a ) <NEWLINE> a . _remove_method = self . artists . remove <NEWLINE> self . _set_artist_props ( a ) <NEWLINE> a . set_clip_path ( self . patch ) <NEWLINE> self . stale = True <NEWLINE> return a <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _add_logical_methods ( cls ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> _doc = <NEWLINE> <NEWLINE> _index_shared_docs [ <STRING> ] = dedent ( " " " 
 
                 S e e   A l s o 
                 - - - - - - - - 
                 p a n d a s . I n d e x . a n y   :   R e t u r n   w h e t h e r   a n y   e l e m e n t   i n   a n   I n d e x   i s   T r u e . 
                 p a n d a s . S e r i e s . a n y   :   R e t u r n   w h e t h e r   a n y   e l e m e n t   i n   a   S e r i e s   i s   T r u e . 
                 p a n d a s . S e r i e s . a l l   :   R e t u r n   w h e t h e r   a l l   e l e m e n t s   i n   a   S e r i e s   a r e   T r u e . 
 
                 N o t e s 
                 - - - - - 
                 N o t   a   N u m b e r   ( N a N ) ,   p o s i t i v e   i n f i n i t y   a n d   n e g a t i v e   i n f i n i t y 
                 e v a l u a t e   t o   T r u e   b e c a u s e   t h e s e   a r e   n o t   e q u a l   t o   z e r o . 
 
                 E x a m p l e s 
                 - - - - - - - - 
                 * * a l l * * 
 
                 T r u e ,   b e c a u s e   n o n z e r o   i n t e g e r s   a r e   c o n s i d e r e d   T r u e . 
 
                 > > >   p d . I n d e x ( [ 1 ,   2 ,   3 ] ) . a l l ( ) 
                 T r u e 
 
                 F a l s e ,   b e c a u s e   ` ` 0 ` `   i s   c o n s i d e r e d   F a l s e . 
 
                 > > >   p d . I n d e x ( [ 0 ,   1 ,   2 ] ) . a l l ( ) 
                 F a l s e 
 
                 * * a n y * * 
 
                 T r u e ,   b e c a u s e   ` ` 1 ` `   i s   c o n s i d e r e d   T r u e . 
 
                 > > >   p d . I n d e x ( [ 0 ,   0 ,   1 ] ) . a n y ( ) 
                 T r u e 
 
                 F a l s e ,   b e c a u s e   ` ` 0 ` `   i s   c o n s i d e r e d   F a l s e . 
 
                 > > >   p d . I n d e x ( [ 0 ,   0 ,   0 ] ) . a n y ( ) 
                 F a l s e 
                 " " " ) <NEWLINE> <NEWLINE> _index_shared_docs [ <STRING> ] = dedent ( " " " 
 
                 S e e   A l s o 
                 - - - - - - - - 
                 p a n d a s . I n d e x . a l l   :   R e t u r n   w h e t h e r   a l l   e l e m e n t s   a r e   T r u e . 
                 p a n d a s . S e r i e s . a l l   :   R e t u r n   w h e t h e r   a l l   e l e m e n t s   a r e   T r u e . 
 
                 N o t e s 
                 - - - - - 
                 N o t   a   N u m b e r   ( N a N ) ,   p o s i t i v e   i n f i n i t y   a n d   n e g a t i v e   i n f i n i t y 
                 e v a l u a t e   t o   T r u e   b e c a u s e   t h e s e   a r e   n o t   e q u a l   t o   z e r o . 
 
                 E x a m p l e s 
                 - - - - - - - - 
                 > > >   i n d e x   =   p d . I n d e x ( [ 0 ,   1 ,   2 ] ) 
                 > > >   i n d e x . a n y ( ) 
                 T r u e 
 
                 > > >   i n d e x   =   p d . I n d e x ( [ 0 ,   0 ,   0 ] ) 
                 > > >   i n d e x . a n y ( ) 
                 F a l s e 
                 " " " ) <NEWLINE> <NEWLINE> def _make_logical_function ( name , desc , f ) : <NEWLINE> <TAB> @ Substitution ( outname = name , desc = desc ) <NEWLINE> @ Appender ( _index_shared_docs [ <STRING> + name ] ) <NEWLINE> @ Appender ( _doc ) <NEWLINE> def logical_func ( self , * args , ** kwargs ) : <NEWLINE> <TAB> result = f ( self . values ) <NEWLINE> if ( isinstance ( result , ( np . ndarray , ABCSeries , Index ) ) and <NEWLINE> result . ndim == <NUMBER> ) : <NEWLINE> <NEWLINE> <TAB> return result . dtype . type ( result . item ( ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return result <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> logical_func . __name__ = name <NEWLINE> return logical_func <NEWLINE> <NEWLINE> <UNTAB> cls . all = _make_logical_function ( <STRING> , <STRING> <NEWLINE> <STRING> , <NEWLINE> np . all ) <NEWLINE> cls . any = _make_logical_function ( <STRING> , <NEWLINE> <STRING> , <NEWLINE> np . any ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def compute_gradients ( self , loss , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> loss = _scale_loss ( loss , <NEWLINE> self . _graph_state ( ) . loss_reduction , <NEWLINE> self . _graph_state ( ) . number_of_towers ) <NEWLINE> return self . _get_optimizer ( ) . compute_gradients ( loss , * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __gt__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> other = as_dimension ( other ) <NEWLINE> if self . _value is None or other . value is None : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . _value > other . value <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def matrix_rank ( M , tol = None , hermitian = False ) : <NEWLINE> <TAB> <NEWLINE> M = asarray ( M ) <NEWLINE> if M . ndim < <NUMBER> : <NEWLINE> <TAB> return int ( not all ( M == <NUMBER> ) ) <NEWLINE> <UNTAB> if hermitian : <NEWLINE> <TAB> S = abs ( eigvalsh ( M ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> S = svd ( M , compute_uv = False ) <NEWLINE> <UNTAB> if tol is None : <NEWLINE> <TAB> tol = S . max ( axis = - <NUMBER> , keepdims = True ) * max ( M . shape [ - <NUMBER> : ] ) * finfo ( S . dtype ) . eps <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> tol = asarray ( tol ) [ ... , newaxis ] <NEWLINE> <UNTAB> return count_nonzero ( S > tol , axis = - <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _is_level_reference ( self , key , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> axis = self . _get_axis_number ( axis ) <NEWLINE> <NEWLINE> if self . ndim > <NUMBER> : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> <NEWLINE> . format ( type = type ( self ) ) ) <NEWLINE> <NEWLINE> <UNTAB> return ( key is not None and <NEWLINE> is_hashable ( key ) and <NEWLINE> key in self . axes [ axis ] . names and <NEWLINE> not self . _is_label_reference ( key , axis = axis ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def idctn ( x , type = <NUMBER> , shape = None , axes = None , norm = None , overwrite_x = False ) : <NEWLINE> <TAB> <NEWLINE> x = np . asanyarray ( x ) <NEWLINE> shape , axes = _init_nd_shape_and_axes ( x , shape , axes ) <NEWLINE> for n , ax in zip ( shape , axes ) : <NEWLINE> <TAB> x = idct ( x , type = type , n = n , axis = ax , norm = norm , <NEWLINE> overwrite_x = overwrite_x ) <NEWLINE> <UNTAB> return x <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ _sympifyit ( <STRING> , NotImplementedError ) <NEWLINE> def doit_numerically ( self , z0 ) : <NEWLINE> <TAB> <NEWLINE> import mpmath <NEWLINE> from sympy . core . expr import Expr <NEWLINE> if len ( self . free_symbols ) != <NUMBER> or len ( self . variables ) != <NUMBER> : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> z = list ( self . free_symbols ) [ <NUMBER> ] <NEWLINE> <NEWLINE> def eval ( x ) : <NEWLINE> <TAB> f0 = self . expr . subs ( z , Expr . _from_mpmath ( x , prec = mpmath . mp . prec ) ) <NEWLINE> f0 = f0 . evalf ( mlib . libmpf . prec_to_dps ( mpmath . mp . prec ) ) <NEWLINE> return f0 . _to_mpmath ( mpmath . mp . prec ) <NEWLINE> <UNTAB> return Expr . _from_mpmath ( mpmath . diff ( eval , <NEWLINE> z0 . _to_mpmath ( mpmath . mp . prec ) ) , <NEWLINE> mpmath . mp . prec ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def print_octave_code ( expr , ** settings ) : <NEWLINE> <TAB> <NEWLINE> print ( octave_code ( expr , ** settings ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def get_home_dir ( ) : <NEWLINE> <TAB> <NEWLINE> home = os . getenv ( <STRING> ) <NEWLINE> if home is None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> home = os . path . expanduser ( <STRING> ) <NEWLINE> if home == <STRING> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> home = os . getenv ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> assert home is not None <NEWLINE> return home <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def str_extractall ( arr , pat , flags = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> regex = re . compile ( pat , flags = flags ) <NEWLINE> <NEWLINE> if regex . groups == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( arr , ABCIndex ) : <NEWLINE> <TAB> arr = arr . to_series ( ) . reset_index ( drop = True ) <NEWLINE> <NEWLINE> <UNTAB> names = dict ( zip ( regex . groupindex . values ( ) , regex . groupindex . keys ( ) ) ) <NEWLINE> columns = [ names . get ( <NUMBER> + i , i ) for i in range ( regex . groups ) ] <NEWLINE> match_list = [ ] <NEWLINE> index_list = [ ] <NEWLINE> is_mi = arr . index . nlevels > <NUMBER> <NEWLINE> <NEWLINE> for subject_key , subject in arr . iteritems ( ) : <NEWLINE> <TAB> if isinstance ( subject , compat . string_types ) : <NEWLINE> <NEWLINE> <TAB> if not is_mi : <NEWLINE> <TAB> subject_key = ( subject_key , ) <NEWLINE> <NEWLINE> <UNTAB> for match_i , match_tuple in enumerate ( regex . findall ( subject ) ) : <NEWLINE> <TAB> if isinstance ( match_tuple , compat . string_types ) : <NEWLINE> <TAB> match_tuple = ( match_tuple , ) <NEWLINE> <UNTAB> na_tuple = [ np . NaN if group == <STRING> else group <NEWLINE> for group in match_tuple ] <NEWLINE> match_list . append ( na_tuple ) <NEWLINE> result_key = tuple ( subject_key + ( match_i , ) ) <NEWLINE> index_list . append ( result_key ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> from pandas import MultiIndex <NEWLINE> index = MultiIndex . from_tuples ( <NEWLINE> index_list , names = arr . index . names + [ <STRING> ] ) <NEWLINE> <NEWLINE> result = arr . _constructor_expanddim ( match_list , index = index , <NEWLINE> columns = columns ) <NEWLINE> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def doprint ( self , expr ) : <NEWLINE> <TAB> <NEWLINE> return self . _str ( self . _print ( expr ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def tvar ( a , limits = None , inclusive = ( True , True ) , axis = <NUMBER> , ddof = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> a = asarray ( a ) <NEWLINE> a = a . astype ( float ) . ravel ( ) <NEWLINE> if limits is None : <NEWLINE> <TAB> n = len ( a ) <NEWLINE> return a . var ( ) * n / ( n - <NUMBER> ) <NEWLINE> <UNTAB> am = _mask_to_limits ( a , limits , inclusive ) <NEWLINE> return np . ma . var ( am , ddof = ddof , axis = axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def min ( self ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def line_graph ( G , create_using = None ) : <NEWLINE> <TAB> <NEWLINE> if G . is_directed ( ) : <NEWLINE> <TAB> L = _lg_directed ( G , create_using = create_using ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> L = _lg_undirected ( G , selfloops = False , create_using = create_using ) <NEWLINE> <UNTAB> return L <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def hermfromroots ( roots ) : <NEWLINE> <TAB> <NEWLINE> if len ( roots ) == <NUMBER> : <NEWLINE> <TAB> return np . ones ( <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> [ roots ] = pu . as_series ( [ roots ] , trim = False ) <NEWLINE> roots . sort ( ) <NEWLINE> p = [ hermline ( - r , <NUMBER> ) for r in roots ] <NEWLINE> n = len ( p ) <NEWLINE> while n > <NUMBER> : <NEWLINE> <TAB> m , r = divmod ( n , <NUMBER> ) <NEWLINE> tmp = [ hermmul ( p [ i ] , p [ i + m ] ) for i in range ( m ) ] <NEWLINE> if r : <NEWLINE> <TAB> tmp [ <NUMBER> ] = hermmul ( tmp [ <NUMBER> ] , p [ - <NUMBER> ] ) <NEWLINE> <UNTAB> p = tmp <NEWLINE> n = m <NEWLINE> <UNTAB> return p [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _node_key ( layer , node_index ) : <NEWLINE> <TAB> <NEWLINE> return layer . name + <STRING> + str ( node_index ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _LDL_sparse ( self ) : <NEWLINE> <TAB> <NEWLINE> Lrowstruc = self . row_structure_symbolic_cholesky ( ) <NEWLINE> L = self . eye ( self . rows ) <NEWLINE> D = self . zeros ( self . rows , self . cols ) <NEWLINE> <NEWLINE> for i in range ( len ( Lrowstruc ) ) : <NEWLINE> <TAB> for j in Lrowstruc [ i ] : <NEWLINE> <TAB> if i != j : <NEWLINE> <TAB> L [ i , j ] = self [ i , j ] <NEWLINE> summ = <NUMBER> <NEWLINE> for p1 in Lrowstruc [ i ] : <NEWLINE> <TAB> if p1 < j : <NEWLINE> <TAB> for p2 in Lrowstruc [ j ] : <NEWLINE> <TAB> if p2 < j : <NEWLINE> <TAB> if p1 == p2 : <NEWLINE> <TAB> summ += L [ i , p1 ] * L [ j , p1 ] * D [ p1 , p1 ] <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> L [ i , j ] -= summ <NEWLINE> L [ i , j ] /= D [ j , j ] <NEWLINE> <UNTAB> elif i == j : <NEWLINE> <TAB> D [ i , i ] = self [ i , i ] <NEWLINE> summ = <NUMBER> <NEWLINE> for k in Lrowstruc [ i ] : <NEWLINE> <TAB> if k < i : <NEWLINE> <TAB> summ += L [ i , k ] ** <NUMBER> * D [ k , k ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> D [ i , i ] -= summ <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return L , D <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def itercoeffs ( self ) : <NEWLINE> <TAB> <NEWLINE> return iter ( self . values ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __getattr__ ( self , name ) : <NEWLINE> <TAB> <NEWLINE> if name in self . tags : <NEWLINE> <TAB> value = self . tags [ name ] . value <NEWLINE> setattr ( self , name , value ) <NEWLINE> return value <NEWLINE> <UNTAB> raise AttributeError ( name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def denom ( self , a ) : <NEWLINE> <TAB> <NEWLINE> return self . one <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_ground_TC ( f , u , K ) : <NEWLINE> <TAB> <NEWLINE> while u : <NEWLINE> <TAB> f = dmp_TC ( f , K ) <NEWLINE> u -= <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> return dup_TC ( f , K ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_patch ( self , p ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . _set_artist_props ( p ) <NEWLINE> if p . get_clip_path ( ) is None : <NEWLINE> <TAB> p . set_clip_path ( self . patch ) <NEWLINE> <UNTAB> self . _update_patch_limits ( p ) <NEWLINE> self . patches . append ( p ) <NEWLINE> p . _remove_method = self . patches . remove <NEWLINE> return p <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def strided_slice ( input_ , <NEWLINE> begin , <NEWLINE> end , <NEWLINE> strides = None , <NEWLINE> begin_mask = <NUMBER> , <NEWLINE> end_mask = <NUMBER> , <NEWLINE> ellipsis_mask = <NUMBER> , <NEWLINE> new_axis_mask = <NUMBER> , <NEWLINE> shrink_axis_mask = <NUMBER> , <NEWLINE> var = None , <NEWLINE> name = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if strides is None : <NEWLINE> <TAB> strides = ones_like ( begin ) <NEWLINE> <NEWLINE> <UNTAB> op = gen_array_ops . strided_slice ( <NEWLINE> input = input_ , <NEWLINE> begin = begin , <NEWLINE> end = end , <NEWLINE> strides = strides , <NEWLINE> name = name , <NEWLINE> begin_mask = begin_mask , <NEWLINE> end_mask = end_mask , <NEWLINE> ellipsis_mask = ellipsis_mask , <NEWLINE> new_axis_mask = new_axis_mask , <NEWLINE> shrink_axis_mask = shrink_axis_mask ) <NEWLINE> <NEWLINE> parent_name = name <NEWLINE> <NEWLINE> if not ( var is None and isinstance ( op , ops . EagerTensor ) ) : <NEWLINE> <TAB> def assign ( val , name = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if var is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if name is None : <NEWLINE> <TAB> name = parent_name + <STRING> <NEWLINE> <NEWLINE> <UNTAB> return var . _strided_slice_assign ( <NEWLINE> begin = begin , <NEWLINE> end = end , <NEWLINE> strides = strides , <NEWLINE> value = val , <NEWLINE> name = name , <NEWLINE> begin_mask = begin_mask , <NEWLINE> end_mask = end_mask , <NEWLINE> ellipsis_mask = ellipsis_mask , <NEWLINE> new_axis_mask = new_axis_mask , <NEWLINE> shrink_axis_mask = shrink_axis_mask ) <NEWLINE> <NEWLINE> <UNTAB> op . assign = assign <NEWLINE> <UNTAB> return op <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def consumers ( self ) : <NEWLINE> <TAB> <NEWLINE> values_consumers = set ( self . _values . consumers ( ) ) <NEWLINE> indices_consumers = set ( self . _indices . consumers ( ) ) <NEWLINE> dense_shape_consumers = set ( self . _dense_shape . consumers ( ) ) <NEWLINE> return list ( values_consumers . union ( indices_consumers , dense_shape_consumers ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_function ( self , name ) : <NEWLINE> <TAB> <NEWLINE> return self . _functions . get ( compat . as_str ( name ) , None ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def regularized_lsq_with_qr ( m , n , R , QTb , perm , diag , copy_R = True ) : <NEWLINE> <TAB> <NEWLINE> if copy_R : <NEWLINE> <TAB> R = R . copy ( ) <NEWLINE> <UNTAB> v = QTb . copy ( ) <NEWLINE> <NEWLINE> givens_elimination ( R , v , diag [ perm ] ) <NEWLINE> <NEWLINE> abs_diag_R = np . abs ( np . diag ( R ) ) <NEWLINE> threshold = EPS * max ( m , n ) * np . max ( abs_diag_R ) <NEWLINE> nns , = np . nonzero ( abs_diag_R > threshold ) <NEWLINE> <NEWLINE> R = R [ np . ix_ ( nns , nns ) ] <NEWLINE> v = v [ nns ] <NEWLINE> <NEWLINE> x = np . zeros ( n ) <NEWLINE> x [ perm [ nns ] ] = solve_triangular ( R , v ) <NEWLINE> <NEWLINE> return x <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def format_coord ( self , x , y ) : <NEWLINE> <TAB> <NEWLINE> if x is None : <NEWLINE> <TAB> xs = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> xs = self . format_xdata ( x ) <NEWLINE> <UNTAB> if y is None : <NEWLINE> <TAB> ys = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ys = self . format_ydata ( y ) <NEWLINE> <UNTAB> return <STRING> % ( xs , ys ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def check_stack_trace ( f_or_fgraph , ops_to_check = <STRING> , bug_print = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( f_or_fgraph , theano . compile . function_module . Function ) : <NEWLINE> <TAB> fgraph = f_or_fgraph . maker . fgraph <NEWLINE> <UNTAB> elif isinstance ( f_or_fgraph , theano . gof . fg . FunctionGraph ) : <NEWLINE> <TAB> fgraph = f_or_fgraph <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if ( isinstance ( ops_to_check , theano . gof . Op ) or <NEWLINE> ( inspect . isclass ( ops_to_check ) and <NEWLINE> issubclass ( ops_to_check , theano . gof . Op ) ) ) : <NEWLINE> <TAB> ops_to_check = ( ops_to_check , ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( ops_to_check , string_types ) : <NEWLINE> <TAB> if ops_to_check == <STRING> : <NEWLINE> <TAB> apply_nodes_to_check = [ fgraph . outputs [ i ] . owner for i in range ( <NEWLINE> len ( fgraph . outputs ) ) ] <NEWLINE> <UNTAB> elif ops_to_check == <STRING> : <NEWLINE> <TAB> apply_nodes_to_check = fgraph . apply_nodes <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( ops_to_check , ( tuple , list ) ) : <NEWLINE> <NEWLINE> <TAB> op_instances = [ ] <NEWLINE> op_classes = [ ] <NEWLINE> for obj in ops_to_check : <NEWLINE> <TAB> if isinstance ( obj , theano . gof . Op ) : <NEWLINE> <TAB> op_instances . append ( obj ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> op_classes . append ( obj ) <NEWLINE> <UNTAB> <UNTAB> op_classes = tuple ( op_classes ) <NEWLINE> <NEWLINE> apply_nodes_to_check = ( <NEWLINE> [ node for node in fgraph . apply_nodes if node . op in ops_to_check ] + <NEWLINE> [ node for node in fgraph . apply_nodes <NEWLINE> if isinstance ( node . op , op_classes ) or <NEWLINE> ( hasattr ( node . op , <STRING> ) and <NEWLINE> isinstance ( node . op . scalar_op , op_classes ) ) ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif hasattr ( ops_to_check , <STRING> ) : <NEWLINE> <TAB> apply_nodes_to_check = [ node for node in fgraph . apply_nodes <NEWLINE> if ops_to_check ( node ) ] <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if not apply_nodes_to_check : <NEWLINE> <TAB> msg = <STRING> <STRING> <NEWLINE> if bug_print == <STRING> : <NEWLINE> <TAB> warnings . warn ( msg ) <NEWLINE> <UNTAB> elif bug_print == <STRING> : <NEWLINE> <TAB> raise Exception ( msg ) <NEWLINE> <UNTAB> elif bug_print == <STRING> : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for node in apply_nodes_to_check : <NEWLINE> <TAB> for output in node . outputs : <NEWLINE> <TAB> if ( not hasattr ( output . tag , <STRING> ) or not output . tag . trace ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def broadcast ( tensor , src , group = group . WORLD ) : <NEWLINE> <TAB> <NEWLINE> assert torch . distributed . _initialized == _INITIALIZED_PG , <STRING> <NEWLINE> return torch . _C . _dist_broadcast ( tensor , src , group ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def test_parallel ( num_threads = <NUMBER> , kwargs_list = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> assert num_threads > <NUMBER> <NEWLINE> has_kwargs_list = kwargs_list is not None <NEWLINE> if has_kwargs_list : <NEWLINE> <TAB> assert len ( kwargs_list ) == num_threads <NEWLINE> <UNTAB> import threading <NEWLINE> <NEWLINE> def wrapper ( func ) : <NEWLINE> <TAB> @ wraps ( func ) <NEWLINE> def inner ( * args , ** kwargs ) : <NEWLINE> <TAB> if has_kwargs_list : <NEWLINE> <TAB> update_kwargs = lambda i : dict ( kwargs , ** kwargs_list [ i ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> update_kwargs = lambda i : kwargs <NEWLINE> <UNTAB> threads = [ ] <NEWLINE> for i in range ( num_threads ) : <NEWLINE> <TAB> updated_kwargs = update_kwargs ( i ) <NEWLINE> thread = threading . Thread ( target = func , args = args , <NEWLINE> kwargs = updated_kwargs ) <NEWLINE> threads . append ( thread ) <NEWLINE> <UNTAB> for thread in threads : <NEWLINE> <TAB> thread . start ( ) <NEWLINE> <UNTAB> for thread in threads : <NEWLINE> <TAB> thread . join ( ) <NEWLINE> <UNTAB> <UNTAB> return inner <NEWLINE> <UNTAB> return wrapper <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_feed_params ( self ) : <NEWLINE> <TAB> <NEWLINE> return { <STRING> : self . _batch_size } <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_size_inches ( self ) : <NEWLINE> <TAB> <NEWLINE> return np . array ( self . bbox_inches . p1 ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def negative ( x , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ x ] ) as name : <NEWLINE> <TAB> if isinstance ( x , sparse_tensor . SparseTensor ) : <NEWLINE> <TAB> x_neg = gen_math_ops . neg ( x . values , name = name ) <NEWLINE> return sparse_tensor . SparseTensor ( <NEWLINE> indices = x . indices , values = x_neg , dense_shape = x . dense_shape ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return gen_math_ops . neg ( x , name = name ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _from_dict ( cls , rep , opt ) : <NEWLINE> <TAB> <NEWLINE> gens = opt . gens <NEWLINE> <NEWLINE> if not gens : <NEWLINE> <TAB> raise GeneratorsNeeded ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> level = len ( gens ) - <NUMBER> <NEWLINE> domain = opt . domain <NEWLINE> <NEWLINE> if domain is None : <NEWLINE> <TAB> domain , rep = construct_domain ( rep , opt = opt ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for monom , coeff in rep . items ( ) : <NEWLINE> <TAB> rep [ monom ] = domain . convert ( coeff ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return cls . new ( DMP . from_dict ( rep , level , domain ) , * gens ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def debug ( brule , file = None ) : <NEWLINE> <TAB> <NEWLINE> if not file : <NEWLINE> <TAB> from sys import stdout <NEWLINE> file = stdout <NEWLINE> <NEWLINE> <UNTAB> def write ( brl , expr , result ) : <NEWLINE> <TAB> file . write ( <STRING> % get_function_name ( brl ) ) <NEWLINE> file . write ( <STRING> % ( expr , result ) ) <NEWLINE> <NEWLINE> <UNTAB> return onaction ( brule , write ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , x , pos = None ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def eye ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> from . dense import Matrix <NEWLINE> <NEWLINE> return Matrix . eye ( * args , ** kwargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def fsencode ( filename ) : <NEWLINE> <TAB> <NEWLINE> filename = fspath ( filename ) <NEWLINE> if isinstance ( filename , str ) : <NEWLINE> <TAB> return filename . encode ( encoding , errors ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return filename <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def tree_predictions_v4_eager_fallback ( tree_handle , input_data , sparse_input_indices , sparse_input_values , sparse_input_shape , input_spec , params , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> input_spec = _execute . make_str ( input_spec , <STRING> ) <NEWLINE> params = _execute . make_str ( params , <STRING> ) <NEWLINE> tree_handle = _ops . convert_to_tensor ( tree_handle , _dtypes . resource ) <NEWLINE> input_data = _ops . convert_to_tensor ( input_data , _dtypes . float32 ) <NEWLINE> sparse_input_indices = _ops . convert_to_tensor ( sparse_input_indices , _dtypes . int64 ) <NEWLINE> sparse_input_values = _ops . convert_to_tensor ( sparse_input_values , _dtypes . float32 ) <NEWLINE> sparse_input_shape = _ops . convert_to_tensor ( sparse_input_shape , _dtypes . int64 ) <NEWLINE> _inputs_flat = [ tree_handle , input_data , sparse_input_indices , sparse_input_values , sparse_input_shape ] <NEWLINE> _attrs = ( <STRING> , input_spec , <STRING> , params ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result = _TreePredictionsV4Output . _make ( _result ) <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def init_r ( self , r ) : <NEWLINE> <TAB> <NEWLINE> if r not in self . shape_of : <NEWLINE> <TAB> try : <NEWLINE> <TAB> self . set_shape ( r , self . shape_tuple ( r ) ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> self . set_shape ( r , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _semantic_type ( self , data ) : <NEWLINE> <TAB> <NEWLINE> if self . input_format == <STRING> : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> float_data = data . astype ( np . float ) <NEWLINE> values = np . unique ( float_data . dropna ( ) ) <NEWLINE> if np . array_equal ( values , np . array ( [ <NUMBER> , <NUMBER> ] ) ) : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> return <STRING> <NEWLINE> <UNTAB> except ( ValueError , TypeError ) : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def issubset ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return self . is_subset ( other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _append_max ( arr , pad_amt , num , axis = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if pad_amt == <NUMBER> : <NEWLINE> <TAB> return arr <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if num == <NUMBER> : <NEWLINE> <TAB> return _append_edge ( arr , pad_amt , axis ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if num is not None : <NEWLINE> <TAB> if num >= arr . shape [ axis ] : <NEWLINE> <TAB> num = None <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> end = arr . shape [ axis ] - <NUMBER> <NEWLINE> if num is not None : <NEWLINE> <TAB> max_slice = tuple ( <NEWLINE> slice ( None ) if i != axis else slice ( end , end - num , - <NUMBER> ) <NEWLINE> for ( i , x ) in enumerate ( arr . shape ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> max_slice = tuple ( slice ( None ) for x in arr . shape ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> pad_singleton = tuple ( x if i != axis else <NUMBER> <NEWLINE> for ( i , x ) in enumerate ( arr . shape ) ) <NEWLINE> <NEWLINE> <NEWLINE> max_chunk = arr [ max_slice ] . max ( axis = axis ) . reshape ( pad_singleton ) <NEWLINE> <NEWLINE> <NEWLINE> return np . concatenate ( ( arr , max_chunk . repeat ( pad_amt , axis = axis ) ) , <NEWLINE> axis = axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def set_epsilon ( value ) : <NEWLINE> <TAB> <NEWLINE> global _EPSILON <NEWLINE> _EPSILON = value <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def argmax ( self , axis = None ) : <NEWLINE> <TAB> <NEWLINE> return nanops . nanargmax ( self . values ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def predict_x ( self , y , params = None ) : <NEWLINE> <TAB> <NEWLINE> x = self . predict ( y , axis = <NUMBER> , params = params ) [ : , <NUMBER> ] <NEWLINE> return x <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def to_tree ( Z , rd = False ) : <NEWLINE> <TAB> <NEWLINE> Z = np . asarray ( Z , order = <STRING> ) <NEWLINE> is_valid_linkage ( Z , throw = True , name = <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> n = Z . shape [ <NUMBER> ] + <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> d = [ None ] * ( n * <NUMBER> - <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> for i in xrange ( <NUMBER> , n ) : <NEWLINE> <TAB> d [ i ] = ClusterNode ( i ) <NEWLINE> <NEWLINE> <UNTAB> nd = None <NEWLINE> <NEWLINE> for i in xrange ( <NUMBER> , n - <NUMBER> ) : <NEWLINE> <TAB> fi = int ( Z [ i , <NUMBER> ] ) <NEWLINE> fj = int ( Z [ i , <NUMBER> ] ) <NEWLINE> if fi > i + n : <NEWLINE> <TAB> raise ValueError ( ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) % fi ) <NEWLINE> <UNTAB> if fj > i + n : <NEWLINE> <TAB> raise ValueError ( ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) % fj ) <NEWLINE> <UNTAB> nd = ClusterNode ( i + n , d [ fi ] , d [ fj ] , Z [ i , <NUMBER> ] ) <NEWLINE> <NEWLINE> if Z [ i , <NUMBER> ] != nd . count : <NEWLINE> <TAB> raise ValueError ( ( <STRING> <NEWLINE> <STRING> ) % i ) <NEWLINE> <UNTAB> d [ n + i ] = nd <NEWLINE> <NEWLINE> <UNTAB> if rd : <NEWLINE> <TAB> return ( nd , d ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return nd <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _number_theoretic_transform ( seq , prime , inverse = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not iterable ( seq ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> p = as_int ( prime ) <NEWLINE> if not isprime ( p ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> a = [ as_int ( x ) % p for x in seq ] <NEWLINE> <NEWLINE> n = len ( a ) <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> return a <NEWLINE> <NEWLINE> <UNTAB> b = n . bit_length ( ) - <NUMBER> <NEWLINE> if n & ( n - <NUMBER> ) : <NEWLINE> <TAB> b += <NUMBER> <NEWLINE> n = <NUMBER> ** b <NEWLINE> <NEWLINE> <UNTAB> if ( p - <NUMBER> ) % n : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> a += [ <NUMBER> ] * ( n - len ( a ) ) <NEWLINE> for i in range ( <NUMBER> , n ) : <NEWLINE> <TAB> j = int ( ibin ( i , b , str = True ) [ : : - <NUMBER> ] , <NUMBER> ) <NEWLINE> if i < j : <NEWLINE> <TAB> a [ i ] , a [ j ] = a [ j ] , a [ i ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> pr = primitive_root ( p ) <NEWLINE> <NEWLINE> rt = pow ( pr , ( p - <NUMBER> ) // n , p ) <NEWLINE> if inverse : <NEWLINE> <TAB> rt = pow ( rt , p - <NUMBER> , p ) <NEWLINE> <NEWLINE> <UNTAB> w = [ <NUMBER> ] * ( n // <NUMBER> ) <NEWLINE> for i in range ( <NUMBER> , n // <NUMBER> ) : <NEWLINE> <TAB> w [ i ] = w [ i - <NUMBER> ] * rt % p <NEWLINE> <NEWLINE> <UNTAB> h = <NUMBER> <NEWLINE> while h <= n : <NEWLINE> <TAB> hf , ut = h // <NUMBER> , n // h <NEWLINE> for i in range ( <NUMBER> , n , h ) : <NEWLINE> <TAB> for j in range ( hf ) : <NEWLINE> <TAB> u , v = a [ i + j ] , a [ i + j + hf ] * w [ ut * j ] <NEWLINE> a [ i + j ] , a [ i + j + hf ] = ( u + v ) % p , ( u - v ) % p <NEWLINE> <UNTAB> <UNTAB> h *= <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> if inverse : <NEWLINE> <TAB> rv = pow ( n , p - <NUMBER> , p ) <NEWLINE> a = [ x * rv % p for x in a ] <NEWLINE> <NEWLINE> <UNTAB> return a <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _shard_sizes ( cls , dims , num_shards ) : <NEWLINE> <TAB> <NEWLINE> shard_size , residual = divmod ( dims , num_shards ) <NEWLINE> return [ shard_size + <NUMBER> ] * residual + [ shard_size ] * ( num_shards - residual ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_left ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . left <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def after_create_session ( self , session , coord ) : <NEWLINE> <TAB> <NEWLINE> if ops . get_collection ( ops . GraphKeys . SAVEABLE_OBJECTS ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> self . _var_name_to_train_var = { <NEWLINE> v . name : v for v in ops . get_collection ( ops . GraphKeys . GLOBAL_VARIABLES ) <NEWLINE> } <NEWLINE> var_names_to_transfer = set ( self . _var_name_to_placeholder . keys ( ) ) & set ( <NEWLINE> self . _var_name_to_train_var . keys ( ) ) <NEWLINE> <NEWLINE> self . _var_name_to_train_var = { <NEWLINE> v_name : self . _var_name_to_train_var [ v_name ] <NEWLINE> for v_name in var_names_to_transfer <NEWLINE> } <NEWLINE> <NEWLINE> self . _var_name_to_eval_var = { <NEWLINE> v_name : self . _var_name_to_eval_var [ v_name ] <NEWLINE> for v_name in var_names_to_transfer <NEWLINE> } <NEWLINE> <NEWLINE> with self . _graph . as_default ( ) : <NEWLINE> <TAB> self . _var_feed_op = control_flow_ops . group ( [ <NEWLINE> state_ops . assign ( self . _var_name_to_eval_var [ v_name ] , <NEWLINE> self . _var_name_to_placeholder [ v_name ] ) <NEWLINE> for v_name in var_names_to_transfer <NEWLINE> ] ) <NEWLINE> <NEWLINE> <UNTAB> self . _evaluate ( session ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def prec_to_dps ( n ) : <NEWLINE> <TAB> <NEWLINE> return max ( <NUMBER> , int ( round ( int ( n ) / <NUMBER> ) - <NUMBER> ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def diag ( diagonal , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , diagonal = diagonal , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , diagonal ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return diag_eager_fallback ( <NEWLINE> diagonal , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def div ( self , other ) : <NEWLINE> <TAB> <NEWLINE> quo , rem = dict ( self . factors ) , { } <NEWLINE> <NEWLINE> if not isinstance ( other , Factors ) : <NEWLINE> <TAB> other = Factors ( other ) <NEWLINE> if other . is_zero : <NEWLINE> <TAB> raise ZeroDivisionError <NEWLINE> <UNTAB> if self . is_zero : <NEWLINE> <TAB> return ( Factors ( S . Zero ) , Factors ( ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for factor , exp in other . factors . items ( ) : <NEWLINE> <TAB> if factor in quo : <NEWLINE> <TAB> d = quo [ factor ] - exp <NEWLINE> if _isnumber ( d ) : <NEWLINE> <TAB> if d <= <NUMBER> : <NEWLINE> <TAB> del quo [ factor ] <NEWLINE> <NEWLINE> <UNTAB> if d >= <NUMBER> : <NEWLINE> <TAB> if d : <NEWLINE> <TAB> quo [ factor ] = d <NEWLINE> <NEWLINE> <UNTAB> continue <NEWLINE> <NEWLINE> <UNTAB> exp = - d <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> r = quo [ factor ] . extract_additively ( exp ) <NEWLINE> if r is not None : <NEWLINE> <TAB> if r : <NEWLINE> <TAB> quo [ factor ] = r <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> del quo [ factor ] <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> other_exp = exp <NEWLINE> sc , sa = quo [ factor ] . as_coeff_Add ( ) <NEWLINE> if sc : <NEWLINE> <TAB> oc , oa = other_exp . as_coeff_Add ( ) <NEWLINE> diff = sc - oc <NEWLINE> if diff > <NUMBER> : <NEWLINE> <TAB> quo [ factor ] -= oc <NEWLINE> other_exp = oa <NEWLINE> <UNTAB> elif diff < <NUMBER> : <NEWLINE> <TAB> quo [ factor ] -= sc <NEWLINE> other_exp = oa - diff <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> quo [ factor ] = sa <NEWLINE> other_exp = oa <NEWLINE> <UNTAB> <UNTAB> if other_exp : <NEWLINE> <TAB> rem [ factor ] = other_exp <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> assert factor not in rem <NEWLINE> <UNTAB> <UNTAB> continue <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> rem [ factor ] = exp <NEWLINE> <NEWLINE> <UNTAB> return Factors ( quo ) , Factors ( rem ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def winfo_containing ( self , rootX , rootY , displayof = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> args = ( <STRING> , <STRING> ) + self . _displayof ( displayof ) + ( rootX , rootY ) <NEWLINE> name = self . tk . call ( args ) <NEWLINE> if not name : return None <NEWLINE> return self . _nametowidget ( name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_zz_zassenhaus ( f , K ) : <NEWLINE> <TAB> <NEWLINE> n = dup_degree ( f ) <NEWLINE> <NEWLINE> if n == <NUMBER> : <NEWLINE> <TAB> return [ f ] <NEWLINE> <NEWLINE> <UNTAB> fc = f [ - <NUMBER> ] <NEWLINE> A = dup_max_norm ( f , K ) <NEWLINE> b = dup_LC ( f , K ) <NEWLINE> B = int ( abs ( K . sqrt ( K ( n + <NUMBER> ) ) * <NUMBER> ** n * A * b ) ) <NEWLINE> C = int ( ( n + <NUMBER> ) ** ( <NUMBER> * n ) * A ** ( <NUMBER> * n - <NUMBER> ) ) <NEWLINE> gamma = int ( _ceil ( <NUMBER> * _log ( C , <NUMBER> ) ) ) <NEWLINE> bound = int ( <NUMBER> * gamma * _log ( gamma ) ) <NEWLINE> a = [ ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for px in range ( <NUMBER> , bound + <NUMBER> ) : <NEWLINE> <TAB> if not isprime ( px ) or b % px == <NUMBER> : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> px = K . convert ( px ) <NEWLINE> <NEWLINE> F = gf_from_int_poly ( f , px ) <NEWLINE> <NEWLINE> if not gf_sqf_p ( F , px , K ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> fsqfx = gf_factor_sqf ( F , px , K ) [ <NUMBER> ] <NEWLINE> a . append ( ( px , fsqfx ) ) <NEWLINE> if len ( fsqfx ) < <NUMBER> or len ( a ) > <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> p , fsqf = min ( a , key = lambda x : len ( x [ <NUMBER> ] ) ) <NEWLINE> <NEWLINE> l = int ( _ceil ( _log ( <NUMBER> * B + <NUMBER> , p ) ) ) <NEWLINE> <NEWLINE> modular = [ gf_to_int_poly ( ff , p ) for ff in fsqf ] <NEWLINE> <NEWLINE> g = dup_zz_hensel_lift ( p , f , modular , l , K ) <NEWLINE> <NEWLINE> sorted_T = range ( len ( g ) ) <NEWLINE> T = set ( sorted_T ) <NEWLINE> factors , s = [ ] , <NUMBER> <NEWLINE> pl = p ** l <NEWLINE> <NEWLINE> while <NUMBER> * s <= len ( T ) : <NEWLINE> <TAB> for S in subsets ( sorted_T , s ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if b == <NUMBER> : <NEWLINE> <TAB> q = <NUMBER> <NEWLINE> for i in S : <NEWLINE> <TAB> q = q * g [ i ] [ - <NUMBER> ] <NEWLINE> <UNTAB> q = q % pl <NEWLINE> if not _test_pl ( fc , q , pl ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> G = [ b ] <NEWLINE> for i in S : <NEWLINE> <TAB> G = dup_mul ( G , g [ i ] , K ) <NEWLINE> <UNTAB> G = dup_trunc ( G , pl , K ) <NEWLINE> G = dup_primitive ( G , K ) [ <NUMBER> ] <NEWLINE> q = G [ - <NUMBER> ] <NEWLINE> if q and fc % q != <NUMBER> : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> H = [ b ] <NEWLINE> S = set ( S ) <NEWLINE> T_S = T - S <NEWLINE> <NEWLINE> if b == <NUMBER> : <NEWLINE> <TAB> G = [ b ] <NEWLINE> for i in S : <NEWLINE> <TAB> G = dup_mul ( G , g [ i ] , K ) <NEWLINE> <UNTAB> G = dup_trunc ( G , pl , K ) <NEWLINE> <NEWLINE> <UNTAB> for i in T_S : <NEWLINE> <TAB> H = dup_mul ( H , g [ i ] , K ) <NEWLINE> <NEWLINE> <UNTAB> H = dup_trunc ( H , pl , K ) <NEWLINE> <NEWLINE> G_norm = dup_l1_norm ( G , K ) <NEWLINE> H_norm = dup_l1_norm ( H , K ) <NEWLINE> <NEWLINE> if G_norm * H_norm <= B : <NEWLINE> <TAB> T = T_S <NEWLINE> sorted_T = [ i for i in sorted_T if i not in S ] <NEWLINE> <NEWLINE> G = dup_primitive ( G , K ) [ <NUMBER> ] <NEWLINE> f = dup_primitive ( H , K ) [ <NUMBER> ] <NEWLINE> <NEWLINE> factors . append ( G ) <NEWLINE> b = dup_LC ( f , K ) <NEWLINE> <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> s += <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return factors + [ f ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def issubdtype ( arg1 , arg2 ) : <NEWLINE> <TAB> <NEWLINE> if not issubclass_ ( arg1 , generic ) : <NEWLINE> <TAB> arg1 = dtype ( arg1 ) . type <NEWLINE> <UNTAB> if not issubclass_ ( arg2 , generic ) : <NEWLINE> <TAB> arg2_orig = arg2 <NEWLINE> arg2 = dtype ( arg2 ) . type <NEWLINE> if not isinstance ( arg2_orig , dtype ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> mro = arg2 . mro ( ) <NEWLINE> arg2 = mro [ <NUMBER> ] if len ( mro ) > <NUMBER> else mro [ <NUMBER> ] <NEWLINE> <NEWLINE> def type_repr ( x ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( x , type ) : <NEWLINE> <TAB> return repr ( x ) <NEWLINE> <UNTAB> elif issubclass ( x , generic ) : <NEWLINE> <TAB> return <STRING> . format ( x . __name__ ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return x . __name__ <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( <NEWLINE> raw = type_repr ( arg2_orig ) , <NEWLINE> abstract = type_repr ( arg2 ) , <NEWLINE> concrete = type_repr ( dtype ( arg2_orig ) . type ) <NEWLINE> ) , <NEWLINE> FutureWarning , stacklevel = <NUMBER> <NEWLINE> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return issubclass ( arg1 , arg2 ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def elemwise ( op , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> out = kwargs . pop ( <STRING> , None ) <NEWLINE> if not set ( [ <STRING> , <STRING> ] ) . issuperset ( kwargs ) : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise TypeError ( msg % ( op . __name__ , str ( sorted ( set ( kwargs ) - set ( [ <STRING> , <STRING> ] ) ) ) ) ) <NEWLINE> <NEWLINE> <UNTAB> args = [ np . asarray ( a ) if isinstance ( a , ( list , tuple ) ) else a for a in args ] <NEWLINE> <NEWLINE> shapes = [ ] <NEWLINE> for arg in args : <NEWLINE> <TAB> shape = getattr ( arg , <STRING> , ( ) ) <NEWLINE> if any ( is_dask_collection ( x ) for x in shape ) : <NEWLINE> <NEWLINE> <TAB> shape = ( ) <NEWLINE> <UNTAB> shapes . append ( shape ) <NEWLINE> <NEWLINE> <UNTAB> shapes = [ s if isinstance ( s , Iterable ) else ( ) for s in shapes ] <NEWLINE> out_ndim = len ( broadcast_shapes ( * shapes ) ) <NEWLINE> expr_inds = tuple ( range ( out_ndim ) ) [ : : - <NUMBER> ] <NEWLINE> <NEWLINE> need_enforce_dtype = False <NEWLINE> if <STRING> in kwargs : <NEWLINE> <TAB> dt = kwargs [ <STRING> ] <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> vals = [ np . empty ( ( <NUMBER> , ) * max ( <NUMBER> , a . ndim ) , dtype = a . dtype ) <NEWLINE> if not is_scalar_for_elemwise ( a ) else a <NEWLINE> for a in args ] <NEWLINE> try : <NEWLINE> <TAB> dt = apply_infer_dtype ( op , vals , { } , <STRING> , suggest_dtype = False ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> return NotImplemented <NEWLINE> <UNTAB> need_enforce_dtype = any ( not is_scalar_for_elemwise ( a ) and a . ndim == <NUMBER> for a in args ) <NEWLINE> <NEWLINE> <UNTAB> name = kwargs . get ( <STRING> , None ) or <STRING> % ( funcname ( op ) , <NEWLINE> tokenize ( op , dt , * args ) ) <NEWLINE> <NEWLINE> atop_kwargs = dict ( dtype = dt , name = name , token = funcname ( op ) . strip ( <STRING> ) ) <NEWLINE> if need_enforce_dtype : <NEWLINE> <TAB> atop_kwargs [ <STRING> ] = dt <NEWLINE> atop_kwargs [ <STRING> ] = op <NEWLINE> op = _enforce_dtype <NEWLINE> <UNTAB> result = atop ( op , expr_inds , <NEWLINE> * concat ( ( a , tuple ( range ( a . ndim ) [ : : - <NUMBER> ] ) <NEWLINE> if not is_scalar_for_elemwise ( a ) <NEWLINE> else None ) for a in args ) , <NEWLINE> ** atop_kwargs ) <NEWLINE> <NEWLINE> return handle_out ( out , result ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def gcd ( self , a , b ) : <NEWLINE> <TAB> <NEWLINE> return self . one <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def deformable_convolution_2d_sampler ( x , offset , W , b = None , stride = <NUMBER> , pad = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> sy , sx = _pair ( stride ) <NEWLINE> ph , pw = _pair ( pad ) <NEWLINE> out_c , _ , kh , kw = W . shape <NEWLINE> n , c , h , w = x . shape <NEWLINE> _ , khkw2 , out_h , out_w = offset . shape <NEWLINE> <NEWLINE> if khkw2 != <NUMBER> * kh * kw : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> grid = _offset2grid ( offset , kh , kw , sy , sx , ph , pw , h , w ) <NEWLINE> grid = grid . reshape ( n , <NUMBER> , kh * kw , out_h * out_w ) <NEWLINE> x_pad = pad_module . pad ( x , ( ( <NUMBER> , <NUMBER> ) , ( <NUMBER> , <NUMBER> ) , ( ph , ph ) , ( pw , pw ) ) , <STRING> ) <NEWLINE> x_st = spatial_transformer_sampler . spatial_transformer_sampler ( <NEWLINE> x_pad , grid ) <NEWLINE> <NEWLINE> x_st = x_st . transpose ( <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) . reshape ( n * out_h * out_w , c * kh * kw ) <NEWLINE> W = W . transpose ( <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) . reshape ( c * kh * kw , out_c ) <NEWLINE> y = matmul . matmul ( x_st , W ) <NEWLINE> y = y . reshape ( n , out_h , out_w , out_c ) . transpose ( <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> <NEWLINE> if b is not None : <NEWLINE> <TAB> b = broadcast . broadcast_to ( b [ None , : , None , None ] , y . shape ) <NEWLINE> y += b <NEWLINE> <UNTAB> return y <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def unit_regular_star ( cls , numVertices , innerCircle = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if numVertices <= <NUMBER> : <NEWLINE> <TAB> path = cls . _unit_regular_stars . get ( ( numVertices , innerCircle ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> path = None <NEWLINE> <UNTAB> if path is None : <NEWLINE> <TAB> ns2 = numVertices * <NUMBER> <NEWLINE> theta = ( <NUMBER> * np . pi / ns2 * np . arange ( ns2 + <NUMBER> ) ) <NEWLINE> <NEWLINE> <NEWLINE> theta += np . pi / <NUMBER> <NEWLINE> r = np . ones ( ns2 + <NUMBER> ) <NEWLINE> r [ <NUMBER> : : <NUMBER> ] = innerCircle <NEWLINE> verts = np . vstack ( ( r * np . cos ( theta ) , r * np . sin ( theta ) ) ) . transpose ( ) <NEWLINE> codes = np . empty ( ( ns2 + <NUMBER> , ) ) <NEWLINE> codes [ <NUMBER> ] = cls . MOVETO <NEWLINE> codes [ <NUMBER> : - <NUMBER> ] = cls . LINETO <NEWLINE> codes [ - <NUMBER> ] = cls . CLOSEPOLY <NEWLINE> path = cls ( verts , codes , readonly = True ) <NEWLINE> if numVertices <= <NUMBER> : <NEWLINE> <TAB> cls . _unit_regular_stars [ ( numVertices , innerCircle ) ] = path <NEWLINE> <UNTAB> <UNTAB> return path <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def eval ( self , expr , assumptions = True ) : <NEWLINE> <TAB> <NEWLINE> res , _res = None , None <NEWLINE> mro = inspect . getmro ( type ( expr ) ) <NEWLINE> for handler in self . handlers : <NEWLINE> <TAB> cls = get_class ( handler ) <NEWLINE> for subclass in mro : <NEWLINE> <TAB> try : <NEWLINE> <TAB> eval = getattr ( cls , subclass . __name__ ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> res = eval ( expr , assumptions ) <NEWLINE> <NEWLINE> <NEWLINE> if res is None : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> if _res is None : <NEWLINE> <TAB> _res = res <NEWLINE> <UNTAB> elif res is None : <NEWLINE> <NEWLINE> <TAB> res = _res <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> if _res != res : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> break <NEWLINE> <UNTAB> <UNTAB> return res <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_sub_ground ( f , c , u , K ) : <NEWLINE> <TAB> <NEWLINE> return dmp_sub_term ( f , dmp_ground ( c , u - <NUMBER> ) , <NUMBER> , u , K ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def focus_displayof ( self ) : <NEWLINE> <TAB> <NEWLINE> name = self . tk . call ( <STRING> , <STRING> , self . _w ) <NEWLINE> if name == <STRING> or not name : return None <NEWLINE> return self . _nametowidget ( name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _create_blocks ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> obj , index = self . _convert_freq ( ) <NEWLINE> if index is not None : <NEWLINE> <TAB> index = self . _on <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . on is not None : <NEWLINE> <TAB> if obj . ndim == <NUMBER> : <NEWLINE> <TAB> obj = obj . reindex ( columns = obj . columns . difference ( [ self . on ] ) , <NEWLINE> copy = False ) <NEWLINE> <UNTAB> <UNTAB> blocks = obj . _to_dict_of_blocks ( copy = False ) . values ( ) <NEWLINE> <NEWLINE> return blocks , obj , index <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def bellman_ford_path_length ( G , source , target , weight = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if source == target : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> weight = _weight_function ( G , weight ) <NEWLINE> <NEWLINE> length = _bellman_ford ( G , [ source ] , weight , target = target ) <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> return length [ target ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> raise nx . NetworkXNoPath ( <NEWLINE> <STRING> % ( source , target ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_weights ( self ) : <NEWLINE> <TAB> <NEWLINE> return K . batch_get_value ( self . weights ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def half_gcdex ( f , g , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> options . allowed_flags ( args , [ <STRING> , <STRING> ] ) <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> ( F , G ) , opt = parallel_poly_from_expr ( ( f , g ) , * gens , ** args ) <NEWLINE> <UNTAB> except PolificationFailed as exc : <NEWLINE> <TAB> domain , ( a , b ) = construct_domain ( exc . exprs ) <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> s , h = domain . half_gcdex ( a , b ) <NEWLINE> <UNTAB> except NotImplementedError : <NEWLINE> <TAB> raise ComputationFailed ( <STRING> , <NUMBER> , exc ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return domain . to_sympy ( s ) , domain . to_sympy ( h ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> s , h = F . half_gcdex ( G , auto = opt . auto ) <NEWLINE> <NEWLINE> if not opt . polys : <NEWLINE> <TAB> return s . as_expr ( ) , h . as_expr ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return s , h <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def who ( vardict = None ) : <NEWLINE> <TAB> <NEWLINE> if vardict is None : <NEWLINE> <TAB> frame = sys . _getframe ( ) . f_back <NEWLINE> vardict = frame . f_globals <NEWLINE> <UNTAB> sta = [ ] <NEWLINE> cache = { } <NEWLINE> for name in vardict . keys ( ) : <NEWLINE> <TAB> if isinstance ( vardict [ name ] , ndarray ) : <NEWLINE> <TAB> var = vardict [ name ] <NEWLINE> idv = id ( var ) <NEWLINE> if idv in cache . keys ( ) : <NEWLINE> <TAB> namestr = name + <STRING> % cache [ idv ] <NEWLINE> original = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cache [ idv ] = name <NEWLINE> namestr = name <NEWLINE> original = <NUMBER> <NEWLINE> <UNTAB> shapestr = <STRING> . join ( map ( str , var . shape ) ) <NEWLINE> bytestr = str ( var . nbytes ) <NEWLINE> sta . append ( [ namestr , shapestr , bytestr , var . dtype . name , <NEWLINE> original ] ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> maxname = <NUMBER> <NEWLINE> maxshape = <NUMBER> <NEWLINE> maxbyte = <NUMBER> <NEWLINE> totalbytes = <NUMBER> <NEWLINE> for k in range ( len ( sta ) ) : <NEWLINE> <TAB> val = sta [ k ] <NEWLINE> if maxname < len ( val [ <NUMBER> ] ) : <NEWLINE> <TAB> maxname = len ( val [ <NUMBER> ] ) <NEWLINE> <UNTAB> if maxshape < len ( val [ <NUMBER> ] ) : <NEWLINE> <TAB> maxshape = len ( val [ <NUMBER> ] ) <NEWLINE> <UNTAB> if maxbyte < len ( val [ <NUMBER> ] ) : <NEWLINE> <TAB> maxbyte = len ( val [ <NUMBER> ] ) <NEWLINE> <UNTAB> if val [ <NUMBER> ] : <NEWLINE> <TAB> totalbytes += int ( val [ <NUMBER> ] ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if len ( sta ) > <NUMBER> : <NEWLINE> <TAB> sp1 = max ( <NUMBER> , maxname ) <NEWLINE> sp2 = max ( <NUMBER> , maxshape ) <NEWLINE> sp3 = max ( <NUMBER> , maxbyte ) <NEWLINE> prval = <STRING> % ( sp1 * <STRING> , sp2 * <STRING> , sp3 * <STRING> ) <NEWLINE> print ( prval + <STRING> + <STRING> * ( len ( prval ) + <NUMBER> ) + <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> for k in range ( len ( sta ) ) : <NEWLINE> <TAB> val = sta [ k ] <NEWLINE> print ( <STRING> % ( val [ <NUMBER> ] , <STRING> * ( sp1 - len ( val [ <NUMBER> ] ) + <NUMBER> ) , <NEWLINE> val [ <NUMBER> ] , <STRING> * ( sp2 - len ( val [ <NUMBER> ] ) + <NUMBER> ) , <NEWLINE> val [ <NUMBER> ] , <STRING> * ( sp3 - len ( val [ <NUMBER> ] ) + <NUMBER> ) , <NEWLINE> val [ <NUMBER> ] ) ) <NEWLINE> <UNTAB> print ( <STRING> % totalbytes ) <NEWLINE> return <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def label ( self , name ) : <NEWLINE> <TAB> <NEWLINE> return self . as_scalar ( ) . label ( name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_rng_state_all ( ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> results = [ ] <NEWLINE> for i in range ( device_count ( ) ) : <NEWLINE> <TAB> with device_ctx_manager ( i ) : <NEWLINE> <TAB> results . append ( get_rng_state ( ) ) <NEWLINE> <UNTAB> <UNTAB> return results <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def render ( self , x , y ) : <NEWLINE> <TAB> <NEWLINE> self . font_output . render_glyph ( <NEWLINE> x - self . _metrics . xmin , y + self . _metrics . ymin , <NEWLINE> self . font , self . font_class , self . c , self . fontsize , self . dpi ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def infer_dtype_from_array ( arr , pandas_dtype = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( arr , np . ndarray ) : <NEWLINE> <TAB> return arr . dtype , arr <NEWLINE> <NEWLINE> <UNTAB> if not is_list_like ( arr ) : <NEWLINE> <TAB> arr = [ arr ] <NEWLINE> <NEWLINE> <UNTAB> if pandas_dtype and is_extension_type ( arr ) : <NEWLINE> <TAB> return arr . dtype , arr <NEWLINE> <NEWLINE> <UNTAB> elif isinstance ( arr , ABCSeries ) : <NEWLINE> <TAB> return arr . dtype , np . asarray ( arr ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> inferred = lib . infer_dtype ( arr ) <NEWLINE> if inferred in [ <STRING> , <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> ] : <NEWLINE> <TAB> return ( np . object_ , arr ) <NEWLINE> <NEWLINE> <UNTAB> arr = np . asarray ( arr ) <NEWLINE> return arr . dtype , arr <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def terminate ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _popen . terminate ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def expm_cond ( A , check_finite = True ) : <NEWLINE> <TAB> <NEWLINE> if check_finite : <NEWLINE> <TAB> A = np . asarray_chkfinite ( A ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> A = np . asarray ( A ) <NEWLINE> <UNTAB> if len ( A . shape ) != <NUMBER> or A . shape [ <NUMBER> ] != A . shape [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> X = scipy . linalg . expm ( A ) <NEWLINE> K = expm_frechet_kronform ( A , check_finite = False ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> A_norm = scipy . linalg . norm ( A , <STRING> ) <NEWLINE> X_norm = scipy . linalg . norm ( X , <STRING> ) <NEWLINE> K_norm = scipy . linalg . norm ( K , <NUMBER> ) <NEWLINE> <NEWLINE> kappa = ( K_norm * A_norm ) / X_norm <NEWLINE> return kappa <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def bias_add ( value , bias , data_format = <STRING> , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if data_format is None : <NEWLINE> <TAB> data_format = <STRING> <NEWLINE> <UNTAB> data_format = _execute . make_str ( data_format , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , value = value , bias = bias , data_format = data_format , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , value , bias , <STRING> , <NEWLINE> data_format ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return bias_add_eager_fallback ( <NEWLINE> value , bias , data_format = data_format , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def asc ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . operate ( asc_op ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def group_norm ( input , num_groups , weight = None , bias = None , eps = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return torch . group_norm ( input , num_groups , weight , bias , eps , <NEWLINE> torch . backends . cudnn . enabled ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _gf_pow_pnm1d2 ( f , n , g , b , p , K ) : <NEWLINE> <TAB> <NEWLINE> f = gf_rem ( f , g , p , K ) <NEWLINE> h = f <NEWLINE> r = f <NEWLINE> for i in range ( <NUMBER> , n ) : <NEWLINE> <TAB> h = gf_frobenius_map ( h , g , b , p , K ) <NEWLINE> r = gf_mul ( r , h , p , K ) <NEWLINE> r = gf_rem ( r , g , p , K ) <NEWLINE> <NEWLINE> <UNTAB> res = gf_pow_mod ( r , ( p - <NUMBER> ) // <NUMBER> , g , p , K ) <NEWLINE> return res <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def logpmf ( self , x , n , p ) : <NEWLINE> <TAB> <NEWLINE> n , p , npcond = self . _process_parameters ( n , p ) <NEWLINE> x , xcond = self . _process_quantiles ( x , n , p ) <NEWLINE> <NEWLINE> result = self . _logpmf ( x , n , p ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> xcond_ = xcond | np . zeros ( npcond . shape , dtype = np . bool_ ) <NEWLINE> result = self . _checkresult ( result , xcond_ , np . NINF ) <NEWLINE> <NEWLINE> <NEWLINE> npcond_ = npcond | np . zeros ( xcond . shape , dtype = np . bool_ ) <NEWLINE> return self . _checkresult ( result , npcond_ , np . NAN ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def subgraph ( G , nbunch ) : <NEWLINE> <TAB> <NEWLINE> return G . subgraph ( nbunch ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def intersect_trust_region ( x , s , Delta ) : <NEWLINE> <TAB> <NEWLINE> a = np . dot ( s , s ) <NEWLINE> if a == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> b = np . dot ( x , s ) <NEWLINE> <NEWLINE> c = np . dot ( x , x ) - Delta ** <NUMBER> <NEWLINE> if c > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> d = np . sqrt ( b * b - a * c ) <NEWLINE> <NEWLINE> <NEWLINE> q = - ( b + copysign ( d , b ) ) <NEWLINE> t1 = q / a <NEWLINE> t2 = c / q <NEWLINE> <NEWLINE> if t1 < t2 : <NEWLINE> <TAB> return t1 , t2 <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return t2 , t1 <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def softsign ( input ) : <NEWLINE> <TAB> <NEWLINE> return input / ( input . abs ( ) + <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def setup ( self , link ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( link , link_module . Link ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> self . target = link <NEWLINE> self . t = <NUMBER> <NEWLINE> self . epoch = <NUMBER> <NEWLINE> self . _pre_update_hooks = collections . OrderedDict ( ) <NEWLINE> self . _post_update_hooks = collections . OrderedDict ( ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_object ( self , obj ) : <NEWLINE> <TAB> <NEWLINE> if self . is_transposed : <NEWLINE> <TAB> obj = obj . T <NEWLINE> <UNTAB> return obj <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def nullspace ( self , simplify = False , iszerofunc = _iszero ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> reduced , pivots = self . rref ( iszerofunc = iszerofunc , simplify = simplify ) <NEWLINE> <NEWLINE> free_vars = [ i for i in range ( self . cols ) if i not in pivots ] <NEWLINE> <NEWLINE> basis = [ ] <NEWLINE> for free_var in free_vars : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> vec = [ S . Zero ] * self . cols <NEWLINE> vec [ free_var ] = S . One <NEWLINE> for piv_row , piv_col in enumerate ( pivots ) : <NEWLINE> <TAB> vec [ piv_col ] -= reduced [ piv_row , free_var ] <NEWLINE> <UNTAB> basis . append ( vec ) <NEWLINE> <NEWLINE> <UNTAB> return [ self . _new ( self . cols , <NUMBER> , b ) for b in basis ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def mutual_weight ( G , u , v , weight = None ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> a_uv = G [ u ] [ v ] . get ( weight , <NUMBER> ) <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> a_uv = <NUMBER> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> a_vu = G [ v ] [ u ] . get ( weight , <NUMBER> ) <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> a_vu = <NUMBER> <NEWLINE> <UNTAB> return a_uv + a_vu <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _kurtosis ( data ) : <NEWLINE> <TAB> <NEWLINE> data = np . ravel ( data ) <NEWLINE> mu = data . mean ( ) <NEWLINE> m2 = ( ( data - mu ) ** <NUMBER> ) . mean ( ) <NEWLINE> m4 = ( ( data - mu ) ** <NUMBER> ) . mean ( ) <NEWLINE> return m4 / m2 ** <NUMBER> - <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _OverloadAllOperators ( ) : <NEWLINE> <TAB> <NEWLINE> for operator in ops . Tensor . OVERLOADABLE_OPERATORS : <NEWLINE> <TAB> ResourceVariable . _OverloadOperator ( operator ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> setattr ( ResourceVariable , <STRING> , array_ops . _SliceHelperVar ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def fractional_max_pool ( value , pooling_ratio , pseudo_random = False , overlapping = False , deterministic = False , seed = <NUMBER> , seed2 = <NUMBER> , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if not isinstance ( pooling_ratio , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % pooling_ratio ) <NEWLINE> <UNTAB> pooling_ratio = [ _execute . make_float ( _f , <STRING> ) for _f in pooling_ratio ] <NEWLINE> if pseudo_random is None : <NEWLINE> <TAB> pseudo_random = False <NEWLINE> <UNTAB> pseudo_random = _execute . make_bool ( pseudo_random , <STRING> ) <NEWLINE> if overlapping is None : <NEWLINE> <TAB> overlapping = False <NEWLINE> <UNTAB> overlapping = _execute . make_bool ( overlapping , <STRING> ) <NEWLINE> if deterministic is None : <NEWLINE> <TAB> deterministic = False <NEWLINE> <UNTAB> deterministic = _execute . make_bool ( deterministic , <STRING> ) <NEWLINE> if seed is None : <NEWLINE> <TAB> seed = <NUMBER> <NEWLINE> <UNTAB> seed = _execute . make_int ( seed , <STRING> ) <NEWLINE> if seed2 is None : <NEWLINE> <TAB> seed2 = <NUMBER> <NEWLINE> <UNTAB> seed2 = _execute . make_int ( seed2 , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , value = value , pooling_ratio = pooling_ratio , <NEWLINE> pseudo_random = pseudo_random , overlapping = overlapping , <NEWLINE> deterministic = deterministic , seed = seed , seed2 = seed2 , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) , <NEWLINE> <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result = _FractionalMaxPoolOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , value , <NEWLINE> <STRING> , pooling_ratio , <STRING> , pseudo_random , <NEWLINE> <STRING> , overlapping , <STRING> , deterministic , <STRING> , <NEWLINE> seed , <STRING> , seed2 ) <NEWLINE> _result = _FractionalMaxPoolOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return fractional_max_pool_eager_fallback ( <NEWLINE> value , pooling_ratio = pooling_ratio , pseudo_random = pseudo_random , <NEWLINE> overlapping = overlapping , deterministic = deterministic , seed = seed , <NEWLINE> seed2 = seed2 , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ cbook . deprecated ( <STRING> , alternative = <STRING> ) <NEWLINE> def griddata ( x , y , z , xi , yi , interp = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> x = np . asanyarray ( x , dtype = np . float64 ) <NEWLINE> y = np . asanyarray ( y , dtype = np . float64 ) <NEWLINE> z = np . asanyarray ( z , dtype = np . float64 ) <NEWLINE> if x . shape != y . shape or x . shape != z . shape or x . ndim != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> xi = np . asanyarray ( xi , dtype = np . float64 ) <NEWLINE> yi = np . asanyarray ( yi , dtype = np . float64 ) <NEWLINE> if xi . ndim != yi . ndim : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if xi . ndim == <NUMBER> and xi . shape != yi . shape : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if xi . ndim == <NUMBER> : <NEWLINE> <TAB> xi , yi = np . meshgrid ( xi , yi ) <NEWLINE> <NEWLINE> <UNTAB> if interp == <STRING> : <NEWLINE> <TAB> use_nn_interpolation = True <NEWLINE> <UNTAB> elif interp == <STRING> : <NEWLINE> <TAB> use_nn_interpolation = False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> mask = np . ma . getmask ( z ) <NEWLINE> if mask is not np . ma . nomask : <NEWLINE> <TAB> x = x . compress ( ~ mask ) <NEWLINE> y = y . compress ( ~ mask ) <NEWLINE> z = z . compressed ( ) <NEWLINE> <NEWLINE> <UNTAB> if use_nn_interpolation : <NEWLINE> <TAB> try : <NEWLINE> <TAB> from mpl_toolkits . natgrid import _natgrid <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> raise RuntimeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if xi . ndim == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> xi = xi [ <NUMBER> , : ] <NEWLINE> yi = yi [ : , <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> _natgrid . seti ( <STRING> , <NUMBER> ) <NEWLINE> _natgrid . setr ( <STRING> , np . nan ) <NEWLINE> <NEWLINE> if np . min ( np . diff ( xi ) ) < <NUMBER> or np . min ( np . diff ( yi ) ) < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> zi = np . empty ( ( yi . shape [ <NUMBER> ] , xi . shape [ <NUMBER> ] ) , np . float64 ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> x = np . require ( x , requirements = [ <STRING> ] ) <NEWLINE> y = np . require ( y , requirements = [ <STRING> ] ) <NEWLINE> z = np . require ( z , requirements = [ <STRING> ] ) <NEWLINE> xi = np . require ( xi , requirements = [ <STRING> ] ) <NEWLINE> yi = np . require ( yi , requirements = [ <STRING> ] ) <NEWLINE> _natgrid . natgridd ( x , y , z , xi , yi , zi ) <NEWLINE> <NEWLINE> <NEWLINE> if np . any ( np . isnan ( zi ) ) : <NEWLINE> <TAB> zi = np . ma . masked_where ( np . isnan ( zi ) , zi ) <NEWLINE> <UNTAB> return zi <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> from . tri import Triangulation , LinearTriInterpolator <NEWLINE> triang = Triangulation ( x , y ) <NEWLINE> interpolator = LinearTriInterpolator ( triang , z ) <NEWLINE> return interpolator ( xi , yi ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ _preprocess_data ( replace_names = [ <STRING> , <STRING> ] , label_namer = <STRING> ) <NEWLINE> def step ( self , x , y , * args , where = <STRING> , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if where not in ( <STRING> , <STRING> , <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> kwargs [ <STRING> ] = <STRING> + where + kwargs . get ( <STRING> , <STRING> ) <NEWLINE> <NEWLINE> return self . plot ( x , y , * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get ( ind , seq , default = no_default ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return seq [ ind ] <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> if isinstance ( ind , list ) : <NEWLINE> <TAB> if default == no_default : <NEWLINE> <TAB> if len ( ind ) > <NUMBER> : <NEWLINE> <TAB> return operator . itemgetter ( * ind ) ( seq ) <NEWLINE> <UNTAB> elif ind : <NEWLINE> <TAB> return ( seq [ ind [ <NUMBER> ] ] , ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return ( ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return tuple ( _get ( i , seq , default ) for i in ind ) <NEWLINE> <UNTAB> <UNTAB> elif default != no_default : <NEWLINE> <TAB> return default <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise <NEWLINE> <UNTAB> <UNTAB> except ( KeyError , IndexError ) : <NEWLINE> <TAB> if default == no_default : <NEWLINE> <TAB> raise <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return default <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def compute_output_shape ( self , input_shape ) : <NEWLINE> <TAB> <NEWLINE> if context . executing_eagerly ( ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> self . build ( input_shape ) <NEWLINE> <NEWLINE> with context . graph_mode ( ) : <NEWLINE> <TAB> graph = func_graph . FuncGraph ( <STRING> ) <NEWLINE> with graph . as_default ( ) : <NEWLINE> <TAB> if isinstance ( input_shape , list ) : <NEWLINE> <TAB> inputs = [ generate_placeholders_from_shape ( shape ) <NEWLINE> for shape in input_shape ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> inputs = generate_placeholders_from_shape ( input_shape ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> if self . _expects_training_arg : <NEWLINE> <TAB> outputs = self ( inputs , training = False ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> outputs = self ( inputs ) <NEWLINE> <UNTAB> <UNTAB> except TypeError : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % self . __class__ . __name__ ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if isinstance ( outputs , list ) : <NEWLINE> <TAB> return [ output . shape for output in outputs ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return outputs . shape <NEWLINE> <UNTAB> <UNTAB> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def spherical_jn ( n , z , derivative = False ) : <NEWLINE> <TAB> <NEWLINE> if derivative : <NEWLINE> <TAB> return _spherical_jn_d ( n , z ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _spherical_jn ( n , z ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def cov ( m , y = None , rowvar = True , bias = False , ddof = None , fweights = None , aweights = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if fweights is not None : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> if aweights is not None : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if not rowvar and m . shape [ <NUMBER> ] != <NUMBER> : <NEWLINE> <TAB> m = m . T <NEWLINE> <NEWLINE> <UNTAB> if y is not None : <NEWLINE> <TAB> if not rowvar and y . shape [ <NUMBER> ] != <NUMBER> : <NEWLINE> <TAB> y = y . T <NEWLINE> <UNTAB> m = theano . tensor . concatenate ( ( m , y ) , axis = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> if ddof is None : <NEWLINE> <TAB> if not bias : <NEWLINE> <TAB> ddof = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ddof = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> fact = m . shape [ <NUMBER> ] - ddof <NEWLINE> <NEWLINE> m -= m . mean ( axis = <NUMBER> , keepdims = <NUMBER> ) <NEWLINE> c = m . dot ( m . T ) <NEWLINE> c *= theano . tensor . constant ( <NUMBER> ) / fact <NEWLINE> return c . squeeze ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _linear_2eq_order2_type6 ( x , y , t , r , eq ) : <NEWLINE> <TAB> <NEWLINE> C1 , C2 , C3 , C4 = get_numbered_constants ( eq , num = <NUMBER> ) <NEWLINE> k = Symbol ( <STRING> ) <NEWLINE> z = Function ( <STRING> ) <NEWLINE> num , den = cancel ( <NEWLINE> ( r [ <STRING> ] * x ( t ) + r [ <STRING> ] * y ( t ) ) / <NEWLINE> ( r [ <STRING> ] * x ( t ) + r [ <STRING> ] * y ( t ) ) ) . as_numer_denom ( ) <NEWLINE> f = r [ <STRING> ] / num . coeff ( x ( t ) ) <NEWLINE> a1 = num . coeff ( x ( t ) ) <NEWLINE> b1 = num . coeff ( y ( t ) ) <NEWLINE> a2 = den . coeff ( x ( t ) ) <NEWLINE> b2 = den . coeff ( y ( t ) ) <NEWLINE> chareq = k ** <NUMBER> - ( a1 + b2 ) * k + a1 * b2 - a2 * b1 <NEWLINE> k1 , k2 = [ rootof ( chareq , k ) for k in range ( Poly ( chareq ) . degree ( ) ) ] <NEWLINE> z1 = dsolve ( diff ( z ( t ) , t , t ) - k1 * f * z ( t ) ) . rhs <NEWLINE> z2 = dsolve ( diff ( z ( t ) , t , t ) - k2 * f * z ( t ) ) . rhs <NEWLINE> sol1 = ( k1 * z2 - k2 * z1 + a1 * ( z1 - z2 ) ) / ( a2 * ( k1 - k2 ) ) <NEWLINE> sol2 = ( z1 - z2 ) / ( k1 - k2 ) <NEWLINE> return [ Eq ( x ( t ) , sol1 ) , Eq ( y ( t ) , sol2 ) ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def xticks ( ticks = None , labels = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> ax = gca ( ) <NEWLINE> <NEWLINE> if ticks is None and labels is None : <NEWLINE> <TAB> locs = ax . get_xticks ( ) <NEWLINE> labels = ax . get_xticklabels ( ) <NEWLINE> <UNTAB> elif labels is None : <NEWLINE> <TAB> locs = ax . set_xticks ( ticks ) <NEWLINE> labels = ax . get_xticklabels ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> locs = ax . set_xticks ( ticks ) <NEWLINE> labels = ax . set_xticklabels ( labels , ** kwargs ) <NEWLINE> <UNTAB> for l in labels : <NEWLINE> <TAB> l . update ( kwargs ) <NEWLINE> <NEWLINE> <UNTAB> return locs , silent_list ( <STRING> , labels ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _rolling_window ( a , window ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> shape = a . shape [ : - <NUMBER> ] + ( a . shape [ - <NUMBER> ] - window + <NUMBER> , window ) <NEWLINE> strides = a . strides + ( a . strides [ - <NUMBER> ] , ) <NEWLINE> return np . lib . stride_tricks . as_strided ( a , shape = shape , strides = strides ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def stripascii ( string ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> ord_ = ord if sys . version_info [ <NUMBER> ] < <NUMBER> else lambda x : x <NEWLINE> i = len ( string ) <NEWLINE> while i : <NEWLINE> <TAB> i -= <NUMBER> <NEWLINE> if <NUMBER> < ord_ ( string [ i ] ) < <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> i = - <NUMBER> <NEWLINE> <UNTAB> return string [ : i + <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def current_thread ( ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return _active [ get_ident ( ) ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> return _DummyThread ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def not_equal ( x1 , x2 ) : <NEWLINE> <TAB> <NEWLINE> return compare_chararrays ( x1 , x2 , <STRING> , True ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _guarded_task_generation ( self , result_job , func , iterable ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> i = - <NUMBER> <NEWLINE> for i , x in enumerate ( iterable ) : <NEWLINE> <TAB> yield ( result_job , i , func , ( x , ) , { } ) <NEWLINE> <UNTAB> <UNTAB> except Exception as e : <NEWLINE> <TAB> yield ( result_job , i + <NUMBER> , _helper_reraises_exception , ( e , ) , { } ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit ( self , K , y = None ) : <NEWLINE> <TAB> <NEWLINE> K = check_array ( K , dtype = FLOAT_DTYPES ) <NEWLINE> n_samples = K . shape [ <NUMBER> ] <NEWLINE> self . K_fit_rows_ = np . sum ( K , axis = <NUMBER> ) / n_samples <NEWLINE> self . K_fit_all_ = self . K_fit_rows_ . sum ( ) / n_samples <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def is_valid_dtype_n_method ( dtype ) : <NEWLINE> <TAB> <NEWLINE> return ( ( is_numeric_dtype ( dtype ) and not is_complex_dtype ( dtype ) ) or <NEWLINE> needs_i8_conversion ( dtype ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def transpose_axes ( image , axes , asaxes = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> for ax in axes : <NEWLINE> <TAB> if ax not in asaxes : <NEWLINE> <TAB> raise ValueError ( <STRING> % ax ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> shape = image . shape <NEWLINE> for ax in reversed ( asaxes ) : <NEWLINE> <TAB> if ax not in axes : <NEWLINE> <TAB> axes = ax + axes <NEWLINE> shape = ( <NUMBER> , ) + shape <NEWLINE> <UNTAB> <UNTAB> image = image . reshape ( shape ) <NEWLINE> <NEWLINE> image = image . transpose ( [ axes . index ( ax ) for ax in asaxes ] ) <NEWLINE> return image <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def invert ( x , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , x = x , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , x ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return invert_eager_fallback ( <NEWLINE> x , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_coeff_Mul ( self , rational = False ) : <NEWLINE> <TAB> <NEWLINE> coeff , args = self . args [ <NUMBER> ] , self . args [ <NUMBER> : ] <NEWLINE> <NEWLINE> if coeff . is_Number : <NEWLINE> <TAB> if not rational or coeff . is_Rational : <NEWLINE> <TAB> if len ( args ) == <NUMBER> : <NEWLINE> <TAB> return coeff , args [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return coeff , self . _new_rawargs ( * args ) <NEWLINE> <UNTAB> <UNTAB> elif coeff . is_negative : <NEWLINE> <TAB> return S . NegativeOne , self . _new_rawargs ( * ( ( - coeff , ) + args ) ) <NEWLINE> <UNTAB> <UNTAB> return S . One , self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def arbitrary_point ( self , parameter = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if parameter is None : <NEWLINE> <TAB> return Point ( * self . functions ) <NEWLINE> <NEWLINE> <UNTAB> tnew = _symbol ( parameter , self . parameter , real = True ) <NEWLINE> t = self . parameter <NEWLINE> if ( tnew . name != t . name and <NEWLINE> tnew . name in ( f . name for f in self . free_symbols ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % tnew . name ) <NEWLINE> <UNTAB> return Point ( * [ w . subs ( t , tnew ) for w in self . functions ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def apply ( self , func , args = ( ) , kwds = { } ) : <NEWLINE> <TAB> <NEWLINE> assert self . _state == RUN <NEWLINE> return self . apply_async ( func , args , kwds ) . get ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_input_mask_at ( self , node_index ) : <NEWLINE> <TAB> <NEWLINE> return self . _get_node_attribute_at_index ( node_index , <NEWLINE> <STRING> , <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def key_averages ( self ) : <NEWLINE> <TAB> <NEWLINE> stats = defaultdict ( FunctionEventAvg ) <NEWLINE> for evt in self : <NEWLINE> <TAB> stats [ evt . key ] += evt <NEWLINE> <UNTAB> return EventList ( stats . values ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def conjtransp ( self ) : <NEWLINE> <TAB> <NEWLINE> M , N = self . shape <NEWLINE> new = dok_matrix ( ( N , M ) , dtype = self . dtype ) <NEWLINE> dict . update ( new , ( ( ( right , left ) , np . conj ( val ) ) <NEWLINE> for ( left , right ) , val in iteritems ( self ) ) ) <NEWLINE> return new <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def style_to_attributes ( self , levels , style , defaults , name ) : <NEWLINE> <TAB> <NEWLINE> if style is True : <NEWLINE> <TAB> attrdict = dict ( zip ( levels , defaults ) ) <NEWLINE> <UNTAB> elif style and isinstance ( style , dict ) : <NEWLINE> <TAB> attrdict = style <NEWLINE> <UNTAB> elif style : <NEWLINE> <TAB> attrdict = dict ( zip ( levels , style ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> attrdict = { } <NEWLINE> <NEWLINE> <UNTAB> if attrdict : <NEWLINE> <TAB> missing_levels = set ( levels ) - set ( attrdict ) <NEWLINE> if any ( missing_levels ) : <NEWLINE> <TAB> err = <STRING> <NEWLINE> raise ValueError ( err . format ( name , missing_levels ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return attrdict <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sos2tf ( sos ) : <NEWLINE> <TAB> <NEWLINE> sos = np . asarray ( sos ) <NEWLINE> b = [ <NUMBER> ] <NEWLINE> a = [ <NUMBER> ] <NEWLINE> n_sections = sos . shape [ <NUMBER> ] <NEWLINE> for section in range ( n_sections ) : <NEWLINE> <TAB> b = np . polymul ( b , sos [ section , : <NUMBER> ] ) <NEWLINE> a = np . polymul ( a , sos [ section , <NUMBER> : ] ) <NEWLINE> <UNTAB> return b , a <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def ceil ( x ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( x , chainer . variable . Variable ) : <NEWLINE> <TAB> x = x . data <NEWLINE> <UNTAB> xp = backend . get_array_module ( x ) <NEWLINE> return chainer . as_variable ( utils . force_array ( xp . ceil ( x ) , x . dtype ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> def gnmk_random_graph ( n , m , k , seed = None , directed = False ) : <NEWLINE> <TAB> <NEWLINE> G = nx . Graph ( ) <NEWLINE> G = _add_nodes_with_bipartite_label ( G , n , m ) <NEWLINE> if directed : <NEWLINE> <TAB> G = nx . DiGraph ( G ) <NEWLINE> <UNTAB> G . name = <STRING> % ( n , m , k ) <NEWLINE> if n == <NUMBER> or m == <NUMBER> : <NEWLINE> <TAB> return G <NEWLINE> <UNTAB> max_edges = n * m <NEWLINE> if k >= max_edges : <NEWLINE> <TAB> return nx . complete_bipartite_graph ( n , m , create_using = G ) <NEWLINE> <NEWLINE> <UNTAB> top = [ n for n , d in G . nodes ( data = True ) if d [ <STRING> ] == <NUMBER> ] <NEWLINE> bottom = list ( set ( G ) - set ( top ) ) <NEWLINE> edge_count = <NUMBER> <NEWLINE> while edge_count < k : <NEWLINE> <NEWLINE> <TAB> u = seed . choice ( top ) <NEWLINE> v = seed . choice ( bottom ) <NEWLINE> if v in G [ u ] : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> G . add_edge ( u , v ) <NEWLINE> edge_count += <NUMBER> <NEWLINE> <UNTAB> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_yticklabels ( self , labels = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> for ax in self . axes . flat : <NEWLINE> <TAB> if labels is None : <NEWLINE> <TAB> labels = [ l . get_text ( ) for l in ax . get_yticklabels ( ) ] <NEWLINE> <UNTAB> ax . set_yticklabels ( labels , ** kwargs ) <NEWLINE> <UNTAB> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _create_nullsfirst ( cls , column ) : <NEWLINE> <TAB> <NEWLINE> return UnaryExpression ( <NEWLINE> _literal_as_label_reference ( column ) , <NEWLINE> modifier = operators . nullsfirst_op , <NEWLINE> wraps_column_expression = False ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_module_hash ( src_code , key ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> to_hash = [ l . strip ( ) for l in src_code . split ( <STRING> ) ] <NEWLINE> <NEWLINE> if key [ <NUMBER> ] : <NEWLINE> <TAB> to_hash += list ( map ( str , key [ <NUMBER> ] ) ) <NEWLINE> <UNTAB> c_link_key = key [ <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> error_msg = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> assert c_link_key [ <NUMBER> ] == <STRING> , error_msg <NEWLINE> for key_element in c_link_key [ <NUMBER> : ] : <NEWLINE> <TAB> if isinstance ( key_element , tuple ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> to_hash += list ( key_element ) <NEWLINE> <UNTAB> elif isinstance ( key_element , string_types ) : <NEWLINE> <TAB> if ( key_element . startswith ( <STRING> ) or <NEWLINE> key_element . startswith ( <STRING> ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> break <NEWLINE> <UNTAB> elif ( key_element . startswith ( <STRING> ) or <NEWLINE> key_element . startswith ( <STRING> ) ) : <NEWLINE> <TAB> to_hash . append ( key_element ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise AssertionError ( error_msg ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise AssertionError ( error_msg ) <NEWLINE> <UNTAB> <UNTAB> return hash_from_code ( <STRING> . join ( to_hash ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def refine_field ( self , z , triinterpolator = None , subdiv = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if triinterpolator is None : <NEWLINE> <TAB> interp = matplotlib . tri . CubicTriInterpolator ( <NEWLINE> self . _triangulation , z ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if not isinstance ( triinterpolator , <NEWLINE> matplotlib . tri . TriInterpolator ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> interp = triinterpolator <NEWLINE> <NEWLINE> <UNTAB> refi_tri , found_index = self . refine_triangulation ( <NEWLINE> subdiv = subdiv , return_tri_index = True ) <NEWLINE> refi_z = interp . _interpolate_multikeys ( <NEWLINE> refi_tri . x , refi_tri . y , tri_index = found_index ) [ <NUMBER> ] <NEWLINE> return refi_tri , refi_z <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def tree_data ( G , root , attrs = _attrs ) : <NEWLINE> <TAB> <NEWLINE> if G . number_of_nodes ( ) != G . number_of_edges ( ) + <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if not G . is_directed ( ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> id_ = attrs [ <STRING> ] <NEWLINE> children = attrs [ <STRING> ] <NEWLINE> if id_ == children : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> def add_children ( n , G ) : <NEWLINE> <TAB> nbrs = G [ n ] <NEWLINE> if len ( nbrs ) == <NUMBER> : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> children_ = [ ] <NEWLINE> for child in nbrs : <NEWLINE> <TAB> d = dict ( chain ( G . nodes [ child ] . items ( ) , [ ( id_ , child ) ] ) ) <NEWLINE> c = add_children ( child , G ) <NEWLINE> if c : <NEWLINE> <TAB> d [ children ] = c <NEWLINE> <UNTAB> children_ . append ( d ) <NEWLINE> <UNTAB> return children_ <NEWLINE> <NEWLINE> <UNTAB> data = dict ( chain ( G . nodes [ root ] . items ( ) , [ ( id_ , root ) ] ) ) <NEWLINE> data [ children ] = add_children ( root , G ) <NEWLINE> return data <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def from_file ( cls , fid ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> line = fid . readline ( ) . strip ( <STRING> ) <NEWLINE> if not len ( line ) > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % line ) <NEWLINE> <UNTAB> title = line [ : <NUMBER> ] <NEWLINE> key = line [ <NUMBER> : ] <NEWLINE> <NEWLINE> <NEWLINE> line = fid . readline ( ) . strip ( <STRING> ) <NEWLINE> if not len ( line . rstrip ( ) ) >= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % line ) <NEWLINE> <UNTAB> total_nlines = _expect_int ( line [ : <NUMBER> ] ) <NEWLINE> pointer_nlines = _expect_int ( line [ <NUMBER> : <NUMBER> ] ) <NEWLINE> indices_nlines = _expect_int ( line [ <NUMBER> : <NUMBER> ] ) <NEWLINE> values_nlines = _expect_int ( line [ <NUMBER> : <NUMBER> ] ) <NEWLINE> <NEWLINE> rhs_nlines = line [ <NUMBER> : <NUMBER> ] . strip ( ) <NEWLINE> if rhs_nlines == <STRING> : <NEWLINE> <TAB> rhs_nlines = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rhs_nlines = _expect_int ( rhs_nlines ) <NEWLINE> <UNTAB> if not rhs_nlines == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> line = fid . readline ( ) . strip ( <STRING> ) <NEWLINE> if not len ( line ) >= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % line ) <NEWLINE> <NEWLINE> <UNTAB> mxtype_s = line [ : <NUMBER> ] . upper ( ) <NEWLINE> if not len ( mxtype_s ) == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> mxtype = HBMatrixType . from_fortran ( mxtype_s ) <NEWLINE> if mxtype . value_type not in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % mxtype ) <NEWLINE> <UNTAB> if not mxtype . structure == <STRING> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % mxtype ) <NEWLINE> <UNTAB> if not mxtype . storage == <STRING> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if not line [ <NUMBER> : <NUMBER> ] == <STRING> * <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % line ) <NEWLINE> <NEWLINE> <UNTAB> nrows = _expect_int ( line [ <NUMBER> : <NUMBER> ] ) <NEWLINE> ncols = _expect_int ( line [ <NUMBER> : <NUMBER> ] ) <NEWLINE> nnon_zeros = _expect_int ( line [ <NUMBER> : <NUMBER> ] ) <NEWLINE> nelementals = _expect_int ( line [ <NUMBER> : <NUMBER> ] ) <NEWLINE> if not nelementals == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> % nelementals ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> line = fid . readline ( ) . strip ( <STRING> ) <NEWLINE> <NEWLINE> ct = line . split ( ) <NEWLINE> if not len ( ct ) == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % ct ) <NEWLINE> <NEWLINE> <UNTAB> return cls ( title , key , <NEWLINE> total_nlines , pointer_nlines , indices_nlines , values_nlines , <NEWLINE> mxtype , nrows , ncols , nnon_zeros , <NEWLINE> ct [ <NUMBER> ] , ct [ <NUMBER> ] , ct [ <NUMBER> ] , <NEWLINE> rhs_nlines , nelementals ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def kruskal ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> args = list ( map ( np . asarray , args ) ) <NEWLINE> num_groups = len ( args ) <NEWLINE> if num_groups < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> for arg in args : <NEWLINE> <TAB> if arg . size == <NUMBER> : <NEWLINE> <TAB> return KruskalResult ( np . nan , np . nan ) <NEWLINE> <UNTAB> <UNTAB> n = np . asarray ( list ( map ( len , args ) ) ) <NEWLINE> <NEWLINE> if <STRING> in kwargs . keys ( ) : <NEWLINE> <TAB> if kwargs [ <STRING> ] not in ( <STRING> , <STRING> , <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nan_policy = kwargs [ <STRING> ] <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> nan_policy = <STRING> <NEWLINE> <NEWLINE> <UNTAB> contains_nan = False <NEWLINE> for arg in args : <NEWLINE> <TAB> cn = _contains_nan ( arg , nan_policy ) <NEWLINE> if cn [ <NUMBER> ] : <NEWLINE> <TAB> contains_nan = True <NEWLINE> break <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if contains_nan and nan_policy == <STRING> : <NEWLINE> <TAB> for a in args : <NEWLINE> <TAB> a = ma . masked_invalid ( a ) <NEWLINE> <UNTAB> return mstats_basic . kruskal ( * args ) <NEWLINE> <NEWLINE> <UNTAB> if contains_nan and nan_policy == <STRING> : <NEWLINE> <TAB> return KruskalResult ( np . nan , np . nan ) <NEWLINE> <NEWLINE> <UNTAB> alldata = np . concatenate ( args ) <NEWLINE> ranked = rankdata ( alldata ) <NEWLINE> ties = tiecorrect ( ranked ) <NEWLINE> if ties == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> j = np . insert ( np . cumsum ( n ) , <NUMBER> , <NUMBER> ) <NEWLINE> ssbn = <NUMBER> <NEWLINE> for i in range ( num_groups ) : <NEWLINE> <TAB> ssbn += _square_of_sums ( ranked [ j [ i ] : j [ i + <NUMBER> ] ] ) / float ( n [ i ] ) <NEWLINE> <NEWLINE> <UNTAB> totaln = np . sum ( n ) <NEWLINE> h = <NUMBER> / ( totaln * ( totaln + <NUMBER> ) ) * ssbn - <NUMBER> * ( totaln + <NUMBER> ) <NEWLINE> df = num_groups - <NUMBER> <NEWLINE> h /= ties <NEWLINE> <NEWLINE> return KruskalResult ( h , distributions . chi2 . sf ( h , df ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def getcol ( self , j ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> from . csc import csc_matrix <NEWLINE> n = self . shape [ <NUMBER> ] <NEWLINE> if j < <NUMBER> : <NEWLINE> <TAB> j += n <NEWLINE> <UNTAB> if j < <NUMBER> or j >= n : <NEWLINE> <TAB> raise IndexError ( <STRING> ) <NEWLINE> <UNTAB> col_selector = csc_matrix ( ( [ <NUMBER> ] , [ [ j ] , [ <NUMBER> ] ] ) , <NEWLINE> shape = ( n , <NUMBER> ) , dtype = self . dtype ) <NEWLINE> return self * col_selector <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> def biconnected_component_edges ( G ) : <NEWLINE> <TAB> <NEWLINE> for comp in _biconnected_dfs ( G , components = True ) : <NEWLINE> <TAB> yield comp <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def autoscale ( self ) : <NEWLINE> <TAB> <NEWLINE> dmin , dmax = self . datalim_to_dt ( ) <NEWLINE> if dmin > dmax : <NEWLINE> <TAB> dmax , dmin = dmin , dmax <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> dmin , dmax = self . datalim_to_dt ( ) <NEWLINE> <NEWLINE> vmin = dates . date2num ( dmin ) <NEWLINE> vmax = dates . date2num ( dmax ) <NEWLINE> <NEWLINE> return self . nonsingular ( vmin , vmax ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def equation ( self , x = <STRING> , y = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> x = _symbol ( x , real = True ) <NEWLINE> y = _symbol ( y , real = True ) <NEWLINE> t1 = ( x - self . center . x ) ** <NUMBER> <NEWLINE> t2 = ( y - self . center . y ) ** <NUMBER> <NEWLINE> return t1 + t2 - self . major ** <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_input_sparse_tensor ( self , input_tensor ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( input_tensor , sparse_tensor_py . SparseTensor ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if input_tensor . dtype == dtypes . string : <NEWLINE> <TAB> ignore_value = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ignore_value = - <NUMBER> <NEWLINE> <UNTAB> input_tensor = _reshape_real_valued_tensor ( input_tensor , <NUMBER> , self . name ) <NEWLINE> input_tensor = contrib_sparse_ops . dense_to_sparse_tensor ( <NEWLINE> input_tensor , ignore_value = ignore_value ) <NEWLINE> <NEWLINE> <UNTAB> return input_tensor <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def button_release_event ( self , x , y , button , guiEvent = None ) : <NEWLINE> <TAB> <NEWLINE> s = <STRING> <NEWLINE> event = MouseEvent ( s , self , x , y , button , self . _key , guiEvent = guiEvent ) <NEWLINE> self . callbacks . process ( s , event ) <NEWLINE> self . _button = None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def print_global_stats ( ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if config . profiling . destination == <STRING> : <NEWLINE> <TAB> destination_file = sys . stderr <NEWLINE> <UNTAB> elif config . profiling . destination == <STRING> : <NEWLINE> <TAB> destination_file = sys . stdout <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> destination_file = open ( config . profiling . destination , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> print ( <STRING> * <NUMBER> , file = destination_file ) <NEWLINE> print ( <STRING> , <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % <NEWLINE> ( time . time ( ) - theano_imported_time , <NEWLINE> total_fct_exec_time , <NEWLINE> total_graph_opt_time , <NEWLINE> total_time_linker ) , <NEWLINE> file = destination_file ) <NEWLINE> print ( <STRING> * <NUMBER> , file = destination_file ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def pick ( self , * args ) : <NEWLINE> <TAB> <NEWLINE> martist . Artist . pick ( self , args [ <NUMBER> ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _validate_sos ( sos ) : <NEWLINE> <TAB> <NEWLINE> sos = np . atleast_2d ( sos ) <NEWLINE> if sos . ndim != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> n_sections , m = sos . shape <NEWLINE> if m != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if not ( sos [ : , <NUMBER> ] == <NUMBER> ) . all ( ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return sos , n_sections <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def stack_search ( start , expand , mode = <STRING> , build_inv = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if mode not in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> , mode ) <NEWLINE> <UNTAB> rval_set = set ( ) <NEWLINE> rval_list = list ( ) <NEWLINE> if mode == <STRING> : <NEWLINE> <TAB> start_pop = start . popleft <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> start_pop = start . pop <NEWLINE> <UNTAB> expand_inv = { } <NEWLINE> while start : <NEWLINE> <TAB> l = start_pop ( ) <NEWLINE> if id ( l ) not in rval_set : <NEWLINE> <TAB> rval_list . append ( l ) <NEWLINE> rval_set . add ( id ( l ) ) <NEWLINE> expand_l = expand ( l ) <NEWLINE> if expand_l : <NEWLINE> <TAB> if build_inv : <NEWLINE> <TAB> for r in expand_l : <NEWLINE> <TAB> expand_inv . setdefault ( r , [ ] ) . append ( l ) <NEWLINE> <UNTAB> <UNTAB> start . extend ( expand_l ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> assert len ( rval_list ) == len ( rval_set ) <NEWLINE> if build_inv : <NEWLINE> <TAB> return rval_list , expand_inv <NEWLINE> <UNTAB> return rval_list <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def flush ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _fh . flush ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def restore ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if self . G1_node is not None and self . G2_node is not None : <NEWLINE> <TAB> del self . GM . core_1 [ self . G1_node ] <NEWLINE> del self . GM . core_2 [ self . G2_node ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for vector in ( self . GM . in_1 , self . GM . in_2 , self . GM . out_1 , self . GM . out_2 ) : <NEWLINE> <TAB> for node in list ( vector . keys ( ) ) : <NEWLINE> <TAB> if vector [ node ] == self . depth : <NEWLINE> <TAB> del vector [ node ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _quote_arg ( arg ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if <STRING> not in arg and <STRING> in arg : <NEWLINE> <TAB> return <STRING> % arg <NEWLINE> <UNTAB> return arg <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def fake_quant_with_min_max_vars_per_channel_gradient ( gradients , inputs , min , max , num_bits = <NUMBER> , narrow_range = False , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if num_bits is None : <NEWLINE> <TAB> num_bits = <NUMBER> <NEWLINE> <UNTAB> num_bits = _execute . make_int ( num_bits , <STRING> ) <NEWLINE> if narrow_range is None : <NEWLINE> <TAB> narrow_range = False <NEWLINE> <UNTAB> narrow_range = _execute . make_bool ( narrow_range , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , gradients = gradients , <NEWLINE> inputs = inputs , min = min , max = max , num_bits = num_bits , <NEWLINE> narrow_range = narrow_range , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result = _FakeQuantWithMinMaxVarsPerChannelGradientOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , gradients , inputs , min , max , <NEWLINE> <STRING> , num_bits , <STRING> , narrow_range ) <NEWLINE> _result = _FakeQuantWithMinMaxVarsPerChannelGradientOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return fake_quant_with_min_max_vars_per_channel_gradient_eager_fallback ( <NEWLINE> gradients , inputs , min , max , num_bits = num_bits , <NEWLINE> narrow_range = narrow_range , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def moments_coords_central ( coords , center = None , order = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( coords , tuple ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> coords = np . transpose ( coords ) <NEWLINE> <UNTAB> assert_nD ( coords , <NUMBER> ) <NEWLINE> ndim = coords . shape [ <NUMBER> ] <NEWLINE> if center is None : <NEWLINE> <TAB> center = np . mean ( coords , axis = <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> coords = coords . astype ( float ) - center <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> coords = coords [ ... , np . newaxis ] ** np . arange ( order + <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> coords = coords . reshape ( coords . shape + ( <NUMBER> , ) * ( ndim - <NUMBER> ) ) <NEWLINE> <NEWLINE> calc = <NUMBER> <NEWLINE> <NEWLINE> for axis in range ( ndim ) : <NEWLINE> <NEWLINE> <TAB> isolated_axis = coords [ : , axis ] <NEWLINE> <NEWLINE> <NEWLINE> isolated_axis = np . moveaxis ( isolated_axis , <NUMBER> , <NUMBER> + axis ) <NEWLINE> <NEWLINE> <NEWLINE> calc = calc * isolated_axis <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> Mc = np . sum ( calc , axis = <NUMBER> ) <NEWLINE> <NEWLINE> return Mc <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( None , <STRING> ) <NEWLINE> def rnn_decoder ( decoder_inputs , initial_state , cell , scope = None ) : <NEWLINE> <TAB> <NEWLINE> with vs . variable_scope ( scope or <STRING> ) : <NEWLINE> <TAB> states , sampling_states = [ initial_state ] , [ initial_state ] <NEWLINE> outputs , sampling_outputs = [ ] , [ ] <NEWLINE> with ops . name_scope ( <STRING> , values = [ decoder_inputs , initial_state ] ) : <NEWLINE> <TAB> for i , inp in enumerate ( decoder_inputs ) : <NEWLINE> <TAB> if i > <NUMBER> : <NEWLINE> <TAB> vs . get_variable_scope ( ) . reuse_variables ( ) <NEWLINE> <UNTAB> output , new_state = cell ( inp , states [ - <NUMBER> ] ) <NEWLINE> outputs . append ( output ) <NEWLINE> states . append ( new_state ) <NEWLINE> <UNTAB> <UNTAB> with ops . name_scope ( <STRING> , values = [ initial_state ] ) : <NEWLINE> <TAB> for i , _ in enumerate ( decoder_inputs ) : <NEWLINE> <TAB> if i == <NUMBER> : <NEWLINE> <TAB> sampling_outputs . append ( outputs [ i ] ) <NEWLINE> sampling_states . append ( states [ i ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> sampling_output , sampling_state = cell ( sampling_outputs [ - <NUMBER> ] , <NEWLINE> sampling_states [ - <NUMBER> ] ) <NEWLINE> sampling_outputs . append ( sampling_output ) <NEWLINE> sampling_states . append ( sampling_state ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> return outputs , states , sampling_outputs , sampling_states <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_decreasing ( expression , interval = S . Reals , symbol = None ) : <NEWLINE> <TAB> <NEWLINE> return monotonicity_helper ( expression , lambda x : x <= <NUMBER> , interval , symbol ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def can_zoom ( self ) : <NEWLINE> <TAB> <NEWLINE> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def freqs ( b , a , worN = <NUMBER> , plot = None ) : <NEWLINE> <TAB> <NEWLINE> if worN is None : <NEWLINE> <TAB> w = findfreqs ( b , a , <NUMBER> ) <NEWLINE> <UNTAB> elif isinstance ( worN , int ) : <NEWLINE> <TAB> N = worN <NEWLINE> w = findfreqs ( b , a , N ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> w = worN <NEWLINE> <UNTAB> w = atleast_1d ( w ) <NEWLINE> s = <NUMBER> * w <NEWLINE> h = polyval ( b , s ) / polyval ( a , s ) <NEWLINE> if plot is not None : <NEWLINE> <TAB> plot ( w , h ) <NEWLINE> <NEWLINE> <UNTAB> return w , h <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_series ( self , keep_tz = False , index = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> from pandas import Series <NEWLINE> <NEWLINE> if index is None : <NEWLINE> <TAB> index = self . _shallow_copy ( ) <NEWLINE> <UNTAB> if name is None : <NEWLINE> <TAB> name = self . name <NEWLINE> <NEWLINE> <UNTAB> return Series ( self . _to_embed ( keep_tz ) , index = index , name = name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def lbound ( array , dim = None , kind = None ) : <NEWLINE> <TAB> <NEWLINE> return FunctionCall ( <NEWLINE> <STRING> , <NEWLINE> [ _printable ( array ) ] + <NEWLINE> ( [ _printable ( dim ) ] if dim else [ ] ) + <NEWLINE> ( [ _printable ( kind ) ] if kind else [ ] ) <NEWLINE> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def pro_cv_seq ( m , n , c ) : <NEWLINE> <TAB> <NEWLINE> if not ( isscalar ( m ) and isscalar ( n ) and isscalar ( c ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if ( n != floor ( n ) ) or ( m != floor ( m ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if ( n - m > <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> maxL = n - m + <NUMBER> <NEWLINE> return specfun . segv ( m , n , c , <NUMBER> ) [ <NUMBER> ] [ : maxL ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def create_py_random_state ( random_state = None ) : <NEWLINE> <TAB> <NEWLINE> import random <NEWLINE> try : <NEWLINE> <TAB> import numpy as np <NEWLINE> if random_state is np . random : <NEWLINE> <TAB> return PythonRandomInterface ( np . random . mtrand . _rand ) <NEWLINE> <UNTAB> if isinstance ( random_state , np . random . RandomState ) : <NEWLINE> <TAB> return PythonRandomInterface ( random_state ) <NEWLINE> <UNTAB> if isinstance ( random_state , PythonRandomInterface ) : <NEWLINE> <TAB> return random_state <NEWLINE> <UNTAB> has_numpy = True <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> has_numpy = False <NEWLINE> <NEWLINE> <UNTAB> if random_state is None or random_state is random : <NEWLINE> <TAB> return random . _inst <NEWLINE> <UNTAB> if isinstance ( random_state , random . Random ) : <NEWLINE> <TAB> return random_state <NEWLINE> <UNTAB> if isinstance ( random_state , int ) : <NEWLINE> <TAB> return random . Random ( random_state ) <NEWLINE> <UNTAB> msg = <STRING> <NEWLINE> raise ValueError ( msg % random_state ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _test ( * paths , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> verbose = kwargs . get ( <STRING> , False ) <NEWLINE> tb = kwargs . get ( <STRING> , <STRING> ) <NEWLINE> kw = kwargs . get ( <STRING> , None ) or ( ) <NEWLINE> <NEWLINE> if isinstance ( kw , str ) : <NEWLINE> <TAB> kw = ( kw , ) <NEWLINE> <UNTAB> post_mortem = kwargs . get ( <STRING> , False ) <NEWLINE> colors = kwargs . get ( <STRING> , True ) <NEWLINE> force_colors = kwargs . get ( <STRING> , False ) <NEWLINE> sort = kwargs . get ( <STRING> , True ) <NEWLINE> seed = kwargs . get ( <STRING> , None ) <NEWLINE> if seed is None : <NEWLINE> <TAB> seed = random . randrange ( <NUMBER> ) <NEWLINE> <UNTAB> timeout = kwargs . get ( <STRING> , False ) <NEWLINE> fail_on_timeout = kwargs . get ( <STRING> , False ) <NEWLINE> if ON_TRAVIS and timeout is False : <NEWLINE> <NEWLINE> <TAB> timeout = <NUMBER> <NEWLINE> fail_on_timeout = True <NEWLINE> <UNTAB> slow = kwargs . get ( <STRING> , False ) <NEWLINE> enhance_asserts = kwargs . get ( <STRING> , False ) <NEWLINE> split = kwargs . get ( <STRING> , None ) <NEWLINE> time_balance = kwargs . get ( <STRING> , True ) <NEWLINE> blacklist = kwargs . get ( <STRING> , [ <STRING> ] ) <NEWLINE> blacklist = convert_to_native_paths ( blacklist ) <NEWLINE> fast_threshold = kwargs . get ( <STRING> , None ) <NEWLINE> slow_threshold = kwargs . get ( <STRING> , None ) <NEWLINE> r = PyTestReporter ( verbose = verbose , tb = tb , colors = colors , <NEWLINE> force_colors = force_colors , split = split ) <NEWLINE> t = SymPyTests ( r , kw , post_mortem , seed , <NEWLINE> fast_threshold = fast_threshold , <NEWLINE> slow_threshold = slow_threshold ) <NEWLINE> <NEWLINE> <NEWLINE> import sympy . external <NEWLINE> sympy . external . importtools . WARN_OLD_VERSION = False <NEWLINE> sympy . external . importtools . WARN_NOT_INSTALLED = False <NEWLINE> <NEWLINE> <NEWLINE> import warnings <NEWLINE> warnings . simplefilter ( <STRING> , SymPyDeprecationWarning ) <NEWLINE> warnings . filterwarnings ( <STRING> , <STRING> , DeprecationWarning , module = <STRING> ) <NEWLINE> <NEWLINE> test_files = t . get_test_files ( <STRING> ) <NEWLINE> <NEWLINE> not_blacklisted = [ f for f in test_files <NEWLINE> if not any ( b in f for b in blacklist ) ] <NEWLINE> <NEWLINE> if len ( paths ) == <NUMBER> : <NEWLINE> <TAB> matched = not_blacklisted <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> paths = convert_to_native_paths ( paths ) <NEWLINE> matched = [ ] <NEWLINE> for f in not_blacklisted : <NEWLINE> <TAB> basename = os . path . basename ( f ) <NEWLINE> for p in paths : <NEWLINE> <TAB> if p in f or fnmatch ( basename , p ) : <NEWLINE> <TAB> matched . append ( f ) <NEWLINE> break <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> density = None <NEWLINE> if time_balance : <NEWLINE> <TAB> if slow : <NEWLINE> <TAB> density = SPLIT_DENSITY_SLOW <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> density = SPLIT_DENSITY <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if split : <NEWLINE> <TAB> matched = split_list ( matched , split , density = density ) <NEWLINE> <NEWLINE> <UNTAB> t . _testfiles . extend ( matched ) <NEWLINE> <NEWLINE> return int ( not t . test ( sort = sort , timeout = timeout , slow = slow , <NEWLINE> enhance_asserts = enhance_asserts , fail_on_timeout = fail_on_timeout ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __rtruediv__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return true_divide ( other , self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def reroute_ios ( sgv0 , sgv1 ) : <NEWLINE> <TAB> <NEWLINE> return _reroute_sgv ( sgv0 , sgv1 , _RerouteMode . a2b ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _update_line_limits ( self , line ) : <NEWLINE> <TAB> <NEWLINE> path = line . get_path ( ) <NEWLINE> if path . vertices . size == <NUMBER> : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> line_trans = line . get_transform ( ) <NEWLINE> <NEWLINE> if line_trans == self . transData : <NEWLINE> <TAB> data_path = path <NEWLINE> <NEWLINE> <UNTAB> elif any ( line_trans . contains_branch_seperately ( self . transData ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> trans_to_data = line_trans - self . transData <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if self . transData . is_affine : <NEWLINE> <TAB> line_trans_path = line . _get_transformed_path ( ) <NEWLINE> na_path , _ = line_trans_path . get_transformed_path_and_affine ( ) <NEWLINE> data_path = trans_to_data . transform_path_affine ( na_path ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> data_path = trans_to_data . transform_path ( path ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> data_path = path <NEWLINE> <NEWLINE> <UNTAB> if data_path . vertices . size > <NUMBER> : <NEWLINE> <TAB> updatex , updatey = line_trans . contains_branch_seperately ( <NEWLINE> self . transData ) <NEWLINE> self . dataLim . update_from_path ( data_path , <NEWLINE> self . ignore_existing_data_limits , <NEWLINE> updatex = updatex , <NEWLINE> updatey = updatey ) <NEWLINE> self . ignore_existing_data_limits = False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def squared_norm ( x ) : <NEWLINE> <TAB> <NEWLINE> x = np . ravel ( x , order = <STRING> ) <NEWLINE> if np . issubdtype ( x . dtype , np . integer ) : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> , <NEWLINE> UserWarning ) <NEWLINE> <UNTAB> return np . dot ( x , x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _sort_variable_count ( cls , varcounts ) : <NEWLINE> <TAB> <NEWLINE> sorted_vars = [ ] <NEWLINE> symbol_part = [ ] <NEWLINE> non_symbol_part = [ ] <NEWLINE> for ( v , c ) in varcounts : <NEWLINE> <TAB> if not v . is_symbol : <NEWLINE> <TAB> if len ( symbol_part ) > <NUMBER> : <NEWLINE> <TAB> sorted_vars . extend ( sorted ( symbol_part , <NEWLINE> key = lambda i : default_sort_key ( i [ <NUMBER> ] ) ) ) <NEWLINE> symbol_part = [ ] <NEWLINE> <UNTAB> non_symbol_part . append ( ( v , c ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if len ( non_symbol_part ) > <NUMBER> : <NEWLINE> <TAB> sorted_vars . extend ( sorted ( non_symbol_part , <NEWLINE> key = lambda i : default_sort_key ( i [ <NUMBER> ] ) ) ) <NEWLINE> non_symbol_part = [ ] <NEWLINE> <UNTAB> symbol_part . append ( ( v , c ) ) <NEWLINE> <UNTAB> <UNTAB> if len ( non_symbol_part ) > <NUMBER> : <NEWLINE> <TAB> sorted_vars . extend ( sorted ( non_symbol_part , <NEWLINE> key = lambda i : default_sort_key ( i [ <NUMBER> ] ) ) ) <NEWLINE> <UNTAB> if len ( symbol_part ) > <NUMBER> : <NEWLINE> <TAB> sorted_vars . extend ( sorted ( symbol_part , <NEWLINE> key = lambda i : default_sort_key ( i [ <NUMBER> ] ) ) ) <NEWLINE> <UNTAB> return [ Tuple ( * i ) for i in sorted_vars ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , coords ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> out = np . empty_like ( coords , np . double ) <NEWLINE> <NEWLINE> <NEWLINE> simplex = self . _tesselation . find_simplex ( coords ) <NEWLINE> <NEWLINE> <NEWLINE> out [ simplex == - <NUMBER> , : ] = - <NUMBER> <NEWLINE> <NEWLINE> for index in range ( len ( self . _tesselation . vertices ) ) : <NEWLINE> <NEWLINE> <TAB> affine = self . affines [ index ] <NEWLINE> <NEWLINE> index_mask = simplex == index <NEWLINE> <NEWLINE> out [ index_mask , : ] = affine ( coords [ index_mask , : ] ) <NEWLINE> <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _validate ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . tuple_shapes is not None : <NEWLINE> <TAB> for ( policy , shape ) in zip ( self . _sharding_policies , self . _tuple_shapes ) : <NEWLINE> <NEWLINE> <TAB> _ = policy . get_sharded_shape ( shape ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def rollback_twophase ( self , conn , rollback_twophase , xid , is_prepared ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return rollback_twophase ( xid , is_prepared ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def eval ( cls , variable , offset , exponent ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> x = sympify ( variable ) <NEWLINE> a = sympify ( offset ) <NEWLINE> n = sympify ( exponent ) <NEWLINE> shift = ( x - a ) <NEWLINE> <NEWLINE> if fuzzy_not ( im ( shift ) . is_zero ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if fuzzy_not ( im ( n ) . is_zero ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if shift is S . NaN or n is S . NaN : <NEWLINE> <TAB> return S . NaN <NEWLINE> <UNTAB> if ( n + <NUMBER> ) . is_negative : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if shift . is_negative : <NEWLINE> <TAB> return S . Zero <NEWLINE> <UNTAB> if n . is_nonnegative and shift . is_nonnegative : <NEWLINE> <TAB> return ( x - a ) ** n <NEWLINE> <UNTAB> if n == - <NUMBER> or n == - <NUMBER> : <NEWLINE> <TAB> if shift . is_negative or shift . is_positive : <NEWLINE> <TAB> return S . Zero <NEWLINE> <UNTAB> if shift . is_zero : <NEWLINE> <TAB> return S . Infinity <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def predict_on_batch ( self , x ) : <NEWLINE> <TAB> <NEWLINE> if self . _distribution_strategy : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> inputs , _ , _ = self . _standardize_user_data ( x ) <NEWLINE> if context . executing_eagerly ( ) : <NEWLINE> <TAB> if ( isinstance ( x , iterator_ops . EagerIterator ) or <NEWLINE> ( isinstance ( x , dataset_ops . Dataset ) and context . executing_eagerly ( ) ) ) : <NEWLINE> <TAB> inputs = training_utils . cast_if_floating_dtype ( inputs ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> inputs = [ <NEWLINE> ops . convert_to_tensor ( val , dtype = K . floatx ( ) ) for val in inputs <NEWLINE> ] <NEWLINE> <UNTAB> return self ( inputs ) <NEWLINE> <NEWLINE> <UNTAB> if not context . executing_eagerly ( ) : <NEWLINE> <TAB> if self . uses_learning_phase and not isinstance ( K . learning_phase ( ) , int ) : <NEWLINE> <TAB> ins = inputs + [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ins = inputs <NEWLINE> <NEWLINE> <UNTAB> self . _make_predict_function ( ) <NEWLINE> outputs = self . predict_function ( ins ) <NEWLINE> <NEWLINE> if len ( outputs ) == <NUMBER> : <NEWLINE> <TAB> return outputs [ <NUMBER> ] <NEWLINE> <UNTAB> return outputs <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def cartesian ( arrays , out = None ) : <NEWLINE> <TAB> <NEWLINE> arrays = [ np . asarray ( x ) for x in arrays ] <NEWLINE> shape = ( len ( x ) for x in arrays ) <NEWLINE> dtype = arrays [ <NUMBER> ] . dtype <NEWLINE> <NEWLINE> ix = np . indices ( shape ) <NEWLINE> ix = ix . reshape ( len ( arrays ) , - <NUMBER> ) . T <NEWLINE> <NEWLINE> if out is None : <NEWLINE> <TAB> out = np . empty_like ( ix , dtype = dtype ) <NEWLINE> <NEWLINE> <UNTAB> for n , arr in enumerate ( arrays ) : <NEWLINE> <TAB> out [ : , n ] = arrays [ n ] [ ix [ : , n ] ] <NEWLINE> <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _simple_new ( cls , values , name = None , dtype = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if not hasattr ( values , <STRING> ) : <NEWLINE> <TAB> if ( values is None or not len ( values ) ) and dtype is not None : <NEWLINE> <TAB> values = np . empty ( <NUMBER> , dtype = dtype ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> values = np . array ( values , copy = False ) <NEWLINE> if is_object_dtype ( values ) : <NEWLINE> <TAB> values = cls ( values , name = name , dtype = dtype , <NEWLINE> ** kwargs ) . _ndarray_values <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> result = object . __new__ ( cls ) <NEWLINE> result . _data = values <NEWLINE> result . name = name <NEWLINE> for k , v in compat . iteritems ( kwargs ) : <NEWLINE> <TAB> setattr ( result , k , v ) <NEWLINE> <UNTAB> return result . _reset_identity ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def duck_type_collection ( specimen , default = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if hasattr ( specimen , <STRING> ) : <NEWLINE> <NEWLINE> <TAB> if ( specimen . __emulates__ is not None and <NEWLINE> issubclass ( specimen . __emulates__ , set ) ) : <NEWLINE> <TAB> return set <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return specimen . __emulates__ <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> isa = isinstance ( specimen , type ) and issubclass or isinstance <NEWLINE> if isa ( specimen , list ) : <NEWLINE> <TAB> return list <NEWLINE> <UNTAB> elif isa ( specimen , set ) : <NEWLINE> <TAB> return set <NEWLINE> <UNTAB> elif isa ( specimen , dict ) : <NEWLINE> <TAB> return dict <NEWLINE> <NEWLINE> <UNTAB> if hasattr ( specimen , <STRING> ) : <NEWLINE> <TAB> return list <NEWLINE> <UNTAB> elif hasattr ( specimen , <STRING> ) : <NEWLINE> <TAB> return set <NEWLINE> <UNTAB> elif hasattr ( specimen , <STRING> ) : <NEWLINE> <TAB> return dict <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return default <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _prepare ( self ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , opt ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( opt , optimizer . Optimizer ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> self . _opt = opt <NEWLINE> overridden_methods = ( <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> ) <NEWLINE> for name in overridden_methods : <NEWLINE> <TAB> fn = getattr ( self . _opt , name ) <NEWLINE> wrapper = _get_wrapper ( fn , self . _opt ) <NEWLINE> setattr ( self . _opt , name , wrapper ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _is_builtin_func ( self , arg ) : <NEWLINE> <TAB> <NEWLINE> return self . _builtin_table . get ( arg , arg ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _type ( self , dtype = None , non_blocking = False , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> non_blocking = _get_async_or_non_blocking ( <STRING> , non_blocking , kwargs ) <NEWLINE> if dtype is None : <NEWLINE> <TAB> return self . __module__ + <STRING> + self . __class__ . __name__ <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( dtype , str ) : <NEWLINE> <TAB> dtype = _import_dotted_name ( dtype ) <NEWLINE> <UNTAB> if dtype == type ( self ) : <NEWLINE> <TAB> return self <NEWLINE> <UNTAB> if self . is_sparse : <NEWLINE> <TAB> if not dtype . is_sparse : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> new_module_name = dtype . __module__ . replace ( <STRING> , <STRING> ) <NEWLINE> new_values_type_name = new_module_name + <STRING> + dtype . __name__ <NEWLINE> new_values = self . _values ( ) . type ( new_values_type_name , non_blocking ) <NEWLINE> new_indices_type_name = new_module_name + <STRING> <NEWLINE> new_indices = self . _indices ( ) . type ( new_indices_type_name , non_blocking ) <NEWLINE> return dtype ( new_indices , new_values , self . size ( ) ) <NEWLINE> <UNTAB> if dtype . is_sparse : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> return dtype ( self . size ( ) ) . copy_ ( self , non_blocking ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def fresnels_zeros ( nt ) : <NEWLINE> <TAB> <NEWLINE> if ( floor ( nt ) != nt ) or ( nt <= <NUMBER> ) or not isscalar ( nt ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return specfun . fcszo ( <NUMBER> , nt ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def split_at_breaks ( array , breaks , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> padded_breaks = concat ( [ [ None ] , breaks , [ None ] ] ) <NEWLINE> slices = [ slice ( i , j ) for i , j in sliding_window ( <NUMBER> , padded_breaks ) ] <NEWLINE> preslice = ( slice ( None ) , ) * axis <NEWLINE> split_array = [ array [ preslice + ( s , ) ] for s in slices ] <NEWLINE> return split_array <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def polygamma ( n , x ) : <NEWLINE> <TAB> <NEWLINE> n , x = asarray ( n ) , asarray ( x ) <NEWLINE> fac2 = ( - <NUMBER> ) ** ( n + <NUMBER> ) * gamma ( n + <NUMBER> ) * zeta ( n + <NUMBER> , x ) <NEWLINE> return where ( n == <NUMBER> , psi ( x ) , fac2 ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_path ( self ) : <NEWLINE> <TAB> <NEWLINE> codes = [ Path . MOVETO ] <NEWLINE> <NEWLINE> for edge in self . _edges : <NEWLINE> <TAB> if edge in self . _visible_edges : <NEWLINE> <TAB> codes . append ( Path . LINETO ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> codes . append ( Path . MOVETO ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if Path . MOVETO not in codes [ <NUMBER> : ] : <NEWLINE> <TAB> codes [ - <NUMBER> ] = Path . CLOSEPOLY <NEWLINE> <NEWLINE> <UNTAB> return Path ( <NEWLINE> [ [ <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] ] , <NEWLINE> codes , <NEWLINE> readonly = True <NEWLINE> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def indentcount_lines ( lines ) : <NEWLINE> <TAB> <NEWLINE> indentno = sys . maxsize <NEWLINE> for line in lines : <NEWLINE> <TAB> stripped = line . lstrip ( ) <NEWLINE> if stripped : <NEWLINE> <TAB> indentno = min ( indentno , len ( line ) - len ( stripped ) ) <NEWLINE> <UNTAB> <UNTAB> if indentno == sys . maxsize : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> return indentno <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def assert_allclose_dense_sparse ( x , y , rtol = <NUMBER> , atol = <NUMBER> , err_msg = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if sp . sparse . issparse ( x ) and sp . sparse . issparse ( y ) : <NEWLINE> <TAB> x = x . tocsr ( ) <NEWLINE> y = y . tocsr ( ) <NEWLINE> x . sum_duplicates ( ) <NEWLINE> y . sum_duplicates ( ) <NEWLINE> assert_array_equal ( x . indices , y . indices , err_msg = err_msg ) <NEWLINE> assert_array_equal ( x . indptr , y . indptr , err_msg = err_msg ) <NEWLINE> assert_allclose ( x . data , y . data , rtol = rtol , atol = atol , err_msg = err_msg ) <NEWLINE> <UNTAB> elif not sp . sparse . issparse ( x ) and not sp . sparse . issparse ( y ) : <NEWLINE> <NEWLINE> <TAB> assert_allclose ( x , y , rtol = rtol , atol = atol , err_msg = err_msg ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_nest ( f , l , K ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( f , list ) : <NEWLINE> <TAB> return dmp_ground ( f , l ) <NEWLINE> <NEWLINE> <UNTAB> for i in range ( l ) : <NEWLINE> <TAB> f = [ f ] <NEWLINE> <NEWLINE> <UNTAB> return f <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _gen_axes_patch ( self ) : <NEWLINE> <TAB> <NEWLINE> return mpatches . Rectangle ( ( <NUMBER> , <NUMBER> ) , <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def l2_normalize ( x , axis = None ) : <NEWLINE> <TAB> <NEWLINE> return tf . nn . l2_normalize ( x , axis = axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _repr_categories_info ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> category_strs = self . _repr_categories ( ) <NEWLINE> dtype = getattr ( self . categories , <STRING> , <NEWLINE> str ( self . categories . dtype ) ) <NEWLINE> <NEWLINE> levheader = <STRING> . format ( <NEWLINE> length = len ( self . categories ) , dtype = dtype ) <NEWLINE> width , height = get_terminal_size ( ) <NEWLINE> max_width = get_option ( <STRING> ) or width <NEWLINE> if com . in_ipython_frontend ( ) : <NEWLINE> <NEWLINE> <TAB> max_width = <NUMBER> <NEWLINE> <UNTAB> levstring = <STRING> <NEWLINE> start = True <NEWLINE> cur_col_len = len ( levheader ) <NEWLINE> sep_len , sep = ( <NUMBER> , <STRING> ) if self . ordered else ( <NUMBER> , <STRING> ) <NEWLINE> linesep = sep . rstrip ( ) + <STRING> <NEWLINE> for val in category_strs : <NEWLINE> <TAB> if max_width != <NUMBER> and cur_col_len + sep_len + len ( val ) > max_width : <NEWLINE> <TAB> levstring += linesep + ( <STRING> * ( len ( levheader ) + <NUMBER> ) ) <NEWLINE> cur_col_len = len ( levheader ) + <NUMBER> <NEWLINE> <UNTAB> elif not start : <NEWLINE> <TAB> levstring += sep <NEWLINE> cur_col_len += len ( val ) <NEWLINE> <UNTAB> levstring += val <NEWLINE> start = False <NEWLINE> <NEWLINE> <UNTAB> return levheader + <STRING> + levstring . replace ( <STRING> , <STRING> ) + <STRING> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def make_mask ( m , copy = False , shrink = True , dtype = MaskType ) : <NEWLINE> <TAB> <NEWLINE> if m is nomask : <NEWLINE> <TAB> return nomask <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> dtype = make_mask_descr ( dtype ) <NEWLINE> <NEWLINE> <NEWLINE> if isinstance ( m , ndarray ) and m . dtype . fields and dtype == np . bool_ : <NEWLINE> <TAB> return np . ones ( m . shape , dtype = dtype ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> result = np . array ( filled ( m , True ) , copy = copy , dtype = dtype , subok = True ) <NEWLINE> <NEWLINE> if shrink : <NEWLINE> <TAB> result = _shrink_mask ( result ) <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def manual_seed_all ( seed ) : <NEWLINE> <TAB> <NEWLINE> seed = int ( seed ) <NEWLINE> _lazy_call ( lambda : _C . _cuda_manualSeedAll ( seed ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def close ( self ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> self . path_or_buf . close ( ) <NEWLINE> <UNTAB> except IOError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _getdtype ( cls , val ) : <NEWLINE> <TAB> <NEWLINE> return np . array ( val ) . dtype <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def mpf_sub ( s , t , prec = <NUMBER> , rnd = round_fast ) : <NEWLINE> <TAB> <NEWLINE> return mpf_add ( s , t , prec , rnd , <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def string_split_v2 ( source , sep = None , maxsplit = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if sep is None : <NEWLINE> <TAB> sep = <STRING> <NEWLINE> <UNTAB> sep = ops . convert_to_tensor ( sep , dtype = dtypes . string ) <NEWLINE> source = ops . convert_to_tensor ( source , dtype = dtypes . string ) <NEWLINE> <NEWLINE> indices , values , shape = gen_string_ops . string_split_v2 ( <NEWLINE> source , sep = sep , maxsplit = maxsplit ) <NEWLINE> indices . set_shape ( [ None , <NUMBER> ] ) <NEWLINE> values . set_shape ( [ None ] ) <NEWLINE> shape . set_shape ( [ <NUMBER> ] ) <NEWLINE> return sparse_tensor . SparseTensor ( indices , values , shape ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def nunique ( self , dropna = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> obj = self . _selected_obj <NEWLINE> <NEWLINE> def groupby_series ( obj , col = None ) : <NEWLINE> <TAB> return SeriesGroupBy ( obj , <NEWLINE> selection = col , <NEWLINE> grouper = self . grouper ) . nunique ( dropna = dropna ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( obj , Series ) : <NEWLINE> <TAB> results = groupby_series ( obj ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> from pandas . core . reshape . concat import concat <NEWLINE> results = [ groupby_series ( obj [ col ] , col ) for col in obj . columns ] <NEWLINE> results = concat ( results , axis = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> if not self . as_index : <NEWLINE> <TAB> results . index = com . _default_index ( len ( results ) ) <NEWLINE> <UNTAB> return results <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _preprocess_for_cut ( x ) : <NEWLINE> <TAB> <NEWLINE> x_is_series = isinstance ( x , Series ) <NEWLINE> series_index = None <NEWLINE> name = None <NEWLINE> <NEWLINE> if x_is_series : <NEWLINE> <TAB> series_index = x . index <NEWLINE> name = x . name <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> ndim = getattr ( x , <STRING> , None ) <NEWLINE> if ndim is None : <NEWLINE> <TAB> x = np . asarray ( x ) <NEWLINE> <UNTAB> if x . ndim != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return x_is_series , series_index , name , x <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def regular_seeds ( ar_shape , n_points , dtype = int ) : <NEWLINE> <TAB> <NEWLINE> grid = regular_grid ( ar_shape , n_points ) <NEWLINE> seed_img = np . zeros ( ar_shape , dtype = dtype ) <NEWLINE> seed_img [ grid ] = <NUMBER> + np . reshape ( np . arange ( seed_img [ grid ] . size ) , <NEWLINE> seed_img [ grid ] . shape ) <NEWLINE> return seed_img <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dmp_invert ( f , g , u , K ) : <NEWLINE> <TAB> <NEWLINE> if not u : <NEWLINE> <TAB> return dup_invert ( f , g , K ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise MultivariatePolynomialError ( f , g ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fill ( self , value ) : <NEWLINE> <TAB> <NEWLINE> return theano . tensor . basic . fill ( self , value ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ constructor <NEWLINE> def smallest ( * args ) : <NEWLINE> <TAB> <NEWLINE> if len ( args ) == <NUMBER> : <NEWLINE> <TAB> a , b = args <NEWLINE> return switch ( a < b , a , b ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return min ( stack ( args ) , axis = <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def fft ( input , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , input ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return fft_eager_fallback ( <NEWLINE> input , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def can_be_regex ( obj ) : <NEWLINE> <TAB> <NEWLINE> return isinstance ( obj , string_types + ( _RE_TYPE , ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def inherit_docstring_from ( cls ) : <NEWLINE> <TAB> <NEWLINE> def _doc ( func ) : <NEWLINE> <TAB> cls_docstring = getattr ( cls , func . __name__ ) . __doc__ <NEWLINE> func_docstring = func . __doc__ <NEWLINE> if func_docstring is None : <NEWLINE> <TAB> func . __doc__ = cls_docstring <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> new_docstring = func_docstring % dict ( super = cls_docstring ) <NEWLINE> func . __doc__ = new_docstring <NEWLINE> <UNTAB> return func <NEWLINE> <UNTAB> return _doc <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def nnls ( A , b , maxiter = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> A , b = map ( asarray_chkfinite , ( A , b ) ) <NEWLINE> <NEWLINE> if len ( A . shape ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if len ( b . shape ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> m , n = A . shape <NEWLINE> <NEWLINE> if m != b . shape [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> maxiter = - <NUMBER> if maxiter is None else int ( maxiter ) <NEWLINE> <NEWLINE> w = zeros ( ( n , ) , dtype = double ) <NEWLINE> zz = zeros ( ( m , ) , dtype = double ) <NEWLINE> index = zeros ( ( n , ) , dtype = int ) <NEWLINE> <NEWLINE> x , rnorm , mode = _nnls . nnls ( A , m , n , b , w , zz , index , maxiter ) <NEWLINE> if mode != <NUMBER> : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return x , rnorm <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def add_n ( inputs , name = None ) : <NEWLINE> <TAB> <NEWLINE> if not inputs or not isinstance ( inputs , ( list , tuple ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> inputs = ops . convert_n_to_tensor_or_indexed_slices ( inputs ) <NEWLINE> if not all ( isinstance ( x , ( ops . Tensor , ops . IndexedSlices ) ) for x in inputs ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if len ( inputs ) == <NUMBER> : <NEWLINE> <TAB> if isinstance ( inputs [ <NUMBER> ] , ops . IndexedSlices ) : <NEWLINE> <TAB> values = inputs [ <NUMBER> ] . values <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> values = inputs [ <NUMBER> ] <NEWLINE> <UNTAB> if name : <NEWLINE> <TAB> return array_ops . identity ( values , name = name ) <NEWLINE> <UNTAB> return values <NEWLINE> <UNTAB> return gen_math_ops . add_n ( inputs , name = name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def get_default_size ( ) : <NEWLINE> <TAB> <NEWLINE> return rcParams [ <STRING> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def sub ( f , g ) : <NEWLINE> <TAB> <NEWLINE> g = sympify ( g ) <NEWLINE> <NEWLINE> if not g . is_Poly : <NEWLINE> <TAB> return f . sub_ground ( g ) <NEWLINE> <NEWLINE> <UNTAB> _ , per , F , G = f . _unify ( g ) <NEWLINE> <NEWLINE> if hasattr ( f . rep , <STRING> ) : <NEWLINE> <TAB> result = F . sub ( G ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise OperationNotSupported ( f , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return per ( result ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def id_tensor ( self , input_tensor ) : <NEWLINE> <TAB> <NEWLINE> return input_tensor <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_real_imag ( self , deep = True , ** hints ) : <NEWLINE> <TAB> <NEWLINE> from sympy import im , re <NEWLINE> if hints . get ( <STRING> ) == self : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return ( re ( self ) , im ( self ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _transform ( self , X , inverse = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if sparse . issparse ( X ) : <NEWLINE> <TAB> for feature_idx in range ( X . shape [ <NUMBER> ] ) : <NEWLINE> <TAB> column_slice = slice ( X . indptr [ feature_idx ] , <NEWLINE> X . indptr [ feature_idx + <NUMBER> ] ) <NEWLINE> X . data [ column_slice ] = self . _transform_col ( <NEWLINE> X . data [ column_slice ] , self . quantiles_ [ : , feature_idx ] , <NEWLINE> inverse ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for feature_idx in range ( X . shape [ <NUMBER> ] ) : <NEWLINE> <TAB> X [ : , feature_idx ] = self . _transform_col ( <NEWLINE> X [ : , feature_idx ] , self . quantiles_ [ : , feature_idx ] , <NEWLINE> inverse ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return X <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def new_axes ( self , ax ) : <NEWLINE> <TAB> <NEWLINE> self . ax = ax <NEWLINE> if self . canvas is not ax . figure . canvas : <NEWLINE> <TAB> if self . canvas is not None : <NEWLINE> <TAB> self . disconnect_events ( ) <NEWLINE> <NEWLINE> <UNTAB> self . canvas = ax . figure . canvas <NEWLINE> self . connect_default_events ( ) <NEWLINE> <NEWLINE> <UNTAB> if self . direction == <STRING> : <NEWLINE> <TAB> trans = blended_transform_factory ( self . ax . transData , <NEWLINE> self . ax . transAxes ) <NEWLINE> w , h = <NUMBER> , <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> trans = blended_transform_factory ( self . ax . transAxes , <NEWLINE> self . ax . transData ) <NEWLINE> w , h = <NUMBER> , <NUMBER> <NEWLINE> <UNTAB> self . rect = Rectangle ( ( <NUMBER> , <NUMBER> ) , w , h , <NEWLINE> transform = trans , <NEWLINE> visible = False , <NEWLINE> ** self . rectprops ) <NEWLINE> if self . span_stays : <NEWLINE> <TAB> self . stay_rect = Rectangle ( ( <NUMBER> , <NUMBER> ) , w , h , <NEWLINE> transform = trans , <NEWLINE> visible = False , <NEWLINE> ** self . rectprops ) <NEWLINE> self . stay_rect . set_animated ( False ) <NEWLINE> self . ax . add_patch ( self . stay_rect ) <NEWLINE> <NEWLINE> <UNTAB> self . ax . add_patch ( self . rect ) <NEWLINE> self . artists = [ self . rect ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _read_int64 ( f ) : <NEWLINE> <TAB> <NEWLINE> return np . int64 ( struct . unpack ( <STRING> , f . read ( <NUMBER> ) ) [ <NUMBER> ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( v1 = [ <STRING> ] ) <NEWLINE> def disable_v2_tensorshape ( ) : <NEWLINE> <TAB> <NEWLINE> global _TENSORSHAPE_V2_OVERRIDE , TensorShape <NEWLINE> _TENSORSHAPE_V2_OVERRIDE = False <NEWLINE> TensorShape = TensorShapeV1 <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def digits ( n , b = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> b = as_int ( b ) <NEWLINE> n = as_int ( n ) <NEWLINE> if b <= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x , y = abs ( n ) , [ ] <NEWLINE> while x >= b : <NEWLINE> <TAB> x , r = divmod ( x , b ) <NEWLINE> y . append ( r ) <NEWLINE> <UNTAB> y . append ( x ) <NEWLINE> y . append ( - b if n < <NUMBER> else b ) <NEWLINE> y . reverse ( ) <NEWLINE> return y <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def sqf_part ( f ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( f . rep , <STRING> ) : <NEWLINE> <TAB> result = f . rep . sqf_part ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise OperationNotSupported ( f , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return f . per ( result ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_gf_factor ( f , u , K ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ checkpointable . no_automatic_dependency_tracking <NEWLINE> def add ( self , layer ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( layer , base_layer . Layer ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> + str ( layer ) ) <NEWLINE> <UNTAB> self . built = False <NEWLINE> set_inputs = False <NEWLINE> if not self . _layers : <NEWLINE> <TAB> if isinstance ( layer , InputLayer ) : <NEWLINE> <NEWLINE> <TAB> assert len ( layer . _inbound_nodes [ - <NUMBER> ] . output_tensors ) == <NUMBER> <NEWLINE> set_inputs = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> batch_shape , dtype = get_input_shape_and_dtype ( layer ) <NEWLINE> if batch_shape : <NEWLINE> <NEWLINE> <TAB> x = Input ( <NEWLINE> batch_shape = batch_shape , <NEWLINE> dtype = dtype , <NEWLINE> name = layer . name + <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> layer ( x ) <NEWLINE> set_inputs = True <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if set_inputs : <NEWLINE> <NEWLINE> <TAB> if len ( layer . _inbound_nodes [ - <NUMBER> ] . output_tensors ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> self . outputs = [ layer . _inbound_nodes [ - <NUMBER> ] . output_tensors [ <NUMBER> ] ] <NEWLINE> self . inputs = layer_utils . get_source_inputs ( self . outputs [ <NUMBER> ] ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif self . outputs : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> output_tensor = layer ( self . outputs [ <NUMBER> ] ) <NEWLINE> if isinstance ( output_tensor , list ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> self . outputs = [ output_tensor ] <NEWLINE> <UNTAB> if set_inputs or self . _is_graph_network : <NEWLINE> <TAB> self . _init_graph_network ( self . inputs , self . outputs , name = self . name ) <NEWLINE> self . built = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _layers . append ( layer ) <NEWLINE> <UNTAB> if self . _layers : <NEWLINE> <TAB> self . _track_layers ( self . _layers ) <NEWLINE> <UNTAB> self . _can_use_graph_functions = all ( <NEWLINE> layer . _can_use_graph_functions for layer in self . layers ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _check_num_rows_possibly_add_asserts ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if self . _assert_proper_shapes : <NEWLINE> <TAB> self . _num_rows = control_flow_ops . with_dependencies ( [ <NEWLINE> check_ops . assert_rank ( <NEWLINE> self . _num_rows , <NEWLINE> <NUMBER> , <NEWLINE> message = <STRING> ) , <NEWLINE> check_ops . assert_non_negative ( <NEWLINE> self . _num_rows , <NEWLINE> message = <STRING> ) , <NEWLINE> ] , self . _num_rows ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if not self . _num_rows . dtype . is_integer : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> % self . _num_rows ) <NEWLINE> <NEWLINE> <UNTAB> num_rows_static = self . _num_rows_static <NEWLINE> <NEWLINE> if num_rows_static is None : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> if num_rows_static . ndim != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % num_rows_static ) <NEWLINE> <NEWLINE> <UNTAB> if num_rows_static < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % num_rows_static ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def bind_method ( cls , name , func ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not PY3 : <NEWLINE> <TAB> setattr ( cls , name , types . MethodType ( func , None , cls ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> setattr ( cls , name , func ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def twinx ( self ) : <NEWLINE> <TAB> <NEWLINE> ax2 = self . _make_twin_axes ( sharex = self ) <NEWLINE> ax2 . yaxis . tick_right ( ) <NEWLINE> ax2 . yaxis . set_label_position ( <STRING> ) <NEWLINE> ax2 . yaxis . set_offset_position ( <STRING> ) <NEWLINE> ax2 . set_autoscalex_on ( self . get_autoscalex_on ( ) ) <NEWLINE> self . yaxis . tick_left ( ) <NEWLINE> ax2 . xaxis . set_visible ( False ) <NEWLINE> ax2 . patch . set_visible ( False ) <NEWLINE> return ax2 <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def build_supervised_input_receiver_fn_from_input_fn ( input_fn , ** input_fn_args ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> with ops . Graph ( ) . as_default ( ) : <NEWLINE> <TAB> result = input_fn ( ** input_fn_args ) <NEWLINE> features , labels , _ = util . parse_input_fn_result ( result ) <NEWLINE> <NEWLINE> <UNTAB> return build_raw_supervised_input_receiver_fn ( features , labels ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def get_task_id ( ) : <NEWLINE> <TAB> <NEWLINE> config = json . loads ( os . environ . get ( <STRING> ) or <STRING> ) <NEWLINE> task_env = config . get ( <STRING> , { } ) <NEWLINE> task_index = task_env . get ( <STRING> ) <NEWLINE> return int ( task_index ) if task_index else <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_ticks ( self , minor = False ) : <NEWLINE> <TAB> <NEWLINE> return self . _tick_data_values <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , target , bind , ** kw ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if self . _should_execute ( target , bind , ** kw ) : <NEWLINE> <TAB> return bind . execute ( self . against ( target ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def on_batch_end ( self , batch , logs = None ) : <NEWLINE> <TAB> <NEWLINE> logs = logs or { } <NEWLINE> if not hasattr ( self , <STRING> ) : <NEWLINE> <TAB> self . _t_enter_batch = time . time ( ) <NEWLINE> <UNTAB> self . _delta_t_batch = time . time ( ) - self . _t_enter_batch <NEWLINE> t_before_callbacks = time . time ( ) <NEWLINE> for callback in self . callbacks : <NEWLINE> <TAB> callback . on_batch_end ( batch , logs ) <NEWLINE> <UNTAB> self . _delta_ts_batch_end . append ( time . time ( ) - t_before_callbacks ) <NEWLINE> delta_t_median = np . median ( self . _delta_ts_batch_end ) <NEWLINE> if ( self . _delta_t_batch > <NUMBER> and <NEWLINE> ( delta_t_median > <NUMBER> * self . _delta_t_batch and delta_t_median > <NUMBER> ) ) : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> % delta_t_median ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ abc . abstractmethod <NEWLINE> def master ( self , task_type = None , task_index = None ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> . format ( self ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_unit ( self , unit ) : <NEWLINE> <TAB> <NEWLINE> if unit not in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> self . _unit = unit <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def readable ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _check_not_closed ( ) <NEWLINE> return self . _mode == _MODE_READ <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def wait_for_stop ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _coord . wait_for_stop ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def float ( self ) : <NEWLINE> <TAB> <NEWLINE> return type ( self ) ( self . data . float ( ) , self . batch_sizes ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pop ( ) : <NEWLINE> <TAB> <NEWLINE> return image_stack . pop ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_QQ_gmpy ( K1 , a , K0 ) : <NEWLINE> <TAB> <NEWLINE> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def recv_bytes ( self , maxlength = None ) : <NEWLINE> <TAB> <NEWLINE> self . _check_closed ( ) <NEWLINE> self . _check_readable ( ) <NEWLINE> if maxlength is not None and maxlength < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> buf = self . _recv_bytes ( maxlength ) <NEWLINE> if buf is None : <NEWLINE> <TAB> self . _bad_message_length ( ) <NEWLINE> <UNTAB> return buf . getvalue ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def square ( self ) : <NEWLINE> <TAB> <NEWLINE> ring = self . ring <NEWLINE> p = ring . zero <NEWLINE> get = p . get <NEWLINE> keys = list ( self . keys ( ) ) <NEWLINE> zero = ring . domain . zero <NEWLINE> monomial_mul = ring . monomial_mul <NEWLINE> for i in range ( len ( keys ) ) : <NEWLINE> <TAB> k1 = keys [ i ] <NEWLINE> pk = self [ k1 ] <NEWLINE> for j in range ( i ) : <NEWLINE> <TAB> k2 = keys [ j ] <NEWLINE> exp = monomial_mul ( k1 , k2 ) <NEWLINE> p [ exp ] = get ( exp , zero ) + pk * self [ k2 ] <NEWLINE> <UNTAB> <UNTAB> p = p . imul_num ( <NUMBER> ) <NEWLINE> get = p . get <NEWLINE> for k , v in self . items ( ) : <NEWLINE> <TAB> k2 = monomial_mul ( k , k ) <NEWLINE> p [ k2 ] = get ( k2 , zero ) + v ** <NUMBER> <NEWLINE> <UNTAB> p . strip_zero ( ) <NEWLINE> return p <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def limit_denominator ( self , max_denominator = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if max_denominator < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if self . _denominator <= max_denominator : <NEWLINE> <TAB> return Fraction ( self ) <NEWLINE> <NEWLINE> <UNTAB> p0 , q0 , p1 , q1 = <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> <NEWLINE> n , d = self . _numerator , self . _denominator <NEWLINE> while True : <NEWLINE> <TAB> a = n // d <NEWLINE> q2 = q0 + a * q1 <NEWLINE> if q2 > max_denominator : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> p0 , q0 , p1 , q1 = p1 , q1 , p0 + a * p1 , q2 <NEWLINE> n , d = d , n - a * d <NEWLINE> <NEWLINE> <UNTAB> k = ( max_denominator - q0 ) // q1 <NEWLINE> bound1 = Fraction ( p0 + k * p1 , q0 + k * q1 ) <NEWLINE> bound2 = Fraction ( p1 , q1 ) <NEWLINE> if abs ( bound2 - self ) <= abs ( bound1 - self ) : <NEWLINE> <TAB> return bound2 <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return bound1 <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_help_for_modules ( self , modules , prefix , include_special_flags ) : <NEWLINE> <TAB> <NEWLINE> output_lines = [ ] <NEWLINE> for module in modules : <NEWLINE> <TAB> self . _render_our_module_flags ( module , output_lines , prefix ) <NEWLINE> <UNTAB> if include_special_flags : <NEWLINE> <TAB> self . _render_module_flags ( <NEWLINE> <STRING> , <NEWLINE> six . itervalues ( _helpers . SPECIAL_FLAGS . _flags ( ) ) , <NEWLINE> output_lines , <NEWLINE> prefix ) <NEWLINE> <UNTAB> return <STRING> . join ( output_lines ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _root_krylov_doc ( ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rgb2hed ( rgb ) : <NEWLINE> <TAB> <NEWLINE> return separate_stains ( rgb , hed_from_rgb ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def random_point ( self , seed = None ) : <NEWLINE> <TAB> <NEWLINE> import random <NEWLINE> if seed is not None : <NEWLINE> <TAB> rng = random . Random ( seed ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rng = random <NEWLINE> <UNTAB> u , v = Dummy ( <STRING> ) , Dummy ( <STRING> ) <NEWLINE> params = { <NEWLINE> u : <NUMBER> * Rational ( rng . gauss ( <NUMBER> , <NUMBER> ) ) - <NUMBER> , <NEWLINE> v : <NUMBER> * Rational ( rng . gauss ( <NUMBER> , <NUMBER> ) ) - <NUMBER> } <NEWLINE> return self . arbitrary_point ( u , v ) . subs ( params ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def set_test_mode ( v = True ) : <NEWLINE> <TAB> <NEWLINE> global _TEST_MODE , _TEST_RESULT <NEWLINE> _TEST_MODE = v <NEWLINE> _TEST_RESULT = [ ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def isspmatrix_bsr ( x ) : <NEWLINE> <TAB> <NEWLINE> return isinstance ( x , bsr_matrix ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def reset_defaults ( ) : <NEWLINE> <TAB> <NEWLINE> mpl . rcParams . update ( mpl . rcParamsDefault ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def ctc_label_dense_to_sparse ( labels , label_lengths ) : <NEWLINE> <TAB> <NEWLINE> label_shape = array_ops . shape ( labels ) <NEWLINE> num_batches_tns = array_ops . stack ( [ label_shape [ <NUMBER> ] ] ) <NEWLINE> max_num_labels_tns = array_ops . stack ( [ label_shape [ <NUMBER> ] ] ) <NEWLINE> <NEWLINE> def range_less_than ( _ , current_input ) : <NEWLINE> <TAB> return array_ops . expand_dims ( <NEWLINE> math_ops . range ( label_shape [ <NUMBER> ] ) , <NUMBER> ) < array_ops . fill ( <NEWLINE> max_num_labels_tns , current_input ) <NEWLINE> <NEWLINE> <UNTAB> init = math_ops . cast ( <NEWLINE> array_ops . fill ( [ <NUMBER> , label_shape [ <NUMBER> ] ] , <NUMBER> ) , dtypes_module . bool ) <NEWLINE> dense_mask = functional_ops . scan ( <NEWLINE> range_less_than , label_lengths , initializer = init , parallel_iterations = <NUMBER> ) <NEWLINE> dense_mask = dense_mask [ : , <NUMBER> , : ] <NEWLINE> <NEWLINE> label_array = array_ops . reshape ( <NEWLINE> array_ops . tile ( math_ops . range ( <NUMBER> , label_shape [ <NUMBER> ] ) , num_batches_tns ) , <NEWLINE> label_shape ) <NEWLINE> label_ind = array_ops . boolean_mask ( label_array , dense_mask ) <NEWLINE> <NEWLINE> batch_array = array_ops . transpose ( <NEWLINE> array_ops . reshape ( <NEWLINE> array_ops . tile ( math_ops . range ( <NUMBER> , label_shape [ <NUMBER> ] ) , max_num_labels_tns ) , <NEWLINE> reverse ( label_shape , <NUMBER> ) ) ) <NEWLINE> batch_ind = array_ops . boolean_mask ( batch_array , dense_mask ) <NEWLINE> indices = array_ops . transpose ( <NEWLINE> array_ops . reshape ( concatenate ( [ batch_ind , label_ind ] , axis = <NUMBER> ) , [ <NUMBER> , - <NUMBER> ] ) ) <NEWLINE> <NEWLINE> vals_sparse = array_ops . gather_nd ( labels , indices ) <NEWLINE> <NEWLINE> return sparse_tensor . SparseTensor ( <NEWLINE> math_ops . to_int64 ( indices ) , vals_sparse , math_ops . to_int64 ( label_shape ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_coo ( self ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> from scipy . sparse import coo_matrix <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> raise ImportError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> dtype = find_common_type ( self . dtypes ) <NEWLINE> cols , rows , datas = [ ] , [ ] , [ ] <NEWLINE> for col , name in enumerate ( self ) : <NEWLINE> <TAB> s = self [ name ] <NEWLINE> row = s . sp_index . to_int_index ( ) . indices <NEWLINE> cols . append ( np . repeat ( col , len ( row ) ) ) <NEWLINE> rows . append ( row ) <NEWLINE> datas . append ( s . sp_values . astype ( dtype , copy = False ) ) <NEWLINE> <NEWLINE> <UNTAB> cols = np . concatenate ( cols ) <NEWLINE> rows = np . concatenate ( rows ) <NEWLINE> datas = np . concatenate ( datas ) <NEWLINE> return coo_matrix ( ( datas , ( rows , cols ) ) , shape = self . shape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , rules ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( rules , string_types ) : <NEWLINE> <TAB> rules = rules . splitlines ( ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> P = Prover ( ) <NEWLINE> <NEWLINE> for rule in rules : <NEWLINE> <NEWLINE> <TAB> a , op , b = rule . split ( None , <NUMBER> ) <NEWLINE> <NEWLINE> a = Logic . fromstring ( a ) <NEWLINE> b = Logic . fromstring ( b ) <NEWLINE> <NEWLINE> if op == <STRING> : <NEWLINE> <TAB> P . process_rule ( a , b ) <NEWLINE> <UNTAB> elif op == <STRING> : <NEWLINE> <TAB> P . process_rule ( a , b ) <NEWLINE> P . process_rule ( b , a ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % op ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . beta_rules = [ ] <NEWLINE> for bcond , bimpl in P . rules_beta : <NEWLINE> <TAB> self . beta_rules . append ( <NEWLINE> ( set ( _as_pair ( a ) for a in bcond . args ) , _as_pair ( bimpl ) ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> impl_a = deduce_alpha_implications ( P . rules_alpha ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> impl_ab = apply_beta_to_alpha_route ( impl_a , P . rules_beta ) <NEWLINE> <NEWLINE> <NEWLINE> self . defined_facts = set ( _base_fact ( k ) for k in impl_ab . keys ( ) ) <NEWLINE> <NEWLINE> <NEWLINE> full_implications = defaultdict ( set ) <NEWLINE> beta_triggers = defaultdict ( set ) <NEWLINE> for k , ( impl , betaidxs ) in impl_ab . items ( ) : <NEWLINE> <TAB> full_implications [ _as_pair ( k ) ] = set ( _as_pair ( i ) for i in impl ) <NEWLINE> beta_triggers [ _as_pair ( k ) ] = betaidxs <NEWLINE> <NEWLINE> <UNTAB> self . full_implications = full_implications <NEWLINE> self . beta_triggers = beta_triggers <NEWLINE> <NEWLINE> <NEWLINE> prereq = defaultdict ( set ) <NEWLINE> rel_prereq = rules_2prereq ( full_implications ) <NEWLINE> for k , pitems in rel_prereq . items ( ) : <NEWLINE> <TAB> prereq [ k ] |= pitems <NEWLINE> <UNTAB> self . prereq = prereq <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def are_concurrent ( * planes ) : <NEWLINE> <TAB> <NEWLINE> planes = list ( uniq ( planes ) ) <NEWLINE> for i in planes : <NEWLINE> <TAB> if not isinstance ( i , Plane ) : <NEWLINE> <TAB> raise ValueError ( <STRING> % i . func ) <NEWLINE> <UNTAB> <UNTAB> if len ( planes ) < <NUMBER> : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> planes = list ( planes ) <NEWLINE> first = planes . pop ( <NUMBER> ) <NEWLINE> sol = first . intersection ( planes [ <NUMBER> ] ) <NEWLINE> if sol == [ ] : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> line = sol [ <NUMBER> ] <NEWLINE> for i in planes [ <NUMBER> : ] : <NEWLINE> <TAB> l = first . intersection ( i ) <NEWLINE> if not l or not l [ <NUMBER> ] in line : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def skew ( self , xShear , yShear ) : <NEWLINE> <TAB> <NEWLINE> rotX = np . tan ( xShear ) <NEWLINE> rotY = np . tan ( yShear ) <NEWLINE> skew_mtx = np . array ( <NEWLINE> [ [ <NUMBER> , rotX , <NUMBER> ] , [ rotY , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> , <NUMBER> ] ] , float ) <NEWLINE> self . _mtx = np . dot ( skew_mtx , self . _mtx ) <NEWLINE> self . invalidate ( ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def accepts ( * types ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def check_accepts ( f ) : <NEWLINE> <TAB> <NEWLINE> spec = tf_inspect . getargspec ( f ) <NEWLINE> <NEWLINE> num_function_arguments = len ( spec . args ) <NEWLINE> if len ( types ) != num_function_arguments : <NEWLINE> <TAB> raise Error ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ( f , num_function_arguments , len ( types ) ) ) <NEWLINE> <NEWLINE> <UNTAB> if spec . defaults : <NEWLINE> <TAB> num_defaults = len ( spec . defaults ) <NEWLINE> for ( name , a , t ) in zip ( spec . args [ - num_defaults : ] , <NEWLINE> spec . defaults , <NEWLINE> types [ - num_defaults : ] ) : <NEWLINE> <TAB> allowed_type = _replace_forward_references ( t , f . __globals__ ) <NEWLINE> if not isinstance ( a , allowed_type ) : <NEWLINE> <TAB> raise Error ( <STRING> <NEWLINE> <STRING> <NEWLINE> % ( a , type ( a ) , _type_repr ( allowed_type ) , name , f ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> @ functools . wraps ( f ) <NEWLINE> def new_f ( * args , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> for ( a , t ) in zip ( args , types ) : <NEWLINE> <TAB> allowed_type = _replace_forward_references ( t , f . __globals__ ) <NEWLINE> if not isinstance ( a , allowed_type ) : <NEWLINE> <TAB> raise Error ( <STRING> <NEWLINE> <STRING> % ( a , type ( a ) , _type_repr ( allowed_type ) , f ) ) <NEWLINE> <UNTAB> <UNTAB> return f ( * args , ** kwds ) <NEWLINE> <NEWLINE> <UNTAB> return new_f <NEWLINE> <NEWLINE> <UNTAB> return check_accepts <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def base ( self , base ) : <NEWLINE> <TAB> <NEWLINE> self . _base = float ( base ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _nth_linear_match ( eq , func , order ) : <NEWLINE> <TAB> <NEWLINE> x = func . args [ <NUMBER> ] <NEWLINE> one_x = { x } <NEWLINE> terms = { i : S . Zero for i in range ( - <NUMBER> , order + <NUMBER> ) } <NEWLINE> for i in Add . make_args ( eq ) : <NEWLINE> <TAB> if not i . has ( func ) : <NEWLINE> <TAB> terms [ - <NUMBER> ] += i <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> c , f = i . as_independent ( func ) <NEWLINE> if isinstance ( f , Derivative ) and set ( f . variables ) == one_x : <NEWLINE> <TAB> terms [ f . derivative_count ] += c <NEWLINE> <UNTAB> elif f == func : <NEWLINE> <TAB> terms [ len ( f . args [ <NUMBER> : ] ) ] += c <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return terms <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def weighted_moments ( x , axes , frequency_weights , name = None , keep_dims = False ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ x , frequency_weights , axes ] ) : <NEWLINE> <TAB> x = ops . convert_to_tensor ( x , name = <STRING> ) <NEWLINE> frequency_weights = ops . convert_to_tensor ( <NEWLINE> frequency_weights , name = <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> needs_cast = x . dtype == dtypes . float16 <NEWLINE> if needs_cast : <NEWLINE> <TAB> x = math_ops . cast ( x , dtypes . float32 ) <NEWLINE> <NEWLINE> <UNTAB> if frequency_weights . dtype != x . dtype : <NEWLINE> <TAB> frequency_weights = math_ops . cast ( frequency_weights , x . dtype ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> weighted_input_sum = math_ops . reduce_sum ( <NEWLINE> frequency_weights * x , axes , name = <STRING> , keepdims = True ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> broadcasted_weights = frequency_weights + array_ops . zeros_like ( x ) <NEWLINE> <NEWLINE> sum_of_weights = math_ops . reduce_sum ( <NEWLINE> broadcasted_weights , axes , name = <STRING> , keepdims = True ) <NEWLINE> <NEWLINE> divisor = math_ops . reciprocal ( sum_of_weights , name = <STRING> ) <NEWLINE> <NEWLINE> weighted_mean = math_ops . multiply ( weighted_input_sum , divisor ) <NEWLINE> <NEWLINE> <NEWLINE> weighted_distsq = math_ops . reduce_sum ( <NEWLINE> frequency_weights * math_ops . squared_difference ( x , weighted_mean ) , <NEWLINE> axes , <NEWLINE> name = <STRING> , <NEWLINE> keepdims = True ) <NEWLINE> <NEWLINE> weighted_variance = math_ops . multiply ( weighted_distsq , divisor ) <NEWLINE> <NEWLINE> if not keep_dims : <NEWLINE> <TAB> weighted_mean = array_ops . squeeze ( weighted_mean , axis = axes ) <NEWLINE> weighted_variance = array_ops . squeeze ( <NEWLINE> weighted_variance , axis = axes ) <NEWLINE> <NEWLINE> <UNTAB> if needs_cast : <NEWLINE> <TAB> weighted_mean = math_ops . cast ( weighted_mean , dtypes . float16 ) <NEWLINE> weighted_variance = math_ops . cast ( weighted_variance , dtypes . float16 ) <NEWLINE> <NEWLINE> <UNTAB> return weighted_mean , weighted_variance <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecation . deprecated ( <NEWLINE> None , <NEWLINE> <STRING> ) <NEWLINE> @ tf_export ( v1 = [ <STRING> ] ) <NEWLINE> def do_quantize_training_on_graphdef ( input_graph , num_bits ) : <NEWLINE> <TAB> <NEWLINE> from tensorflow . core . framework . graph_pb2 import GraphDef <NEWLINE> from tensorflow . python . framework import errors <NEWLINE> with errors . raise_exception_on_not_ok_status ( ) as status : <NEWLINE> <TAB> graph = GraphDef ( ) <NEWLINE> result_graph_string = DoQuantizeTrainingOnGraphDefHelper ( <NEWLINE> input_graph . SerializeToString ( ) , num_bits , status ) <NEWLINE> <NEWLINE> <UNTAB> graph . ParseFromString ( result_graph_string ) <NEWLINE> return graph <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _cg ( fhess_p , fgrad , maxiter , tol ) : <NEWLINE> <TAB> <NEWLINE> xsupi = np . zeros ( len ( fgrad ) , dtype = fgrad . dtype ) <NEWLINE> ri = fgrad <NEWLINE> psupi = - ri <NEWLINE> i = <NUMBER> <NEWLINE> dri0 = np . dot ( ri , ri ) <NEWLINE> <NEWLINE> while i <= maxiter : <NEWLINE> <TAB> if np . sum ( np . abs ( ri ) ) <= tol : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <UNTAB> Ap = fhess_p ( psupi ) <NEWLINE> <NEWLINE> curv = np . dot ( psupi , Ap ) <NEWLINE> if <NUMBER> <= curv <= <NUMBER> * np . finfo ( np . float64 ) . eps : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> elif curv < <NUMBER> : <NEWLINE> <TAB> if i > <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> xsupi += dri0 / curv * psupi <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> alphai = dri0 / curv <NEWLINE> xsupi += alphai * psupi <NEWLINE> ri = ri + alphai * Ap <NEWLINE> dri1 = np . dot ( ri , ri ) <NEWLINE> betai = dri1 / dri0 <NEWLINE> psupi = - ri + betai * psupi <NEWLINE> i = i + <NUMBER> <NEWLINE> dri0 = dri1 <NEWLINE> <NEWLINE> <UNTAB> return xsupi <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def remove ( self , o ) : <NEWLINE> <TAB> <NEWLINE> if o not in self . _elements : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> old = self . _elements [ : ] <NEWLINE> self . clear ( ) <NEWLINE> for thiso in old : <NEWLINE> <TAB> if thiso != o : <NEWLINE> <TAB> self . push ( thiso ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def scale ( self , x = <NUMBER> , y = <NUMBER> , pt = None ) : <NEWLINE> <TAB> <NEWLINE> from sympy . geometry . point import Point <NEWLINE> if pt : <NEWLINE> <TAB> pt = Point ( pt , dim = <NUMBER> ) <NEWLINE> return self . translate ( * ( - pt ) . args ) . scale ( x , y ) . translate ( * pt . args ) <NEWLINE> <UNTAB> return type ( self ) ( * [ a . scale ( x , y ) for a in self . args ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def todict ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . _optimize_data_files ( ) <NEWLINE> d = { } <NEWLINE> known_keys = self . list_keys + self . dict_keys + self . extra_keys <NEWLINE> for n in known_keys : <NEWLINE> <TAB> a = getattr ( self , n ) <NEWLINE> if a : <NEWLINE> <TAB> d [ n ] = a <NEWLINE> <UNTAB> <UNTAB> return d <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def set_global_settings ( cls , ** settings ) : <NEWLINE> <TAB> <NEWLINE> for key , val in settings . items ( ) : <NEWLINE> <TAB> if val is not None : <NEWLINE> <TAB> cls . _global_settings [ key ] = val <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ if_delegate_has_method ( delegate = ( <STRING> , <STRING> ) ) <NEWLINE> def transform ( self , X ) : <NEWLINE> <TAB> <NEWLINE> self . _check_is_fitted ( <STRING> ) <NEWLINE> return self . best_estimator_ . transform ( X ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def compute_dof_from_df ( self ) : <NEWLINE> <TAB> <NEWLINE> J = CubicTriInterpolator . _get_jacobian ( self . _tris_pts ) <NEWLINE> tri_z = self . z [ self . _triangles ] <NEWLINE> tri_dz = self . dz [ self . _triangles ] <NEWLINE> tri_dof = self . get_dof_vec ( tri_z , tri_dz , J ) <NEWLINE> return tri_dof <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def lagfromroots ( roots ) : <NEWLINE> <TAB> <NEWLINE> if len ( roots ) == <NUMBER> : <NEWLINE> <TAB> return np . ones ( <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> [ roots ] = pu . as_series ( [ roots ] , trim = False ) <NEWLINE> roots . sort ( ) <NEWLINE> p = [ lagline ( - r , <NUMBER> ) for r in roots ] <NEWLINE> n = len ( p ) <NEWLINE> while n > <NUMBER> : <NEWLINE> <TAB> m , r = divmod ( n , <NUMBER> ) <NEWLINE> tmp = [ lagmul ( p [ i ] , p [ i + m ] ) for i in range ( m ) ] <NEWLINE> if r : <NEWLINE> <TAB> tmp [ <NUMBER> ] = lagmul ( tmp [ <NUMBER> ] , p [ - <NUMBER> ] ) <NEWLINE> <UNTAB> p = tmp <NEWLINE> n = m <NEWLINE> <UNTAB> return p [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , node_def , op , message ) : <NEWLINE> <TAB> <NEWLINE> super ( CancelledError , self ) . __init__ ( node_def , op , message , CANCELLED ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_minor_locator ( self , locator ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( locator , mticker . Locator ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> self . isDefault_minloc = False <NEWLINE> self . minor . locator = locator <NEWLINE> locator . set_axis ( self ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _get_machar ( ftype ) : <NEWLINE> <TAB> <NEWLINE> params = _MACHAR_PARAMS . get ( ftype ) <NEWLINE> if params is None : <NEWLINE> <TAB> raise ValueError ( repr ( ftype ) ) <NEWLINE> <NEWLINE> <UNTAB> key = ftype ( <STRING> ) . newbyteorder ( <STRING> ) . tobytes ( ) <NEWLINE> ma_like = _KNOWN_TYPES . get ( key ) <NEWLINE> <NEWLINE> <NEWLINE> if ma_like is None and ftype == ntypes . longdouble : <NEWLINE> <TAB> ma_like = _KNOWN_TYPES . get ( key [ : <NUMBER> ] ) <NEWLINE> <UNTAB> if ma_like is not None : <NEWLINE> <TAB> return ma_like <NEWLINE> <NEWLINE> <UNTAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( key , ftype ) , <NEWLINE> UserWarning , stacklevel = <NUMBER> ) <NEWLINE> return _discovered_machar ( ftype ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _rewrite_gamma ( f , s , a , b ) : <NEWLINE> <TAB> <NEWLINE> from itertools import repeat <NEWLINE> from sympy import ( Poly , gamma , Mul , re , CRootOf , exp as exp_ , expand , <NEWLINE> roots , ilcm , pi , sin , cos , tan , cot , igcd , exp_polar ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> a_ , b_ = S ( [ a , b ] ) <NEWLINE> <NEWLINE> def left ( c , is_numer ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> c = expand ( re ( c ) ) <NEWLINE> if a_ is None and b_ is oo : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> if a_ is None : <NEWLINE> <TAB> return c < b_ <NEWLINE> <UNTAB> if b_ is None : <NEWLINE> <TAB> return c <= a_ <NEWLINE> <UNTAB> if ( c >= b_ ) == True : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> if ( c <= a_ ) == True : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> if is_numer : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> if a_ . free_symbols or b_ . free_symbols or c . free_symbols : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> raise MellinTransformStripError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> s_multipliers = [ ] <NEWLINE> for g in f . atoms ( gamma ) : <NEWLINE> <TAB> if not g . has ( s ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> arg = g . args [ <NUMBER> ] <NEWLINE> if arg . is_Add : <NEWLINE> <TAB> arg = arg . as_independent ( s ) [ <NUMBER> ] <NEWLINE> <UNTAB> coeff , _ = arg . as_coeff_mul ( s ) <NEWLINE> s_multipliers += [ coeff ] <NEWLINE> <UNTAB> for g in f . atoms ( sin , cos , tan , cot ) : <NEWLINE> <TAB> if not g . has ( s ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> arg = g . args [ <NUMBER> ] <NEWLINE> if arg . is_Add : <NEWLINE> <TAB> arg = arg . as_independent ( s ) [ <NUMBER> ] <NEWLINE> <UNTAB> coeff , _ = arg . as_coeff_mul ( s ) <NEWLINE> s_multipliers += [ coeff / pi ] <NEWLINE> <UNTAB> s_multipliers = [ abs ( x ) if x . is_real else x for x in s_multipliers ] <NEWLINE> common_coefficient = S ( <NUMBER> ) <NEWLINE> for x in s_multipliers : <NEWLINE> <TAB> if not x . is_Rational : <NEWLINE> <TAB> common_coefficient = x <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> s_multipliers = [ x / common_coefficient for x in s_multipliers ] <NEWLINE> if ( any ( not x . is_Rational for x in s_multipliers ) or <NEWLINE> not common_coefficient . is_real ) : <NEWLINE> <TAB> raise IntegralTransformError ( <STRING> , None , <STRING> ) <NEWLINE> <UNTAB> s_multiplier = common_coefficient / reduce ( ilcm , [ S ( x . q ) <NEWLINE> for x in s_multipliers ] , S ( <NUMBER> ) ) <NEWLINE> if s_multiplier == common_coefficient : <NEWLINE> <TAB> if len ( s_multipliers ) == <NUMBER> : <NEWLINE> <TAB> s_multiplier = common_coefficient <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> s_multiplier = common_coefficient * reduce ( igcd , [ S ( x . p ) for x in s_multipliers ] ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> exponent = S ( <NUMBER> ) <NEWLINE> fac = S ( <NUMBER> ) <NEWLINE> f = f . subs ( s , s / s_multiplier ) <NEWLINE> fac /= s_multiplier <NEWLINE> exponent = <NUMBER> / s_multiplier <NEWLINE> if a_ is not None : <NEWLINE> <TAB> a_ *= s_multiplier <NEWLINE> <UNTAB> if b_ is not None : <NEWLINE> <TAB> b_ *= s_multiplier <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> numer , denom = f . as_numer_denom ( ) <NEWLINE> numer = Mul . make_args ( numer ) <NEWLINE> denom = Mul . make_args ( denom ) <NEWLINE> args = list ( zip ( numer , repeat ( True ) ) ) + list ( zip ( denom , repeat ( False ) ) ) <NEWLINE> <NEWLINE> facs = [ ] <NEWLINE> dfacs = [ ] <NEWLINE> <NEWLINE> numer_gammas = [ ] <NEWLINE> denom_gammas = [ ] <NEWLINE> <NEWLINE> exponentials = [ ] <NEWLINE> <NEWLINE> def exception ( fact ) : <NEWLINE> <TAB> return IntegralTransformError ( <STRING> , f , <STRING> % fact ) <NEWLINE> <UNTAB> while args : <NEWLINE> <TAB> fact , is_numer = args . pop ( ) <NEWLINE> if is_numer : <NEWLINE> <TAB> ugammas , lgammas = numer_gammas , denom_gammas <NEWLINE> ufacs , lfacs = facs , dfacs <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ugammas , lgammas = denom_gammas , numer_gammas <NEWLINE> ufacs , lfacs = dfacs , facs <NEWLINE> <NEWLINE> <UNTAB> def linear_arg ( arg ) : <NEWLINE> <TAB> <NEWLINE> if not arg . is_polynomial ( s ) : <NEWLINE> <TAB> raise exception ( fact ) <NEWLINE> <UNTAB> p = Poly ( arg , s ) <NEWLINE> if p . degree ( ) != <NUMBER> : <NEWLINE> <TAB> raise exception ( fact ) <NEWLINE> <UNTAB> return p . all_coeffs ( ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if not fact . has ( s ) : <NEWLINE> <TAB> ufacs += [ fact ] <NEWLINE> <NEWLINE> <UNTAB> elif fact . is_Pow or isinstance ( fact , exp_ ) : <NEWLINE> <TAB> if fact . is_Pow : <NEWLINE> <TAB> base = fact . base <NEWLINE> exp = fact . exp <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> base = exp_polar ( <NUMBER> ) <NEWLINE> exp = fact . args [ <NUMBER> ] <NEWLINE> <UNTAB> if exp . is_Integer : <NEWLINE> <TAB> cond = is_numer <NEWLINE> if exp < <NUMBER> : <NEWLINE> <TAB> cond = not cond <NEWLINE> <UNTAB> args += [ ( base , cond ) ] * abs ( exp ) <NEWLINE> continue <NEWLINE> <UNTAB> elif not base . has ( s ) : <NEWLINE> <TAB> a , b = linear_arg ( exp ) <NEWLINE> if not is_numer : <NEWLINE> <TAB> base = <NUMBER> / base <NEWLINE> <UNTAB> exponentials += [ base ** a ] <NEWLINE> facs += [ base ** b ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise exception ( fact ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif fact . is_polynomial ( s ) : <NEWLINE> <TAB> p = Poly ( fact , s ) <NEWLINE> if p . degree ( ) != <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> coeff = p . LT ( ) [ <NUMBER> ] <NEWLINE> rs = roots ( p , s ) <NEWLINE> if len ( rs ) != p . degree ( ) : <NEWLINE> <TAB> rs = CRootOf . all_roots ( p ) <NEWLINE> <UNTAB> ufacs += [ coeff ] <NEWLINE> args += [ ( s - c , is_numer ) for c in rs ] <NEWLINE> continue <NEWLINE> <UNTAB> a , c = p . all_coeffs ( ) <NEWLINE> ufacs += [ a ] <NEWLINE> c /= - a <NEWLINE> <NEWLINE> if left ( c , is_numer ) : <NEWLINE> <TAB> ugammas += [ ( S ( <NUMBER> ) , - c + <NUMBER> ) ] <NEWLINE> lgammas += [ ( S ( <NUMBER> ) , - c ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ufacs += [ - <NUMBER> ] <NEWLINE> ugammas += [ ( S ( - <NUMBER> ) , c + <NUMBER> ) ] <NEWLINE> lgammas += [ ( S ( - <NUMBER> ) , c ) ] <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( fact , gamma ) : <NEWLINE> <TAB> a , b = linear_arg ( fact . args [ <NUMBER> ] ) <NEWLINE> if is_numer : <NEWLINE> <TAB> if ( a > <NUMBER> and ( left ( - b / a , is_numer ) == False ) ) or ( a < <NUMBER> and ( left ( - b / a , is_numer ) == True ) ) : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> ugammas += [ ( a , b ) ] <NEWLINE> <UNTAB> elif isinstance ( fact , sin ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> a = fact . args [ <NUMBER> ] <NEWLINE> if is_numer : <NEWLINE> <NEWLINE> <TAB> gamma1 , gamma2 , fac_ = gamma ( a / pi ) , gamma ( <NUMBER> - a / pi ) , pi <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> gamma1 , gamma2 , fac_ = _rewrite_sin ( linear_arg ( a ) , s , a_ , b_ ) <NEWLINE> <UNTAB> args += [ ( gamma1 , not is_numer ) , ( gamma2 , not is_numer ) ] <NEWLINE> ufacs += [ fac_ ] <NEWLINE> <UNTAB> elif isinstance ( fact , tan ) : <NEWLINE> <TAB> a = fact . args [ <NUMBER> ] <NEWLINE> args += [ ( sin ( a , evaluate = False ) , is_numer ) , <NEWLINE> ( sin ( pi / <NUMBER> - a , evaluate = False ) , not is_numer ) ] <NEWLINE> <UNTAB> elif isinstance ( fact , cos ) : <NEWLINE> <TAB> a = fact . args [ <NUMBER> ] <NEWLINE> args += [ ( sin ( pi / <NUMBER> - a , evaluate = False ) , is_numer ) ] <NEWLINE> <UNTAB> elif isinstance ( fact , cot ) : <NEWLINE> <TAB> a = fact . args [ <NUMBER> ] <NEWLINE> args += [ ( sin ( pi / <NUMBER> - a , evaluate = False ) , is_numer ) , <NEWLINE> ( sin ( a , evaluate = False ) , not is_numer ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise exception ( fact ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> fac *= Mul ( * facs ) / Mul ( * dfacs ) <NEWLINE> <NEWLINE> <NEWLINE> an , ap , bm , bq = [ ] , [ ] , [ ] , [ ] <NEWLINE> for gammas , plus , minus , is_numer in [ ( numer_gammas , an , bm , True ) , <NEWLINE> ( denom_gammas , bq , ap , False ) ] : <NEWLINE> <TAB> while gammas : <NEWLINE> <TAB> a , c = gammas . pop ( ) <NEWLINE> if a != - <NUMBER> and a != + <NUMBER> : <NEWLINE> <NEWLINE> <TAB> p = abs ( S ( a ) ) <NEWLINE> newa = a / p <NEWLINE> newc = c / p <NEWLINE> if not a . is_Integer : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> for k in range ( p ) : <NEWLINE> <TAB> gammas += [ ( newa , newc + k / p ) ] <NEWLINE> <UNTAB> if is_numer : <NEWLINE> <TAB> fac *= ( <NUMBER> * pi ) ** ( ( <NUMBER> - p ) / <NUMBER> ) * p ** ( c - S ( <NUMBER> ) / <NUMBER> ) <NEWLINE> exponentials += [ p ** a ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> fac /= ( <NUMBER> * pi ) ** ( ( <NUMBER> - p ) / <NUMBER> ) * p ** ( c - S ( <NUMBER> ) / <NUMBER> ) <NEWLINE> exponentials += [ p ** ( - a ) ] <NEWLINE> <UNTAB> continue <NEWLINE> <UNTAB> if a == + <NUMBER> : <NEWLINE> <TAB> plus . append ( <NUMBER> - c ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> minus . append ( c ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> arg = Mul ( * exponentials ) <NEWLINE> <NEWLINE> <NEWLINE> an . sort ( key = default_sort_key ) <NEWLINE> ap . sort ( key = default_sort_key ) <NEWLINE> bm . sort ( key = default_sort_key ) <NEWLINE> bq . sort ( key = default_sort_key ) <NEWLINE> <NEWLINE> return ( an , ap ) , ( bm , bq ) , arg , exponent , fac <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_discrete ( self , dt , method = <STRING> , alpha = None ) : <NEWLINE> <TAB> <NEWLINE> return ZerosPolesGain ( <NEWLINE> * cont2discrete ( ( self . zeros , self . poles , self . gain ) , <NEWLINE> dt , <NEWLINE> method = method , <NEWLINE> alpha = alpha ) [ : - <NUMBER> ] , <NEWLINE> dt = dt ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def waitforbuttonpress ( self , timeout = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> blocking_input = BlockingKeyMouseInput ( self ) <NEWLINE> return blocking_input ( timeout = timeout ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def reverse ( self , class_id ) : <NEWLINE> <TAB> <NEWLINE> if not self . _support_reverse : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> return self . _reverse_mapping [ class_id ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def Ynm_c ( n , m , theta , phi ) : <NEWLINE> <TAB> <NEWLINE> from sympy import conjugate <NEWLINE> return conjugate ( Ynm ( n , m , theta , phi ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def in1d ( ar1 , ar2 , assume_unique = False , invert = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> ar1 = np . asarray ( ar1 ) . ravel ( ) <NEWLINE> ar2 = np . asarray ( ar2 ) . ravel ( ) <NEWLINE> <NEWLINE> <NEWLINE> contains_object = ar1 . dtype . hasobject or ar2 . dtype . hasobject <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if len ( ar2 ) < <NUMBER> * len ( ar1 ) ** <NUMBER> or contains_object : <NEWLINE> <TAB> if invert : <NEWLINE> <TAB> mask = np . ones ( len ( ar1 ) , dtype = bool ) <NEWLINE> for a in ar2 : <NEWLINE> <TAB> mask &= ( ar1 != a ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> mask = np . zeros ( len ( ar1 ) , dtype = bool ) <NEWLINE> for a in ar2 : <NEWLINE> <TAB> mask |= ( ar1 == a ) <NEWLINE> <UNTAB> <UNTAB> return mask <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if not assume_unique : <NEWLINE> <TAB> ar1 , rev_idx = np . unique ( ar1 , return_inverse = True ) <NEWLINE> ar2 = np . unique ( ar2 ) <NEWLINE> <NEWLINE> <UNTAB> ar = np . concatenate ( ( ar1 , ar2 ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> order = ar . argsort ( kind = <STRING> ) <NEWLINE> sar = ar [ order ] <NEWLINE> if invert : <NEWLINE> <TAB> bool_ar = ( sar [ <NUMBER> : ] != sar [ : - <NUMBER> ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> bool_ar = ( sar [ <NUMBER> : ] == sar [ : - <NUMBER> ] ) <NEWLINE> <UNTAB> flag = np . concatenate ( ( bool_ar , [ invert ] ) ) <NEWLINE> ret = np . empty ( ar . shape , dtype = bool ) <NEWLINE> ret [ order ] = flag <NEWLINE> <NEWLINE> if assume_unique : <NEWLINE> <TAB> return ret [ : len ( ar1 ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return ret [ rev_idx ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def variable_repr ( var ) : <NEWLINE> <TAB> <NEWLINE> xp = backend . get_array_module ( var ) <NEWLINE> if xp is numpy : <NEWLINE> <TAB> arr = var . data <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> arr = var . data . get ( ) <NEWLINE> <NEWLINE> <UNTAB> if var . name : <NEWLINE> <TAB> prefix = <STRING> + var . name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> prefix = <STRING> <NEWLINE> <NEWLINE> <UNTAB> if arr is None : <NEWLINE> <TAB> lst = <STRING> <NEWLINE> <UNTAB> elif arr . size > <NUMBER> or arr . shape == ( <NUMBER> , ) : <NEWLINE> <TAB> lst = numpy . array2string ( arr , None , None , None , <STRING> , prefix + <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> lst = <STRING> % ( repr ( arr . shape ) , ) <NEWLINE> <NEWLINE> <UNTAB> return <STRING> % ( prefix , lst ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def to_parquet ( df , path , engine = <STRING> , compression = <STRING> , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> impl = get_engine ( engine ) <NEWLINE> return impl . write ( df , path , compression = compression , ** kwargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def anderson_ksamp ( samples , midrank = True ) : <NEWLINE> <TAB> <NEWLINE> k = len ( samples ) <NEWLINE> if ( k < <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> samples = list ( map ( np . asarray , samples ) ) <NEWLINE> Z = np . sort ( np . hstack ( samples ) ) <NEWLINE> N = Z . size <NEWLINE> Zstar = np . unique ( Z ) <NEWLINE> if Zstar . size < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> n = np . array ( [ sample . size for sample in samples ] ) <NEWLINE> if any ( n == <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if midrank : <NEWLINE> <TAB> A2kN = _anderson_ksamp_midrank ( samples , Z , Zstar , k , n , N ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> A2kN = _anderson_ksamp_right ( samples , Z , Zstar , k , n , N ) <NEWLINE> <NEWLINE> <UNTAB> H = ( <NUMBER> / n ) . sum ( ) <NEWLINE> hs_cs = ( <NUMBER> / arange ( N - <NUMBER> , <NUMBER> , - <NUMBER> ) ) . cumsum ( ) <NEWLINE> h = hs_cs [ - <NUMBER> ] + <NUMBER> <NEWLINE> g = ( hs_cs / arange ( <NUMBER> , N ) ) . sum ( ) <NEWLINE> <NEWLINE> a = ( <NUMBER> * g - <NUMBER> ) * ( k - <NUMBER> ) + ( <NUMBER> - <NUMBER> * g ) * H <NEWLINE> b = ( <NUMBER> * g - <NUMBER> ) * k ** <NUMBER> + <NUMBER> * h * k + ( <NUMBER> * g - <NUMBER> * h - <NUMBER> ) * H - <NUMBER> * h + <NUMBER> * g - <NUMBER> <NEWLINE> c = ( <NUMBER> * h + <NUMBER> * g - <NUMBER> ) * k ** <NUMBER> + ( <NUMBER> * h - <NUMBER> * g + <NUMBER> ) * k + ( <NUMBER> * h - <NUMBER> ) * H + <NUMBER> * h <NEWLINE> d = ( <NUMBER> * h + <NUMBER> ) * k ** <NUMBER> - <NUMBER> * h * k <NEWLINE> sigmasq = ( a * N ** <NUMBER> + b * N ** <NUMBER> + c * N + d ) / ( ( N - <NUMBER> ) * ( N - <NUMBER> ) * ( N - <NUMBER> ) ) <NEWLINE> m = k - <NUMBER> <NEWLINE> A2 = ( A2kN - m ) / math . sqrt ( sigmasq ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> b0 = np . array ( [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] ) <NEWLINE> b1 = np . array ( [ - <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] ) <NEWLINE> b2 = np . array ( [ - <NUMBER> , - <NUMBER> , - <NUMBER> , - <NUMBER> , - <NUMBER> ] ) <NEWLINE> critical = b0 + b1 / math . sqrt ( m ) + b2 / m <NEWLINE> pf = np . polyfit ( critical , log ( np . array ( [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] ) ) , <NUMBER> ) <NEWLINE> if A2 < critical . min ( ) or A2 > critical . max ( ) : <NEWLINE> <TAB> warnings . warn ( <STRING> ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> p = math . exp ( np . polyval ( pf , A2 ) ) <NEWLINE> <UNTAB> except ( OverflowError , ) : <NEWLINE> <TAB> p = float ( <STRING> ) <NEWLINE> <UNTAB> return Anderson_ksampResult ( A2 , critical , p ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def swarm_points ( self , ax , points , center , width , s , ** kws ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> default_lw = mpl . rcParams [ <STRING> ] <NEWLINE> lw = kws . get ( <STRING> , kws . get ( <STRING> , default_lw ) ) <NEWLINE> dpi = ax . figure . dpi <NEWLINE> d = ( np . sqrt ( s ) + lw ) * ( dpi / <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> orig_xy = ax . transData . transform ( points . get_offsets ( ) ) <NEWLINE> <NEWLINE> <NEWLINE> if self . orient == <STRING> : <NEWLINE> <TAB> orig_xy = orig_xy [ : , [ <NUMBER> , <NUMBER> ] ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> new_xy = self . beeswarm ( orig_xy , d ) <NEWLINE> <NEWLINE> <NEWLINE> if self . orient == <STRING> : <NEWLINE> <TAB> new_xy = new_xy [ : , [ <NUMBER> , <NUMBER> ] ] <NEWLINE> <UNTAB> new_x , new_y = ax . transData . inverted ( ) . transform ( new_xy ) . T <NEWLINE> <NEWLINE> <NEWLINE> if self . orient == <STRING> : <NEWLINE> <TAB> self . add_gutters ( new_x , center , width ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . add_gutters ( new_y , center , width ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> points . set_offsets ( np . c_ [ new_x , new_y ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def splittag ( url ) : <NEWLINE> <TAB> <NEWLINE> path , delim , tag = url . rpartition ( <STRING> ) <NEWLINE> if delim : <NEWLINE> <TAB> return path , tag <NEWLINE> <UNTAB> return url , None <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def linear_interpolate ( p , x , y ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return LinearInterpolate ( ) . apply ( ( p , x , y ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def gen_preprocess_options ( macros , include_dirs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> pp_opts = [ ] <NEWLINE> for macro in macros : <NEWLINE> <TAB> if not ( isinstance ( macro , tuple ) and <NUMBER> <= len ( macro ) <= <NUMBER> ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> % macro ) <NEWLINE> <NEWLINE> <UNTAB> if len ( macro ) == <NUMBER> : <NEWLINE> <TAB> pp_opts . append ( <STRING> % macro [ <NUMBER> ] ) <NEWLINE> <UNTAB> elif len ( macro ) == <NUMBER> : <NEWLINE> <TAB> if macro [ <NUMBER> ] is None : <NEWLINE> <TAB> pp_opts . append ( <STRING> % macro [ <NUMBER> ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> pp_opts . append ( <STRING> % macro ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> for dir in include_dirs : <NEWLINE> <TAB> pp_opts . append ( <STRING> % dir ) <NEWLINE> <UNTAB> return pp_opts <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def sub_pre ( e ) : <NEWLINE> <TAB> <NEWLINE> reps = [ a for a in e . atoms ( Add ) if a . could_extract_minus_sign ( ) ] <NEWLINE> <NEWLINE> <NEWLINE> reps . sort ( key = default_sort_key ) <NEWLINE> <NEWLINE> e = e . xreplace ( dict ( ( a , Mul . _from_args ( [ S . NegativeOne , - a ] ) ) for a in reps ) ) <NEWLINE> <NEWLINE> <NEWLINE> if isinstance ( e , Basic ) : <NEWLINE> <TAB> negs = { } <NEWLINE> for a in sorted ( e . atoms ( Add ) , key = default_sort_key ) : <NEWLINE> <TAB> if a in reps or a . could_extract_minus_sign ( ) : <NEWLINE> <TAB> negs [ a ] = Mul . _from_args ( [ S . One , S . NegativeOne , - a ] ) <NEWLINE> <UNTAB> <UNTAB> e = e . xreplace ( negs ) <NEWLINE> <UNTAB> return e <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def trace ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> def wrapper ( func ) : <NEWLINE> <TAB> executor_options = { <STRING> : True } <NEWLINE> for name in executor_options : <NEWLINE> <TAB> executor_options [ name ] = kwargs . pop ( name , executor_options [ name ] ) <NEWLINE> <UNTAB> if len ( kwargs ) != <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> . format ( <STRING> . join ( kwargs . keys ( ) ) ) ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( func , torch . nn . Module ) : <NEWLINE> <TAB> orig = func <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> orig = Module ( ) <NEWLINE> <NEWLINE> <UNTAB> module = TopLevelTracedModule ( orig , ** executor_options ) <NEWLINE> module . _create_method_from_trace ( <STRING> , func , args ) <NEWLINE> return module <NEWLINE> <NEWLINE> <UNTAB> return wrapper <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def effective_n_jobs ( self , n_jobs ) : <NEWLINE> <TAB> <NEWLINE> if n_jobs == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> elif mp is None or n_jobs is None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> elif mp . current_process ( ) . daemon : <NEWLINE> <NEWLINE> <TAB> if n_jobs != <NUMBER> : <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> , <NEWLINE> stacklevel = <NUMBER> ) <NEWLINE> <UNTAB> return <NUMBER> <NEWLINE> <UNTAB> elif not isinstance ( threading . current_thread ( ) , threading . _MainThread ) : <NEWLINE> <NEWLINE> <TAB> if n_jobs != <NUMBER> : <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> , <NEWLINE> stacklevel = <NUMBER> ) <NEWLINE> <UNTAB> return <NUMBER> <NEWLINE> <UNTAB> elif n_jobs < <NUMBER> : <NEWLINE> <TAB> n_jobs = max ( cpu_count ( ) + <NUMBER> + n_jobs , <NUMBER> ) <NEWLINE> <UNTAB> return n_jobs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def clear ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _adj . clear ( ) <NEWLINE> self . _node . clear ( ) <NEWLINE> self . graph . clear ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _array_perimeter ( arr ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> forward = np . s_ [ <NUMBER> : - <NUMBER> ] <NEWLINE> backward = np . s_ [ - <NUMBER> : <NUMBER> : - <NUMBER> ] <NEWLINE> return np . concatenate ( ( <NEWLINE> arr [ <NUMBER> , forward ] , <NEWLINE> arr [ forward , - <NUMBER> ] , <NEWLINE> arr [ - <NUMBER> , backward ] , <NEWLINE> arr [ backward , <NUMBER> ] , <NEWLINE> ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def connect_to_remote_host ( remote_host = None , job_name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if remote_host is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> cluster_def = ClusterDef ( ) <NEWLINE> job_def = cluster_def . job . add ( ) <NEWLINE> job_def . name = job_name <NEWLINE> job_def . tasks [ <NUMBER> ] = <STRING> <NEWLINE> job_def . tasks [ <NUMBER> ] = remote_host <NEWLINE> <NEWLINE> server_def = ServerDef ( <NEWLINE> cluster = cluster_def , <NEWLINE> job_name = job_name , <NEWLINE> task_index = <NUMBER> , <NEWLINE> protocol = <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> os . environ [ <STRING> ] = <STRING> <NEWLINE> context . set_server_def ( server_def ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def polar ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if gcf ( ) . get_axes ( ) : <NEWLINE> <TAB> if not isinstance ( gca ( ) , PolarAxes ) : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> ax = gca ( polar = True ) <NEWLINE> ret = ax . plot ( * args , ** kwargs ) <NEWLINE> return ret <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _split_logits ( self , logits ) : <NEWLINE> <TAB> <NEWLINE> all_logits = [ ] <NEWLINE> begin = <NUMBER> <NEWLINE> for head in self . _heads : <NEWLINE> <TAB> current_logits_size = head . logits_dimension <NEWLINE> current_logits = array_ops . slice ( logits , [ <NUMBER> , begin ] , <NEWLINE> [ - <NUMBER> , current_logits_size ] ) <NEWLINE> all_logits . append ( current_logits ) <NEWLINE> begin += current_logits_size <NEWLINE> <UNTAB> return all_logits <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def extract_func_data ( self , func ) : <NEWLINE> <TAB> <NEWLINE> code = func . __code__ <NEWLINE> <NEWLINE> <NEWLINE> func_global_refs = self . extract_code_globals ( code ) <NEWLINE> <NEWLINE> <NEWLINE> f_globals = { } <NEWLINE> for var in func_global_refs : <NEWLINE> <TAB> if var in func . __globals__ : <NEWLINE> <TAB> f_globals [ var ] = func . __globals__ [ var ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> defaults = func . __defaults__ <NEWLINE> <NEWLINE> <NEWLINE> closure = ( <NEWLINE> list ( map ( _get_cell_contents , func . __closure__ ) ) <NEWLINE> if func . __closure__ is not None <NEWLINE> else None <NEWLINE> ) <NEWLINE> <NEWLINE> <NEWLINE> dct = func . __dict__ <NEWLINE> <NEWLINE> base_globals = self . globals_ref . get ( id ( func . __globals__ ) , None ) <NEWLINE> if base_globals is None : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if hasattr ( func , <STRING> ) and func . __module__ is not None : <NEWLINE> <TAB> base_globals = func . __module__ <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> base_globals = { } <NEWLINE> <UNTAB> <UNTAB> self . globals_ref [ id ( func . __globals__ ) ] = base_globals <NEWLINE> <NEWLINE> return ( code , f_globals , defaults , closure , dct , base_globals ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_multialignment ( self , align ) : <NEWLINE> <TAB> <NEWLINE> legal = ( <STRING> , <STRING> , <STRING> ) <NEWLINE> if align not in legal : <NEWLINE> <TAB> raise ValueError ( <STRING> % <NEWLINE> str ( legal ) ) <NEWLINE> <UNTAB> self . _multialignment = align <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def summary ( self , line_length = None , positions = None , print_fn = None ) : <NEWLINE> <TAB> <NEWLINE> if not self . built : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> return print_layer_summary ( self , <NEWLINE> line_length = line_length , <NEWLINE> positions = positions , <NEWLINE> print_fn = print_fn ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pager_print ( expr , ** settings ) : <NEWLINE> <TAB> <NEWLINE> from pydoc import pager <NEWLINE> from locale import getpreferredencoding <NEWLINE> if <STRING> not in settings : <NEWLINE> <TAB> settings [ <STRING> ] = <NUMBER> <NEWLINE> <UNTAB> pager ( pretty ( expr , ** settings ) . encode ( getpreferredencoding ( ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def pack_propagate ( self , flag = _noarg_ ) : <NEWLINE> <TAB> <NEWLINE> if flag is Misc . _noarg_ : <NEWLINE> <TAB> return self . _getboolean ( self . tk . call ( <NEWLINE> <STRING> , <STRING> , self . _w ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . tk . call ( <STRING> , <STRING> , self . _w , flag ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _rewrite_saxena_1 ( fac , po , g , x ) : <NEWLINE> <TAB> <NEWLINE> _ , s = _get_coeff_exp ( po , x ) <NEWLINE> a , b = _get_coeff_exp ( g . argument , x ) <NEWLINE> period = g . get_period ( ) <NEWLINE> a = _my_principal_branch ( a , period ) <NEWLINE> <NEWLINE> <NEWLINE> C = fac / ( abs ( b ) * a ** ( ( s + <NUMBER> ) / b - <NUMBER> ) ) <NEWLINE> <NEWLINE> <NEWLINE> def tr ( l ) : <NEWLINE> <TAB> return [ a + ( <NUMBER> + s ) / b - <NUMBER> for a in l ] <NEWLINE> <UNTAB> return C , meijerg ( tr ( g . an ) , tr ( g . aother ) , tr ( g . bm ) , tr ( g . bother ) , <NEWLINE> a * x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit ( self , X = None , y = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . _validate_params ( self . n_features , self . input_type ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def makedirs ( name , mode = <NUMBER> , exist_ok = False ) : <NEWLINE> <TAB> <NEWLINE> head , tail = path . split ( name ) <NEWLINE> if not tail : <NEWLINE> <TAB> head , tail = path . split ( head ) <NEWLINE> <UNTAB> if head and tail and not path . exists ( head ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> makedirs ( head , mode , exist_ok ) <NEWLINE> <UNTAB> except FileExistsError : <NEWLINE> <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> cdir = curdir <NEWLINE> if isinstance ( tail , bytes ) : <NEWLINE> <TAB> cdir = bytes ( curdir , <STRING> ) <NEWLINE> <UNTAB> if tail == cdir : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> <UNTAB> try : <NEWLINE> <TAB> mkdir ( name , mode ) <NEWLINE> <UNTAB> except OSError : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if not exist_ok or not path . isdir ( name ) : <NEWLINE> <TAB> raise <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _set_transforms ( self ) : <NEWLINE> <TAB> <NEWLINE> ax = self . axes <NEWLINE> fig = self . figure <NEWLINE> <NEWLINE> if self . _units == <STRING> : <NEWLINE> <TAB> sc = <NUMBER> <NEWLINE> <UNTAB> elif self . _units == <STRING> : <NEWLINE> <TAB> sc = ax . bbox . width / ax . viewLim . width <NEWLINE> <UNTAB> elif self . _units == <STRING> : <NEWLINE> <TAB> sc = ax . bbox . height / ax . viewLim . height <NEWLINE> <UNTAB> elif self . _units == <STRING> : <NEWLINE> <TAB> sc = fig . dpi <NEWLINE> <UNTAB> elif self . _units == <STRING> : <NEWLINE> <TAB> sc = fig . dpi / <NUMBER> <NEWLINE> <UNTAB> elif self . _units == <STRING> : <NEWLINE> <TAB> sc = ax . bbox . width <NEWLINE> <UNTAB> elif self . _units == <STRING> : <NEWLINE> <TAB> sc = ax . bbox . height <NEWLINE> <UNTAB> elif self . _units == <STRING> : <NEWLINE> <TAB> sc = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % self . _units ) <NEWLINE> <NEWLINE> <UNTAB> self . _transforms = np . zeros ( ( len ( self . _widths ) , <NUMBER> , <NUMBER> ) ) <NEWLINE> widths = self . _widths * sc <NEWLINE> heights = self . _heights * sc <NEWLINE> sin_angle = np . sin ( self . _angles ) <NEWLINE> cos_angle = np . cos ( self . _angles ) <NEWLINE> self . _transforms [ : , <NUMBER> , <NUMBER> ] = widths * cos_angle <NEWLINE> self . _transforms [ : , <NUMBER> , <NUMBER> ] = heights * - sin_angle <NEWLINE> self . _transforms [ : , <NUMBER> , <NUMBER> ] = widths * sin_angle <NEWLINE> self . _transforms [ : , <NUMBER> , <NUMBER> ] = heights * cos_angle <NEWLINE> self . _transforms [ : , <NUMBER> , <NUMBER> ] = <NUMBER> <NEWLINE> <NEWLINE> _affine = transforms . Affine2D <NEWLINE> if self . _units == <STRING> : <NEWLINE> <TAB> m = ax . transData . get_affine ( ) . get_matrix ( ) . copy ( ) <NEWLINE> m [ : <NUMBER> , <NUMBER> : ] = <NUMBER> <NEWLINE> self . set_transform ( _affine ( m ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_value ( self , index , col , value , takeable = False ) : <NEWLINE> <TAB> <NEWLINE> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> , FutureWarning , <NEWLINE> stacklevel = <NUMBER> ) <NEWLINE> return self . _set_value ( index , col , value , takeable = takeable ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def make_new_inplace ( self , output_types_preference = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> return self . __class__ ( self . o_type , name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _pack ( cls , tensors ) : <NEWLINE> <TAB> <NEWLINE> if not tensors : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> elif len ( tensors ) == <NUMBER> : <NEWLINE> <TAB> return array_ops . reshape ( tensors [ <NUMBER> ] , [ - <NUMBER> ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> flattened = [ array_ops . reshape ( tensor , [ - <NUMBER> ] ) for tensor in tensors ] <NEWLINE> return array_ops . concat ( flattened , <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def hb_write ( path_or_open_file , m , hb_info = None ) : <NEWLINE> <TAB> <NEWLINE> if hb_info is None : <NEWLINE> <TAB> hb_info = HBInfo . from_data ( m ) <NEWLINE> <NEWLINE> <UNTAB> def _set_matrix ( fid ) : <NEWLINE> <TAB> hb = HBFile ( fid , hb_info ) <NEWLINE> return hb . write_matrix ( m ) <NEWLINE> <NEWLINE> <UNTAB> if hasattr ( path_or_open_file , <STRING> ) : <NEWLINE> <TAB> return _set_matrix ( path_or_open_file ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> with open ( path_or_open_file , <STRING> ) as f : <NEWLINE> <TAB> return _set_matrix ( f ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _standard_rvs ( self , n , shape , dim , df , random_state ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> n_tril = dim * ( dim - <NUMBER> ) // <NUMBER> <NEWLINE> covariances = random_state . normal ( <NEWLINE> size = n * n_tril ) . reshape ( shape + ( n_tril , ) ) <NEWLINE> <NEWLINE> <NEWLINE> variances = np . r_ [ [ random_state . chisquare ( df - ( i + <NUMBER> ) + <NUMBER> , size = n ) ** <NUMBER> <NEWLINE> for i in range ( dim ) ] ] . reshape ( ( dim , ) + shape [ : : - <NUMBER> ] ) . T <NEWLINE> <NEWLINE> <NEWLINE> A = np . zeros ( shape + ( dim , dim ) ) <NEWLINE> <NEWLINE> <NEWLINE> size_idx = tuple ( [ slice ( None , None , None ) ] * len ( shape ) ) <NEWLINE> tril_idx = np . tril_indices ( dim , k = - <NUMBER> ) <NEWLINE> A [ size_idx + tril_idx ] = covariances <NEWLINE> <NEWLINE> <NEWLINE> diag_idx = np . diag_indices ( dim ) <NEWLINE> A [ size_idx + diag_idx ] = variances <NEWLINE> <NEWLINE> return A <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def autoscale_None ( self , A ) : <NEWLINE> <TAB> <NEWLINE> if self . vmin is not None and self . vmax is not None : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> A = np . asanyarray ( A ) <NEWLINE> if self . vmin is None and A . size : <NEWLINE> <TAB> self . vmin = A . min ( ) <NEWLINE> <UNTAB> if self . vmax is None and A . size : <NEWLINE> <TAB> self . vmax = A . max ( ) <NEWLINE> <UNTAB> self . _transform_vmin_vmax ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def union ( G , H , rename = ( None , None ) , name = None ) : <NEWLINE> <TAB> <NEWLINE> if not G . is_multigraph ( ) == H . is_multigraph ( ) : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> R = G . __class__ ( ) <NEWLINE> <NEWLINE> R . graph . update ( G . graph ) <NEWLINE> R . graph . update ( H . graph ) <NEWLINE> <NEWLINE> <NEWLINE> def add_prefix ( graph , prefix ) : <NEWLINE> <TAB> if prefix is None : <NEWLINE> <TAB> return graph <NEWLINE> <NEWLINE> <UNTAB> def label ( x ) : <NEWLINE> <TAB> if is_string_like ( x ) : <NEWLINE> <TAB> name = prefix + x <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> name = prefix + repr ( x ) <NEWLINE> <UNTAB> return name <NEWLINE> <UNTAB> return nx . relabel_nodes ( graph , label ) <NEWLINE> <UNTAB> G = add_prefix ( G , rename [ <NUMBER> ] ) <NEWLINE> H = add_prefix ( H , rename [ <NUMBER> ] ) <NEWLINE> if set ( G ) & set ( H ) : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> , <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if G . is_multigraph ( ) : <NEWLINE> <TAB> G_edges = G . edges ( keys = True , data = True ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> G_edges = G . edges ( data = True ) <NEWLINE> <UNTAB> if H . is_multigraph ( ) : <NEWLINE> <TAB> H_edges = H . edges ( keys = True , data = True ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> H_edges = H . edges ( data = True ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> R . add_nodes_from ( G ) <NEWLINE> R . add_edges_from ( G_edges ) <NEWLINE> <NEWLINE> R . add_nodes_from ( H ) <NEWLINE> R . add_edges_from ( H_edges ) <NEWLINE> <NEWLINE> for n in G : <NEWLINE> <TAB> R . nodes [ n ] . update ( G . nodes [ n ] ) <NEWLINE> <UNTAB> for n in H : <NEWLINE> <TAB> R . nodes [ n ] . update ( H . nodes [ n ] ) <NEWLINE> <NEWLINE> <UNTAB> return R <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_modulus ( f ) : <NEWLINE> <TAB> <NEWLINE> domain = f . get_domain ( ) <NEWLINE> <NEWLINE> if domain . is_FiniteField : <NEWLINE> <TAB> return Integer ( domain . characteristic ( ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise PolynomialError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def save_attrgetter ( self , obj ) : <NEWLINE> <TAB> <NEWLINE> class Dummy ( object ) : <NEWLINE> <TAB> def __init__ ( self , attrs , index = None ) : <NEWLINE> <TAB> self . attrs = attrs <NEWLINE> self . index = index <NEWLINE> <UNTAB> def __getattribute__ ( self , item ) : <NEWLINE> <TAB> attrs = object . __getattribute__ ( self , <STRING> ) <NEWLINE> index = object . __getattribute__ ( self , <STRING> ) <NEWLINE> if index is None : <NEWLINE> <TAB> index = len ( attrs ) <NEWLINE> attrs . append ( item ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> attrs [ index ] = <STRING> . join ( [ attrs [ index ] , item ] ) <NEWLINE> <UNTAB> return type ( self ) ( attrs , index ) <NEWLINE> <UNTAB> <UNTAB> attrs = [ ] <NEWLINE> obj ( Dummy ( attrs ) ) <NEWLINE> return self . save_reduce ( operator . attrgetter , tuple ( attrs ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def forward_event_shape ( self , input_shape ) : <NEWLINE> <TAB> <NEWLINE> return self . _forward_event_shape ( tensor_shape . TensorShape ( input_shape ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_swap ( f , i , j , u , K ) : <NEWLINE> <TAB> <NEWLINE> if i < <NUMBER> or j < <NUMBER> or i > u or j > u : <NEWLINE> <TAB> raise IndexError ( <STRING> % u ) <NEWLINE> <UNTAB> elif i == j : <NEWLINE> <TAB> return f <NEWLINE> <NEWLINE> <UNTAB> F , H = dmp_to_dict ( f , u ) , { } <NEWLINE> <NEWLINE> for exp , coeff in F . items ( ) : <NEWLINE> <TAB> H [ exp [ : i ] + ( exp [ j ] , ) + <NEWLINE> exp [ i + <NUMBER> : j ] + <NEWLINE> ( exp [ i ] , ) + exp [ j + <NUMBER> : ] ] = coeff <NEWLINE> <NEWLINE> <UNTAB> return dmp_from_dict ( H , u , K ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_isomorphic ( T1 , T2 ) : <NEWLINE> <TAB> <NEWLINE> T1 = np . asarray ( T1 , order = <STRING> ) <NEWLINE> T2 = np . asarray ( T2 , order = <STRING> ) <NEWLINE> <NEWLINE> if type ( T1 ) != np . ndarray : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if type ( T2 ) != np . ndarray : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> T1S = T1 . shape <NEWLINE> T2S = T2 . shape <NEWLINE> <NEWLINE> if len ( T1S ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if len ( T2S ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if T1S [ <NUMBER> ] != T2S [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> n = T1S [ <NUMBER> ] <NEWLINE> d1 = { } <NEWLINE> d2 = { } <NEWLINE> for i in xrange ( <NUMBER> , n ) : <NEWLINE> <TAB> if T1 [ i ] in d1 : <NEWLINE> <TAB> if not T2 [ i ] in d2 : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> if d1 [ T1 [ i ] ] != T2 [ i ] or d2 [ T2 [ i ] ] != T1 [ i ] : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> elif T2 [ i ] in d2 : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> d1 [ T1 [ i ] ] = T2 [ i ] <NEWLINE> d2 [ T2 [ i ] ] = T1 [ i ] <NEWLINE> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def ismethod ( object ) : <NEWLINE> <TAB> <NEWLINE> return isinstance ( object , types . MethodType ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def adaptive_avg_pool2d ( input , output_size ) : <NEWLINE> <TAB> <NEWLINE> output_size = _list_with_default ( output_size , input . size ( ) ) <NEWLINE> return torch . _C . _nn . adaptive_avg_pool2d ( input , output_size ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_default_reinterpreted_batch_ndims ( self , distribution ) : <NEWLINE> <TAB> <NEWLINE> ndims = distribution . batch_shape . ndims <NEWLINE> if ndims is None : <NEWLINE> <TAB> which_maximum = math_ops . maximum <NEWLINE> ndims = array_ops . shape ( distribution . batch_shape_tensor ( ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> which_maximum = np . maximum <NEWLINE> <UNTAB> return which_maximum ( <NUMBER> , ndims - <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def update ( self , var , fn , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> _require_cross_replica_context ( self ) <NEWLINE> options = { <STRING> : kwargs . pop ( <STRING> , True ) } <NEWLINE> return self . _update ( var , options , fn , * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_sparse ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def fast_inplace_check ( inputs ) : <NEWLINE> <TAB> <NEWLINE> fgraph = inputs [ <NUMBER> ] . fgraph <NEWLINE> Supervisor = theano . compile . function_module . Supervisor <NEWLINE> protected_inputs = [ f . protected for f in fgraph . _features <NEWLINE> if isinstance ( f , Supervisor ) ] <NEWLINE> protected_inputs = sum ( protected_inputs , [ ] ) <NEWLINE> protected_inputs . extend ( fgraph . outputs ) <NEWLINE> <NEWLINE> inputs = [ i for i in inputs if <NEWLINE> not isinstance ( i , graph . Constant ) and <NEWLINE> not fgraph . has_destroyers ( [ i ] ) and <NEWLINE> i not in protected_inputs ] <NEWLINE> return inputs <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_isosceles ( self ) : <NEWLINE> <TAB> <NEWLINE> return has_dups ( s . length for s in self . sides ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def first_connect ( self , dbapi_connection , connection_record ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def savefig ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> kwargs = kwargs . copy ( ) <NEWLINE> kwargs . setdefault ( <STRING> , <STRING> ) <NEWLINE> self . fig . savefig ( * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def polygamma ( n , x ) : <NEWLINE> <TAB> <NEWLINE> return PolyGamma ( ) . apply ( ( n , x ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def suptitle ( self , t , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> manual_position = ( <STRING> in kwargs or <STRING> in kwargs ) <NEWLINE> <NEWLINE> x = kwargs . pop ( <STRING> , <NUMBER> ) <NEWLINE> y = kwargs . pop ( <STRING> , <NUMBER> ) <NEWLINE> <NEWLINE> if <STRING> not in kwargs and <STRING> not in kwargs : <NEWLINE> <TAB> kwargs [ <STRING> ] = <STRING> <NEWLINE> <UNTAB> if <STRING> not in kwargs and <STRING> not in kwargs : <NEWLINE> <TAB> kwargs [ <STRING> ] = <STRING> <NEWLINE> <NEWLINE> <UNTAB> if <STRING> not in kwargs : <NEWLINE> <TAB> if <STRING> not in kwargs and <STRING> not in kwargs : <NEWLINE> <TAB> kwargs [ <STRING> ] = rcParams [ <STRING> ] <NEWLINE> <UNTAB> if <STRING> not in kwargs and <STRING> not in kwargs : <NEWLINE> <TAB> kwargs [ <STRING> ] = rcParams [ <STRING> ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> sup = self . text ( x , y , t , ** kwargs ) <NEWLINE> if self . _suptitle is not None : <NEWLINE> <TAB> self . _suptitle . set_text ( t ) <NEWLINE> self . _suptitle . set_position ( ( x , y ) ) <NEWLINE> self . _suptitle . update_from ( sup ) <NEWLINE> sup . remove ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _suptitle = sup <NEWLINE> self . _suptitle . _layoutbox = None <NEWLINE> if self . _layoutbox is not None and not manual_position : <NEWLINE> <TAB> w_pad , h_pad , wspace , hspace = self . get_constrained_layout_pads ( relative = True ) <NEWLINE> figlb = self . _layoutbox <NEWLINE> self . _suptitle . _layoutbox = layoutbox . LayoutBox ( <NEWLINE> parent = figlb , artist = self . _suptitle , <NEWLINE> name = figlb . name + <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for child in figlb . children : <NEWLINE> <TAB> if child is not self . _suptitle . _layoutbox : <NEWLINE> <TAB> layoutbox . vstack ( [ self . _suptitle . _layoutbox , <NEWLINE> child ] , <NEWLINE> padding = h_pad * <NUMBER> , strength = <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> self . stale = True <NEWLINE> return self . _suptitle <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def options ( self ) : <NEWLINE> <TAB> <NEWLINE> options = Options ( ) <NEWLINE> for input_dataset in self . _inputs ( ) : <NEWLINE> <TAB> input_options = input_dataset . options ( ) <NEWLINE> if input_options is not None : <NEWLINE> <TAB> options = options . merge ( input_options ) <NEWLINE> <UNTAB> <UNTAB> return options <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_constrained_layout ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _constrained <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def kurtosistest ( a , axis = <NUMBER> , nan_policy = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> a , axis = _chk_asarray ( a , axis ) <NEWLINE> <NEWLINE> contains_nan , nan_policy = _contains_nan ( a , nan_policy ) <NEWLINE> <NEWLINE> if contains_nan and nan_policy == <STRING> : <NEWLINE> <TAB> a = ma . masked_invalid ( a ) <NEWLINE> return mstats_basic . kurtosistest ( a , axis ) <NEWLINE> <NEWLINE> <UNTAB> n = float ( a . shape [ axis ] ) <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % int ( n ) ) <NEWLINE> <UNTAB> if n < <NUMBER> : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> % int ( n ) ) <NEWLINE> <UNTAB> b2 = kurtosis ( a , axis , fisher = False ) <NEWLINE> <NEWLINE> E = <NUMBER> * ( n - <NUMBER> ) / ( n + <NUMBER> ) <NEWLINE> varb2 = <NUMBER> * n * ( n - <NUMBER> ) * ( n - <NUMBER> ) / ( ( n + <NUMBER> ) * ( n + <NUMBER> ) * ( n + <NUMBER> ) * ( n + <NUMBER> ) ) <NEWLINE> x = ( b2 - E ) / np . sqrt ( varb2 ) <NEWLINE> <NEWLINE> sqrtbeta1 = <NUMBER> * ( n * n - <NUMBER> * n + <NUMBER> ) / ( ( n + <NUMBER> ) * ( n + <NUMBER> ) ) * np . sqrt ( ( <NUMBER> * ( n + <NUMBER> ) * ( n + <NUMBER> ) ) / <NEWLINE> ( n * ( n - <NUMBER> ) * ( n - <NUMBER> ) ) ) <NEWLINE> <NEWLINE> A = <NUMBER> + <NUMBER> / sqrtbeta1 * ( <NUMBER> / sqrtbeta1 + np . sqrt ( <NUMBER> + <NUMBER> / ( sqrtbeta1 ** <NUMBER> ) ) ) <NEWLINE> term1 = <NUMBER> - <NUMBER> / ( <NUMBER> * A ) <NEWLINE> denom = <NUMBER> + x * np . sqrt ( <NUMBER> / ( A - <NUMBER> ) ) <NEWLINE> denom = np . where ( denom < <NUMBER> , <NUMBER> , denom ) <NEWLINE> term2 = np . where ( denom < <NUMBER> , term1 , np . power ( ( <NUMBER> - <NUMBER> / A ) / denom , <NUMBER> / <NUMBER> ) ) <NEWLINE> Z = ( term1 - term2 ) / np . sqrt ( <NUMBER> / ( <NUMBER> * A ) ) <NEWLINE> Z = np . where ( denom == <NUMBER> , <NUMBER> , Z ) <NEWLINE> if Z . ndim == <NUMBER> : <NEWLINE> <TAB> Z = Z [ ( ) ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return KurtosistestResult ( Z , <NUMBER> * distributions . norm . sf ( np . abs ( Z ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _ttest_finish ( df , t ) : <NEWLINE> <TAB> <NEWLINE> prob = distributions . t . sf ( np . abs ( t ) , df ) * <NUMBER> <NEWLINE> if t . ndim == <NUMBER> : <NEWLINE> <TAB> t = t [ ( ) ] <NEWLINE> <NEWLINE> <UNTAB> return t , prob <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def mx2num ( mxdates ) : <NEWLINE> <TAB> <NEWLINE> scalar = False <NEWLINE> if not cbook . iterable ( mxdates ) : <NEWLINE> <TAB> scalar = True <NEWLINE> mxdates = [ mxdates ] <NEWLINE> <UNTAB> ret = epoch2num ( [ m . ticks ( ) for m in mxdates ] ) <NEWLINE> if scalar : <NEWLINE> <TAB> return ret [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return ret <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def sub_ground ( f , c ) : <NEWLINE> <TAB> <NEWLINE> return f . per ( dmp_sub_ground ( f . rep , f . dom . convert ( c ) , f . lev , f . dom ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_class ( lookup_view ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( lookup_view , str ) : <NEWLINE> <TAB> mod_name , func_name = get_mod_func ( lookup_view ) <NEWLINE> if func_name != <STRING> : <NEWLINE> <TAB> lookup_view = getattr ( <NEWLINE> __import__ ( mod_name , { } , { } , [ <STRING> ] ) , func_name ) <NEWLINE> if not callable ( lookup_view ) : <NEWLINE> <TAB> raise AttributeError ( <NEWLINE> <STRING> % ( mod_name , func_name ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return lookup_view <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def get_session ( ) : <NEWLINE> <TAB> <NEWLINE> global _SESSION <NEWLINE> <NEWLINE> default_session = tf . get_default_session ( ) <NEWLINE> <NEWLINE> if default_session is not None : <NEWLINE> <TAB> session = default_session <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if _SESSION is None : <NEWLINE> <TAB> if not os . environ . get ( <STRING> ) : <NEWLINE> <TAB> config = tf . ConfigProto ( allow_soft_placement = True ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> num_thread = int ( os . environ . get ( <STRING> ) ) <NEWLINE> config = tf . ConfigProto ( intra_op_parallelism_threads = num_thread , <NEWLINE> allow_soft_placement = True ) <NEWLINE> <UNTAB> _SESSION = tf . Session ( config = config ) <NEWLINE> <UNTAB> session = _SESSION <NEWLINE> <UNTAB> if not _MANUAL_VAR_INIT : <NEWLINE> <TAB> with session . graph . as_default ( ) : <NEWLINE> <TAB> variables = tf . global_variables ( ) <NEWLINE> candidate_vars = [ ] <NEWLINE> for v in variables : <NEWLINE> <TAB> if not getattr ( v , <STRING> , False ) : <NEWLINE> <TAB> candidate_vars . append ( v ) <NEWLINE> <UNTAB> <UNTAB> if candidate_vars : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> is_initialized = session . run ( <NEWLINE> [ tf . is_variable_initialized ( v ) for v in candidate_vars ] ) <NEWLINE> uninitialized_vars = [ ] <NEWLINE> for flag , v in zip ( is_initialized , candidate_vars ) : <NEWLINE> <TAB> if not flag : <NEWLINE> <TAB> uninitialized_vars . append ( v ) <NEWLINE> <UNTAB> v . _keras_initialized = True <NEWLINE> <UNTAB> if uninitialized_vars : <NEWLINE> <TAB> session . run ( tf . variables_initializer ( uninitialized_vars ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> if not hasattr ( session , <STRING> ) : <NEWLINE> <TAB> session . list_devices = lambda : device_lib . list_local_devices ( ) <NEWLINE> <UNTAB> return session <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def helmert ( n , full = False ) : <NEWLINE> <TAB> <NEWLINE> H = np . tril ( np . ones ( ( n , n ) ) , - <NUMBER> ) - np . diag ( np . arange ( n ) ) <NEWLINE> d = np . arange ( n ) * np . arange ( <NUMBER> , n + <NUMBER> ) <NEWLINE> H [ <NUMBER> ] = <NUMBER> <NEWLINE> d [ <NUMBER> ] = n <NEWLINE> H_full = H / np . sqrt ( d ) [ : , np . newaxis ] <NEWLINE> if full : <NEWLINE> <TAB> return H_full <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return H_full [ <NUMBER> : ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def plugin_order ( ) : <NEWLINE> <TAB> <NEWLINE> p = { } <NEWLINE> for func in plugin_store : <NEWLINE> <TAB> p [ func ] = [ plugin_name for ( plugin_name , f ) in plugin_store [ func ] ] <NEWLINE> <UNTAB> return p <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_aperiodic ( G ) : <NEWLINE> <TAB> <NEWLINE> if not G . is_directed ( ) : <NEWLINE> <TAB> raise nx . NetworkXError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> s = arbitrary_element ( G ) <NEWLINE> levels = { s : <NUMBER> } <NEWLINE> this_level = [ s ] <NEWLINE> g = <NUMBER> <NEWLINE> l = <NUMBER> <NEWLINE> while this_level : <NEWLINE> <TAB> next_level = [ ] <NEWLINE> for u in this_level : <NEWLINE> <TAB> for v in G [ u ] : <NEWLINE> <TAB> if v in levels : <NEWLINE> <TAB> g = gcd ( g , levels [ u ] - levels [ v ] + <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> next_level . append ( v ) <NEWLINE> levels [ v ] = l <NEWLINE> <UNTAB> <UNTAB> <UNTAB> this_level = next_level <NEWLINE> l += <NUMBER> <NEWLINE> <UNTAB> if len ( levels ) == len ( G ) : <NEWLINE> <TAB> return g == <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return g == <NUMBER> and nx . is_aperiodic ( G . subgraph ( set ( G ) - set ( levels ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _concat_categorical ( to_concat , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def _concat_asobject ( to_concat ) : <NEWLINE> <TAB> to_concat = [ x . get_values ( ) if is_categorical_dtype ( x . dtype ) <NEWLINE> else np . asarray ( x ) . ravel ( ) for x in to_concat ] <NEWLINE> res = _concat_compat ( to_concat ) <NEWLINE> if axis == <NUMBER> : <NEWLINE> <TAB> return res . reshape ( <NUMBER> , len ( res ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return res <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> categoricals = [ x for x in to_concat if is_categorical_dtype ( x . dtype ) ] <NEWLINE> <NEWLINE> <NEWLINE> if len ( categoricals ) != len ( to_concat ) : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> first = to_concat [ <NUMBER> ] <NEWLINE> if all ( first . is_dtype_equal ( other ) for other in to_concat [ <NUMBER> : ] ) : <NEWLINE> <TAB> return union_categoricals ( categoricals ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return _concat_asobject ( to_concat ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _log_signature_report ( signature_def_map , excluded_signatures ) : <NEWLINE> <TAB> <NEWLINE> sig_names_by_method_name = collections . defaultdict ( list ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for method_name in _FRIENDLY_METHOD_NAMES : <NEWLINE> <TAB> sig_names_by_method_name [ method_name ] = [ ] <NEWLINE> <NEWLINE> <UNTAB> for signature_name , sig in signature_def_map . items ( ) : <NEWLINE> <TAB> sig_names_by_method_name [ sig . method_name ] . append ( signature_name ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for method_name , sig_names in sig_names_by_method_name . items ( ) : <NEWLINE> <TAB> if method_name in _FRIENDLY_METHOD_NAMES : <NEWLINE> <TAB> method_name = _FRIENDLY_METHOD_NAMES [ method_name ] <NEWLINE> <UNTAB> logging . info ( <STRING> . format ( <NEWLINE> method_name , sig_names if sig_names else <STRING> ) ) <NEWLINE> <NEWLINE> <UNTAB> if excluded_signatures : <NEWLINE> <TAB> logging . info ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> for signature_name , message in excluded_signatures . items ( ) : <NEWLINE> <TAB> logging . info ( <STRING> . format ( signature_name , message ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not signature_def_map : <NEWLINE> <TAB> logging . warn ( <STRING> ) <NEWLINE> <UNTAB> elif ( signature_constants . DEFAULT_SERVING_SIGNATURE_DEF_KEY not in <NEWLINE> signature_def_map ) : <NEWLINE> <TAB> logging . warn ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get ( self , category ) : <NEWLINE> <TAB> <NEWLINE> if category not in self . _mapping : <NEWLINE> <TAB> if self . _freeze : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> self . _mapping [ category ] = len ( self . _mapping ) <NEWLINE> if self . _support_reverse : <NEWLINE> <TAB> self . _reverse_mapping . append ( category ) <NEWLINE> <UNTAB> <UNTAB> return self . _mapping [ category ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def afmFontProperty ( fontpath , font ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> name = font . get_familyname ( ) <NEWLINE> fontname = font . get_fontname ( ) . lower ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if font . get_angle ( ) != <NUMBER> or <STRING> in name . lower ( ) : <NEWLINE> <TAB> style = <STRING> <NEWLINE> <UNTAB> elif <STRING> in name . lower ( ) : <NEWLINE> <TAB> style = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> style = <STRING> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if name . lower ( ) in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> variant = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> variant = <STRING> <NEWLINE> <NEWLINE> <UNTAB> weight = font . get_weight ( ) . lower ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if <STRING> in fontname : <NEWLINE> <TAB> stretch = <STRING> <NEWLINE> <UNTAB> elif <STRING> in fontname or <STRING> in fontname : <NEWLINE> <TAB> stretch = <STRING> <NEWLINE> <UNTAB> elif <STRING> in fontname or <STRING> in fontname : <NEWLINE> <TAB> stretch = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> stretch = <STRING> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> size = <STRING> <NEWLINE> <NEWLINE> return FontEntry ( fontpath , name , style , variant , weight , stretch , size ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def shape ( source , kind = None ) : <NEWLINE> <TAB> <NEWLINE> return FunctionCall ( <NEWLINE> <STRING> , <NEWLINE> [ _printable ( source ) ] + <NEWLINE> ( [ _printable ( kind ) ] if kind else [ ] ) <NEWLINE> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def engine_connect ( self , conn , branch ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def getcol ( self , i ) : <NEWLINE> <TAB> <NEWLINE> M , N = self . shape <NEWLINE> i = int ( i ) <NEWLINE> if i < <NUMBER> : <NEWLINE> <TAB> i += N <NEWLINE> <UNTAB> if i < <NUMBER> or i >= N : <NEWLINE> <TAB> raise IndexError ( <STRING> % i ) <NEWLINE> <UNTAB> idx = slice ( * self . indptr [ i : i + <NUMBER> ] ) <NEWLINE> data = self . data [ idx ] . copy ( ) <NEWLINE> indices = self . indices [ idx ] . copy ( ) <NEWLINE> indptr = np . array ( [ <NUMBER> , len ( indices ) ] , dtype = self . indptr . dtype ) <NEWLINE> return csc_matrix ( ( data , indices , indptr ) , shape = ( M , <NUMBER> ) , <NEWLINE> dtype = self . dtype , copy = False ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _compile ( self , obj , src , ext , cc_args , extra_postargs , pp_opts ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _tan1 ( p , x , prec ) : <NEWLINE> <TAB> <NEWLINE> R = p . ring <NEWLINE> p1 = R ( <NUMBER> ) <NEWLINE> for precx in _giant_steps ( prec ) : <NEWLINE> <TAB> tmp = p - rs_atan ( p1 , x , precx ) <NEWLINE> tmp = rs_mul ( tmp , <NUMBER> + rs_square ( p1 , x , precx ) , x , precx ) <NEWLINE> p1 += tmp <NEWLINE> <UNTAB> return p1 <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _add_library ( self , name , sources , install_dir , build_info ) : <NEWLINE> <TAB> <NEWLINE> build_info = copy . copy ( build_info ) <NEWLINE> name = name <NEWLINE> build_info [ <STRING> ] = sources <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if not <STRING> in build_info : <NEWLINE> <TAB> build_info [ <STRING> ] = [ ] <NEWLINE> <NEWLINE> <UNTAB> self . _fix_paths_dict ( build_info ) <NEWLINE> <NEWLINE> <NEWLINE> self . libraries . append ( ( name , build_info ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def isend ( tensor , dst ) : <NEWLINE> <TAB> <NEWLINE> assert torch . distributed . _initialized == _INITIALIZED_PG , <STRING> <NEWLINE> return _DistributedRequest ( torch . _C . _dist_isend ( tensor , dst ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def update_units ( self , data ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> converter = munits . registry . get_converter ( data ) <NEWLINE> if converter is None : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> neednew = self . converter != converter <NEWLINE> self . converter = converter <NEWLINE> default = self . converter . default_units ( data , self ) <NEWLINE> if default is not None and self . units is None : <NEWLINE> <TAB> self . set_units ( default ) <NEWLINE> <NEWLINE> <UNTAB> if neednew : <NEWLINE> <TAB> self . _update_axisinfo ( ) <NEWLINE> <UNTAB> self . stale = True <NEWLINE> return True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _inv_totient_estimate ( m ) : <NEWLINE> <TAB> <NEWLINE> primes = [ d + <NUMBER> for d in divisors ( m ) if isprime ( d + <NUMBER> ) ] <NEWLINE> <NEWLINE> a , b = <NUMBER> , <NUMBER> <NEWLINE> <NEWLINE> for p in primes : <NEWLINE> <TAB> a *= p <NEWLINE> b *= p - <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> L = m <NEWLINE> U = int ( math . ceil ( m * ( float ( a ) / b ) ) ) <NEWLINE> <NEWLINE> P = p = <NUMBER> <NEWLINE> primes = [ ] <NEWLINE> <NEWLINE> while P <= U : <NEWLINE> <TAB> p = nextprime ( p ) <NEWLINE> primes . append ( p ) <NEWLINE> P *= p <NEWLINE> <NEWLINE> <UNTAB> P //= p <NEWLINE> b = <NUMBER> <NEWLINE> <NEWLINE> for p in primes [ : - <NUMBER> ] : <NEWLINE> <TAB> b *= p - <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> U = int ( math . ceil ( m * ( float ( P ) / b ) ) ) <NEWLINE> <NEWLINE> return L , U <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def compute_dz ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> dz_init = _DOF_estimator_geom . compute_dz ( self ) <NEWLINE> Uf0 = np . ravel ( dz_init ) <NEWLINE> <NEWLINE> reference_element = _ReducedHCT_Element ( ) <NEWLINE> J = CubicTriInterpolator . _get_jacobian ( self . _tris_pts ) <NEWLINE> eccs = self . _eccs <NEWLINE> triangles = self . _triangles <NEWLINE> Uc = self . z [ self . _triangles ] <NEWLINE> <NEWLINE> <NEWLINE> Kff_rows , Kff_cols , Kff_vals , Ff = reference_element . get_Kff_and_Ff ( <NEWLINE> J , eccs , triangles , Uc ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> tol = <NUMBER> <NEWLINE> n_dof = Ff . shape [ <NUMBER> ] <NEWLINE> Kff_coo = _Sparse_Matrix_coo ( Kff_vals , Kff_rows , Kff_cols , <NEWLINE> shape = ( n_dof , n_dof ) ) <NEWLINE> Kff_coo . compress_csc ( ) <NEWLINE> Uf , err = _cg ( A = Kff_coo , b = Ff , x0 = Uf0 , tol = tol ) <NEWLINE> <NEWLINE> <NEWLINE> err0 = np . linalg . norm ( Kff_coo . dot ( Uf0 ) - Ff ) <NEWLINE> if err0 < err : <NEWLINE> <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> Uf = Uf0 <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> dz = np . empty ( [ self . _pts . shape [ <NUMBER> ] , <NUMBER> ] , dtype = np . float64 ) <NEWLINE> dz [ : , <NUMBER> ] = Uf [ : : <NUMBER> ] <NEWLINE> dz [ : , <NUMBER> ] = Uf [ <NUMBER> : : <NUMBER> ] <NEWLINE> return dz <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_real_imag ( self , deep = True , ** hints ) : <NEWLINE> <TAB> <NEWLINE> return ( self , S . Zero ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_bool_dtype ( arr_or_dtype ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if arr_or_dtype is None : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> tipo = _get_dtype_type ( arr_or_dtype ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( arr_or_dtype , ABCIndexClass ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return ( arr_or_dtype . is_object and <NEWLINE> arr_or_dtype . inferred_type == <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return issubclass ( tipo , np . bool_ ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _replace_booleans ( tok ) : <NEWLINE> <TAB> <NEWLINE> toknum , tokval = tok <NEWLINE> if toknum == tokenize . OP : <NEWLINE> <TAB> if tokval == <STRING> : <NEWLINE> <TAB> return tokenize . NAME , <STRING> <NEWLINE> <UNTAB> elif tokval == <STRING> : <NEWLINE> <TAB> return tokenize . NAME , <STRING> <NEWLINE> <UNTAB> return toknum , tokval <NEWLINE> <UNTAB> return toknum , tokval <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , trainer ) : <NEWLINE> <TAB> <NEWLINE> updater = trainer . updater <NEWLINE> if self . unit == <STRING> : <NEWLINE> <TAB> epoch_detail = updater . epoch_detail <NEWLINE> previous_epoch_detail = self . _previous_epoch_detail <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if previous_epoch_detail < <NUMBER> : <NEWLINE> <TAB> previous_epoch_detail = updater . previous_epoch_detail <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . count = epoch_detail // self . period <NEWLINE> <NEWLINE> fire = previous_epoch_detail // self . period != epoch_detail // self . period <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> iteration = updater . iteration <NEWLINE> previous_iteration = self . _previous_iteration <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if previous_iteration < <NUMBER> : <NEWLINE> <TAB> previous_iteration = iteration - <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> fire = previous_iteration // self . period != iteration // self . period <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . _previous_iteration = updater . iteration <NEWLINE> if hasattr ( updater , <STRING> ) : <NEWLINE> <TAB> self . _previous_epoch_detail = updater . epoch_detail <NEWLINE> <NEWLINE> <UNTAB> return fire <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def order ( dsk , dependencies = None ) : <NEWLINE> <TAB> <NEWLINE> if dependencies is None : <NEWLINE> <TAB> dependencies = { k : get_dependencies ( dsk , k ) for k in dsk } <NEWLINE> <NEWLINE> <UNTAB> for k , deps in dependencies . items ( ) : <NEWLINE> <TAB> deps . discard ( k ) <NEWLINE> <NEWLINE> <UNTAB> dependents = reverse_dict ( dependencies ) <NEWLINE> <NEWLINE> total_dependencies = ndependencies ( dependencies , dependents ) <NEWLINE> total_dependents , min_dependencies = ndependents ( dependencies , dependents , total_dependencies ) <NEWLINE> <NEWLINE> waiting = { k : set ( v ) for k , v in dependencies . items ( ) } <NEWLINE> <NEWLINE> def dependencies_key ( x ) : <NEWLINE> <TAB> return total_dependencies . get ( x , <NUMBER> ) , ReverseStrComparable ( x ) <NEWLINE> <NEWLINE> <UNTAB> def dependents_key ( x ) : <NEWLINE> <TAB> return ( min_dependencies [ x ] , <NEWLINE> - total_dependents . get ( x , <NUMBER> ) , <NEWLINE> StrComparable ( x ) ) <NEWLINE> <NEWLINE> <UNTAB> result = dict ( ) <NEWLINE> seen = set ( ) <NEWLINE> i = <NUMBER> <NEWLINE> <NEWLINE> stack = [ k for k , v in dependents . items ( ) if not v ] <NEWLINE> if len ( stack ) < <NUMBER> : <NEWLINE> <TAB> stack = sorted ( stack , key = dependencies_key ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> stack = stack [ : : - <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> while stack : <NEWLINE> <TAB> item = stack . pop ( ) <NEWLINE> <NEWLINE> if item in result : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> deps = waiting [ item ] <NEWLINE> <NEWLINE> if deps : <NEWLINE> <TAB> stack . append ( item ) <NEWLINE> seen . add ( item ) <NEWLINE> if len ( deps ) < <NUMBER> : <NEWLINE> <TAB> deps = sorted ( deps , key = dependencies_key ) <NEWLINE> <UNTAB> stack . extend ( deps ) <NEWLINE> continue <NEWLINE> <NEWLINE> <UNTAB> result [ item ] = i <NEWLINE> i += <NUMBER> <NEWLINE> <NEWLINE> for dep in dependents [ item ] : <NEWLINE> <TAB> waiting [ dep ] . discard ( item ) <NEWLINE> <NEWLINE> <UNTAB> deps = [ d for d in dependents [ item ] <NEWLINE> if d not in result and not ( d in seen and len ( waiting [ d ] ) > <NUMBER> ) ] <NEWLINE> if len ( deps ) < <NUMBER> : <NEWLINE> <TAB> deps = sorted ( deps , key = dependents_key , reverse = True ) <NEWLINE> <NEWLINE> <UNTAB> stack . extend ( deps ) <NEWLINE> <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _randdm ( pnts ) : <NEWLINE> <TAB> <NEWLINE> if pnts >= <NUMBER> : <NEWLINE> <TAB> D = np . random . rand ( pnts * ( pnts - <NUMBER> ) / <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> return D <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> def strategy_random_sequential ( G , colors , seed = None ) : <NEWLINE> <TAB> <NEWLINE> nodes = list ( G ) <NEWLINE> seed . shuffle ( nodes ) <NEWLINE> return nodes <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def diff ( f , x ) : <NEWLINE> <TAB> <NEWLINE> x = x . to_poly ( ) <NEWLINE> return f . new ( f . numer . diff ( x ) * f . denom - f . numer * f . denom . diff ( x ) , f . denom ** <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def lagrange ( x , w ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> M = len ( x ) <NEWLINE> p = poly1d ( <NUMBER> ) <NEWLINE> for j in xrange ( M ) : <NEWLINE> <TAB> pt = poly1d ( w [ j ] ) <NEWLINE> for k in xrange ( M ) : <NEWLINE> <TAB> if k == j : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> fac = x [ j ] - x [ k ] <NEWLINE> pt *= poly1d ( [ <NUMBER> , - x [ k ] ] ) / fac <NEWLINE> <UNTAB> p += pt <NEWLINE> <UNTAB> return p <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def multiply_elementwise ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if self . shape != other . shape : <NEWLINE> <TAB> raise ShapeError ( <STRING> . format ( self . shape , other . shape ) ) <NEWLINE> <NEWLINE> <UNTAB> return self . _eval_matrix_mul_elementwise ( other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_texmanager ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _texmanager is None : <NEWLINE> <TAB> from matplotlib . texmanager import TexManager <NEWLINE> self . _texmanager = TexManager ( ) <NEWLINE> <UNTAB> return self . _texmanager <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _encode_relation ( self , name ) : <NEWLINE> <TAB> <NEWLINE> for char in <STRING> : <NEWLINE> <TAB> if char in name : <NEWLINE> <TAB> name = <STRING> % name <NEWLINE> break <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return <STRING> % ( _TK_RELATION , name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def c_sync ( self , name , sub ) : <NEWLINE> <TAB> <NEWLINE> fail = sub [ <STRING> ] <NEWLINE> type_num = self . dtype_specs ( ) [ <NUMBER> ] <NEWLINE> return " " " 
                 { P y _ X D E C R E F ( p y _ % ( n a m e ) s ) ; } 
                 i f   ( ! % ( n a m e ) s )   { 
                         P y _ I N C R E F ( P y _ N o n e ) ; 
                         p y _ % ( n a m e ) s   =   P y _ N o n e ; 
                 } 
                 e l s e   i f   ( ( v o i d * ) p y _ % ( n a m e ) s   ! =   ( v o i d * ) % ( n a m e ) s )   { 
                         p y _ % ( n a m e ) s   =   ( P y O b j e c t * ) % ( n a m e ) s ; 
                 } 
 
                 { P y _ X I N C R E F ( p y _ % ( n a m e ) s ) ; } 
 
                 i f   ( % ( n a m e ) s   & &   ! P y A r r a y _ I S A L I G N E D ( ( P y A r r a y O b j e c t * )   p y _ % ( n a m e ) s ) )   { 
                         P y E r r _ F o r m a t ( P y E x c _ N o t I m p l e m e n t e d E r r o r , 
                                                   " c _ s y n c :   e x p e c t e d   a n   a l i g n e d   a r r a y ,   g o t   n o n - a l i g n e d   a r r a y   o f   t y p e   % % l d " 
                                                   "   w i t h   % % l d   d i m e n s i o n s ,   w i t h   3   l a s t   d i m s   " 
                                                   " % % l d ,   % % l d ,   % % l d " 
                                                   "   a n d   3   l a s t   s t r i d e s   % % l d   % % l d ,   % % l d . " , 
                                                   ( l o n g   i n t )   P y A r r a y _ T Y P E ( ( P y A r r a y O b j e c t * )   p y _ % ( n a m e ) s ) , 
                                                   ( l o n g   i n t )   P y A r r a y _ N D I M ( % ( n a m e ) s ) , 
                                                   ( l o n g   i n t )   ( P y A r r a y _ N D I M ( % ( n a m e ) s )   > =   3   ? 
                 P y A r r a y _ D I M S ( % ( n a m e ) s ) [ P y A r r a y _ N D I M ( % ( n a m e ) s ) - 3 ]   :   - 1 ) , 
                                                   ( l o n g   i n t )   ( P y A r r a y _ N D I M ( % ( n a m e ) s )   > =   2   ? 
                 P y A r r a y _ D I M S ( % ( n a m e ) s ) [ P y A r r a y _ N D I M ( % ( n a m e ) s ) - 2 ]   :   - 1 ) , 
                                                   ( l o n g   i n t )   ( P y A r r a y _ N D I M ( % ( n a m e ) s )   > =   1   ? 
                 P y A r r a y _ D I M S ( % ( n a m e ) s ) [ P y A r r a y _ N D I M ( % ( n a m e ) s ) - 1 ]   :   - 1 ) , 
                                                   ( l o n g   i n t )   ( P y A r r a y _ N D I M ( % ( n a m e ) s )   > =   3   ? 
                 P y A r r a y _ S T R I D E S ( % ( n a m e ) s ) [ P y A r r a y _ N D I M ( % ( n a m e ) s ) - 3 ]   :   - 1 ) , 
                                                   ( l o n g   i n t )   ( P y A r r a y _ N D I M ( % ( n a m e ) s )   > =   2   ? 
                 P y A r r a y _ S T R I D E S ( % ( n a m e ) s ) [ P y A r r a y _ N D I M ( % ( n a m e ) s ) - 2 ]   :   - 1 ) , 
                                                   ( l o n g   i n t )   ( P y A r r a y _ N D I M ( % ( n a m e ) s )   > =   1   ? 
                 P y A r r a y _ S T R I D E S ( % ( n a m e ) s ) [ P y A r r a y _ N D I M ( % ( n a m e ) s ) - 1 ]   :   - 1 ) 
                 ) ; 
                         % ( f a i l ) s 
                 } 
                 " " " % locals ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def min ( x , axis = None , keepdims = False ) : <NEWLINE> <TAB> <NEWLINE> return Min ( axis , keepdims ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def circstd ( samples , high = <NUMBER> * pi , low = <NUMBER> , axis = None ) : <NEWLINE> <TAB> <NEWLINE> samples , ang = _circfuncs_common ( samples , high , low ) <NEWLINE> S = sin ( ang ) . mean ( axis = axis ) <NEWLINE> C = cos ( ang ) . mean ( axis = axis ) <NEWLINE> R = hypot ( S , C ) <NEWLINE> return ( ( high - low ) / <NUMBER> / pi ) * sqrt ( - <NUMBER> * log ( R ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def call ( self , inputs , state ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if self . _linear is None : <NEWLINE> <TAB> self . _linear = _Linear ( inputs , self . _num_proj , True ) <NEWLINE> <UNTAB> projected = self . _linear ( inputs ) <NEWLINE> if self . _activation : <NEWLINE> <TAB> projected = self . _activation ( projected ) <NEWLINE> <UNTAB> return self . _cell ( projected , state ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def parallel_plane ( self , pt ) : <NEWLINE> <TAB> <NEWLINE> a = self . normal_vector <NEWLINE> return Plane ( pt , normal_vector = a ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_Kff_and_Ff ( self , J , ecc , triangles , Uc ) : <NEWLINE> <TAB> <NEWLINE> ntri = np . size ( ecc , <NUMBER> ) <NEWLINE> vec_range = np . arange ( ntri , dtype = np . int32 ) <NEWLINE> c_indices = - np . ones ( ntri , dtype = np . int32 ) <NEWLINE> f_dof = [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] <NEWLINE> c_dof = [ <NUMBER> , <NUMBER> , <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> f_dof_indices = _to_matrix_vectorized ( [ [ <NEWLINE> c_indices , triangles [ : , <NUMBER> ] * <NUMBER> , triangles [ : , <NUMBER> ] * <NUMBER> + <NUMBER> , <NEWLINE> c_indices , triangles [ : , <NUMBER> ] * <NUMBER> , triangles [ : , <NUMBER> ] * <NUMBER> + <NUMBER> , <NEWLINE> c_indices , triangles [ : , <NUMBER> ] * <NUMBER> , triangles [ : , <NUMBER> ] * <NUMBER> + <NUMBER> ] ] ) <NEWLINE> <NEWLINE> expand_indices = np . ones ( [ ntri , <NUMBER> , <NUMBER> ] , dtype = np . int32 ) <NEWLINE> f_row_indices = _prod_vectorized ( _transpose_vectorized ( f_dof_indices ) , <NEWLINE> _transpose_vectorized ( expand_indices ) ) <NEWLINE> f_col_indices = _prod_vectorized ( expand_indices , f_dof_indices ) <NEWLINE> K_elem = self . get_bending_matrices ( J , ecc ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> Kff_vals = np . ravel ( K_elem [ np . ix_ ( vec_range , f_dof , f_dof ) ] ) <NEWLINE> Kff_rows = np . ravel ( f_row_indices [ np . ix_ ( vec_range , f_dof , f_dof ) ] ) <NEWLINE> Kff_cols = np . ravel ( f_col_indices [ np . ix_ ( vec_range , f_dof , f_dof ) ] ) <NEWLINE> <NEWLINE> <NEWLINE> Kfc_elem = K_elem [ np . ix_ ( vec_range , f_dof , c_dof ) ] <NEWLINE> Uc_elem = np . expand_dims ( Uc , axis = <NUMBER> ) <NEWLINE> Ff_elem = - _prod_vectorized ( Kfc_elem , Uc_elem ) [ : , : , <NUMBER> ] <NEWLINE> Ff_indices = f_dof_indices [ np . ix_ ( vec_range , [ <NUMBER> ] , f_dof ) ] [ : , <NUMBER> , : ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> Ff = np . bincount ( np . ravel ( Ff_indices ) , weights = np . ravel ( Ff_elem ) ) <NEWLINE> return Kff_rows , Kff_cols , Kff_vals , Ff <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_module_cache ( dirname , init_args = None ) : <NEWLINE> <TAB> <NEWLINE> global _module_cache <NEWLINE> if init_args is None : <NEWLINE> <TAB> init_args = { } <NEWLINE> <UNTAB> if _module_cache is None : <NEWLINE> <TAB> _module_cache = ModuleCache ( dirname , ** init_args ) <NEWLINE> atexit . register ( _module_cache . _on_atexit ) <NEWLINE> <UNTAB> elif init_args : <NEWLINE> <TAB> _logger . warning ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if _module_cache . dirname != dirname : <NEWLINE> <TAB> _logger . warning ( <STRING> <NEWLINE> <STRING> , <NEWLINE> _module_cache . dirname , dirname ) <NEWLINE> <UNTAB> return _module_cache <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def clear_session ( ) : <NEWLINE> <TAB> <NEWLINE> global _SESSION <NEWLINE> global _GRAPH_LEARNING_PHASES <NEWLINE> global _GRAPH_VARIABLES <NEWLINE> global _GRAPH_TF_OPTIMIZERS <NEWLINE> ops . reset_default_graph ( ) <NEWLINE> reset_uids ( ) <NEWLINE> _SESSION = None <NEWLINE> graph = get_graph ( ) <NEWLINE> with graph . as_default ( ) : <NEWLINE> <TAB> phase = array_ops . placeholder_with_default ( <NEWLINE> False , shape = ( ) , name = <STRING> ) <NEWLINE> _GRAPH_LEARNING_PHASES = { } <NEWLINE> _GRAPH_LEARNING_PHASES [ graph ] = phase <NEWLINE> _GRAPH_VARIABLES . pop ( graph , None ) <NEWLINE> _GRAPH_TF_OPTIMIZERS . pop ( graph , None ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_graph_def_from_disk ( filename ) : <NEWLINE> <TAB> <NEWLINE> with gfile . FastGFile ( filename , <STRING> ) as f : <NEWLINE> <TAB> return graph_pb2 . GraphDef . FromString ( f . read ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def convert ( f , dom ) : <NEWLINE> <TAB> <NEWLINE> if f . dom == dom : <NEWLINE> <TAB> return f <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return DMP ( dmp_convert ( f . rep , f . lev , f . dom , dom ) , dom , f . lev ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( <NEWLINE> <STRING> , <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> def binary_svm_target ( label_name = None , weight_column_name = None ) : <NEWLINE> <TAB> <NEWLINE> return _BinarySvmTargetColumn ( <NEWLINE> label_name = label_name , weight_column_name = weight_column_name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _next_opening_time ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if not self . next_bday . onOffset ( other ) : <NEWLINE> <TAB> other = other + self . next_bday <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if self . n >= <NUMBER> and self . start < other . time ( ) : <NEWLINE> <TAB> other = other + self . next_bday <NEWLINE> <UNTAB> elif self . n < <NUMBER> and other . time ( ) < self . start : <NEWLINE> <TAB> other = other + self . next_bday <NEWLINE> <UNTAB> <UNTAB> return datetime ( other . year , other . month , other . day , <NEWLINE> self . start . hour , self . start . minute ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def construct_fast ( cls , c , x , extrapolate = None , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> self = object . __new__ ( cls ) <NEWLINE> self . c = c <NEWLINE> self . x = x <NEWLINE> self . axis = axis <NEWLINE> if extrapolate is None : <NEWLINE> <TAB> extrapolate = True <NEWLINE> <UNTAB> self . extrapolate = extrapolate <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit_transform ( self , X , y = None ) : <NEWLINE> <TAB> <NEWLINE> return self . _transform ( X , fitting = True ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def register_shape_checker ( left_type , right_type , shape_checker_function ) : <NEWLINE> <TAB> <NEWLINE> key = ( left_type , right_type ) <NEWLINE> if key in shape_checkers : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( key , <NEWLINE> shape_checkers [ key ] ) ) <NEWLINE> <UNTAB> shape_checkers [ key ] = shape_checker_function <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def rank ( self , iszerofunc = _iszero , simplify = False ) : <NEWLINE> <TAB> <NEWLINE> simpfunc = simplify if isinstance ( <NEWLINE> simplify , FunctionType ) else _simplify <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if self . rows <= <NUMBER> or self . cols <= <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> if self . rows <= <NUMBER> or self . cols <= <NUMBER> : <NEWLINE> <TAB> zeros = [ iszerofunc ( x ) for x in self ] <NEWLINE> if False in zeros : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> <UNTAB> if self . rows == <NUMBER> and self . cols == <NUMBER> : <NEWLINE> <TAB> zeros = [ iszerofunc ( x ) for x in self ] <NEWLINE> if not False in zeros and not None in zeros : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> det = self . det ( ) <NEWLINE> if iszerofunc ( det ) and False in zeros : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> if iszerofunc ( det ) is False : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> mat , _ = self . _permute_complexity_right ( iszerofunc = iszerofunc ) <NEWLINE> echelon_form , pivots , swaps = mat . _eval_echelon_form ( iszerofunc = iszerofunc , simpfunc = simpfunc ) <NEWLINE> return len ( pivots ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _format_attrs ( self ) : <NEWLINE> <TAB> <NEWLINE> max_categories = ( <NUMBER> if get_option ( <STRING> ) == <NUMBER> else <NEWLINE> get_option ( <STRING> ) ) <NEWLINE> attrs = [ <NEWLINE> ( <STRING> , <NEWLINE> ibase . default_pprint ( self . categories , <NEWLINE> max_seq_items = max_categories ) ) , <NEWLINE> ( <STRING> , self . ordered ) ] <NEWLINE> if self . name is not None : <NEWLINE> <TAB> attrs . append ( ( <STRING> , ibase . default_pprint ( self . name ) ) ) <NEWLINE> <UNTAB> attrs . append ( ( <STRING> , <STRING> % self . dtype . name ) ) <NEWLINE> max_seq_items = get_option ( <STRING> ) or len ( self ) <NEWLINE> if len ( self ) > max_seq_items : <NEWLINE> <TAB> attrs . append ( ( <STRING> , len ( self ) ) ) <NEWLINE> <UNTAB> return attrs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gf_neg ( f , p , K ) : <NEWLINE> <TAB> <NEWLINE> return [ - coeff % p for coeff in f ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _cached_call ( self , args , kwargs , shelving = False ) : <NEWLINE> <TAB> <NEWLINE> func_id , args_id = self . _get_output_identifiers ( * args , ** kwargs ) <NEWLINE> metadata = None <NEWLINE> msg = None <NEWLINE> <NEWLINE> <NEWLINE> must_call = False <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if not ( self . _check_previous_func_code ( stacklevel = <NUMBER> ) and <NEWLINE> self . store_backend . contains_item ( [ func_id , args_id ] ) ) : <NEWLINE> <TAB> if self . _verbose > <NUMBER> : <NEWLINE> <TAB> _ , name = get_func_name ( self . func ) <NEWLINE> self . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> . format ( name , args_id , <NEWLINE> self . store_backend . <NEWLINE> get_cached_func_info ( [ func_id ] ) [ <STRING> ] ) ) <NEWLINE> <UNTAB> must_call = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> t0 = time . time ( ) <NEWLINE> if self . _verbose : <NEWLINE> <TAB> msg = _format_load_msg ( func_id , args_id , <NEWLINE> timestamp = self . timestamp , <NEWLINE> metadata = metadata ) <NEWLINE> <NEWLINE> <UNTAB> if not shelving : <NEWLINE> <NEWLINE> <TAB> out = self . store_backend . load_item ( <NEWLINE> [ func_id , args_id ] , <NEWLINE> msg = msg , <NEWLINE> verbose = self . _verbose ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> out = None <NEWLINE> <NEWLINE> <UNTAB> if self . _verbose > <NUMBER> : <NEWLINE> <TAB> t = time . time ( ) - t0 <NEWLINE> _ , name = get_func_name ( self . func ) <NEWLINE> msg = <STRING> % ( name , format_time ( t ) ) <NEWLINE> print ( max ( <NUMBER> , ( <NUMBER> - len ( msg ) ) ) * <STRING> + msg ) <NEWLINE> <UNTAB> <UNTAB> except Exception : <NEWLINE> <NEWLINE> <TAB> _ , signature = format_signature ( self . func , * args , ** kwargs ) <NEWLINE> self . warn ( <STRING> <NEWLINE> <STRING> . format ( signature , traceback . format_exc ( ) ) ) <NEWLINE> <NEWLINE> must_call = True <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if must_call : <NEWLINE> <TAB> out , metadata = self . call ( * args , ** kwargs ) <NEWLINE> if self . mmap_mode is not None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if self . _verbose : <NEWLINE> <TAB> msg = _format_load_msg ( func_id , args_id , <NEWLINE> timestamp = self . timestamp , <NEWLINE> metadata = metadata ) <NEWLINE> <UNTAB> out = self . store_backend . load_item ( [ func_id , args_id ] , msg = msg , <NEWLINE> verbose = self . _verbose ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return ( out , args_id , metadata ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def tukeylambda_variance ( lam ) : <NEWLINE> <TAB> <NEWLINE> lam = np . asarray ( lam ) <NEWLINE> shp = lam . shape <NEWLINE> lam = np . atleast_1d ( lam ) . astype ( np . float64 ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> threshold = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> low_mask = lam < - <NUMBER> <NEWLINE> <NEWLINE> neghalf_mask = lam == - <NUMBER> <NEWLINE> <NEWLINE> small_mask = np . abs ( lam ) < threshold <NEWLINE> <NEWLINE> reg_mask = ~ ( low_mask | neghalf_mask | small_mask ) <NEWLINE> <NEWLINE> <NEWLINE> small = lam [ small_mask ] <NEWLINE> reg = lam [ reg_mask ] <NEWLINE> <NEWLINE> <NEWLINE> v = np . empty_like ( lam ) <NEWLINE> v [ low_mask ] = np . nan <NEWLINE> v [ neghalf_mask ] = np . inf <NEWLINE> if small . size > <NUMBER> : <NEWLINE> <NEWLINE> <TAB> v [ small_mask ] = _tukeylambda_var_p ( small ) / _tukeylambda_var_q ( small ) <NEWLINE> <UNTAB> if reg . size > <NUMBER> : <NEWLINE> <TAB> v [ reg_mask ] = ( <NUMBER> / reg ** <NUMBER> ) * ( <NUMBER> / ( <NUMBER> + <NUMBER> * reg ) - <NEWLINE> beta ( reg + <NUMBER> , reg + <NUMBER> ) ) <NEWLINE> <UNTAB> v . shape = shp <NEWLINE> return v <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , theta , phi , dtheta = <NUMBER> , dphi = <NUMBER> , grid = True ) : <NEWLINE> <TAB> <NEWLINE> theta = np . asarray ( theta ) <NEWLINE> phi = np . asarray ( phi ) <NEWLINE> <NEWLINE> if theta . size > <NUMBER> and ( theta . min ( ) < <NUMBER> or theta . max ( ) > np . pi ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if phi . size > <NUMBER> and ( phi . min ( ) < <NUMBER> or phi . max ( ) > <NUMBER> * np . pi ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return _BivariateSplineBase . __call__ ( self , theta , phi , <NEWLINE> dx = dtheta , dy = dphi , grid = grid ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def plot_parametric ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> args = list ( map ( sympify , args ) ) <NEWLINE> show = kwargs . pop ( <STRING> , True ) <NEWLINE> series = [ ] <NEWLINE> plot_expr = check_arguments ( args , <NUMBER> , <NUMBER> ) <NEWLINE> series = [ Parametric2DLineSeries ( * arg , ** kwargs ) for arg in plot_expr ] <NEWLINE> plots = Plot ( * series , ** kwargs ) <NEWLINE> if show : <NEWLINE> <TAB> plots . show ( ) <NEWLINE> <UNTAB> return plots <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def circle_perimeter ( r , c , radius , method = <STRING> , shape = None ) : <NEWLINE> <TAB> <NEWLINE> return _circle_perimeter ( r , c , radius , method , shape ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _stackcopy ( a , b ) : <NEWLINE> <TAB> <NEWLINE> if a . ndim == <NUMBER> : <NEWLINE> <TAB> a [ : ] = b [ : , : , np . newaxis ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> a [ : ] = b <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def real_roots ( cls , poly , radicals = True ) : <NEWLINE> <TAB> <NEWLINE> return cls . _get_roots ( <STRING> , poly , radicals ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def apply_beta_to_alpha_route ( alpha_implications , beta_rules ) : <NEWLINE> <TAB> <NEWLINE> x_impl = { } <NEWLINE> for x in alpha_implications . keys ( ) : <NEWLINE> <TAB> x_impl [ x ] = ( set ( alpha_implications [ x ] ) , [ ] ) <NEWLINE> <UNTAB> for bcond , bimpl in beta_rules : <NEWLINE> <TAB> for bk in bcond . args : <NEWLINE> <TAB> if bk in x_impl : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> x_impl [ bk ] = ( set ( ) , [ ] ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> seen_static_extension = True <NEWLINE> while seen_static_extension : <NEWLINE> <TAB> seen_static_extension = False <NEWLINE> <NEWLINE> for bcond , bimpl in beta_rules : <NEWLINE> <TAB> if not isinstance ( bcond , And ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> bargs = set ( bcond . args ) <NEWLINE> for x , ( ximpls , bb ) in x_impl . items ( ) : <NEWLINE> <TAB> x_all = ximpls | { x } <NEWLINE> <NEWLINE> if bimpl not in x_all and bargs . issubset ( x_all ) : <NEWLINE> <TAB> ximpls . add ( bimpl ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> bimpl_impl = x_impl . get ( bimpl ) <NEWLINE> if bimpl_impl is not None : <NEWLINE> <TAB> ximpls |= bimpl_impl [ <NUMBER> ] <NEWLINE> <UNTAB> seen_static_extension = True <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> for bidx , ( bcond , bimpl ) in enumerate ( beta_rules ) : <NEWLINE> <TAB> bargs = set ( bcond . args ) <NEWLINE> for x , ( ximpls , bb ) in x_impl . items ( ) : <NEWLINE> <TAB> x_all = ximpls | { x } <NEWLINE> <NEWLINE> if bimpl in x_all : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if any ( Not ( xi ) in bargs or Not ( xi ) == bimpl for xi in x_all ) : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> if bargs & x_all : <NEWLINE> <TAB> bb . append ( bidx ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return x_impl <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def read_magic ( fp ) : <NEWLINE> <TAB> <NEWLINE> magic_str = _read_bytes ( fp , MAGIC_LEN , <STRING> ) <NEWLINE> if magic_str [ : - <NUMBER> ] != MAGIC_PREFIX : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise ValueError ( msg % ( MAGIC_PREFIX , magic_str [ : - <NUMBER> ] ) ) <NEWLINE> <UNTAB> if sys . version_info [ <NUMBER> ] < <NUMBER> : <NEWLINE> <TAB> major , minor = map ( ord , magic_str [ - <NUMBER> : ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> major , minor = magic_str [ - <NUMBER> : ] <NEWLINE> <UNTAB> return major , minor <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def winfo_viewable ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . tk . getint ( <NEWLINE> self . tk . call ( <STRING> , <STRING> , self . _w ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ _generative <NEWLINE> def offset ( self , offset ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . _offset_clause = _offset_or_limit_clause ( offset ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_value ( self , series , key ) : <NEWLINE> <TAB> <NEWLINE> s = com . _values_from_object ( series ) <NEWLINE> try : <NEWLINE> <TAB> return com . _maybe_box ( self , <NEWLINE> super ( PeriodIndex , self ) . get_value ( s , key ) , <NEWLINE> series , key ) <NEWLINE> <UNTAB> except ( KeyError , IndexError ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> asdt , parsed , reso = parse_time_string ( key , self . freq ) <NEWLINE> grp = resolution . Resolution . get_freq_group ( reso ) <NEWLINE> freqn = resolution . get_freq_group ( self . freq ) <NEWLINE> <NEWLINE> vals = self . _ndarray_values <NEWLINE> <NEWLINE> <NEWLINE> if grp < freqn : <NEWLINE> <TAB> iv = Period ( asdt , freq = ( grp , <NUMBER> ) ) <NEWLINE> ord1 = iv . asfreq ( self . freq , how = <STRING> ) . ordinal <NEWLINE> ord2 = iv . asfreq ( self . freq , how = <STRING> ) . ordinal <NEWLINE> <NEWLINE> if ord2 < vals [ <NUMBER> ] or ord1 > vals [ - <NUMBER> ] : <NEWLINE> <TAB> raise KeyError ( key ) <NEWLINE> <NEWLINE> <UNTAB> pos = np . searchsorted ( self . _ndarray_values , [ ord1 , ord2 ] ) <NEWLINE> key = slice ( pos [ <NUMBER> ] , pos [ <NUMBER> ] + <NUMBER> ) <NEWLINE> return series [ key ] <NEWLINE> <UNTAB> elif grp == freqn : <NEWLINE> <TAB> key = Period ( asdt , freq = self . freq ) . ordinal <NEWLINE> return com . _maybe_box ( self , self . _engine . get_value ( s , key ) , <NEWLINE> series , key ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise KeyError ( key ) <NEWLINE> <UNTAB> <UNTAB> except TypeError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> key = Period ( key , self . freq ) . ordinal <NEWLINE> return com . _maybe_box ( self , self . _engine . get_value ( s , key ) , <NEWLINE> series , key ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def lecun_uniform ( seed = None ) : <NEWLINE> <TAB> <NEWLINE> return VarianceScaling ( <NEWLINE> scale = <NUMBER> , mode = <STRING> , distribution = <STRING> , seed = seed ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _make_twin_axes ( self , * kl , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> from matplotlib . projections import process_projection_requirements <NEWLINE> if <STRING> in kwargs and <STRING> in kwargs : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if kwargs [ <STRING> ] is not self and kwargs [ <STRING> ] is not self : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> kl = ( self . get_subplotspec ( ) , ) + kl <NEWLINE> projection_class , kwargs , key = process_projection_requirements ( <NEWLINE> self . figure , * kl , ** kwargs ) <NEWLINE> <NEWLINE> ax2 = subplot_class_factory ( projection_class ) ( self . figure , <NEWLINE> * kl , ** kwargs ) <NEWLINE> self . figure . add_subplot ( ax2 ) <NEWLINE> self . set_adjustable ( <STRING> ) <NEWLINE> ax2 . set_adjustable ( <STRING> ) <NEWLINE> <NEWLINE> if self . _layoutbox is not None and ax2 . _layoutbox is not None : <NEWLINE> <NEWLINE> <TAB> ax2 . _layoutbox . constrain_same ( self . _layoutbox ) <NEWLINE> ax2 . _poslayoutbox . constrain_same ( self . _poslayoutbox ) <NEWLINE> <NEWLINE> <UNTAB> self . _twinned_axes . join ( self , ax2 ) <NEWLINE> return ax2 <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def matches ( self , x ) : <NEWLINE> <TAB> <NEWLINE> if not self . _kw : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> for kw in self . _kw : <NEWLINE> <TAB> if x . __name__ . find ( kw ) != - <NUMBER> : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> <UNTAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def load_data ( path = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> origin_folder = <STRING> <NEWLINE> path = get_file ( <NEWLINE> path , <NEWLINE> origin = origin_folder + <STRING> , <NEWLINE> file_hash = <STRING> ) <NEWLINE> with np . load ( path ) as f : <NEWLINE> <TAB> x_train , y_train = f [ <STRING> ] , f [ <STRING> ] <NEWLINE> x_test , y_test = f [ <STRING> ] , f [ <STRING> ] <NEWLINE> <NEWLINE> return ( x_train , y_train ) , ( x_test , y_test ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def lagroots ( c ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> [ c ] = pu . as_series ( [ c ] ) <NEWLINE> if len ( c ) <= <NUMBER> : <NEWLINE> <TAB> return np . array ( [ ] , dtype = c . dtype ) <NEWLINE> <UNTAB> if len ( c ) == <NUMBER> : <NEWLINE> <TAB> return np . array ( [ <NUMBER> + c [ <NUMBER> ] / c [ <NUMBER> ] ] ) <NEWLINE> <NEWLINE> <UNTAB> m = lagcompanion ( c ) <NEWLINE> r = la . eigvals ( m ) <NEWLINE> r . sort ( ) <NEWLINE> return r <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def manage ( module , ** params ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return proxies [ module ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> return proxies . setdefault ( module , _DBProxy ( module , ** params ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def read_var ( self , v ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_horizontalalignment ( self , align ) : <NEWLINE> <TAB> <NEWLINE> legal = ( <STRING> , <STRING> , <STRING> ) <NEWLINE> if align not in legal : <NEWLINE> <TAB> raise ValueError ( <STRING> % <NEWLINE> str ( legal ) ) <NEWLINE> <UNTAB> self . _horizontalalignment = align <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _get_legend_handles_labels ( axs , legend_handler_map = None ) : <NEWLINE> <TAB> <NEWLINE> handles = [ ] <NEWLINE> labels = [ ] <NEWLINE> <NEWLINE> for handle in _get_legend_handles ( axs , legend_handler_map ) : <NEWLINE> <TAB> label = handle . get_label ( ) <NEWLINE> if label and not label . startswith ( <STRING> ) : <NEWLINE> <TAB> handles . append ( handle ) <NEWLINE> labels . append ( label ) <NEWLINE> <UNTAB> <UNTAB> return handles , labels <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def astronaut ( ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return load ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def update_background ( self , event ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if self . useblit : <NEWLINE> <TAB> self . background = self . canvas . copy_from_bbox ( self . ax . bbox ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_integer_part ( expr , no , options , return_ints = False ) : <NEWLINE> <TAB> <NEWLINE> from sympy . functions . elementary . complexes import re , im <NEWLINE> <NEWLINE> assumed_size = <NUMBER> <NEWLINE> ire , iim , ire_acc , iim_acc = evalf ( expr , assumed_size , options ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if ire and iim : <NEWLINE> <TAB> gap = max ( fastlog ( ire ) - ire_acc , fastlog ( iim ) - iim_acc ) <NEWLINE> <UNTAB> elif ire : <NEWLINE> <TAB> gap = fastlog ( ire ) - ire_acc <NEWLINE> <UNTAB> elif iim : <NEWLINE> <TAB> gap = fastlog ( iim ) - iim_acc <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> return None , None , None , None <NEWLINE> <NEWLINE> <UNTAB> margin = <NUMBER> <NEWLINE> <NEWLINE> if gap >= - margin : <NEWLINE> <TAB> prec = margin + assumed_size + gap <NEWLINE> ire , iim , ire_acc , iim_acc = evalf ( <NEWLINE> expr , prec , options ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> prec = assumed_size <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> def calc_part ( re_im , nexpr ) : <NEWLINE> <TAB> from sympy . core . add import Add <NEWLINE> n , c , p , b = nexpr <NEWLINE> is_int = ( p == <NUMBER> ) <NEWLINE> nint = int ( to_int ( nexpr , rnd ) ) <NEWLINE> if is_int : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> ire , iim , ire_acc , iim_acc = evalf ( <NEWLINE> re_im - nint , <NUMBER> , options ) <NEWLINE> assert not iim <NEWLINE> size = - fastlog ( ire ) + <NUMBER> <NEWLINE> if size > prec : <NEWLINE> <TAB> ire , iim , ire_acc , iim_acc = evalf ( <NEWLINE> re_im , size , options ) <NEWLINE> assert not iim <NEWLINE> nexpr = ire <NEWLINE> n , c , p , b = nexpr <NEWLINE> is_int = ( p == <NUMBER> ) <NEWLINE> nint = int ( to_int ( nexpr , rnd ) ) <NEWLINE> <UNTAB> <UNTAB> if not is_int : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> s = options . get ( <STRING> , False ) <NEWLINE> if s : <NEWLINE> <TAB> doit = True <NEWLINE> from sympy . core . compatibility import as_int <NEWLINE> for v in s . values ( ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> as_int ( v ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> try : <NEWLINE> <TAB> [ as_int ( i ) for i in v . as_real_imag ( ) ] <NEWLINE> continue <NEWLINE> <UNTAB> except ( ValueError , AttributeError ) : <NEWLINE> <TAB> doit = False <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if doit : <NEWLINE> <TAB> re_im = re_im . subs ( s ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> re_im = Add ( re_im , - nint , evaluate = False ) <NEWLINE> x , _ , x_acc , _ = evalf ( re_im , <NUMBER> , options ) <NEWLINE> try : <NEWLINE> <TAB> check_target ( re_im , ( x , None , x_acc , None ) , <NUMBER> ) <NEWLINE> <UNTAB> except PrecisionExhausted : <NEWLINE> <TAB> if not re_im . equals ( <NUMBER> ) : <NEWLINE> <TAB> raise PrecisionExhausted <NEWLINE> <UNTAB> x = fzero <NEWLINE> <UNTAB> nint += int ( no * ( mpf_cmp ( x or fzero , fzero ) == no ) ) <NEWLINE> <UNTAB> nint = from_int ( nint ) <NEWLINE> return nint , INF <NEWLINE> <NEWLINE> <UNTAB> re_ , im_ , re_acc , im_acc = None , None , None , None <NEWLINE> <NEWLINE> if ire : <NEWLINE> <TAB> re_ , re_acc = calc_part ( re ( expr , evaluate = False ) , ire ) <NEWLINE> <UNTAB> if iim : <NEWLINE> <TAB> im_ , im_acc = calc_part ( im ( expr , evaluate = False ) , iim ) <NEWLINE> <NEWLINE> <UNTAB> if return_ints : <NEWLINE> <TAB> return int ( to_int ( re_ or fzero ) ) , int ( to_int ( im_ or fzero ) ) <NEWLINE> <UNTAB> return re_ , im_ , re_acc , im_acc <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_key ( self , key , save_pkl = True ) : <NEWLINE> <TAB> <NEWLINE> assert key not in self . keys <NEWLINE> self . keys . add ( key ) <NEWLINE> if save_pkl : <NEWLINE> <TAB> self . save_pkl ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def zero_grad ( self ) : <NEWLINE> <TAB> <NEWLINE> for p in self . parameters ( ) : <NEWLINE> <TAB> if p . grad is not None : <NEWLINE> <TAB> p . grad . detach_ ( ) <NEWLINE> p . grad . zero_ ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_axisbelow ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _axisbelow <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def searchsorted ( a , v , side = <STRING> , sorter = None ) : <NEWLINE> <TAB> <NEWLINE> return _wrapfunc ( a , <STRING> , v , side = side , sorter = sorter ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def get_joint_train_hooks ( train_steps = namedtuples . GANTrainSteps ( <NUMBER> , <NUMBER> ) ) : <NEWLINE> <TAB> <NEWLINE> g_steps = train_steps . generator_train_steps <NEWLINE> d_steps = train_steps . discriminator_train_steps <NEWLINE> <NEWLINE> num_d_and_g_steps = min ( g_steps , d_steps ) <NEWLINE> num_g_steps = g_steps - num_d_and_g_steps <NEWLINE> num_d_steps = d_steps - num_d_and_g_steps <NEWLINE> <NEWLINE> def get_hooks ( train_ops ) : <NEWLINE> <TAB> g_op = train_ops . generator_train_op <NEWLINE> d_op = train_ops . discriminator_train_op <NEWLINE> <NEWLINE> joint_hook = RunTrainOpsHook ( [ g_op , d_op ] , num_d_and_g_steps ) <NEWLINE> g_hook = RunTrainOpsHook ( g_op , num_g_steps ) <NEWLINE> d_hook = RunTrainOpsHook ( d_op , num_d_steps ) <NEWLINE> <NEWLINE> return [ joint_hook , g_hook , d_hook ] <NEWLINE> <NEWLINE> <UNTAB> return get_hooks <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def extractall ( self , path = None , members = None , pwd = None ) : <NEWLINE> <TAB> <NEWLINE> if members is None : <NEWLINE> <TAB> members = self . namelist ( ) <NEWLINE> <NEWLINE> <UNTAB> if path is None : <NEWLINE> <TAB> path = os . getcwd ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> path = os . fspath ( path ) <NEWLINE> <NEWLINE> <UNTAB> for zipinfo in members : <NEWLINE> <TAB> self . _extract_member ( zipinfo , path , pwd ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def update_loss_scale ( self , finite_grads ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def update_if_finite_grads ( ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def incr_loss_scale ( ) : <NEWLINE> <TAB> new_loss_scale = control_flow_ops . cond ( <NEWLINE> gen_math_ops . is_finite ( self . _loss_scale * self . _incr_ratio ) , <NEWLINE> lambda : self . _loss_scale * self . _incr_ratio , <NEWLINE> lambda : self . _loss_scale ) <NEWLINE> update_op = state_ops . assign ( self . _loss_scale , new_loss_scale ) <NEWLINE> <NEWLINE> return control_flow_ops . group ( update_op , self . _reset_stats ( ) ) <NEWLINE> <NEWLINE> <UNTAB> return control_flow_ops . cond ( <NEWLINE> self . _num_good_steps + <NUMBER> >= self . _incr_every_n_steps , <NEWLINE> incr_loss_scale , <NEWLINE> lambda : state_ops . assign_add ( self . _num_good_steps , <NUMBER> ) . op ) <NEWLINE> <NEWLINE> <UNTAB> def update_if_not_finite_grads ( ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def decr_loss_scale ( ) : <NEWLINE> <TAB> update_op = state_ops . assign ( <NEWLINE> self . _loss_scale , <NEWLINE> gen_math_ops . maximum ( <NUMBER> , self . _loss_scale * self . _decr_ratio ) ) <NEWLINE> <NEWLINE> return control_flow_ops . group ( update_op , self . _reset_stats ( ) ) <NEWLINE> <NEWLINE> <UNTAB> def just_update_steps ( ) : <NEWLINE> <NEWLINE> <TAB> return control_flow_ops . group ( <NEWLINE> state_ops . assign_add ( self . _num_bad_steps , <NUMBER> ) , <NEWLINE> state_ops . assign ( self . _num_good_steps , <NUMBER> ) ) <NEWLINE> <NEWLINE> <UNTAB> return control_flow_ops . cond ( <NEWLINE> self . _num_bad_steps + <NUMBER> >= self . _decr_every_n_nan_or_inf , <NEWLINE> decr_loss_scale , just_update_steps ) <NEWLINE> <NEWLINE> <UNTAB> return control_flow_ops . cond ( finite_grads , update_if_finite_grads , <NEWLINE> update_if_not_finite_grads ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def hermegrid3d ( x , y , z , c ) : <NEWLINE> <TAB> <NEWLINE> c = hermeval ( x , c ) <NEWLINE> c = hermeval ( y , c ) <NEWLINE> c = hermeval ( z , c ) <NEWLINE> return c <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def euclidean ( u , v , w = None ) : <NEWLINE> <TAB> <NEWLINE> return minkowski ( u , v , p = <NUMBER> , w = w ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def apply ( self , func , convert_dtype = True , args = ( ) , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> if len ( self ) == <NUMBER> : <NEWLINE> <TAB> return self . _constructor ( dtype = self . dtype , <NEWLINE> index = self . index ) . __finalize__ ( self ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( func , ( list , dict ) ) : <NEWLINE> <TAB> return self . aggregate ( func , * args , ** kwds ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( func , compat . string_types ) : <NEWLINE> <TAB> return self . _try_aggregate_string_function ( func , * args , ** kwds ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if kwds or args and not isinstance ( func , np . ufunc ) : <NEWLINE> <TAB> f = lambda x : func ( x , * args , ** kwds ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> f = func <NEWLINE> <NEWLINE> <UNTAB> with np . errstate ( all = <STRING> ) : <NEWLINE> <TAB> if isinstance ( f , np . ufunc ) : <NEWLINE> <TAB> return f ( self ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if is_extension_type ( self . dtype ) : <NEWLINE> <TAB> mapped = self . _values . map ( f ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> values = self . astype ( object ) . values <NEWLINE> mapped = lib . map_infer ( values , f , convert = convert_dtype ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if len ( mapped ) and isinstance ( mapped [ <NUMBER> ] , Series ) : <NEWLINE> <TAB> from pandas . core . frame import DataFrame <NEWLINE> return DataFrame ( mapped . tolist ( ) , index = self . index ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . _constructor ( mapped , <NEWLINE> index = self . index ) . __finalize__ ( self ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def check_random_state ( seed ) : <NEWLINE> <TAB> <NEWLINE> if seed is None or seed is np . random : <NEWLINE> <TAB> return np . random . mtrand . _rand <NEWLINE> <UNTAB> if isinstance ( seed , ( numbers . Integral , np . integer ) ) : <NEWLINE> <TAB> return np . random . RandomState ( seed ) <NEWLINE> <UNTAB> if isinstance ( seed , np . random . RandomState ) : <NEWLINE> <TAB> return seed <NEWLINE> <UNTAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % seed ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _generate_weighted_edges ( A ) : <NEWLINE> <TAB> <NEWLINE> if A . format == <STRING> : <NEWLINE> <TAB> return _csr_gen_triples ( A ) <NEWLINE> <UNTAB> if A . format == <STRING> : <NEWLINE> <TAB> return _csc_gen_triples ( A ) <NEWLINE> <UNTAB> if A . format == <STRING> : <NEWLINE> <TAB> return _dok_gen_triples ( A ) <NEWLINE> <NEWLINE> <UNTAB> return _coo_gen_triples ( A . tocoo ( ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_font_config ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _rc_cache is None : <NEWLINE> <TAB> self . _rc_cache = dict . fromkeys ( self . _rc_cache_keys ) <NEWLINE> <UNTAB> changed = [ par for par in self . _rc_cache_keys <NEWLINE> if rcParams [ par ] != self . _rc_cache [ par ] ] <NEWLINE> if changed : <NEWLINE> <TAB> _log . debug ( <STRING> , changed ) <NEWLINE> for k in changed : <NEWLINE> <TAB> _log . debug ( <STRING> , <NEWLINE> k , self . _rc_cache [ k ] , rcParams [ k ] ) <NEWLINE> <NEWLINE> self . _rc_cache [ k ] = copy . deepcopy ( rcParams [ k ] ) <NEWLINE> <UNTAB> _log . debug ( <STRING> , self . _fontconfig ) <NEWLINE> self . __init__ ( ) <NEWLINE> <UNTAB> _log . debug ( <STRING> , self . _fontconfig ) <NEWLINE> return self . _fontconfig <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_solid_capstyle ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _solidcapstyle <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_records ( self , index = True , convert_datetime64 = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if convert_datetime64 is not None : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> , <NEWLINE> FutureWarning , stacklevel = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> if index : <NEWLINE> <TAB> if is_datetime64_any_dtype ( self . index ) and convert_datetime64 : <NEWLINE> <TAB> ix_vals = [ self . index . to_pydatetime ( ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if isinstance ( self . index , MultiIndex ) : <NEWLINE> <NEWLINE> <TAB> ix_vals = lmap ( np . array , zip ( * self . index . values ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ix_vals = [ self . index . values ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> arrays = ix_vals + [ self [ c ] . get_values ( ) for c in self . columns ] <NEWLINE> <NEWLINE> count = <NUMBER> <NEWLINE> index_names = list ( self . index . names ) <NEWLINE> if isinstance ( self . index , MultiIndex ) : <NEWLINE> <TAB> for i , n in enumerate ( index_names ) : <NEWLINE> <TAB> if n is None : <NEWLINE> <TAB> index_names [ i ] = <STRING> % count <NEWLINE> count += <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif index_names [ <NUMBER> ] is None : <NEWLINE> <TAB> index_names = [ <STRING> ] <NEWLINE> <UNTAB> names = ( lmap ( compat . text_type , index_names ) + <NEWLINE> lmap ( compat . text_type , self . columns ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> arrays = [ self [ c ] . get_values ( ) for c in self . columns ] <NEWLINE> names = lmap ( compat . text_type , self . columns ) <NEWLINE> <NEWLINE> <UNTAB> formats = [ v . dtype for v in arrays ] <NEWLINE> return np . rec . fromarrays ( <NEWLINE> arrays , <NEWLINE> dtype = { <STRING> : names , <STRING> : formats } <NEWLINE> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def subspace_angles ( A , B ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> A = _asarray_validated ( A , check_finite = True ) <NEWLINE> if len ( A . shape ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( A . shape , ) ) <NEWLINE> <UNTAB> QA = orth ( A ) <NEWLINE> del A <NEWLINE> <NEWLINE> B = _asarray_validated ( B , check_finite = True ) <NEWLINE> if len ( B . shape ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( B . shape , ) ) <NEWLINE> <UNTAB> if len ( B ) != len ( QA ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % ( QA . shape [ <NUMBER> ] , B . shape [ <NUMBER> ] ) ) <NEWLINE> <UNTAB> QB = orth ( B ) <NEWLINE> del B <NEWLINE> <NEWLINE> <NEWLINE> QA_T_QB = dot ( QA . T , QB ) <NEWLINE> sigma = svdvals ( QA_T_QB ) <NEWLINE> <NEWLINE> <NEWLINE> if QA . shape [ <NUMBER> ] >= QB . shape [ <NUMBER> ] : <NEWLINE> <TAB> B = QB - dot ( QA , QA_T_QB ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> B = QA - dot ( QB , QA_T_QB . T ) <NEWLINE> <UNTAB> del QA , QB , QA_T_QB <NEWLINE> <NEWLINE> <NEWLINE> mask = sigma ** <NUMBER> >= <NUMBER> <NEWLINE> if mask . any ( ) : <NEWLINE> <TAB> mu_arcsin = arcsin ( clip ( svdvals ( B , overwrite_a = True ) , - <NUMBER> , <NUMBER> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> mu_arcsin = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> theta = where ( mask , mu_arcsin , arccos ( clip ( sigma , - <NUMBER> , <NUMBER> ) ) ) <NEWLINE> return theta <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def unwrap ( self , value ) : <NEWLINE> <TAB> <NEWLINE> return self . _unwrap ( value ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def mode ( self , axis = <NUMBER> , numeric_only = False ) : <NEWLINE> <TAB> <NEWLINE> data = self if not numeric_only else self . _get_numeric_data ( ) <NEWLINE> <NEWLINE> def f ( s ) : <NEWLINE> <TAB> return s . mode ( ) <NEWLINE> <NEWLINE> <UNTAB> return data . apply ( f , axis = axis ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def external_values ( self , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> return self . values <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def expand_log ( expr , deep = True , force = False ) : <NEWLINE> <TAB> <NEWLINE> return sympify ( expr ) . expand ( deep = deep , log = True , mul = False , <NEWLINE> power_exp = False , power_base = False , multinomial = False , <NEWLINE> basic = False , force = force ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _rational_case ( cls , poly , func ) : <NEWLINE> <TAB> <NEWLINE> roots = symbols ( <STRING> % poly . degree ( ) ) <NEWLINE> var , expr = func . variables [ <NUMBER> ] , func . expr <NEWLINE> <NEWLINE> f = sum ( expr . subs ( var , r ) for r in roots ) <NEWLINE> p , q = together ( f ) . as_numer_denom ( ) <NEWLINE> <NEWLINE> domain = QQ [ roots ] <NEWLINE> <NEWLINE> p = p . expand ( ) <NEWLINE> q = q . expand ( ) <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> p = Poly ( p , domain = domain , expand = False ) <NEWLINE> <UNTAB> except GeneratorsNeeded : <NEWLINE> <TAB> p , p_coeff = None , ( p , ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> p_monom , p_coeff = zip ( * p . terms ( ) ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> q = Poly ( q , domain = domain , expand = False ) <NEWLINE> <UNTAB> except GeneratorsNeeded : <NEWLINE> <TAB> q , q_coeff = None , ( q , ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> q_monom , q_coeff = zip ( * q . terms ( ) ) <NEWLINE> <NEWLINE> <UNTAB> coeffs , mapping = symmetrize ( p_coeff + q_coeff , formal = True ) <NEWLINE> formulas , values = viete ( poly , roots ) , [ ] <NEWLINE> <NEWLINE> for ( sym , _ ) , ( _ , val ) in zip ( mapping , formulas ) : <NEWLINE> <TAB> values . append ( ( sym , val ) ) <NEWLINE> <NEWLINE> <UNTAB> for i , ( coeff , _ ) in enumerate ( coeffs ) : <NEWLINE> <TAB> coeffs [ i ] = coeff . subs ( values ) <NEWLINE> <NEWLINE> <UNTAB> n = len ( p_coeff ) <NEWLINE> <NEWLINE> p_coeff = coeffs [ : n ] <NEWLINE> q_coeff = coeffs [ n : ] <NEWLINE> <NEWLINE> if p is not None : <NEWLINE> <TAB> p = Poly ( dict ( zip ( p_monom , p_coeff ) ) , * p . gens ) . as_expr ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ( p , ) = p_coeff <NEWLINE> <NEWLINE> <UNTAB> if q is not None : <NEWLINE> <TAB> q = Poly ( dict ( zip ( q_monom , q_coeff ) ) , * q . gens ) . as_expr ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ( q , ) = q_coeff <NEWLINE> <NEWLINE> <UNTAB> return factor ( p / q ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def radius_neighbors ( self , X , radius = None , return_distance = True ) : <NEWLINE> <TAB> <NEWLINE> if not hasattr ( self , <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if radius is None : <NEWLINE> <TAB> radius = self . radius <NEWLINE> <NEWLINE> <UNTAB> X = check_array ( X , accept_sparse = <STRING> ) <NEWLINE> <NEWLINE> neighbors , distances = [ ] , [ ] <NEWLINE> bin_queries , max_depth = self . _query ( X ) <NEWLINE> for i in range ( X . shape [ <NUMBER> ] ) : <NEWLINE> <NEWLINE> <TAB> neighs , dists = self . _get_radius_neighbors ( X [ [ i ] ] , max_depth [ i ] , <NEWLINE> bin_queries [ i ] , radius ) <NEWLINE> neighbors . append ( neighs ) <NEWLINE> distances . append ( dists ) <NEWLINE> <NEWLINE> <UNTAB> if return_distance : <NEWLINE> <TAB> return _array_of_arrays ( distances ) , _array_of_arrays ( neighbors ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _array_of_arrays ( neighbors ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def create_xid ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _inv_impl ( expr , op , ** kw ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( expr , <STRING> ) : <NEWLINE> <TAB> return expr . negation_clause <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return expr . _negate ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_index ( self , name ) : <NEWLINE> <TAB> <NEWLINE> return self . _get_indices ( [ name ] ) [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def derivatives ( self , x , der = None ) : <NEWLINE> <TAB> <NEWLINE> x , x_shape = self . _prepare_x ( x ) <NEWLINE> y = self . _evaluate_derivatives ( x , der ) <NEWLINE> <NEWLINE> y = y . reshape ( ( y . shape [ <NUMBER> ] , ) + x_shape + self . _y_extra_shape ) <NEWLINE> if self . _y_axis != <NUMBER> and x_shape != ( ) : <NEWLINE> <TAB> nx = len ( x_shape ) <NEWLINE> ny = len ( self . _y_extra_shape ) <NEWLINE> s = ( [ <NUMBER> ] + list ( range ( nx + <NUMBER> , nx + self . _y_axis + <NUMBER> ) ) <NEWLINE> + list ( range ( <NUMBER> , nx + <NUMBER> ) ) + <NEWLINE> list ( range ( nx + <NUMBER> + self . _y_axis , nx + ny + <NUMBER> ) ) ) <NEWLINE> y = y . transpose ( s ) <NEWLINE> <UNTAB> return y <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , bbox , x0 = None , y0 = None , x1 = None , y1 = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if not bbox . is_bbox : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> BboxBase . __init__ ( self , ** kwargs ) <NEWLINE> self . _bbox = bbox <NEWLINE> self . set_children ( bbox ) <NEWLINE> self . _points = None <NEWLINE> fp = [ x0 , y0 , x1 , y1 ] <NEWLINE> mask = [ val is None for val in fp ] <NEWLINE> self . _locked_points = np . ma . array ( fp , float , mask = mask ) . reshape ( ( <NUMBER> , <NUMBER> ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def zpk2tf ( z , p , k ) : <NEWLINE> <TAB> <NEWLINE> z = atleast_1d ( z ) <NEWLINE> k = atleast_1d ( k ) <NEWLINE> if len ( z . shape ) > <NUMBER> : <NEWLINE> <TAB> temp = poly ( z [ <NUMBER> ] ) <NEWLINE> b = zeros ( ( z . shape [ <NUMBER> ] , z . shape [ <NUMBER> ] + <NUMBER> ) , temp . dtype . char ) <NEWLINE> if len ( k ) == <NUMBER> : <NEWLINE> <TAB> k = [ k [ <NUMBER> ] ] * z . shape [ <NUMBER> ] <NEWLINE> <UNTAB> for i in range ( z . shape [ <NUMBER> ] ) : <NEWLINE> <TAB> b [ i ] = k [ i ] * poly ( z [ i ] ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> b = k * poly ( z ) <NEWLINE> <UNTAB> a = atleast_1d ( poly ( p ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if issubclass ( b . dtype . type , numpy . complexfloating ) : <NEWLINE> <NEWLINE> <TAB> roots = numpy . asarray ( z , complex ) <NEWLINE> pos_roots = numpy . compress ( roots . imag > <NUMBER> , roots ) <NEWLINE> neg_roots = numpy . conjugate ( numpy . compress ( roots . imag < <NUMBER> , roots ) ) <NEWLINE> if len ( pos_roots ) == len ( neg_roots ) : <NEWLINE> <TAB> if numpy . all ( numpy . sort_complex ( neg_roots ) == <NEWLINE> numpy . sort_complex ( pos_roots ) ) : <NEWLINE> <TAB> b = b . real . copy ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if issubclass ( a . dtype . type , numpy . complexfloating ) : <NEWLINE> <NEWLINE> <TAB> roots = numpy . asarray ( p , complex ) <NEWLINE> pos_roots = numpy . compress ( roots . imag > <NUMBER> , roots ) <NEWLINE> neg_roots = numpy . conjugate ( numpy . compress ( roots . imag < <NUMBER> , roots ) ) <NEWLINE> if len ( pos_roots ) == len ( neg_roots ) : <NEWLINE> <TAB> if numpy . all ( numpy . sort_complex ( neg_roots ) == <NEWLINE> numpy . sort_complex ( pos_roots ) ) : <NEWLINE> <TAB> a = a . real . copy ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return b , a <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ contextlib . contextmanager <NEWLINE> def _name_scope ( self , name = None , values = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( self . name ) : <NEWLINE> <TAB> with ops . name_scope ( <NEWLINE> name , values = ( values or [ ] ) + self . graph_parents ) as scope : <NEWLINE> <TAB> yield scope <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def laplace_transform ( f , t , s , ** hints ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( f , MatrixBase ) and hasattr ( f , <STRING> ) : <NEWLINE> <TAB> return f . applyfunc ( lambda fij : laplace_transform ( fij , t , s , ** hints ) ) <NEWLINE> <UNTAB> return LaplaceTransform ( f , t , s ) . doit ( ** hints ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def hypersimp ( f , k ) : <NEWLINE> <TAB> <NEWLINE> f = sympify ( f ) <NEWLINE> <NEWLINE> g = f . subs ( k , k + <NUMBER> ) / f <NEWLINE> <NEWLINE> g = g . rewrite ( gamma ) <NEWLINE> g = expand_func ( g ) <NEWLINE> g = powsimp ( g , deep = True , combine = <STRING> ) <NEWLINE> <NEWLINE> if g . is_rational_function ( k ) : <NEWLINE> <TAB> return simplify ( g , ratio = S . Infinity ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def union ( self , other , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return CompoundSelect . _create_union ( self , other , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_default ( self , name , value ) : <NEWLINE> <TAB> <NEWLINE> fl = self . _flags ( ) <NEWLINE> if name not in fl : <NEWLINE> <TAB> self . _set_unknown_flag ( name , value ) <NEWLINE> return <NEWLINE> <UNTAB> fl [ name ] . _set_default ( value ) <NEWLINE> self . _assert_validators ( fl [ name ] . validators ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def format ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . condition <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def funcname ( func ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( func , functools . partial ) : <NEWLINE> <TAB> return funcname ( func . func ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( func , methodcaller ) : <NEWLINE> <TAB> return func . method <NEWLINE> <NEWLINE> <UNTAB> module_name = getattr ( func , <STRING> , None ) or <STRING> <NEWLINE> type_name = getattr ( type ( func ) , <STRING> , None ) or <STRING> <NEWLINE> <NEWLINE> <NEWLINE> if <STRING> in module_name and <STRING> == type_name : <NEWLINE> <TAB> return func . func_name <NEWLINE> <NEWLINE> <UNTAB> if <STRING> in module_name and <STRING> == type_name : <NEWLINE> <TAB> return func . name <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> name = func . __name__ <NEWLINE> if name == <STRING> : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> return name <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> return str ( func ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def linear_sum_assignment ( cost_matrix ) : <NEWLINE> <TAB> <NEWLINE> cost_matrix = np . asarray ( cost_matrix ) <NEWLINE> if len ( cost_matrix . shape ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> % ( cost_matrix . shape , ) ) <NEWLINE> <NEWLINE> <UNTAB> if not ( np . issubdtype ( cost_matrix . dtype , np . number ) or <NEWLINE> cost_matrix . dtype == np . dtype ( np . bool ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> % ( cost_matrix . dtype , ) ) <NEWLINE> <NEWLINE> <UNTAB> if np . any ( np . isinf ( cost_matrix ) | np . isnan ( cost_matrix ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if cost_matrix . dtype == np . dtype ( np . bool ) : <NEWLINE> <TAB> cost_matrix = cost_matrix . astype ( np . int ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if cost_matrix . shape [ <NUMBER> ] < cost_matrix . shape [ <NUMBER> ] : <NEWLINE> <TAB> cost_matrix = cost_matrix . T <NEWLINE> transposed = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> transposed = False <NEWLINE> <NEWLINE> <UNTAB> state = _Hungary ( cost_matrix ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> step = None if <NUMBER> in cost_matrix . shape else _step1 <NEWLINE> <NEWLINE> while step is not None : <NEWLINE> <TAB> step = step ( state ) <NEWLINE> <NEWLINE> <UNTAB> if transposed : <NEWLINE> <TAB> marked = state . marked . T <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> marked = state . marked <NEWLINE> <UNTAB> return np . where ( marked == <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def check_paired_arrays ( X , Y ) : <NEWLINE> <TAB> <NEWLINE> X , Y = check_pairwise_arrays ( X , Y ) <NEWLINE> if X . shape != Y . shape : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % ( X . shape , Y . shape ) ) <NEWLINE> <UNTAB> return X , Y <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def load_variable ( ckpt_dir_or_file , name ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if name . endswith ( <STRING> ) : <NEWLINE> <TAB> name = name [ : - <NUMBER> ] <NEWLINE> <UNTAB> reader = load_checkpoint ( ckpt_dir_or_file ) <NEWLINE> return reader . get_tensor ( name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def extend ( self , parameters ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( parameters , Iterable ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> + type ( parameters ) . __name__ ) <NEWLINE> <UNTAB> offset = len ( self ) <NEWLINE> for i , param in enumerate ( parameters ) : <NEWLINE> <TAB> self . register_parameter ( str ( offset + i ) , param ) <NEWLINE> <UNTAB> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , learning_rate , use_locking = False , name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> super ( GradientDescentOptimizer , self ) . __init__ ( use_locking , name ) <NEWLINE> self . _learning_rate = learning_rate <NEWLINE> self . _learning_rate_tensor = None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def bincount ( x , weights = None , minlength = None , assert_nonneg = False ) : <NEWLINE> <TAB> <NEWLINE> if x . ndim != <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if assert_nonneg : <NEWLINE> <TAB> from theano . tensor . opt import Assert <NEWLINE> assert_op = Assert ( <STRING> ) <NEWLINE> x = assert_op ( x , theano . tensor . all ( x >= <NUMBER> ) ) <NEWLINE> <NEWLINE> <UNTAB> max_value = theano . tensor . cast ( x . max ( ) + <NUMBER> , <STRING> ) <NEWLINE> <NEWLINE> if minlength is not None : <NEWLINE> <TAB> max_value = theano . tensor . maximum ( max_value , minlength ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if weights is None : <NEWLINE> <TAB> out = theano . tensor . zeros ( [ max_value ] , dtype = x . dtype ) <NEWLINE> out = theano . tensor . advanced_inc_subtensor1 ( out , <NUMBER> , x ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> out = theano . tensor . zeros ( [ max_value ] , dtype = weights . dtype ) <NEWLINE> out = theano . tensor . advanced_inc_subtensor1 ( out , weights , x ) <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _is_form ( expr , function1 , function2 ) : <NEWLINE> <TAB> <NEWLINE> expr = sympify ( expr ) <NEWLINE> <NEWLINE> <NEWLINE> if expr . is_Atom : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( expr , function2 ) : <NEWLINE> <TAB> for lit in expr . args : <NEWLINE> <TAB> if isinstance ( lit , Not ) : <NEWLINE> <TAB> if not lit . args [ <NUMBER> ] . is_Atom : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if not lit . is_Atom : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return True <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( expr , Not ) : <NEWLINE> <TAB> if not expr . args [ <NUMBER> ] . is_Atom : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not isinstance ( expr , function1 ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> for cls in expr . args : <NEWLINE> <TAB> if cls . is_Atom : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> if isinstance ( cls , Not ) : <NEWLINE> <TAB> if not cls . args [ <NUMBER> ] . is_Atom : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> elif not isinstance ( cls , function2 ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> for lit in cls . args : <NEWLINE> <TAB> if isinstance ( lit , Not ) : <NEWLINE> <TAB> if not lit . args [ <NUMBER> ] . is_Atom : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if not lit . is_Atom : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _convert_to_varsSOP ( minterm , variables ) : <NEWLINE> <TAB> <NEWLINE> temp = [ ] <NEWLINE> for i , m in enumerate ( minterm ) : <NEWLINE> <TAB> if m == <NUMBER> : <NEWLINE> <TAB> temp . append ( Not ( variables [ i ] ) ) <NEWLINE> <UNTAB> elif m == <NUMBER> : <NEWLINE> <TAB> temp . append ( variables [ i ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> return And ( * temp ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _OverloadOperator ( operator ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> tensor_oper = getattr ( ops . Tensor , operator ) <NEWLINE> def _run_op ( a , * args ) : <NEWLINE> <NEWLINE> <TAB> value = a . _AsTensor ( ) <NEWLINE> return tensor_oper ( value , * args ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> _run_op . __doc__ = tensor_oper . __doc__ <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> setattr ( ResourceVariable , operator , _run_op ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def check ( self , value ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _fix_lsm_bitspersample ( self , parent ) : <NEWLINE> <TAB> <NEWLINE> if self . code == <NUMBER> and self . count == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> warnings . warn ( <STRING> ) <NEWLINE> fh = parent . filehandle <NEWLINE> tof = { <NUMBER> : <STRING> , <NUMBER> : <STRING> } [ parent . offset_size ] <NEWLINE> self . value_offset = struct . unpack ( tof , self . _value ) [ <NUMBER> ] <NEWLINE> fh . seek ( self . value_offset ) <NEWLINE> self . value = struct . unpack ( <STRING> , fh . read ( <NUMBER> ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def fliplr ( m ) : <NEWLINE> <TAB> <NEWLINE> m = asanyarray ( m ) <NEWLINE> if m . ndim < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return m [ : , : : - <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def nanprod ( a , axis = None , dtype = None , out = None , keepdims = np . _NoValue ) : <NEWLINE> <TAB> <NEWLINE> a , mask = _replace_nan ( a , <NUMBER> ) <NEWLINE> return np . prod ( a , axis = axis , dtype = dtype , out = out , keepdims = keepdims ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _updated_ctor_param ( self ) : <NEWLINE> <TAB> <NEWLINE> dct = super ( rv_histogram , self ) . _updated_ctor_param ( ) <NEWLINE> dct [ <STRING> ] = self . _histogram <NEWLINE> return dct <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def observe_value ( observation_key , target_func ) : <NEWLINE> <TAB> <NEWLINE> @ extension . make_extension ( <NEWLINE> trigger = ( <NUMBER> , <STRING> ) , priority = extension . PRIORITY_WRITER ) <NEWLINE> def _observe_value ( trainer ) : <NEWLINE> <TAB> trainer . observation [ observation_key ] = target_func ( trainer ) <NEWLINE> <UNTAB> return _observe_value <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def generate_table ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> gso_table = self . _gso_table <NEWLINE> gso_df = self . df <NEWLINE> columns = list ( gso_df . columns ) <NEWLINE> selected = gso_df [ self . columns ] <NEWLINE> col_index = [ ( col , columns . index ( col ) ) for col in self . columns ] <NEWLINE> keys = np . empty ( selected . shape , dtype = np . uint64 ) <NEWLINE> for o , ( idx , row ) in enumerate ( selected . iterrows ( ) ) : <NEWLINE> <TAB> for j , ( col , v ) in enumerate ( col_index ) : <NEWLINE> <TAB> val = row [ col ] <NEWLINE> key = gso_table . get ( val , None ) <NEWLINE> if key is None : <NEWLINE> <NEWLINE> <TAB> key = ( v + <NUMBER> , o + <NUMBER> ) <NEWLINE> gso_table [ val ] = key <NEWLINE> <UNTAB> keys [ o , j ] = self . _convert_key ( key ) <NEWLINE> <UNTAB> <UNTAB> for i , col in enumerate ( self . columns ) : <NEWLINE> <TAB> gso_df [ col ] = keys [ : , i ] <NEWLINE> <NEWLINE> <UNTAB> return gso_table , gso_df <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def distance ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( other , GeometryEntity ) : <NEWLINE> <TAB> other = Point ( other , dim = self . ambient_dimension ) <NEWLINE> <UNTAB> if self . contains ( other ) : <NEWLINE> <TAB> return S . Zero <NEWLINE> <NEWLINE> <UNTAB> proj = Line ( self . p1 , self . p2 ) . projection ( other ) <NEWLINE> if self . contains ( proj ) : <NEWLINE> <TAB> return abs ( other - proj ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return abs ( other - self . source ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , locator , tz = None , defaultfmt = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> self . _locator = locator <NEWLINE> self . _tz = tz <NEWLINE> self . defaultfmt = defaultfmt <NEWLINE> self . _formatter = DateFormatter ( self . defaultfmt , tz ) <NEWLINE> self . scaled = { DAYS_PER_YEAR : rcParams [ <STRING> ] , <NEWLINE> DAYS_PER_MONTH : rcParams [ <STRING> ] , <NEWLINE> <NUMBER> : rcParams [ <STRING> ] , <NEWLINE> <NUMBER> / HOURS_PER_DAY : rcParams [ <STRING> ] , <NEWLINE> <NUMBER> / ( MINUTES_PER_DAY ) : <NEWLINE> rcParams [ <STRING> ] , <NEWLINE> <NUMBER> / ( SEC_PER_DAY ) : <NEWLINE> rcParams [ <STRING> ] , <NEWLINE> <NUMBER> / ( MUSECONDS_PER_DAY ) : <NEWLINE> rcParams [ <STRING> ] } <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def allowed_flags ( args , flags ) : <NEWLINE> <TAB> <NEWLINE> flags = set ( flags ) <NEWLINE> <NEWLINE> for arg in args . keys ( ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> if Options . __options__ [ arg ] . is_Flag and not arg in flags : <NEWLINE> <TAB> raise FlagError ( <NEWLINE> <STRING> % arg ) <NEWLINE> <UNTAB> <UNTAB> except KeyError : <NEWLINE> <TAB> raise OptionError ( <STRING> % arg ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_output_canvas ( self , fmt ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if hasattr ( self , <STRING> . format ( fmt ) ) : <NEWLINE> <TAB> return self <NEWLINE> <NEWLINE> <UNTAB> canvas_class = get_registered_canvas_class ( fmt ) <NEWLINE> if canvas_class : <NEWLINE> <TAB> return self . switch_backends ( canvas_class ) <NEWLINE> <NEWLINE> <UNTAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> . format ( fmt , <STRING> . join ( sorted ( self . get_supported_filetypes ( ) ) ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_same_graph_with_merge ( var1 , var2 , givens = None ) : <NEWLINE> <TAB> <NEWLINE> if givens is None : <NEWLINE> <TAB> givens = { } <NEWLINE> <NEWLINE> <UNTAB> copied = copy . deepcopy ( [ var1 , var2 , givens ] ) <NEWLINE> vars = copied [ <NUMBER> : <NUMBER> ] <NEWLINE> givens = copied [ <NUMBER> ] <NEWLINE> <NEWLINE> inputs = theano . gof . graph . inputs ( vars ) <NEWLINE> <NEWLINE> <NEWLINE> fgraph = theano . gof . fg . FunctionGraph ( inputs , vars , clone = False ) <NEWLINE> <NEWLINE> for to_replace , replace_by in iteritems ( givens ) : <NEWLINE> <TAB> fgraph . replace ( to_replace , replace_by ) <NEWLINE> <NEWLINE> <UNTAB> MergeOptimizer ( ) . optimize ( fgraph ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> vars_replaced = [ givens . get ( v , v ) for v in vars ] <NEWLINE> o1 , o2 = [ v . owner for v in vars_replaced ] <NEWLINE> if o1 is None and o2 is None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return vars_replaced [ <NUMBER> ] == vars_replaced [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return o1 is o2 <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def polydiv ( u , v ) : <NEWLINE> <TAB> <NEWLINE> truepoly = ( isinstance ( u , poly1d ) or isinstance ( u , poly1d ) ) <NEWLINE> u = atleast_1d ( u ) + <NUMBER> <NEWLINE> v = atleast_1d ( v ) + <NUMBER> <NEWLINE> <NEWLINE> w = u [ <NUMBER> ] + v [ <NUMBER> ] <NEWLINE> m = len ( u ) - <NUMBER> <NEWLINE> n = len ( v ) - <NUMBER> <NEWLINE> scale = <NUMBER> / v [ <NUMBER> ] <NEWLINE> q = NX . zeros ( ( max ( m - n + <NUMBER> , <NUMBER> ) , ) , w . dtype ) <NEWLINE> r = u . copy ( ) <NEWLINE> for k in range ( <NUMBER> , m - n + <NUMBER> ) : <NEWLINE> <TAB> d = scale * r [ k ] <NEWLINE> q [ k ] = d <NEWLINE> r [ k : k + n + <NUMBER> ] -= d * v <NEWLINE> <UNTAB> while NX . allclose ( r [ <NUMBER> ] , <NUMBER> , rtol = <NUMBER> ) and ( r . shape [ - <NUMBER> ] > <NUMBER> ) : <NEWLINE> <TAB> r = r [ <NUMBER> : ] <NEWLINE> <UNTAB> if truepoly : <NEWLINE> <TAB> return poly1d ( q ) , poly1d ( r ) <NEWLINE> <UNTAB> return q , r <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def pretty ( expr , ** settings ) : <NEWLINE> <TAB> <NEWLINE> pp = PrettyPrinter ( settings ) <NEWLINE> <NEWLINE> <NEWLINE> use_unicode = pp . _settings [ <STRING> ] <NEWLINE> uflag = pretty_use_unicode ( use_unicode ) <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> return pp . doprint ( expr ) <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> pretty_use_unicode ( uflag ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def before ( self , dt , inc = False ) : <NEWLINE> <TAB> <NEWLINE> if self . _cache_complete : <NEWLINE> <TAB> gen = self . _cache <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> gen = self <NEWLINE> <UNTAB> last = None <NEWLINE> if inc : <NEWLINE> <TAB> for i in gen : <NEWLINE> <TAB> if i > dt : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> last = i <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for i in gen : <NEWLINE> <TAB> if i >= dt : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> last = i <NEWLINE> <UNTAB> <UNTAB> return last <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def select_ts ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> graph = None <NEWLINE> positive_filter = None <NEWLINE> restrict_ts_regex = False <NEWLINE> for k , v in iteritems ( kwargs ) : <NEWLINE> <TAB> if k == <STRING> : <NEWLINE> <TAB> graph = v <NEWLINE> if graph is not None and not isinstance ( graph , tf_ops . Graph ) : <NEWLINE> <TAB> raise TypeError ( <STRING> . format ( type ( graph ) ) ) <NEWLINE> <UNTAB> <UNTAB> elif k == <STRING> : <NEWLINE> <TAB> positive_filter = v <NEWLINE> <UNTAB> elif k == <STRING> : <NEWLINE> <TAB> restrict_ts_regex = v <NEWLINE> <UNTAB> elif k == <STRING> : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( k ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> ts = [ ] <NEWLINE> <NEWLINE> for arg in args : <NEWLINE> <TAB> if can_be_regex ( arg ) : <NEWLINE> <TAB> if graph is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> regex = make_regex ( arg ) <NEWLINE> if regex . pattern . startswith ( <STRING> ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> if restrict_ts_regex and not regex . pattern . startswith ( <STRING> ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> ts_ = filter_ts_from_regex ( graph , regex ) <NEWLINE> for t_ in ts_ : <NEWLINE> <TAB> if t_ not in ts : <NEWLINE> <TAB> if positive_filter is None or positive_filter ( t_ ) : <NEWLINE> <TAB> ts . append ( t_ ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> ts_aux = util . make_list_of_t ( arg , ignore_ops = True ) <NEWLINE> if positive_filter is not None : <NEWLINE> <TAB> ts_aux = [ t for t in ts_aux if positive_filter ( t ) ] <NEWLINE> <UNTAB> ts_aux = [ t for t in ts_aux if t not in ts ] <NEWLINE> ts += ts_aux <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return ts <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def reverse ( x , axes ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( axes , int ) : <NEWLINE> <TAB> axes = [ axes ] <NEWLINE> <UNTAB> return tf . reverse ( x , axes ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_shape_tuple ( self , init_tuple , tensor , start_idx , int_shape = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if int_shape is None : <NEWLINE> <TAB> int_shape = K . int_shape ( tensor ) [ start_idx : ] <NEWLINE> <UNTAB> if not any ( not s for s in int_shape ) : <NEWLINE> <TAB> return init_tuple + int_shape <NEWLINE> <UNTAB> tensor_shape = K . shape ( tensor ) <NEWLINE> int_shape = list ( int_shape ) <NEWLINE> for i , s in enumerate ( int_shape ) : <NEWLINE> <TAB> if not s : <NEWLINE> <TAB> int_shape [ i ] = tensor_shape [ start_idx + i ] <NEWLINE> <UNTAB> <UNTAB> return init_tuple + tuple ( int_shape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_x ( self , x ) : <NEWLINE> <TAB> <NEWLINE> self . _x = x <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _combine_inverse ( lhs , rhs ) : <NEWLINE> <TAB> <NEWLINE> if lhs == rhs : <NEWLINE> <TAB> return S . One <NEWLINE> <NEWLINE> <UNTAB> def check ( l , r ) : <NEWLINE> <TAB> if l . is_Float and r . is_comparable : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return l . __add__ ( <NUMBER> ) == r . evalf ( ) . __add__ ( <NUMBER> ) <NEWLINE> <UNTAB> return False <NEWLINE> <UNTAB> if check ( lhs , rhs ) or check ( rhs , lhs ) : <NEWLINE> <TAB> return S . One <NEWLINE> <UNTAB> if lhs . is_Mul and rhs . is_Mul : <NEWLINE> <TAB> a = list ( lhs . args ) <NEWLINE> b = [ <NUMBER> ] <NEWLINE> for x in rhs . args : <NEWLINE> <TAB> if x in a : <NEWLINE> <TAB> a . remove ( x ) <NEWLINE> <UNTAB> elif - x in a : <NEWLINE> <TAB> a . remove ( - x ) <NEWLINE> b . append ( - <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> b . append ( x ) <NEWLINE> <UNTAB> <UNTAB> return lhs . func ( * a ) / rhs . func ( * b ) <NEWLINE> <UNTAB> return lhs / rhs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _assert_input_compatibility ( self , inputs ) : <NEWLINE> <TAB> <NEWLINE> if not self . input_spec : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> if not isinstance ( self . input_spec , ( list , tuple ) ) : <NEWLINE> <TAB> input_spec = nest . flatten ( self . input_spec ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> input_spec = self . input_spec <NEWLINE> <UNTAB> inputs = nest . flatten ( inputs ) <NEWLINE> if len ( inputs ) != len ( input_spec ) : <NEWLINE> <TAB> raise ValueError ( <STRING> + self . name + <STRING> + <NEWLINE> str ( len ( input_spec ) ) + <STRING> <NEWLINE> <STRING> + str ( len ( inputs ) ) + <NEWLINE> <STRING> + str ( inputs ) ) <NEWLINE> <UNTAB> for input_index , ( x , spec ) in enumerate ( zip ( inputs , input_spec ) ) : <NEWLINE> <TAB> if spec is None : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> if ( spec . ndim is not None or <NEWLINE> spec . min_ndim is not None or <NEWLINE> spec . max_ndim is not None ) : <NEWLINE> <TAB> if x . shape . ndims is None : <NEWLINE> <TAB> raise ValueError ( <STRING> + str ( input_index ) + <STRING> + <NEWLINE> self . name + <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if spec . ndim is not None : <NEWLINE> <TAB> ndim = x . shape . ndims <NEWLINE> if ndim != spec . ndim : <NEWLINE> <TAB> raise ValueError ( <STRING> + str ( input_index ) + <STRING> + <NEWLINE> self . name + <STRING> <NEWLINE> <STRING> + str ( spec . ndim ) + <STRING> + <NEWLINE> str ( ndim ) + <STRING> + <NEWLINE> str ( x . shape . as_list ( ) ) ) <NEWLINE> <UNTAB> <UNTAB> if spec . max_ndim is not None : <NEWLINE> <TAB> ndim = x . shape . ndims <NEWLINE> if ndim is not None and ndim > spec . max_ndim : <NEWLINE> <TAB> raise ValueError ( <STRING> + str ( input_index ) + <STRING> + <NEWLINE> self . name + <STRING> <NEWLINE> <STRING> + str ( spec . max_ndim ) + <NEWLINE> <STRING> + str ( ndim ) ) <NEWLINE> <UNTAB> <UNTAB> if spec . min_ndim is not None : <NEWLINE> <TAB> ndim = x . shape . ndims <NEWLINE> if ndim is not None and ndim < spec . min_ndim : <NEWLINE> <TAB> raise ValueError ( <STRING> + str ( input_index ) + <STRING> + <NEWLINE> self . name + <STRING> <NEWLINE> <STRING> + str ( spec . min_ndim ) + <NEWLINE> <STRING> + str ( ndim ) + <NEWLINE> <STRING> + <NEWLINE> str ( x . shape . as_list ( ) ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if spec . dtype is not None : <NEWLINE> <TAB> if x . dtype != spec . dtype : <NEWLINE> <TAB> raise ValueError ( <STRING> + str ( input_index ) + <STRING> + <NEWLINE> self . name + <STRING> <NEWLINE> <STRING> + str ( spec . dtype ) + <NEWLINE> <STRING> + str ( x . dtype ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if spec . axes : <NEWLINE> <TAB> shape = x . shape . as_list ( ) <NEWLINE> if shape is not None : <NEWLINE> <TAB> for axis , value in spec . axes . items ( ) : <NEWLINE> <TAB> if hasattr ( value , <STRING> ) : <NEWLINE> <TAB> value = value . value <NEWLINE> <UNTAB> if value is not None and shape [ int ( axis ) ] not in { value , None } : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> + str ( input_index ) + <STRING> + self . name + <STRING> <NEWLINE> <STRING> + str ( axis ) + <NEWLINE> <STRING> + str ( value ) + <NEWLINE> <STRING> + str ( shape ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> if spec . shape is not None : <NEWLINE> <TAB> shape = x . shape . as_list ( ) <NEWLINE> if shape is not None : <NEWLINE> <TAB> for spec_dim , dim in zip ( spec . shape , shape ) : <NEWLINE> <TAB> if spec_dim is not None and dim is not None : <NEWLINE> <TAB> if spec_dim != dim : <NEWLINE> <TAB> raise ValueError ( <STRING> + str ( input_index ) + <NEWLINE> <STRING> + self . name + <NEWLINE> <STRING> + str ( spec . shape ) + <NEWLINE> <STRING> + str ( shape ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def plotting_context ( context = None , font_scale = <NUMBER> , rc = None ) : <NEWLINE> <TAB> <NEWLINE> if context is None : <NEWLINE> <TAB> context_dict = { k : mpl . rcParams [ k ] for k in _context_keys } <NEWLINE> <NEWLINE> <UNTAB> elif isinstance ( context , dict ) : <NEWLINE> <TAB> context_dict = context <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> contexts = [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> if context not in contexts : <NEWLINE> <TAB> raise ValueError ( <STRING> % <STRING> . join ( contexts ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> base_context = { <NEWLINE> <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <NEWLINE> } <NEWLINE> <NEWLINE> <NEWLINE> scaling = dict ( paper = <NUMBER> , notebook = <NUMBER> , talk = <NUMBER> , poster = <NUMBER> ) [ context ] <NEWLINE> context_dict = { k : v * scaling for k , v in base_context . items ( ) } <NEWLINE> <NEWLINE> <NEWLINE> font_keys = [ <STRING> , <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <STRING> ] <NEWLINE> font_dict = { k : context_dict [ k ] * font_scale for k in font_keys } <NEWLINE> context_dict . update ( font_dict ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if rc is not None : <NEWLINE> <TAB> rc = { k : v for k , v in rc . items ( ) if k in _context_keys } <NEWLINE> context_dict . update ( rc ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> context_object = _PlottingContext ( context_dict ) <NEWLINE> <NEWLINE> return context_object <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _getconv ( dtype ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def floatconv ( x ) : <NEWLINE> <TAB> x . lower ( ) <NEWLINE> if <STRING> in x : <NEWLINE> <TAB> return float . fromhex ( x ) <NEWLINE> <UNTAB> return float ( x ) <NEWLINE> <NEWLINE> <UNTAB> typ = dtype . type <NEWLINE> if issubclass ( typ , np . bool_ ) : <NEWLINE> <TAB> return lambda x : bool ( int ( x ) ) <NEWLINE> <UNTAB> if issubclass ( typ , np . uint64 ) : <NEWLINE> <TAB> return np . uint64 <NEWLINE> <UNTAB> if issubclass ( typ , np . int64 ) : <NEWLINE> <TAB> return np . int64 <NEWLINE> <UNTAB> if issubclass ( typ , np . integer ) : <NEWLINE> <TAB> return lambda x : int ( float ( x ) ) <NEWLINE> <UNTAB> elif issubclass ( typ , np . longdouble ) : <NEWLINE> <TAB> return np . longdouble <NEWLINE> <UNTAB> elif issubclass ( typ , np . floating ) : <NEWLINE> <TAB> return floatconv <NEWLINE> <UNTAB> elif issubclass ( typ , complex ) : <NEWLINE> <TAB> return lambda x : complex ( asstr ( x ) ) <NEWLINE> <UNTAB> elif issubclass ( typ , np . bytes_ ) : <NEWLINE> <TAB> return asbytes <NEWLINE> <UNTAB> elif issubclass ( typ , np . unicode_ ) : <NEWLINE> <TAB> return asunicode <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return asstr <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def reduce_store_size ( self , bytes_limit ) : <NEWLINE> <TAB> <NEWLINE> items_to_delete = self . _get_items_to_delete ( bytes_limit ) <NEWLINE> <NEWLINE> for item in items_to_delete : <NEWLINE> <TAB> if self . verbose > <NUMBER> : <NEWLINE> <TAB> print ( <STRING> . format ( item ) ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> self . clear_location ( item . path ) <NEWLINE> <UNTAB> except OSError : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def factoring_visitor ( state , primes ) : <NEWLINE> <TAB> <NEWLINE> f , lpart , pstack = state <NEWLINE> factoring = [ ] <NEWLINE> for i in range ( lpart + <NUMBER> ) : <NEWLINE> <TAB> factor = <NUMBER> <NEWLINE> for ps in pstack [ f [ i ] : f [ i + <NUMBER> ] ] : <NEWLINE> <TAB> if ps . v > <NUMBER> : <NEWLINE> <TAB> factor *= primes [ ps . c ] ** ps . v <NEWLINE> <UNTAB> <UNTAB> factoring . append ( factor ) <NEWLINE> <UNTAB> return factoring <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def resample ( self , size = None ) : <NEWLINE> <TAB> <NEWLINE> if size is None : <NEWLINE> <TAB> size = self . n <NEWLINE> <NEWLINE> <UNTAB> norm = transpose ( multivariate_normal ( zeros ( ( self . d , ) , float ) , <NEWLINE> self . covariance , size = size ) ) <NEWLINE> indices = randint ( <NUMBER> , self . n , size = size ) <NEWLINE> means = self . dataset [ : , indices ] <NEWLINE> <NEWLINE> return means + norm <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def static_graph ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> force_test_define_by_run = False <NEWLINE> <NEWLINE> minimize_cache_size = False <NEWLINE> verbosity_level = <NUMBER> <NEWLINE> enable_double_backprop = False <NEWLINE> zero_args = False <NEWLINE> if len ( args ) == <NUMBER> and not kwargs and callable ( args [ <NUMBER> ] ) : <NEWLINE> <TAB> callable_arg = args [ <NUMBER> ] <NEWLINE> zero_args = True <NEWLINE> <UNTAB> elif kwargs : <NEWLINE> <TAB> if <STRING> in kwargs : <NEWLINE> <TAB> force_test_define_by_run = kwargs [ <STRING> ] <NEWLINE> <UNTAB> if <STRING> in kwargs : <NEWLINE> <TAB> minimize_cache_size = kwargs [ <STRING> ] <NEWLINE> <UNTAB> if <STRING> in kwargs : <NEWLINE> <TAB> verbosity_level = kwargs [ <STRING> ] <NEWLINE> <UNTAB> if <STRING> in kwargs : <NEWLINE> <TAB> enable_double_backprop = kwargs [ <STRING> ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def wrap ( func ) : <NEWLINE> <TAB> def wrapped_func ( * inner_args , ** inner_kwargs ) : <NEWLINE> <TAB> if verbosity_level >= <NUMBER> : <NEWLINE> <TAB> print ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> chain = inner_args [ <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> chain_args = inner_args [ <NUMBER> : ] <NEWLINE> if chainer . config . train is False and force_test_define_by_run : <NEWLINE> <TAB> return func ( * inner_args , ** inner_kwargs ) <NEWLINE> <NEWLINE> <UNTAB> chain_args_flat , in_unflatten_inds , __ = _flatten_args ( chain_args ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> flat_vars = [ ] <NEWLINE> for x in chain_args_flat : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if not isinstance ( x , chainer . Variable ) : <NEWLINE> <TAB> flat_vars . append ( chainer . Variable ( x ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> flat_vars . append ( x ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> flat_vars = tuple ( flat_vars ) <NEWLINE> <NEWLINE> if not hasattr ( chain , <STRING> ) : <NEWLINE> <TAB> chain . schedule_manager = ScheduleManager ( <NEWLINE> minimize_cache_size = minimize_cache_size , <NEWLINE> verbosity_level = verbosity_level ) <NEWLINE> <NEWLINE> <UNTAB> schedule_manager = chain . schedule_manager <NEWLINE> <NEWLINE> edb = enable_double_backprop <NEWLINE> chain . static_schedule = schedule_manager . get_schedule ( flat_vars , <NEWLINE> enable_double_backprop = edb ) <NEWLINE> <NEWLINE> if verbosity_level >= <NUMBER> : <NEWLINE> <TAB> print ( <STRING> , schedule_manager ) <NEWLINE> <UNTAB> if not chain . static_schedule . is_empty ( ) : <NEWLINE> <NEWLINE> <TAB> if verbosity_level >= <NUMBER> : <NEWLINE> <TAB> print ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> chain . static_schedule . debug_print_ref_counts ( ) <NEWLINE> <UNTAB> out_vars_flat = chain . static_schedule . apply ( flat_vars ) <NEWLINE> out_vars = _unflatten_args ( out_vars_flat , <NEWLINE> chain . _out_vars_unflatten_inds ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> assert isinstance ( chain , chainer . Chain ) <NEWLINE> if verbosity_level >= <NUMBER> : <NEWLINE> <TAB> print ( <STRING> <NEWLINE> <STRING> , func ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if chainer . config . schedule_func is not None : <NEWLINE> <TAB> raise RuntimeError ( <STRING> , <NEWLINE> chain ) <NEWLINE> <NEWLINE> <UNTAB> new_args = [ ] <NEWLINE> new_args . append ( chain ) <NEWLINE> new_flat_vars = [ ] <NEWLINE> for var in flat_vars : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> new_flat_vars . append ( chainer . Variable ( var . data ) ) <NEWLINE> <NEWLINE> <UNTAB> unflat_in_args = _unflatten_args_as_list ( new_flat_vars , <NEWLINE> in_unflatten_inds ) <NEWLINE> <NEWLINE> for item in unflat_in_args : <NEWLINE> <TAB> new_args . append ( item ) <NEWLINE> <NEWLINE> <UNTAB> inner_args = tuple ( new_args ) <NEWLINE> <NEWLINE> with chainer . using_config ( <STRING> , <NEWLINE> chain . static_schedule ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> out_vars = func ( * inner_args , ** inner_kwargs ) <NEWLINE> <NEWLINE> <UNTAB> out_vars_flat_dbr , chain . _out_vars_unflatten_inds , __ = _flatten_args ( out_vars ) <NEWLINE> sched_out_vars = list ( out_vars_flat_dbr ) <NEWLINE> chain . static_schedule . set_out_variables ( sched_out_vars ) <NEWLINE> <NEWLINE> <NEWLINE> chain . static_schedule . build_schedule ( chain , new_flat_vars ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> out_vars_flat = chain . static_schedule . apply ( flat_vars ) <NEWLINE> <NEWLINE> out_vars = _unflatten_args ( out_vars_flat , <NEWLINE> chain . _out_vars_unflatten_inds ) <NEWLINE> <NEWLINE> if verbosity_level >= <NUMBER> : <NEWLINE> <TAB> print ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return out_vars <NEWLINE> <NEWLINE> <UNTAB> return wrapped_func <NEWLINE> <NEWLINE> <UNTAB> if zero_args : <NEWLINE> <TAB> return wrap ( callable_arg ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return wrap <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def group_by_window ( key_func , <NEWLINE> reduce_func , <NEWLINE> window_size = None , <NEWLINE> window_size_func = None ) : <NEWLINE> <TAB> <NEWLINE> if ( window_size is not None and window_size_func or <NEWLINE> not ( window_size is not None or window_size_func ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if window_size is not None : <NEWLINE> <NEWLINE> <TAB> def constant_window_func ( unused_key ) : <NEWLINE> <TAB> return ops . convert_to_tensor ( window_size , dtype = dtypes . int64 ) <NEWLINE> <NEWLINE> <UNTAB> window_size_func = constant_window_func <NEWLINE> <NEWLINE> <UNTAB> assert window_size_func is not None <NEWLINE> <NEWLINE> def _apply_fn ( dataset ) : <NEWLINE> <TAB> <NEWLINE> return _GroupByWindowDataset ( dataset , key_func , reduce_func , <NEWLINE> window_size_func ) <NEWLINE> <NEWLINE> <UNTAB> return _apply_fn <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def init_ops ( self ) : <NEWLINE> <TAB> <NEWLINE> return control_flow_ops . group ( * self . _init_ops ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_stretch ( self , stretch ) : <NEWLINE> <TAB> <NEWLINE> if stretch is None : <NEWLINE> <TAB> stretch = rcParams [ <STRING> ] <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> stretch = int ( stretch ) <NEWLINE> if stretch < <NUMBER> or stretch > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( ) <NEWLINE> <UNTAB> <UNTAB> except ValueError : <NEWLINE> <TAB> if stretch not in stretch_dict : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> self . _stretch = stretch <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def vstack ( cls , * args ) : <NEWLINE> <TAB> <NEWLINE> if len ( args ) == <NUMBER> : <NEWLINE> <TAB> return cls . _new ( ) <NEWLINE> <NEWLINE> <UNTAB> kls = type ( args [ <NUMBER> ] ) <NEWLINE> return reduce ( kls . col_join , args ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def hankel_transform ( f , r , k , nu , ** hints ) : <NEWLINE> <TAB> <NEWLINE> return HankelTransform ( f , r , k , nu ) . doit ( ** hints ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def inner_sitsot_only_last_step_used ( self , var , scan_args ) : <NEWLINE> <TAB> <NEWLINE> idx = scan_args . inner_out_sit_sot . index ( var ) <NEWLINE> outer_var = scan_args . outer_out_sit_sot [ idx ] <NEWLINE> <NEWLINE> if len ( outer_var . clients ) == <NUMBER> : <NEWLINE> <TAB> client = outer_var . clients [ <NUMBER> ] [ <NUMBER> ] <NEWLINE> if ( client != <STRING> and isinstance ( client . op , <NEWLINE> theano . tensor . Subtensor ) ) : <NEWLINE> <TAB> lst = theano . tensor . subtensor . get_idx_list ( <NEWLINE> client . inputs , client . op . idx_list ) <NEWLINE> if ( len ( lst ) == <NUMBER> and <NEWLINE> theano . tensor . extract_constant ( lst [ <NUMBER> ] ) == - <NUMBER> ) : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def set_size ( a , validate_indices = True ) : <NEWLINE> <TAB> <NEWLINE> a = sparse_tensor . convert_to_tensor_or_sparse_tensor ( a , name = <STRING> ) <NEWLINE> if not isinstance ( a , sparse_tensor . SparseTensor ) : <NEWLINE> <TAB> raise TypeError ( <STRING> % a ) <NEWLINE> <UNTAB> if a . values . dtype . base_dtype not in _VALID_DTYPES : <NEWLINE> <TAB> raise TypeError ( <STRING> % a . values . dtype ) <NEWLINE> <NEWLINE> <UNTAB> return gen_set_ops . set_size ( <NEWLINE> a . indices , a . values , a . dense_shape , validate_indices ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _findfile ( self , path ) : <NEWLINE> <TAB> <NEWLINE> return DataSource . _findfile ( self , self . _fullpath ( path ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def register_type_abbreviation ( name , alias ) : <NEWLINE> <TAB> <NEWLINE> _TYPE_ABBREVIATIONS [ name ] = alias <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def barbell_graph ( m1 , m2 , create_using = None ) : <NEWLINE> <TAB> <NEWLINE> if m1 < <NUMBER> : <NEWLINE> <TAB> raise NetworkXError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if m2 < <NUMBER> : <NEWLINE> <TAB> raise NetworkXError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> G = complete_graph ( m1 , create_using ) <NEWLINE> if G . is_directed ( ) : <NEWLINE> <TAB> raise NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> G . add_nodes_from ( range ( m1 , m1 + m2 - <NUMBER> ) ) <NEWLINE> if m2 > <NUMBER> : <NEWLINE> <TAB> G . add_edges_from ( pairwise ( range ( m1 , m1 + m2 ) ) ) <NEWLINE> <NEWLINE> <UNTAB> G . add_edges_from ( ( u , v ) for u in range ( m1 + m2 , <NUMBER> * m1 + m2 ) <NEWLINE> for v in range ( u + <NUMBER> , <NUMBER> * m1 + m2 ) ) <NEWLINE> <NEWLINE> G . add_edge ( m1 - <NUMBER> , m1 ) <NEWLINE> if m2 > <NUMBER> : <NEWLINE> <TAB> G . add_edge ( m1 + m2 - <NUMBER> , m1 + m2 ) <NEWLINE> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def reinforce_box_boundaries ( x , lb , ub ) : <NEWLINE> <TAB> <NEWLINE> return np . minimum ( np . maximum ( x , lb ) , ub ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_absolutely_convergent ( self ) : <NEWLINE> <TAB> <NEWLINE> return Sum ( abs ( self . function ) , self . limits ) . is_convergent ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _predict ( self , X = None ) : <NEWLINE> <TAB> <NEWLINE> check_is_fitted ( self , [ <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> ] ) <NEWLINE> <NEWLINE> if X is not None : <NEWLINE> <TAB> X = check_array ( X , accept_sparse = <STRING> ) <NEWLINE> is_inlier = np . ones ( X . shape [ <NUMBER> ] , dtype = int ) <NEWLINE> is_inlier [ self . decision_function ( X ) < <NUMBER> ] = - <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> is_inlier = np . ones ( self . _fit_X . shape [ <NUMBER> ] , dtype = int ) <NEWLINE> is_inlier [ self . negative_outlier_factor_ < self . offset_ ] = - <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> return is_inlier <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_RealField ( K1 , a , K0 ) : <NEWLINE> <TAB> <NEWLINE> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def y1p_zeros ( nt , complex = False ) : <NEWLINE> <TAB> <NEWLINE> if not isscalar ( nt ) or ( floor ( nt ) != nt ) or ( nt <= <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> kf = <NUMBER> <NEWLINE> kc = not complex <NEWLINE> return specfun . cyzo ( nt , kf , kc ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def redirect_request ( self , req , fp , code , msg , headers , newurl ) : <NEWLINE> <TAB> <NEWLINE> m = req . get_method ( ) <NEWLINE> if ( not ( code in ( <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) and m in ( <STRING> , <STRING> ) <NEWLINE> or code in ( <NUMBER> , <NUMBER> , <NUMBER> ) and m == <STRING> ) ) : <NEWLINE> <TAB> raise HTTPError ( req . full_url , code , msg , headers , fp ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> newurl = newurl . replace ( <STRING> , <STRING> ) <NEWLINE> <NEWLINE> CONTENT_HEADERS = ( <STRING> , <STRING> ) <NEWLINE> newheaders = dict ( ( k , v ) for k , v in req . headers . items ( ) <NEWLINE> if k . lower ( ) not in CONTENT_HEADERS ) <NEWLINE> return Request ( newurl , <NEWLINE> headers = newheaders , <NEWLINE> origin_req_host = req . origin_req_host , <NEWLINE> unverifiable = True ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _dict_to_tensor ( self , x , k1 , k2 ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return array_ops . stack ( [ array_ops . stack ( [ x [ i , j ] for j in range ( k2 ) ] ) <NEWLINE> for i in range ( k1 ) ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def lcm ( self , a , b ) : <NEWLINE> <TAB> <NEWLINE> return a * b <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _call_previousnext ( self , x_new ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> x_new_indices = searchsorted ( self . _x_shift , x_new , side = self . _side ) <NEWLINE> <NEWLINE> <NEWLINE> x_new_indices = x_new_indices . clip ( <NUMBER> - self . _ind , <NEWLINE> len ( self . x ) - self . _ind ) . astype ( intp ) <NEWLINE> <NEWLINE> <NEWLINE> y_new = self . _y [ x_new_indices + self . _ind - <NUMBER> ] <NEWLINE> <NEWLINE> return y_new <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def from_dict_of_lists ( d , create_using = None ) : <NEWLINE> <TAB> <NEWLINE> G = nx . empty_graph ( <NUMBER> , create_using ) <NEWLINE> G . add_nodes_from ( d ) <NEWLINE> if G . is_multigraph ( ) and not G . is_directed ( ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> seen = { } <NEWLINE> for node , nbrlist in d . items ( ) : <NEWLINE> <TAB> for nbr in nbrlist : <NEWLINE> <TAB> if nbr not in seen : <NEWLINE> <TAB> G . add_edge ( node , nbr ) <NEWLINE> <UNTAB> <UNTAB> seen [ node ] = <NUMBER> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> G . add_edges_from ( ( ( node , nbr ) for node , nbrlist in d . items ( ) <NEWLINE> for nbr in nbrlist ) ) <NEWLINE> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set ( self , locs , values , check = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if check : <NEWLINE> <TAB> try : <NEWLINE> <TAB> if ( self . values [ locs ] == values ) . all ( ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> <UNTAB> except : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> try : <NEWLINE> <TAB> self . values [ locs ] = values <NEWLINE> <UNTAB> except ( ValueError ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> new_shape = list ( values . shape ) <NEWLINE> new_shape [ <NUMBER> ] = len ( self . items ) <NEWLINE> self . values = np . empty ( tuple ( new_shape ) , dtype = self . dtype ) <NEWLINE> self . values . fill ( np . nan ) <NEWLINE> self . values [ locs ] = values <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , * args , ** kw ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> for fn in self . parent_listeners : <NEWLINE> <TAB> fn ( * args , ** kw ) <NEWLINE> <UNTAB> for fn in self . listeners : <NEWLINE> <TAB> fn ( * args , ** kw ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def scatter ( inputs , target_gpus , dim = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> def scatter_map ( obj ) : <NEWLINE> <TAB> if isinstance ( obj , torch . Tensor ) : <NEWLINE> <TAB> return Scatter . apply ( target_gpus , None , dim , obj ) <NEWLINE> <UNTAB> if isinstance ( obj , tuple ) and len ( obj ) > <NUMBER> : <NEWLINE> <TAB> return list ( zip ( * map ( scatter_map , obj ) ) ) <NEWLINE> <UNTAB> if isinstance ( obj , list ) and len ( obj ) > <NUMBER> : <NEWLINE> <TAB> return list ( map ( list , zip ( * map ( scatter_map , obj ) ) ) ) <NEWLINE> <UNTAB> if isinstance ( obj , dict ) and len ( obj ) > <NUMBER> : <NEWLINE> <TAB> return list ( map ( type ( obj ) , zip ( * map ( scatter_map , obj . items ( ) ) ) ) ) <NEWLINE> <UNTAB> return [ obj for targets in target_gpus ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> return scatter_map ( inputs ) <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> scatter_map = None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def initialize ( self , n , approx_type ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def unit_regular_asterisk ( cls , numVertices ) : <NEWLINE> <TAB> <NEWLINE> return cls . unit_regular_star ( numVertices , <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def adjusted_rand_score ( labels_true , labels_pred ) : <NEWLINE> <TAB> <NEWLINE> labels_true , labels_pred = check_clusterings ( labels_true , labels_pred ) <NEWLINE> n_samples = labels_true . shape [ <NUMBER> ] <NEWLINE> n_classes = np . unique ( labels_true ) . shape [ <NUMBER> ] <NEWLINE> n_clusters = np . unique ( labels_pred ) . shape [ <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if ( n_classes == n_clusters == <NUMBER> or <NEWLINE> n_classes == n_clusters == <NUMBER> or <NEWLINE> n_classes == n_clusters == n_samples ) : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> contingency = contingency_matrix ( labels_true , labels_pred , sparse = True ) <NEWLINE> sum_comb_c = sum ( _comb2 ( n_c ) for n_c in np . ravel ( contingency . sum ( axis = <NUMBER> ) ) ) <NEWLINE> sum_comb_k = sum ( _comb2 ( n_k ) for n_k in np . ravel ( contingency . sum ( axis = <NUMBER> ) ) ) <NEWLINE> sum_comb = sum ( _comb2 ( n_ij ) for n_ij in contingency . data ) <NEWLINE> <NEWLINE> prod_comb = ( sum_comb_c * sum_comb_k ) / _comb2 ( n_samples ) <NEWLINE> mean_comb = ( sum_comb_k + sum_comb_c ) / <NUMBER> <NEWLINE> return ( sum_comb - prod_comb ) / ( mean_comb - prod_comb ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def conv3d_backprop_filter ( input , filter , out_backprop , strides , padding , dilations = [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if not isinstance ( strides , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % strides ) <NEWLINE> <UNTAB> strides = [ _execute . make_int ( _i , <STRING> ) for _i in strides ] <NEWLINE> padding = _execute . make_str ( padding , <STRING> ) <NEWLINE> if dilations is None : <NEWLINE> <TAB> dilations = [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] <NEWLINE> <UNTAB> if not isinstance ( dilations , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % dilations ) <NEWLINE> <UNTAB> dilations = [ _execute . make_int ( _i , <STRING> ) for _i in dilations ] <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , filter = filter , <NEWLINE> out_backprop = out_backprop , strides = strides , padding = padding , <NEWLINE> dilations = dilations , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) , <NEWLINE> <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , input , <NEWLINE> filter , out_backprop , <STRING> , strides , <STRING> , padding , <NEWLINE> <STRING> , dilations ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return conv3d_backprop_filter_eager_fallback ( <NEWLINE> input , filter , out_backprop , strides = strides , padding = padding , <NEWLINE> dilations = dilations , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def winfo_vrootwidth ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . tk . getint ( <NEWLINE> self . tk . call ( <STRING> , <STRING> , self . _w ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ open_file ( <NUMBER> , mode = <STRING> ) <NEWLINE> def read_gexf ( path , node_type = None , relabel = False , version = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> reader = GEXFReader ( node_type = node_type , version = version ) <NEWLINE> if relabel : <NEWLINE> <TAB> G = relabel_gexf_graph ( reader ( path ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> G = reader ( path ) <NEWLINE> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def degree_centrality ( G , nodes ) : <NEWLINE> <TAB> <NEWLINE> top = set ( nodes ) <NEWLINE> bottom = set ( G ) - top <NEWLINE> s = <NUMBER> / len ( bottom ) <NEWLINE> centrality = dict ( ( n , d * s ) for n , d in G . degree ( top ) ) <NEWLINE> s = <NUMBER> / len ( top ) <NEWLINE> centrality . update ( dict ( ( n , d * s ) for n , d in G . degree ( bottom ) ) ) <NEWLINE> return centrality <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def save_function ( self , obj , name = None ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> should_special_case = obj in _BUILTIN_TYPE_CONSTRUCTORS <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <NEWLINE> <TAB> should_special_case = False <NEWLINE> <NEWLINE> <UNTAB> if should_special_case : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return self . save_reduce ( _BUILTIN_TYPE_CONSTRUCTORS [ obj ] , ( ) , obj = obj ) <NEWLINE> <NEWLINE> <UNTAB> write = self . write <NEWLINE> <NEWLINE> if name is None : <NEWLINE> <TAB> name = obj . __name__ <NEWLINE> <UNTAB> try : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> modname = pickle . whichmodule ( obj , name ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> modname = None <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> themodule = sys . modules [ modname ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <NEWLINE> <TAB> modname = <STRING> <NEWLINE> <NEWLINE> <UNTAB> if modname == <STRING> : <NEWLINE> <TAB> themodule = None <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> lookedup_by_name = getattr ( themodule , name , None ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> lookedup_by_name = None <NEWLINE> <NEWLINE> <UNTAB> if themodule : <NEWLINE> <TAB> self . modules . add ( themodule ) <NEWLINE> if lookedup_by_name is obj : <NEWLINE> <TAB> return self . save_global ( obj , name ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not hasattr ( obj , <STRING> ) : <NEWLINE> <TAB> if PY3 : <NEWLINE> <TAB> rv = obj . __reduce_ex__ ( self . proto ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if hasattr ( obj , <STRING> ) : <NEWLINE> <TAB> rv = ( getattr , ( obj . __self__ , name ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise pickle . PicklingError ( <STRING> % obj ) <NEWLINE> <UNTAB> <UNTAB> return self . save_reduce ( obj = obj , * rv ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if ( islambda ( obj ) <NEWLINE> or getattr ( obj . __code__ , <STRING> , None ) == <STRING> <NEWLINE> or themodule is None ) : <NEWLINE> <TAB> self . save_function_tuple ( obj ) <NEWLINE> return <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> if lookedup_by_name is None or lookedup_by_name is not obj : <NEWLINE> <TAB> self . save_function_tuple ( obj ) <NEWLINE> return <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if obj . __dict__ : <NEWLINE> <NEWLINE> <TAB> self . save ( _restore_attr ) <NEWLINE> write ( pickle . MARK + pickle . GLOBAL + modname + <STRING> + name + <STRING> ) <NEWLINE> self . memoize ( obj ) <NEWLINE> self . save ( obj . __dict__ ) <NEWLINE> write ( pickle . TUPLE + pickle . REDUCE ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> write ( pickle . GLOBAL + modname + <STRING> + name + <STRING> ) <NEWLINE> self . memoize ( obj ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def iterate_attributes ( cls ) : <NEWLINE> <TAB> <NEWLINE> keys = dir ( cls ) <NEWLINE> for key in keys : <NEWLINE> <TAB> for c in cls . __mro__ : <NEWLINE> <TAB> if key in c . __dict__ : <NEWLINE> <TAB> yield ( key , c . __dict__ [ key ] ) <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_sympy ( self , a ) : <NEWLINE> <TAB> <NEWLINE> return self . dtype ( a ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rankdata ( a , method = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if method not in ( <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( method ) ) <NEWLINE> <NEWLINE> <UNTAB> arr = np . ravel ( np . asarray ( a ) ) <NEWLINE> algo = <STRING> if method == <STRING> else <STRING> <NEWLINE> sorter = np . argsort ( arr , kind = algo ) <NEWLINE> <NEWLINE> inv = np . empty ( sorter . size , dtype = np . intp ) <NEWLINE> inv [ sorter ] = np . arange ( sorter . size , dtype = np . intp ) <NEWLINE> <NEWLINE> if method == <STRING> : <NEWLINE> <TAB> return inv + <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> arr = arr [ sorter ] <NEWLINE> obs = np . r_ [ True , arr [ <NUMBER> : ] != arr [ : - <NUMBER> ] ] <NEWLINE> dense = obs . cumsum ( ) [ inv ] <NEWLINE> <NEWLINE> if method == <STRING> : <NEWLINE> <TAB> return dense <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> count = np . r_ [ np . nonzero ( obs ) [ <NUMBER> ] , len ( obs ) ] <NEWLINE> <NEWLINE> if method == <STRING> : <NEWLINE> <TAB> return count [ dense ] <NEWLINE> <NEWLINE> <UNTAB> if method == <STRING> : <NEWLINE> <TAB> return count [ dense - <NUMBER> ] + <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return <NUMBER> * ( count [ dense ] + count [ dense - <NUMBER> ] + <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def initial_alignments ( self , batch_size , dtype ) : <NEWLINE> <TAB> <NEWLINE> max_time = self . _alignments_size <NEWLINE> return _zero_state_tensors ( max_time , batch_size , dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> @ not_implemented_for ( <STRING> ) <NEWLINE> def mycielskian ( G , iterations = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> n = G . number_of_nodes ( ) <NEWLINE> M = nx . convert_node_labels_to_integers ( G ) <NEWLINE> <NEWLINE> for i in range ( iterations ) : <NEWLINE> <TAB> n = M . number_of_nodes ( ) <NEWLINE> M . add_nodes_from ( range ( n , <NUMBER> * n ) ) <NEWLINE> old_edges = list ( M . edges ( ) ) <NEWLINE> M . add_edges_from ( ( u , v + n ) for u , v in old_edges ) <NEWLINE> M . add_edges_from ( ( u + n , v ) for u , v in old_edges ) <NEWLINE> M . add_node ( <NUMBER> * n ) <NEWLINE> M . add_edges_from ( ( u + n , <NUMBER> * n ) for u in range ( n ) ) <NEWLINE> <NEWLINE> <UNTAB> return M <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _arrange_subplotspecs ( gs , hspace = <NUMBER> , wspace = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> sschildren = [ ] <NEWLINE> for child in gs . children : <NEWLINE> <TAB> if child . _is_subplotspec_layoutbox ( ) : <NEWLINE> <TAB> for child2 in child . children : <NEWLINE> <NEWLINE> <TAB> if child2 . _is_gridspec_layoutbox ( ) : <NEWLINE> <TAB> _arrange_subplotspecs ( child2 , hspace = hspace , wspace = wspace ) <NEWLINE> <UNTAB> <UNTAB> sschildren += [ child ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for child0 in sschildren : <NEWLINE> <TAB> ss0 = child0 . artist <NEWLINE> nrows , ncols = ss0 . get_gridspec ( ) . get_geometry ( ) <NEWLINE> if ss0 . num2 is None : <NEWLINE> <TAB> ss0 . num2 = ss0 . num1 <NEWLINE> <UNTAB> rowNum0min , colNum0min = divmod ( ss0 . num1 , ncols ) <NEWLINE> rowNum0max , colNum0max = divmod ( ss0 . num2 , ncols ) <NEWLINE> sschildren = sschildren [ <NUMBER> : ] <NEWLINE> for childc in sschildren : <NEWLINE> <TAB> ssc = childc . artist <NEWLINE> rowNumCmin , colNumCmin = divmod ( ssc . num1 , ncols ) <NEWLINE> if ssc . num2 is None : <NEWLINE> <TAB> ssc . num2 = ssc . num1 <NEWLINE> <UNTAB> rowNumCmax , colNumCmax = divmod ( ssc . num2 , ncols ) <NEWLINE> <NEWLINE> <NEWLINE> thepad = wspace / ncols <NEWLINE> if colNum0max < colNumCmin : <NEWLINE> <TAB> layoutbox . hstack ( [ ss0 . _layoutbox , ssc . _layoutbox ] , <NEWLINE> padding = thepad ) <NEWLINE> <UNTAB> if colNumCmax < colNum0min : <NEWLINE> <TAB> layoutbox . hstack ( [ ssc . _layoutbox , ss0 . _layoutbox ] , <NEWLINE> padding = thepad ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> thepad = hspace / nrows <NEWLINE> if rowNum0max < rowNumCmin : <NEWLINE> <TAB> layoutbox . vstack ( [ ss0 . _layoutbox , <NEWLINE> ssc . _layoutbox ] , <NEWLINE> padding = thepad ) <NEWLINE> <UNTAB> if rowNumCmax < rowNum0min : <NEWLINE> <TAB> layoutbox . vstack ( [ ssc . _layoutbox , <NEWLINE> ss0 . _layoutbox ] , <NEWLINE> padding = thepad ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def legfit ( x , y , deg , rcond = None , full = False , w = None ) : <NEWLINE> <TAB> <NEWLINE> x = np . asarray ( x ) + <NUMBER> <NEWLINE> y = np . asarray ( y ) + <NUMBER> <NEWLINE> deg = np . asarray ( deg ) <NEWLINE> <NEWLINE> <NEWLINE> if deg . ndim > <NUMBER> or deg . dtype . kind not in <STRING> or deg . size == <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if deg . min ( ) < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if x . ndim != <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if x . size == <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if y . ndim < <NUMBER> or y . ndim > <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if len ( x ) != len ( y ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if deg . ndim == <NUMBER> : <NEWLINE> <TAB> lmax = deg <NEWLINE> order = lmax + <NUMBER> <NEWLINE> van = legvander ( x , lmax ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> deg = np . sort ( deg ) <NEWLINE> lmax = deg [ - <NUMBER> ] <NEWLINE> order = len ( deg ) <NEWLINE> van = legvander ( x , lmax ) [ : , deg ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> lhs = van . T <NEWLINE> rhs = y . T <NEWLINE> if w is not None : <NEWLINE> <TAB> w = np . asarray ( w ) + <NUMBER> <NEWLINE> if w . ndim != <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if len ( x ) != len ( w ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> lhs = lhs * w <NEWLINE> rhs = rhs * w <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if rcond is None : <NEWLINE> <TAB> rcond = len ( x ) * np . finfo ( x . dtype ) . eps <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if issubclass ( lhs . dtype . type , np . complexfloating ) : <NEWLINE> <TAB> scl = np . sqrt ( ( np . square ( lhs . real ) + np . square ( lhs . imag ) ) . sum ( <NUMBER> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> scl = np . sqrt ( np . square ( lhs ) . sum ( <NUMBER> ) ) <NEWLINE> <UNTAB> scl [ scl == <NUMBER> ] = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> c , resids , rank , s = la . lstsq ( lhs . T / scl , rhs . T , rcond ) <NEWLINE> c = ( c . T / scl ) . T <NEWLINE> <NEWLINE> <NEWLINE> if deg . ndim > <NUMBER> : <NEWLINE> <TAB> if c . ndim == <NUMBER> : <NEWLINE> <TAB> cc = np . zeros ( ( lmax + <NUMBER> , c . shape [ <NUMBER> ] ) , dtype = c . dtype ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cc = np . zeros ( lmax + <NUMBER> , dtype = c . dtype ) <NEWLINE> <UNTAB> cc [ deg ] = c <NEWLINE> c = cc <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if rank != order and not full : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> warnings . warn ( msg , pu . RankWarning , stacklevel = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> if full : <NEWLINE> <TAB> return c , [ resids , rank , s , rcond ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return c <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def sample_from_datasets ( datasets , weights = None , seed = None ) : <NEWLINE> <TAB> <NEWLINE> num_datasets = len ( datasets ) <NEWLINE> if not isinstance ( weights , dataset_ops . Dataset ) : <NEWLINE> <TAB> if weights is None : <NEWLINE> <NEWLINE> <TAB> logits = [ [ <NUMBER> ] * num_datasets ] <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> weights = ops . convert_to_tensor ( weights , name = <STRING> ) <NEWLINE> if weights . dtype not in ( dtypes . float32 , dtypes . float64 ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if not weights . shape . is_compatible_with ( [ num_datasets ] ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> logits = array_ops . expand_dims ( math_ops . log ( weights , name = <STRING> ) , <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if len ( datasets ) == <NUMBER> : <NEWLINE> <TAB> return datasets [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> def select_dataset_constant_logits ( seed ) : <NEWLINE> <TAB> return array_ops . squeeze ( <NEWLINE> gen_stateless_random_ops . stateless_multinomial ( logits , <NUMBER> , seed = seed ) , <NEWLINE> axis = [ <NUMBER> , <NUMBER> ] ) <NEWLINE> <NEWLINE> <UNTAB> selector_input = dataset_ops . MapDataset ( <NEWLINE> random_ops . RandomDataset ( seed ) . batch ( <NUMBER> ) , <NEWLINE> select_dataset_constant_logits , <NEWLINE> use_inter_op_parallelism = False ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> logits_ds = weights . map ( lambda * p : math_ops . log ( p , name = <STRING> ) ) <NEWLINE> <NEWLINE> def select_dataset_varying_logits ( logits , seed ) : <NEWLINE> <TAB> return array_ops . squeeze ( <NEWLINE> gen_stateless_random_ops . stateless_multinomial ( logits , <NUMBER> , seed = seed ) , <NEWLINE> axis = [ <NUMBER> , <NUMBER> ] ) <NEWLINE> <NEWLINE> <UNTAB> logits_and_seeds = dataset_ops . Dataset . zip ( <NEWLINE> ( logits_ds , random_ops . RandomDataset ( seed ) . batch ( <NUMBER> ) ) ) <NEWLINE> selector_input = dataset_ops . MapDataset ( <NEWLINE> logits_and_seeds , <NEWLINE> select_dataset_varying_logits , <NEWLINE> use_inter_op_parallelism = False ) <NEWLINE> <NEWLINE> <UNTAB> return _DirectedInterleaveDataset ( selector_input , datasets ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def ground_to_exact ( f ) : <NEWLINE> <TAB> <NEWLINE> return f . set_domain ( f . dom . get_exact ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _make_complex_eigvecs ( w , vin , dtype ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> v = numpy . array ( vin , dtype = dtype ) <NEWLINE> m = ( w . imag > <NUMBER> ) <NEWLINE> m [ : - <NUMBER> ] |= ( w . imag [ <NUMBER> : ] < <NUMBER> ) <NEWLINE> for i in flatnonzero ( m ) : <NEWLINE> <TAB> v . imag [ : , i ] = vin [ : , i + <NUMBER> ] <NEWLINE> conj ( v [ : , i ] , v [ : , i + <NUMBER> ] ) <NEWLINE> <UNTAB> return v <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit_kde ( self , x , bw ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> kde = stats . gaussian_kde ( x , bw ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> kde = stats . gaussian_kde ( x ) <NEWLINE> if bw != <STRING> : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> warnings . warn ( msg , UserWarning ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> bw_used = kde . factor <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> bw_used = bw_used * x . std ( ddof = <NUMBER> ) <NEWLINE> <NEWLINE> return kde , bw_used <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def close ( x , y , rtol = <NUMBER> , atol = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return abs ( x - y ) <= atol + rtol * abs ( y ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def close ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . save ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_offset ( self ) : <NEWLINE> <TAB> <NEWLINE> if len ( self . locs ) == <NUMBER> : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> s = <STRING> <NEWLINE> if self . orderOfMagnitude or self . offset : <NEWLINE> <TAB> offsetStr = <STRING> <NEWLINE> sciNotStr = <STRING> <NEWLINE> if self . offset : <NEWLINE> <TAB> offsetStr = self . format_data ( self . offset ) <NEWLINE> if self . offset > <NUMBER> : <NEWLINE> <TAB> offsetStr = <STRING> + offsetStr <NEWLINE> <UNTAB> <UNTAB> if self . orderOfMagnitude : <NEWLINE> <TAB> if self . _usetex or self . _useMathText : <NEWLINE> <TAB> sciNotStr = self . format_data ( <NUMBER> ** self . orderOfMagnitude ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> sciNotStr = <STRING> % self . orderOfMagnitude <NEWLINE> <UNTAB> <UNTAB> if self . _useMathText : <NEWLINE> <TAB> if sciNotStr != <STRING> : <NEWLINE> <TAB> sciNotStr = <STRING> % _mathdefault ( sciNotStr ) <NEWLINE> <UNTAB> s = <STRING> . join ( ( <STRING> , sciNotStr , _mathdefault ( offsetStr ) , <STRING> ) ) <NEWLINE> <UNTAB> elif self . _usetex : <NEWLINE> <TAB> if sciNotStr != <STRING> : <NEWLINE> <TAB> sciNotStr = <STRING> % sciNotStr <NEWLINE> <UNTAB> s = <STRING> . join ( ( <STRING> , sciNotStr , offsetStr , <STRING> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> s = <STRING> . join ( ( sciNotStr , offsetStr ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return self . fix_minus ( s ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def coeff_monomial ( f , monom ) : <NEWLINE> <TAB> <NEWLINE> return f . nth ( * Monomial ( monom , f . gens ) . exponents ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def transformString ( self , instring ) : <NEWLINE> <TAB> <NEWLINE> out = [ ] <NEWLINE> lastE = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> self . keepTabs = True <NEWLINE> try : <NEWLINE> <TAB> for t , s , e in self . scanString ( instring ) : <NEWLINE> <TAB> out . append ( instring [ lastE : s ] ) <NEWLINE> if t : <NEWLINE> <TAB> if isinstance ( t , ParseResults ) : <NEWLINE> <TAB> out += t . asList ( ) <NEWLINE> <UNTAB> elif isinstance ( t , list ) : <NEWLINE> <TAB> out += t <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> out . append ( t ) <NEWLINE> <UNTAB> <UNTAB> lastE = e <NEWLINE> <UNTAB> out . append ( instring [ lastE : ] ) <NEWLINE> out = [ o for o in out if o ] <NEWLINE> return <STRING> . join ( map ( _ustr , _flatten ( out ) ) ) <NEWLINE> <UNTAB> except ParseBaseException as exc : <NEWLINE> <TAB> if ParserElement . verbose_stacktrace : <NEWLINE> <TAB> raise <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> raise exc <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _eval_rewrite_as_SingularityFunction ( self , args ) : <NEWLINE> <TAB> <NEWLINE> from sympy . solvers import solve <NEWLINE> from sympy . functions import SingularityFunction <NEWLINE> if self == Heaviside ( <NUMBER> ) : <NEWLINE> <TAB> return SingularityFunction ( <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> free = self . free_symbols <NEWLINE> if len ( free ) == <NUMBER> : <NEWLINE> <TAB> x = ( free . pop ( ) ) <NEWLINE> return SingularityFunction ( x , solve ( args , x ) [ <NUMBER> ] , <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> raise TypeError ( filldedent ( ' ' ' 
                                 r e w r i t e ( S i n g u l a r i t y F u n c t i o n )   d o e s n ' t 
                                 s u p p o r t   a r g u m e n t s   w i t h   m o r e   t h a t   1   v a r i a b l e . ' ' ' ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def auto_set_font_size ( self , renderer ) : <NEWLINE> <TAB> <NEWLINE> fontsize = self . get_fontsize ( ) <NEWLINE> required = self . get_required_width ( renderer ) <NEWLINE> while fontsize > <NUMBER> and required > self . get_width ( ) : <NEWLINE> <TAB> fontsize -= <NUMBER> <NEWLINE> self . set_fontsize ( fontsize ) <NEWLINE> required = self . get_required_width ( renderer ) <NEWLINE> <NEWLINE> <UNTAB> return fontsize <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rfft ( a , n = None , axis = - <NUMBER> , norm = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> a = array ( a , copy = True , dtype = float ) <NEWLINE> output = _raw_fft ( a , n , axis , fftpack . rffti , fftpack . rfftf , <NEWLINE> _real_fft_cache ) <NEWLINE> if _unitary ( norm ) : <NEWLINE> <TAB> if n is None : <NEWLINE> <TAB> n = a . shape [ axis ] <NEWLINE> <UNTAB> output *= <NUMBER> / sqrt ( n ) <NEWLINE> <UNTAB> return output <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _enum_init ( self , enums , kw ) : <NEWLINE> <TAB> <NEWLINE> self . native_enum = kw . pop ( <STRING> , True ) <NEWLINE> self . create_constraint = kw . pop ( <STRING> , True ) <NEWLINE> self . values_callable = kw . pop ( <STRING> , None ) <NEWLINE> <NEWLINE> values , objects = self . _parse_into_values ( enums , kw ) <NEWLINE> self . _setup_for_values ( values , objects , kw ) <NEWLINE> <NEWLINE> convert_unicode = kw . pop ( <STRING> , None ) <NEWLINE> self . validate_strings = kw . pop ( <STRING> , False ) <NEWLINE> <NEWLINE> if convert_unicode is None : <NEWLINE> <TAB> for e in self . enums : <NEWLINE> <TAB> if isinstance ( e , util . text_type ) : <NEWLINE> <TAB> convert_unicode = True <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> convert_unicode = False <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if self . enums : <NEWLINE> <TAB> length = max ( len ( x ) for x in self . enums ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> length = <NUMBER> <NEWLINE> <UNTAB> self . _valid_lookup [ None ] = self . _object_lookup [ None ] = None <NEWLINE> <NEWLINE> super ( Enum , self ) . __init__ ( <NEWLINE> length = length , <NEWLINE> convert_unicode = convert_unicode , <NEWLINE> ) <NEWLINE> <NEWLINE> if self . enum_class : <NEWLINE> <TAB> kw . setdefault ( <STRING> , self . enum_class . __name__ . lower ( ) ) <NEWLINE> <UNTAB> SchemaType . __init__ ( <NEWLINE> self , <NEWLINE> name = kw . pop ( <STRING> , None ) , <NEWLINE> schema = kw . pop ( <STRING> , None ) , <NEWLINE> metadata = kw . pop ( <STRING> , None ) , <NEWLINE> inherit_schema = kw . pop ( <STRING> , False ) , <NEWLINE> quote = kw . pop ( <STRING> , None ) , <NEWLINE> _create_events = kw . pop ( <STRING> , True ) <NEWLINE> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _errors_and_values_helper ( self , alpha , y , v , Q , QT_y ) : <NEWLINE> <TAB> <NEWLINE> w = <NUMBER> / ( v + alpha ) <NEWLINE> constant_column = np . var ( Q , <NUMBER> ) < <NUMBER> <NEWLINE> <NEWLINE> w [ constant_column ] = <NUMBER> <NEWLINE> <NEWLINE> c = np . dot ( Q , self . _diag_dot ( w , QT_y ) ) <NEWLINE> G_diag = self . _decomp_diag ( w , Q ) <NEWLINE> <NEWLINE> if len ( y . shape ) != <NUMBER> : <NEWLINE> <TAB> G_diag = G_diag [ : , np . newaxis ] <NEWLINE> <UNTAB> return G_diag , c <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_input_shape_at ( self , node_index ) : <NEWLINE> <TAB> <NEWLINE> return self . _get_node_attribute_at_index ( node_index , <STRING> , <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def adjoint_name ( func , wrt ) : <NEWLINE> <TAB> <NEWLINE> return _adjoint_name ( func , wrt , ADJOINT_NAME ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_grid_positions ( self , fig , raw = False ) : <NEWLINE> <TAB> <NEWLINE> nrows , ncols = self . get_geometry ( ) <NEWLINE> <NEWLINE> if raw : <NEWLINE> <TAB> left = <NUMBER> <NEWLINE> right = <NUMBER> <NEWLINE> bottom = <NUMBER> <NEWLINE> top = <NUMBER> <NEWLINE> wspace = <NUMBER> <NEWLINE> hspace = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> subplot_params = self . get_subplot_params ( fig ) <NEWLINE> left = subplot_params . left <NEWLINE> right = subplot_params . right <NEWLINE> bottom = subplot_params . bottom <NEWLINE> top = subplot_params . top <NEWLINE> wspace = subplot_params . wspace <NEWLINE> hspace = subplot_params . hspace <NEWLINE> <UNTAB> tot_width = right - left <NEWLINE> tot_height = top - bottom <NEWLINE> <NEWLINE> <NEWLINE> cell_h = tot_height / ( nrows + hspace * ( nrows - <NUMBER> ) ) <NEWLINE> sep_h = hspace * cell_h <NEWLINE> if self . _row_height_ratios is not None : <NEWLINE> <TAB> norm = cell_h * nrows / sum ( self . _row_height_ratios ) <NEWLINE> cell_heights = [ r * norm for r in self . _row_height_ratios ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cell_heights = [ cell_h ] * nrows <NEWLINE> <UNTAB> sep_heights = [ <NUMBER> ] + ( [ sep_h ] * ( nrows - <NUMBER> ) ) <NEWLINE> cell_hs = np . cumsum ( np . column_stack ( [ sep_heights , cell_heights ] ) . flat ) <NEWLINE> <NEWLINE> <NEWLINE> cell_w = tot_width / ( ncols + wspace * ( ncols - <NUMBER> ) ) <NEWLINE> sep_w = wspace * cell_w <NEWLINE> if self . _col_width_ratios is not None : <NEWLINE> <TAB> norm = cell_w * ncols / sum ( self . _col_width_ratios ) <NEWLINE> cell_widths = [ r * norm for r in self . _col_width_ratios ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cell_widths = [ cell_w ] * ncols <NEWLINE> <UNTAB> sep_widths = [ <NUMBER> ] + ( [ sep_w ] * ( ncols - <NUMBER> ) ) <NEWLINE> cell_ws = np . cumsum ( np . column_stack ( [ sep_widths , cell_widths ] ) . flat ) <NEWLINE> <NEWLINE> fig_tops , fig_bottoms = ( top - cell_hs ) . reshape ( ( - <NUMBER> , <NUMBER> ) ) . T <NEWLINE> fig_lefts , fig_rights = ( left + cell_ws ) . reshape ( ( - <NUMBER> , <NUMBER> ) ) . T <NEWLINE> return fig_bottoms , fig_tops , fig_lefts , fig_rights <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def greater ( x , y ) : <NEWLINE> <TAB> <NEWLINE> return math_ops . greater ( x , y ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_ring ( self ) : <NEWLINE> <TAB> <NEWLINE> raise DomainError ( <STRING> % self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def take ( arr , indices , axis = <NUMBER> , allow_fill = False , fill_value = None ) : <NEWLINE> <TAB> <NEWLINE> from pandas . core . indexing import validate_indices <NEWLINE> <NEWLINE> if not is_array_like ( arr ) : <NEWLINE> <TAB> arr = np . asarray ( arr ) <NEWLINE> <NEWLINE> <UNTAB> indices = np . asarray ( indices , dtype = np . intp ) <NEWLINE> <NEWLINE> if allow_fill : <NEWLINE> <NEWLINE> <TAB> validate_indices ( indices , len ( arr ) ) <NEWLINE> result = take_1d ( arr , indices , axis = axis , allow_fill = True , <NEWLINE> fill_value = fill_value ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> result = arr . take ( indices , axis = axis ) <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , time_series_reader ) : <NEWLINE> <TAB> <NEWLINE> self . _reader = time_series_reader <NEWLINE> super ( WholeDatasetInputFn , self ) . __init__ ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_arraylike ( x ) : <NEWLINE> <TAB> <NEWLINE> from . base import is_dask_collection <NEWLINE> <NEWLINE> return ( <NEWLINE> hasattr ( x , <STRING> ) and x . shape and <NEWLINE> hasattr ( x , <STRING> ) and <NEWLINE> not any ( is_dask_collection ( n ) for n in x . shape ) <NEWLINE> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _non_slot_variables ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _non_slot_dict . values ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def add ( inputs , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return Add ( ** kwargs ) ( inputs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __ne__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _is_gridspec_layoutbox ( self ) : <NEWLINE> <TAB> <NEWLINE> name = ( self . name ) . split ( <STRING> ) [ - <NUMBER> ] <NEWLINE> return name [ : <NUMBER> ] == <STRING> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __winfo_getint ( self , x ) : <NEWLINE> <TAB> <NEWLINE> return int ( x , <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_regressor ( estimator ) : <NEWLINE> <TAB> <NEWLINE> return getattr ( estimator , <STRING> , None ) == <STRING> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def transform ( self , matrix ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> col , row = matrix . shape <NEWLINE> valid_matrix = matrix . is_square and col == <NUMBER> <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <NEWLINE> <TAB> valid_matrix = False <NEWLINE> <UNTAB> if not valid_matrix : <NEWLINE> <TAB> raise ValueError ( <STRING> + <STRING> ) <NEWLINE> <UNTAB> x , y = self . args <NEWLINE> return Point ( * ( Matrix ( <NUMBER> , <NUMBER> , [ x , y , <NUMBER> ] ) * matrix ) . tolist ( ) [ <NUMBER> ] [ : <NUMBER> ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def read_value ( self ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def Counter ( start = <NUMBER> , step = <NUMBER> , dtype = dtypes . int64 ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( <STRING> ) : <NEWLINE> <TAB> start = ops . convert_to_tensor ( start , dtype = dtype , name = <STRING> ) <NEWLINE> step = ops . convert_to_tensor ( step , dtype = dtype , name = <STRING> ) <NEWLINE> return dataset_ops . Dataset . from_tensors ( <NUMBER> ) . repeat ( None ) . apply ( <NEWLINE> scan_ops . scan ( start , lambda state , _ : ( state + step , state ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_frame ( self , index = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> from pandas import DataFrame <NEWLINE> result = DataFrame ( { ( name or level ) : <NEWLINE> self . _get_level_values ( level ) <NEWLINE> for name , level in <NEWLINE> zip ( self . names , range ( len ( self . levels ) ) ) } , <NEWLINE> copy = False ) <NEWLINE> if index : <NEWLINE> <TAB> result . index = self <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def reorder_limit ( expr , x , y ) : <NEWLINE> <TAB> <NEWLINE> var = { limit [ <NUMBER> ] for limit in expr . limits } <NEWLINE> limit_x = expr . limits [ x ] <NEWLINE> limit_y = expr . limits [ y ] <NEWLINE> <NEWLINE> if ( len ( set ( limit_x [ <NUMBER> ] . free_symbols ) . intersection ( var ) ) == <NUMBER> and <NEWLINE> len ( set ( limit_x [ <NUMBER> ] . free_symbols ) . intersection ( var ) ) == <NUMBER> and <NEWLINE> len ( set ( limit_y [ <NUMBER> ] . free_symbols ) . intersection ( var ) ) == <NUMBER> and <NEWLINE> len ( set ( limit_y [ <NUMBER> ] . free_symbols ) . intersection ( var ) ) == <NUMBER> ) : <NEWLINE> <NEWLINE> <TAB> limits = [ ] <NEWLINE> for i , limit in enumerate ( expr . limits ) : <NEWLINE> <TAB> if i == x : <NEWLINE> <TAB> limits . append ( limit_y ) <NEWLINE> <UNTAB> elif i == y : <NEWLINE> <TAB> limits . append ( limit_x ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> limits . append ( limit ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return type ( expr ) ( expr . function , * limits ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ReorderError ( expr , <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _check_params ( X , metric , p , metric_params ) : <NEWLINE> <TAB> <NEWLINE> params = zip ( [ <STRING> , <STRING> , <STRING> ] , <NEWLINE> [ metric , p , metric_params ] ) <NEWLINE> est_params = X . get_params ( ) <NEWLINE> for param_name , func_param in params : <NEWLINE> <TAB> if func_param != est_params [ param_name ] : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ( <NEWLINE> func_param , param_name , est_params [ param_name ] ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def asarray ( obj , itemsize = None , unicode = None , order = None ) : <NEWLINE> <TAB> <NEWLINE> return array ( obj , itemsize , copy = False , <NEWLINE> unicode = unicode , order = order ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_string_like ( obj ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return isinstance ( obj , ( text_type , string_types ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , seed , salt ) : <NEWLINE> <TAB> <NEWLINE> self . _seed = seed . original_seed if isinstance ( seed , SeedStream ) else seed <NEWLINE> self . _salt = salt <NEWLINE> self . _counter = <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def jet ( ) : <NEWLINE> <TAB> <NEWLINE> set_cmap ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def hermmul ( c1 , c2 ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> [ c1 , c2 ] = pu . as_series ( [ c1 , c2 ] ) <NEWLINE> <NEWLINE> if len ( c1 ) > len ( c2 ) : <NEWLINE> <TAB> c = c2 <NEWLINE> xs = c1 <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> c = c1 <NEWLINE> xs = c2 <NEWLINE> <NEWLINE> <UNTAB> if len ( c ) == <NUMBER> : <NEWLINE> <TAB> c0 = c [ <NUMBER> ] * xs <NEWLINE> c1 = <NUMBER> <NEWLINE> <UNTAB> elif len ( c ) == <NUMBER> : <NEWLINE> <TAB> c0 = c [ <NUMBER> ] * xs <NEWLINE> c1 = c [ <NUMBER> ] * xs <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nd = len ( c ) <NEWLINE> c0 = c [ - <NUMBER> ] * xs <NEWLINE> c1 = c [ - <NUMBER> ] * xs <NEWLINE> for i in range ( <NUMBER> , len ( c ) + <NUMBER> ) : <NEWLINE> <TAB> tmp = c0 <NEWLINE> nd = nd - <NUMBER> <NEWLINE> c0 = hermsub ( c [ - i ] * xs , c1 * ( <NUMBER> * ( nd - <NUMBER> ) ) ) <NEWLINE> c1 = hermadd ( tmp , hermmulx ( c1 ) * <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> return hermadd ( c0 , hermmulx ( c1 ) * <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _expr_small_minus ( cls , x ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def assert_element_shape ( expected_shapes ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def _merge_output_shapes ( original_shapes , expected_shapes ) : <NEWLINE> <TAB> flat_original_shapes = nest . flatten ( original_shapes ) <NEWLINE> flat_new_shapes = nest . flatten_up_to ( original_shapes , expected_shapes ) <NEWLINE> flat_merged_output_shapes = [ <NEWLINE> original_shape . merge_with ( new_shape ) <NEWLINE> for original_shape , new_shape in zip ( flat_original_shapes , <NEWLINE> flat_new_shapes ) ] <NEWLINE> return nest . pack_sequence_as ( original_shapes , flat_merged_output_shapes ) <NEWLINE> <NEWLINE> <UNTAB> def _check_shape ( * elements ) : <NEWLINE> <TAB> flatten_tensors = nest . flatten ( elements ) <NEWLINE> flatten_shapes = nest . flatten ( expected_shapes ) <NEWLINE> checked_tensors = [ <NEWLINE> with_shape ( shape , tensor ) if shape else tensor <NEWLINE> for shape , tensor in zip ( flatten_shapes , flatten_tensors ) <NEWLINE> ] <NEWLINE> return nest . pack_sequence_as ( elements , checked_tensors ) <NEWLINE> <NEWLINE> <UNTAB> def _apply_fn ( dataset ) : <NEWLINE> <TAB> output_shapes = _merge_output_shapes ( dataset . output_shapes , <NEWLINE> expected_shapes ) <NEWLINE> <NEWLINE> return batching . _RestructuredDataset ( <NEWLINE> dataset . map ( _check_shape ) , <NEWLINE> dataset . output_types , <NEWLINE> output_shapes = output_shapes , <NEWLINE> output_classes = dataset . output_classes ) <NEWLINE> <NEWLINE> <UNTAB> return _apply_fn <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def add_move ( move ) : <NEWLINE> <TAB> <NEWLINE> setattr ( _MovedItems , move . name , move ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def intersect_all ( self , other , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return CompoundSelect . _create_intersect_all ( self , other , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_joinstyle ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _joinstyle <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def Or ( * args ) : <NEWLINE> <TAB> <NEWLINE> def reduce_or ( cmp_intervala , cmp_intervalb ) : <NEWLINE> <TAB> if cmp_intervala [ <NUMBER> ] is True or cmp_intervalb [ <NUMBER> ] is True : <NEWLINE> <TAB> first = True <NEWLINE> <UNTAB> elif cmp_intervala [ <NUMBER> ] is None or cmp_intervalb [ <NUMBER> ] is None : <NEWLINE> <TAB> first = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> first = False <NEWLINE> <NEWLINE> <UNTAB> if cmp_intervala [ <NUMBER> ] is True or cmp_intervalb [ <NUMBER> ] is True : <NEWLINE> <TAB> second = True <NEWLINE> <UNTAB> elif cmp_intervala [ <NUMBER> ] is None or cmp_intervalb [ <NUMBER> ] is None : <NEWLINE> <TAB> second = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> second = False <NEWLINE> <UNTAB> return ( first , second ) <NEWLINE> <UNTAB> return reduce ( reduce_or , args ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def transpose ( x ) : <NEWLINE> <TAB> <NEWLINE> return array_ops . transpose ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ docstring . dedent_interpd <NEWLINE> def legend ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> handles , labels , extra_args , kwargs = mlegend . _parse_legend_args ( <NEWLINE> [ self ] , <NEWLINE> * args , <NEWLINE> ** kwargs ) <NEWLINE> if len ( extra_args ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> self . legend_ = mlegend . Legend ( self , handles , labels , ** kwargs ) <NEWLINE> self . legend_ . _remove_method = self . _remove_legend <NEWLINE> return self . legend_ <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def hex_str ( an_int ) : <NEWLINE> <TAB> <NEWLINE> return <STRING> . format ( an_int ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def clear ( ) : <NEWLINE> <TAB> <NEWLINE> with FileWriterCache . _lock : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> for item in FileWriterCache . _cache . values ( ) : <NEWLINE> <TAB> item . close ( ) <NEWLINE> <UNTAB> FileWriterCache . _cache = { } <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_flinalg_funcs ( names , arrays = ( ) , debug = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> ordering = [ ] <NEWLINE> for i in range ( len ( arrays ) ) : <NEWLINE> <TAB> t = arrays [ i ] . dtype . char <NEWLINE> if t not in _type_conv : <NEWLINE> <TAB> t = <STRING> <NEWLINE> <UNTAB> ordering . append ( ( t , i ) ) <NEWLINE> <UNTAB> if ordering : <NEWLINE> <TAB> ordering . sort ( ) <NEWLINE> required_prefix = _type_conv [ ordering [ <NUMBER> ] [ <NUMBER> ] ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> required_prefix = <STRING> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if ordering and has_column_major_storage ( arrays [ ordering [ <NUMBER> ] [ <NUMBER> ] ] ) : <NEWLINE> <TAB> suffix1 , suffix2 = <STRING> , <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> suffix1 , suffix2 = <STRING> , <STRING> <NEWLINE> <NEWLINE> <UNTAB> funcs = [ ] <NEWLINE> for name in names : <NEWLINE> <TAB> func_name = required_prefix + name <NEWLINE> func = getattr ( _flinalg , func_name + suffix1 , <NEWLINE> getattr ( _flinalg , func_name + suffix2 , None ) ) <NEWLINE> funcs . append ( func ) <NEWLINE> <UNTAB> return tuple ( funcs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def compare_and_bitpack_eager_fallback ( input , threshold , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ input , threshold ] , _ctx ) <NEWLINE> ( input , threshold ) = _inputs_T <NEWLINE> _inputs_flat = [ input , threshold ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def msvc_version ( compiler ) : <NEWLINE> <TAB> <NEWLINE> if not compiler . compiler_type == <STRING> : <NEWLINE> <TAB> raise ValueError ( <STRING> % compiler . compiler_type ) <NEWLINE> <UNTAB> return compiler . _MSVCCompiler__version <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def keys ( self ) : <NEWLINE> <TAB> <NEWLINE> return [ n . _v_pathname for n in self . groups ( ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ abc . abstractmethod <NEWLINE> def _evaluate ( self ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _process_limits ( * symbols ) : <NEWLINE> <TAB> <NEWLINE> limits = [ ] <NEWLINE> orientation = <NUMBER> <NEWLINE> for V in symbols : <NEWLINE> <TAB> if isinstance ( V , ( Relational , BooleanFunction ) ) : <NEWLINE> <TAB> variable = V . atoms ( Symbol ) . pop ( ) <NEWLINE> V = ( variable , V . as_set ( ) ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( V , Symbol ) or getattr ( V , <STRING> , False ) : <NEWLINE> <TAB> if isinstance ( V , Idx ) : <NEWLINE> <TAB> if V . lower is None or V . upper is None : <NEWLINE> <TAB> limits . append ( Tuple ( V ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> limits . append ( Tuple ( V , V . lower , V . upper ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> limits . append ( Tuple ( V ) ) <NEWLINE> <UNTAB> continue <NEWLINE> <UNTAB> elif is_sequence ( V , Tuple ) : <NEWLINE> <TAB> V = sympify ( flatten ( V ) ) <NEWLINE> if isinstance ( V [ <NUMBER> ] , ( Symbol , Idx ) ) or getattr ( V [ <NUMBER> ] , <STRING> , False ) : <NEWLINE> <TAB> newsymbol = V [ <NUMBER> ] <NEWLINE> if len ( V ) == <NUMBER> and isinstance ( V [ <NUMBER> ] , Interval ) : <NEWLINE> <TAB> V [ <NUMBER> : ] = [ V [ <NUMBER> ] . start , V [ <NUMBER> ] . end ] <NEWLINE> <NEWLINE> <UNTAB> if len ( V ) == <NUMBER> : <NEWLINE> <TAB> if V [ <NUMBER> ] is None and V [ <NUMBER> ] is not None : <NEWLINE> <TAB> nlim = [ V [ <NUMBER> ] ] <NEWLINE> <UNTAB> elif V [ <NUMBER> ] is not None and V [ <NUMBER> ] is None : <NEWLINE> <TAB> orientation *= - <NUMBER> <NEWLINE> nlim = [ V [ <NUMBER> ] ] <NEWLINE> <UNTAB> elif V [ <NUMBER> ] is None and V [ <NUMBER> ] is None : <NEWLINE> <TAB> nlim = [ ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nlim = V [ <NUMBER> : ] <NEWLINE> <UNTAB> limits . append ( Tuple ( newsymbol , * nlim ) ) <NEWLINE> if isinstance ( V [ <NUMBER> ] , Idx ) : <NEWLINE> <TAB> if V [ <NUMBER> ] . lower is not None and not bool ( nlim [ <NUMBER> ] >= V [ <NUMBER> ] . lower ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if V [ <NUMBER> ] . upper is not None and not bool ( nlim [ <NUMBER> ] <= V [ <NUMBER> ] . upper ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> continue <NEWLINE> <UNTAB> elif len ( V ) == <NUMBER> or ( len ( V ) == <NUMBER> and V [ <NUMBER> ] is None ) : <NEWLINE> <TAB> limits . append ( Tuple ( newsymbol ) ) <NEWLINE> continue <NEWLINE> <UNTAB> elif len ( V ) == <NUMBER> : <NEWLINE> <TAB> limits . append ( Tuple ( newsymbol , V [ <NUMBER> ] ) ) <NEWLINE> continue <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> raise ValueError ( <STRING> % str ( symbols ) ) <NEWLINE> <NEWLINE> <UNTAB> return limits , orientation <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def reverse_order ( expr , * indices ) : <NEWLINE> <TAB> <NEWLINE> l_indices = list ( indices ) <NEWLINE> <NEWLINE> for i , indx in enumerate ( l_indices ) : <NEWLINE> <TAB> if not isinstance ( indx , int ) : <NEWLINE> <TAB> l_indices [ i ] = expr . index ( indx ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> e = <NUMBER> <NEWLINE> limits = [ ] <NEWLINE> for i , limit in enumerate ( expr . limits ) : <NEWLINE> <TAB> l = limit <NEWLINE> if i in l_indices : <NEWLINE> <TAB> e = - e <NEWLINE> l = ( limit [ <NUMBER> ] , limit [ <NUMBER> ] + <NUMBER> , limit [ <NUMBER> ] - <NUMBER> ) <NEWLINE> <UNTAB> limits . append ( l ) <NEWLINE> <NEWLINE> <UNTAB> return Product ( expr . function ** e , * limits ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def remove ( target , identifier , fn ) : <NEWLINE> <TAB> <NEWLINE> _event_key ( target , identifier , fn ) . remove ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _inv_z ( self , z ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( <STRING> , values = [ z ] ) : <NEWLINE> <TAB> return z * self . scale + self . loc <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _ixs ( self , i , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> ax = self . _get_axis ( axis ) <NEWLINE> key = ax [ i ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if not ( isinstance ( ax , MultiIndex ) and isinstance ( key , tuple ) ) : <NEWLINE> <TAB> if is_list_like ( key ) : <NEWLINE> <TAB> indexer = { self . _get_axis_name ( axis ) : key } <NEWLINE> return self . reindex ( ** indexer ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if axis == <NUMBER> : <NEWLINE> <TAB> values = self . _data . iget ( i ) <NEWLINE> return self . _box_item_values ( key , values ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . _consolidate_inplace ( ) <NEWLINE> new_data = self . _data . xs ( i , axis = axis , copy = True , takeable = True ) <NEWLINE> return self . _construct_return_type ( new_data ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def inv ( A ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not scipy . sparse . isspmatrix ( A ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> I = speye ( A . shape [ <NUMBER> ] , A . shape [ <NUMBER> ] , dtype = A . dtype , format = A . format ) <NEWLINE> Ainv = spsolve ( A , I ) <NEWLINE> return Ainv <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def legend_elements ( self , variable_name = <STRING> , str_format = str ) : <NEWLINE> <TAB> <NEWLINE> artists = [ ] <NEWLINE> labels = [ ] <NEWLINE> <NEWLINE> if self . filled : <NEWLINE> <TAB> lowers , uppers = self . _get_lowers_and_uppers ( ) <NEWLINE> n_levels = len ( self . collections ) <NEWLINE> <NEWLINE> for i , ( collection , lower , upper ) in enumerate ( <NEWLINE> zip ( self . collections , lowers , uppers ) ) : <NEWLINE> <TAB> patch = mpatches . Rectangle ( <NEWLINE> ( <NUMBER> , <NUMBER> ) , <NUMBER> , <NUMBER> , <NEWLINE> facecolor = collection . get_facecolor ( ) [ <NUMBER> ] , <NEWLINE> hatch = collection . get_hatch ( ) , <NEWLINE> alpha = collection . get_alpha ( ) ) <NEWLINE> artists . append ( patch ) <NEWLINE> <NEWLINE> lower = str_format ( lower ) <NEWLINE> upper = str_format ( upper ) <NEWLINE> <NEWLINE> if i == <NUMBER> and self . extend in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> labels . append ( <STRING> % ( variable_name , <NEWLINE> lower ) ) <NEWLINE> <UNTAB> elif i == n_levels - <NUMBER> and self . extend in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> labels . append ( <STRING> % ( variable_name , <NEWLINE> upper ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> labels . append ( <STRING> % ( lower , <NEWLINE> variable_name , <NEWLINE> upper ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for collection , level in zip ( self . collections , self . levels ) : <NEWLINE> <NEWLINE> <TAB> patch = mcoll . LineCollection ( None ) <NEWLINE> patch . update_from ( collection ) <NEWLINE> <NEWLINE> artists . append ( patch ) <NEWLINE> <NEWLINE> level = str_format ( level ) <NEWLINE> labels . append ( <STRING> % ( variable_name , level ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return artists , labels <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def tile ( input , multiples , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , multiples = multiples , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , input , multiples ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return tile_eager_fallback ( <NEWLINE> input , multiples , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def compute_leading_term ( self , x , logx = None ) : <NEWLINE> <TAB> <NEWLINE> from sympy import Dummy , log <NEWLINE> from sympy . series . gruntz import calculate_series <NEWLINE> <NEWLINE> if self . removeO ( ) == <NUMBER> : <NEWLINE> <TAB> return self <NEWLINE> <NEWLINE> <UNTAB> if logx is None : <NEWLINE> <TAB> d = Dummy ( <STRING> ) <NEWLINE> s = calculate_series ( self , x , d ) . subs ( d , log ( x ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> s = calculate_series ( self , x , logx ) <NEWLINE> <NEWLINE> <UNTAB> return s . as_leading_term ( x ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def rank ( input , name = None ) : <NEWLINE> <NEWLINE> <TAB> <NEWLINE> return rank_internal ( input , name , optimize = True ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def tril_indices_from ( arr , k = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if arr . ndim != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return tril_indices ( arr . shape [ - <NUMBER> ] , k = k , m = arr . shape [ - <NUMBER> ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tc . returns ( LabeledTensor , LabeledTensor , Axes ) <NEWLINE> @ tc . accepts ( LabeledTensorLike , LabeledTensorLike , tc . Optional ( string_types ) ) <NEWLINE> def align ( labeled_tensor_0 , labeled_tensor_1 , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , <NEWLINE> [ labeled_tensor_0 , labeled_tensor_1 ] ) as scope : <NEWLINE> <NEWLINE> <TAB> labeled_tensor_0 = convert_to_labeled_tensor ( labeled_tensor_0 ) <NEWLINE> labeled_tensor_1 = convert_to_labeled_tensor ( labeled_tensor_1 ) <NEWLINE> <NEWLINE> axes_0 = labeled_tensor_0 . axes <NEWLINE> axes_1 = labeled_tensor_1 . axes <NEWLINE> for axis_name in axes_0 : <NEWLINE> <TAB> if axis_name in axes_1 : <NEWLINE> <TAB> if axes_0 [ axis_name ] != axes_1 [ axis_name ] : <NEWLINE> <TAB> raise ValueError ( <STRING> % <NEWLINE> ( axis_name , axes_0 [ axis_name ] , axes_1 [ axis_name ] ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> axis_scope_order = get_axis_order ( ) <NEWLINE> if axis_scope_order is not None : <NEWLINE> <NEWLINE> <TAB> axis_names_set = set ( axes_0 ) | set ( axes_1 ) <NEWLINE> new_axis_names = [ a for a in axis_scope_order if a in axis_names_set ] <NEWLINE> <NEWLINE> check_axis_order ( labeled_tensor_0 , axis_scope_order ) <NEWLINE> check_axis_order ( labeled_tensor_1 , axis_scope_order ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> new_axis_names = _find_consistent_ordering ( list ( axes_0 ) , list ( axes_1 ) ) <NEWLINE> if new_axis_names is None : <NEWLINE> <TAB> raise AxisOrderError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % <NEWLINE> ( axes_0 . keys ( ) , axes_1 . keys ( ) ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> labeled_tensor_0 = expand_dims ( <NEWLINE> labeled_tensor_0 , new_axis_names , name = scope + <STRING> ) <NEWLINE> labeled_tensor_1 = expand_dims ( <NEWLINE> labeled_tensor_1 , new_axis_names , name = scope + <STRING> ) <NEWLINE> <NEWLINE> broadcast_axes = [ ] <NEWLINE> for axis_name in new_axis_names : <NEWLINE> <TAB> if axis_name in axes_0 : <NEWLINE> <TAB> broadcast_axes . append ( axes_0 [ axis_name ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> broadcast_axes . append ( axes_1 [ axis_name ] ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return labeled_tensor_0 , labeled_tensor_1 , Axes ( broadcast_axes ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _mul ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def encode_data ( self , data , attributes ) : <NEWLINE> <TAB> <NEWLINE> current_row = <NUMBER> <NEWLINE> <NEWLINE> for inst in data : <NEWLINE> <TAB> if len ( inst ) != len ( attributes ) : <NEWLINE> <TAB> raise BadObject ( <NEWLINE> <STRING> % <NEWLINE> ( current_row , len ( inst ) , len ( attributes ) ) <NEWLINE> ) <NEWLINE> <NEWLINE> <UNTAB> new_data = [ ] <NEWLINE> for value in inst : <NEWLINE> <TAB> if value is None or value == <STRING> or value != value : <NEWLINE> <TAB> s = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> s = encode_string ( unicode ( value ) ) <NEWLINE> <UNTAB> new_data . append ( s ) <NEWLINE> <NEWLINE> <UNTAB> current_row += <NUMBER> <NEWLINE> yield <STRING> . join ( new_data ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _line_profile_coordinates ( src , dst , linewidth = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> src_row , src_col = src = np . asarray ( src , dtype = float ) <NEWLINE> dst_row , dst_col = dst = np . asarray ( dst , dtype = float ) <NEWLINE> d_row , d_col = dst - src <NEWLINE> theta = np . arctan2 ( d_row , d_col ) <NEWLINE> <NEWLINE> length = np . ceil ( np . hypot ( d_row , d_col ) + <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> line_col = np . linspace ( src_col , dst_col , length ) <NEWLINE> line_row = np . linspace ( src_row , dst_row , length ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> col_width = ( linewidth - <NUMBER> ) * np . sin ( - theta ) / <NUMBER> <NEWLINE> row_width = ( linewidth - <NUMBER> ) * np . cos ( theta ) / <NUMBER> <NEWLINE> perp_rows = np . array ( [ np . linspace ( row_i - row_width , row_i + row_width , <NEWLINE> linewidth ) for row_i in line_row ] ) <NEWLINE> perp_cols = np . array ( [ np . linspace ( col_i - col_width , col_i + col_width , <NEWLINE> linewidth ) for col_i in line_col ] ) <NEWLINE> return np . array ( [ perp_rows , perp_cols ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def sift ( seq , keyfunc , binary = False ) : <NEWLINE> <TAB> <NEWLINE> if not binary : <NEWLINE> <TAB> m = defaultdict ( list ) <NEWLINE> for i in seq : <NEWLINE> <TAB> m [ keyfunc ( i ) ] . append ( i ) <NEWLINE> <UNTAB> return m <NEWLINE> <UNTAB> sift = F , T = [ ] , [ ] <NEWLINE> for i in seq : <NEWLINE> <TAB> try : <NEWLINE> <TAB> sift [ keyfunc ( i ) ] . append ( i ) <NEWLINE> <UNTAB> except ( IndexError , TypeError ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> return T , F <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def update ( self , checkpoint_path , eval_result ) : <NEWLINE> <TAB> <NEWLINE> if not checkpoint_path : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if eval_result is None : <NEWLINE> <TAB> raise ValueError ( <STRING> , checkpoint_path ) <NEWLINE> <NEWLINE> <UNTAB> if ( self . _best_eval_result is None or <NEWLINE> self . _compare_fn ( self . _best_eval_result , eval_result ) ) : <NEWLINE> <TAB> self . _best_eval_result = eval_result <NEWLINE> return checkpoint_path , eval_result <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return <STRING> , None <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _disabled ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> raise TypeError ( <STRING> % <NEWLINE> self . __class__ ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _set_parent ( self , parent ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def invert ( self , a , b ) : <NEWLINE> <TAB> <NEWLINE> s , t , h = self . gcdex ( a , b ) <NEWLINE> <NEWLINE> if self . is_one ( h ) : <NEWLINE> <TAB> return s % b <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise NotInvertible ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def ks_twosamp ( data1 , data2 , alternative = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> ( data1 , data2 ) = ( ma . asarray ( data1 ) , ma . asarray ( data2 ) ) <NEWLINE> ( n1 , n2 ) = ( data1 . count ( ) , data2 . count ( ) ) <NEWLINE> n = ( n1 * n2 / float ( n1 + n2 ) ) <NEWLINE> mix = ma . concatenate ( ( data1 . compressed ( ) , data2 . compressed ( ) ) ) <NEWLINE> mixsort = mix . argsort ( kind = <STRING> ) <NEWLINE> csum = np . where ( mixsort < n1 , <NUMBER> / n1 , - <NUMBER> / n2 ) . cumsum ( ) <NEWLINE> <NEWLINE> if len ( np . unique ( mix ) ) < ( n1 + n2 ) : <NEWLINE> <TAB> csum = csum [ np . r_ [ np . diff ( mix [ mixsort ] ) . nonzero ( ) [ <NUMBER> ] , - <NUMBER> ] ] <NEWLINE> <NEWLINE> <UNTAB> alternative = str ( alternative ) . lower ( ) [ <NUMBER> ] <NEWLINE> if alternative == <STRING> : <NEWLINE> <TAB> d = ma . abs ( csum ) . max ( ) <NEWLINE> prob = special . kolmogorov ( np . sqrt ( n ) * d ) <NEWLINE> <UNTAB> elif alternative == <STRING> : <NEWLINE> <TAB> d = - csum . min ( ) <NEWLINE> prob = np . exp ( - <NUMBER> * n * d ** <NUMBER> ) <NEWLINE> <UNTAB> elif alternative == <STRING> : <NEWLINE> <TAB> d = csum . max ( ) <NEWLINE> prob = np . exp ( - <NUMBER> * n * d ** <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return ( d , prob ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def all_roots ( f , multiple = True , radicals = True ) : <NEWLINE> <TAB> <NEWLINE> roots = sympy . polys . rootoftools . CRootOf . all_roots ( f , radicals = radicals ) <NEWLINE> <NEWLINE> if multiple : <NEWLINE> <TAB> return roots <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return group ( roots , multiple = False ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def make_surface ( array ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( array , numpy_ndarray ) and array . dtype in numpy_floats : <NEWLINE> <TAB> array = array . round ( <NUMBER> ) . astype ( numpy_uint32 ) <NEWLINE> <UNTAB> return pix_make_surface ( array ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def main ( argv = None ) : <NEWLINE> <TAB> <NEWLINE> _test_util . InstallStackTraceHandler ( ) <NEWLINE> return _googletest . main ( argv ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dmp_mul_term ( f , c , i , u , K ) : <NEWLINE> <TAB> <NEWLINE> if not u : <NEWLINE> <TAB> return dup_mul_term ( f , c , i , K ) <NEWLINE> <NEWLINE> <UNTAB> v = u - <NUMBER> <NEWLINE> <NEWLINE> if dmp_zero_p ( f , u ) : <NEWLINE> <TAB> return f <NEWLINE> <UNTAB> if dmp_zero_p ( c , v ) : <NEWLINE> <TAB> return dmp_zero ( u ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return [ dmp_mul ( cf , c , v , K ) for cf in f ] + dmp_zeros ( i , v , K ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_edgecolor ( self , c ) : <NEWLINE> <TAB> <NEWLINE> self . _original_edgecolor = c <NEWLINE> self . _set_edgecolor ( c ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def fft ( a , n = None , axis = - <NUMBER> , norm = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> a = asarray ( a ) . astype ( complex , copy = False ) <NEWLINE> if n is None : <NEWLINE> <TAB> n = a . shape [ axis ] <NEWLINE> <UNTAB> output = _raw_fft ( a , n , axis , fftpack . cffti , fftpack . cfftf , _fft_cache ) <NEWLINE> if _unitary ( norm ) : <NEWLINE> <TAB> output *= <NUMBER> / sqrt ( n ) <NEWLINE> <UNTAB> return output <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _set_default ( self , value ) : <NEWLINE> <TAB> <NEWLINE> self . default_unparsed = value <NEWLINE> if value is None : <NEWLINE> <TAB> self . default = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . default = self . _parse ( value ) <NEWLINE> <UNTAB> self . default_as_str = self . _get_parsed_value_as_string ( self . default ) <NEWLINE> if self . using_default_value : <NEWLINE> <TAB> self . value = self . default <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_snap ( self ) : <NEWLINE> <TAB> <NEWLINE> if rcParams [ <STRING> ] : <NEWLINE> <TAB> return self . _snap <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_graph_from_inputs ( op_input_list , graph = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return ops . _get_graph_from_inputs ( op_input_list , graph ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def degree_list ( f ) : <NEWLINE> <TAB> <NEWLINE> return dmp_degree_list ( f . rep , f . lev ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def trim_zeros ( filt , trim = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> first = <NUMBER> <NEWLINE> trim = trim . upper ( ) <NEWLINE> if <STRING> in trim : <NEWLINE> <TAB> for i in filt : <NEWLINE> <TAB> if i != <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> first = first + <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> last = len ( filt ) <NEWLINE> if <STRING> in trim : <NEWLINE> <TAB> for i in filt [ : : - <NUMBER> ] : <NEWLINE> <TAB> if i != <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> last = last - <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return filt [ first : last ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def delete ( self , loc ) : <NEWLINE> <TAB> <NEWLINE> new_tds = np . delete ( self . asi8 , loc ) <NEWLINE> <NEWLINE> freq = <STRING> <NEWLINE> if is_integer ( loc ) : <NEWLINE> <TAB> if loc in ( <NUMBER> , - len ( self ) , - <NUMBER> , len ( self ) - <NUMBER> ) : <NEWLINE> <TAB> freq = self . freq <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if is_list_like ( loc ) : <NEWLINE> <TAB> loc = lib . maybe_indices_to_slice ( <NEWLINE> _ensure_int64 ( np . array ( loc ) ) , len ( self ) ) <NEWLINE> <UNTAB> if isinstance ( loc , slice ) and loc . step in ( <NUMBER> , None ) : <NEWLINE> <TAB> if ( loc . start in ( <NUMBER> , None ) or loc . stop in ( len ( self ) , None ) ) : <NEWLINE> <TAB> freq = self . freq <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return TimedeltaIndex ( new_tds , name = self . name , freq = freq ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __iter__ ( self ) : <NEWLINE> <TAB> <NEWLINE> while self . _read ( ) : <NEWLINE> <TAB> yield self . _output ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def remove ( self , key , where = None , start = None , stop = None ) : <NEWLINE> <TAB> <NEWLINE> where = _ensure_term ( where , scope_level = <NUMBER> ) <NEWLINE> try : <NEWLINE> <TAB> s = self . get_storer ( key ) <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <NEWLINE> <TAB> raise <NEWLINE> <UNTAB> except Exception : <NEWLINE> <NEWLINE> <TAB> if where is not None : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> s = self . get_node ( key ) <NEWLINE> if s is not None : <NEWLINE> <TAB> s . _f_remove ( recursive = True ) <NEWLINE> return None <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if com . _all_none ( where , start , stop ) : <NEWLINE> <TAB> s . group . _f_remove ( recursive = True ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if not s . is_table : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> return s . delete ( where = where , start = start , stop = stop ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_fonts ( ) : <NEWLINE> <TAB> <NEWLINE> if not Sysfonts : <NEWLINE> <TAB> initsysfonts ( ) <NEWLINE> <UNTAB> return list ( Sysfonts ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , node_def , op , message ) : <NEWLINE> <TAB> <NEWLINE> super ( PermissionDeniedError , self ) . __init__ ( node_def , op , message , <NEWLINE> PERMISSION_DENIED ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def with_rank ( self , rank ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return self . merge_with ( unknown_shape ( rank = rank ) ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( self , rank ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_ymajorticklabels ( self ) : <NEWLINE> <TAB> <NEWLINE> return cbook . silent_list ( <STRING> , <NEWLINE> self . yaxis . get_majorticklabels ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def retain_grad ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . grad_fn is None : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> if not self . requires_grad : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> if hasattr ( self , <STRING> ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> weak_self = weakref . ref ( self ) <NEWLINE> <NEWLINE> def retain_grad_hook ( grad ) : <NEWLINE> <TAB> var = weak_self ( ) <NEWLINE> if var is None : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> if var . _grad is None : <NEWLINE> <TAB> var . _grad = grad . clone ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> var . _grad = var . _grad + grad <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . register_hook ( retain_grad_hook ) <NEWLINE> self . retains_grad = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def to_vertex_cover ( G , matching , top_nodes = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> L , R = bipartite_sets ( G , top_nodes ) <NEWLINE> <NEWLINE> unmatched_vertices = set ( G ) - set ( matching ) <NEWLINE> U = unmatched_vertices & L <NEWLINE> <NEWLINE> <NEWLINE> Z = _connected_by_alternating_paths ( G , matching , U ) <NEWLINE> <NEWLINE> <NEWLINE> return ( L - Z ) | ( R & Z ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dup_laguerre ( n , alpha , K ) : <NEWLINE> <TAB> <NEWLINE> seq = [ [ K . zero ] , [ K . one ] ] <NEWLINE> <NEWLINE> for i in range ( <NUMBER> , n + <NUMBER> ) : <NEWLINE> <TAB> a = dup_mul ( seq [ - <NUMBER> ] , [ - K . one / i , alpha / i + K ( <NUMBER> * i - <NUMBER> ) / i ] , K ) <NEWLINE> b = dup_mul_ground ( seq [ - <NUMBER> ] , alpha / i + K ( i - <NUMBER> ) / i , K ) <NEWLINE> <NEWLINE> seq . append ( dup_sub ( a , b , K ) ) <NEWLINE> <NEWLINE> <UNTAB> return seq [ - <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rankdata ( data , axis = None , use_missing = False ) : <NEWLINE> <TAB> <NEWLINE> def _rank1d ( data , use_missing = False ) : <NEWLINE> <TAB> n = data . count ( ) <NEWLINE> rk = np . empty ( data . size , dtype = float ) <NEWLINE> idx = data . argsort ( ) <NEWLINE> rk [ idx [ : n ] ] = np . arange ( <NUMBER> , n + <NUMBER> ) <NEWLINE> <NEWLINE> if use_missing : <NEWLINE> <TAB> rk [ idx [ n : ] ] = ( n + <NUMBER> ) / <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rk [ idx [ n : ] ] = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> repeats = find_repeats ( data . copy ( ) ) <NEWLINE> for r in repeats [ <NUMBER> ] : <NEWLINE> <TAB> condition = ( data == r ) . filled ( False ) <NEWLINE> rk [ condition ] = rk [ condition ] . mean ( ) <NEWLINE> <UNTAB> return rk <NEWLINE> <NEWLINE> <UNTAB> data = ma . array ( data , copy = False ) <NEWLINE> if axis is None : <NEWLINE> <TAB> if data . ndim > <NUMBER> : <NEWLINE> <TAB> return _rank1d ( data . ravel ( ) , use_missing ) . reshape ( data . shape ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _rank1d ( data , use_missing ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return ma . apply_along_axis ( _rank1d , axis , data , use_missing ) . view ( ndarray ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def matvec ( self , v ) : <NEWLINE> <TAB> <NEWLINE> if self . collapsed is not None : <NEWLINE> <TAB> return np . dot ( self . collapsed , v ) <NEWLINE> <UNTAB> return LowRankMatrix . _matvec ( v , self . alpha , self . cs , self . ds ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def tsem ( a , limits = None , inclusive = ( True , True ) , axis = <NUMBER> , ddof = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> a = ma . asarray ( a ) . ravel ( ) <NEWLINE> if limits is None : <NEWLINE> <TAB> n = float ( a . count ( ) ) <NEWLINE> return a . std ( axis = axis , ddof = ddof ) / ma . sqrt ( n ) <NEWLINE> <NEWLINE> <UNTAB> am = trima ( a . ravel ( ) , limits , inclusive ) <NEWLINE> sd = np . sqrt ( am . var ( axis = axis , ddof = ddof ) ) <NEWLINE> return sd / np . sqrt ( am . count ( ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __add_client__ ( self , r , new_client ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> r . clients . append ( new_client ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ cbook . deprecated ( <STRING> , <STRING> ) <NEWLINE> def identity ( n , rank = <NUMBER> , dtype = <STRING> , typecode = None ) : <NEWLINE> <TAB> <NEWLINE> if typecode is not None : <NEWLINE> <TAB> dtype = typecode <NEWLINE> <UNTAB> iden = np . zeros ( ( n , ) * rank , dtype ) <NEWLINE> for i in range ( n ) : <NEWLINE> <TAB> idx = ( i , ) * rank <NEWLINE> iden [ idx ] = <NUMBER> <NEWLINE> <UNTAB> return iden <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def validate_path_exists ( s ) : <NEWLINE> <TAB> <NEWLINE> if s is None : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> if os . path . exists ( s ) : <NEWLINE> <TAB> return s <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise RuntimeError ( <STRING> % s ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def unique ( ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def _apply_fn ( dataset ) : <NEWLINE> <TAB> return _UniqueDataset ( dataset ) <NEWLINE> <NEWLINE> <UNTAB> return _apply_fn <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def binary_accuracy ( y , t ) : <NEWLINE> <TAB> <NEWLINE> return BinaryAccuracy ( ) ( y , t ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_xbound ( self , lower = None , upper = None ) : <NEWLINE> <TAB> <NEWLINE> if upper is None and iterable ( lower ) : <NEWLINE> <TAB> lower , upper = lower <NEWLINE> <NEWLINE> <UNTAB> old_lower , old_upper = self . get_xbound ( ) <NEWLINE> <NEWLINE> if lower is None : <NEWLINE> <TAB> lower = old_lower <NEWLINE> <UNTAB> if upper is None : <NEWLINE> <TAB> upper = old_upper <NEWLINE> <NEWLINE> <UNTAB> if self . xaxis_inverted ( ) : <NEWLINE> <TAB> if lower < upper : <NEWLINE> <TAB> self . set_xlim ( upper , lower , auto = None ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . set_xlim ( lower , upper , auto = None ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if lower < upper : <NEWLINE> <TAB> self . set_xlim ( lower , upper , auto = None ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . set_xlim ( upper , lower , auto = None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_default_session_config_distributed ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> rewrite_opts = rewriter_config_pb2 . RewriterConfig ( <NEWLINE> meta_optimizer_iterations = rewriter_config_pb2 . RewriterConfig . ONE ) <NEWLINE> graph_opts = config_pb2 . GraphOptions ( rewrite_options = rewrite_opts ) <NEWLINE> <NEWLINE> device_filters = None <NEWLINE> if self . _task_type == TaskType . MASTER : <NEWLINE> <TAB> device_filters = [ <STRING> , <STRING> ] <NEWLINE> <UNTAB> elif self . _task_type == TaskType . CHIEF : <NEWLINE> <TAB> device_filters = [ <STRING> , <STRING> ] <NEWLINE> <UNTAB> elif self . _task_type == TaskType . WORKER : <NEWLINE> <TAB> device_filters = [ <STRING> , <STRING> % self . _task_id ] <NEWLINE> <UNTAB> elif self . _task_type == TaskType . PS : <NEWLINE> <TAB> device_filters = [ <STRING> , <STRING> , <STRING> ] <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> return config_pb2 . ConfigProto ( <NEWLINE> allow_soft_placement = True , <NEWLINE> graph_options = graph_opts , <NEWLINE> device_filters = device_filters ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __sub__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( other , SeqBase ) : <NEWLINE> <TAB> raise TypeError ( <STRING> % type ( other ) ) <NEWLINE> <UNTAB> return SeqAdd ( self , - other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gen_even_slices ( n , n_packs , n_samples = None ) : <NEWLINE> <TAB> <NEWLINE> start = <NUMBER> <NEWLINE> if n_packs < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> % n_packs ) <NEWLINE> <UNTAB> for pack_num in range ( n_packs ) : <NEWLINE> <TAB> this_n = n // n_packs <NEWLINE> if pack_num < n % n_packs : <NEWLINE> <TAB> this_n += <NUMBER> <NEWLINE> <UNTAB> if this_n > <NUMBER> : <NEWLINE> <TAB> end = start + this_n <NEWLINE> if n_samples is not None : <NEWLINE> <TAB> end = min ( n_samples , end ) <NEWLINE> <UNTAB> yield slice ( start , end , None ) <NEWLINE> start = end <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def all ( self , axis = None , out = None ) : <NEWLINE> <TAB> <NEWLINE> return N . ndarray . all ( self , axis , out , keepdims = True ) . _collapse ( axis ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def binary_fill_holes ( input , structure = None , output = None , origin = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> mask = numpy . logical_not ( input ) <NEWLINE> tmp = numpy . zeros ( mask . shape , bool ) <NEWLINE> inplace = isinstance ( output , numpy . ndarray ) <NEWLINE> if inplace : <NEWLINE> <TAB> binary_dilation ( tmp , structure , - <NUMBER> , mask , output , <NUMBER> , origin ) <NEWLINE> numpy . logical_not ( output , output ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> output = binary_dilation ( tmp , structure , - <NUMBER> , mask , None , <NUMBER> , <NEWLINE> origin ) <NEWLINE> numpy . logical_not ( output , output ) <NEWLINE> return output <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def write ( self , arr ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> mat_tag_pos = self . file_stream . tell ( ) <NEWLINE> <NEWLINE> if scipy . sparse . issparse ( arr ) : <NEWLINE> <TAB> self . write_sparse ( arr ) <NEWLINE> self . update_matrix_tag ( mat_tag_pos ) <NEWLINE> return <NEWLINE> <NEWLINE> <UNTAB> narr = to_writeable ( arr ) <NEWLINE> if narr is None : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> % ( arr , type ( arr ) ) ) <NEWLINE> <UNTAB> if isinstance ( narr , MatlabObject ) : <NEWLINE> <TAB> self . write_object ( narr ) <NEWLINE> <UNTAB> elif isinstance ( narr , MatlabFunction ) : <NEWLINE> <TAB> raise MatWriteError ( <STRING> ) <NEWLINE> <UNTAB> elif narr is EmptyStructMarker : <NEWLINE> <TAB> self . write_empty_struct ( ) <NEWLINE> <UNTAB> elif narr . dtype . fields : <NEWLINE> <TAB> self . write_struct ( narr ) <NEWLINE> <UNTAB> elif narr . dtype . hasobject : <NEWLINE> <TAB> self . write_cells ( narr ) <NEWLINE> <UNTAB> elif narr . dtype . kind in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> if self . unicode_strings : <NEWLINE> <TAB> codec = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> codec = <STRING> <NEWLINE> <UNTAB> self . write_char ( narr , codec ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . write_numeric ( narr ) <NEWLINE> <UNTAB> self . update_matrix_tag ( mat_tag_pos ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def assertAllEqual ( self , a , b , msg = None ) : <NEWLINE> <TAB> <NEWLINE> msg = msg if msg else <STRING> <NEWLINE> a = self . _GetNdArray ( a ) <NEWLINE> b = self . _GetNdArray ( b ) <NEWLINE> <NEWLINE> if ( b . ndim <= <NUMBER> or b . size < <NUMBER> ) : <NEWLINE> <TAB> self . assertEqual ( <NEWLINE> a . shape , b . shape , <STRING> <NEWLINE> <STRING> % ( a . shape , b . shape , b , msg ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . assertEqual ( <NEWLINE> a . shape , b . shape , <STRING> <NEWLINE> <STRING> % ( a . shape , b . shape , msg ) ) <NEWLINE> <NEWLINE> <UNTAB> same = ( a == b ) <NEWLINE> <NEWLINE> if ( a . dtype in [ <NEWLINE> np . float16 , np . float32 , np . float64 , dtypes . bfloat16 . as_numpy_dtype <NEWLINE> ] ) : <NEWLINE> <TAB> same = np . logical_or ( same , np . logical_and ( np . isnan ( a ) , np . isnan ( b ) ) ) <NEWLINE> <UNTAB> msgs = [ msg ] <NEWLINE> if not np . all ( same ) : <NEWLINE> <NEWLINE> <TAB> diff = np . logical_not ( same ) <NEWLINE> if a . ndim : <NEWLINE> <TAB> x = a [ np . where ( diff ) ] <NEWLINE> y = b [ np . where ( diff ) ] <NEWLINE> msgs . append ( <STRING> . format ( np . where ( diff ) ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> x , y = a , b <NEWLINE> <UNTAB> msgs . append ( <STRING> . format ( x ) ) <NEWLINE> msgs . append ( <STRING> . format ( y ) ) <NEWLINE> np . testing . assert_array_equal ( a , b , err_msg = <STRING> . join ( msgs ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def encode ( a , encoding = None , errors = None ) : <NEWLINE> <TAB> <NEWLINE> return _to_string_or_unicode_array ( <NEWLINE> _vec_string ( a , object_ , <STRING> , _clean_args ( encoding , errors ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _my_principal_branch ( expr , period , full_pb = False ) : <NEWLINE> <TAB> <NEWLINE> from sympy import principal_branch <NEWLINE> res = principal_branch ( expr , period ) <NEWLINE> if not full_pb : <NEWLINE> <TAB> res = res . replace ( principal_branch , lambda x , y : x ) <NEWLINE> <UNTAB> return res <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def reshape ( self , * s , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> kwargs . update ( order = kwargs . get ( <STRING> , <STRING> ) ) <NEWLINE> result = self . _data . reshape ( * s , ** kwargs ) . view ( type ( self ) ) <NEWLINE> result . _update_from ( self ) <NEWLINE> mask = self . _mask <NEWLINE> if mask is not nomask : <NEWLINE> <TAB> result . _mask = mask . reshape ( * s , ** kwargs ) <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_label ( self , s ) : <NEWLINE> <TAB> <NEWLINE> if s is not None : <NEWLINE> <TAB> self . _label = <STRING> % ( s , ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _label = None <NEWLINE> <UNTAB> self . pchanged ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def lagrangian_hessian_s ( self , z , v ) : <NEWLINE> <TAB> <NEWLINE> s = self . get_slack ( z ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> primal = self . barrier_parameter <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> primal_dual = v [ - self . n_ineq : ] * s <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> return np . where ( v [ - self . n_ineq : ] > <NUMBER> , primal_dual , primal ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ constructor <NEWLINE> def min ( x , axis = None , keepdims = False ) : <NEWLINE> <TAB> <NEWLINE> x = as_tensor_variable ( x ) <NEWLINE> str_x_type = str ( x . dtype ) <NEWLINE> if str_x_type . startswith ( <STRING> ) or str_x_type in int_dtypes : <NEWLINE> <TAB> return - max ( - x , axis = axis , keepdims = keepdims ) <NEWLINE> <UNTAB> elif str_x_type in uint_dtypes : <NEWLINE> <TAB> itype = np . iinfo ( x . dtype ) <NEWLINE> max_val = np . array ( itype . max , dtype = itype . dtype ) <NEWLINE> return max_val - max ( max_val - x , axis = axis , keepdims = keepdims ) <NEWLINE> <UNTAB> elif str_x_type == <STRING> : <NEWLINE> <TAB> return ~ max ( ~ x , axis = axis , keepdims = keepdims ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fetch_variables ( self ) : <NEWLINE> <TAB> <NEWLINE> fgraph = self . fgraph <NEWLINE> self . inputs = fgraph . inputs <NEWLINE> self . outputs = fgraph . outputs <NEWLINE> <NEWLINE> self . node_order = self . schedule ( fgraph ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . variables = [ var for var in self . inputs if not len ( var . clients ) ] <NEWLINE> self . variables += graph . variables ( self . inputs , self . outputs ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . node_params = dict ( ) <NEWLINE> for node in self . node_order : <NEWLINE> <TAB> params = node . run_params ( ) <NEWLINE> if params is not graph . NoParams : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if params in self . node_params : <NEWLINE> <TAB> var = self . node_params [ params ] <NEWLINE> assert var . type == node . params_type <NEWLINE> var . clients . append ( ( node , <STRING> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> var = graph . Constant ( node . params_type , params ) <NEWLINE> var . clients = [ ( node , <STRING> ) ] <NEWLINE> self . node_params [ params ] = var <NEWLINE> self . variables . append ( var ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> self . orphans = list ( r for r in self . variables <NEWLINE> if isinstance ( r , graph . Constant ) and <NEWLINE> r not in self . inputs ) <NEWLINE> <NEWLINE> self . consts = [ ] <NEWLINE> <NEWLINE> for variable in self . orphans : <NEWLINE> <TAB> if isinstance ( variable , graph . Constant ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> variable . type . c_literal ( variable . data ) <NEWLINE> self . consts . append ( variable ) <NEWLINE> self . orphans . remove ( variable ) <NEWLINE> <UNTAB> except ( utils . MethodNotDefined , NotImplementedError ) : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> self . temps = list ( set ( self . variables ) . difference ( <NEWLINE> self . inputs ) . difference ( self . outputs ) . difference ( self . orphans ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def elu ( x , alpha = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return K . elu ( x , alpha ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def roots_jacobi ( n , alpha , beta , mu = False ) : <NEWLINE> <TAB> <NEWLINE> m = int ( n ) <NEWLINE> if n < <NUMBER> or n != m : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if alpha <= - <NUMBER> or beta <= - <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if alpha == <NUMBER> and beta == <NUMBER> : <NEWLINE> <TAB> return roots_legendre ( m , mu ) <NEWLINE> <UNTAB> if alpha == beta : <NEWLINE> <TAB> return roots_gegenbauer ( m , alpha + <NUMBER> , mu ) <NEWLINE> <NEWLINE> <UNTAB> mu0 = <NUMBER> ** ( alpha + beta + <NUMBER> ) * cephes . beta ( alpha + <NUMBER> , beta + <NUMBER> ) <NEWLINE> a = alpha <NEWLINE> b = beta <NEWLINE> if a + b == <NUMBER> : <NEWLINE> <TAB> an_func = lambda k : np . where ( k == <NUMBER> , ( b - a ) / ( <NUMBER> + a + b ) , <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> an_func = lambda k : np . where ( k == <NUMBER> , ( b - a ) / ( <NUMBER> + a + b ) , <NEWLINE> ( b * b - a * a ) / ( ( <NUMBER> * k + a + b ) * ( <NUMBER> * k + a + b + <NUMBER> ) ) ) <NEWLINE> <NEWLINE> <UNTAB> bn_func = lambda k : <NUMBER> / ( <NUMBER> * k + a + b ) * np . sqrt ( ( k + a ) * ( k + b ) / ( <NUMBER> * k + a + b + <NUMBER> ) ) * np . where ( k == <NUMBER> , <NUMBER> , np . sqrt ( k * ( k + a + b ) / ( <NUMBER> * k + a + b - <NUMBER> ) ) ) <NEWLINE> <NEWLINE> f = lambda n , x : cephes . eval_jacobi ( n , a , b , x ) <NEWLINE> df = lambda n , x : <NUMBER> * ( n + a + b + <NUMBER> ) * cephes . eval_jacobi ( n - <NUMBER> , a + <NUMBER> , b + <NUMBER> , x ) <NEWLINE> return _gen_roots_and_weights ( m , mu0 , an_func , bn_func , f , df , False , mu ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def random_state ( random_state_index ) : <NEWLINE> <TAB> <NEWLINE> @ decorator <NEWLINE> def _random_state ( func , * args , ** kwargs ) : <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> random_state_arg = args [ random_state_index ] <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <UNTAB> except IndexError : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> random_state = create_random_state ( random_state_arg ) <NEWLINE> <NEWLINE> <NEWLINE> new_args = list ( args ) <NEWLINE> new_args [ random_state_index ] = random_state <NEWLINE> return func ( * new_args , ** kwargs ) <NEWLINE> <UNTAB> return _random_state <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _init_data ( self , data , copy , dtype , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if data is None : <NEWLINE> <TAB> data = { } <NEWLINE> <UNTAB> if dtype is not None : <NEWLINE> <TAB> dtype = self . _validate_dtype ( dtype ) <NEWLINE> <NEWLINE> <UNTAB> passed_axes = [ kwargs . pop ( a , None ) for a in self . _AXIS_ORDERS ] <NEWLINE> <NEWLINE> if kwargs : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> . format ( list ( kwargs . keys ( ) ) [ <NUMBER> ] ) ) <NEWLINE> <NEWLINE> <UNTAB> axes = None <NEWLINE> if isinstance ( data , BlockManager ) : <NEWLINE> <TAB> if com . _any_not_none ( * passed_axes ) : <NEWLINE> <TAB> axes = [ x if x is not None else y <NEWLINE> for x , y in zip ( passed_axes , data . axes ) ] <NEWLINE> <UNTAB> mgr = data <NEWLINE> <UNTAB> elif isinstance ( data , dict ) : <NEWLINE> <TAB> mgr = self . _init_dict ( data , passed_axes , dtype = dtype ) <NEWLINE> copy = False <NEWLINE> dtype = None <NEWLINE> <UNTAB> elif isinstance ( data , ( np . ndarray , list ) ) : <NEWLINE> <TAB> mgr = self . _init_matrix ( data , passed_axes , dtype = dtype , copy = copy ) <NEWLINE> copy = False <NEWLINE> dtype = None <NEWLINE> <UNTAB> elif is_scalar ( data ) and com . _all_not_none ( * passed_axes ) : <NEWLINE> <TAB> values = cast_scalar_to_array ( [ len ( x ) for x in passed_axes ] , <NEWLINE> data , dtype = dtype ) <NEWLINE> mgr = self . _init_matrix ( values , passed_axes , dtype = values . dtype , <NEWLINE> copy = False ) <NEWLINE> copy = False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> NDFrame . __init__ ( self , mgr , axes = axes , copy = copy , dtype = dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _n2 ( a , b ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if a . is_comparable and b . is_comparable : <NEWLINE> <TAB> dif = ( a - b ) . evalf ( <NUMBER> ) <NEWLINE> if dif . is_comparable : <NEWLINE> <TAB> return dif <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def termwise ( f , func , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> terms = { } <NEWLINE> <NEWLINE> for monom , coeff in f . terms ( ) : <NEWLINE> <TAB> result = func ( monom , coeff ) <NEWLINE> <NEWLINE> if isinstance ( result , tuple ) : <NEWLINE> <TAB> monom , coeff = result <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> coeff = result <NEWLINE> <NEWLINE> <UNTAB> if coeff : <NEWLINE> <TAB> if monom not in terms : <NEWLINE> <TAB> terms [ monom ] = coeff <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise PolynomialError ( <NEWLINE> <STRING> % monom ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return f . from_dict ( terms , * ( gens or f . gens ) , ** args ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def unique_params ( self , * optionaldict , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return self . _params ( True , optionaldict , kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def get_data_files_path ( ) : <NEWLINE> <TAB> <NEWLINE> return _os . path . dirname ( _inspect . getfile ( _sys . _getframe ( <NUMBER> ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def characteristic ( self ) : <NEWLINE> <TAB> <NEWLINE> return <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def from_edgelist ( edgelist , create_using = None ) : <NEWLINE> <TAB> <NEWLINE> G = nx . empty_graph ( <NUMBER> , create_using ) <NEWLINE> G . add_edges_from ( edgelist ) <NEWLINE> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_hdf5 ( self , filename , datapath , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return to_hdf5 ( filename , datapath , self , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def as_text ( bytes_or_text , encoding = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( bytes_or_text , _six . text_type ) : <NEWLINE> <TAB> return bytes_or_text <NEWLINE> <UNTAB> elif isinstance ( bytes_or_text , bytes ) : <NEWLINE> <TAB> return bytes_or_text . decode ( encoding ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> % bytes_or_text ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def deprecate ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if args : <NEWLINE> <TAB> fn = args [ <NUMBER> ] <NEWLINE> args = args [ <NUMBER> : ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if <STRING> in kwargs : <NEWLINE> <TAB> kwargs [ <STRING> ] = kwargs . pop ( <STRING> ) <NEWLINE> <UNTAB> if <STRING> in kwargs : <NEWLINE> <TAB> kwargs [ <STRING> ] = kwargs . pop ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return _Deprecate ( * args , ** kwargs ) ( fn ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _Deprecate ( * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def apply ( self , fgraph ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def lecun_normal ( seed = None ) : <NEWLINE> <TAB> <NEWLINE> return VarianceScaling ( <NEWLINE> scale = <NUMBER> , mode = <STRING> , distribution = <STRING> , seed = seed ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def try_march_flag ( flags ) : <NEWLINE> <TAB> <NEWLINE> test_code = textwrap . dedent ( " " " \ 
                         # i n c l u d e   < c m a t h > 
                         u s i n g   n a m e s p a c e   s t d ; 
                         i n t   m a i n ( i n t   a r g c ,   c h a r * *   a r g v ) 
                         { 
                                 f l o a t   N x   =   - 1 . 3 7 8 7 7 0 6 6 4 1 ; 
                                 f l o a t   S x   =   2 5 . 0 ; 
                                 d o u b l e   r   =   N x   +   s q r t ( S x ) ; 
                                 i f   ( a b s ( r   -   3 . 6 2 1 2 2 9 )   >   0 . 0 1 ) 
                                 { 
                                         r e t u r n   - 1 ; 
                                 } 
                                 r e t u r n   0 ; 
                         } 
                         " " " ) <NEWLINE> <NEWLINE> cflags = flags + [ <STRING> + d for d in theano . gof . cmodule . std_lib_dirs ( ) ] <NEWLINE> compilation_result , execution_result = GCC_compiler . try_compile_tmp ( <NEWLINE> test_code , tmp_prefix = <STRING> , <NEWLINE> flags = cflags , try_run = True ) <NEWLINE> return compilation_result , execution_result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def read ( self , size = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if size < <NUMBER> and self . _offset : <NEWLINE> <TAB> size = self . _size <NEWLINE> <UNTAB> return self . _fh . read ( size ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_dpi_cor ( self , dpi_cor ) : <NEWLINE> <TAB> <NEWLINE> self . _dpi_cor = dpi_cor <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def arcsin ( x ) : <NEWLINE> <TAB> <NEWLINE> return Arcsin ( ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dup_reverse ( f ) : <NEWLINE> <TAB> <NEWLINE> return dup_strip ( list ( reversed ( f ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_color ( self , color ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> hash ( color ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> color = tuple ( color ) <NEWLINE> <UNTAB> self . _color = color <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def isin ( element , test_elements , assume_unique = False , invert = False ) : <NEWLINE> <TAB> <NEWLINE> element = ma . asarray ( element ) <NEWLINE> return in1d ( element , test_elements , assume_unique = assume_unique , <NEWLINE> invert = invert ) . reshape ( element . shape ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def get_cifar100 ( withlabel = True , ndim = <NUMBER> , scale = <NUMBER> , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> return _get_cifar ( <STRING> , withlabel , ndim , scale , dtype ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def house_x_graph ( create_using = None ) : <NEWLINE> <TAB> <NEWLINE> description = [ <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <NUMBER> , <NEWLINE> [ [ <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] ] <NEWLINE> ] <NEWLINE> G = make_small_undirected_graph ( description , create_using ) <NEWLINE> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _array_of_arrays ( list_of_arrays ) : <NEWLINE> <TAB> <NEWLINE> out = np . empty ( len ( list_of_arrays ) , dtype = object ) <NEWLINE> out [ : ] = list_of_arrays <NEWLINE> return out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def all_monoms ( f ) : <NEWLINE> <TAB> <NEWLINE> return f . rep . all_monoms ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def from_engine ( cls , bind ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( bind . dialect , <STRING> ) : <NEWLINE> <TAB> return bind . dialect . inspector ( bind ) <NEWLINE> <UNTAB> return Inspector ( bind ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def cumsum ( self , axis = <NUMBER> , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> nv . validate_cumsum ( args , kwargs ) <NEWLINE> if axis is not None : <NEWLINE> <TAB> axis = self . _get_axis_number ( axis ) <NEWLINE> <NEWLINE> <UNTAB> new_array = self . values . cumsum ( ) <NEWLINE> <NEWLINE> return self . _constructor ( <NEWLINE> new_array , index = self . index , <NEWLINE> sparse_index = new_array . sp_index ) . __finalize__ ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _cut ( self , node ) : <NEWLINE> <TAB> <NEWLINE> prev = node . prev <NEWLINE> next = node . next <NEWLINE> if prev is not None : <NEWLINE> <TAB> prev . next = next <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> node . parent . left = next <NEWLINE> <UNTAB> node . prev = None <NEWLINE> if next is not None : <NEWLINE> <TAB> next . prev = prev <NEWLINE> node . next = None <NEWLINE> <UNTAB> node . parent = None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_ZZ_gmpy ( K1 , a , K0 ) : <NEWLINE> <TAB> <NEWLINE> return PythonRational ( PythonInteger ( a ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def scatter_add_ndim ( input , indices , deltas , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , indices = indices , deltas = deltas , <NEWLINE> name = name ) <NEWLINE> return _op <NEWLINE> _result = None <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def generate_blob ( self , gso_table ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> bio = BytesIO ( ) <NEWLINE> gso = _bytes ( <STRING> , <STRING> ) <NEWLINE> gso_type = struct . pack ( self . _byteorder + <STRING> , <NUMBER> ) <NEWLINE> null = struct . pack ( self . _byteorder + <STRING> , <NUMBER> ) <NEWLINE> v_type = self . _byteorder + self . _gso_v_type <NEWLINE> o_type = self . _byteorder + self . _gso_o_type <NEWLINE> len_type = self . _byteorder + <STRING> <NEWLINE> for strl , vo in gso_table . items ( ) : <NEWLINE> <TAB> if vo == ( <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> v , o = vo <NEWLINE> <NEWLINE> <NEWLINE> bio . write ( gso ) <NEWLINE> <NEWLINE> <NEWLINE> bio . write ( struct . pack ( v_type , v ) ) <NEWLINE> <NEWLINE> <NEWLINE> bio . write ( struct . pack ( o_type , o ) ) <NEWLINE> <NEWLINE> <NEWLINE> bio . write ( gso_type ) <NEWLINE> <NEWLINE> <NEWLINE> encoded = self . _encode ( strl ) <NEWLINE> bio . write ( struct . pack ( len_type , len ( encoded ) + <NUMBER> ) ) <NEWLINE> <NEWLINE> <NEWLINE> s = _bytes ( strl , <STRING> ) <NEWLINE> bio . write ( s ) <NEWLINE> bio . write ( null ) <NEWLINE> <NEWLINE> <UNTAB> bio . seek ( <NUMBER> ) <NEWLINE> return bio . read ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def completeness_score ( labels_true , labels_pred ) : <NEWLINE> <TAB> <NEWLINE> return homogeneity_completeness_v_measure ( labels_true , labels_pred ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def close ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . zip is not None : <NEWLINE> <TAB> self . zip . close ( ) <NEWLINE> self . zip = None <NEWLINE> <UNTAB> if self . fid is not None : <NEWLINE> <TAB> self . fid . close ( ) <NEWLINE> self . fid = None <NEWLINE> <UNTAB> self . f = None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rotate ( images , angles , interpolation = <STRING> , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> ) : <NEWLINE> <TAB> image_or_images = ops . convert_to_tensor ( images ) <NEWLINE> if image_or_images . dtype . base_dtype not in _IMAGE_DTYPES : <NEWLINE> <TAB> raise TypeError ( <STRING> % image_or_images . dtype ) <NEWLINE> <UNTAB> elif image_or_images . get_shape ( ) . ndims is None : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> elif len ( image_or_images . get_shape ( ) ) == <NUMBER> : <NEWLINE> <TAB> images = image_or_images [ None , : , : , None ] <NEWLINE> <UNTAB> elif len ( image_or_images . get_shape ( ) ) == <NUMBER> : <NEWLINE> <TAB> images = image_or_images [ None , : , : , : ] <NEWLINE> <UNTAB> elif len ( image_or_images . get_shape ( ) ) == <NUMBER> : <NEWLINE> <TAB> images = image_or_images <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> image_height = math_ops . cast ( array_ops . shape ( images ) [ <NUMBER> ] , <NEWLINE> dtypes . float32 ) [ None ] <NEWLINE> image_width = math_ops . cast ( array_ops . shape ( images ) [ <NUMBER> ] , <NEWLINE> dtypes . float32 ) [ None ] <NEWLINE> output = transform ( <NEWLINE> images , <NEWLINE> angles_to_projective_transforms ( angles , image_height , image_width ) , <NEWLINE> interpolation = interpolation ) <NEWLINE> if image_or_images . get_shape ( ) . ndims is None : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> elif len ( image_or_images . get_shape ( ) ) == <NUMBER> : <NEWLINE> <TAB> return output [ <NUMBER> , : , : , <NUMBER> ] <NEWLINE> <UNTAB> elif len ( image_or_images . get_shape ( ) ) == <NUMBER> : <NEWLINE> <TAB> return output [ <NUMBER> , : , : , : ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return output <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def all_terms ( f ) : <NEWLINE> <TAB> <NEWLINE> return [ ( m , f . rep . dom . to_sympy ( c ) ) for m , c in f . rep . all_terms ( ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def savez_compressed ( file , * args , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> _savez ( file , args , kwds , True ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def ptp ( obj , axis = None , out = None , fill_value = None ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return obj . ptp ( axis , out = out , fill_value = fill_value ) <NEWLINE> <UNTAB> except ( AttributeError , TypeError ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return asanyarray ( obj ) . ptp ( axis = axis , fill_value = fill_value , out = out ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gf_factor ( f , p , K ) : <NEWLINE> <TAB> <NEWLINE> lc , f = gf_monic ( f , p , K ) <NEWLINE> <NEWLINE> if gf_degree ( f ) < <NUMBER> : <NEWLINE> <TAB> return lc , [ ] <NEWLINE> <NEWLINE> <UNTAB> factors = [ ] <NEWLINE> <NEWLINE> for g , n in gf_sqf_list ( f , p , K ) [ <NUMBER> ] : <NEWLINE> <TAB> for h in gf_factor_sqf ( g , p , K ) [ <NUMBER> ] : <NEWLINE> <TAB> factors . append ( ( h , n ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return lc , _sort_factors ( factors ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def safe_sparse_dot ( a , b , dense_output = False ) : <NEWLINE> <TAB> <NEWLINE> if sparse . issparse ( a ) or sparse . issparse ( b ) : <NEWLINE> <TAB> ret = a * b <NEWLINE> if dense_output and hasattr ( ret , <STRING> ) : <NEWLINE> <TAB> ret = ret . toarray ( ) <NEWLINE> <UNTAB> return ret <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return np . dot ( a , b ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ cbook . deprecated ( <STRING> ) <NEWLINE> def path_length ( X ) : <NEWLINE> <TAB> <NEWLINE> X = distances_along_curve ( X ) <NEWLINE> return np . concatenate ( ( np . zeros ( <NUMBER> ) , np . cumsum ( X ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_exact ( f ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( f . rep , <STRING> ) : <NEWLINE> <TAB> result = f . rep . to_exact ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise OperationNotSupported ( f , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return f . per ( result ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_tick_params ( self , which = <STRING> , reset = False , ** kw ) : <NEWLINE> <TAB> <NEWLINE> dicts = [ ] <NEWLINE> if which == <STRING> or which == <STRING> : <NEWLINE> <TAB> dicts . append ( self . _major_tick_kw ) <NEWLINE> <UNTAB> if which == <STRING> or which == <STRING> : <NEWLINE> <TAB> dicts . append ( self . _minor_tick_kw ) <NEWLINE> <UNTAB> kwtrans = self . _translate_tick_kw ( kw , to_init_kw = True ) <NEWLINE> for d in dicts : <NEWLINE> <TAB> if reset : <NEWLINE> <TAB> d . clear ( ) <NEWLINE> <UNTAB> d . update ( kwtrans ) <NEWLINE> <NEWLINE> <UNTAB> if reset : <NEWLINE> <TAB> self . reset_ticks ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if which == <STRING> or which == <STRING> : <NEWLINE> <TAB> for tick in self . majorTicks : <NEWLINE> <TAB> tick . _apply_params ( ** self . _major_tick_kw ) <NEWLINE> <UNTAB> <UNTAB> if which == <STRING> or which == <STRING> : <NEWLINE> <TAB> for tick in self . minorTicks : <NEWLINE> <TAB> tick . _apply_params ( ** self . _minor_tick_kw ) <NEWLINE> <UNTAB> <UNTAB> if <STRING> in kwtrans : <NEWLINE> <TAB> self . offsetText . set_color ( kwtrans [ <STRING> ] ) <NEWLINE> <UNTAB> <UNTAB> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def unpack ( expr ) : <NEWLINE> <TAB> <NEWLINE> if len ( expr . args ) == <NUMBER> : <NEWLINE> <TAB> return expr . args [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return expr <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def save_module ( self , obj ) : <NEWLINE> <TAB> <NEWLINE> mod_name = obj . __name__ <NEWLINE> <NEWLINE> if hasattr ( obj , <STRING> ) : <NEWLINE> <TAB> is_dynamic = False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _find_module ( mod_name ) <NEWLINE> is_dynamic = False <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> is_dynamic = True <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . modules . add ( obj ) <NEWLINE> if is_dynamic : <NEWLINE> <TAB> self . save_reduce ( dynamic_subimport , ( obj . __name__ , vars ( obj ) ) , obj = obj ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . save_reduce ( subimport , ( obj . __name__ , ) , obj = obj ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ if_delegate_has_method ( delegate = ( <STRING> , <STRING> ) ) <NEWLINE> def predict ( self , X ) : <NEWLINE> <TAB> <NEWLINE> self . _check_is_fitted ( <STRING> ) <NEWLINE> return self . best_estimator_ . predict ( X ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def eval ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . train ( False ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _extended_shape ( self , sample_shape = torch . Size ( ) ) : <NEWLINE> <TAB> <NEWLINE> return torch . Size ( sample_shape + self . _batch_shape + self . _event_shape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def blit_array ( surface , array ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( array , numpy_ndarray ) and array . dtype in numpy_floats : <NEWLINE> <TAB> array = array . round ( <NUMBER> ) . astype ( numpy_uint32 ) <NEWLINE> <UNTAB> return array_to_surface ( surface , array ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_negative ( self , a ) : <NEWLINE> <TAB> <NEWLINE> return self . dom . is_negative ( a . LC ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_pk_constraint ( self , conn , table_name , schema = None , ** kw ) : <NEWLINE> <TAB> <NEWLINE> return { <NEWLINE> <STRING> : <NEWLINE> self . get_primary_keys ( conn , table_name , <NEWLINE> schema = schema , ** kw ) <NEWLINE> } <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _linear_3eq_order1_type4 ( x , y , z , t , r , eq ) : <NEWLINE> <TAB> <NEWLINE> u , v , w = symbols ( <STRING> , cls = Function ) <NEWLINE> a2 , a3 = cancel ( r [ <STRING> ] / r [ <STRING> ] ) . as_numer_denom ( ) <NEWLINE> f = cancel ( r [ <STRING> ] / a2 ) <NEWLINE> b1 = cancel ( r [ <STRING> ] / f ) ; b3 = cancel ( r [ <STRING> ] / f ) <NEWLINE> c1 = cancel ( r [ <STRING> ] / f ) ; c2 = cancel ( r [ <STRING> ] / f ) <NEWLINE> a1 , g = div ( r [ <STRING> ] , f ) <NEWLINE> b2 = div ( r [ <STRING> ] , f ) [ <NUMBER> ] <NEWLINE> c3 = div ( r [ <STRING> ] , f ) [ <NUMBER> ] <NEWLINE> trans_eq = ( diff ( u ( t ) , t ) - a1 * u ( t ) - a2 * v ( t ) - a3 * w ( t ) , diff ( v ( t ) , t ) - b1 * u ( t ) - b2 * v ( t ) - b3 * w ( t ) , diff ( w ( t ) , t ) - c1 * u ( t ) - c2 * v ( t ) - c3 * w ( t ) ) <NEWLINE> sol = dsolve ( trans_eq ) <NEWLINE> sol1 = exp ( Integral ( g , t ) ) * ( ( sol [ <NUMBER> ] . rhs ) . subs ( t , Integral ( f , t ) ) ) <NEWLINE> sol2 = exp ( Integral ( g , t ) ) * ( ( sol [ <NUMBER> ] . rhs ) . subs ( t , Integral ( f , t ) ) ) <NEWLINE> sol3 = exp ( Integral ( g , t ) ) * ( ( sol [ <NUMBER> ] . rhs ) . subs ( t , Integral ( f , t ) ) ) <NEWLINE> return [ Eq ( x ( t ) , sol1 ) , Eq ( y ( t ) , sol2 ) , Eq ( z ( t ) , sol3 ) ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _encode ( values , uniques = None , encode = False ) : <NEWLINE> <TAB> <NEWLINE> if values . dtype == object : <NEWLINE> <TAB> return _encode_python ( values , uniques , encode ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _encode_numpy ( values , uniques , encode ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def gather_nd ( params , indices , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , params = params , indices = indices , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , params , indices ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return gather_nd_eager_fallback ( <NEWLINE> params , indices , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def array_red ( surface ) : <NEWLINE> <TAB> <NEWLINE> size = surface . get_size ( ) <NEWLINE> array = numpy . empty ( size , numpy . uint8 ) <NEWLINE> surface_to_array ( array , surface , <STRING> ) <NEWLINE> return array <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def winfo_visual ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . tk . call ( <STRING> , <STRING> , self . _w ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def eigvals ( a ) : <NEWLINE> <TAB> <NEWLINE> a , wrap = _makearray ( a ) <NEWLINE> _assertRankAtLeast2 ( a ) <NEWLINE> _assertNdSquareness ( a ) <NEWLINE> _assertFinite ( a ) <NEWLINE> t , result_t = _commonType ( a ) <NEWLINE> <NEWLINE> extobj = get_linalg_error_extobj ( <NEWLINE> _raise_linalgerror_eigenvalues_nonconvergence ) <NEWLINE> signature = <STRING> if isComplexType ( t ) else <STRING> <NEWLINE> w = _umath_linalg . eigvals ( a , signature = signature , extobj = extobj ) <NEWLINE> <NEWLINE> if not isComplexType ( t ) : <NEWLINE> <TAB> if all ( w . imag == <NUMBER> ) : <NEWLINE> <TAB> w = w . real <NEWLINE> result_t = _realType ( result_t ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result_t = _complexType ( result_t ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return w . astype ( result_t , copy = False ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _eval_Eq ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if not hasattr ( other , <STRING> ) or self . shape != other . shape : <NEWLINE> <TAB> return S . false <NEWLINE> <UNTAB> if isinstance ( other , MatrixExpr ) and not isinstance ( <NEWLINE> other , ImmutableDenseMatrix ) : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> diff = self - other <NEWLINE> return sympify ( diff . is_zero ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def union ( bboxes ) : <NEWLINE> <TAB> <NEWLINE> if not len ( bboxes ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> x0 = np . min ( [ bbox . xmin for bbox in bboxes ] ) <NEWLINE> x1 = np . max ( [ bbox . xmax for bbox in bboxes ] ) <NEWLINE> y0 = np . min ( [ bbox . ymin for bbox in bboxes ] ) <NEWLINE> y1 = np . max ( [ bbox . ymax for bbox in bboxes ] ) <NEWLINE> return Bbox ( [ [ x0 , y0 ] , [ x1 , y1 ] ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def viterbi_decode ( score , transition_params ) : <NEWLINE> <TAB> <NEWLINE> trellis = np . zeros_like ( score ) <NEWLINE> backpointers = np . zeros_like ( score , dtype = np . int32 ) <NEWLINE> trellis [ <NUMBER> ] = score [ <NUMBER> ] <NEWLINE> <NEWLINE> for t in range ( <NUMBER> , score . shape [ <NUMBER> ] ) : <NEWLINE> <TAB> v = np . expand_dims ( trellis [ t - <NUMBER> ] , <NUMBER> ) + transition_params <NEWLINE> trellis [ t ] = score [ t ] + np . max ( v , <NUMBER> ) <NEWLINE> backpointers [ t ] = np . argmax ( v , <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> viterbi = [ np . argmax ( trellis [ - <NUMBER> ] ) ] <NEWLINE> for bp in reversed ( backpointers [ <NUMBER> : ] ) : <NEWLINE> <TAB> viterbi . append ( bp [ viterbi [ - <NUMBER> ] ] ) <NEWLINE> <UNTAB> viterbi . reverse ( ) <NEWLINE> <NEWLINE> viterbi_score = np . max ( trellis [ - <NUMBER> ] ) <NEWLINE> return viterbi , viterbi_score <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def approx_fprime ( xk , f , epsilon , * args ) : <NEWLINE> <TAB> <NEWLINE> return _approx_fprime_helper ( xk , f , epsilon , args = args ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def primitive ( self ) : <NEWLINE> <TAB> <NEWLINE> if not self : <NEWLINE> <TAB> return S . One , S . Zero <NEWLINE> <UNTAB> c , r = self . as_coeff_Mul ( rational = True ) <NEWLINE> if c . is_negative : <NEWLINE> <TAB> c , r = - c , - r <NEWLINE> <UNTAB> return c , r <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def samples ( sound ) : <NEWLINE> <TAB> <NEWLINE> return numpysnd . samples ( sound ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def winfo_colormapfull ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . tk . getboolean ( <NEWLINE> self . tk . call ( <STRING> , <STRING> , self . _w ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_undefined_options ( self , src_cmd , * option_pairs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> src_cmd_obj = self . distribution . get_command_obj ( src_cmd ) <NEWLINE> src_cmd_obj . ensure_finalized ( ) <NEWLINE> for ( src_option , dst_option ) in option_pairs : <NEWLINE> <TAB> if getattr ( self , dst_option ) is None : <NEWLINE> <TAB> setattr ( self , dst_option , getattr ( src_cmd_obj , src_option ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def consumers ( self ) : <NEWLINE> <TAB> <NEWLINE> consumer_names = c_api . TF_OperationOutputConsumers_wrapper ( <NEWLINE> self . _as_tf_output ( ) ) <NEWLINE> <NEWLINE> return [ <NEWLINE> self . graph . _get_operation_by_name_unsafe ( name ) <NEWLINE> for name in consumer_names <NEWLINE> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def max_pool_grad_grad_v2 ( orig_input , orig_output , grad , ksize , strides , padding , data_format = <STRING> , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> padding = _execute . make_str ( padding , <STRING> ) <NEWLINE> if data_format is None : <NEWLINE> <TAB> data_format = <STRING> <NEWLINE> <UNTAB> data_format = _execute . make_str ( data_format , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , orig_input = orig_input , orig_output = orig_output , <NEWLINE> grad = grad , ksize = ksize , strides = strides , padding = padding , <NEWLINE> data_format = data_format , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , orig_input , <NEWLINE> orig_output , grad , ksize , strides , <STRING> , padding , <STRING> , <NEWLINE> data_format ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return max_pool_grad_grad_v2_eager_fallback ( <NEWLINE> orig_input , orig_output , grad , ksize , strides , padding = padding , <NEWLINE> data_format = data_format , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( None , <STRING> <NEWLINE> <STRING> ) <NEWLINE> def build_parsing_serving_input_fn ( feature_spec , default_batch_size = None ) : <NEWLINE> <TAB> <NEWLINE> def input_fn ( ) : <NEWLINE> <TAB> <NEWLINE> serialized_tf_example = array_ops . placeholder ( dtype = dtypes . string , <NEWLINE> shape = [ default_batch_size ] , <NEWLINE> name = <STRING> ) <NEWLINE> inputs = { <STRING> : serialized_tf_example } <NEWLINE> features = parsing_ops . parse_example ( serialized_tf_example , feature_spec ) <NEWLINE> labels = None <NEWLINE> return InputFnOps ( features , labels , inputs ) <NEWLINE> <UNTAB> return input_fn <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def ones ( shape , dtype = dtypes . float32 , name = None ) : <NEWLINE> <TAB> <NEWLINE> dtype = dtypes . as_dtype ( dtype ) . base_dtype <NEWLINE> with ops . name_scope ( name , <STRING> , [ shape ] ) as name : <NEWLINE> <TAB> one = True if dtype == dtypes . bool else <NUMBER> <NEWLINE> if not isinstance ( shape , ops . Tensor ) : <NEWLINE> <TAB> try : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> output = _constant_if_small ( one , shape , dtype , name ) <NEWLINE> if output is not None : <NEWLINE> <TAB> return output <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> shape = constant_op . _tensor_shape_tensor_conversion_function ( <NEWLINE> tensor_shape . TensorShape ( shape ) ) <NEWLINE> <UNTAB> except ( TypeError , ValueError ) : <NEWLINE> <NEWLINE> <TAB> shape = ops . convert_to_tensor ( shape , dtype = dtypes . int32 ) <NEWLINE> <UNTAB> <UNTAB> if not shape . _shape_tuple ( ) : <NEWLINE> <TAB> shape = reshape ( shape , [ - <NUMBER> ] ) <NEWLINE> <UNTAB> output = fill ( shape , constant ( one , dtype = dtype ) , name = name ) <NEWLINE> <UNTAB> assert output . dtype . base_dtype == dtype <NEWLINE> return output <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def unicode_transcode ( input , input_encoding , output_encoding , errors = <STRING> , replacement_char = <NUMBER> , replace_control_characters = False , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> input_encoding = _execute . make_str ( input_encoding , <STRING> ) <NEWLINE> output_encoding = _execute . make_str ( output_encoding , <STRING> ) <NEWLINE> if errors is None : <NEWLINE> <TAB> errors = <STRING> <NEWLINE> <UNTAB> errors = _execute . make_str ( errors , <STRING> ) <NEWLINE> if replacement_char is None : <NEWLINE> <TAB> replacement_char = <NUMBER> <NEWLINE> <UNTAB> replacement_char = _execute . make_int ( replacement_char , <STRING> ) <NEWLINE> if replace_control_characters is None : <NEWLINE> <TAB> replace_control_characters = False <NEWLINE> <UNTAB> replace_control_characters = _execute . make_bool ( replace_control_characters , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , input_encoding = input_encoding , <NEWLINE> output_encoding = output_encoding , errors = errors , <NEWLINE> replacement_char = replacement_char , <NEWLINE> replace_control_characters = replace_control_characters , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <NEWLINE> <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , input , <NEWLINE> <STRING> , input_encoding , <STRING> , output_encoding , <NEWLINE> <STRING> , errors , <STRING> , replacement_char , <NEWLINE> <STRING> , replace_control_characters ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return unicode_transcode_eager_fallback ( <NEWLINE> input , input_encoding = input_encoding , <NEWLINE> output_encoding = output_encoding , errors = errors , <NEWLINE> replacement_char = replacement_char , <NEWLINE> replace_control_characters = replace_control_characters , name = name , <NEWLINE> ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _align_series ( self , indexer , ser , multiindex_indexer = False ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( indexer , ( slice , np . ndarray , list , Index ) ) : <NEWLINE> <TAB> indexer = tuple ( [ indexer ] ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( indexer , tuple ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> ravel = lambda i : i . ravel ( ) if isinstance ( i , np . ndarray ) else i <NEWLINE> indexer = tuple ( map ( ravel , indexer ) ) <NEWLINE> <NEWLINE> aligners = [ not com . is_null_slice ( idx ) for idx in indexer ] <NEWLINE> sum_aligners = sum ( aligners ) <NEWLINE> single_aligner = sum_aligners == <NUMBER> <NEWLINE> is_frame = self . obj . ndim == <NUMBER> <NEWLINE> is_panel = self . obj . ndim >= <NUMBER> <NEWLINE> obj = self . obj <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if is_frame : <NEWLINE> <TAB> single_aligner = single_aligner and aligners [ <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif is_panel : <NEWLINE> <TAB> single_aligner = ( single_aligner and <NEWLINE> ( aligners [ <NUMBER> ] or aligners [ <NUMBER> ] ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if ( sum_aligners == self . ndim and <NEWLINE> all ( is_sequence ( _ ) for _ in indexer ) ) : <NEWLINE> <TAB> ser = ser . reindex ( obj . axes [ <NUMBER> ] [ indexer [ <NUMBER> ] ] , copy = True ) . _values <NEWLINE> <NEWLINE> <NEWLINE> if len ( indexer ) > <NUMBER> and not multiindex_indexer : <NEWLINE> <TAB> l = len ( indexer [ <NUMBER> ] ) <NEWLINE> ser = np . tile ( ser , l ) . reshape ( l , - <NUMBER> ) . T <NEWLINE> <NEWLINE> <UNTAB> return ser <NEWLINE> <NEWLINE> <UNTAB> for i , idx in enumerate ( indexer ) : <NEWLINE> <TAB> ax = obj . axes [ i ] <NEWLINE> <NEWLINE> <NEWLINE> if is_sequence ( idx ) or isinstance ( idx , slice ) : <NEWLINE> <TAB> if single_aligner and com . is_null_slice ( idx ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> new_ix = ax [ idx ] <NEWLINE> if not is_list_like_indexer ( new_ix ) : <NEWLINE> <TAB> new_ix = Index ( [ new_ix ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> new_ix = Index ( new_ix ) <NEWLINE> <UNTAB> if ser . index . equals ( new_ix ) or not len ( new_ix ) : <NEWLINE> <TAB> return ser . _values . copy ( ) <NEWLINE> <NEWLINE> <UNTAB> return ser . reindex ( new_ix ) . _values <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif single_aligner and is_frame : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> ax = self . obj . axes [ <NUMBER> ] <NEWLINE> if ser . index . equals ( ax ) or not len ( ax ) : <NEWLINE> <TAB> return ser . _values . copy ( ) <NEWLINE> <UNTAB> return ser . reindex ( ax ) . _values <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif single_aligner : <NEWLINE> <NEWLINE> <TAB> broadcast = [ ] <NEWLINE> for n , labels in enumerate ( self . obj . _get_plane_axes ( i ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if len ( labels & ser . index ) : <NEWLINE> <TAB> ser = ser . reindex ( labels ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> broadcast . append ( ( n , len ( labels ) ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> ser = ser . _values . copy ( ) <NEWLINE> for ( axis , l ) in broadcast : <NEWLINE> <TAB> shape = [ - <NUMBER> ] * ( len ( broadcast ) + <NUMBER> ) <NEWLINE> shape [ axis ] = l <NEWLINE> ser = np . tile ( ser , l ) . reshape ( shape ) <NEWLINE> <NEWLINE> <UNTAB> if self . obj . ndim == <NUMBER> : <NEWLINE> <TAB> ser = ser . T <NEWLINE> <NEWLINE> <UNTAB> return ser <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif is_scalar ( indexer ) : <NEWLINE> <TAB> ax = self . obj . _get_axis ( <NUMBER> ) <NEWLINE> <NEWLINE> if ser . index . equals ( ax ) : <NEWLINE> <TAB> return ser . _values . copy ( ) <NEWLINE> <NEWLINE> <UNTAB> return ser . reindex ( ax ) . _values <NEWLINE> <NEWLINE> <UNTAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _get_uniform_grid_state ( ticks ) : <NEWLINE> <TAB> <NEWLINE> if all ( tick . gridOn for tick in ticks ) : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> elif not any ( tick . gridOn for tick in ticks ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _eval_inverse ( self , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> from sympy . matrices import diag <NEWLINE> <NEWLINE> method = kwargs . get ( <STRING> , <STRING> ) <NEWLINE> iszerofunc = kwargs . get ( <STRING> , _iszero ) <NEWLINE> if kwargs . get ( <STRING> , False ) : <NEWLINE> <TAB> blocks = self . get_diag_blocks ( ) <NEWLINE> r = [ ] <NEWLINE> for block in blocks : <NEWLINE> <TAB> r . append ( block . inv ( method = method , iszerofunc = iszerofunc ) ) <NEWLINE> <UNTAB> return diag ( * r ) <NEWLINE> <NEWLINE> <UNTAB> M = self . as_mutable ( ) <NEWLINE> if method == <STRING> : <NEWLINE> <TAB> rv = M . inverse_GE ( iszerofunc = iszerofunc ) <NEWLINE> <UNTAB> elif method == <STRING> : <NEWLINE> <TAB> rv = M . inverse_LU ( iszerofunc = iszerofunc ) <NEWLINE> <UNTAB> elif method == <STRING> : <NEWLINE> <TAB> rv = M . inverse_ADJ ( iszerofunc = iszerofunc ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return self . _new ( rv ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def float ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _apply ( lambda t : t . float ( ) if t . is_floating_point ( ) else t ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def unique_roots ( p , tol = <NUMBER> , rtype = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if rtype in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> comproot = np . max <NEWLINE> <UNTAB> elif rtype in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> comproot = np . min <NEWLINE> <UNTAB> elif rtype in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> comproot = np . mean <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> p = asarray ( p ) * <NUMBER> <NEWLINE> tol = abs ( tol ) <NEWLINE> p , indx = cmplx_sort ( p ) <NEWLINE> pout = [ ] <NEWLINE> mult = [ ] <NEWLINE> indx = - <NUMBER> <NEWLINE> curp = p [ <NUMBER> ] + <NUMBER> * tol <NEWLINE> sameroots = [ ] <NEWLINE> for k in range ( len ( p ) ) : <NEWLINE> <TAB> tr = p [ k ] <NEWLINE> if abs ( tr - curp ) < tol : <NEWLINE> <TAB> sameroots . append ( tr ) <NEWLINE> curp = comproot ( sameroots ) <NEWLINE> pout [ indx ] = curp <NEWLINE> mult [ indx ] += <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pout . append ( tr ) <NEWLINE> curp = tr <NEWLINE> sameroots = [ tr ] <NEWLINE> indx += <NUMBER> <NEWLINE> mult . append ( <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> return array ( pout ) , array ( mult ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def deflate ( f ) : <NEWLINE> <TAB> <NEWLINE> J , F = dmp_deflate ( f . rep , f . lev , f . dom ) <NEWLINE> return J , f . per ( F ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def end ( self , session ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def forward ( self , x ) : <NEWLINE> <TAB> <NEWLINE> if self . W . data is None : <NEWLINE> <TAB> self . _initialize_params ( x . shape [ <NUMBER> ] ) <NEWLINE> <UNTAB> return convolution_2d . convolution_2d ( <NEWLINE> x , self . W , self . b , self . stride , self . pad , dilate = self . dilate , <NEWLINE> groups = self . groups ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_terms_gcd ( f , K ) : <NEWLINE> <TAB> <NEWLINE> if dup_TC ( f , K ) or not f : <NEWLINE> <TAB> return <NUMBER> , f <NEWLINE> <NEWLINE> <UNTAB> i = <NUMBER> <NEWLINE> <NEWLINE> for c in reversed ( f ) : <NEWLINE> <TAB> if not c : <NEWLINE> <TAB> i += <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return i , f [ : - i ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def perpendicular_line ( self , p ) : <NEWLINE> <TAB> <NEWLINE> p = Point ( p , dim = self . ambient_dimension ) <NEWLINE> <NEWLINE> <NEWLINE> return Line ( p , p + self . direction . orthogonal_direction ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_dense ( self , sparse_only = False ) : <NEWLINE> <TAB> <NEWLINE> if sparse_only : <NEWLINE> <TAB> warnings . warn ( ( <STRING> <NEWLINE> <STRING> ) , <NEWLINE> FutureWarning , stacklevel = <NUMBER> ) <NEWLINE> int_index = self . sp_index . to_int_index ( ) <NEWLINE> index = self . index . take ( int_index . indices ) <NEWLINE> return Series ( self . sp_values , index = index , name = self . name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return Series ( self . values . to_dense ( ) , index = self . index , <NEWLINE> name = self . name ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def moment ( a , moment = <NUMBER> , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> a , axis = _chk_asarray ( a , axis ) <NEWLINE> if moment == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> shape = list ( a . shape ) <NEWLINE> del shape [ axis ] <NEWLINE> if shape : <NEWLINE> <NEWLINE> <TAB> return np . zeros ( shape , dtype = float ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> return np . float64 ( <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> n_list = [ moment ] <NEWLINE> current_n = moment <NEWLINE> while current_n > <NUMBER> : <NEWLINE> <TAB> if current_n % <NUMBER> : <NEWLINE> <TAB> current_n = ( current_n - <NUMBER> ) / <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> current_n /= <NUMBER> <NEWLINE> <UNTAB> n_list . append ( current_n ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> a_zero_mean = a - ma . expand_dims ( a . mean ( axis ) , axis ) <NEWLINE> if n_list [ - <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> s = a_zero_mean . copy ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> s = a_zero_mean ** <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for n in n_list [ - <NUMBER> : : - <NUMBER> ] : <NEWLINE> <TAB> s = s ** <NUMBER> <NEWLINE> if n % <NUMBER> : <NEWLINE> <TAB> s *= a_zero_mean <NEWLINE> <UNTAB> <UNTAB> return s . mean ( axis ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def center ( G , e = None , usebounds = False ) : <NEWLINE> <TAB> <NEWLINE> if usebounds is True and e is None and not G . is_directed ( ) : <NEWLINE> <TAB> return extrema_bounding ( G , compute = <STRING> ) <NEWLINE> <UNTAB> if e is None : <NEWLINE> <TAB> e = eccentricity ( G ) <NEWLINE> <UNTAB> radius = min ( e . values ( ) ) <NEWLINE> p = [ v for v in e if e [ v ] == radius ] <NEWLINE> return p <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def data_to_n ( data ) : <NEWLINE> <TAB> <NEWLINE> if data [ <NUMBER> ] <= <NUMBER> : <NEWLINE> <TAB> return data [ <NUMBER> ] , data [ <NUMBER> : ] <NEWLINE> <UNTAB> if data [ <NUMBER> ] <= <NUMBER> : <NEWLINE> <TAB> return ( data [ <NUMBER> ] << <NUMBER> ) + ( data [ <NUMBER> ] << <NUMBER> ) + data [ <NUMBER> ] , data [ <NUMBER> : ] <NEWLINE> <UNTAB> return ( ( data [ <NUMBER> ] << <NUMBER> ) + ( data [ <NUMBER> ] << <NUMBER> ) + ( data [ <NUMBER> ] << <NUMBER> ) + <NEWLINE> ( data [ <NUMBER> ] << <NUMBER> ) + ( data [ <NUMBER> ] << <NUMBER> ) + data [ <NUMBER> ] , data [ <NUMBER> : ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _multimetric_score ( estimator , X_test , y_test , scorers ) : <NEWLINE> <TAB> <NEWLINE> scores = { } <NEWLINE> <NEWLINE> for name , scorer in scorers . items ( ) : <NEWLINE> <TAB> if y_test is None : <NEWLINE> <TAB> score = scorer ( estimator , X_test ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> score = scorer ( estimator , X_test , y_test ) <NEWLINE> <NEWLINE> <UNTAB> if hasattr ( score , <STRING> ) : <NEWLINE> <TAB> try : <NEWLINE> <NEWLINE> <TAB> score = score . item ( ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> scores [ name ] = score <NEWLINE> <NEWLINE> if not isinstance ( score , numbers . Number ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> % ( str ( score ) , type ( score ) , name ) ) <NEWLINE> <UNTAB> <UNTAB> return scores <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def pop_stack ( stack , op_id ) : <NEWLINE> <TAB> <NEWLINE> if __debug__ : <NEWLINE> <TAB> pushed_stack , pushed_op_id = stack . pop ( ) <NEWLINE> assert pushed_op_id == op_id , <STRING> % ( op_id , pushed_op_id ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pushed_stack = stack . pop ( ) <NEWLINE> <UNTAB> return pushed_stack <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def polyint ( c , m = <NUMBER> , k = [ ] , lbnd = <NUMBER> , scl = <NUMBER> , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> c = np . array ( c , ndmin = <NUMBER> , copy = <NUMBER> ) <NEWLINE> if c . dtype . char in <STRING> : <NEWLINE> <NEWLINE> <TAB> c = c + <NUMBER> <NEWLINE> <UNTAB> cdt = c . dtype <NEWLINE> if not np . iterable ( k ) : <NEWLINE> <TAB> k = [ k ] <NEWLINE> <UNTAB> cnt , iaxis = [ int ( t ) for t in [ m , axis ] ] <NEWLINE> <NEWLINE> if cnt != m : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if cnt < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if len ( k ) > cnt : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if np . ndim ( lbnd ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if np . ndim ( scl ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if iaxis != axis : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> iaxis = normalize_axis_index ( iaxis , c . ndim ) <NEWLINE> <NEWLINE> if cnt == <NUMBER> : <NEWLINE> <TAB> return c <NEWLINE> <NEWLINE> <UNTAB> k = list ( k ) + [ <NUMBER> ] * ( cnt - len ( k ) ) <NEWLINE> c = np . moveaxis ( c , iaxis , <NUMBER> ) <NEWLINE> for i in range ( cnt ) : <NEWLINE> <TAB> n = len ( c ) <NEWLINE> c *= scl <NEWLINE> if n == <NUMBER> and np . all ( c [ <NUMBER> ] == <NUMBER> ) : <NEWLINE> <TAB> c [ <NUMBER> ] += k [ i ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> tmp = np . empty ( ( n + <NUMBER> , ) + c . shape [ <NUMBER> : ] , dtype = cdt ) <NEWLINE> tmp [ <NUMBER> ] = c [ <NUMBER> ] * <NUMBER> <NEWLINE> tmp [ <NUMBER> ] = c [ <NUMBER> ] <NEWLINE> for j in range ( <NUMBER> , n ) : <NEWLINE> <TAB> tmp [ j + <NUMBER> ] = c [ j ] / ( j + <NUMBER> ) <NEWLINE> <UNTAB> tmp [ <NUMBER> ] += k [ i ] - polyval ( lbnd , tmp ) <NEWLINE> c = tmp <NEWLINE> <UNTAB> <UNTAB> c = np . moveaxis ( c , <NUMBER> , iaxis ) <NEWLINE> return c <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def print_progress ( self ) : <NEWLINE> <TAB> <NEWLINE> if not self . verbose : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> elapsed_time = time . time ( ) - self . _start_time <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if self . _original_iterator is not None : <NEWLINE> <TAB> if _verbosity_filter ( self . n_dispatched_batches , self . verbose ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> self . _print ( <STRING> , <NEWLINE> ( self . n_completed_tasks , <NEWLINE> short_format_time ( elapsed_time ) , ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> index = self . n_completed_tasks <NEWLINE> <NEWLINE> total_tasks = self . n_dispatched_tasks <NEWLINE> <NEWLINE> if not index == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> cursor = ( total_tasks - index + <NUMBER> - <NEWLINE> self . _pre_dispatch_amount ) <NEWLINE> frequency = ( total_tasks // self . verbose ) + <NUMBER> <NEWLINE> is_last_item = ( index + <NUMBER> == total_tasks ) <NEWLINE> if ( is_last_item or cursor % frequency ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> <UNTAB> remaining_time = ( elapsed_time / index ) * ( self . n_dispatched_tasks - index * <NUMBER> ) <NEWLINE> <NEWLINE> self . _print ( <STRING> , <NEWLINE> ( index , <NEWLINE> total_tasks , <NEWLINE> short_format_time ( elapsed_time ) , <NEWLINE> short_format_time ( remaining_time ) , <NEWLINE> ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _file_path_value ( self , path_tensor ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( path_tensor , ops . Tensor ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if path_tensor . op . type != <STRING> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if path_tensor . dtype != dtypes . string : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> str_value = path_tensor . op . get_attr ( <STRING> ) . string_val <NEWLINE> if len ( str_value ) != <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> return str_value [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def items ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _parameters . items ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fdot ( ctx , A , B = None , conjugate = False ) : <NEWLINE> <TAB> <NEWLINE> if B : <NEWLINE> <TAB> A = zip ( A , B ) <NEWLINE> <UNTAB> prec , rnd = ctx . _prec_rounding <NEWLINE> real = [ ] <NEWLINE> imag = [ ] <NEWLINE> other = <NUMBER> <NEWLINE> hasattr_ = hasattr <NEWLINE> types = ( ctx . mpf , ctx . mpc ) <NEWLINE> for a , b in A : <NEWLINE> <TAB> if type ( a ) not in types : a = ctx . convert ( a ) <NEWLINE> if type ( b ) not in types : b = ctx . convert ( b ) <NEWLINE> a_real = hasattr_ ( a , <STRING> ) <NEWLINE> b_real = hasattr_ ( b , <STRING> ) <NEWLINE> if a_real and b_real : <NEWLINE> <TAB> real . append ( mpf_mul ( a . _mpf_ , b . _mpf_ ) ) <NEWLINE> continue <NEWLINE> <UNTAB> a_complex = hasattr_ ( a , <STRING> ) <NEWLINE> b_complex = hasattr_ ( b , <STRING> ) <NEWLINE> if a_real and b_complex : <NEWLINE> <TAB> aval = a . _mpf_ <NEWLINE> bre , bim = b . _mpc_ <NEWLINE> if conjugate : <NEWLINE> <TAB> bim = mpf_neg ( bim ) <NEWLINE> <UNTAB> real . append ( mpf_mul ( aval , bre ) ) <NEWLINE> imag . append ( mpf_mul ( aval , bim ) ) <NEWLINE> <UNTAB> elif b_real and a_complex : <NEWLINE> <TAB> are , aim = a . _mpc_ <NEWLINE> bval = b . _mpf_ <NEWLINE> real . append ( mpf_mul ( are , bval ) ) <NEWLINE> imag . append ( mpf_mul ( aim , bval ) ) <NEWLINE> <UNTAB> elif a_complex and b_complex : <NEWLINE> <NEWLINE> <TAB> are , aim = a . _mpc_ <NEWLINE> bre , bim = b . _mpc_ <NEWLINE> if conjugate : <NEWLINE> <TAB> bim = mpf_neg ( bim ) <NEWLINE> <UNTAB> real . append ( mpf_mul ( are , bre ) ) <NEWLINE> real . append ( mpf_neg ( mpf_mul ( aim , bim ) ) ) <NEWLINE> imag . append ( mpf_mul ( are , bim ) ) <NEWLINE> imag . append ( mpf_mul ( aim , bre ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if conjugate : <NEWLINE> <TAB> other += a * ctx . conj ( b ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> other += a * b <NEWLINE> <UNTAB> <UNTAB> <UNTAB> s = mpf_sum ( real , prec , rnd ) <NEWLINE> if imag : <NEWLINE> <TAB> s = ctx . make_mpc ( ( s , mpf_sum ( imag , prec , rnd ) ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> s = ctx . make_mpf ( s ) <NEWLINE> <UNTAB> if other is <NUMBER> : <NEWLINE> <TAB> return s <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return s + other <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def serialize ( self , serializer ) : <NEWLINE> <TAB> <NEWLINE> for name , iterator in six . iteritems ( self . _iterators ) : <NEWLINE> <TAB> iterator . serialize ( serializer [ <STRING> + name ] ) <NEWLINE> <NEWLINE> <UNTAB> for name , optimizer in six . iteritems ( self . _optimizers ) : <NEWLINE> <TAB> optimizer . serialize ( serializer [ <STRING> + name ] ) <NEWLINE> optimizer . target . serialize ( serializer [ <STRING> + name ] ) <NEWLINE> <NEWLINE> <UNTAB> self . iteration = serializer ( <STRING> , self . iteration ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def scale ( self , sx , sy = None ) : <NEWLINE> <TAB> <NEWLINE> if sy is None : <NEWLINE> <TAB> sy = sx <NEWLINE> <UNTAB> scale_mtx = np . array ( <NEWLINE> [ [ sx , <NUMBER> , <NUMBER> ] , [ <NUMBER> , sy , <NUMBER> ] , [ <NUMBER> , <NUMBER> , <NUMBER> ] ] , float ) <NEWLINE> self . _mtx = np . dot ( scale_mtx , self . _mtx ) <NEWLINE> self . invalidate ( ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _record_op_seen_by_control_dependencies ( self , op ) : <NEWLINE> <TAB> <NEWLINE> for controller in self . _control_dependencies_stack : <NEWLINE> <TAB> controller . add_op ( op ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def count_params ( self ) : <NEWLINE> <TAB> <NEWLINE> if not self . built : <NEWLINE> <TAB> if self . __class__ . __name__ == <STRING> : <NEWLINE> <TAB> self . build ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> + self . name + <NEWLINE> <STRING> <NEWLINE> <STRING> + self . name + <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> weight_shapes = [ w . shape . as_list ( ) for w in self . weights ] <NEWLINE> return int ( sum ( [ np . prod ( w ) for w in weight_shapes ] ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def training_graph ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if ( isinstance ( self . _initial_clusters , str ) or <NEWLINE> callable ( self . _initial_clusters ) ) : <NEWLINE> <TAB> initial_clusters = self . _initial_clusters <NEWLINE> num_clusters = ops . convert_to_tensor ( self . _num_clusters ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> initial_clusters = ops . convert_to_tensor ( self . _initial_clusters ) <NEWLINE> num_clusters = array_ops . shape ( initial_clusters ) [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> inputs = self . _inputs <NEWLINE> ( cluster_centers_var , cluster_centers_initialized , total_counts , <NEWLINE> cluster_centers_updated , <NEWLINE> update_in_steps ) = self . _create_variables ( num_clusters ) <NEWLINE> init_op = _InitializeClustersOpFactory ( <NEWLINE> self . _inputs , num_clusters , initial_clusters , self . _distance_metric , <NEWLINE> self . _random_seed , self . _kmeans_plus_plus_num_retries , <NEWLINE> self . _kmc2_chain_length , cluster_centers_var , cluster_centers_updated , <NEWLINE> cluster_centers_initialized ) . op ( ) <NEWLINE> cluster_centers = cluster_centers_var <NEWLINE> <NEWLINE> if self . _distance_metric == COSINE_DISTANCE : <NEWLINE> <TAB> inputs = self . _l2_normalize_data ( inputs ) <NEWLINE> if not self . _clusters_l2_normalized ( ) : <NEWLINE> <TAB> cluster_centers = nn_impl . l2_normalize ( cluster_centers , dim = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> all_scores , scores , cluster_idx = self . _infer_graph ( inputs , cluster_centers ) <NEWLINE> if self . _use_mini_batch : <NEWLINE> <TAB> sync_updates_op = self . _mini_batch_sync_updates_op ( <NEWLINE> update_in_steps , cluster_centers_var , cluster_centers_updated , <NEWLINE> total_counts ) <NEWLINE> assert sync_updates_op is not None <NEWLINE> with ops . control_dependencies ( [ sync_updates_op ] ) : <NEWLINE> <TAB> training_op = self . _mini_batch_training_op ( <NEWLINE> inputs , cluster_idx , cluster_centers_updated , total_counts ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> assert cluster_centers == cluster_centers_var <NEWLINE> training_op = self . _full_batch_training_op ( <NEWLINE> inputs , num_clusters , cluster_idx , cluster_centers_var ) <NEWLINE> <NEWLINE> <UNTAB> return ( all_scores , cluster_idx , scores , cluster_centers_initialized , <NEWLINE> init_op , training_op ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def setup_module ( module ) : <NEWLINE> <TAB> <NEWLINE> from nose import SkipTest <NEWLINE> try : <NEWLINE> <TAB> import numpy <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> raise SkipTest ( <STRING> ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> import scipy <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> raise SkipTest ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def isupper ( a ) : <NEWLINE> <TAB> <NEWLINE> return _vec_string ( a , bool_ , <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def next ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return self . __next__ ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def display ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _display <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _convert_strls ( self , data ) : <NEWLINE> <TAB> <NEWLINE> return data <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _reset_identity ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _id = _Identity ( ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def obtain_next ( string_list_tensor , counter ) : <NEWLINE> <TAB> <NEWLINE> return gen_input_pipeline_ops . obtain_next ( string_list_tensor , counter ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def nipy_spectral ( ) : <NEWLINE> <TAB> <NEWLINE> set_cmap ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _create_tmp_config_dir ( ) : <NEWLINE> <TAB> <NEWLINE> configdir = os . environ [ <STRING> ] = ( <NEWLINE> tempfile . mkdtemp ( prefix = <STRING> ) ) <NEWLINE> atexit . register ( shutil . rmtree , configdir ) <NEWLINE> return configdir <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_rlabel_position ( self ) : <NEWLINE> <TAB> <NEWLINE> return np . rad2deg ( self . _r_label_position . get_matrix ( ) [ <NUMBER> , <NUMBER> ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def fix_invalid ( a , mask = nomask , copy = True , fill_value = None ) : <NEWLINE> <TAB> <NEWLINE> a = masked_array ( a , copy = copy , mask = mask , subok = True ) <NEWLINE> invalid = np . logical_not ( np . isfinite ( a . _data ) ) <NEWLINE> if not invalid . any ( ) : <NEWLINE> <TAB> return a <NEWLINE> <UNTAB> a . _mask |= invalid <NEWLINE> if fill_value is None : <NEWLINE> <TAB> fill_value = a . fill_value <NEWLINE> <UNTAB> a . _data [ invalid ] = fill_value <NEWLINE> return a <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_datetimetz ( arr ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> return ( ( isinstance ( arr , ABCDatetimeIndex ) and <NEWLINE> getattr ( arr , <STRING> , None ) is not None ) or <NEWLINE> is_datetime64tz_dtype ( arr ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def block ( arrays , allow_unknown_chunksizes = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> def atleast_nd ( x , ndim ) : <NEWLINE> <TAB> x = asanyarray ( x ) <NEWLINE> diff = max ( ndim - x . ndim , <NUMBER> ) <NEWLINE> return x [ ( None , ) * diff + ( Ellipsis , ) ] <NEWLINE> <NEWLINE> <UNTAB> def format_index ( index ) : <NEWLINE> <TAB> return <STRING> + <STRING> . join ( <STRING> . format ( i ) for i in index ) <NEWLINE> <NEWLINE> <UNTAB> rec = _Recurser ( recurse_if = lambda x : type ( x ) is list ) <NEWLINE> <NEWLINE> <NEWLINE> list_ndim = None <NEWLINE> any_empty = False <NEWLINE> for index , value , entering in rec . walk ( arrays ) : <NEWLINE> <TAB> if type ( value ) is tuple : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( <NEWLINE> format_index ( index ) <NEWLINE> ) <NEWLINE> ) <NEWLINE> <UNTAB> if not entering : <NEWLINE> <TAB> curr_depth = len ( index ) <NEWLINE> <UNTAB> elif len ( value ) == <NUMBER> : <NEWLINE> <TAB> curr_depth = len ( index ) + <NUMBER> <NEWLINE> any_empty = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> if list_ndim is not None and list_ndim != curr_depth : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( <NEWLINE> list_ndim , <NEWLINE> curr_depth , <NEWLINE> format_index ( index ) <NEWLINE> ) <NEWLINE> ) <NEWLINE> <UNTAB> list_ndim = curr_depth <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if any_empty : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> arrays = rec . map_reduce ( <NEWLINE> arrays , <NEWLINE> f_map = asanyarray , <NEWLINE> f_reduce = list <NEWLINE> ) <NEWLINE> <NEWLINE> <NEWLINE> elem_ndim = rec . map_reduce ( <NEWLINE> arrays , <NEWLINE> f_map = lambda xi : xi . ndim , <NEWLINE> f_reduce = max <NEWLINE> ) <NEWLINE> ndim = max ( list_ndim , elem_ndim ) <NEWLINE> <NEWLINE> <NEWLINE> first_axis = ndim - list_ndim <NEWLINE> <NEWLINE> <NEWLINE> arrays = rec . map_reduce ( <NEWLINE> arrays , <NEWLINE> f_map = lambda xi : atleast_nd ( xi , ndim ) , <NEWLINE> f_reduce = list <NEWLINE> ) <NEWLINE> <NEWLINE> <NEWLINE> return rec . map_reduce ( <NEWLINE> arrays , <NEWLINE> f_reduce = lambda xs , axis : concatenate ( <NEWLINE> list ( xs ) , <NEWLINE> axis = axis , <NEWLINE> allow_unknown_chunksizes = allow_unknown_chunksizes <NEWLINE> ) , <NEWLINE> f_kwargs = lambda axis : dict ( axis = ( axis + <NUMBER> ) ) , <NEWLINE> axis = first_axis <NEWLINE> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def gf_edf_shoup ( f , n , p , K ) : <NEWLINE> <TAB> <NEWLINE> N , q = gf_degree ( f ) , int ( p ) <NEWLINE> <NEWLINE> if not N : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> if N <= n : <NEWLINE> <TAB> return [ f ] <NEWLINE> <NEWLINE> <UNTAB> factors , x = [ f ] , [ K . one , K . zero ] <NEWLINE> <NEWLINE> r = gf_random ( N - <NUMBER> , p , K ) <NEWLINE> <NEWLINE> if p == <NUMBER> : <NEWLINE> <TAB> h = gf_pow_mod ( x , q , f , p , K ) <NEWLINE> H = gf_trace_map ( r , h , x , n - <NUMBER> , f , p , K ) [ <NUMBER> ] <NEWLINE> h1 = gf_gcd ( f , H , p , K ) <NEWLINE> h2 = gf_quo ( f , h1 , p , K ) <NEWLINE> <NEWLINE> factors = gf_edf_shoup ( h1 , n , p , K ) + gf_edf_shoup ( h2 , n , p , K ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> b = gf_frobenius_monomial_base ( f , p , K ) <NEWLINE> H = _gf_trace_map ( r , n , f , b , p , K ) <NEWLINE> h = gf_pow_mod ( H , ( q - <NUMBER> ) // <NUMBER> , f , p , K ) <NEWLINE> <NEWLINE> h1 = gf_gcd ( f , h , p , K ) <NEWLINE> h2 = gf_gcd ( f , gf_sub_ground ( h , K . one , p , K ) , p , K ) <NEWLINE> h3 = gf_quo ( f , gf_mul ( h1 , h2 , p , K ) , p , K ) <NEWLINE> <NEWLINE> factors = gf_edf_shoup ( h1 , n , p , K ) + gf_edf_shoup ( h2 , n , p , K ) + gf_edf_shoup ( h3 , n , p , K ) <NEWLINE> <NEWLINE> <UNTAB> return _sort_factors ( factors , multiple = False ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def eject ( f , dom , front = False ) : <NEWLINE> <TAB> <NEWLINE> F = dmp_eject ( f . rep , f . lev , dom , front = front ) <NEWLINE> return f . __class__ ( F , dom , f . lev - len ( dom . symbols ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _void_scalar_repr ( x ) : <NEWLINE> <TAB> <NEWLINE> return StructuredVoidFormat . from_data ( array ( x ) , ** _format_options ) ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_familyname ( self ) : <NEWLINE> <TAB> <NEWLINE> name = self . _header . get ( <STRING> ) <NEWLINE> if name is not None : <NEWLINE> <TAB> return name <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> name = self . get_fullname ( ) <NEWLINE> extras = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> return re . sub ( extras , <STRING> , name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def upcast_char ( * args ) : <NEWLINE> <TAB> <NEWLINE> t = _upcast_memo . get ( args ) <NEWLINE> if t is not None : <NEWLINE> <TAB> return t <NEWLINE> <UNTAB> t = upcast ( * map ( np . dtype , args ) ) <NEWLINE> _upcast_memo [ args ] = t <NEWLINE> return t <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _prepare_categoricals ( self , data ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> is_cat = [ is_categorical_dtype ( data [ col ] ) for col in data ] <NEWLINE> self . _is_col_cat = is_cat <NEWLINE> self . _value_labels = [ ] <NEWLINE> if not any ( is_cat ) : <NEWLINE> <TAB> return data <NEWLINE> <NEWLINE> <UNTAB> get_base_missing_value = StataMissingValue . get_base_missing_value <NEWLINE> data_formatted = [ ] <NEWLINE> for col , col_is_cat in zip ( data , is_cat ) : <NEWLINE> <TAB> if col_is_cat : <NEWLINE> <TAB> self . _value_labels . append ( StataValueLabel ( data [ col ] ) ) <NEWLINE> dtype = data [ col ] . cat . codes . dtype <NEWLINE> if dtype == np . int64 : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> values = data [ col ] . cat . codes . values . copy ( ) <NEWLINE> <NEWLINE> <NEWLINE> if values . max ( ) >= get_base_missing_value ( dtype ) : <NEWLINE> <TAB> if dtype == np . int8 : <NEWLINE> <TAB> dtype = np . int16 <NEWLINE> <UNTAB> elif dtype == np . int16 : <NEWLINE> <TAB> dtype = np . int32 <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dtype = np . float64 <NEWLINE> <UNTAB> values = np . array ( values , dtype = dtype ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> values [ values == - <NUMBER> ] = get_base_missing_value ( dtype ) <NEWLINE> data_formatted . append ( ( col , values ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> data_formatted . append ( ( col , data [ col ] ) ) <NEWLINE> <UNTAB> <UNTAB> return DataFrame . from_dict ( OrderedDict ( data_formatted ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def new ( cls , rep , * gens ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( rep , DMP ) : <NEWLINE> <TAB> raise PolynomialError ( <NEWLINE> <STRING> % rep ) <NEWLINE> <UNTAB> elif rep . lev != len ( gens ) - <NUMBER> : <NEWLINE> <TAB> raise PolynomialError ( <STRING> % ( rep , gens ) ) <NEWLINE> <NEWLINE> <UNTAB> obj = Basic . __new__ ( cls ) <NEWLINE> <NEWLINE> obj . rep = rep <NEWLINE> obj . gens = gens <NEWLINE> <NEWLINE> return obj <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_tmp ( self , value ) : <NEWLINE> <TAB> <NEWLINE> name = <STRING> . format ( name = type ( value ) . __name__ , <NEWLINE> num = self . ntemps , <NEWLINE> hex_id = _raw_hex_id ( self ) ) <NEWLINE> <NEWLINE> <NEWLINE> assert name not in self . temps <NEWLINE> self . temps [ name ] = value <NEWLINE> assert name in self . temps <NEWLINE> <NEWLINE> <NEWLINE> return name <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _add_tool ( self , tool ) : <NEWLINE> <TAB> <NEWLINE> if getattr ( tool , <STRING> , None ) is not None : <NEWLINE> <TAB> self . toolmanager . toolmanager_connect ( <STRING> % tool . name , <NEWLINE> self . _tool_trigger_cbk ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def diff ( self , n , axis = <NUMBER> , mgr = None ) : <NEWLINE> <TAB> <NEWLINE> if axis == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> raise NotImplementedError <NEWLINE> <UNTAB> new_values = ( self . values - self . shift ( n , axis = axis ) [ <NUMBER> ] . values ) . asi8 <NEWLINE> <NEWLINE> <NEWLINE> new_values = new_values . reshape ( <NUMBER> , len ( new_values ) ) <NEWLINE> new_values = new_values . astype ( <STRING> ) <NEWLINE> return [ TimeDeltaBlock ( new_values , placement = self . mgr_locs . indexer ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_irreducible_p ( f , u , K ) : <NEWLINE> <TAB> <NEWLINE> _ , factors = dmp_factor_list ( f , u , K ) <NEWLINE> <NEWLINE> if not factors : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> elif len ( factors ) > <NUMBER> : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> _ , k = factors [ <NUMBER> ] <NEWLINE> return k == <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def read ( self , size = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> self . _check_can_read ( ) <NEWLINE> return self . _buffer . read ( size ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def step ( self , closure = None ) : <NEWLINE> <TAB> <NEWLINE> loss = None <NEWLINE> if closure is not None : <NEWLINE> <TAB> loss = closure ( ) <NEWLINE> <NEWLINE> <UNTAB> for group in self . param_groups : <NEWLINE> <TAB> for p in group [ <STRING> ] : <NEWLINE> <TAB> if p . grad is None : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> grad = p . grad . data <NEWLINE> if grad . is_sparse : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> state = self . state [ p ] <NEWLINE> <NEWLINE> <NEWLINE> if len ( state ) == <NUMBER> : <NEWLINE> <TAB> state [ <STRING> ] = <NUMBER> <NEWLINE> state [ <STRING> ] = group [ <STRING> ] <NEWLINE> state [ <STRING> ] = <NUMBER> <NEWLINE> state [ <STRING> ] = torch . zeros_like ( p . data ) <NEWLINE> <NEWLINE> <UNTAB> state [ <STRING> ] += <NUMBER> <NEWLINE> <NEWLINE> if group [ <STRING> ] != <NUMBER> : <NEWLINE> <TAB> grad = grad . add ( group [ <STRING> ] , p . data ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> p . data . mul_ ( <NUMBER> - group [ <STRING> ] * state [ <STRING> ] ) <NEWLINE> <NEWLINE> <NEWLINE> p . data . add_ ( - state [ <STRING> ] , grad ) <NEWLINE> <NEWLINE> <NEWLINE> if state [ <STRING> ] != <NUMBER> : <NEWLINE> <TAB> state [ <STRING> ] . add_ ( p . data . sub ( state [ <STRING> ] ) . mul ( state [ <STRING> ] ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> state [ <STRING> ] . copy_ ( p . data ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> state [ <STRING> ] = ( group [ <STRING> ] / <NEWLINE> math . pow ( ( <NUMBER> + group [ <STRING> ] * group [ <STRING> ] * state [ <STRING> ] ) , group [ <STRING> ] ) ) <NEWLINE> state [ <STRING> ] = <NUMBER> / max ( <NUMBER> , state [ <STRING> ] - group [ <STRING> ] ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return loss <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def make_compound_path ( cls , * args ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not args : <NEWLINE> <TAB> return Path ( np . empty ( [ <NUMBER> , <NUMBER> ] , dtype = np . float32 ) ) <NEWLINE> <NEWLINE> <UNTAB> lengths = [ len ( x ) for x in args ] <NEWLINE> total_length = sum ( lengths ) <NEWLINE> <NEWLINE> vertices = np . vstack ( [ x . vertices for x in args ] ) <NEWLINE> vertices . reshape ( ( total_length , <NUMBER> ) ) <NEWLINE> <NEWLINE> codes = np . empty ( total_length , dtype = cls . code_type ) <NEWLINE> i = <NUMBER> <NEWLINE> for path in args : <NEWLINE> <TAB> if path . codes is None : <NEWLINE> <TAB> codes [ i ] = cls . MOVETO <NEWLINE> codes [ i + <NUMBER> : i + len ( path . vertices ) ] = cls . LINETO <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> codes [ i : i + len ( path . codes ) ] = path . codes <NEWLINE> <UNTAB> i += len ( path . vertices ) <NEWLINE> <NEWLINE> <UNTAB> return cls ( vertices , codes ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _update_strl_names ( self ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _function_called_str ( function_name , args , kwargs ) : <NEWLINE> <TAB> <NEWLINE> template_str = <STRING> <NEWLINE> <NEWLINE> args_str = repr ( args ) [ <NUMBER> : - <NUMBER> ] <NEWLINE> kwargs_str = <STRING> . join ( <STRING> % ( k , v ) <NEWLINE> for k , v in kwargs . items ( ) ) <NEWLINE> return template_str . format ( function_name , args_str , <NEWLINE> kwargs_str ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _has_plotted_object ( self , ax ) : <NEWLINE> <TAB> <NEWLINE> return ( len ( ax . lines ) != <NUMBER> or <NEWLINE> len ( ax . artists ) != <NUMBER> or <NEWLINE> len ( ax . containers ) != <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def contains ( self , mouseevent ) : <NEWLINE> <TAB> <NEWLINE> if callable ( self . _contains ) : <NEWLINE> <TAB> return self . _contains ( self , mouseevent ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> x , y = mouseevent . xdata , mouseevent . ydata <NEWLINE> xmin , xmax , ymin , ymax = self . get_extent ( ) <NEWLINE> if xmin > xmax : <NEWLINE> <TAB> xmin , xmax = xmax , xmin <NEWLINE> <UNTAB> if ymin > ymax : <NEWLINE> <TAB> ymin , ymax = ymax , ymin <NEWLINE> <NEWLINE> <UNTAB> if x is not None and y is not None : <NEWLINE> <TAB> inside = ( xmin <= x <= xmax ) and ( ymin <= y <= ymax ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> inside = False <NEWLINE> <NEWLINE> <UNTAB> return inside , { } <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , cell , device ) : <NEWLINE> <TAB> <NEWLINE> super ( DeviceWrapper , self ) . __init__ ( ) <NEWLINE> self . _cell = cell <NEWLINE> if isinstance ( cell , checkpointable . CheckpointableBase ) : <NEWLINE> <TAB> self . _track_checkpointable ( self . _cell , name = <STRING> ) <NEWLINE> <UNTAB> self . _device = device <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def from_coo ( cls , A , dense_index = False ) : <NEWLINE> <TAB> <NEWLINE> return _coo_to_sparse_series ( A , dense_index = dense_index ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def build_raw_supervised_input_receiver_fn ( features , <NEWLINE> labels , <NEWLINE> default_batch_size = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> feat_keys = features . keys ( ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> feat_keys = [ _SINGLE_RECEIVER_DEFAULT_NAME ] <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> label_keys = labels . keys ( ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> label_keys = [ _SINGLE_LABEL_DEFAULT_NAME ] <NEWLINE> <NEWLINE> <UNTAB> overlap_keys = set ( feat_keys ) & set ( label_keys ) <NEWLINE> if overlap_keys : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( overlap_keys ) ) <NEWLINE> <NEWLINE> <UNTAB> def supervised_input_receiver_fn ( ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( features , dict ) : <NEWLINE> <TAB> features_cp = _placeholder_from_tensor ( features , default_batch_size ) <NEWLINE> receiver_features = { _SINGLE_RECEIVER_DEFAULT_NAME : features_cp } <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> receiver_features = _placeholders_from_receiver_tensors_dict ( <NEWLINE> features , default_batch_size ) <NEWLINE> features_cp = receiver_features <NEWLINE> <NEWLINE> <UNTAB> if not isinstance ( labels , dict ) : <NEWLINE> <TAB> labels_cp = _placeholder_from_tensor ( labels , default_batch_size ) <NEWLINE> receiver_labels = { _SINGLE_LABEL_DEFAULT_NAME : labels_cp } <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> receiver_labels = _placeholders_from_receiver_tensors_dict ( <NEWLINE> labels , default_batch_size ) <NEWLINE> labels_cp = receiver_labels <NEWLINE> <NEWLINE> <UNTAB> receiver_tensors = dict ( receiver_features ) <NEWLINE> receiver_tensors . update ( receiver_labels ) <NEWLINE> return SupervisedInputReceiver ( features_cp , labels_cp , receiver_tensors ) <NEWLINE> <NEWLINE> <UNTAB> return supervised_input_receiver_fn <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dmp_diff ( f , m , u , K ) : <NEWLINE> <TAB> <NEWLINE> if not u : <NEWLINE> <TAB> return dup_diff ( f , m , K ) <NEWLINE> <UNTAB> if m <= <NUMBER> : <NEWLINE> <TAB> return f <NEWLINE> <NEWLINE> <UNTAB> n = dmp_degree ( f , u ) <NEWLINE> <NEWLINE> if n < m : <NEWLINE> <TAB> return dmp_zero ( u ) <NEWLINE> <NEWLINE> <UNTAB> deriv , v = [ ] , u - <NUMBER> <NEWLINE> <NEWLINE> if m == <NUMBER> : <NEWLINE> <TAB> for coeff in f [ : - m ] : <NEWLINE> <TAB> deriv . append ( dmp_mul_ground ( coeff , K ( n ) , v , K ) ) <NEWLINE> n -= <NUMBER> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for coeff in f [ : - m ] : <NEWLINE> <TAB> k = n <NEWLINE> <NEWLINE> for i in range ( n - <NUMBER> , n - m , - <NUMBER> ) : <NEWLINE> <TAB> k *= i <NEWLINE> <NEWLINE> <UNTAB> deriv . append ( dmp_mul_ground ( coeff , K ( k ) , v , K ) ) <NEWLINE> n -= <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return dmp_strip ( deriv , u ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def global_parameters ( b , c ) : <NEWLINE> <TAB> <NEWLINE> return ( ( y , b [ <NUMBER> ] - x - y , x ) for x , y in zip ( b + [ <NUMBER> ] , [ <NUMBER> ] + c ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def concurrency_safe_write ( object_to_write , filename , write_func ) : <NEWLINE> <TAB> <NEWLINE> thread_id = id ( threading . current_thread ( ) ) <NEWLINE> temporary_filename = <STRING> . format ( <NEWLINE> filename , thread_id , os . getpid ( ) ) <NEWLINE> write_func ( object_to_write , temporary_filename ) <NEWLINE> <NEWLINE> return temporary_filename <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def cse_separate ( r , e ) : <NEWLINE> <TAB> <NEWLINE> d = sift ( e , lambda w : w . is_Equality and w . lhs . is_Symbol ) <NEWLINE> r = r + [ w . args for w in d [ True ] ] <NEWLINE> e = d [ False ] <NEWLINE> return [ reps_toposort ( r ) , e ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _z ( self , x ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( <STRING> , values = [ x ] ) : <NEWLINE> <TAB> return ( x - self . loc ) / self . scale <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def update_bruteforce ( self , mappable ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . ax . cla ( ) <NEWLINE> <NEWLINE> self . outline = None <NEWLINE> self . patch = None <NEWLINE> self . solids = None <NEWLINE> self . lines = list ( ) <NEWLINE> self . dividers = None <NEWLINE> self . set_alpha ( mappable . get_alpha ( ) ) <NEWLINE> self . cmap = mappable . cmap <NEWLINE> self . norm = mappable . norm <NEWLINE> self . draw_all ( ) <NEWLINE> if isinstance ( self . mappable , contour . ContourSet ) : <NEWLINE> <TAB> CS = self . mappable <NEWLINE> if not CS . filled : <NEWLINE> <TAB> self . add_lines ( CS ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _make_int_array ( ) : <NEWLINE> <TAB> <NEWLINE> return array . array ( str ( <STRING> ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def keys ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _modules . keys ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def fake_quant_with_min_max_args_gradient ( gradients , inputs , min = - <NUMBER> , max = <NUMBER> , num_bits = <NUMBER> , narrow_range = False , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if min is None : <NEWLINE> <TAB> min = - <NUMBER> <NEWLINE> <UNTAB> min = _execute . make_float ( min , <STRING> ) <NEWLINE> if max is None : <NEWLINE> <TAB> max = <NUMBER> <NEWLINE> <UNTAB> max = _execute . make_float ( max , <STRING> ) <NEWLINE> if num_bits is None : <NEWLINE> <TAB> num_bits = <NUMBER> <NEWLINE> <UNTAB> num_bits = _execute . make_int ( num_bits , <STRING> ) <NEWLINE> if narrow_range is None : <NEWLINE> <TAB> narrow_range = False <NEWLINE> <UNTAB> narrow_range = _execute . make_bool ( narrow_range , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , gradients = gradients , inputs = inputs , <NEWLINE> min = min , max = max , num_bits = num_bits , narrow_range = narrow_range , <NEWLINE> name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) , <NEWLINE> <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , gradients , inputs , <STRING> , min , <STRING> , <NEWLINE> max , <STRING> , num_bits , <STRING> , narrow_range ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return fake_quant_with_min_max_args_gradient_eager_fallback ( <NEWLINE> gradients , inputs , min = min , max = max , num_bits = num_bits , <NEWLINE> narrow_range = narrow_range , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def polyline ( off , scl ) : <NEWLINE> <TAB> <NEWLINE> if scl != <NUMBER> : <NEWLINE> <TAB> return np . array ( [ off , scl ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return np . array ( [ off ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def eval ( self , feed_dict = None , session = None ) : <NEWLINE> <TAB> <NEWLINE> return _eval_using_default_session ( self , feed_dict , self . graph , session ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_fateman_poly_F_3 ( n , K ) : <NEWLINE> <TAB> <NEWLINE> u = dup_from_raw_dict ( { n + <NUMBER> : K . one } , K ) <NEWLINE> <NEWLINE> for i in range ( <NUMBER> , n - <NUMBER> ) : <NEWLINE> <TAB> u = dmp_add_term ( [ u ] , dmp_one ( i , K ) , n + <NUMBER> , i + <NUMBER> , K ) <NEWLINE> <NEWLINE> <UNTAB> v = dmp_add_term ( u , dmp_ground ( K ( <NUMBER> ) , n - <NUMBER> ) , <NUMBER> , n , K ) <NEWLINE> <NEWLINE> f = dmp_sqr ( <NEWLINE> dmp_add_term ( [ dmp_neg ( v , n - <NUMBER> , K ) ] , dmp_one ( n - <NUMBER> , K ) , n + <NUMBER> , n , K ) , n , K ) <NEWLINE> g = dmp_sqr ( dmp_add_term ( [ v ] , dmp_one ( n - <NUMBER> , K ) , n + <NUMBER> , n , K ) , n , K ) <NEWLINE> <NEWLINE> v = dmp_add_term ( u , dmp_one ( n - <NUMBER> , K ) , <NUMBER> , n - <NUMBER> , K ) <NEWLINE> <NEWLINE> h = dmp_sqr ( dmp_add_term ( [ v ] , dmp_one ( n - <NUMBER> , K ) , n + <NUMBER> , n , K ) , n , K ) <NEWLINE> <NEWLINE> return dmp_mul ( f , h , n , K ) , dmp_mul ( g , h , n , K ) , h <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def union_categoricals ( to_union , sort_categories = False , ignore_order = False ) : <NEWLINE> <TAB> <NEWLINE> from pandas import Index , Categorical , CategoricalIndex , Series <NEWLINE> from pandas . core . arrays . categorical import _recode_for_categories <NEWLINE> <NEWLINE> if len ( to_union ) == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> def _maybe_unwrap ( x ) : <NEWLINE> <TAB> if isinstance ( x , ( CategoricalIndex , Series ) ) : <NEWLINE> <TAB> return x . values <NEWLINE> <UNTAB> elif isinstance ( x , Categorical ) : <NEWLINE> <TAB> return x <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> to_union = [ _maybe_unwrap ( x ) for x in to_union ] <NEWLINE> first = to_union [ <NUMBER> ] <NEWLINE> <NEWLINE> if not all ( is_dtype_equal ( other . categories . dtype , first . categories . dtype ) <NEWLINE> for other in to_union [ <NUMBER> : ] ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> ordered = False <NEWLINE> if all ( first . is_dtype_equal ( other ) for other in to_union [ <NUMBER> : ] ) : <NEWLINE> <NEWLINE> <TAB> categories = first . categories <NEWLINE> ordered = first . ordered <NEWLINE> <NEWLINE> if all ( first . categories . equals ( other . categories ) <NEWLINE> for other in to_union [ <NUMBER> : ] ) : <NEWLINE> <TAB> new_codes = np . concatenate ( [ c . codes for c in to_union ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> codes = [ first . codes ] + [ _recode_for_categories ( other . codes , <NEWLINE> other . categories , <NEWLINE> first . categories ) <NEWLINE> for other in to_union [ <NUMBER> : ] ] <NEWLINE> new_codes = np . concatenate ( codes ) <NEWLINE> <NEWLINE> <UNTAB> if sort_categories and not ignore_order and ordered : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if sort_categories and not categories . is_monotonic_increasing : <NEWLINE> <TAB> categories = categories . sort_values ( ) <NEWLINE> indexer = categories . get_indexer ( first . categories ) <NEWLINE> <NEWLINE> from pandas . core . algorithms import take_1d <NEWLINE> new_codes = take_1d ( indexer , new_codes , fill_value = - <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> elif ignore_order or all ( not c . ordered for c in to_union ) : <NEWLINE> <NEWLINE> <TAB> cats = first . categories . append ( [ c . categories for c in to_union [ <NUMBER> : ] ] ) <NEWLINE> categories = Index ( cats . unique ( ) ) <NEWLINE> if sort_categories : <NEWLINE> <TAB> categories = categories . sort_values ( ) <NEWLINE> <NEWLINE> <UNTAB> new_codes = [ ] <NEWLINE> for c in to_union : <NEWLINE> <TAB> new_codes . append ( _recode_for_categories ( c . codes , c . categories , <NEWLINE> categories ) ) <NEWLINE> <UNTAB> new_codes = np . concatenate ( new_codes ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> if all ( c . ordered for c in to_union ) : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> raise TypeError ( msg ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if ignore_order : <NEWLINE> <TAB> ordered = False <NEWLINE> <NEWLINE> <UNTAB> return Categorical ( new_codes , categories = categories , ordered = ordered , <NEWLINE> fastpath = True ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def moment ( self , n , * args , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> args , loc , scale = self . _parse_args ( * args , ** kwds ) <NEWLINE> if not ( self . _argcheck ( * args ) and ( scale > <NUMBER> ) ) : <NEWLINE> <TAB> return nan <NEWLINE> <UNTAB> if ( floor ( n ) != n ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if ( n < <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> mu , mu2 , g1 , g2 = None , None , None , None <NEWLINE> if ( n > <NUMBER> ) and ( n < <NUMBER> ) : <NEWLINE> <TAB> if self . _stats_has_moments : <NEWLINE> <TAB> mdict = { <STRING> : { <NUMBER> : <STRING> , <NUMBER> : <STRING> , <NUMBER> : <STRING> , <NUMBER> : <STRING> } [ n ] } <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> mdict = { } <NEWLINE> <UNTAB> mu , mu2 , g1 , g2 = self . _stats ( * args , ** mdict ) <NEWLINE> <UNTAB> val = _moment_from_stats ( n , mu , mu2 , g1 , g2 , self . _munp , args ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if loc == <NUMBER> : <NEWLINE> <TAB> return scale ** n * val <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result = <NUMBER> <NEWLINE> fac = float ( scale ) / float ( loc ) <NEWLINE> for k in range ( n ) : <NEWLINE> <TAB> valk = _moment_from_stats ( k , mu , mu2 , g1 , g2 , self . _munp , args ) <NEWLINE> result += comb ( n , k , exact = True ) * ( fac ** k ) * valk <NEWLINE> <UNTAB> result += fac ** n * val <NEWLINE> return result * loc ** n <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def make_declare ( loop_orders , dtypes , sub ) : <NEWLINE> <TAB> <NEWLINE> decl = <STRING> <NEWLINE> for i , ( loop_order , dtype ) in enumerate ( zip ( loop_orders , dtypes ) ) : <NEWLINE> <TAB> var = sub [ <STRING> % i ] <NEWLINE> <NEWLINE> <NEWLINE> decl += " " " 
                 % ( d t y p e ) s *   % ( v a r ) s _ i t e r ; 
                 " " " % locals ( ) <NEWLINE> for j , value in enumerate ( loop_order ) : <NEWLINE> <TAB> if value != <STRING> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> decl += " " " 
                                 n p y _ i n t p   % ( v a r ) s _ n % ( v a l u e ) i ; 
                                 s s i z e _ t   % ( v a r ) s _ s t r i d e % ( v a l u e ) i ; 
                                 i n t   % ( v a r ) s _ j u m p % ( v a l u e ) i _ % ( j ) i ; 
                                 " " " % locals ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> decl += " " " 
                                 i n t   % ( v a r ) s _ j u m p % ( v a l u e ) s _ % ( j ) i ; 
                                 " " " % locals ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return decl <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def pts_to_prestep ( x , * args ) : <NEWLINE> <TAB> <NEWLINE> steps = np . zeros ( ( <NUMBER> + len ( args ) , max ( <NUMBER> * len ( x ) - <NUMBER> , <NUMBER> ) ) ) <NEWLINE> <NEWLINE> <NEWLINE> steps [ <NUMBER> , <NUMBER> : : <NUMBER> ] = x <NEWLINE> steps [ <NUMBER> , <NUMBER> : : <NUMBER> ] = steps [ <NUMBER> , <NUMBER> : - <NUMBER> : <NUMBER> ] <NEWLINE> steps [ <NUMBER> : , <NUMBER> : : <NUMBER> ] = args <NEWLINE> steps [ <NUMBER> : , <NUMBER> : : <NUMBER> ] = steps [ <NUMBER> : , <NUMBER> : : <NUMBER> ] <NEWLINE> return steps <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def rsolve ( self , v , tol = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if self . collapsed is not None : <NEWLINE> <TAB> return solve ( self . collapsed . T . conj ( ) , v ) <NEWLINE> <UNTAB> return LowRankMatrix . _solve ( v , np . conj ( self . alpha ) , self . ds , self . cs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def predict ( self , X ) : <NEWLINE> <TAB> <NEWLINE> if issparse ( X ) and self . metric == <STRING> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> ) <NEWLINE> <UNTAB> X = check_array ( X , accept_sparse = <STRING> ) <NEWLINE> <NEWLINE> neigh_dist , neigh_ind = self . kneighbors ( X ) <NEWLINE> <NEWLINE> weights = _get_weights ( neigh_dist , self . weights ) <NEWLINE> <NEWLINE> _y = self . _y <NEWLINE> if _y . ndim == <NUMBER> : <NEWLINE> <TAB> _y = _y . reshape ( ( - <NUMBER> , <NUMBER> ) ) <NEWLINE> <NEWLINE> <UNTAB> if weights is None : <NEWLINE> <TAB> y_pred = np . mean ( _y [ neigh_ind ] , axis = <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> y_pred = np . empty ( ( X . shape [ <NUMBER> ] , _y . shape [ <NUMBER> ] ) , dtype = np . float64 ) <NEWLINE> denom = np . sum ( weights , axis = <NUMBER> ) <NEWLINE> <NEWLINE> for j in range ( _y . shape [ <NUMBER> ] ) : <NEWLINE> <TAB> num = np . sum ( _y [ neigh_ind , j ] * weights , axis = <NUMBER> ) <NEWLINE> y_pred [ : , j ] = num / denom <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if self . _y . ndim == <NUMBER> : <NEWLINE> <TAB> y_pred = y_pred . ravel ( ) <NEWLINE> <NEWLINE> <UNTAB> return y_pred <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( None , <NEWLINE> <STRING> ) <NEWLINE> def make_parsing_export_strategy ( feature_columns , <NEWLINE> default_output_alternative_key = None , <NEWLINE> assets_extra = None , <NEWLINE> as_text = False , <NEWLINE> exports_to_keep = <NUMBER> , <NEWLINE> target_core = False , <NEWLINE> strip_default_attrs = None ) : <NEWLINE> <TAB> <NEWLINE> feature_spec = feature_column . create_feature_spec_for_parsing ( feature_columns ) <NEWLINE> if target_core : <NEWLINE> <TAB> serving_input_fn = ( <NEWLINE> core_export . build_parsing_serving_input_receiver_fn ( feature_spec ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> serving_input_fn = ( <NEWLINE> input_fn_utils . build_parsing_serving_input_fn ( feature_spec ) ) <NEWLINE> <UNTAB> return make_export_strategy ( <NEWLINE> serving_input_fn , <NEWLINE> default_output_alternative_key = default_output_alternative_key , <NEWLINE> assets_extra = assets_extra , <NEWLINE> as_text = as_text , <NEWLINE> exports_to_keep = exports_to_keep , <NEWLINE> strip_default_attrs = strip_default_attrs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _unescape_identifier ( self , value ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return value . replace ( self . escape_to_quote , self . escape_quote ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def predict_log_proba ( self , X ) : <NEWLINE> <TAB> <NEWLINE> return np . log ( self . predict_proba ( X ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def sequences_to_matrix ( self , sequences , mode = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if not self . num_words : <NEWLINE> <TAB> if self . word_index : <NEWLINE> <TAB> num_words = len ( self . word_index ) + <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> num_words = self . num_words <NEWLINE> <NEWLINE> <UNTAB> if mode == <STRING> and not self . document_count : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> x = np . zeros ( ( len ( sequences ) , num_words ) ) <NEWLINE> for i , seq in enumerate ( sequences ) : <NEWLINE> <TAB> if not seq : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> counts = defaultdict ( int ) <NEWLINE> for j in seq : <NEWLINE> <TAB> if j >= num_words : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> counts [ j ] += <NUMBER> <NEWLINE> <UNTAB> for j , c in list ( counts . items ( ) ) : <NEWLINE> <TAB> if mode == <STRING> : <NEWLINE> <TAB> x [ i ] [ j ] = c <NEWLINE> <UNTAB> elif mode == <STRING> : <NEWLINE> <TAB> x [ i ] [ j ] = c / len ( seq ) <NEWLINE> <UNTAB> elif mode == <STRING> : <NEWLINE> <TAB> x [ i ] [ j ] = <NUMBER> <NEWLINE> <UNTAB> elif mode == <STRING> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> tf = <NUMBER> + np . log ( c ) <NEWLINE> idf = np . log ( <NUMBER> + self . document_count / <NEWLINE> ( <NUMBER> + self . index_docs . get ( j , <NUMBER> ) ) ) <NEWLINE> x [ i ] [ j ] = tf * idf <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> , mode ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return x <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def c_literal ( self , data ) : <NEWLINE> <TAB> <NEWLINE> raise MethodNotDefined ( <STRING> , type ( self ) , <NEWLINE> self . __class__ . __name__ ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def inverse ( self , argindex = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return sech <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_diff ( f , m , K ) : <NEWLINE> <TAB> <NEWLINE> if m <= <NUMBER> : <NEWLINE> <TAB> return f <NEWLINE> <NEWLINE> <UNTAB> n = dup_degree ( f ) <NEWLINE> <NEWLINE> if n < m : <NEWLINE> <TAB> return [ ] <NEWLINE> <NEWLINE> <UNTAB> deriv = [ ] <NEWLINE> <NEWLINE> if m == <NUMBER> : <NEWLINE> <TAB> for coeff in f [ : - m ] : <NEWLINE> <TAB> deriv . append ( K ( n ) * coeff ) <NEWLINE> n -= <NUMBER> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for coeff in f [ : - m ] : <NEWLINE> <TAB> k = n <NEWLINE> <NEWLINE> for i in range ( n - <NUMBER> , n - m , - <NUMBER> ) : <NEWLINE> <TAB> k *= i <NEWLINE> <NEWLINE> <UNTAB> deriv . append ( K ( k ) * coeff ) <NEWLINE> n -= <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return dup_strip ( deriv ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def iirpeak ( w0 , Q ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return _design_notch_peak_filter ( w0 , Q , <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def roots_genlaguerre ( n , alpha , mu = False ) : <NEWLINE> <TAB> <NEWLINE> m = int ( n ) <NEWLINE> if n < <NUMBER> or n != m : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if alpha < - <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> mu0 = cephes . gamma ( alpha + <NUMBER> ) <NEWLINE> <NEWLINE> if m == <NUMBER> : <NEWLINE> <TAB> x = np . array ( [ alpha + <NUMBER> ] , <STRING> ) <NEWLINE> w = np . array ( [ mu0 ] , <STRING> ) <NEWLINE> if mu : <NEWLINE> <TAB> return x , w , mu0 <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return x , w <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> an_func = lambda k : <NUMBER> * k + alpha + <NUMBER> <NEWLINE> bn_func = lambda k : - np . sqrt ( k * ( k + alpha ) ) <NEWLINE> f = lambda n , x : cephes . eval_genlaguerre ( n , alpha , x ) <NEWLINE> df = lambda n , x : ( n * cephes . eval_genlaguerre ( n , alpha , x ) <NEWLINE> - ( n + alpha ) * cephes . eval_genlaguerre ( n - <NUMBER> , alpha , x ) ) / x <NEWLINE> return _gen_roots_and_weights ( m , mu0 , an_func , bn_func , f , df , False , mu ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def imagej_description_dict ( description ) : <NEWLINE> <TAB> <NEWLINE> def _bool ( val ) : <NEWLINE> <TAB> return { <STRING> : True , <STRING> : False } [ val . lower ( ) ] <NEWLINE> <NEWLINE> <UNTAB> _str = str if sys . version_info [ <NUMBER> ] < <NUMBER> else lambda x : str ( x , <STRING> ) <NEWLINE> result = { } <NEWLINE> for line in description . splitlines ( ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> key , val = line . split ( <STRING> ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> key = key . strip ( ) <NEWLINE> val = val . strip ( ) <NEWLINE> for dtype in ( int , float , _bool , _str ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> val = dtype ( val ) <NEWLINE> break <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> result [ _str ( key ) ] = val <NEWLINE> <UNTAB> if <STRING> not in result : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , x , y , dx = <NUMBER> , dy = <NUMBER> , grid = True ) : <NEWLINE> <TAB> <NEWLINE> x = np . asarray ( x ) <NEWLINE> y = np . asarray ( y ) <NEWLINE> <NEWLINE> tx , ty , c = self . tck [ : <NUMBER> ] <NEWLINE> kx , ky = self . degrees <NEWLINE> if grid : <NEWLINE> <TAB> if x . size == <NUMBER> or y . size == <NUMBER> : <NEWLINE> <TAB> return np . zeros ( ( x . size , y . size ) , dtype = self . tck [ <NUMBER> ] . dtype ) <NEWLINE> <NEWLINE> <UNTAB> if dx or dy : <NEWLINE> <TAB> z , ier = dfitpack . parder ( tx , ty , c , kx , ky , dx , dy , x , y ) <NEWLINE> if not ier == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % ier ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> z , ier = dfitpack . bispev ( tx , ty , c , kx , ky , x , y ) <NEWLINE> if not ier == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % ier ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> if x . shape != y . shape : <NEWLINE> <TAB> x , y = np . broadcast_arrays ( x , y ) <NEWLINE> <NEWLINE> <UNTAB> shape = x . shape <NEWLINE> x = x . ravel ( ) <NEWLINE> y = y . ravel ( ) <NEWLINE> <NEWLINE> if x . size == <NUMBER> or y . size == <NUMBER> : <NEWLINE> <TAB> return np . zeros ( shape , dtype = self . tck [ <NUMBER> ] . dtype ) <NEWLINE> <NEWLINE> <UNTAB> if dx or dy : <NEWLINE> <TAB> z , ier = dfitpack . pardeu ( tx , ty , c , kx , ky , dx , dy , x , y ) <NEWLINE> if not ier == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % ier ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> z , ier = dfitpack . bispeu ( tx , ty , c , kx , ky , x , y ) <NEWLINE> if not ier == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % ier ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> z = z . reshape ( shape ) <NEWLINE> <UNTAB> return z <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sparsemax ( logits , name = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> with ops . name_scope ( name , <STRING> , [ logits ] ) as name : <NEWLINE> <TAB> logits = ops . convert_to_tensor ( logits , name = <STRING> ) <NEWLINE> obs = array_ops . shape ( logits ) [ <NUMBER> ] <NEWLINE> dims = array_ops . shape ( logits ) [ <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> z = logits <NEWLINE> <NEWLINE> <NEWLINE> z_sorted , _ = nn . top_k ( z , k = dims ) <NEWLINE> <NEWLINE> <NEWLINE> z_cumsum = math_ops . cumsum ( z_sorted , axis = <NUMBER> ) <NEWLINE> k = math_ops . range ( <NEWLINE> <NUMBER> , math_ops . cast ( dims , logits . dtype ) + <NUMBER> , dtype = logits . dtype ) <NEWLINE> z_check = <NUMBER> + k * z_sorted > z_cumsum <NEWLINE> <NEWLINE> <NEWLINE> k_z = math_ops . reduce_sum ( math_ops . cast ( z_check , dtypes . int32 ) , axis = <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> k_z_safe = math_ops . maximum ( k_z , <NUMBER> ) <NEWLINE> indices = array_ops . stack ( [ math_ops . range ( <NUMBER> , obs ) , k_z_safe - <NUMBER> ] , axis = <NUMBER> ) <NEWLINE> tau_sum = array_ops . gather_nd ( z_cumsum , indices ) <NEWLINE> tau_z = ( tau_sum - <NUMBER> ) / math_ops . cast ( k_z , logits . dtype ) <NEWLINE> <NEWLINE> <NEWLINE> p = math_ops . maximum ( <NEWLINE> math_ops . cast ( <NUMBER> , logits . dtype ) , z - tau_z [ : , array_ops . newaxis ] ) <NEWLINE> <NEWLINE> p_safe = array_ops . where ( <NEWLINE> math_ops . logical_or ( <NEWLINE> math_ops . equal ( k_z , <NUMBER> ) , math_ops . is_nan ( z_cumsum [ : , - <NUMBER> ] ) ) , <NEWLINE> array_ops . fill ( [ obs , dims ] , math_ops . cast ( float ( <STRING> ) , logits . dtype ) ) , <NEWLINE> p ) <NEWLINE> <NEWLINE> return p_safe <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def stack_pages ( pages , memmap = False , tempdir = None , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if len ( pages ) == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if len ( pages ) == <NUMBER> : <NEWLINE> <TAB> return pages [ <NUMBER> ] . asarray ( memmap = memmap , * args , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> data0 = pages [ <NUMBER> ] . asarray ( * args , ** kwargs ) <NEWLINE> shape = ( len ( pages ) , ) + data0 . shape <NEWLINE> if memmap : <NEWLINE> <TAB> with tempfile . NamedTemporaryFile ( dir = tempdir ) as fh : <NEWLINE> <TAB> data = numpy . memmap ( fh , dtype = data0 . dtype , shape = shape ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> data = numpy . empty ( shape , dtype = data0 . dtype ) <NEWLINE> <NEWLINE> <UNTAB> data [ <NUMBER> ] = data0 <NEWLINE> if memmap : <NEWLINE> <TAB> data . flush ( ) <NEWLINE> <UNTAB> del data0 <NEWLINE> for i , page in enumerate ( pages [ <NUMBER> : ] ) : <NEWLINE> <TAB> data [ i + <NUMBER> ] = page . asarray ( * args , ** kwargs ) <NEWLINE> if memmap : <NEWLINE> <TAB> data . flush ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return data <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _render_module_flags ( self , module , flags , output_lines , prefix = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( module , str ) : <NEWLINE> <TAB> module = module . __name__ <NEWLINE> <UNTAB> output_lines . append ( <STRING> % ( prefix , module ) ) <NEWLINE> self . _render_flag_list ( flags , output_lines , prefix + <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def guess_byte_order ( self ) : <NEWLINE> <TAB> <NEWLINE> self . mat_stream . seek ( <NUMBER> ) <NEWLINE> mi = self . mat_stream . read ( <NUMBER> ) <NEWLINE> self . mat_stream . seek ( <NUMBER> ) <NEWLINE> return mi == <STRING> and <STRING> or <STRING> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_shape ( self , shape ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def local_response_norm ( input , size , alpha = <NUMBER> , beta = <NUMBER> , k = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> dim = input . dim ( ) <NEWLINE> if dim < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( dim ) ) <NEWLINE> <UNTAB> div = input . mul ( input ) . unsqueeze ( <NUMBER> ) <NEWLINE> if dim == <NUMBER> : <NEWLINE> <TAB> div = pad ( div , ( <NUMBER> , <NUMBER> , size // <NUMBER> , ( size - <NUMBER> ) // <NUMBER> ) ) <NEWLINE> div = avg_pool2d ( div , ( size , <NUMBER> ) , stride = <NUMBER> ) . squeeze ( <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> sizes = input . size ( ) <NEWLINE> div = div . view ( sizes [ <NUMBER> ] , <NUMBER> , sizes [ <NUMBER> ] , sizes [ <NUMBER> ] , - <NUMBER> ) <NEWLINE> div = pad ( div , ( <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , size // <NUMBER> , ( size - <NUMBER> ) // <NUMBER> ) ) <NEWLINE> div = avg_pool3d ( div , ( size , <NUMBER> , <NUMBER> ) , stride = <NUMBER> ) . squeeze ( <NUMBER> ) <NEWLINE> div = div . view ( sizes ) <NEWLINE> <UNTAB> div = div . mul ( alpha ) . add ( k ) . pow ( beta ) <NEWLINE> return input / div <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _validate_frequency ( cls , index , freq , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> inferred = index . inferred_freq <NEWLINE> if index . empty or inferred == freq . freqstr : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> on_freq = cls . _generate ( <NEWLINE> index [ <NUMBER> ] , None , len ( index ) , None , freq , ** kwargs ) <NEWLINE> if not np . array_equal ( index . asi8 , on_freq . asi8 ) : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> raise ValueError ( msg . format ( infer = inferred , passed = freq . freqstr ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def vfield ( symbols , domain , order = lex ) : <NEWLINE> <TAB> <NEWLINE> _field = FracField ( symbols , domain , order ) <NEWLINE> pollute ( [ sym . name for sym in _field . symbols ] , _field . gens ) <NEWLINE> return _field <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def asin_eager_fallback ( x , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , ( x , ) = _execute . args_to_matching_eager ( [ x ] , _ctx ) <NEWLINE> _inputs_flat = [ x ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> def number_strongly_connected_components ( G ) : <NEWLINE> <TAB> <NEWLINE> return sum ( <NUMBER> for scc in strongly_connected_components ( G ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit_transform ( self , y ) : <NEWLINE> <TAB> <NEWLINE> if self . classes is not None : <NEWLINE> <TAB> return self . fit ( y ) . transform ( y ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> class_mapping = defaultdict ( int ) <NEWLINE> class_mapping . default_factory = class_mapping . __len__ <NEWLINE> yt = self . _transform ( y , class_mapping ) <NEWLINE> <NEWLINE> <NEWLINE> tmp = sorted ( class_mapping , key = class_mapping . get ) <NEWLINE> <NEWLINE> <NEWLINE> dtype = np . int if all ( isinstance ( c , int ) for c in tmp ) else object <NEWLINE> class_mapping = np . empty ( len ( tmp ) , dtype = dtype ) <NEWLINE> class_mapping [ : ] = tmp <NEWLINE> self . classes_ , inverse = np . unique ( class_mapping , return_inverse = True ) <NEWLINE> <NEWLINE> yt . indices = np . array ( inverse [ yt . indices ] , dtype = yt . indices . dtype , <NEWLINE> copy = False ) <NEWLINE> <NEWLINE> if not self . sparse_output : <NEWLINE> <TAB> yt = yt . toarray ( ) <NEWLINE> <NEWLINE> <UNTAB> return yt <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_transform ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . dpi_transform + self . offset_transform <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _to_arrays ( data , columns , coerce_float = False , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( data , DataFrame ) : <NEWLINE> <TAB> if columns is not None : <NEWLINE> <TAB> arrays = [ data . _ixs ( i , axis = <NUMBER> ) . values <NEWLINE> for i , col in enumerate ( data . columns ) if col in columns ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> columns = data . columns <NEWLINE> arrays = [ data . _ixs ( i , axis = <NUMBER> ) . values for i in range ( len ( columns ) ) ] <NEWLINE> <NEWLINE> <UNTAB> return arrays , columns <NEWLINE> <NEWLINE> <UNTAB> if not len ( data ) : <NEWLINE> <TAB> if isinstance ( data , np . ndarray ) : <NEWLINE> <TAB> columns = data . dtype . names <NEWLINE> if columns is not None : <NEWLINE> <TAB> return [ [ ] ] * len ( columns ) , columns <NEWLINE> <UNTAB> <UNTAB> return [ ] , [ ] <NEWLINE> <UNTAB> if isinstance ( data [ <NUMBER> ] , ( list , tuple ) ) : <NEWLINE> <TAB> return _list_to_arrays ( data , columns , coerce_float = coerce_float , <NEWLINE> dtype = dtype ) <NEWLINE> <UNTAB> elif isinstance ( data [ <NUMBER> ] , collections . Mapping ) : <NEWLINE> <TAB> return _list_of_dict_to_arrays ( data , columns , <NEWLINE> coerce_float = coerce_float , dtype = dtype ) <NEWLINE> <UNTAB> elif isinstance ( data [ <NUMBER> ] , Series ) : <NEWLINE> <TAB> return _list_of_series_to_arrays ( data , columns , <NEWLINE> coerce_float = coerce_float , <NEWLINE> dtype = dtype ) <NEWLINE> <UNTAB> elif isinstance ( data [ <NUMBER> ] , Categorical ) : <NEWLINE> <TAB> if columns is None : <NEWLINE> <TAB> columns = com . _default_index ( len ( data ) ) <NEWLINE> <UNTAB> return data , columns <NEWLINE> <UNTAB> elif ( isinstance ( data , ( np . ndarray , Series , Index ) ) and <NEWLINE> data . dtype . names is not None ) : <NEWLINE> <NEWLINE> <TAB> columns = list ( data . dtype . names ) <NEWLINE> arrays = [ data [ k ] for k in columns ] <NEWLINE> return arrays , columns <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> data = lmap ( tuple , data ) <NEWLINE> return _list_to_arrays ( data , columns , coerce_float = coerce_float , <NEWLINE> dtype = dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def laggauss ( deg ) : <NEWLINE> <TAB> <NEWLINE> ideg = int ( deg ) <NEWLINE> if ideg != deg or ideg < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> c = np . array ( [ <NUMBER> ] * deg + [ <NUMBER> ] ) <NEWLINE> m = lagcompanion ( c ) <NEWLINE> x = la . eigvalsh ( m ) <NEWLINE> <NEWLINE> <NEWLINE> dy = lagval ( x , c ) <NEWLINE> df = lagval ( x , lagder ( c ) ) <NEWLINE> x -= dy / df <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> fm = lagval ( x , c [ <NUMBER> : ] ) <NEWLINE> fm /= np . abs ( fm ) . max ( ) <NEWLINE> df /= np . abs ( df ) . max ( ) <NEWLINE> w = <NUMBER> / ( fm * df ) <NEWLINE> <NEWLINE> <NEWLINE> w /= w . sum ( ) <NEWLINE> <NEWLINE> return x , w <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def press_zoom ( self , event ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if self . _ids_zoom != [ ] : <NEWLINE> <TAB> for zoom_id in self . _ids_zoom : <NEWLINE> <TAB> self . canvas . mpl_disconnect ( zoom_id ) <NEWLINE> <UNTAB> self . release ( event ) <NEWLINE> self . draw ( ) <NEWLINE> self . _xypress = None <NEWLINE> self . _button_pressed = None <NEWLINE> self . _ids_zoom = [ ] <NEWLINE> return <NEWLINE> <NEWLINE> <UNTAB> if event . button == <NUMBER> : <NEWLINE> <TAB> self . _button_pressed = <NUMBER> <NEWLINE> <UNTAB> elif event . button == <NUMBER> : <NEWLINE> <TAB> self . _button_pressed = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _button_pressed = None <NEWLINE> return <NEWLINE> <NEWLINE> <UNTAB> if self . _nav_stack ( ) is None : <NEWLINE> <NEWLINE> <TAB> self . push_current ( ) <NEWLINE> <NEWLINE> <UNTAB> x , y = event . x , event . y <NEWLINE> self . _xypress = [ ] <NEWLINE> for i , a in enumerate ( self . canvas . figure . get_axes ( ) ) : <NEWLINE> <TAB> if ( x is not None and y is not None and a . in_axes ( event ) and <NEWLINE> a . get_navigate ( ) and a . can_zoom ( ) ) : <NEWLINE> <TAB> self . _xypress . append ( ( x , y , a , i , a . _get_view ( ) ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> id1 = self . canvas . mpl_connect ( <STRING> , self . drag_zoom ) <NEWLINE> id2 = self . canvas . mpl_connect ( <STRING> , <NEWLINE> self . _switch_on_zoom_mode ) <NEWLINE> id3 = self . canvas . mpl_connect ( <STRING> , <NEWLINE> self . _switch_off_zoom_mode ) <NEWLINE> <NEWLINE> self . _ids_zoom = id1 , id2 , id3 <NEWLINE> self . _zoom_mode = event . key <NEWLINE> <NEWLINE> self . press ( event ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def query ( self ) : <NEWLINE> <TAB> <NEWLINE> res = cudart ( ) . cudaStreamQuery ( self ) <NEWLINE> if res == cudaStatus . ERROR_NOT_READY : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> check_error ( res ) <NEWLINE> return True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _coefficient_t ( p , t ) : <NEWLINE> <TAB> <NEWLINE> i , j = t <NEWLINE> R = p . ring <NEWLINE> expv1 = [ <NUMBER> ] * R . ngens <NEWLINE> expv1 [ i ] = j <NEWLINE> expv1 = tuple ( expv1 ) <NEWLINE> p1 = R ( <NUMBER> ) <NEWLINE> for expv in p : <NEWLINE> <TAB> if expv [ i ] == j : <NEWLINE> <TAB> p1 [ monomial_div ( expv , expv1 ) ] = p [ expv ] <NEWLINE> <UNTAB> <UNTAB> return p1 <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def relu ( x , alpha = <NUMBER> , max_value = None , threshold = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if alpha != <NUMBER> : <NEWLINE> <TAB> if max_value is None and threshold == <NUMBER> : <NEWLINE> <TAB> return nn . leaky_relu ( x , alpha = alpha ) <NEWLINE> <NEWLINE> <UNTAB> if threshold != <NUMBER> : <NEWLINE> <TAB> negative_part = nn . relu ( - x + threshold ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> negative_part = nn . relu ( - x ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> clip_max = max_value is not None <NEWLINE> <NEWLINE> if threshold != <NUMBER> : <NEWLINE> <NEWLINE> <TAB> x = x * math_ops . cast ( math_ops . greater ( x , threshold ) , floatx ( ) ) <NEWLINE> <UNTAB> elif max_value == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> x = nn . relu6 ( x ) <NEWLINE> clip_max = False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x = nn . relu ( x ) <NEWLINE> <NEWLINE> <UNTAB> if clip_max : <NEWLINE> <TAB> max_value = _to_tensor ( max_value , x . dtype . base_dtype ) <NEWLINE> zero = _to_tensor ( <NUMBER> , x . dtype . base_dtype ) <NEWLINE> x = clip_ops . clip_by_value ( x , zero , max_value ) <NEWLINE> <NEWLINE> <UNTAB> if alpha != <NUMBER> : <NEWLINE> <TAB> alpha = _to_tensor ( alpha , x . dtype . base_dtype ) <NEWLINE> x -= alpha * negative_part <NEWLINE> <UNTAB> return x <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_sympy ( self , element ) : <NEWLINE> <TAB> <NEWLINE> return Float ( element . real , self . dps ) + I * Float ( element . imag , self . dps ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def abstractmethod ( funcobj ) : <NEWLINE> <TAB> <NEWLINE> funcobj . __isabstractmethod__ = True <NEWLINE> return funcobj <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def equal ( x , y , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , x = x , y = y , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , x , y ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return equal_eager_fallback ( <NEWLINE> x , y , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pow ( self , rhs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if numpy . isscalar ( rhs ) : <NEWLINE> <TAB> return PowVarConst ( rhs ) . apply ( ( self , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> rhs = _preprocess_rhs ( self , rhs ) <NEWLINE> return PowVarVar ( ) . apply ( ( self , rhs ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def reshape_nd ( self , axes , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return self . apply ( <STRING> , axes = axes , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _scale_parameters ( self , trial ) : <NEWLINE> <TAB> <NEWLINE> return self . __scale_arg1 + ( trial - <NUMBER> ) * self . __scale_arg2 <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def reshape ( source , shape , pad = None , order = None ) : <NEWLINE> <TAB> <NEWLINE> return FunctionCall ( <NEWLINE> <STRING> , <NEWLINE> [ _printable ( source ) , _printable ( shape ) ] + <NEWLINE> ( [ _printable ( pad ) ] if pad else [ ] ) + <NEWLINE> ( [ _printable ( order ) ] if pad else [ ] ) <NEWLINE> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rundocs ( filename = None , raise_on_error = True ) : <NEWLINE> <TAB> <NEWLINE> from numpy . compat import npy_load_module <NEWLINE> import doctest <NEWLINE> if filename is None : <NEWLINE> <TAB> f = sys . _getframe ( <NUMBER> ) <NEWLINE> filename = f . f_globals [ <STRING> ] <NEWLINE> <UNTAB> name = os . path . splitext ( os . path . basename ( filename ) ) [ <NUMBER> ] <NEWLINE> m = npy_load_module ( name , filename ) <NEWLINE> <NEWLINE> tests = doctest . DocTestFinder ( ) . find ( m ) <NEWLINE> runner = doctest . DocTestRunner ( verbose = False ) <NEWLINE> <NEWLINE> msg = [ ] <NEWLINE> if raise_on_error : <NEWLINE> <TAB> out = lambda s : msg . append ( s ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> out = None <NEWLINE> <NEWLINE> <UNTAB> for test in tests : <NEWLINE> <TAB> runner . run ( test , out = out ) <NEWLINE> <NEWLINE> <UNTAB> if runner . failures > <NUMBER> and raise_on_error : <NEWLINE> <TAB> raise AssertionError ( <STRING> % <STRING> . join ( msg ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _set_dpi ( self , dpi , forward = True ) : <NEWLINE> <TAB> <NEWLINE> self . _dpi = dpi <NEWLINE> self . dpi_scale_trans . clear ( ) . scale ( dpi , dpi ) <NEWLINE> w , h = self . get_size_inches ( ) <NEWLINE> self . set_size_inches ( w , h , forward = forward ) <NEWLINE> self . callbacks . process ( <STRING> , self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def read_uic1tag ( fh , byteorder , dtype , count , plane_count = None ) : <NEWLINE> <TAB> <NEWLINE> assert dtype in ( <STRING> , <STRING> ) and byteorder == <STRING> <NEWLINE> result = { } <NEWLINE> if dtype == <STRING> : <NEWLINE> <NEWLINE> <TAB> values = fh . read_array ( <STRING> , <NUMBER> * count ) . reshape ( count , <NUMBER> ) <NEWLINE> result = { <STRING> : values [ : , <NUMBER> ] / values [ : , <NUMBER> ] } <NEWLINE> <UNTAB> elif plane_count : <NEWLINE> <TAB> for _ in range ( count ) : <NEWLINE> <TAB> tagid = struct . unpack ( <STRING> , fh . read ( <NUMBER> ) ) [ <NUMBER> ] <NEWLINE> if tagid in ( <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) : <NEWLINE> <NEWLINE> <TAB> fh . read ( <NUMBER> ) <NEWLINE> continue <NEWLINE> <UNTAB> name , value = read_uic_tag ( fh , tagid , plane_count , offset = True ) <NEWLINE> result [ name ] = value <NEWLINE> <UNTAB> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def log ( x ) : <NEWLINE> <TAB> <NEWLINE> np = import_module ( <STRING> ) <NEWLINE> if isinstance ( x , ( int , float ) ) : <NEWLINE> <TAB> if x <= <NUMBER> : <NEWLINE> <TAB> return interval ( - np . inf , np . inf , is_valid = False ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return interval ( np . log ( x ) ) <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( x , interval ) : <NEWLINE> <TAB> if not x . is_valid : <NEWLINE> <TAB> return interval ( - np . inf , np . inf , is_valid = x . is_valid ) <NEWLINE> <UNTAB> elif x . end <= <NUMBER> : <NEWLINE> <TAB> return interval ( - np . inf , np . inf , is_valid = False ) <NEWLINE> <UNTAB> elif x . start <= <NUMBER> : <NEWLINE> <TAB> return interval ( - np . inf , np . inf , is_valid = None ) <NEWLINE> <NEWLINE> <UNTAB> return interval ( np . log ( x . start ) , np . log ( x . end ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def project ( self , v ) : <NEWLINE> <TAB> <NEWLINE> return v * ( self . dot ( v ) / v . dot ( v ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def auc ( x , y , reorder = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> check_consistent_length ( x , y ) <NEWLINE> x = column_or_1d ( x ) <NEWLINE> y = column_or_1d ( y ) <NEWLINE> <NEWLINE> if x . shape [ <NUMBER> ] < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % x . shape ) <NEWLINE> <NEWLINE> <UNTAB> if reorder != <STRING> : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> , <NEWLINE> DeprecationWarning ) <NEWLINE> <NEWLINE> <UNTAB> direction = <NUMBER> <NEWLINE> if reorder is True : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> order = np . lexsort ( ( y , x ) ) <NEWLINE> x , y = x [ order ] , y [ order ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dx = np . diff ( x ) <NEWLINE> if np . any ( dx < <NUMBER> ) : <NEWLINE> <TAB> if np . all ( dx <= <NUMBER> ) : <NEWLINE> <TAB> direction = - <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( x ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> area = direction * np . trapz ( y , x ) <NEWLINE> if isinstance ( area , np . memmap ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> area = area . dtype . type ( area ) <NEWLINE> <UNTAB> return area <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ open_file ( <NUMBER> , mode = <STRING> ) <NEWLINE> def read_pajek ( path , encoding = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> lines = ( line . decode ( encoding ) for line in path ) <NEWLINE> return parse_pajek ( lines ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def where ( cond , a , b , use_numexpr = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if use_numexpr : <NEWLINE> <TAB> return _where ( cond , a , b ) <NEWLINE> <UNTAB> return _where_standard ( cond , a , b ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def imshow_collection ( ic , plugin = None , ** plugin_args ) : <NEWLINE> <TAB> <NEWLINE> return call_plugin ( <STRING> , ic , plugin = plugin , ** plugin_args ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def save_attributes_to_hdf5_group ( group , name , data ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> bad_attributes = [ x for x in data if len ( x ) > HDF5_OBJECT_HEADER_LIMIT ] <NEWLINE> <NEWLINE> <NEWLINE> if len ( bad_attributes ) > <NUMBER> : <NEWLINE> <TAB> raise RuntimeError ( <STRING> <NEWLINE> <STRING> <NEWLINE> % ( HDF5_OBJECT_HEADER_LIMIT , <NEWLINE> <STRING> . join ( [ x for x in bad_attributes ] ) ) ) <NEWLINE> <NEWLINE> <UNTAB> data_npy = np . asarray ( data ) <NEWLINE> <NEWLINE> num_chunks = <NUMBER> <NEWLINE> chunked_data = np . array_split ( data_npy , num_chunks ) <NEWLINE> <NEWLINE> <NEWLINE> while any ( map ( lambda x : x . nbytes > HDF5_OBJECT_HEADER_LIMIT , chunked_data ) ) : <NEWLINE> <TAB> num_chunks += <NUMBER> <NEWLINE> chunked_data = np . array_split ( data_npy , num_chunks ) <NEWLINE> <NEWLINE> <UNTAB> if num_chunks > <NUMBER> : <NEWLINE> <TAB> for chunk_id , chunk_data in enumerate ( chunked_data ) : <NEWLINE> <TAB> group . attrs [ <STRING> % ( name , chunk_id ) ] = chunk_data <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> group . attrs [ name ] = data <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def default_fused_linear_keys_renamer ( keys ) : <NEWLINE> <TAB> <NEWLINE> typ = type ( keys [ <NUMBER> ] ) <NEWLINE> if typ is str or typ is unicode : <NEWLINE> <TAB> names = [ key_split ( x ) for x in keys [ : <NUMBER> : - <NUMBER> ] ] <NEWLINE> names . append ( keys [ <NUMBER> ] ) <NEWLINE> return <STRING> . join ( names ) <NEWLINE> <UNTAB> elif ( typ is tuple and len ( keys [ <NUMBER> ] ) > <NUMBER> and <NEWLINE> isinstance ( keys [ <NUMBER> ] [ <NUMBER> ] , ( str , unicode ) ) ) : <NEWLINE> <TAB> names = [ key_split ( x ) for x in keys [ : <NUMBER> : - <NUMBER> ] ] <NEWLINE> names . append ( keys [ <NUMBER> ] [ <NUMBER> ] ) <NEWLINE> return ( <STRING> . join ( names ) , ) + keys [ <NUMBER> ] [ <NUMBER> : ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gf_irreducible_p ( f , p , K ) : <NEWLINE> <TAB> <NEWLINE> method = query ( <STRING> ) <NEWLINE> <NEWLINE> if method is not None : <NEWLINE> <TAB> irred = _irred_methods [ method ] ( f , p , K ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> irred = gf_irred_p_rabin ( f , p , K ) <NEWLINE> <NEWLINE> <UNTAB> return irred <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def inverse_laplace_transform ( F , s , t , plane = None , ** hints ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( F , MatrixBase ) and hasattr ( F , <STRING> ) : <NEWLINE> <TAB> return F . applyfunc ( lambda Fij : inverse_laplace_transform ( Fij , s , t , plane , ** hints ) ) <NEWLINE> <UNTAB> return InverseLaplaceTransform ( F , s , t , plane ) . doit ( ** hints ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def reload ( self , n = None ) : <NEWLINE> <TAB> <NEWLINE> self . data = np . empty_like ( self . data ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def has_key ( self , key ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return self . _parent . _has_key ( key ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_prem ( f , g , K ) : <NEWLINE> <TAB> <NEWLINE> df = dup_degree ( f ) <NEWLINE> dg = dup_degree ( g ) <NEWLINE> <NEWLINE> r , dr = f , df <NEWLINE> <NEWLINE> if not g : <NEWLINE> <TAB> raise ZeroDivisionError ( <STRING> ) <NEWLINE> <UNTAB> elif df < dg : <NEWLINE> <TAB> return r <NEWLINE> <NEWLINE> <UNTAB> N = df - dg + <NUMBER> <NEWLINE> lc_g = dup_LC ( g , K ) <NEWLINE> <NEWLINE> while True : <NEWLINE> <TAB> lc_r = dup_LC ( r , K ) <NEWLINE> j , N = dr - dg , N - <NUMBER> <NEWLINE> <NEWLINE> R = dup_mul_ground ( r , lc_g , K ) <NEWLINE> G = dup_mul_term ( g , lc_r , j , K ) <NEWLINE> r = dup_sub ( R , G , K ) <NEWLINE> <NEWLINE> _dr , dr = dr , dup_degree ( r ) <NEWLINE> <NEWLINE> if dr < dg : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> elif not ( dr < _dr ) : <NEWLINE> <TAB> raise PolynomialDivisionFailed ( f , g , K ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return dup_mul_ground ( r , lc_g ** N , K ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def between ( self , after , before , inc = False , count = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if self . _cache_complete : <NEWLINE> <TAB> gen = self . _cache <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> gen = self <NEWLINE> <UNTAB> started = False <NEWLINE> l = [ ] <NEWLINE> if inc : <NEWLINE> <TAB> for i in gen : <NEWLINE> <TAB> if i > before : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> elif not started : <NEWLINE> <TAB> if i >= after : <NEWLINE> <TAB> started = True <NEWLINE> l . append ( i ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> l . append ( i ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for i in gen : <NEWLINE> <TAB> if i >= before : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> elif not started : <NEWLINE> <TAB> if i > after : <NEWLINE> <TAB> started = True <NEWLINE> l . append ( i ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> l . append ( i ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return l <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def unindent_dict ( docdict ) : <NEWLINE> <TAB> <NEWLINE> can_dict = { } <NEWLINE> for name , dstr in docdict . items ( ) : <NEWLINE> <TAB> can_dict [ name ] = unindent_string ( dstr ) <NEWLINE> <UNTAB> return can_dict <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_axis_off ( self ) : <NEWLINE> <TAB> <NEWLINE> self . axison = False <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def init_code ( self ) : <NEWLINE> <TAB> <NEWLINE> ret = [ ] <NEWLINE> for x in [ y . type for y in self . variables ] + [ <NEWLINE> y . op for y in self . node_order ] : <NEWLINE> <TAB> try : <NEWLINE> <TAB> ret += x . c_init_code ( ) <NEWLINE> <UNTAB> except utils . MethodNotDefined : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> return utils . uniq ( ret ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def center ( a , width , fillchar = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> a_arr = numpy . asarray ( a ) <NEWLINE> width_arr = numpy . asarray ( width ) <NEWLINE> size = long ( numpy . max ( width_arr . flat ) ) <NEWLINE> if numpy . issubdtype ( a_arr . dtype , numpy . string_ ) : <NEWLINE> <TAB> fillchar = asbytes ( fillchar ) <NEWLINE> <UNTAB> return _vec_string ( <NEWLINE> a_arr , ( a_arr . dtype . type , size ) , <STRING> , ( width_arr , fillchar ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def doctest ( * paths , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> subprocess = kwargs . pop ( <STRING> , True ) <NEWLINE> rerun = kwargs . pop ( <STRING> , <NUMBER> ) <NEWLINE> <NEWLINE> print_counter = lambda i : ( print ( <STRING> % ( rerun - i ) ) <NEWLINE> if rerun - i else None ) <NEWLINE> <NEWLINE> if subprocess : <NEWLINE> <NEWLINE> <TAB> for i in range ( rerun , - <NUMBER> , - <NUMBER> ) : <NEWLINE> <TAB> print_counter ( i ) <NEWLINE> ret = run_in_subprocess_with_hash_randomization ( <STRING> , <NEWLINE> function_args = paths , function_kwargs = kwargs ) <NEWLINE> if ret is False : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> val = not bool ( ret ) <NEWLINE> <NEWLINE> if not val or i == <NUMBER> : <NEWLINE> <TAB> return val <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> for i in range ( rerun , - <NUMBER> , - <NUMBER> ) : <NEWLINE> <TAB> print_counter ( i ) <NEWLINE> val = not bool ( _doctest ( * paths , ** kwargs ) ) <NEWLINE> if not val or i == <NUMBER> : <NEWLINE> <TAB> return val <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def s_metric ( G , normalized = True ) : <NEWLINE> <TAB> <NEWLINE> if normalized : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return float ( sum ( [ G . degree ( u ) * G . degree ( v ) for ( u , v ) in G . edges ( ) ] ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_negatively_weighted ( G , edge = None , weight = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if edge is not None : <NEWLINE> <TAB> data = G . get_edge_data ( * edge ) <NEWLINE> if data is None : <NEWLINE> <TAB> msg = <STRING> . format ( edge ) <NEWLINE> raise nx . NetworkXError ( msg ) <NEWLINE> <UNTAB> return weight in data and data [ weight ] < <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> return any ( weight in data and data [ weight ] < <NUMBER> <NEWLINE> for u , v , data in G . edges ( data = True ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def per_image_standardization ( image ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( None , <STRING> , [ image ] ) as scope : <NEWLINE> <TAB> image = ops . convert_to_tensor ( image , name = <STRING> ) <NEWLINE> image = _AssertAtLeast3DImage ( image ) <NEWLINE> num_pixels = math_ops . reduce_prod ( array_ops . shape ( image ) [ - <NUMBER> : ] ) <NEWLINE> <NEWLINE> image = math_ops . cast ( image , dtype = dtypes . float32 ) <NEWLINE> image_mean = math_ops . reduce_mean ( image , axis = [ - <NUMBER> , - <NUMBER> , - <NUMBER> ] , keepdims = True ) <NEWLINE> <NEWLINE> variance = ( <NEWLINE> math_ops . reduce_mean ( <NEWLINE> math_ops . square ( image ) , axis = [ - <NUMBER> , - <NUMBER> , - <NUMBER> ] , keepdims = True ) - <NEWLINE> math_ops . square ( image_mean ) ) <NEWLINE> variance = gen_nn_ops . relu ( variance ) <NEWLINE> stddev = math_ops . sqrt ( variance ) <NEWLINE> <NEWLINE> <NEWLINE> min_stddev = math_ops . rsqrt ( math_ops . cast ( num_pixels , dtypes . float32 ) ) <NEWLINE> pixel_value_scale = math_ops . maximum ( stddev , min_stddev ) <NEWLINE> pixel_value_offset = image_mean <NEWLINE> <NEWLINE> image = math_ops . subtract ( image , pixel_value_offset ) <NEWLINE> image = math_ops . div ( image , pixel_value_scale , name = scope ) <NEWLINE> return image <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def add_newdoc ( place , obj , doc ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> new = getattr ( __import__ ( place , globals ( ) , { } , [ obj ] ) , obj ) <NEWLINE> if isinstance ( doc , str ) : <NEWLINE> <TAB> add_docstring ( new , doc . strip ( ) ) <NEWLINE> <UNTAB> elif isinstance ( doc , tuple ) : <NEWLINE> <TAB> add_docstring ( getattr ( new , doc [ <NUMBER> ] ) , doc [ <NUMBER> ] . strip ( ) ) <NEWLINE> <UNTAB> elif isinstance ( doc , list ) : <NEWLINE> <TAB> for val in doc : <NEWLINE> <TAB> add_docstring ( getattr ( new , val [ <NUMBER> ] ) , val [ <NUMBER> ] . strip ( ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> except Exception : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def remove ( self , value ) : <NEWLINE> <TAB> <NEWLINE> del self [ self . index ( value ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def leaders ( Z , T ) : <NEWLINE> <TAB> <NEWLINE> Z = np . asarray ( Z , order = <STRING> ) <NEWLINE> T = np . asarray ( T , order = <STRING> ) <NEWLINE> if type ( T ) != np . ndarray or T . dtype != <STRING> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> is_valid_linkage ( Z , throw = True , name = <STRING> ) <NEWLINE> if len ( T ) != Z . shape [ <NUMBER> ] + <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> Cl = np . unique ( T ) <NEWLINE> kk = len ( Cl ) <NEWLINE> L = np . zeros ( ( kk , ) , dtype = <STRING> ) <NEWLINE> M = np . zeros ( ( kk , ) , dtype = <STRING> ) <NEWLINE> n = Z . shape [ <NUMBER> ] + <NUMBER> <NEWLINE> [ Z , T ] = _copy_arrays_if_base_present ( [ Z , T ] ) <NEWLINE> s = _hierarchy . leaders ( Z , T , L , M , int ( kk ) , int ( n ) ) <NEWLINE> if s >= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( ( <STRING> <NEWLINE> <STRING> ) % s ) <NEWLINE> <UNTAB> return ( L , M ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_frame ( self , name = None ) : <NEWLINE> <TAB> <NEWLINE> if name is None : <NEWLINE> <TAB> df = self . _constructor_expanddim ( self ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> df = self . _constructor_expanddim ( { name : self } ) <NEWLINE> <NEWLINE> <UNTAB> return df <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ tc . returns ( LabeledTensor ) <NEWLINE> @ tc . accepts ( LabeledTensorLike , tc . Optional ( string_types ) ) <NEWLINE> def op ( labeled_tensor , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , default_name , [ labeled_tensor ] ) as scope : <NEWLINE> <TAB> labeled_tensor = convert_to_labeled_tensor ( labeled_tensor ) <NEWLINE> result_tensor = elementwise_function ( labeled_tensor . tensor , name = scope ) <NEWLINE> return LabeledTensor ( result_tensor , labeled_tensor . axes ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def std ( self , * args , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> kwds [ <STRING> ] = <STRING> <NEWLINE> res = sqrt ( self . stats ( * args , ** kwds ) ) <NEWLINE> return res <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit ( self , y ) : <NEWLINE> <TAB> <NEWLINE> y = column_or_1d ( y , warn = True ) <NEWLINE> self . classes_ = _encode ( y ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( None , <STRING> ) <NEWLINE> def create_global_step ( graph = None ) : <NEWLINE> <TAB> <NEWLINE> return training_util . create_global_step ( graph ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def cspline1d_eval ( cj , newx , dx = <NUMBER> , x0 = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> newx = ( asarray ( newx ) - x0 ) / float ( dx ) <NEWLINE> res = zeros_like ( newx , dtype = cj . dtype ) <NEWLINE> if res . size == <NUMBER> : <NEWLINE> <TAB> return res <NEWLINE> <UNTAB> N = len ( cj ) <NEWLINE> cond1 = newx < <NUMBER> <NEWLINE> cond2 = newx > ( N - <NUMBER> ) <NEWLINE> cond3 = ~ ( cond1 | cond2 ) <NEWLINE> <NEWLINE> res [ cond1 ] = cspline1d_eval ( cj , - newx [ cond1 ] ) <NEWLINE> res [ cond2 ] = cspline1d_eval ( cj , <NUMBER> * ( N - <NUMBER> ) - newx [ cond2 ] ) <NEWLINE> newx = newx [ cond3 ] <NEWLINE> if newx . size == <NUMBER> : <NEWLINE> <TAB> return res <NEWLINE> <UNTAB> result = zeros_like ( newx , dtype = cj . dtype ) <NEWLINE> jlower = floor ( newx - <NUMBER> ) . astype ( int ) + <NUMBER> <NEWLINE> for i in range ( <NUMBER> ) : <NEWLINE> <TAB> thisj = jlower + i <NEWLINE> indj = thisj . clip ( <NUMBER> , N - <NUMBER> ) <NEWLINE> result += cj [ indj ] * cubic ( newx - thisj ) <NEWLINE> <UNTAB> res [ cond3 ] = result <NEWLINE> return res <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def graph ( param , step = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> if not context . executing_eagerly ( ) and not isinstance ( param , ops . Tensor ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> % type ( param ) ) <NEWLINE> <UNTAB> writer = context . context ( ) . summary_writer_resource <NEWLINE> if writer is None : <NEWLINE> <TAB> return control_flow_ops . no_op ( ) <NEWLINE> <UNTAB> with ops . device ( <STRING> ) : <NEWLINE> <TAB> if isinstance ( param , ( ops . Graph , graph_pb2 . GraphDef ) ) : <NEWLINE> <TAB> tensor = ops . convert_to_tensor ( _serialize_graph ( param ) , dtypes . string ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> tensor = array_ops . identity ( param ) <NEWLINE> <UNTAB> return gen_summary_ops . write_graph_summary ( <NEWLINE> writer , _choose_step ( step ) , tensor , name = name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def print_nonzero ( self , symb = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> s = [ ] <NEWLINE> for i in range ( self . rows ) : <NEWLINE> <TAB> line = [ ] <NEWLINE> for j in range ( self . cols ) : <NEWLINE> <TAB> if self [ i , j ] == <NUMBER> : <NEWLINE> <TAB> line . append ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> line . append ( str ( symb ) ) <NEWLINE> <UNTAB> <UNTAB> s . append ( <STRING> % <STRING> . join ( line ) ) <NEWLINE> <UNTAB> print ( <STRING> . join ( s ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def margulis_gabber_galil_graph ( n , create_using = None ) : <NEWLINE> <TAB> <NEWLINE> G = nx . empty_graph ( <NUMBER> , create_using , default = nx . MultiGraph ) <NEWLINE> if G . is_directed ( ) or not G . is_multigraph ( ) : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise nx . NetworkXError ( msg ) <NEWLINE> <NEWLINE> <UNTAB> for ( x , y ) in itertools . product ( range ( n ) , repeat = <NUMBER> ) : <NEWLINE> <TAB> for ( u , v ) in ( ( ( x + <NUMBER> * y ) % n , y ) , ( ( x + ( <NUMBER> * y + <NUMBER> ) ) % n , y ) , <NEWLINE> ( x , ( y + <NUMBER> * x ) % n ) , ( x , ( y + ( <NUMBER> * x + <NUMBER> ) ) % n ) ) : <NEWLINE> <TAB> G . add_edge ( ( x , y ) , ( u , v ) ) <NEWLINE> <UNTAB> <UNTAB> G . graph [ <STRING> ] = <STRING> . format ( n ) <NEWLINE> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def trace_grad ( fn , args ) : <NEWLINE> <TAB> <NEWLINE> result , vjp = make_vjp ( fn ) ( * args ) <NEWLINE> return result , vjp <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def alpha_dropout ( input , p = <NUMBER> , training = False , inplace = False ) : <NEWLINE> <TAB> <NEWLINE> return _functions . dropout . AlphaDropout . apply ( input , p , training , inplace ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_joinstyle ( self , js ) : <NEWLINE> <TAB> <NEWLINE> if js in ( <STRING> , <STRING> , <STRING> ) : <NEWLINE> <TAB> self . _joinstyle = js <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % js ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _to_rgba_no_colorcycle ( c , alpha = None ) : <NEWLINE> <TAB> <NEWLINE> orig_c = c <NEWLINE> if isinstance ( c , str ) : <NEWLINE> <TAB> if c . lower ( ) == <STRING> : <NEWLINE> <TAB> return ( <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <NEWLINE> <TAB> c = _colors_full_map [ c . lower ( ) ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> if isinstance ( c , str ) : <NEWLINE> <NEWLINE> <TAB> match = re . match ( <STRING> , c ) <NEWLINE> if match : <NEWLINE> <TAB> return ( tuple ( int ( n , <NUMBER> ) / <NUMBER> <NEWLINE> for n in [ c [ <NUMBER> : <NUMBER> ] , c [ <NUMBER> : <NUMBER> ] , c [ <NUMBER> : <NUMBER> ] ] ) <NEWLINE> + ( alpha if alpha is not None else <NUMBER> , ) ) <NEWLINE> <NEWLINE> <UNTAB> match = re . match ( <STRING> , c ) <NEWLINE> if match : <NEWLINE> <TAB> color = [ int ( n , <NUMBER> ) / <NUMBER> <NEWLINE> for n in [ c [ <NUMBER> : <NUMBER> ] , c [ <NUMBER> : <NUMBER> ] , c [ <NUMBER> : <NUMBER> ] , c [ <NUMBER> : <NUMBER> ] ] ] <NEWLINE> if alpha is not None : <NEWLINE> <TAB> color [ - <NUMBER> ] = alpha <NEWLINE> <UNTAB> return tuple ( color ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> return ( float ( c ) , ) * <NUMBER> + ( alpha if alpha is not None else <NUMBER> , ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> raise ValueError ( <STRING> . format ( orig_c ) ) <NEWLINE> <NEWLINE> <UNTAB> c = np . array ( c ) <NEWLINE> if not np . can_cast ( c . dtype , float , <STRING> ) or c . ndim != <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( orig_c ) ) <NEWLINE> <NEWLINE> <UNTAB> c = tuple ( c . astype ( float ) ) <NEWLINE> if len ( c ) not in [ <NUMBER> , <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if len ( c ) == <NUMBER> and alpha is None : <NEWLINE> <TAB> alpha = <NUMBER> <NEWLINE> <UNTAB> if alpha is not None : <NEWLINE> <TAB> c = c [ : <NUMBER> ] + ( alpha , ) <NEWLINE> <UNTAB> if any ( elem < <NUMBER> or elem > <NUMBER> for elem in c ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return c <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def forward ( self , c , h , x ) : <NEWLINE> <TAB> <NEWLINE> if self . upward . W . data is None : <NEWLINE> <TAB> in_size = x . size // x . shape [ <NUMBER> ] <NEWLINE> with cuda . get_device_from_id ( self . _device_id ) : <NEWLINE> <TAB> self . upward . _initialize_params ( in_size ) <NEWLINE> self . _initialize_params ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> lstm_in = self . upward ( x ) <NEWLINE> if h is not None : <NEWLINE> <TAB> lstm_in += self . lateral ( h ) <NEWLINE> <UNTAB> if c is None : <NEWLINE> <TAB> xp = self . xp <NEWLINE> with cuda . get_device_from_id ( self . _device_id ) : <NEWLINE> <TAB> c = variable . Variable ( <NEWLINE> xp . zeros ( ( x . shape [ <NUMBER> ] , self . state_size ) , dtype = x . dtype ) ) <NEWLINE> <UNTAB> <UNTAB> return lstm . lstm ( c , lstm_in ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def savefig ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> kwargs . setdefault ( <STRING> , <STRING> ) <NEWLINE> self . fig . savefig ( * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _check_targets ( y_true , y_pred ) : <NEWLINE> <TAB> <NEWLINE> check_consistent_length ( y_true , y_pred ) <NEWLINE> type_true = type_of_target ( y_true ) <NEWLINE> type_pred = type_of_target ( y_pred ) <NEWLINE> <NEWLINE> y_type = set ( [ type_true , type_pred ] ) <NEWLINE> if y_type == set ( [ <STRING> , <STRING> ] ) : <NEWLINE> <TAB> y_type = set ( [ <STRING> ] ) <NEWLINE> <NEWLINE> <UNTAB> if len ( y_type ) > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( type_true , type_pred ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> y_type = y_type . pop ( ) <NEWLINE> <NEWLINE> <NEWLINE> if ( y_type not in [ <STRING> , <STRING> , <STRING> ] ) : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( y_type ) ) <NEWLINE> <NEWLINE> <UNTAB> if y_type in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> y_true = column_or_1d ( y_true ) <NEWLINE> y_pred = column_or_1d ( y_pred ) <NEWLINE> if y_type == <STRING> : <NEWLINE> <TAB> unique_values = np . union1d ( y_true , y_pred ) <NEWLINE> if len ( unique_values ) > <NUMBER> : <NEWLINE> <TAB> y_type = <STRING> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if y_type . startswith ( <STRING> ) : <NEWLINE> <TAB> y_true = csr_matrix ( y_true ) <NEWLINE> y_pred = csr_matrix ( y_pred ) <NEWLINE> y_type = <STRING> <NEWLINE> <NEWLINE> <UNTAB> return y_type , y_true , y_pred <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def blended_transform_factory ( x_transform , y_transform ) : <NEWLINE> <TAB> <NEWLINE> if ( isinstance ( x_transform , Affine2DBase ) <NEWLINE> and isinstance ( y_transform , Affine2DBase ) ) : <NEWLINE> <TAB> return BlendedAffine2D ( x_transform , y_transform ) <NEWLINE> <UNTAB> return BlendedGenericTransform ( x_transform , y_transform ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __str__ ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> output = [ ] <NEWLINE> h , m , s = [ None ] * <NUMBER> <NEWLINE> if self . _dtstart : <NEWLINE> <TAB> output . append ( self . _dtstart . strftime ( <STRING> ) ) <NEWLINE> h , m , s = self . _dtstart . timetuple ( ) [ <NUMBER> : <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> parts = [ <STRING> + FREQNAMES [ self . _freq ] ] <NEWLINE> if self . _interval != <NUMBER> : <NEWLINE> <TAB> parts . append ( <STRING> + str ( self . _interval ) ) <NEWLINE> <NEWLINE> <UNTAB> if self . _wkst : <NEWLINE> <TAB> parts . append ( <STRING> + repr ( weekday ( self . _wkst ) ) [ <NUMBER> : <NUMBER> ] ) <NEWLINE> <NEWLINE> <UNTAB> if self . _count is not None : <NEWLINE> <TAB> parts . append ( <STRING> + str ( self . _count ) ) <NEWLINE> <NEWLINE> <UNTAB> if self . _until : <NEWLINE> <TAB> parts . append ( self . _until . strftime ( <STRING> ) ) <NEWLINE> <NEWLINE> <UNTAB> if self . _original_rule . get ( <STRING> ) is not None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> original_rule = dict ( self . _original_rule ) <NEWLINE> wday_strings = [ ] <NEWLINE> for wday in original_rule [ <STRING> ] : <NEWLINE> <TAB> if wday . n : <NEWLINE> <TAB> wday_strings . append ( <STRING> . format ( <NEWLINE> n = wday . n , <NEWLINE> wday = repr ( wday ) [ <NUMBER> : <NUMBER> ] ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> wday_strings . append ( repr ( wday ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> original_rule [ <STRING> ] = wday_strings <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> original_rule = self . _original_rule <NEWLINE> <NEWLINE> <UNTAB> partfmt = <STRING> <NEWLINE> for name , key in [ ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) ] : <NEWLINE> <TAB> value = original_rule . get ( key ) <NEWLINE> if value : <NEWLINE> <TAB> parts . append ( partfmt . format ( name = name , vals = ( <STRING> . join ( str ( v ) <NEWLINE> for v in value ) ) ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> output . append ( <STRING> + <STRING> . join ( parts ) ) <NEWLINE> return <STRING> . join ( output ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _convert_to_color ( cls , color_spec ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> from openpyxl . styles import Color <NEWLINE> <NEWLINE> if isinstance ( color_spec , str ) : <NEWLINE> <TAB> return Color ( color_spec ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return Color ( ** color_spec ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tc . returns ( core . LabeledTensor ) <NEWLINE> @ tc . accepts ( core . LabeledTensorLike , <NEWLINE> tc . Mapping ( string_types , int ) , <NEWLINE> tc . Optional ( int ) , tc . Optional ( string_types ) ) <NEWLINE> def random_crop ( labeled_tensor , shape_map , seed = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ labeled_tensor ] ) as scope : <NEWLINE> <TAB> labeled_tensor = core . convert_to_labeled_tensor ( labeled_tensor ) <NEWLINE> <NEWLINE> for axis_name in shape_map : <NEWLINE> <TAB> if axis_name not in labeled_tensor . axes : <NEWLINE> <TAB> raise ValueError ( <STRING> % <NEWLINE> ( axis_name , labeled_tensor . axes ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> shape = [ ] <NEWLINE> axes = [ ] <NEWLINE> for axis in labeled_tensor . axes . values ( ) : <NEWLINE> <TAB> if axis . name in shape_map : <NEWLINE> <TAB> size = shape_map [ axis . name ] <NEWLINE> shape . append ( size ) <NEWLINE> <NEWLINE> axes . append ( ( axis . name , size ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> shape . append ( len ( axis ) ) <NEWLINE> axes . append ( axis ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> crop_op = random_ops . random_crop ( <NEWLINE> labeled_tensor . tensor , shape , seed = seed , name = scope ) <NEWLINE> <NEWLINE> return core . LabeledTensor ( crop_op , axes ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ _replace_by ( <STRING> ) <NEWLINE> def decode_lzw ( encoded ) : <NEWLINE> <TAB> <NEWLINE> len_encoded = len ( encoded ) <NEWLINE> bitcount_max = len_encoded * <NUMBER> <NEWLINE> unpack = struct . unpack <NEWLINE> <NEWLINE> if sys . version [ <NUMBER> ] == <STRING> : <NEWLINE> <TAB> newtable = [ chr ( i ) for i in range ( <NUMBER> ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> newtable = [ bytes ( [ i ] ) for i in range ( <NUMBER> ) ] <NEWLINE> <UNTAB> newtable . extend ( ( <NUMBER> , <NUMBER> ) ) <NEWLINE> <NEWLINE> def next_code ( ) : <NEWLINE> <TAB> <NEWLINE> start = bitcount // <NUMBER> <NEWLINE> s = encoded [ start : start + <NUMBER> ] <NEWLINE> try : <NEWLINE> <TAB> code = unpack ( <STRING> , s ) [ <NUMBER> ] <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> code = unpack ( <STRING> , s + <STRING> * ( <NUMBER> - len ( s ) ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> code <<= bitcount % <NUMBER> <NEWLINE> code &= mask <NEWLINE> return code >> shr <NEWLINE> <NEWLINE> <UNTAB> switchbitch = { <NEWLINE> <NUMBER> : ( <NUMBER> , <NUMBER> , int ( <NUMBER> * <STRING> + <STRING> * <NUMBER> , <NUMBER> ) ) , <NEWLINE> <NUMBER> : ( <NUMBER> , <NUMBER> , int ( <NUMBER> * <STRING> + <STRING> * <NUMBER> , <NUMBER> ) ) , <NEWLINE> <NUMBER> : ( <NUMBER> , <NUMBER> , int ( <NUMBER> * <STRING> + <STRING> * <NUMBER> , <NUMBER> ) ) , <NEWLINE> <NUMBER> : ( <NUMBER> , <NUMBER> , int ( <NUMBER> * <STRING> + <STRING> * <NUMBER> , <NUMBER> ) ) , } <NEWLINE> bitw , shr , mask = switchbitch [ <NUMBER> ] <NEWLINE> bitcount = <NUMBER> <NEWLINE> <NEWLINE> if len_encoded < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if next_code ( ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> code = <NUMBER> <NEWLINE> oldcode = <NUMBER> <NEWLINE> result = [ ] <NEWLINE> result_append = result . append <NEWLINE> while True : <NEWLINE> <TAB> code = next_code ( ) <NEWLINE> bitcount += bitw <NEWLINE> if code == <NUMBER> or bitcount >= bitcount_max : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> if code == <NUMBER> : <NEWLINE> <TAB> table = newtable [ : ] <NEWLINE> table_append = table . append <NEWLINE> lentable = <NUMBER> <NEWLINE> bitw , shr , mask = switchbitch [ <NUMBER> ] <NEWLINE> code = next_code ( ) <NEWLINE> bitcount += bitw <NEWLINE> if code == <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> result_append ( table [ code ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if code < lentable : <NEWLINE> <TAB> decoded = table [ code ] <NEWLINE> newcode = table [ oldcode ] + decoded [ : <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> newcode = table [ oldcode ] <NEWLINE> newcode += newcode [ : <NUMBER> ] <NEWLINE> decoded = newcode <NEWLINE> <UNTAB> result_append ( decoded ) <NEWLINE> table_append ( newcode ) <NEWLINE> lentable += <NUMBER> <NEWLINE> <UNTAB> oldcode = code <NEWLINE> if lentable in switchbitch : <NEWLINE> <TAB> bitw , shr , mask = switchbitch [ lentable ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if code != <NUMBER> : <NEWLINE> <TAB> warnings . warn ( <STRING> % code ) <NEWLINE> <NEWLINE> <UNTAB> return <STRING> . join ( result ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def ldl ( A , lower = True , hermitian = True , overwrite_a = False , check_finite = True ) : <NEWLINE> <TAB> <NEWLINE> a = atleast_2d ( _asarray_validated ( A , check_finite = check_finite ) ) <NEWLINE> if a . shape [ <NUMBER> ] != a . shape [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if a . size == <NUMBER> : <NEWLINE> <TAB> return empty_like ( a ) , empty_like ( a ) , np . array ( [ ] , dtype = int ) <NEWLINE> <NEWLINE> <UNTAB> n = a . shape [ <NUMBER> ] <NEWLINE> r_or_c = complex if iscomplexobj ( a ) else float <NEWLINE> <NEWLINE> <NEWLINE> if r_or_c is complex and hermitian : <NEWLINE> <TAB> s , sl = <STRING> , <STRING> <NEWLINE> if np . any ( imag ( diag ( a ) ) ) : <NEWLINE> <TAB> warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> , ComplexWarning , stacklevel = <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> s , sl = <STRING> , <STRING> <NEWLINE> <NEWLINE> <UNTAB> solver , solver_lwork = get_lapack_funcs ( ( s , sl ) , ( a , ) ) <NEWLINE> lwork = _compute_lwork ( solver_lwork , n , lower = lower ) <NEWLINE> ldu , piv , info = solver ( a , lwork = lwork , lower = lower , <NEWLINE> overwrite_a = overwrite_a ) <NEWLINE> if info < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( s . upper ( ) , - info ) ) <NEWLINE> <NEWLINE> <UNTAB> swap_arr , pivot_arr = _ldl_sanitize_ipiv ( piv , lower = lower ) <NEWLINE> d , lu = _ldl_get_d_and_l ( ldu , pivot_arr , lower = lower , hermitian = hermitian ) <NEWLINE> lu , perm = _ldl_construct_tri_factor ( lu , swap_arr , pivot_arr , lower = lower ) <NEWLINE> <NEWLINE> return lu , d , perm <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def convert_values ( self ) : <NEWLINE> <TAB> <NEWLINE> def stringify ( value ) : <NEWLINE> <TAB> if self . encoding is not None : <NEWLINE> <TAB> encoder = partial ( pprint_thing_encoded , <NEWLINE> encoding = self . encoding ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> encoder = pprint_thing <NEWLINE> <UNTAB> return encoder ( value ) <NEWLINE> <NEWLINE> <UNTAB> lhs , rhs = self . lhs , self . rhs <NEWLINE> <NEWLINE> if is_term ( lhs ) and lhs . is_datetime and is_term ( rhs ) and rhs . is_scalar : <NEWLINE> <TAB> v = rhs . value <NEWLINE> if isinstance ( v , ( int , float ) ) : <NEWLINE> <TAB> v = stringify ( v ) <NEWLINE> <UNTAB> v = pd . Timestamp ( _ensure_decoded ( v ) ) <NEWLINE> if v . tz is not None : <NEWLINE> <TAB> v = v . tz_convert ( <STRING> ) <NEWLINE> <UNTAB> self . rhs . update ( v ) <NEWLINE> <NEWLINE> <UNTAB> if is_term ( rhs ) and rhs . is_datetime and is_term ( lhs ) and lhs . is_scalar : <NEWLINE> <TAB> v = lhs . value <NEWLINE> if isinstance ( v , ( int , float ) ) : <NEWLINE> <TAB> v = stringify ( v ) <NEWLINE> <UNTAB> v = pd . Timestamp ( _ensure_decoded ( v ) ) <NEWLINE> if v . tz is not None : <NEWLINE> <TAB> v = v . tz_convert ( <STRING> ) <NEWLINE> <UNTAB> self . lhs . update ( v ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _raw_fft ( x , n , axis , direction , overwrite_x , work_function ) : <NEWLINE> <TAB> <NEWLINE> if n is None : <NEWLINE> <TAB> n = x . shape [ axis ] <NEWLINE> <UNTAB> elif n != x . shape [ axis ] : <NEWLINE> <TAB> x , copy_made = _fix_shape ( x , n , axis ) <NEWLINE> overwrite_x = overwrite_x or copy_made <NEWLINE> <NEWLINE> <UNTAB> if n < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % n ) <NEWLINE> <NEWLINE> <UNTAB> if axis == - <NUMBER> or axis == len ( x . shape ) - <NUMBER> : <NEWLINE> <TAB> r = work_function ( x , n , direction , overwrite_x = overwrite_x ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x = swapaxes ( x , axis , - <NUMBER> ) <NEWLINE> r = work_function ( x , n , direction , overwrite_x = overwrite_x ) <NEWLINE> r = swapaxes ( r , axis , - <NUMBER> ) <NEWLINE> <UNTAB> return r <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_or_add_value_number ( self , value ) : <NEWLINE> <TAB> <NEWLINE> nvalues = len ( self . value_numbers ) <NEWLINE> value_number = self . value_numbers . setdefault ( value , nvalues ) <NEWLINE> if value_number == nvalues : <NEWLINE> <TAB> self . value_number_to_value . append ( value ) <NEWLINE> self . arg_to_funcset . append ( OrderedSet ( ) ) <NEWLINE> <UNTAB> return value_number <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _arg_slen ( dvi , delta ) : <NEWLINE> <TAB> <NEWLINE> if delta == <NUMBER> : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> return dvi . _arg ( delta , True ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _try_all ( image , methods = None , figsize = None , num_cols = <NUMBER> , verbose = True ) : <NEWLINE> <TAB> <NEWLINE> from matplotlib import pyplot as plt <NEWLINE> <NEWLINE> num_rows = math . ceil ( ( len ( methods ) + <NUMBER> ) / num_cols ) <NEWLINE> num_rows = int ( num_rows ) <NEWLINE> fig , ax = plt . subplots ( num_rows , num_cols , figsize = figsize , <NEWLINE> sharex = True , sharey = True ) <NEWLINE> ax = ax . ravel ( ) <NEWLINE> <NEWLINE> ax [ <NUMBER> ] . imshow ( image , cmap = plt . cm . gray ) <NEWLINE> ax [ <NUMBER> ] . set_title ( <STRING> ) <NEWLINE> <NEWLINE> i = <NUMBER> <NEWLINE> for name , func in methods . items ( ) : <NEWLINE> <TAB> ax [ i ] . imshow ( func ( image ) , cmap = plt . cm . gray ) <NEWLINE> ax [ i ] . set_title ( name ) <NEWLINE> i += <NUMBER> <NEWLINE> if verbose : <NEWLINE> <TAB> print ( func . __orifunc__ ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for a in ax : <NEWLINE> <TAB> a . axis ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> fig . tight_layout ( ) <NEWLINE> return fig , ax <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def assert_is_compatible_with ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if not self . is_compatible_with ( other ) : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( self , other ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add ( self , layer ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( layer , Layer ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> + str ( layer ) ) <NEWLINE> <UNTAB> self . built = False <NEWLINE> if not self . _layers : <NEWLINE> <TAB> set_inputs = False <NEWLINE> <NEWLINE> if not isinstance ( layer , InputLayer ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> first_layer = layer <NEWLINE> if isinstance ( layer , ( Model , Sequential ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if not layer . layers : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> first_layer = layer . layers [ <NUMBER> ] <NEWLINE> while isinstance ( first_layer , ( Model , Sequential ) ) : <NEWLINE> <TAB> first_layer = first_layer . layers [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if hasattr ( first_layer , <STRING> ) : <NEWLINE> <TAB> batch_shape = first_layer . batch_input_shape <NEWLINE> dtype = first_layer . dtype <NEWLINE> <NEWLINE> x = Input ( <NEWLINE> batch_shape = batch_shape , <NEWLINE> dtype = dtype , <NEWLINE> name = layer . name + <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> layer ( x ) <NEWLINE> set_inputs = True <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> assert len ( layer . _inbound_nodes [ - <NUMBER> ] . output_tensors ) == <NUMBER> <NEWLINE> set_inputs = True <NEWLINE> <NEWLINE> <UNTAB> if set_inputs : <NEWLINE> <TAB> if len ( layer . _inbound_nodes [ - <NUMBER> ] . output_tensors ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> self . outputs = [ layer . _inbound_nodes [ - <NUMBER> ] . output_tensors [ <NUMBER> ] ] <NEWLINE> self . inputs = network . get_source_inputs ( self . outputs [ <NUMBER> ] ) <NEWLINE> <UNTAB> <UNTAB> elif self . outputs : <NEWLINE> <TAB> output_tensor = layer ( self . outputs [ <NUMBER> ] ) <NEWLINE> if isinstance ( output_tensor , list ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> self . outputs = [ output_tensor ] <NEWLINE> <UNTAB> if self . inputs : <NEWLINE> <TAB> self . build ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _layers . append ( layer ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __unicode__ ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> parened = ( <STRING> . format ( pprint_thing ( opr ) ) <NEWLINE> for opr in self . operands ) <NEWLINE> return pprint_thing ( <STRING> . format ( self . op ) . join ( parened ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _masked_rec_array_to_mgr ( data , index , columns , dtype , copy ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> fill_value = data . fill_value <NEWLINE> fdata = ma . getdata ( data ) <NEWLINE> if index is None : <NEWLINE> <TAB> index = _get_names_from_index ( fdata ) <NEWLINE> if index is None : <NEWLINE> <TAB> index = com . _default_index ( len ( data ) ) <NEWLINE> <UNTAB> <UNTAB> index = _ensure_index ( index ) <NEWLINE> <NEWLINE> if columns is not None : <NEWLINE> <TAB> columns = _ensure_index ( columns ) <NEWLINE> <UNTAB> arrays , arr_columns = _to_arrays ( fdata , columns ) <NEWLINE> <NEWLINE> <NEWLINE> new_arrays = [ ] <NEWLINE> for fv , arr , col in zip ( fill_value , arrays , arr_columns ) : <NEWLINE> <TAB> mask = ma . getmaskarray ( data [ col ] ) <NEWLINE> if mask . any ( ) : <NEWLINE> <TAB> arr , fv = maybe_upcast ( arr , fill_value = fv , copy = True ) <NEWLINE> arr [ mask ] = fv <NEWLINE> <UNTAB> new_arrays . append ( arr ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> arrays , arr_columns = _reorder_arrays ( new_arrays , arr_columns , columns ) <NEWLINE> if columns is None : <NEWLINE> <TAB> columns = arr_columns <NEWLINE> <NEWLINE> <UNTAB> mgr = _arrays_to_mgr ( arrays , arr_columns , index , columns ) <NEWLINE> <NEWLINE> if copy : <NEWLINE> <TAB> mgr = mgr . copy ( ) <NEWLINE> <UNTAB> return mgr <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def op ( self , op_id ) : <NEWLINE> <TAB> <NEWLINE> return self . _ops [ op_id ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> def powerlaw_cluster_graph ( n , m , p , seed = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if m < <NUMBER> or n < m : <NEWLINE> <TAB> raise nx . NetworkXError ( <NEWLINE> <STRING> % ( m , n ) ) <NEWLINE> <NEWLINE> <UNTAB> if p > <NUMBER> or p < <NUMBER> : <NEWLINE> <TAB> raise nx . NetworkXError ( <NEWLINE> <STRING> % ( p ) ) <NEWLINE> <NEWLINE> <UNTAB> G = empty_graph ( m ) <NEWLINE> repeated_nodes = list ( G . nodes ( ) ) <NEWLINE> <NEWLINE> source = m <NEWLINE> while source < n : <NEWLINE> <TAB> possible_targets = _random_subset ( repeated_nodes , m , seed ) <NEWLINE> <NEWLINE> target = possible_targets . pop ( ) <NEWLINE> G . add_edge ( source , target ) <NEWLINE> repeated_nodes . append ( target ) <NEWLINE> count = <NUMBER> <NEWLINE> while count < m : <NEWLINE> <TAB> if seed . random ( ) < p : <NEWLINE> <TAB> neighborhood = [ nbr for nbr in G . neighbors ( target ) <NEWLINE> if not G . has_edge ( source , nbr ) <NEWLINE> and not nbr == source ] <NEWLINE> if neighborhood : <NEWLINE> <TAB> nbr = seed . choice ( neighborhood ) <NEWLINE> G . add_edge ( source , nbr ) <NEWLINE> repeated_nodes . append ( nbr ) <NEWLINE> count = count + <NUMBER> <NEWLINE> continue <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> target = possible_targets . pop ( ) <NEWLINE> G . add_edge ( source , target ) <NEWLINE> repeated_nodes . append ( target ) <NEWLINE> count = count + <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> repeated_nodes . extend ( [ source ] * m ) <NEWLINE> source += <NUMBER> <NEWLINE> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dup_resultant ( f , g , K , includePRS = False ) : <NEWLINE> <TAB> <NEWLINE> if includePRS : <NEWLINE> <TAB> return dup_prs_resultant ( f , g , K ) <NEWLINE> <UNTAB> return dup_prs_resultant ( f , g , K ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def on_clicked ( self , func ) : <NEWLINE> <TAB> <NEWLINE> cid = self . cnt <NEWLINE> self . observers [ cid ] = func <NEWLINE> self . cnt += <NUMBER> <NEWLINE> return cid <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_view_names ( self , schema = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return self . dialect . get_view_names ( self . bind , schema , <NEWLINE> info_cache = self . info_cache ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def preflow_push_impl ( G , s , t , capacity , residual , global_relabel_freq , <NEWLINE> value_only ) : <NEWLINE> <TAB> <NEWLINE> if s not in G : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> % str ( s ) ) <NEWLINE> <UNTAB> if t not in G : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> % str ( t ) ) <NEWLINE> <UNTAB> if s == t : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if global_relabel_freq is None : <NEWLINE> <TAB> global_relabel_freq = <NUMBER> <NEWLINE> <UNTAB> if global_relabel_freq < <NUMBER> : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if residual is None : <NEWLINE> <TAB> R = build_residual_network ( G , capacity ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> R = residual <NEWLINE> <NEWLINE> <UNTAB> detect_unboundedness ( R , s , t ) <NEWLINE> <NEWLINE> R_nodes = R . nodes <NEWLINE> R_pred = R . pred <NEWLINE> R_succ = R . succ <NEWLINE> <NEWLINE> <NEWLINE> for u in R : <NEWLINE> <TAB> R_nodes [ u ] [ <STRING> ] = <NUMBER> <NEWLINE> for e in R_succ [ u ] . values ( ) : <NEWLINE> <TAB> e [ <STRING> ] = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def reverse_bfs ( src ) : <NEWLINE> <TAB> <NEWLINE> heights = { src : <NUMBER> } <NEWLINE> q = deque ( [ ( src , <NUMBER> ) ] ) <NEWLINE> while q : <NEWLINE> <TAB> u , height = q . popleft ( ) <NEWLINE> height += <NUMBER> <NEWLINE> for v , attr in R_pred [ u ] . items ( ) : <NEWLINE> <TAB> if v not in heights and attr [ <STRING> ] < attr [ <STRING> ] : <NEWLINE> <TAB> heights [ v ] = height <NEWLINE> q . append ( ( v , height ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return heights <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> heights = reverse_bfs ( t ) <NEWLINE> <NEWLINE> if s not in heights : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> R . graph [ <STRING> ] = <NUMBER> <NEWLINE> return R <NEWLINE> <NEWLINE> <UNTAB> n = len ( R ) <NEWLINE> <NEWLINE> <NEWLINE> max_height = max ( heights [ u ] for u in heights if u != s ) <NEWLINE> heights [ s ] = n <NEWLINE> <NEWLINE> grt = GlobalRelabelThreshold ( n , R . size ( ) , global_relabel_freq ) <NEWLINE> <NEWLINE> <NEWLINE> for u in R : <NEWLINE> <TAB> R_nodes [ u ] [ <STRING> ] = heights [ u ] if u in heights else n + <NUMBER> <NEWLINE> R_nodes [ u ] [ <STRING> ] = CurrentEdge ( R_succ [ u ] ) <NEWLINE> <NEWLINE> <UNTAB> def push ( u , v , flow ) : <NEWLINE> <TAB> <NEWLINE> R_succ [ u ] [ v ] [ <STRING> ] += flow <NEWLINE> R_succ [ v ] [ u ] [ <STRING> ] -= flow <NEWLINE> R_nodes [ u ] [ <STRING> ] -= flow <NEWLINE> R_nodes [ v ] [ <STRING> ] += flow <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for u , attr in R_succ [ s ] . items ( ) : <NEWLINE> <TAB> flow = attr [ <STRING> ] <NEWLINE> if flow > <NUMBER> : <NEWLINE> <TAB> push ( s , u , flow ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> levels = [ Level ( ) for i in range ( <NUMBER> * n ) ] <NEWLINE> for u in R : <NEWLINE> <TAB> if u != s and u != t : <NEWLINE> <TAB> level = levels [ R_nodes [ u ] [ <STRING> ] ] <NEWLINE> if R_nodes [ u ] [ <STRING> ] > <NUMBER> : <NEWLINE> <TAB> level . active . add ( u ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> level . inactive . add ( u ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> def activate ( v ) : <NEWLINE> <TAB> <NEWLINE> if v != s and v != t : <NEWLINE> <TAB> level = levels [ R_nodes [ v ] [ <STRING> ] ] <NEWLINE> if v in level . inactive : <NEWLINE> <TAB> level . inactive . remove ( v ) <NEWLINE> level . active . add ( v ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> def relabel ( u ) : <NEWLINE> <TAB> <NEWLINE> grt . add_work ( len ( R_succ [ u ] ) ) <NEWLINE> return min ( R_nodes [ v ] [ <STRING> ] for v , attr in R_succ [ u ] . items ( ) <NEWLINE> if attr [ <STRING> ] < attr [ <STRING> ] ) + <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> def discharge ( u , is_phase1 ) : <NEWLINE> <TAB> <NEWLINE> height = R_nodes [ u ] [ <STRING> ] <NEWLINE> curr_edge = R_nodes [ u ] [ <STRING> ] <NEWLINE> <NEWLINE> <NEWLINE> next_height = height <NEWLINE> levels [ height ] . active . remove ( u ) <NEWLINE> while True : <NEWLINE> <TAB> v , attr = curr_edge . get ( ) <NEWLINE> if ( height == R_nodes [ v ] [ <STRING> ] + <NUMBER> and <NEWLINE> attr [ <STRING> ] < attr [ <STRING> ] ) : <NEWLINE> <TAB> flow = min ( R_nodes [ u ] [ <STRING> ] , <NEWLINE> attr [ <STRING> ] - attr [ <STRING> ] ) <NEWLINE> push ( u , v , flow ) <NEWLINE> activate ( v ) <NEWLINE> if R_nodes [ u ] [ <STRING> ] == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> levels [ height ] . inactive . add ( u ) <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> try : <NEWLINE> <TAB> curr_edge . move_to_next ( ) <NEWLINE> <UNTAB> except StopIteration : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> height = relabel ( u ) <NEWLINE> if is_phase1 and height >= n - <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> levels [ height ] . active . add ( u ) <NEWLINE> break <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> next_height = height <NEWLINE> <UNTAB> <UNTAB> R_nodes [ u ] [ <STRING> ] = height <NEWLINE> return next_height <NEWLINE> <NEWLINE> <UNTAB> def gap_heuristic ( height ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> for level in islice ( levels , height + <NUMBER> , max_height + <NUMBER> ) : <NEWLINE> <TAB> for u in level . active : <NEWLINE> <TAB> R_nodes [ u ] [ <STRING> ] = n + <NUMBER> <NEWLINE> <UNTAB> for u in level . inactive : <NEWLINE> <TAB> R_nodes [ u ] [ <STRING> ] = n + <NUMBER> <NEWLINE> <UNTAB> levels [ n + <NUMBER> ] . active . update ( level . active ) <NEWLINE> level . active . clear ( ) <NEWLINE> levels [ n + <NUMBER> ] . inactive . update ( level . inactive ) <NEWLINE> level . inactive . clear ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def global_relabel ( from_sink ) : <NEWLINE> <TAB> <NEWLINE> src = t if from_sink else s <NEWLINE> heights = reverse_bfs ( src ) <NEWLINE> if not from_sink : <NEWLINE> <NEWLINE> <TAB> del heights [ t ] <NEWLINE> <UNTAB> max_height = max ( heights . values ( ) ) <NEWLINE> if from_sink : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> for u in R : <NEWLINE> <TAB> if u not in heights and R_nodes [ u ] [ <STRING> ] < n : <NEWLINE> <TAB> heights [ u ] = n + <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> for u in heights : <NEWLINE> <TAB> heights [ u ] += n <NEWLINE> <UNTAB> max_height += n <NEWLINE> <UNTAB> del heights [ src ] <NEWLINE> for u , new_height in heights . items ( ) : <NEWLINE> <TAB> old_height = R_nodes [ u ] [ <STRING> ] <NEWLINE> if new_height != old_height : <NEWLINE> <TAB> if u in levels [ old_height ] . active : <NEWLINE> <TAB> levels [ old_height ] . active . remove ( u ) <NEWLINE> levels [ new_height ] . active . add ( u ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> levels [ old_height ] . inactive . remove ( u ) <NEWLINE> levels [ new_height ] . inactive . add ( u ) <NEWLINE> <UNTAB> R_nodes [ u ] [ <STRING> ] = new_height <NEWLINE> <UNTAB> <UNTAB> return max_height <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> height = max_height <NEWLINE> while height > <NUMBER> : <NEWLINE> <NEWLINE> <TAB> while True : <NEWLINE> <TAB> level = levels [ height ] <NEWLINE> if not level . active : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> height -= <NUMBER> <NEWLINE> break <NEWLINE> <NEWLINE> <UNTAB> old_height = height <NEWLINE> old_level = level <NEWLINE> u = arbitrary_element ( level . active ) <NEWLINE> height = discharge ( u , True ) <NEWLINE> if grt . is_reached ( ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> height = global_relabel ( True ) <NEWLINE> max_height = height <NEWLINE> grt . clear_work ( ) <NEWLINE> <UNTAB> elif not old_level . active and not old_level . inactive : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> gap_heuristic ( old_height ) <NEWLINE> height = old_height - <NUMBER> <NEWLINE> max_height = height <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> max_height = max ( max_height , height ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if value_only : <NEWLINE> <TAB> R . graph [ <STRING> ] = R_nodes [ t ] [ <STRING> ] <NEWLINE> return R <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> height = global_relabel ( False ) <NEWLINE> grt . clear_work ( ) <NEWLINE> <NEWLINE> <NEWLINE> while height > n : <NEWLINE> <NEWLINE> <TAB> while True : <NEWLINE> <TAB> level = levels [ height ] <NEWLINE> if not level . active : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> height -= <NUMBER> <NEWLINE> break <NEWLINE> <UNTAB> u = arbitrary_element ( level . active ) <NEWLINE> height = discharge ( u , False ) <NEWLINE> if grt . is_reached ( ) : <NEWLINE> <NEWLINE> <TAB> height = global_relabel ( False ) <NEWLINE> grt . clear_work ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> R . graph [ <STRING> ] = R_nodes [ t ] [ <STRING> ] <NEWLINE> return R <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def log10 ( x ) : <NEWLINE> <TAB> <NEWLINE> return Log10 ( ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _convert_rnn_weights ( layer , weights ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def transform_kernels ( kernels , func , n_gates ) : <NEWLINE> <TAB> <NEWLINE> return np . hstack ( [ func ( k ) for k in np . hsplit ( kernels , n_gates ) ] ) <NEWLINE> <NEWLINE> <UNTAB> def transpose_input ( from_cudnn ) : <NEWLINE> <TAB> <NEWLINE> order = <STRING> if from_cudnn else <STRING> <NEWLINE> <NEWLINE> def transform ( kernel ) : <NEWLINE> <TAB> return kernel . T . reshape ( kernel . shape , order = order ) <NEWLINE> <NEWLINE> <UNTAB> return transform <NEWLINE> <NEWLINE> <UNTAB> target_class = layer . __class__ . __name__ <NEWLINE> <NEWLINE> <NEWLINE> if target_class in [ <STRING> , <STRING> ] and len ( weights ) == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> units = weights [ <NUMBER> ] . shape [ <NUMBER> ] <NEWLINE> bias_shape = weights [ <NUMBER> ] . shape <NEWLINE> n_gates = <NUMBER> <NEWLINE> <NEWLINE> if bias_shape == ( <NUMBER> * units * n_gates , ) : <NEWLINE> <TAB> source = <STRING> <NEWLINE> <UNTAB> elif bias_shape == ( units * n_gates , ) : <NEWLINE> <TAB> source = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> + str ( bias_shape ) ) <NEWLINE> <NEWLINE> <UNTAB> def convert_weights ( weights , from_cudnn = True ) : <NEWLINE> <NEWLINE> <TAB> kernels = transform_kernels ( weights [ <NUMBER> ] , <NEWLINE> transpose_input ( from_cudnn ) , <NEWLINE> n_gates ) <NEWLINE> recurrent_kernels = transform_kernels ( weights [ <NUMBER> ] , lambda k : k . T , n_gates ) <NEWLINE> if from_cudnn : <NEWLINE> <NEWLINE> <TAB> biases = np . sum ( np . split ( weights [ <NUMBER> ] , <NUMBER> , axis = <NUMBER> ) , axis = <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> biases = np . tile ( <NUMBER> * weights [ <NUMBER> ] , <NUMBER> ) <NEWLINE> <UNTAB> return [ kernels , recurrent_kernels , biases ] <NEWLINE> <NEWLINE> <UNTAB> if source != target_class : <NEWLINE> <TAB> weights = convert_weights ( weights , from_cudnn = source == <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if target_class in [ <STRING> , <STRING> ] and len ( weights ) == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> units = weights [ <NUMBER> ] . shape [ <NUMBER> ] <NEWLINE> bias_shape = weights [ <NUMBER> ] . shape <NEWLINE> n_gates = <NUMBER> <NEWLINE> <NEWLINE> def convert_weights ( weights , from_cudnn = True ) : <NEWLINE> <TAB> kernels = transform_kernels ( weights [ <NUMBER> ] , <NEWLINE> transpose_input ( from_cudnn ) , <NEWLINE> n_gates ) <NEWLINE> recurrent_kernels = transform_kernels ( weights [ <NUMBER> ] , lambda k : k . T , n_gates ) <NEWLINE> biases = np . array ( weights [ <NUMBER> ] ) . reshape ( ( <NUMBER> , - <NUMBER> ) if from_cudnn else - <NUMBER> ) <NEWLINE> return [ kernels , recurrent_kernels , biases ] <NEWLINE> <NEWLINE> <UNTAB> if bias_shape == ( <NUMBER> * units * n_gates , ) : <NEWLINE> <TAB> source = <STRING> <NEWLINE> <UNTAB> elif bias_shape == ( <NUMBER> , units * n_gates ) : <NEWLINE> <TAB> source = <STRING> <NEWLINE> <UNTAB> elif bias_shape == ( units * n_gates , ) : <NEWLINE> <TAB> source = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> + str ( bias_shape ) ) <NEWLINE> <NEWLINE> <UNTAB> if target_class == <STRING> : <NEWLINE> <TAB> target = <STRING> <NEWLINE> <UNTAB> elif layer . reset_after : <NEWLINE> <TAB> target = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> target = <STRING> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if source != target : <NEWLINE> <TAB> types = ( source , target ) <NEWLINE> if <STRING> in types : <NEWLINE> <TAB> raise ValueError ( <STRING> % types ) <NEWLINE> <UNTAB> if source == <STRING> : <NEWLINE> <TAB> weights = convert_weights ( weights , from_cudnn = True ) <NEWLINE> <UNTAB> elif source == <STRING> : <NEWLINE> <TAB> weights = convert_weights ( weights , from_cudnn = False ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return weights <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def get_sequential_train_hooks ( train_steps = namedtuples . GANTrainSteps ( <NUMBER> , <NUMBER> ) ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def get_hooks ( train_ops ) : <NEWLINE> <TAB> generator_hook = RunTrainOpsHook ( train_ops . generator_train_op , <NEWLINE> train_steps . generator_train_steps ) <NEWLINE> discriminator_hook = RunTrainOpsHook ( train_ops . discriminator_train_op , <NEWLINE> train_steps . discriminator_train_steps ) <NEWLINE> return [ generator_hook , discriminator_hook ] <NEWLINE> <NEWLINE> <UNTAB> return get_hooks <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def init_zero_int ( _ ) : <NEWLINE> <TAB> <NEWLINE> global init_zero_int_warnings_left <NEWLINE> if init_zero_int_warnings_left : <NEWLINE> <TAB> print ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> init_zero_int_warnings_left -= <NUMBER> <NEWLINE> <UNTAB> return <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_attrs ( self ) : <NEWLINE> <TAB> <NEWLINE> self . attrs . table_type = str ( self . table_type ) <NEWLINE> self . attrs . index_cols = self . index_cols ( ) <NEWLINE> self . attrs . values_cols = self . values_cols ( ) <NEWLINE> self . attrs . non_index_axes = self . non_index_axes <NEWLINE> self . attrs . data_columns = self . data_columns <NEWLINE> self . attrs . nan_rep = self . nan_rep <NEWLINE> self . attrs . encoding = self . encoding <NEWLINE> self . attrs . errors = self . errors <NEWLINE> self . attrs . levels = self . levels <NEWLINE> self . attrs . metadata = self . metadata <NEWLINE> self . set_info ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_legendre ( n , K ) : <NEWLINE> <TAB> <NEWLINE> seq = [ [ K . one ] , [ K . one , K . zero ] ] <NEWLINE> <NEWLINE> for i in range ( <NUMBER> , n + <NUMBER> ) : <NEWLINE> <TAB> a = dup_mul_ground ( dup_lshift ( seq [ - <NUMBER> ] , <NUMBER> , K ) , K ( <NUMBER> * i - <NUMBER> , i ) , K ) <NEWLINE> b = dup_mul_ground ( seq [ - <NUMBER> ] , K ( i - <NUMBER> , i ) , K ) <NEWLINE> <NEWLINE> seq . append ( dup_sub ( a , b , K ) ) <NEWLINE> <NEWLINE> <UNTAB> return seq [ n ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _to_safe_for_reshape ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . set_levels ( [ i . _to_safe_for_reshape ( ) for i in self . levels ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gf_sqr ( f , p , K ) : <NEWLINE> <TAB> <NEWLINE> df = gf_degree ( f ) <NEWLINE> <NEWLINE> dh = <NUMBER> * df <NEWLINE> h = [ <NUMBER> ] * ( dh + <NUMBER> ) <NEWLINE> <NEWLINE> for i in range ( <NUMBER> , dh + <NUMBER> ) : <NEWLINE> <TAB> coeff = K . zero <NEWLINE> <NEWLINE> jmin = max ( <NUMBER> , i - df ) <NEWLINE> jmax = min ( i , df ) <NEWLINE> <NEWLINE> n = jmax - jmin + <NUMBER> <NEWLINE> <NEWLINE> jmax = jmin + n // <NUMBER> - <NUMBER> <NEWLINE> <NEWLINE> for j in range ( jmin , jmax + <NUMBER> ) : <NEWLINE> <TAB> coeff += f [ j ] * f [ i - j ] <NEWLINE> <NEWLINE> <UNTAB> coeff += coeff <NEWLINE> <NEWLINE> if n & <NUMBER> : <NEWLINE> <TAB> elem = f [ jmax + <NUMBER> ] <NEWLINE> coeff += elem ** <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> h [ i ] = coeff % p <NEWLINE> <NEWLINE> <UNTAB> return gf_strip ( h ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def wide_to_long ( df , stubnames , i , j , sep = <STRING> , suffix = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> def get_var_names ( df , stub , sep , suffix ) : <NEWLINE> <TAB> regex = <STRING> . format ( <NEWLINE> stub = re . escape ( stub ) , sep = re . escape ( sep ) , suffix = suffix ) <NEWLINE> pattern = re . compile ( regex ) <NEWLINE> return [ col for col in df . columns if pattern . match ( col ) ] <NEWLINE> <NEWLINE> <UNTAB> def melt_stub ( df , stub , i , j , value_vars , sep ) : <NEWLINE> <TAB> newdf = melt ( df , id_vars = i , value_vars = value_vars , <NEWLINE> value_name = stub . rstrip ( sep ) , var_name = j ) <NEWLINE> newdf [ j ] = Categorical ( newdf [ j ] ) <NEWLINE> newdf [ j ] = newdf [ j ] . str . replace ( re . escape ( stub + sep ) , <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> newdf [ j ] = to_numeric ( newdf [ j ] , errors = <STRING> ) <NEWLINE> <NEWLINE> return newdf . set_index ( i + [ j ] ) <NEWLINE> <NEWLINE> <UNTAB> if any ( col in stubnames for col in df . columns ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if not is_list_like ( stubnames ) : <NEWLINE> <TAB> stubnames = [ stubnames ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> stubnames = list ( stubnames ) <NEWLINE> <NEWLINE> <UNTAB> if not is_list_like ( i ) : <NEWLINE> <TAB> i = [ i ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> i = list ( i ) <NEWLINE> <NEWLINE> <UNTAB> if df [ i ] . duplicated ( ) . any ( ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> value_vars = [ get_var_names ( df , stub , sep , suffix ) for stub in stubnames ] <NEWLINE> <NEWLINE> value_vars_flattened = [ e for sublist in value_vars for e in sublist ] <NEWLINE> id_vars = list ( set ( df . columns . tolist ( ) ) . difference ( value_vars_flattened ) ) <NEWLINE> <NEWLINE> melted = [ ] <NEWLINE> for s , v in zip ( stubnames , value_vars ) : <NEWLINE> <TAB> melted . append ( melt_stub ( df , s , i , j , v , sep ) ) <NEWLINE> <UNTAB> melted = melted [ <NUMBER> ] . join ( melted [ <NUMBER> : ] , how = <STRING> ) <NEWLINE> <NEWLINE> if len ( i ) == <NUMBER> : <NEWLINE> <TAB> new = df [ id_vars ] . set_index ( i ) . join ( melted ) <NEWLINE> return new <NEWLINE> <NEWLINE> <UNTAB> new = df [ id_vars ] . merge ( melted . reset_index ( ) , on = i ) . set_index ( i + [ j ] ) <NEWLINE> <NEWLINE> return new <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_loss_scale ( self , loss_scale ) : <NEWLINE> <TAB> <NEWLINE> self . _loss_scale = loss_scale <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_one_p ( f , u , K ) : <NEWLINE> <TAB> <NEWLINE> return dmp_ground_p ( f , K . one , u ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def div_eager_fallback ( x , y , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ x , y ] , _ctx ) <NEWLINE> ( x , y ) = _inputs_T <NEWLINE> _inputs_flat = [ x , y ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _numeric_arrays ( arrays , kinds = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if type ( arrays ) == ndarray : <NEWLINE> <TAB> return arrays . dtype . kind in kinds <NEWLINE> <UNTAB> for array_ in arrays : <NEWLINE> <TAB> if array_ . dtype . kind not in kinds : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def select ( self ) : <NEWLINE> <TAB> <NEWLINE> s = Select ( [ self ] ) <NEWLINE> if self . _execution_options : <NEWLINE> <TAB> s = s . execution_options ( ** self . _execution_options ) <NEWLINE> <UNTAB> return s <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def save ( self , file_prefix , checkpoint_number = None , session = None ) : <NEWLINE> <TAB> <NEWLINE> feed_additions = { } <NEWLINE> graph_building = not context . executing_eagerly ( ) <NEWLINE> if graph_building : <NEWLINE> <TAB> if self . _object_graph_feed_tensor is None : <NEWLINE> <TAB> with ops . device ( <STRING> ) : <NEWLINE> <TAB> self . _object_graph_feed_tensor = constant_op . constant ( <NEWLINE> <STRING> , dtype = dtypes . string ) <NEWLINE> <UNTAB> <UNTAB> object_graph_tensor = self . _object_graph_feed_tensor <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> object_graph_tensor = None <NEWLINE> <NEWLINE> <UNTAB> saver , new_feed_additions = self . _prepare_save ( <NEWLINE> object_graph_tensor = object_graph_tensor , <NEWLINE> saveable_object_cache = self . _saveable_object_cache ) <NEWLINE> if new_feed_additions : <NEWLINE> <TAB> feed_additions . update ( new_feed_additions ) <NEWLINE> <UNTAB> if not graph_building : <NEWLINE> <TAB> session = None <NEWLINE> <UNTAB> elif session is None : <NEWLINE> <TAB> session = ops . get_default_session ( ) <NEWLINE> <NEWLINE> <UNTAB> with ops . device ( <STRING> ) : <NEWLINE> <TAB> save_path = saver . save ( <NEWLINE> sess = _SessionWithFeedDictAdditions ( <NEWLINE> session = session , feed_additions = feed_additions ) , <NEWLINE> save_path = file_prefix , <NEWLINE> write_meta_graph = False , <NEWLINE> write_state = False , <NEWLINE> global_step = checkpoint_number ) <NEWLINE> <UNTAB> return save_path <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_euclidean_prs ( f , g , u , K ) : <NEWLINE> <TAB> <NEWLINE> if not u : <NEWLINE> <TAB> return dup_euclidean_prs ( f , g , K ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise MultivariatePolynomialError ( f , g ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def show ( self , warn = True ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> manager = getattr ( self . canvas , <STRING> ) <NEWLINE> <UNTAB> except AttributeError as err : <NEWLINE> <TAB> raise AttributeError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % err ) <NEWLINE> <NEWLINE> <UNTAB> if manager is not None : <NEWLINE> <TAB> try : <NEWLINE> <TAB> manager . show ( ) <NEWLINE> return <NEWLINE> <UNTAB> except NonGuiException : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> if ( backends . _get_running_interactive_framework ( ) != <STRING> <NEWLINE> and warn ) : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> % get_backend ( ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _compute_fans ( shape , data_format = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if len ( shape ) == <NUMBER> : <NEWLINE> <TAB> fan_in = shape [ <NUMBER> ] <NEWLINE> fan_out = shape [ <NUMBER> ] <NEWLINE> <UNTAB> elif len ( shape ) in { <NUMBER> , <NUMBER> , <NUMBER> } : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if data_format == <STRING> : <NEWLINE> <TAB> receptive_field_size = np . prod ( shape [ <NUMBER> : ] ) <NEWLINE> fan_in = shape [ <NUMBER> ] * receptive_field_size <NEWLINE> fan_out = shape [ <NUMBER> ] * receptive_field_size <NEWLINE> <UNTAB> elif data_format == <STRING> : <NEWLINE> <TAB> receptive_field_size = np . prod ( shape [ : - <NUMBER> ] ) <NEWLINE> fan_in = shape [ - <NUMBER> ] * receptive_field_size <NEWLINE> fan_out = shape [ - <NUMBER> ] * receptive_field_size <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> + data_format ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> fan_in = np . sqrt ( np . prod ( shape ) ) <NEWLINE> fan_out = np . sqrt ( np . prod ( shape ) ) <NEWLINE> <UNTAB> return fan_in , fan_out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def within_group ( self , * order_by ) : <NEWLINE> <TAB> <NEWLINE> return WithinGroup ( self , * order_by ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def remove_move ( name ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> delattr ( _MovedItems , name ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> try : <NEWLINE> <TAB> del moves . __dict__ [ name ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> raise AttributeError ( <STRING> % ( name , ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _rec_integrate_in ( g , m , v , i , j , K ) : <NEWLINE> <TAB> <NEWLINE> if i == j : <NEWLINE> <TAB> return dmp_integrate ( g , m , v , K ) <NEWLINE> <NEWLINE> <UNTAB> w , i = v - <NUMBER> , i + <NUMBER> <NEWLINE> <NEWLINE> return dmp_strip ( [ _rec_integrate_in ( c , m , w , i , j , K ) for c in g ] , v ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def flatnotmasked_contiguous ( a ) : <NEWLINE> <TAB> <NEWLINE> m = getmask ( a ) <NEWLINE> if m is nomask : <NEWLINE> <TAB> return slice ( <NUMBER> , a . size , None ) <NEWLINE> <UNTAB> i = <NUMBER> <NEWLINE> result = [ ] <NEWLINE> for ( k , g ) in itertools . groupby ( m . ravel ( ) ) : <NEWLINE> <TAB> n = len ( list ( g ) ) <NEWLINE> if not k : <NEWLINE> <TAB> result . append ( slice ( i , i + n ) ) <NEWLINE> <UNTAB> i += n <NEWLINE> <UNTAB> return result or None <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _maybe_match_name ( a , b ) : <NEWLINE> <TAB> <NEWLINE> a_has = hasattr ( a , <STRING> ) <NEWLINE> b_has = hasattr ( b , <STRING> ) <NEWLINE> if a_has and b_has : <NEWLINE> <TAB> if a . name == b . name : <NEWLINE> <TAB> return a . name <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> elif a_has : <NEWLINE> <TAB> return a . name <NEWLINE> <UNTAB> elif b_has : <NEWLINE> <TAB> return b . name <NEWLINE> <UNTAB> return None <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _moment ( self , n ) : <NEWLINE> <TAB> <NEWLINE> total_concentration = self . concentration1 + self . concentration0 <NEWLINE> expanded_concentration1 = array_ops . ones_like ( <NEWLINE> total_concentration , dtype = self . dtype ) * self . concentration1 <NEWLINE> expanded_concentration0 = array_ops . ones_like ( <NEWLINE> total_concentration , dtype = self . dtype ) * self . concentration0 <NEWLINE> beta_arg0 = <NUMBER> + n / expanded_concentration1 <NEWLINE> beta_arg = array_ops . stack ( [ beta_arg0 , expanded_concentration0 ] , - <NUMBER> ) <NEWLINE> log_moment = math_ops . log ( expanded_concentration0 ) + special_math_ops . lbeta ( <NEWLINE> beta_arg ) <NEWLINE> return math_ops . exp ( log_moment ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def identity ( x ) : <NEWLINE> <TAB> <NEWLINE> return x <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def ihfft ( a , n = None , axis = - <NUMBER> , norm = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> a = array ( a , copy = True , dtype = float ) <NEWLINE> if n is None : <NEWLINE> <TAB> n = a . shape [ axis ] <NEWLINE> <UNTAB> unitary = _unitary ( norm ) <NEWLINE> output = conjugate ( rfft ( a , n , axis ) ) <NEWLINE> return output * ( <NUMBER> / ( sqrt ( n ) if unitary else n ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def hash_buffer ( buf , hasher = None ) : <NEWLINE> <TAB> <NEWLINE> if hasher is not None : <NEWLINE> <TAB> try : <NEWLINE> <TAB> return hasher ( buf ) <NEWLINE> <UNTAB> except ( TypeError , OverflowError ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> for hasher in hashers : <NEWLINE> <TAB> try : <NEWLINE> <TAB> return hasher ( buf ) <NEWLINE> <UNTAB> except ( TypeError , OverflowError ) : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> raise TypeError ( <STRING> % ( type ( buf ) , ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_valid_joint_degree ( joint_degrees ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> degree_count = { } <NEWLINE> for k in joint_degrees : <NEWLINE> <TAB> if k > <NUMBER> : <NEWLINE> <TAB> k_size = sum ( joint_degrees [ k ] . values ( ) ) / k <NEWLINE> if not k_size . is_integer ( ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> degree_count [ k ] = k_size <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for k in joint_degrees : <NEWLINE> <TAB> for l in joint_degrees [ k ] : <NEWLINE> <TAB> if not float ( joint_degrees [ k ] [ l ] ) . is_integer ( ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> if ( k != l ) and ( joint_degrees [ k ] [ l ] > <NEWLINE> degree_count [ k ] * degree_count [ l ] ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> elif k == l : <NEWLINE> <TAB> if joint_degrees [ k ] [ k ] > degree_count [ k ] * ( degree_count [ k ] - <NUMBER> ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> if joint_degrees [ k ] [ k ] % <NUMBER> != <NUMBER> : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , f ) : <NEWLINE> <TAB> <NEWLINE> @ wraps ( f ) <NEWLINE> def wrapper ( * args , ** kwargs ) : <NEWLINE> <NEWLINE> <TAB> if self . mdargs : <NEWLINE> <TAB> mdargs = self . mdargs <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> mdargs = range ( len ( args ) ) + kwargs . keys ( ) <NEWLINE> <NEWLINE> <UNTAB> arglength = len ( args ) <NEWLINE> <NEWLINE> for n in mdargs : <NEWLINE> <TAB> if isinstance ( n , int ) : <NEWLINE> <TAB> if n >= arglength : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> entry = args [ n ] <NEWLINE> is_arg = True <NEWLINE> <UNTAB> elif isinstance ( n , str ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> entry = kwargs [ n ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> is_arg = False <NEWLINE> <UNTAB> if hasattr ( entry , <STRING> ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if is_arg : <NEWLINE> <TAB> args = list ( args ) <NEWLINE> args [ n ] = structure_copy ( entry ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> kwargs [ n ] = structure_copy ( entry ) <NEWLINE> <UNTAB> result = apply_on_element ( wrapper , args , kwargs , n ) <NEWLINE> return result <NEWLINE> <UNTAB> <UNTAB> return f ( * args , ** kwargs ) <NEWLINE> <UNTAB> return wrapper <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , num_gpus_per_worker = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> self . _num_gpus_per_worker = num_gpus_per_worker <NEWLINE> self . _initialize_local_worker ( num_gpus_per_worker ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def from_proto ( variable_def , import_scope = None ) : <NEWLINE> <TAB> <NEWLINE> return RefVariable ( variable_def = variable_def , <NEWLINE> import_scope = import_scope ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_numbered_constants ( eq , num = <NUMBER> , start = <NUMBER> , prefix = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( eq , Expr ) : <NEWLINE> <TAB> eq = [ eq ] <NEWLINE> <UNTAB> elif not iterable ( eq ) : <NEWLINE> <TAB> raise ValueError ( <STRING> % eq ) <NEWLINE> <NEWLINE> <UNTAB> atom_set = set ( ) . union ( * [ i . free_symbols for i in eq ] ) <NEWLINE> ncs = numbered_symbols ( start = start , prefix = prefix , exclude = atom_set ) <NEWLINE> Cs = [ next ( ncs ) for i in range ( num ) ] <NEWLINE> return ( Cs [ <NUMBER> ] if num == <NUMBER> else tuple ( Cs ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def choose_conv_method ( in1 , in2 , mode = <STRING> , measure = False ) : <NEWLINE> <TAB> <NEWLINE> volume = asarray ( in1 ) <NEWLINE> kernel = asarray ( in2 ) <NEWLINE> <NEWLINE> if measure : <NEWLINE> <TAB> times = { } <NEWLINE> for method in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> times [ method ] = _timeit_fast ( lambda : convolve ( volume , kernel , <NEWLINE> mode = mode , method = method ) ) <NEWLINE> <NEWLINE> <UNTAB> chosen_method = <STRING> if times [ <STRING> ] < times [ <STRING> ] else <STRING> <NEWLINE> return chosen_method , times <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> fftconv_unsup = <STRING> if sys . maxsize > <NUMBER> ** <NUMBER> else <STRING> <NEWLINE> if hasattr ( np , fftconv_unsup ) : <NEWLINE> <TAB> if volume . dtype == fftconv_unsup or kernel . dtype == fftconv_unsup : <NEWLINE> <TAB> return <STRING> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if any ( [ _numeric_arrays ( [ x ] , kinds = <STRING> ) for x in [ volume , kernel ] ] ) : <NEWLINE> <TAB> max_value = int ( np . abs ( volume ) . max ( ) ) * int ( np . abs ( kernel ) . max ( ) ) <NEWLINE> max_value *= int ( min ( volume . size , kernel . size ) ) <NEWLINE> if max_value > <NUMBER> ** np . finfo ( <STRING> ) . nmant - <NUMBER> : <NEWLINE> <TAB> return <STRING> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if _numeric_arrays ( [ volume , kernel ] , kinds = <STRING> ) : <NEWLINE> <TAB> return <STRING> <NEWLINE> <NEWLINE> <UNTAB> if _numeric_arrays ( [ volume , kernel ] ) : <NEWLINE> <TAB> if _fftconv_faster ( volume , kernel , mode ) : <NEWLINE> <TAB> return <STRING> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return <STRING> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def validate_min_itemsize ( self , min_itemsize ) : <NEWLINE> <TAB> <NEWLINE> if min_itemsize is None : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> if not isinstance ( min_itemsize , dict ) : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> q = self . queryables ( ) <NEWLINE> for k , v in min_itemsize . items ( ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if k == <STRING> : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> if k not in q : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % k ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_arraytype ( ) : <NEWLINE> <TAB> <NEWLINE> return <STRING> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_url ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _url <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _linear_2eq_order2_type9 ( x , y , t , r , eq ) : <NEWLINE> <TAB> <NEWLINE> C1 , C2 , C3 , C4 = get_numbered_constants ( eq , num = <NUMBER> ) <NEWLINE> k = Symbol ( <STRING> ) <NEWLINE> a1 = - r [ <STRING> ] * t ; a2 = - r [ <STRING> ] * t <NEWLINE> b1 = - r [ <STRING> ] * t ; b2 = - r [ <STRING> ] * t <NEWLINE> c1 = - r [ <STRING> ] * t ** <NUMBER> ; c2 = - r [ <STRING> ] * t ** <NUMBER> <NEWLINE> d1 = - r [ <STRING> ] * t ** <NUMBER> ; d2 = - r [ <STRING> ] * t ** <NUMBER> <NEWLINE> eq = ( k ** <NUMBER> + ( a1 - <NUMBER> ) * k + c1 ) * ( k ** <NUMBER> + ( b2 - <NUMBER> ) * k + d2 ) - ( b1 * k + d1 ) * ( a2 * k + c2 ) <NEWLINE> [ k1 , k2 , k3 , k4 ] = roots_quartic ( Poly ( eq ) ) <NEWLINE> sol1 = - C1 * ( b1 * k1 + d1 ) * exp ( k1 * log ( t ) ) - C2 * ( b1 * k2 + d1 ) * exp ( k2 * log ( t ) ) - C3 * ( b1 * k3 + d1 ) * exp ( k3 * log ( t ) ) - C4 * ( b1 * k4 + d1 ) * exp ( k4 * log ( t ) ) <NEWLINE> <NEWLINE> a1_ = ( a1 - <NUMBER> ) <NEWLINE> sol2 = C1 * ( k1 ** <NUMBER> + a1_ * k1 + c1 ) * exp ( k1 * log ( t ) ) + C2 * ( k2 ** <NUMBER> + a1_ * k2 + c1 ) * exp ( k2 * log ( t ) ) + C3 * ( k3 ** <NUMBER> + a1_ * k3 + c1 ) * exp ( k3 * log ( t ) ) + C4 * ( k4 ** <NUMBER> + a1_ * k4 + c1 ) * exp ( k4 * log ( t ) ) <NEWLINE> <NEWLINE> return [ Eq ( x ( t ) , sol1 ) , Eq ( y ( t ) , sol2 ) ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def fsum ( ctx , terms , absolute = False , squared = False ) : <NEWLINE> <TAB> <NEWLINE> prec , rnd = ctx . _prec_rounding <NEWLINE> real = [ ] <NEWLINE> imag = [ ] <NEWLINE> other = <NUMBER> <NEWLINE> for term in terms : <NEWLINE> <TAB> reval = imval = <NUMBER> <NEWLINE> if hasattr ( term , <STRING> ) : <NEWLINE> <TAB> reval = term . _mpf_ <NEWLINE> <UNTAB> elif hasattr ( term , <STRING> ) : <NEWLINE> <TAB> reval , imval = term . _mpc_ <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> term = ctx . convert ( term ) <NEWLINE> if hasattr ( term , <STRING> ) : <NEWLINE> <TAB> reval = term . _mpf_ <NEWLINE> <UNTAB> elif hasattr ( term , <STRING> ) : <NEWLINE> <TAB> reval , imval = term . _mpc_ <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if absolute : term = ctx . absmax ( term ) <NEWLINE> if squared : term = term ** <NUMBER> <NEWLINE> other += term <NEWLINE> continue <NEWLINE> <UNTAB> <UNTAB> if imval : <NEWLINE> <TAB> if squared : <NEWLINE> <TAB> if absolute : <NEWLINE> <TAB> real . append ( mpf_mul ( reval , reval ) ) <NEWLINE> real . append ( mpf_mul ( imval , imval ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> reval , imval = mpc_pow_int ( ( reval , imval ) , <NUMBER> , prec + <NUMBER> ) <NEWLINE> real . append ( reval ) <NEWLINE> imag . append ( imval ) <NEWLINE> <UNTAB> <UNTAB> elif absolute : <NEWLINE> <TAB> real . append ( mpc_abs ( ( reval , imval ) , prec ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> real . append ( reval ) <NEWLINE> imag . append ( imval ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if squared : <NEWLINE> <TAB> reval = mpf_mul ( reval , reval ) <NEWLINE> <UNTAB> elif absolute : <NEWLINE> <TAB> reval = mpf_abs ( reval ) <NEWLINE> <UNTAB> real . append ( reval ) <NEWLINE> <UNTAB> <UNTAB> s = mpf_sum ( real , prec , rnd , absolute ) <NEWLINE> if imag : <NEWLINE> <TAB> s = ctx . make_mpc ( ( s , mpf_sum ( imag , prec , rnd ) ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> s = ctx . make_mpf ( s ) <NEWLINE> <UNTAB> if other is <NUMBER> : <NEWLINE> <TAB> return s <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return s + other <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __contains__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if type ( self ) == type ( other ) : <NEWLINE> <TAB> return self == other <NEWLINE> <UNTAB> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def gcdex ( self , a , b ) : <NEWLINE> <TAB> <NEWLINE> return python_gcdex ( a , b ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _mul ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( other , SeqPer ) : <NEWLINE> <TAB> per1 , lper1 = self . periodical , self . period <NEWLINE> per2 , lper2 = other . periodical , other . period <NEWLINE> <NEWLINE> per_length = lcm ( lper1 , lper2 ) <NEWLINE> <NEWLINE> new_per = [ ] <NEWLINE> for x in range ( per_length ) : <NEWLINE> <TAB> ele1 = per1 [ x % lper1 ] <NEWLINE> ele2 = per2 [ x % lper2 ] <NEWLINE> new_per . append ( ele1 * ele2 ) <NEWLINE> <NEWLINE> <UNTAB> start , stop = self . _intersect_interval ( other ) <NEWLINE> return SeqPer ( new_per , ( self . variables [ <NUMBER> ] , start , stop ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def sparse_expand_dims ( sp_input , axis = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> rank = sp_input . dense_shape . get_shape ( ) [ <NUMBER> ] <NEWLINE> axis = - <NUMBER> if axis is None else axis <NEWLINE> <NEWLINE> with ops . name_scope ( name , default_name = <STRING> , values = [ sp_input ] ) : <NEWLINE> <TAB> if isinstance ( axis , compat . integral_types ) : <NEWLINE> <TAB> axis = ops . convert_to_tensor ( axis , name = <STRING> , dtype = dtypes . int32 ) <NEWLINE> <UNTAB> elif not isinstance ( axis , ops . Tensor ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> axis = array_ops . where ( axis >= <NUMBER> , axis , axis + rank + <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> column_size = array_ops . shape ( sp_input . indices ) [ <NUMBER> ] <NEWLINE> new_index = array_ops . zeros ( [ column_size , <NUMBER> ] , dtype = dtypes . int64 ) <NEWLINE> indices_before = array_ops . slice ( sp_input . indices , [ <NUMBER> , <NUMBER> ] , [ - <NUMBER> , axis ] ) <NEWLINE> indices_after = array_ops . slice ( sp_input . indices , [ <NUMBER> , axis ] , [ - <NUMBER> , - <NUMBER> ] ) <NEWLINE> indices = array_ops . concat ( <NEWLINE> [ indices_before , new_index , indices_after ] , axis = <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> shape_before = array_ops . slice ( sp_input . dense_shape , [ <NUMBER> ] , [ axis ] ) <NEWLINE> shape_after = array_ops . slice ( sp_input . dense_shape , [ axis ] , [ - <NUMBER> ] ) <NEWLINE> new_shape = ops . convert_to_tensor ( [ <NUMBER> ] , name = <STRING> , dtype = dtypes . int64 ) <NEWLINE> shape = array_ops . concat ( [ shape_before , new_shape , shape_after ] , axis = <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> return sparse_tensor . SparseTensor ( <NEWLINE> indices = indices , values = sp_input . values , dense_shape = shape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def tensorcontraction ( array , * contraction_axes ) : <NEWLINE> <TAB> <NEWLINE> array = _arrayfy ( array ) <NEWLINE> <NEWLINE> <NEWLINE> taken_dims = set ( [ ] ) <NEWLINE> for axes_group in contraction_axes : <NEWLINE> <TAB> if not isinstance ( axes_group , Iterable ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> dim = array . shape [ axes_group [ <NUMBER> ] ] <NEWLINE> <NEWLINE> for d in axes_group : <NEWLINE> <TAB> if d in taken_dims : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if dim != array . shape [ d ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> taken_dims . add ( d ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> rank = array . rank ( ) <NEWLINE> <NEWLINE> remaining_shape = [ dim for i , dim in enumerate ( array . shape ) if i not in taken_dims ] <NEWLINE> cum_shape = [ <NUMBER> ] * rank <NEWLINE> _cumul = <NUMBER> <NEWLINE> for i in range ( rank ) : <NEWLINE> <TAB> cum_shape [ rank - i - <NUMBER> ] = _cumul <NEWLINE> _cumul *= int ( array . shape [ rank - i - <NUMBER> ] ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> remaining_indices = [ [ cum_shape [ i ] * j for j in range ( array . shape [ i ] ) ] <NEWLINE> for i in range ( rank ) if i not in taken_dims ] <NEWLINE> <NEWLINE> <NEWLINE> summed_deltas = [ ] <NEWLINE> for axes_group in contraction_axes : <NEWLINE> <TAB> lidx = [ ] <NEWLINE> for js in range ( array . shape [ axes_group [ <NUMBER> ] ] ) : <NEWLINE> <TAB> lidx . append ( sum ( [ cum_shape [ ig ] * js for ig in axes_group ] ) ) <NEWLINE> <UNTAB> summed_deltas . append ( lidx ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> contracted_array = [ ] <NEWLINE> for icontrib in itertools . product ( * remaining_indices ) : <NEWLINE> <TAB> index_base_position = sum ( icontrib ) <NEWLINE> isum = S . Zero <NEWLINE> for sum_to_index in itertools . product ( * summed_deltas ) : <NEWLINE> <TAB> isum += array [ index_base_position + sum ( sum_to_index ) ] <NEWLINE> <NEWLINE> <UNTAB> contracted_array . append ( isum ) <NEWLINE> <NEWLINE> <UNTAB> if len ( remaining_indices ) == <NUMBER> : <NEWLINE> <TAB> assert len ( contracted_array ) == <NUMBER> <NEWLINE> return contracted_array [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> return type ( array ) ( contracted_array , remaining_shape ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def outfeed_enqueue ( input , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , name = name ) <NEWLINE> return _op <NEWLINE> _result = None <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , input ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return outfeed_enqueue_eager_fallback ( <NEWLINE> input , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_deps ( dsk ) : <NEWLINE> <TAB> <NEWLINE> dependencies = { k : get_dependencies ( dsk , task = v ) <NEWLINE> for k , v in dsk . items ( ) } <NEWLINE> dependents = reverse_dict ( dependencies ) <NEWLINE> return dependencies , dependents <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def bilinear_kernel_1D ( ratio , normalize = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> T = theano . tensor <NEWLINE> half_kern = T . arange ( <NUMBER> , ratio + <NUMBER> , dtype = theano . config . floatX ) <NEWLINE> kern = T . concatenate ( [ half_kern , half_kern [ - <NUMBER> : : - <NUMBER> ] ] ) <NEWLINE> <NEWLINE> if normalize : <NEWLINE> <TAB> kern /= ratio <NEWLINE> <UNTAB> return kern <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def spalde ( x , tck ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( tck , BSpline ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _impl . spalde ( x , tck ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def candidate_pairs_iter ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> G1_nodes = self . G1_nodes <NEWLINE> G2_nodes = self . G2_nodes <NEWLINE> min_key = self . G2_node_order . __getitem__ <NEWLINE> <NEWLINE> <NEWLINE> T1_out = [ node for node in self . out_1 if node not in self . core_1 ] <NEWLINE> T2_out = [ node for node in self . out_2 if node not in self . core_2 ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if T1_out and T2_out : <NEWLINE> <TAB> node_2 = min ( T2_out , key = min_key ) <NEWLINE> for node_1 in T1_out : <NEWLINE> <TAB> yield node_1 , node_2 <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> T1_in = [ node for node in self . in_1 if node not in self . core_1 ] <NEWLINE> T2_in = [ node for node in self . in_2 if node not in self . core_2 ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if T1_in and T2_in : <NEWLINE> <TAB> node_2 = min ( T2_in , key = min_key ) <NEWLINE> for node_1 in T1_in : <NEWLINE> <TAB> yield node_1 , node_2 <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> node_2 = min ( G2_nodes - set ( self . core_2 ) , key = min_key ) <NEWLINE> for node_1 in G1_nodes : <NEWLINE> <TAB> if node_1 not in self . core_1 : <NEWLINE> <TAB> yield node_1 , node_2 <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __getitem__ ( self , n ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( n , slice ) : <NEWLINE> <TAB> self . extend_to_no ( n . stop ) <NEWLINE> return self . _list [ n . start - <NUMBER> : n . stop - <NUMBER> : n . step ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> n = as_int ( n ) <NEWLINE> self . extend_to_no ( n ) <NEWLINE> return self . _list [ n - <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def format_argspec_plus ( fn , grouped = True ) : <NEWLINE> <TAB> <NEWLINE> if compat . callable ( fn ) : <NEWLINE> <TAB> spec = compat . inspect_getfullargspec ( fn ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> spec = fn <NEWLINE> <UNTAB> args = compat . inspect_formatargspec ( * spec ) <NEWLINE> if spec [ <NUMBER> ] : <NEWLINE> <TAB> self_arg = spec [ <NUMBER> ] [ <NUMBER> ] <NEWLINE> <UNTAB> elif spec [ <NUMBER> ] : <NEWLINE> <TAB> self_arg = <STRING> % spec [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self_arg = None <NEWLINE> <NEWLINE> <UNTAB> if compat . py3k : <NEWLINE> <TAB> apply_pos = compat . inspect_formatargspec ( <NEWLINE> spec [ <NUMBER> ] , spec [ <NUMBER> ] , spec [ <NUMBER> ] , None , spec [ <NUMBER> ] ) <NEWLINE> num_defaults = <NUMBER> <NEWLINE> if spec [ <NUMBER> ] : <NEWLINE> <TAB> num_defaults += len ( spec [ <NUMBER> ] ) <NEWLINE> <UNTAB> if spec [ <NUMBER> ] : <NEWLINE> <TAB> num_defaults += len ( spec [ <NUMBER> ] ) <NEWLINE> <UNTAB> name_args = spec [ <NUMBER> ] + spec [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> apply_pos = compat . inspect_formatargspec ( spec [ <NUMBER> ] , spec [ <NUMBER> ] , spec [ <NUMBER> ] ) <NEWLINE> num_defaults = <NUMBER> <NEWLINE> if spec [ <NUMBER> ] : <NEWLINE> <TAB> num_defaults += len ( spec [ <NUMBER> ] ) <NEWLINE> <UNTAB> name_args = spec [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> if num_defaults : <NEWLINE> <TAB> defaulted_vals = name_args [ <NUMBER> - num_defaults : ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> defaulted_vals = ( ) <NEWLINE> <NEWLINE> <UNTAB> apply_kw = compat . inspect_formatargspec ( <NEWLINE> name_args , spec [ <NUMBER> ] , spec [ <NUMBER> ] , defaulted_vals , <NEWLINE> formatvalue = lambda x : <STRING> + x ) <NEWLINE> if grouped : <NEWLINE> <TAB> return dict ( args = args , self_arg = self_arg , <NEWLINE> apply_pos = apply_pos , apply_kw = apply_kw ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return dict ( args = args [ <NUMBER> : - <NUMBER> ] , self_arg = self_arg , <NEWLINE> apply_pos = apply_pos [ <NUMBER> : - <NUMBER> ] , apply_kw = apply_kw [ <NUMBER> : - <NUMBER> ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def easy_dtype ( ndtype , names = None , defaultfmt = <STRING> , ** validationargs ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> ndtype = np . dtype ( ndtype ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> validate = NameValidator ( ** validationargs ) <NEWLINE> nbfields = len ( ndtype ) <NEWLINE> if names is None : <NEWLINE> <TAB> names = [ <STRING> ] * len ( ndtype ) <NEWLINE> <UNTAB> elif isinstance ( names , basestring ) : <NEWLINE> <TAB> names = names . split ( <STRING> ) <NEWLINE> <UNTAB> names = validate ( names , nbfields = nbfields , defaultfmt = defaultfmt ) <NEWLINE> ndtype = np . dtype ( dict ( formats = ndtype , names = names ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nbtypes = len ( ndtype ) <NEWLINE> <NEWLINE> if names is not None : <NEWLINE> <TAB> validate = NameValidator ( ** validationargs ) <NEWLINE> if isinstance ( names , basestring ) : <NEWLINE> <TAB> names = names . split ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if nbtypes == <NUMBER> : <NEWLINE> <TAB> formats = tuple ( [ ndtype . type ] * len ( names ) ) <NEWLINE> names = validate ( names , defaultfmt = defaultfmt ) <NEWLINE> ndtype = np . dtype ( list ( zip ( names , formats ) ) ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ndtype . names = validate ( names , nbfields = nbtypes , <NEWLINE> defaultfmt = defaultfmt ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif ( nbtypes > <NUMBER> ) : <NEWLINE> <TAB> validate = NameValidator ( ** validationargs ) <NEWLINE> <NEWLINE> if ( ( ndtype . names == tuple ( <STRING> % i for i in range ( nbtypes ) ) ) and <NEWLINE> ( defaultfmt != <STRING> ) ) : <NEWLINE> <TAB> ndtype . names = validate ( [ <STRING> ] * nbtypes , defaultfmt = defaultfmt ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ndtype . names = validate ( ndtype . names , defaultfmt = defaultfmt ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return ndtype <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def shutdown_system ( job = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . device ( _tpu_system_device_name ( job ) ) : <NEWLINE> <TAB> shutdown_distributed_tpu = tpu_ops . shutdown_distributed_tpu ( ) <NEWLINE> <UNTAB> return shutdown_distributed_tpu <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _initialize_x_y ( self , z ) : <NEWLINE> <TAB> <NEWLINE> if z . ndim != <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> elif z . shape [ <NUMBER> ] < <NUMBER> or z . shape [ <NUMBER> ] < <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> Ny , Nx = z . shape <NEWLINE> <UNTAB> if self . origin is None : <NEWLINE> <TAB> if self . extent is None : <NEWLINE> <TAB> return np . meshgrid ( np . arange ( Nx ) , np . arange ( Ny ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x0 , x1 , y0 , y1 = self . extent <NEWLINE> x = np . linspace ( x0 , x1 , Nx ) <NEWLINE> y = np . linspace ( y0 , y1 , Ny ) <NEWLINE> return np . meshgrid ( x , y ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if self . extent is None : <NEWLINE> <TAB> x0 , x1 , y0 , y1 = ( <NUMBER> , Nx , <NUMBER> , Ny ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x0 , x1 , y0 , y1 = self . extent <NEWLINE> <UNTAB> dx = ( x1 - x0 ) / Nx <NEWLINE> dy = ( y1 - y0 ) / Ny <NEWLINE> x = x0 + ( np . arange ( Nx ) + <NUMBER> ) * dx <NEWLINE> y = y0 + ( np . arange ( Ny ) + <NUMBER> ) * dy <NEWLINE> if self . origin == <STRING> : <NEWLINE> <TAB> y = y [ : : - <NUMBER> ] <NEWLINE> <UNTAB> return np . meshgrid ( x , y ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def any ( self , axis = None , out = None , keepdims = np . _NoValue ) : <NEWLINE> <TAB> <NEWLINE> kwargs = { } if keepdims is np . _NoValue else { <STRING> : keepdims } <NEWLINE> <NEWLINE> mask = _check_mask_axis ( self . _mask , axis , ** kwargs ) <NEWLINE> if out is None : <NEWLINE> <TAB> d = self . filled ( False ) . any ( axis = axis , ** kwargs ) . view ( type ( self ) ) <NEWLINE> if d . ndim : <NEWLINE> <TAB> d . __setmask__ ( mask ) <NEWLINE> <UNTAB> elif mask : <NEWLINE> <TAB> d = masked <NEWLINE> <UNTAB> return d <NEWLINE> <UNTAB> self . filled ( False ) . any ( axis = axis , out = out , ** kwargs ) <NEWLINE> if isinstance ( out , MaskedArray ) : <NEWLINE> <TAB> if out . ndim or mask : <NEWLINE> <TAB> out . __setmask__ ( mask ) <NEWLINE> <UNTAB> <UNTAB> return out <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def eliminate_zeros ( self ) : <NEWLINE> <TAB> <NEWLINE> R , C = self . blocksize <NEWLINE> M , N = self . shape <NEWLINE> <NEWLINE> mask = ( self . data != <NUMBER> ) . reshape ( - <NUMBER> , R * C ) . sum ( axis = <NUMBER> ) <NEWLINE> <NEWLINE> nonzero_blocks = mask . nonzero ( ) [ <NUMBER> ] <NEWLINE> <NEWLINE> if len ( nonzero_blocks ) == <NUMBER> : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> self . data [ : len ( nonzero_blocks ) ] = self . data [ nonzero_blocks ] <NEWLINE> <NEWLINE> <NEWLINE> _sparsetools . csr_eliminate_zeros ( M // R , N // C , self . indptr , <NEWLINE> self . indices , mask ) <NEWLINE> self . prune ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def safe_eval ( source ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> import ast <NEWLINE> <NEWLINE> return ast . literal_eval ( source ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def compress ( condition , a , axis = None , out = None ) : <NEWLINE> <TAB> <NEWLINE> return _wrapfunc ( a , <STRING> , condition , axis = axis , out = out ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def reinterpret_string_to_float_eager_fallback ( input_data , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> input_data = _ops . convert_to_tensor ( input_data , _dtypes . string ) <NEWLINE> _inputs_flat = [ input_data ] <NEWLINE> _attrs = None <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , <NEWLINE> inputs = _inputs_flat , attrs = _attrs , ctx = _ctx , <NEWLINE> name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def could_be_isomorphic ( G1 , G2 ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if G1 . order ( ) != G2 . order ( ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> d1 = G1 . degree ( ) <NEWLINE> t1 = nx . triangles ( G1 ) <NEWLINE> c1 = nx . number_of_cliques ( G1 ) <NEWLINE> props1 = [ [ d , t1 [ v ] , c1 [ v ] ] for v , d in d1 ] <NEWLINE> props1 . sort ( ) <NEWLINE> <NEWLINE> d2 = G2 . degree ( ) <NEWLINE> t2 = nx . triangles ( G2 ) <NEWLINE> c2 = nx . number_of_cliques ( G2 ) <NEWLINE> props2 = [ [ d , t2 [ v ] , c2 [ v ] ] for v , d in d2 ] <NEWLINE> props2 . sort ( ) <NEWLINE> <NEWLINE> if props1 != props2 : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def border_mode_to_pad ( mode , convdim , kshp ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( mode , tuple ) : <NEWLINE> <TAB> if len ( mode ) != convdim : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( mode , convdim ) ) <NEWLINE> <UNTAB> border = ( ) <NEWLINE> for m in mode : <NEWLINE> <TAB> if isinstance ( m , integer_types ) and m >= <NUMBER> : <NEWLINE> <TAB> border += ( ( m , m ) , ) <NEWLINE> <UNTAB> elif isinstance ( m , tuple ) and min ( m ) >= <NUMBER> and all ( isinstance ( b , integer_types ) for b in m ) : <NEWLINE> <TAB> if len ( m ) != <NUMBER> : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( len ( m ) ) ) <NEWLINE> <UNTAB> border += ( ( m [ <NUMBER> ] , m [ <NUMBER> ] ) , ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( mode ) ) <NEWLINE> <UNTAB> <UNTAB> pad = border <NEWLINE> <UNTAB> elif mode == <STRING> : <NEWLINE> <TAB> pad = tuple ( ( kshp [ i ] - <NUMBER> , ) * <NUMBER> for i in range ( convdim ) ) <NEWLINE> <UNTAB> elif mode == <STRING> : <NEWLINE> <TAB> pad = tuple ( ( kshp [ i ] // <NUMBER> , ) * <NUMBER> for i in range ( convdim ) ) <NEWLINE> <UNTAB> elif mode == <STRING> : <NEWLINE> <TAB> pad = ( ( <NUMBER> , <NUMBER> ) , ) * convdim <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( mode , convdim ) ) <NEWLINE> <UNTAB> return pad <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def transform ( self , X ) : <NEWLINE> <TAB> <NEWLINE> check_is_fitted ( self , [ <STRING> ] ) <NEWLINE> <NEWLINE> Xt = check_array ( X , copy = True , dtype = FLOAT_DTYPES ) <NEWLINE> n_features = self . n_bins_ . shape [ <NUMBER> ] <NEWLINE> if Xt . shape [ <NUMBER> ] != n_features : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( n_features , Xt . shape [ <NUMBER> ] ) ) <NEWLINE> <NEWLINE> <UNTAB> bin_edges = self . bin_edges_ <NEWLINE> for jj in range ( Xt . shape [ <NUMBER> ] ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> rtol = <NUMBER> <NEWLINE> atol = <NUMBER> <NEWLINE> eps = atol + rtol * np . abs ( Xt [ : , jj ] ) <NEWLINE> Xt [ : , jj ] = np . digitize ( Xt [ : , jj ] + eps , bin_edges [ jj ] [ <NUMBER> : ] ) <NEWLINE> <UNTAB> np . clip ( Xt , <NUMBER> , self . n_bins_ - <NUMBER> , out = Xt ) <NEWLINE> <NEWLINE> if self . encode == <STRING> : <NEWLINE> <TAB> return Xt <NEWLINE> <NEWLINE> <UNTAB> return self . _encoder . fit_transform ( Xt ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def from_config ( cls , config , custom_objects = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> created_layers = { } <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> unprocessed_nodes = { } <NEWLINE> <NEWLINE> def add_unprocessed_node ( layer , node_data ) : <NEWLINE> <TAB> if layer not in unprocessed_nodes : <NEWLINE> <TAB> unprocessed_nodes [ layer ] = [ node_data ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> unprocessed_nodes [ layer ] . append ( node_data ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def process_node ( layer , node_data ) : <NEWLINE> <TAB> <NEWLINE> input_tensors = [ ] <NEWLINE> for input_data in node_data : <NEWLINE> <TAB> inbound_layer_name = input_data [ <NUMBER> ] <NEWLINE> inbound_node_index = input_data [ <NUMBER> ] <NEWLINE> inbound_tensor_index = input_data [ <NUMBER> ] <NEWLINE> if len ( input_data ) == <NUMBER> : <NEWLINE> <TAB> kwargs = { } <NEWLINE> <UNTAB> elif len ( input_data ) == <NUMBER> : <NEWLINE> <TAB> kwargs = input_data [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if inbound_layer_name not in created_layers : <NEWLINE> <TAB> add_unprocessed_node ( layer , node_data ) <NEWLINE> return <NEWLINE> <UNTAB> inbound_layer = created_layers [ inbound_layer_name ] <NEWLINE> if len ( inbound_layer . _inbound_nodes ) <= inbound_node_index : <NEWLINE> <TAB> add_unprocessed_node ( layer , node_data ) <NEWLINE> return <NEWLINE> <UNTAB> inbound_node = inbound_layer . _inbound_nodes [ inbound_node_index ] <NEWLINE> input_tensors . append ( inbound_node . output_tensors [ inbound_tensor_index ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if input_tensors : <NEWLINE> <TAB> if len ( input_tensors ) == <NUMBER> : <NEWLINE> <TAB> layer ( input_tensors [ <NUMBER> ] , ** kwargs ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> layer ( input_tensors , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> def process_layer ( layer_data ) : <NEWLINE> <TAB> <NEWLINE> layer_name = layer_data [ <STRING> ] <NEWLINE> <NEWLINE> <NEWLINE> from tensorflow . python . keras . layers import deserialize as deserialize_layer <NEWLINE> <NEWLINE> layer = deserialize_layer ( layer_data , custom_objects = custom_objects ) <NEWLINE> created_layers [ layer_name ] = layer <NEWLINE> <NEWLINE> <NEWLINE> inbound_nodes_data = layer_data [ <STRING> ] <NEWLINE> for node_data in inbound_nodes_data : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> add_unprocessed_node ( layer , node_data ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for layer_data in config [ <STRING> ] : <NEWLINE> <TAB> process_layer ( layer_data ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> while unprocessed_nodes : <NEWLINE> <TAB> for layer_data in config [ <STRING> ] : <NEWLINE> <TAB> layer = created_layers [ layer_data [ <STRING> ] ] <NEWLINE> if layer in unprocessed_nodes : <NEWLINE> <TAB> for node_data in unprocessed_nodes . pop ( layer ) : <NEWLINE> <TAB> process_node ( layer , node_data ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> name = config . get ( <STRING> ) <NEWLINE> input_tensors = [ ] <NEWLINE> output_tensors = [ ] <NEWLINE> for layer_data in config [ <STRING> ] : <NEWLINE> <TAB> layer_name , node_index , tensor_index = layer_data <NEWLINE> assert layer_name in created_layers <NEWLINE> layer = created_layers [ layer_name ] <NEWLINE> layer_output_tensors = layer . _inbound_nodes [ node_index ] . output_tensors <NEWLINE> input_tensors . append ( layer_output_tensors [ tensor_index ] ) <NEWLINE> <UNTAB> for layer_data in config [ <STRING> ] : <NEWLINE> <TAB> layer_name , node_index , tensor_index = layer_data <NEWLINE> assert layer_name in created_layers <NEWLINE> layer = created_layers [ layer_name ] <NEWLINE> layer_output_tensors = layer . _inbound_nodes [ node_index ] . output_tensors <NEWLINE> output_tensors . append ( layer_output_tensors [ tensor_index ] ) <NEWLINE> <UNTAB> return cls ( inputs = input_tensors , outputs = output_tensors , name = name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def latest_checkpoint ( checkpoint_dir , latest_filename = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> ckpt = get_checkpoint_state ( checkpoint_dir , latest_filename ) <NEWLINE> if ckpt and ckpt . model_checkpoint_path : <NEWLINE> <NEWLINE> <TAB> v2_path = _prefix_to_checkpoint_path ( ckpt . model_checkpoint_path , <NEWLINE> saver_pb2 . SaverDef . V2 ) <NEWLINE> v1_path = _prefix_to_checkpoint_path ( ckpt . model_checkpoint_path , <NEWLINE> saver_pb2 . SaverDef . V1 ) <NEWLINE> if file_io . get_matching_files ( v2_path ) or file_io . get_matching_files ( <NEWLINE> v1_path ) : <NEWLINE> <TAB> return ckpt . model_checkpoint_path <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> logging . error ( <STRING> , <NEWLINE> ckpt . model_checkpoint_path ) <NEWLINE> <UNTAB> <UNTAB> return None <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _add_to_cache ( self , module , key , module_hash ) : <NEWLINE> <TAB> <NEWLINE> name = module . __file__ <NEWLINE> _logger . debug ( <STRING> , <NEWLINE> key , name ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> assert key not in self . entry_from_key <NEWLINE> <NEWLINE> location = os . path . dirname ( name ) <NEWLINE> key_pkl = os . path . join ( location , <STRING> ) <NEWLINE> assert not os . path . exists ( key_pkl ) <NEWLINE> key_data = KeyData ( <NEWLINE> keys = set ( [ key ] ) , <NEWLINE> module_hash = module_hash , <NEWLINE> key_pkl = key_pkl , <NEWLINE> entry = name ) <NEWLINE> <NEWLINE> key_broken = False <NEWLINE> if key [ <NUMBER> ] : <NEWLINE> <TAB> try : <NEWLINE> <TAB> key_data . save_pkl ( ) <NEWLINE> <UNTAB> except pickle . PicklingError : <NEWLINE> <TAB> key_broken = True <NEWLINE> key_data . remove_key ( key ) <NEWLINE> key_data . save_pkl ( ) <NEWLINE> <UNTAB> if not key_broken and self . check_for_broken_eq : <NEWLINE> <TAB> self . check_key ( key , key_pkl ) <NEWLINE> <UNTAB> self . loaded_key_pkl . add ( key_pkl ) <NEWLINE> <UNTAB> elif config . cmodule . warn_no_version : <NEWLINE> <TAB> key_flat = flatten ( key ) <NEWLINE> ops = [ k for k in key_flat if isinstance ( k , theano . Op ) ] <NEWLINE> _logger . warning ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> + str ( ops ) ) <NEWLINE> <UNTAB> self . _update_mappings ( key , key_data , module . __file__ , not key_broken ) <NEWLINE> return key_data <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def number_of_nodes ( G ) : <NEWLINE> <TAB> <NEWLINE> return G . number_of_nodes ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def percentileofscore ( a , score , kind = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if np . isnan ( score ) : <NEWLINE> <TAB> return np . nan <NEWLINE> <UNTAB> a = np . asarray ( a ) <NEWLINE> n = len ( a ) <NEWLINE> if n == <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> if kind == <STRING> : <NEWLINE> <TAB> left = np . count_nonzero ( a < score ) <NEWLINE> right = np . count_nonzero ( a <= score ) <NEWLINE> pct = ( right + left + ( <NUMBER> if right > left else <NUMBER> ) ) * <NUMBER> / n <NEWLINE> return pct <NEWLINE> <UNTAB> elif kind == <STRING> : <NEWLINE> <TAB> return np . count_nonzero ( a < score ) / float ( n ) * <NUMBER> <NEWLINE> <UNTAB> elif kind == <STRING> : <NEWLINE> <TAB> return np . count_nonzero ( a <= score ) / float ( n ) * <NUMBER> <NEWLINE> <UNTAB> elif kind == <STRING> : <NEWLINE> <TAB> pct = ( np . count_nonzero ( a < score ) + np . count_nonzero ( a <= score ) ) / float ( n ) * <NUMBER> <NEWLINE> return pct <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def inverse ( self , argindex = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return cosh <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , names ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( names , dict ) : <NEWLINE> <TAB> names = vars ( names ) <NEWLINE> <UNTAB> self . names = names <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def english_upper ( s ) : <NEWLINE> <TAB> <NEWLINE> uppered = s . translate ( UPPER_TABLE ) <NEWLINE> return uppered <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __getattr__ ( self , name ) : <NEWLINE> <TAB> <NEWLINE> fl = self . _flags ( ) <NEWLINE> if name not in fl : <NEWLINE> <TAB> raise AttributeError ( name ) <NEWLINE> <UNTAB> if name in self . __dict__ [ <STRING> ] : <NEWLINE> <TAB> raise AttributeError ( name ) <NEWLINE> <NEWLINE> <UNTAB> if self . __dict__ [ <STRING> ] or fl [ name ] . present : <NEWLINE> <TAB> return fl [ name ] . value <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> error_message = ( <NEWLINE> <STRING> % name ) <NEWLINE> if six . PY2 : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> logging . error ( error_message ) <NEWLINE> <UNTAB> raise _exceptions . UnparsedFlagAccessError ( error_message ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def num_obs_linkage ( Z ) : <NEWLINE> <TAB> <NEWLINE> Z = np . asarray ( Z , order = <STRING> ) <NEWLINE> is_valid_linkage ( Z , throw = True , name = <STRING> ) <NEWLINE> return ( Z . shape [ <NUMBER> ] + <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def load_data ( label_mode = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if label_mode not in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> dirname = <STRING> <NEWLINE> origin = <STRING> <NEWLINE> path = get_file ( dirname , origin = origin , untar = True ) <NEWLINE> <NEWLINE> fpath = os . path . join ( path , <STRING> ) <NEWLINE> x_train , y_train = load_batch ( fpath , label_key = label_mode + <STRING> ) <NEWLINE> <NEWLINE> fpath = os . path . join ( path , <STRING> ) <NEWLINE> x_test , y_test = load_batch ( fpath , label_key = label_mode + <STRING> ) <NEWLINE> <NEWLINE> y_train = np . reshape ( y_train , ( len ( y_train ) , <NUMBER> ) ) <NEWLINE> y_test = np . reshape ( y_test , ( len ( y_test ) , <NUMBER> ) ) <NEWLINE> <NEWLINE> if K . image_data_format ( ) == <STRING> : <NEWLINE> <TAB> x_train = x_train . transpose ( <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> x_test = x_test . transpose ( <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> return ( x_train , y_train ) , ( x_test , y_test ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __ne__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return not self == other <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def tobytes ( self , fill_value = None , order = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return self . filled ( fill_value ) . tobytes ( order = order ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _homogenize_dict ( self , frames , intersect = True , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> result = dict ( ) <NEWLINE> <NEWLINE> if isinstance ( frames , OrderedDict ) : <NEWLINE> <TAB> result = OrderedDict ( ) <NEWLINE> <NEWLINE> <UNTAB> adj_frames = OrderedDict ( ) <NEWLINE> for k , v in compat . iteritems ( frames ) : <NEWLINE> <TAB> if isinstance ( v , dict ) : <NEWLINE> <TAB> adj_frames [ k ] = self . _constructor_sliced ( v ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> adj_frames [ k ] = v <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> axes = self . _AXIS_ORDERS [ <NUMBER> : ] <NEWLINE> axes_dict = dict ( ( a , ax ) for a , ax in zip ( axes , self . _extract_axes ( <NEWLINE> self , adj_frames , axes , intersect = intersect ) ) ) <NEWLINE> <NEWLINE> reindex_dict = dict ( <NEWLINE> [ ( self . _AXIS_SLICEMAP [ a ] , axes_dict [ a ] ) for a in axes ] ) <NEWLINE> reindex_dict [ <STRING> ] = False <NEWLINE> for key , frame in compat . iteritems ( adj_frames ) : <NEWLINE> <TAB> if frame is not None : <NEWLINE> <TAB> result [ key ] = frame . reindex ( ** reindex_dict ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result [ key ] = None <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> axes_dict [ <STRING> ] = result <NEWLINE> axes_dict [ <STRING> ] = dtype <NEWLINE> return axes_dict <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def lqmn ( m , n , z ) : <NEWLINE> <TAB> <NEWLINE> if not isscalar ( m ) or ( m < <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if not isscalar ( n ) or ( n < <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if not isscalar ( z ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> m = int ( m ) <NEWLINE> n = int ( n ) <NEWLINE> <NEWLINE> <NEWLINE> mm = max ( <NUMBER> , m ) <NEWLINE> nn = max ( <NUMBER> , n ) <NEWLINE> <NEWLINE> if iscomplex ( z ) : <NEWLINE> <TAB> q , qd = specfun . clqmn ( mm , nn , z ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> q , qd = specfun . lqmn ( mm , nn , z ) <NEWLINE> <UNTAB> return q [ : ( m + <NUMBER> ) , : ( n + <NUMBER> ) ] , qd [ : ( m + <NUMBER> ) , : ( n + <NUMBER> ) ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_lineoffset ( self , lineoffset ) : <NEWLINE> <TAB> <NEWLINE> if lineoffset == self . get_lineoffset ( ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> linelength = self . get_linelength ( ) <NEWLINE> segments = self . get_segments ( ) <NEWLINE> pos = <NUMBER> if self . is_horizontal ( ) else <NUMBER> <NEWLINE> for segment in segments : <NEWLINE> <TAB> segment [ <NUMBER> , pos ] = lineoffset + linelength / <NUMBER> <NEWLINE> segment [ <NUMBER> , pos ] = lineoffset - linelength / <NUMBER> <NEWLINE> <UNTAB> self . set_segments ( segments ) <NEWLINE> self . _lineoffset = lineoffset <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def blas_header_text ( ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> blas_code = <STRING> <NEWLINE> if not config . blas . ldflags : <NEWLINE> <NEWLINE> <TAB> current_filedir = dirname ( __file__ ) <NEWLINE> blas_common_filepath = os . path . join ( current_filedir , <STRING> , <STRING> ) <NEWLINE> blas_template_filepath = os . path . join ( current_filedir , <STRING> , <STRING> ) <NEWLINE> common_code = <STRING> <NEWLINE> sblas_code = <STRING> <NEWLINE> dblas_code = <STRING> <NEWLINE> with open ( blas_common_filepath ) as code : <NEWLINE> <TAB> common_code = code . read ( ) <NEWLINE> <UNTAB> with open ( blas_template_filepath ) as code : <NEWLINE> <TAB> template_code = code . read ( ) <NEWLINE> sblas_code = template_code % { <STRING> : <STRING> , <STRING> : <NUMBER> , <STRING> : <STRING> , <STRING> : <STRING> } <NEWLINE> dblas_code = template_code % { <STRING> : <STRING> , <STRING> : <NUMBER> , <STRING> : <STRING> , <STRING> : <STRING> } <NEWLINE> <UNTAB> if not common_code or not template_code : <NEWLINE> <TAB> raise IOError ( <STRING> ) <NEWLINE> <UNTAB> blas_code += common_code <NEWLINE> blas_code += sblas_code <NEWLINE> blas_code += dblas_code <NEWLINE> <NEWLINE> <UNTAB> header = <NEWLINE> <NEWLINE> if detect_macos_sdot_bug ( ) : <NEWLINE> <TAB> if detect_macos_sdot_bug . fix_works : <NEWLINE> <TAB> header += textwrap . dedent ( " " " \ 
                                         e x t e r n   " C "   f l o a t   c b l a s _ s d o t ( i n t ,   f l o a t * ,   i n t ,   f l o a t * ,   i n t ) ; 
                                         s t a t i c   f l o a t   s d o t _ ( i n t *   N x ,   f l o a t *   x ,   i n t *   S x ,   f l o a t *   y ,   i n t *   S y ) 
                                         { 
                                                 r e t u r n   c b l a s _ s d o t ( * N x ,   x ,   * S x ,   y ,   * S y ) ; 
                                         } 
                                         " " " ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> header += textwrap . dedent ( " " " \ 
                                         s t a t i c   f l o a t   s d o t _ ( i n t *   N x ,   f l o a t *   x ,   i n t *   S x ,   f l o a t *   y ,   i n t *   S y ) 
                                         { 
                                                 f p r i n t f ( s t d e r r , 
                                                         " F A T A L :   T h e   i m p l e m e n t a t i o n   o f   B L A S   S D O T   " 
                                                         " r o u t i n e   i n   y o u r   s y s t e m   h a s   a   b u g   t h a t   " 
                                                         " m a k e s   i t   r e t u r n   w r o n g   r e s u l t s . \ \ n " 
                                                         " P l e a s e   c o n t a c t   t h e a n o - d e v @ g r o u p s . g o o g l e . c o m . \ \ n " 
                                                         " Y o u   c a n   w o r k   a r o u n d   t h i s   b u g   b y   u s i n g   a   " 
                                                         " d i f f e r e n t   B L A S   l i b r a r y ,   o r   d i s a b l i n g   B L A S \ \ n " ) ; 
                                                 a s s e r t ( 0 ) ; 
                                         } 
                                         " " " ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return header + blas_code <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _invalid_indexer ( self , form , key ) : <NEWLINE> <TAB> <NEWLINE> raise TypeError ( <STRING> <NEWLINE> <STRING> . format ( <NEWLINE> form = form , klass = type ( self ) , key = key , <NEWLINE> kind = type ( key ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def load_build ( self ) : <NEWLINE> <TAB> <NEWLINE> Unpickler . load_build ( self ) <NEWLINE> <NEWLINE> <NEWLINE> if isinstance ( self . stack [ - <NUMBER> ] , ( NDArrayWrapper , NumpyArrayWrapper ) ) : <NEWLINE> <TAB> if self . np is None : <NEWLINE> <TAB> raise ImportError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> array_wrapper = self . stack . pop ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if isinstance ( array_wrapper , NDArrayWrapper ) : <NEWLINE> <TAB> self . compat_mode = True <NEWLINE> <UNTAB> self . stack . append ( array_wrapper . read ( self ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def get_value ( x ) : <NEWLINE> <TAB> <NEWLINE> if context . executing_eagerly ( ) : <NEWLINE> <TAB> return x . numpy ( ) <NEWLINE> <UNTAB> elif ops . inside_function ( ) : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> return x . eval ( session = get_session ( ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def stop_arg_tracking ( self , func_i ) : <NEWLINE> <TAB> <NEWLINE> for arg in self . func_to_argset [ func_i ] : <NEWLINE> <TAB> self . arg_to_funcset [ arg ] . remove ( func_i ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _infer_fill_value ( val ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not is_list_like ( val ) : <NEWLINE> <TAB> val = [ val ] <NEWLINE> <UNTAB> val = np . array ( val , copy = False ) <NEWLINE> if is_datetimelike ( val ) : <NEWLINE> <TAB> return np . array ( <STRING> , dtype = val . dtype ) <NEWLINE> <UNTAB> elif is_object_dtype ( val . dtype ) : <NEWLINE> <TAB> dtype = lib . infer_dtype ( _ensure_object ( val ) ) <NEWLINE> if dtype in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> return np . array ( <STRING> , dtype = _NS_DTYPE ) <NEWLINE> <UNTAB> elif dtype in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> return np . array ( <STRING> , dtype = _TD_DTYPE ) <NEWLINE> <UNTAB> <UNTAB> return np . nan <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_font ( self , prop ) : <NEWLINE> <TAB> <NEWLINE> fname = font_manager . findfont ( prop ) <NEWLINE> font = get_font ( fname ) <NEWLINE> font . set_size ( self . FONT_SCALE , self . DPI ) <NEWLINE> <NEWLINE> return font <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _coerce_method ( converter ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def wrapper ( self ) : <NEWLINE> <TAB> if len ( self ) == <NUMBER> : <NEWLINE> <TAB> return converter ( self . iloc [ <NUMBER> ] ) <NEWLINE> <UNTAB> raise TypeError ( <STRING> <NEWLINE> <STRING> . format ( str ( converter ) ) ) <NEWLINE> <NEWLINE> <UNTAB> return wrapper <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _linear_2eq_order2_type8 ( x , y , t , r , eq ) : <NEWLINE> <TAB> <NEWLINE> C1 , C2 , C3 , C4 = get_numbered_constants ( eq , num = <NUMBER> ) <NEWLINE> num , den = cancel ( r [ <STRING> ] / r [ <STRING> ] ) . as_numer_denom ( ) <NEWLINE> f = - r [ <STRING> ] / num <NEWLINE> a = num <NEWLINE> b = den <NEWLINE> mul = sqrt ( abs ( a * b ) ) <NEWLINE> Igral = Integral ( t * f , t ) <NEWLINE> if a * b > <NUMBER> : <NEWLINE> <TAB> u = C1 * a * exp ( mul * Igral ) + C2 * a * exp ( - mul * Igral ) <NEWLINE> v = C1 * mul * exp ( mul * Igral ) - C2 * mul * exp ( - mul * Igral ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> u = C1 * a * cos ( mul * Igral ) + C2 * a * sin ( mul * Igral ) <NEWLINE> v = - C1 * mul * sin ( mul * Igral ) + C2 * mul * cos ( mul * Igral ) <NEWLINE> <UNTAB> sol1 = C3 * t + t * Integral ( u / t ** <NUMBER> , t ) <NEWLINE> sol2 = C4 * t + t * Integral ( v / t ** <NUMBER> , t ) <NEWLINE> return [ Eq ( x ( t ) , sol1 ) , Eq ( y ( t ) , sol2 ) ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def can_composite ( self ) : <NEWLINE> <TAB> <NEWLINE> trans = self . get_transform ( ) <NEWLINE> return ( <NEWLINE> self . _interpolation != <STRING> and <NEWLINE> trans . is_affine and <NEWLINE> trans . is_separable ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def report ( self , values , observer = None ) : <NEWLINE> <TAB> <NEWLINE> if not configuration . config . keep_graph_on_report : <NEWLINE> <TAB> values = { k : _copy_variable ( v ) for k , v in six . iteritems ( values ) } <NEWLINE> <NEWLINE> <UNTAB> if observer is not None : <NEWLINE> <TAB> observer_id = id ( observer ) <NEWLINE> if observer_id not in self . _observer_names : <NEWLINE> <TAB> raise KeyError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> observer_name = self . _observer_names [ observer_id ] <NEWLINE> for key , value in six . iteritems ( values ) : <NEWLINE> <TAB> name = <STRING> % ( observer_name , key ) <NEWLINE> self . observation [ name ] = value <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> self . observation . update ( values ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def unbroadcast_tensor ( tensor , like ) : <NEWLINE> <TAB> <NEWLINE> return unbroadcast_tfe_to ( tensor , shape_as_list ( like ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_view_definition ( self , connection , view_name , schema = None , ** kw ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ deprecated ( <NEWLINE> <STRING> , <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> def _get_feature_ops_from_example ( self , examples_batch ) : <NEWLINE> <TAB> <NEWLINE> if self . _features_info is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return tensor_signature . create_example_parser_from_signatures ( <NEWLINE> self . _features_info , examples_batch ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def eject ( f , * gens ) : <NEWLINE> <TAB> <NEWLINE> dom = f . rep . dom <NEWLINE> <NEWLINE> if not dom . is_Numerical : <NEWLINE> <TAB> raise DomainError ( <STRING> % dom ) <NEWLINE> <NEWLINE> <UNTAB> n , k = len ( f . gens ) , len ( gens ) <NEWLINE> <NEWLINE> if f . gens [ : k ] == gens : <NEWLINE> <TAB> _gens , front = f . gens [ k : ] , True <NEWLINE> <UNTAB> elif f . gens [ - k : ] == gens : <NEWLINE> <TAB> _gens , front = f . gens [ : - k ] , False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> dom = dom . inject ( * gens ) <NEWLINE> <NEWLINE> if hasattr ( f . rep , <STRING> ) : <NEWLINE> <TAB> result = f . rep . eject ( dom , front = front ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise OperationNotSupported ( f , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return f . new ( result , * _gens ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def encode_jpeg ( image , format = <STRING> , quality = <NUMBER> , progressive = False , optimize_size = False , chroma_downsampling = True , density_unit = <STRING> , x_density = <NUMBER> , y_density = <NUMBER> , xmp_metadata = <STRING> , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if format is None : <NEWLINE> <TAB> format = <STRING> <NEWLINE> <UNTAB> format = _execute . make_str ( format , <STRING> ) <NEWLINE> if quality is None : <NEWLINE> <TAB> quality = <NUMBER> <NEWLINE> <UNTAB> quality = _execute . make_int ( quality , <STRING> ) <NEWLINE> if progressive is None : <NEWLINE> <TAB> progressive = False <NEWLINE> <UNTAB> progressive = _execute . make_bool ( progressive , <STRING> ) <NEWLINE> if optimize_size is None : <NEWLINE> <TAB> optimize_size = False <NEWLINE> <UNTAB> optimize_size = _execute . make_bool ( optimize_size , <STRING> ) <NEWLINE> if chroma_downsampling is None : <NEWLINE> <TAB> chroma_downsampling = True <NEWLINE> <UNTAB> chroma_downsampling = _execute . make_bool ( chroma_downsampling , <STRING> ) <NEWLINE> if density_unit is None : <NEWLINE> <TAB> density_unit = <STRING> <NEWLINE> <UNTAB> density_unit = _execute . make_str ( density_unit , <STRING> ) <NEWLINE> if x_density is None : <NEWLINE> <TAB> x_density = <NUMBER> <NEWLINE> <UNTAB> x_density = _execute . make_int ( x_density , <STRING> ) <NEWLINE> if y_density is None : <NEWLINE> <TAB> y_density = <NUMBER> <NEWLINE> <UNTAB> y_density = _execute . make_int ( y_density , <STRING> ) <NEWLINE> if xmp_metadata is None : <NEWLINE> <TAB> xmp_metadata = <STRING> <NEWLINE> <UNTAB> xmp_metadata = _execute . make_str ( xmp_metadata , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , image = image , format = format , quality = quality , <NEWLINE> progressive = progressive , optimize_size = optimize_size , <NEWLINE> chroma_downsampling = chroma_downsampling , density_unit = density_unit , <NEWLINE> x_density = x_density , y_density = y_density , xmp_metadata = xmp_metadata , <NEWLINE> name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , image , <STRING> , format , <NEWLINE> <STRING> , quality , <STRING> , progressive , <STRING> , <NEWLINE> optimize_size , <STRING> , chroma_downsampling , <NEWLINE> <STRING> , density_unit , <STRING> , x_density , <STRING> , <NEWLINE> y_density , <STRING> , xmp_metadata ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return encode_jpeg_eager_fallback ( <NEWLINE> image , format = format , quality = quality , progressive = progressive , <NEWLINE> optimize_size = optimize_size , <NEWLINE> chroma_downsampling = chroma_downsampling , density_unit = density_unit , <NEWLINE> x_density = x_density , y_density = y_density , xmp_metadata = xmp_metadata , <NEWLINE> name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _add_doc ( func , doc ) : <NEWLINE> <TAB> <NEWLINE> func . __doc__ = doc <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def assertLess ( self , a , b , msg = None ) : <NEWLINE> <TAB> <NEWLINE> if not a < b : <NEWLINE> <TAB> standardMsg = <STRING> % ( safe_repr ( a ) , safe_repr ( b ) ) <NEWLINE> self . fail ( self . _formatMessage ( msg , standardMsg ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , value ) : <NEWLINE> <TAB> <NEWLINE> if not ( isinstance ( value , ops . Tensor ) and value . dtype . is_floating ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( value ) ) <NEWLINE> <UNTAB> self . _value = value <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def all_gather ( tensor_list , tensor , group = group . WORLD ) : <NEWLINE> <TAB> <NEWLINE> assert torch . distributed . _initialized == _INITIALIZED_PG , <STRING> <NEWLINE> if _backend != dist_backend . NCCL : <NEWLINE> <TAB> return torch . _C . _dist_all_gather ( tensor_list , tensor , group ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return all_gather_multigpu ( [ tensor_list ] , [ tensor ] , group ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _linear_2eq_order1_type3 ( x , y , t , r , eq ) : <NEWLINE> <TAB> <NEWLINE> C1 , C2 , C3 , C4 = get_numbered_constants ( eq , num = <NUMBER> ) <NEWLINE> F = Integral ( r [ <STRING> ] , t ) <NEWLINE> G = Integral ( r [ <STRING> ] , t ) <NEWLINE> sol1 = exp ( F ) * ( C1 * exp ( G ) + C2 * exp ( - G ) ) <NEWLINE> sol2 = exp ( F ) * ( C1 * exp ( G ) - C2 * exp ( - G ) ) <NEWLINE> return [ Eq ( x ( t ) , sol1 ) , Eq ( y ( t ) , sol2 ) ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _maybe_cast_indexed ( self , key ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( key , IntervalIndex ) : <NEWLINE> <TAB> return key <NEWLINE> <NEWLINE> <UNTAB> subtype = self . dtype . subtype <NEWLINE> if is_float_dtype ( subtype ) : <NEWLINE> <TAB> if is_integer ( key ) : <NEWLINE> <TAB> key = float ( key ) <NEWLINE> <UNTAB> elif isinstance ( key , ( np . ndarray , Index ) ) : <NEWLINE> <TAB> key = key . astype ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> elif is_integer_dtype ( subtype ) : <NEWLINE> <TAB> if is_integer ( key ) : <NEWLINE> <TAB> key = int ( key ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return key <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def literal ( value , type_ = None ) : <NEWLINE> <TAB> <NEWLINE> return BindParameter ( None , value , type_ = type_ , unique = True ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def make_block ( self , values , placement = None , ndim = None ) : <NEWLINE> <TAB> <NEWLINE> if placement is None : <NEWLINE> <TAB> placement = self . mgr_locs <NEWLINE> <UNTAB> if ndim is None : <NEWLINE> <TAB> ndim = self . ndim <NEWLINE> <NEWLINE> <UNTAB> return make_block ( values , placement = placement , ndim = ndim ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , colorbar ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . _colorbar = colorbar <NEWLINE> nbins = <STRING> <NEWLINE> steps = [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] <NEWLINE> super ( ) . __init__ ( nbins = nbins , steps = steps ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sparse_matmul ( a , b , transa = False , transb = False ) : <NEWLINE> <TAB> <NEWLINE> if ( isinstance ( a , utils . CooMatrix ) and <NEWLINE> isinstance ( b , ( chainer . Variable , numpy . ndarray , cuda . ndarray ) ) ) : <NEWLINE> <TAB> return CooMatMul ( a . row , a . col , a . shape , a . order , <NEWLINE> transa = transa , <NEWLINE> transb = transb , <NEWLINE> transc = False ) . apply ( ( a . data , b ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> elif ( isinstance ( a , ( chainer . Variable , numpy . ndarray , cuda . ndarray ) ) and <NEWLINE> isinstance ( b , utils . CooMatrix ) ) : <NEWLINE> <TAB> return CooMatMul ( b . row , b . col , b . shape , b . order , <NEWLINE> transa = not transb , <NEWLINE> transb = not transa , <NEWLINE> transc = True ) . apply ( ( b . data , a ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> msg += <STRING> . format ( type ( a ) ) <NEWLINE> msg += <STRING> . format ( type ( b ) ) <NEWLINE> raise ValueError ( msg ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def hann ( M , sym = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return general_hamming ( M , <NUMBER> , sym ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def revert ( f , n ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( f . rep , <STRING> ) : <NEWLINE> <TAB> result = f . rep . revert ( int ( n ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise OperationNotSupported ( f , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return f . per ( result ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def entails ( expr , formula_set = { } ) : <NEWLINE> <TAB> <NEWLINE> formula_set = list ( formula_set ) <NEWLINE> formula_set . append ( Not ( expr ) ) <NEWLINE> return not satisfiable ( And ( * formula_set ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ contextlib . contextmanager <NEWLINE> def _assign_dependencies ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _cached_value is not None : <NEWLINE> <TAB> with ops . control_dependencies ( [ self . _cached_value ] ) : <NEWLINE> <TAB> yield <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> yield <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def make_tex_preview ( self , tex , fontsize ) : <NEWLINE> <TAB> <NEWLINE> basefile = self . get_basefile ( tex , fontsize ) <NEWLINE> texfile = <STRING> % basefile <NEWLINE> custom_preamble = self . get_custom_preamble ( ) <NEWLINE> fontcmd = { <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> } . get ( self . font_family , <NEWLINE> <STRING> ) <NEWLINE> tex = fontcmd % tex <NEWLINE> <NEWLINE> if rcParams [ <STRING> ] : <NEWLINE> <TAB> unicode_preamble = <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> unicode_preamble = <STRING> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> s = r " " " 
 \ d o c u m e n t c l a s s { a r t i c l e } 
 % s 
 % s 
 % s 
 \ u s e p a c k a g e [ a c t i v e , s h o w b o x , t i g h t p a g e ] { p r e v i e w } 
 \ u s e p a c k a g e [ p a p e r s i z e = { 7 2 i n , 7 2 i n } , b o d y = { 7 0 i n , 7 0 i n } , m a r g i n = { 1 i n , 1 i n } ] { g e o m e t r y } 
 
 % %   w e   o v e r r i d e   t h e   d e f a u l t   s h o w b o x   a s   i t   i s   t r e a t e d   a s   a n   e r r o r   a n d   m a k e s 
 % %   t h e   e x i t   s t a t u s   n o t   z e r o 
 \ d e f \ s h o w b o x # 1 % % 
 { \ i m m e d i a t e \ w r i t e 1 6 { M a t p l o t l i b B o x : ( \ t h e \ h t # 1 + \ t h e \ d p # 1 ) x \ t h e \ w d # 1 } } 
 
 \ b e g i n { d o c u m e n t } 
 \ b e g i n { p r e v i e w } 
 { \ f o n t s i z e { % f } { % f } % s } 
 \ e n d { p r e v i e w } 
 \ e n d { d o c u m e n t } 
 " " " % ( self . _font_preamble , unicode_preamble , custom_preamble , <NEWLINE> fontsize , fontsize * <NUMBER> , tex ) <NEWLINE> with open ( texfile , <STRING> ) as fh : <NEWLINE> <TAB> if rcParams [ <STRING> ] : <NEWLINE> <TAB> fh . write ( s . encode ( <STRING> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> fh . write ( s . encode ( <STRING> ) ) <NEWLINE> <UNTAB> except UnicodeEncodeError as err : <NEWLINE> <TAB> _log . info ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> raise <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return texfile <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _mean ( self , dim , df , scale ) : <NEWLINE> <TAB> <NEWLINE> if df > dim + <NUMBER> : <NEWLINE> <TAB> out = scale / ( df - dim - <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> out = None <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_top_layer ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _spritelayers [ self . _spritelist [ - <NUMBER> ] ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tc . returns ( types . FunctionType ) <NEWLINE> @ tc . accepts ( string_types , collections . Callable ) <NEWLINE> def define_reduce_op ( op_name , reduce_fn ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> default_name = <STRING> % op_name <NEWLINE> <NEWLINE> @ tc . returns ( core . LabeledTensor ) <NEWLINE> @ tc . accepts ( core . LabeledTensorLike , ReduceAxes , tc . Optional ( string_types ) ) <NEWLINE> def op ( labeled_tensor , axes = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , default_name , [ labeled_tensor ] ) as scope : <NEWLINE> <TAB> labeled_tensor = core . convert_to_labeled_tensor ( labeled_tensor ) <NEWLINE> <NEWLINE> if axes is None : <NEWLINE> <TAB> axes = labeled_tensor . axes . keys ( ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( axes , ( string_types , tuple ) ) : <NEWLINE> <TAB> axes = [ axes ] <NEWLINE> <NEWLINE> <UNTAB> reduction_axes = { } <NEWLINE> axes_to_squeeze = [ ] <NEWLINE> for a in axes : <NEWLINE> <TAB> if isinstance ( a , string_types ) : <NEWLINE> <NEWLINE> <TAB> reduction_axes [ a ] = a <NEWLINE> axes_to_squeeze . append ( a ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> ( axis_name , label ) = a <NEWLINE> if label is not None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> label = [ label ] <NEWLINE> <UNTAB> reduction_axes [ axis_name ] = ( axis_name , label ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for axis_name in reduction_axes : <NEWLINE> <TAB> if axis_name not in labeled_tensor . axes : <NEWLINE> <TAB> raise ValueError ( <STRING> % <NEWLINE> ( axis_name , labeled_tensor . axes ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> intermediate_axes = [ ] <NEWLINE> reduction_dimensions = [ ] <NEWLINE> for i , axis in enumerate ( labeled_tensor . axes . values ( ) ) : <NEWLINE> <TAB> if axis . name in reduction_axes : <NEWLINE> <TAB> intermediate_axes . append ( reduction_axes [ axis . name ] ) <NEWLINE> reduction_dimensions . append ( i ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> intermediate_axes . append ( axis ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> reduce_op = reduce_fn ( <NEWLINE> labeled_tensor . tensor , reduction_dimensions , keepdims = True ) <NEWLINE> reduce_lt = core . LabeledTensor ( reduce_op , intermediate_axes ) <NEWLINE> <NEWLINE> return squeeze ( reduce_lt , axes_to_squeeze , name = scope ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> op . __doc__ = op . __doc__ . format ( op_name = op_name ) <NEWLINE> op . __name__ = op_name <NEWLINE> <NEWLINE> return op <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_cursor ( self , cursor ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def compute_sample_weight ( class_weight , y , indices = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> y = np . atleast_1d ( y ) <NEWLINE> if y . ndim == <NUMBER> : <NEWLINE> <TAB> y = np . reshape ( y , ( - <NUMBER> , <NUMBER> ) ) <NEWLINE> <UNTAB> n_outputs = y . shape [ <NUMBER> ] <NEWLINE> <NEWLINE> if isinstance ( class_weight , six . string_types ) : <NEWLINE> <TAB> if class_weight not in [ <STRING> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % class_weight ) <NEWLINE> <UNTAB> <UNTAB> elif ( indices is not None and <NEWLINE> not isinstance ( class_weight , six . string_types ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % class_weight ) <NEWLINE> <UNTAB> elif n_outputs > <NUMBER> : <NEWLINE> <TAB> if ( not hasattr ( class_weight , <STRING> ) or <NEWLINE> isinstance ( class_weight , dict ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if len ( class_weight ) != n_outputs : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> expanded_class_weight = [ ] <NEWLINE> for k in range ( n_outputs ) : <NEWLINE> <NEWLINE> <TAB> y_full = y [ : , k ] <NEWLINE> classes_full = np . unique ( y_full ) <NEWLINE> classes_missing = None <NEWLINE> <NEWLINE> if class_weight == <STRING> or n_outputs == <NUMBER> : <NEWLINE> <TAB> class_weight_k = class_weight <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> class_weight_k = class_weight [ k ] <NEWLINE> <NEWLINE> <UNTAB> if indices is not None : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> y_subsample = y [ indices , k ] <NEWLINE> classes_subsample = np . unique ( y_subsample ) <NEWLINE> <NEWLINE> weight_k = np . choose ( np . searchsorted ( classes_subsample , <NEWLINE> classes_full ) , <NEWLINE> compute_class_weight ( class_weight_k , <NEWLINE> classes_subsample , <NEWLINE> y_subsample ) , <NEWLINE> mode = <STRING> ) <NEWLINE> <NEWLINE> classes_missing = set ( classes_full ) - set ( classes_subsample ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> weight_k = compute_class_weight ( class_weight_k , <NEWLINE> classes_full , <NEWLINE> y_full ) <NEWLINE> <NEWLINE> <UNTAB> weight_k = weight_k [ np . searchsorted ( classes_full , y_full ) ] <NEWLINE> <NEWLINE> if classes_missing : <NEWLINE> <NEWLINE> <TAB> weight_k [ np . in1d ( y_full , list ( classes_missing ) ) ] = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> expanded_class_weight . append ( weight_k ) <NEWLINE> <NEWLINE> <UNTAB> expanded_class_weight = np . prod ( expanded_class_weight , <NEWLINE> axis = <NUMBER> , <NEWLINE> dtype = np . float64 ) <NEWLINE> <NEWLINE> return expanded_class_weight <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def degree_histogram ( G ) : <NEWLINE> <TAB> <NEWLINE> counts = Counter ( d for n , d in G . degree ( ) ) <NEWLINE> return [ counts . get ( i , <NUMBER> ) for i in range ( max ( counts ) + <NUMBER> ) ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def angle ( input , Tout = _dtypes . float32 , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if Tout is None : <NEWLINE> <TAB> Tout = _dtypes . float32 <NEWLINE> <UNTAB> Tout = _execute . make_type ( Tout , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , Tout = Tout , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , input , <STRING> , Tout ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return angle_eager_fallback ( <NEWLINE> input , Tout = Tout , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def freqz ( b , a = <NUMBER> , worN = <NUMBER> , whole = False , plot = None ) : <NEWLINE> <TAB> <NEWLINE> b = atleast_1d ( b ) <NEWLINE> a = atleast_1d ( a ) <NEWLINE> <NEWLINE> if worN is None : <NEWLINE> <TAB> worN = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> h = None <NEWLINE> try : <NEWLINE> <TAB> worN = operator . index ( worN ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> w = atleast_1d ( worN ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if worN < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( worN , ) ) <NEWLINE> <UNTAB> lastpoint = <NUMBER> * pi if whole else pi <NEWLINE> w = np . linspace ( <NUMBER> , lastpoint , worN , endpoint = False ) <NEWLINE> if ( a . size == <NUMBER> and worN >= b . shape [ <NUMBER> ] and <NEWLINE> fftpack . next_fast_len ( worN ) == worN and <NEWLINE> ( b . ndim == <NUMBER> or ( b . shape [ - <NUMBER> ] == <NUMBER> ) ) ) : <NEWLINE> <NEWLINE> <TAB> n_fft = worN if whole else worN * <NUMBER> <NEWLINE> if np . isrealobj ( b ) and np . isrealobj ( a ) : <NEWLINE> <TAB> fft_func = np . fft . rfft <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> fft_func = fftpack . fft <NEWLINE> <UNTAB> h = fft_func ( b , n = n_fft , axis = <NUMBER> ) [ : worN ] <NEWLINE> h /= a <NEWLINE> if fft_func is np . fft . rfft and whole : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> stop = - <NUMBER> if n_fft % <NUMBER> == <NUMBER> else - <NUMBER> <NEWLINE> h_flip = slice ( stop , <NUMBER> , - <NUMBER> ) <NEWLINE> h = np . concatenate ( ( h , h [ h_flip ] . conj ( ) ) ) <NEWLINE> <UNTAB> if b . ndim > <NUMBER> : <NEWLINE> <NEWLINE> <TAB> h = h [ ... , <NUMBER> ] <NEWLINE> <NEWLINE> h = np . rollaxis ( h , <NUMBER> , h . ndim ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> del worN <NEWLINE> <NEWLINE> if h is None : <NEWLINE> <TAB> zm1 = exp ( - <NUMBER> * w ) <NEWLINE> h = ( npp_polyval ( zm1 , b , tensor = False ) / <NEWLINE> npp_polyval ( zm1 , a , tensor = False ) ) <NEWLINE> <UNTAB> if plot is not None : <NEWLINE> <TAB> plot ( w , h ) <NEWLINE> <NEWLINE> <UNTAB> return w , h <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def transform ( self , X ) : <NEWLINE> <TAB> <NEWLINE> check_is_fitted ( self , [ <STRING> , <STRING> ] ) <NEWLINE> <NEWLINE> X = check_array ( X , dtype = FLOAT_DTYPES , accept_sparse = <STRING> ) <NEWLINE> n_samples , n_features = X . shape <NEWLINE> <NEWLINE> if n_features != self . n_input_features_ : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> combinations = self . _combinations ( n_features , self . degree , <NEWLINE> self . interaction_only , <NEWLINE> self . include_bias ) <NEWLINE> if sparse . isspmatrix ( X ) : <NEWLINE> <TAB> columns = [ ] <NEWLINE> for comb in combinations : <NEWLINE> <TAB> if comb : <NEWLINE> <TAB> out_col = <NUMBER> <NEWLINE> for col_idx in comb : <NEWLINE> <TAB> out_col = X [ : , col_idx ] . multiply ( out_col ) <NEWLINE> <UNTAB> columns . append ( out_col ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> columns . append ( sparse . csc_matrix ( np . ones ( ( X . shape [ <NUMBER> ] , <NUMBER> ) ) ) ) <NEWLINE> <UNTAB> <UNTAB> XP = sparse . hstack ( columns , dtype = X . dtype ) . tocsc ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> XP = np . empty ( ( n_samples , self . n_output_features_ ) , dtype = X . dtype ) <NEWLINE> for i , comb in enumerate ( combinations ) : <NEWLINE> <TAB> XP [ : , i ] = X [ : , comb ] . prod ( <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return XP <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _cseries_to_zseries ( c ) : <NEWLINE> <TAB> <NEWLINE> n = c . size <NEWLINE> zs = np . zeros ( <NUMBER> * n - <NUMBER> , dtype = c . dtype ) <NEWLINE> zs [ n - <NUMBER> : ] = c / <NUMBER> <NEWLINE> return zs + zs [ : : - <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def dropna ( self ) : <NEWLINE> <TAB> <NEWLINE> result = self [ self . notna ( ) ] <NEWLINE> <NEWLINE> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def prod ( self , axis = None , dtype = None , out = None ) : <NEWLINE> <TAB> <NEWLINE> return N . ndarray . prod ( self , axis , dtype , out , keepdims = True ) . _collapse ( axis ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def minorticks_on ( self ) : <NEWLINE> <TAB> <NEWLINE> for ax in ( self . xaxis , self . yaxis ) : <NEWLINE> <TAB> scale = ax . get_scale ( ) <NEWLINE> if scale == <STRING> : <NEWLINE> <TAB> s = ax . _scale <NEWLINE> ax . set_minor_locator ( mticker . LogLocator ( s . base , s . subs ) ) <NEWLINE> <UNTAB> elif scale == <STRING> : <NEWLINE> <TAB> s = ax . _scale <NEWLINE> ax . set_minor_locator ( <NEWLINE> mticker . SymmetricalLogLocator ( s . _transform , s . subs ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ax . set_minor_locator ( mticker . AutoMinorLocator ( ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def weight_tensor ( self , input_tensor ) : <NEWLINE> <TAB> <NEWLINE> return input_tensor [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def select ( self , whereclause = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> collist = [ self . left , self . right ] <NEWLINE> <NEWLINE> return Select ( collist , whereclause , from_obj = [ self ] , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def sparse_cross ( inputs , name = None ) : <NEWLINE> <TAB> <NEWLINE> return _sparse_cross_internal ( inputs = inputs , hashed_output = False , name = name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def annotate_axes ( self , ax ) : <NEWLINE> <TAB> <NEWLINE> if self . orient == <STRING> : <NEWLINE> <TAB> xlabel , ylabel = self . group_label , self . value_label <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> xlabel , ylabel = self . value_label , self . group_label <NEWLINE> <NEWLINE> <UNTAB> if xlabel is not None : <NEWLINE> <TAB> ax . set_xlabel ( xlabel ) <NEWLINE> <UNTAB> if ylabel is not None : <NEWLINE> <TAB> ax . set_ylabel ( ylabel ) <NEWLINE> <NEWLINE> <UNTAB> if self . orient == <STRING> : <NEWLINE> <TAB> ax . set_xticks ( np . arange ( len ( self . plot_data ) ) ) <NEWLINE> ax . set_xticklabels ( self . group_names ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ax . set_yticks ( np . arange ( len ( self . plot_data ) ) ) <NEWLINE> ax . set_yticklabels ( self . group_names ) <NEWLINE> <NEWLINE> <UNTAB> if self . orient == <STRING> : <NEWLINE> <TAB> ax . xaxis . grid ( False ) <NEWLINE> ax . set_xlim ( - <NUMBER> , len ( self . plot_data ) - <NUMBER> , auto = None ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ax . yaxis . grid ( False ) <NEWLINE> ax . set_ylim ( - <NUMBER> , len ( self . plot_data ) - <NUMBER> , auto = None ) <NEWLINE> <NEWLINE> <UNTAB> if self . hue_names is not None : <NEWLINE> <TAB> leg = ax . legend ( loc = <STRING> ) <NEWLINE> if self . hue_title is not None : <NEWLINE> <TAB> leg . set_title ( self . hue_title ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> title_size = mpl . rcParams [ <STRING> ] * <NUMBER> <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> title_size = mpl . rcParams [ <STRING> ] <NEWLINE> <UNTAB> prop = mpl . font_manager . FontProperties ( size = title_size ) <NEWLINE> leg . _legend_title_box . _text . set_font_properties ( prop ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_width ( self , width ) : <NEWLINE> <TAB> <NEWLINE> self . width = width <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __repr__ ( self ) : <NEWLINE> <TAB> <NEWLINE> from sympy . printing import sstr <NEWLINE> return sstr ( self , order = None ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _minpoly_sin ( ex , x ) : <NEWLINE> <TAB> <NEWLINE> c , a = ex . args [ <NUMBER> ] . as_coeff_Mul ( ) <NEWLINE> if a is pi : <NEWLINE> <TAB> if c . is_rational : <NEWLINE> <TAB> n = c . q <NEWLINE> q = sympify ( n ) <NEWLINE> if q . is_prime : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> a = dup_chebyshevt ( n , ZZ ) <NEWLINE> return Add ( * [ x ** ( n - i - <NUMBER> ) * a [ i ] for i in range ( n ) ] ) <NEWLINE> <UNTAB> if c . p == <NUMBER> : <NEWLINE> <TAB> if q == <NUMBER> : <NEWLINE> <TAB> return <NUMBER> * x ** <NUMBER> - <NUMBER> * x ** <NUMBER> + <NUMBER> * x ** <NUMBER> - <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if n % <NUMBER> == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> a = dup_chebyshevt ( n , ZZ ) <NEWLINE> a = [ x ** ( n - i ) * a [ i ] for i in range ( n + <NUMBER> ) ] <NEWLINE> r = Add ( * a ) <NEWLINE> _ , factors = factor_list ( r ) <NEWLINE> res = _choose_factor ( factors , x , ex ) <NEWLINE> return res <NEWLINE> <NEWLINE> <UNTAB> expr = ( ( <NUMBER> - cos ( <NUMBER> * c * pi ) ) / <NUMBER> ) ** S . Half <NEWLINE> res = _minpoly_compose ( expr , x , QQ ) <NEWLINE> return res <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> raise NotAlgebraic ( <STRING> % ex ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _raise_warnings ( image_properties ) : <NEWLINE> <TAB> <NEWLINE> ip = image_properties <NEWLINE> if ip . unsupported_dtype : <NEWLINE> <TAB> warn ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if ip . low_data_range : <NEWLINE> <TAB> warn ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if ip . out_of_range_float : <NEWLINE> <TAB> warn ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def numpy_scalar ( data ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if ( data . ndim > <NUMBER> and <NEWLINE> ( len ( data . shape ) == <NUMBER> or <NEWLINE> builtins . max ( data . shape ) == <NUMBER> ) ) : <NEWLINE> <TAB> assert np . all ( np . array ( [ ] ) == data ) <NEWLINE> raise EmptyConstantError ( ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> np . complex ( data ) <NEWLINE> return data <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> raise NotScalarConstantError ( <NEWLINE> <STRING> <NEWLINE> <STRING> , data ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_sympy ( self , a ) : <NEWLINE> <TAB> <NEWLINE> return SymPyInteger ( int ( a ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def reshapelist ( shape , seq ) : <NEWLINE> <TAB> <NEWLINE> if len ( shape ) == <NUMBER> : <NEWLINE> <TAB> return list ( seq ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> n = int ( len ( seq ) / shape [ <NUMBER> ] ) <NEWLINE> return [ reshapelist ( shape [ <NUMBER> : ] , part ) for part in partition ( n , seq ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def std ( self , axis = None , dtype = None , out = None , ddof = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return N . ndarray . std ( self , axis , dtype , out , ddof , keepdims = True ) . _collapse ( axis ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _covhelper ( x , y = None , rowvar = True , allow_masked = True ) : <NEWLINE> <TAB> <NEWLINE> x = ma . array ( x , ndmin = <NUMBER> , copy = True , dtype = float ) <NEWLINE> xmask = ma . getmaskarray ( x ) <NEWLINE> <NEWLINE> if not allow_masked and xmask . any ( ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if x . shape [ <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> rowvar = True <NEWLINE> <NEWLINE> <UNTAB> rowvar = int ( bool ( rowvar ) ) <NEWLINE> axis = <NUMBER> - rowvar <NEWLINE> if rowvar : <NEWLINE> <TAB> tup = ( slice ( None ) , None ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> tup = ( None , slice ( None ) ) <NEWLINE> <NEWLINE> <UNTAB> if y is None : <NEWLINE> <TAB> xnotmask = np . logical_not ( xmask ) . astype ( int ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> y = array ( y , copy = False , ndmin = <NUMBER> , dtype = float ) <NEWLINE> ymask = ma . getmaskarray ( y ) <NEWLINE> if not allow_masked and ymask . any ( ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if xmask . any ( ) or ymask . any ( ) : <NEWLINE> <TAB> if y . shape == x . shape : <NEWLINE> <NEWLINE> <TAB> common_mask = np . logical_or ( xmask , ymask ) <NEWLINE> if common_mask is not nomask : <NEWLINE> <TAB> xmask = x . _mask = y . _mask = ymask = common_mask <NEWLINE> x . _sharedmask = False <NEWLINE> y . _sharedmask = False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> x = ma . concatenate ( ( x , y ) , axis ) <NEWLINE> xnotmask = np . logical_not ( np . concatenate ( ( xmask , ymask ) , axis ) ) . astype ( int ) <NEWLINE> <UNTAB> x -= x . mean ( axis = rowvar ) [ tup ] <NEWLINE> return ( x , xnotmask , rowvar ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _set_transform ( self ) : <NEWLINE> <TAB> <NEWLINE> dx = self . _dots_per_unit ( self . units ) <NEWLINE> self . _trans_scale = dx <NEWLINE> trans = transforms . Affine2D ( ) . scale ( dx ) <NEWLINE> self . set_transform ( trans ) <NEWLINE> return trans <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def trigsimp ( expr , ** opts ) : <NEWLINE> <TAB> <NEWLINE> from sympy . simplify . fu import fu <NEWLINE> <NEWLINE> expr = sympify ( expr ) <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> return expr . _eval_trigsimp ( ** opts ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> old = opts . pop ( <STRING> , False ) <NEWLINE> if not old : <NEWLINE> <TAB> opts . pop ( <STRING> , None ) <NEWLINE> recursive = opts . pop ( <STRING> , None ) <NEWLINE> method = opts . pop ( <STRING> , <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> method = <STRING> <NEWLINE> <NEWLINE> <UNTAB> def groebnersimp ( ex , ** opts ) : <NEWLINE> <TAB> def traverse ( e ) : <NEWLINE> <TAB> if e . is_Atom : <NEWLINE> <TAB> return e <NEWLINE> <UNTAB> args = [ traverse ( x ) for x in e . args ] <NEWLINE> if e . is_Function or e . is_Pow : <NEWLINE> <TAB> args = [ trigsimp_groebner ( x , ** opts ) for x in args ] <NEWLINE> <UNTAB> return e . func ( * args ) <NEWLINE> <UNTAB> new = traverse ( ex ) <NEWLINE> if not isinstance ( new , Expr ) : <NEWLINE> <TAB> return new <NEWLINE> <UNTAB> return trigsimp_groebner ( new , ** opts ) <NEWLINE> <NEWLINE> <UNTAB> trigsimpfunc = { <NEWLINE> <STRING> : ( lambda x : fu ( x , ** opts ) ) , <NEWLINE> <STRING> : ( lambda x : futrig ( x ) ) , <NEWLINE> <STRING> : ( lambda x : groebnersimp ( x , ** opts ) ) , <NEWLINE> <STRING> : ( lambda x : futrig ( groebnersimp ( x , <NEWLINE> polynomial = True , hints = [ <NUMBER> , tan ] ) ) ) , <NEWLINE> <STRING> : lambda x : trigsimp_old ( x , ** opts ) , <NEWLINE> } [ method ] <NEWLINE> <NEWLINE> return trigsimpfunc ( expr ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dimension ( * args ) : <NEWLINE> <TAB> <NEWLINE> if len ( args ) > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> parameters = [ ] <NEWLINE> for arg in args : <NEWLINE> <TAB> if isinstance ( arg , Extent ) : <NEWLINE> <TAB> parameters . append ( arg ) <NEWLINE> <UNTAB> elif isinstance ( arg , string_types ) : <NEWLINE> <TAB> if arg == <STRING> : <NEWLINE> <TAB> parameters . append ( Extent ( ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> parameters . append ( String ( arg ) ) <NEWLINE> <UNTAB> <UNTAB> elif iterable ( arg ) : <NEWLINE> <TAB> parameters . append ( Extent ( * arg ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> parameters . append ( sympify ( arg ) ) <NEWLINE> <UNTAB> <UNTAB> if len ( args ) == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return Attribute ( <STRING> , parameters ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_symmetric ( self , simplify = True ) : <NEWLINE> <TAB> <NEWLINE> simpfunc = simplify <NEWLINE> if not isinstance ( simplify , FunctionType ) : <NEWLINE> <TAB> simpfunc = _simplify if simplify else lambda x : x <NEWLINE> <NEWLINE> <UNTAB> if not self . is_square : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> return self . _eval_is_symmetric ( simpfunc ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _max_cardinality_node ( G , choices , wanna_connect ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> max_number = - <NUMBER> <NEWLINE> for x in choices : <NEWLINE> <TAB> number = len ( [ y for y in G [ x ] if y in wanna_connect ] ) <NEWLINE> if number > max_number : <NEWLINE> <TAB> max_number = number <NEWLINE> max_cardinality_node = x <NEWLINE> <UNTAB> <UNTAB> return max_cardinality_node <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rugplot ( a , height = <NUMBER> , axis = <STRING> , ax = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if ax is None : <NEWLINE> <TAB> ax = plt . gca ( ) <NEWLINE> <UNTAB> a = np . asarray ( a ) <NEWLINE> vertical = kwargs . pop ( <STRING> , axis == <STRING> ) <NEWLINE> <NEWLINE> alias_map = dict ( linewidth = <STRING> , linestyle = <STRING> , color = <STRING> ) <NEWLINE> for attr , alias in alias_map . items ( ) : <NEWLINE> <TAB> if alias in kwargs : <NEWLINE> <TAB> kwargs [ attr ] = kwargs . pop ( alias ) <NEWLINE> <UNTAB> <UNTAB> kwargs . setdefault ( <STRING> , <NUMBER> ) <NEWLINE> <NEWLINE> if vertical : <NEWLINE> <TAB> trans = tx . blended_transform_factory ( ax . transAxes , ax . transData ) <NEWLINE> xy_pairs = np . column_stack ( [ np . tile ( [ <NUMBER> , height ] , len ( a ) ) , <NEWLINE> np . repeat ( a , <NUMBER> ) ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> trans = tx . blended_transform_factory ( ax . transData , ax . transAxes ) <NEWLINE> xy_pairs = np . column_stack ( [ np . repeat ( a , <NUMBER> ) , <NEWLINE> np . tile ( [ <NUMBER> , height ] , len ( a ) ) ] ) <NEWLINE> <UNTAB> line_segs = xy_pairs . reshape ( [ len ( a ) , <NUMBER> , <NUMBER> ] ) <NEWLINE> ax . add_collection ( LineCollection ( line_segs , transform = trans , ** kwargs ) ) <NEWLINE> <NEWLINE> ax . autoscale_view ( scalex = not vertical , scaley = vertical ) <NEWLINE> <NEWLINE> return ax <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def logical_not_eager_fallback ( x , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> x = _ops . convert_to_tensor ( x , _dtypes . bool ) <NEWLINE> _inputs_flat = [ x ] <NEWLINE> _attrs = None <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def summary ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> summary = collections . OrderedDict ( ) <NEWLINE> for func_name , used_bytes , acquired_bytes , depth in self . call_history : <NEWLINE> <TAB> if func_name not in summary : <NEWLINE> <TAB> summary [ func_name ] = { <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <STRING> : <NUMBER> } <NEWLINE> <UNTAB> record = summary [ func_name ] <NEWLINE> record [ <STRING> ] += used_bytes <NEWLINE> record [ <STRING> ] += acquired_bytes <NEWLINE> record [ <STRING> ] += <NUMBER> <NEWLINE> <UNTAB> return summary <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _gcd ( a , b ) : <NEWLINE> <TAB> <NEWLINE> while b : <NEWLINE> <TAB> a , b = b , a % b <NEWLINE> <UNTAB> return a <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _deannotate ( self , values = None , clone = False ) : <NEWLINE> <TAB> <NEWLINE> if clone : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return self . _clone ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return self <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def setup_module ( module ) : <NEWLINE> <TAB> <NEWLINE> import os <NEWLINE> import numpy as np <NEWLINE> import random <NEWLINE> <NEWLINE> <NEWLINE> _random_seed = os . environ . get ( <STRING> , None ) <NEWLINE> if _random_seed is None : <NEWLINE> <TAB> _random_seed = np . random . uniform ( ) * ( <NUMBER> ** <NUMBER> - <NUMBER> ) <NEWLINE> <UNTAB> _random_seed = int ( _random_seed ) <NEWLINE> print ( <STRING> % _random_seed ) <NEWLINE> np . random . seed ( _random_seed ) <NEWLINE> random . seed ( _random_seed ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __setattr__ ( self , name , value ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if isinstance ( value , ( numpy . ndarray , numpy . generic ) ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> existing = super ( NumpyState , self ) . __getattribute__ ( name ) <NEWLINE> existing . array = value <NEWLINE> return <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> value = _NumpyWrapper ( value ) <NEWLINE> self . _track_checkpointable ( value , name = name , overwrite = True ) <NEWLINE> <UNTAB> <UNTAB> elif ( name not in ( <STRING> , <STRING> ) <NEWLINE> and getattr ( self , <STRING> , True ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> % ( value , name , self ) ) <NEWLINE> <UNTAB> super ( NumpyState , self ) . __setattr__ ( name , value ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def odd_ext ( x , n , axis = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> return x <NEWLINE> <UNTAB> if n > x . shape [ axis ] - <NUMBER> : <NEWLINE> <TAB> raise ValueError ( ( <STRING> + <NEWLINE> <STRING> ) <NEWLINE> % ( n , x . shape [ axis ] - <NUMBER> ) ) <NEWLINE> <UNTAB> left_end = axis_slice ( x , start = <NUMBER> , stop = <NUMBER> , axis = axis ) <NEWLINE> left_ext = axis_slice ( x , start = n , stop = <NUMBER> , step = - <NUMBER> , axis = axis ) <NEWLINE> right_end = axis_slice ( x , start = - <NUMBER> , axis = axis ) <NEWLINE> right_ext = axis_slice ( x , start = - <NUMBER> , stop = - ( n + <NUMBER> ) , step = - <NUMBER> , axis = axis ) <NEWLINE> ext = np . concatenate ( ( <NUMBER> * left_end - left_ext , <NEWLINE> x , <NEWLINE> <NUMBER> * right_end - right_ext ) , <NEWLINE> axis = axis ) <NEWLINE> return ext <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _clear_covers ( self ) : <NEWLINE> <TAB> <NEWLINE> self . row_uncovered [ : ] = True <NEWLINE> self . col_uncovered [ : ] = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __delitem__ ( self , key ) : <NEWLINE> <TAB> <NEWLINE> deleted = False <NEWLINE> <NEWLINE> maybe_shortcut = False <NEWLINE> if hasattr ( self , <STRING> ) and isinstance ( self . columns , MultiIndex ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> maybe_shortcut = key not in self . columns . _engine <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if maybe_shortcut : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if not isinstance ( key , tuple ) : <NEWLINE> <TAB> key = ( key , ) <NEWLINE> <UNTAB> for col in self . columns : <NEWLINE> <TAB> if isinstance ( col , tuple ) and col [ : len ( key ) ] == key : <NEWLINE> <TAB> del self [ col ] <NEWLINE> deleted = True <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if not deleted : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> self . _data . delete ( key ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> del self . _item_cache [ key ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def successors ( self , n ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return iter ( self . _succ [ n ] ) <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> raise NetworkXError ( <STRING> % ( n , ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def make_fid ( name , mode , userblock_size , fapl , fcpl = None , swmr = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if userblock_size is not None : <NEWLINE> <TAB> if mode in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> userblock_size = int ( userblock_size ) <NEWLINE> <UNTAB> except ( TypeError , ValueError ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if fcpl is None : <NEWLINE> <TAB> fcpl = h5p . create ( h5p . FILE_CREATE ) <NEWLINE> <UNTAB> fcpl . set_userblock ( userblock_size ) <NEWLINE> <NEWLINE> <UNTAB> if mode == <STRING> : <NEWLINE> <TAB> flags = h5f . ACC_RDONLY <NEWLINE> if swmr and swmr_support : <NEWLINE> <TAB> flags |= h5f . ACC_SWMR_READ <NEWLINE> <UNTAB> fid = h5f . open ( name , flags , fapl = fapl ) <NEWLINE> <UNTAB> elif mode == <STRING> : <NEWLINE> <TAB> fid = h5f . open ( name , h5f . ACC_RDWR , fapl = fapl ) <NEWLINE> <UNTAB> elif mode in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> fid = h5f . create ( name , h5f . ACC_EXCL , fapl = fapl , fcpl = fcpl ) <NEWLINE> <UNTAB> elif mode == <STRING> : <NEWLINE> <TAB> fid = h5f . create ( name , h5f . ACC_TRUNC , fapl = fapl , fcpl = fcpl ) <NEWLINE> <UNTAB> elif mode == <STRING> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> fid = h5f . open ( name , h5f . ACC_RDWR , fapl = fapl ) <NEWLINE> <UNTAB> except IOError : <NEWLINE> <TAB> fid = h5f . create ( name , h5f . ACC_EXCL , fapl = fapl , fcpl = fcpl ) <NEWLINE> <UNTAB> <UNTAB> elif mode is None : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> fid = h5f . open ( name , h5f . ACC_RDWR , fapl = fapl ) <NEWLINE> <UNTAB> except IOError : <NEWLINE> <TAB> try : <NEWLINE> <TAB> fid = h5f . open ( name , h5f . ACC_RDONLY , fapl = fapl ) <NEWLINE> <UNTAB> except IOError : <NEWLINE> <TAB> fid = h5f . create ( name , h5f . ACC_EXCL , fapl = fapl , fcpl = fcpl ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> if userblock_size is not None : <NEWLINE> <TAB> existing_fcpl = fid . get_create_plist ( ) <NEWLINE> if existing_fcpl . get_userblock ( ) != userblock_size : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( userblock_size , existing_fcpl . get_userblock ( ) ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> except : <NEWLINE> <TAB> fid . close ( ) <NEWLINE> raise <NEWLINE> <NEWLINE> <UNTAB> return fid <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def isdecimal ( a ) : <NEWLINE> <TAB> <NEWLINE> if _use_unicode ( a ) != unicode_ : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> return _vec_string ( a , bool_ , <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_coeff_add ( self , * deps ) : <NEWLINE> <TAB> <NEWLINE> if deps : <NEWLINE> <TAB> if not self . has ( * deps ) : <NEWLINE> <TAB> return self , tuple ( ) <NEWLINE> <UNTAB> <UNTAB> return S . Zero , ( self , ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def read_header ( self ) : <NEWLINE> <TAB> <NEWLINE> data = read_dtype ( self . mat_stream , self . dtypes [ <STRING> ] ) <NEWLINE> name = self . mat_stream . read ( int ( data [ <STRING> ] ) ) . strip ( <STRING> ) <NEWLINE> if data [ <STRING> ] < <NUMBER> or data [ <STRING> ] > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> M , rest = divmod ( data [ <STRING> ] , <NUMBER> ) <NEWLINE> if M not in ( <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> % order_codes [ M ] , <NEWLINE> UserWarning ) <NEWLINE> <UNTAB> O , rest = divmod ( rest , <NUMBER> ) <NEWLINE> if O != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> P , rest = divmod ( rest , <NUMBER> ) <NEWLINE> T = rest <NEWLINE> dims = ( data [ <STRING> ] , data [ <STRING> ] ) <NEWLINE> is_complex = data [ <STRING> ] == <NUMBER> <NEWLINE> dtype = self . dtypes [ P ] <NEWLINE> return VarHeader4 ( <NEWLINE> name , <NEWLINE> dtype , <NEWLINE> T , <NEWLINE> dims , <NEWLINE> is_complex ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def push_current ( self , figure = None ) : <NEWLINE> <TAB> <NEWLINE> if not figure : <NEWLINE> <TAB> figure = self . figure <NEWLINE> <UNTAB> views = WeakKeyDictionary ( ) <NEWLINE> pos = WeakKeyDictionary ( ) <NEWLINE> for a in figure . get_axes ( ) : <NEWLINE> <TAB> views [ a ] = a . _get_view ( ) <NEWLINE> pos [ a ] = self . _axes_pos ( a ) <NEWLINE> <UNTAB> self . views [ figure ] . push ( views ) <NEWLINE> self . positions [ figure ] . push ( pos ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def clean ( self ) : <NEWLINE> <TAB> <NEWLINE> mapping = self . _mapping <NEWLINE> to_drop = [ key for key in mapping if key ( ) is None ] <NEWLINE> for key in to_drop : <NEWLINE> <TAB> val = mapping . pop ( key ) <NEWLINE> val . remove ( key ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_sqf_p ( f , u , K ) : <NEWLINE> <TAB> <NEWLINE> if dmp_zero_p ( f , u ) : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return not dmp_degree ( dmp_gcd ( f , dmp_diff ( f , <NUMBER> , u , K ) , u , K ) , u ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ abstractmethod <NEWLINE> def __rshift__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def necklaces ( n , k , free = False ) : <NEWLINE> <TAB> <NEWLINE> return uniq ( minlex ( i , directed = not free ) for i in <NEWLINE> variations ( list ( range ( k ) ) , n , repetition = True ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_tightbbox ( self , renderer , bbox_extra_artists = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> bb = [ ] <NEWLINE> if bbox_extra_artists is None : <NEWLINE> <TAB> artists = self . get_default_bbox_extra_artists ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> artists = bbox_extra_artists <NEWLINE> <NEWLINE> <UNTAB> for a in artists : <NEWLINE> <TAB> bbox = a . get_tightbbox ( renderer ) <NEWLINE> if bbox is not None and ( bbox . width != <NUMBER> or bbox . height != <NUMBER> ) : <NEWLINE> <TAB> bb . append ( bbox ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> bb . extend ( <NEWLINE> ax . get_tightbbox ( renderer , bbox_extra_artists = bbox_extra_artists ) <NEWLINE> for ax in self . axes if ax . get_visible ( ) ) <NEWLINE> <NEWLINE> if len ( bb ) == <NUMBER> : <NEWLINE> <TAB> return self . bbox_inches <NEWLINE> <NEWLINE> <UNTAB> _bbox = Bbox . union ( [ b for b in bb if b . width != <NUMBER> or b . height != <NUMBER> ] ) <NEWLINE> <NEWLINE> bbox_inches = TransformedBbox ( _bbox , <NEWLINE> Affine2D ( ) . scale ( <NUMBER> / self . dpi ) ) <NEWLINE> <NEWLINE> return bbox_inches <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _eval_nseries ( self , x , n , logx ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> from sympy import ceiling , collect , exp , log , O , Order , powsimp <NEWLINE> b , e = self . args <NEWLINE> if e . is_Integer : <NEWLINE> <TAB> if e > <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return expand_multinomial ( self . func ( b . _eval_nseries ( x , n = n , <NEWLINE> logx = logx ) , e ) , deep = False ) <NEWLINE> <UNTAB> elif e is S . NegativeOne : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> nuse = n <NEWLINE> cf = <NUMBER> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> ord = b . as_leading_term ( x ) <NEWLINE> cf = Order ( ord , x ) . getn ( ) <NEWLINE> if cf and cf . is_Number : <NEWLINE> <TAB> nuse = n + <NUMBER> * ceiling ( cf ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cf = <NUMBER> <NEWLINE> <UNTAB> <UNTAB> except NotImplementedError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> b_orig , prefactor = b , O ( <NUMBER> , x ) <NEWLINE> while prefactor . is_Order : <NEWLINE> <TAB> nuse += <NUMBER> <NEWLINE> b = b_orig . _eval_nseries ( x , n = nuse , logx = logx ) <NEWLINE> prefactor = b . as_leading_term ( x ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> rest = expand_mul ( ( b - prefactor ) / prefactor ) <NEWLINE> <NEWLINE> if rest . is_Order : <NEWLINE> <TAB> return <NUMBER> / prefactor + rest / prefactor + O ( x ** n , x ) <NEWLINE> <NEWLINE> <UNTAB> k , l = rest . leadterm ( x ) <NEWLINE> if l . is_Rational and l > <NUMBER> : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> elif l . is_number and l > <NUMBER> : <NEWLINE> <TAB> l = l . evalf ( ) <NEWLINE> <UNTAB> elif l == <NUMBER> : <NEWLINE> <TAB> k = k . simplify ( ) <NEWLINE> if k == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return <NUMBER> / collect ( prefactor , x ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise NotImplementedError ( ) <NEWLINE> <NEWLINE> <UNTAB> if cf < <NUMBER> : <NEWLINE> <TAB> cf = S . One / abs ( cf ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> dn = Order ( <NUMBER> / prefactor , x ) . getn ( ) <NEWLINE> if dn and dn < <NUMBER> : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dn = <NUMBER> <NEWLINE> <UNTAB> <UNTAB> except NotImplementedError : <NEWLINE> <TAB> dn = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> terms = [ <NUMBER> / prefactor ] <NEWLINE> for m in range ( <NUMBER> , ceiling ( ( n - dn + <NUMBER> ) / l * cf ) ) : <NEWLINE> <TAB> new_term = terms [ - <NUMBER> ] * ( - rest ) <NEWLINE> if new_term . is_Pow : <NEWLINE> <TAB> new_term = new_term . _eval_expand_multinomial ( <NEWLINE> deep = False ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> new_term = expand_mul ( new_term , deep = False ) <NEWLINE> <UNTAB> terms . append ( new_term ) <NEWLINE> <UNTAB> terms . append ( O ( x ** n , x ) ) <NEWLINE> return powsimp ( Add ( * terms ) , deep = True , combine = <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> nuse , denominator = n , O ( <NUMBER> , x ) <NEWLINE> while denominator . is_Order : <NEWLINE> <TAB> denominator = ( b ** ( - e ) ) . _eval_nseries ( x , n = nuse , logx = logx ) <NEWLINE> nuse += <NUMBER> <NEWLINE> <UNTAB> if <NUMBER> / denominator == self : <NEWLINE> <TAB> return self <NEWLINE> <NEWLINE> <UNTAB> return ( <NUMBER> / denominator ) . _eval_nseries ( x , n = n , logx = logx ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if e . has ( Symbol ) : <NEWLINE> <TAB> return exp ( e * log ( b ) ) . _eval_nseries ( x , n = n , logx = logx ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> bx = b <NEWLINE> while bx . is_Pow and bx . exp . is_Rational : <NEWLINE> <TAB> bx = bx . base <NEWLINE> <UNTAB> if bx == x : <NEWLINE> <TAB> return self <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> def e2int ( e ) : <NEWLINE> <TAB> <NEWLINE> n = e . limit ( x , <NUMBER> ) <NEWLINE> infinite = n . is_infinite <NEWLINE> if not infinite : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> n = int ( n ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> n = int ( n . evalf ( ) ) + <NUMBER> <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> n = _sympify ( n ) <NEWLINE> <UNTAB> return n , infinite <NEWLINE> <NEWLINE> <UNTAB> order = O ( x ** n , x ) <NEWLINE> ei , infinite = e2int ( e ) <NEWLINE> b0 = b . limit ( x , <NUMBER> ) <NEWLINE> if infinite and ( b0 is S . One or b0 . has ( Symbol ) ) : <NEWLINE> <NEWLINE> <TAB> if b0 is S . One : <NEWLINE> <TAB> resid = ( b - <NUMBER> ) <NEWLINE> if resid . is_positive : <NEWLINE> <TAB> return S . Infinity <NEWLINE> <UNTAB> elif resid . is_negative : <NEWLINE> <TAB> return S . Zero <NEWLINE> <UNTAB> raise ValueError ( <STRING> % resid ) <NEWLINE> <NEWLINE> <UNTAB> return b0 ** ei <NEWLINE> <NEWLINE> <UNTAB> if ( b0 is S . Zero or b0 . is_infinite ) : <NEWLINE> <TAB> if infinite is not False : <NEWLINE> <TAB> return b0 ** e <NEWLINE> <NEWLINE> <UNTAB> if not ei . is_number : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % ei ) <NEWLINE> <NEWLINE> <UNTAB> nuse = n - ei <NEWLINE> <NEWLINE> if e . is_real and e . is_positive : <NEWLINE> <TAB> lt = b . as_leading_term ( x ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> cf = Order ( lt , x ) . getn ( ) <NEWLINE> nuse = ceiling ( n - cf * ( e - <NUMBER> ) ) <NEWLINE> <UNTAB> except NotImplementedError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> bs = b . _eval_nseries ( x , n = nuse , logx = logx ) <NEWLINE> terms = bs . removeO ( ) <NEWLINE> if terms . is_Add : <NEWLINE> <TAB> bs = terms <NEWLINE> lt = terms . as_leading_term ( x ) <NEWLINE> <NEWLINE> <NEWLINE> return ( ( self . func ( lt , e ) * self . func ( ( bs / lt ) . expand ( ) , e ) . nseries ( <NEWLINE> x , n = nuse , logx = logx ) ) . expand ( ) + order ) <NEWLINE> <NEWLINE> <UNTAB> if bs . is_Add : <NEWLINE> <TAB> from sympy import O <NEWLINE> <NEWLINE> c = Dummy ( <STRING> ) <NEWLINE> res = [ ] <NEWLINE> for arg in bs . args : <NEWLINE> <TAB> if arg . is_Order : <NEWLINE> <TAB> arg = c * arg . expr <NEWLINE> <UNTAB> res . append ( arg ) <NEWLINE> <UNTAB> bs = Add ( * res ) <NEWLINE> rv = ( bs ** e ) . series ( x ) . subs ( c , O ( <NUMBER> , x ) ) <NEWLINE> rv += order <NEWLINE> return rv <NEWLINE> <NEWLINE> <UNTAB> rv = bs ** e <NEWLINE> if terms != bs : <NEWLINE> <TAB> rv += order <NEWLINE> <UNTAB> return rv <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> o2 = order * ( b0 ** - e ) <NEWLINE> z = ( b / b0 - <NUMBER> ) <NEWLINE> o = O ( z , x ) <NEWLINE> if o is S . Zero or o2 is S . Zero : <NEWLINE> <TAB> infinite = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if o . expr . is_number : <NEWLINE> <TAB> e2 = log ( o2 . expr * x ) / log ( x ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> e2 = log ( o2 . expr ) / log ( o . expr ) <NEWLINE> <UNTAB> n , infinite = e2int ( e2 ) <NEWLINE> <UNTAB> if infinite : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> r = <NUMBER> + z <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> l = [ ] <NEWLINE> g = None <NEWLINE> for i in range ( n + <NUMBER> ) : <NEWLINE> <TAB> g = self . _taylor_term ( i , z , g ) <NEWLINE> g = g . nseries ( x , n = n , logx = logx ) <NEWLINE> l . append ( g ) <NEWLINE> <UNTAB> r = Add ( * l ) <NEWLINE> <UNTAB> return expand_mul ( r * b0 ** e ) + order <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def terms_gcd ( f ) : <NEWLINE> <TAB> <NEWLINE> J , F = dmp_terms_gcd ( f . rep , f . lev , f . dom ) <NEWLINE> return J , f . per ( F ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def output ( self , u , t , x0 = None ) : <NEWLINE> <TAB> <NEWLINE> return dlsim ( self , u , t , x0 = x0 ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def to_complex128 ( x , name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return cast ( x , dtypes . complex128 , name = name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def standardize ( self , x ) : <NEWLINE> <TAB> <NEWLINE> if self . preprocessing_function : <NEWLINE> <TAB> x = self . preprocessing_function ( x ) <NEWLINE> <UNTAB> if self . rescale : <NEWLINE> <TAB> x *= self . rescale <NEWLINE> <UNTAB> if self . samplewise_center : <NEWLINE> <TAB> x -= np . mean ( x , keepdims = True ) <NEWLINE> <UNTAB> if self . samplewise_std_normalization : <NEWLINE> <TAB> x /= ( np . std ( x , keepdims = True ) + <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> if self . featurewise_center : <NEWLINE> <TAB> if self . mean is not None : <NEWLINE> <TAB> x -= self . mean <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> if self . featurewise_std_normalization : <NEWLINE> <TAB> if self . std is not None : <NEWLINE> <TAB> x /= ( self . std + <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> if self . zca_whitening : <NEWLINE> <TAB> if self . principal_components is not None : <NEWLINE> <TAB> flatx = np . reshape ( x , ( - <NUMBER> , np . prod ( x . shape [ - <NUMBER> : ] ) ) ) <NEWLINE> whitex = np . dot ( flatx , self . principal_components ) <NEWLINE> x = np . reshape ( whitex , x . shape ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> return x <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def rotate_deg ( self , degrees ) : <NEWLINE> <TAB> <NEWLINE> return self . rotate ( np . deg2rad ( degrees ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _key_without_properties ( self , properties ) : <NEWLINE> <TAB> <NEWLINE> fields_values = [ ] <NEWLINE> <NEWLINE> for i , k in enumerate ( self . _fields ) : <NEWLINE> <TAB> if k in properties : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> fields_values . append ( <STRING> . format ( k , self [ i ] ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return <STRING> . format ( type ( self ) . __name__ , <STRING> . join ( fields_values ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _mod ( self , x , y ) : <NEWLINE> <TAB> <NEWLINE> return array_ops . stop_gradient ( math_ops . mod ( x , y ) - x ) + x <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def convert_caffemodel_to_npz ( cls , path_caffemodel , path_npz ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> from chainer . links . caffe . caffe_function import CaffeFunction <NEWLINE> caffemodel = CaffeFunction ( path_caffemodel ) <NEWLINE> npz . save_npz ( path_npz , caffemodel , compression = False ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ deprecation . deprecated ( <NEWLINE> None , <STRING> <NEWLINE> <STRING> ) <NEWLINE> def __init__ ( self , name = None ) : <NEWLINE> <TAB> <NEWLINE> rr = gen_io_ops . whole_file_reader_v2 ( name = name ) <NEWLINE> super ( WholeFileReader , self ) . __init__ ( rr , supports_serialize = True ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ abstractmethod <NEWLINE> def __and__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def load ( f , as_gray = False , as_grey = None ) : <NEWLINE> <TAB> <NEWLINE> if as_grey is not None : <NEWLINE> <TAB> as_gray = as_grey <NEWLINE> warn ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> use_plugin ( <STRING> ) <NEWLINE> return imread ( _os . path . join ( data_dir , f ) , as_gray = as_gray ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def trigamma ( x ) : <NEWLINE> <TAB> <NEWLINE> return polygamma ( <NUMBER> , x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def write_array_empty ( self , key , value ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> arr = np . empty ( ( <NUMBER> , ) * value . ndim ) <NEWLINE> self . _handle . create_array ( self . group , key , arr ) <NEWLINE> getattr ( self . group , key ) . _v_attrs . value_type = str ( value . dtype ) <NEWLINE> getattr ( self . group , key ) . _v_attrs . shape = value . shape <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _recursive_printoption ( result , mask , printopt ) : <NEWLINE> <TAB> <NEWLINE> names = result . dtype . names <NEWLINE> if names : <NEWLINE> <TAB> for name in names : <NEWLINE> <TAB> curdata = result [ name ] <NEWLINE> curmask = mask [ name ] <NEWLINE> _recursive_printoption ( curdata , curmask , printopt ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> np . copyto ( result , printopt , where = mask ) <NEWLINE> <UNTAB> return <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def cross_eager_fallback ( a , b , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ a , b ] , _ctx ) <NEWLINE> ( a , b ) = _inputs_T <NEWLINE> _inputs_flat = [ a , b ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _validate_dtype ( dtype ) : <NEWLINE> <TAB> <NEWLINE> if not ( dtype is None or is_int64_dtype ( dtype ) ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def wminkowski ( u , v , p , w ) : <NEWLINE> <TAB> <NEWLINE> w = _validate_weights ( w ) <NEWLINE> return minkowski ( u , v , p = p , w = w ** p ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def EC ( f , order = None ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( f . rep , <STRING> ) : <NEWLINE> <TAB> return f . coeffs ( order ) [ - <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise OperationNotSupported ( f , <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def monomial_div ( A , B ) : <NEWLINE> <TAB> <NEWLINE> C = monomial_ldiv ( A , B ) <NEWLINE> <NEWLINE> if all ( c >= <NUMBER> for c in C ) : <NEWLINE> <TAB> return tuple ( C ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _type_repr ( t ) : <NEWLINE> <TAB> <NEWLINE> string = repr ( t ) <NEWLINE> for type_ , alias in _TYPE_ABBREVIATIONS . items ( ) : <NEWLINE> <TAB> string = string . replace ( repr ( type_ ) , alias ) <NEWLINE> <UNTAB> string = re . sub ( <STRING> , <STRING> , string ) <NEWLINE> string = re . sub ( <STRING> , <STRING> , string ) <NEWLINE> return string <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_radius ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . width / <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __copy__ ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . copy ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _node_redundancy ( G , v ) : <NEWLINE> <TAB> <NEWLINE> n = len ( G [ v ] ) <NEWLINE> <NEWLINE> <NEWLINE> overlap = sum ( <NUMBER> for ( u , w ) in combinations ( G [ v ] , <NUMBER> ) <NEWLINE> if ( set ( G [ u ] ) & set ( G [ w ] ) ) - { v } ) <NEWLINE> return ( <NUMBER> * overlap ) / ( n * ( n - <NUMBER> ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def IsSequenceForData ( o ) : <NEWLINE> <TAB> <NEWLINE> return _pywrap_tensorflow_internal . IsSequenceForData ( o ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __idiv__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> other_data = getdata ( other ) <NEWLINE> dom_mask = _DomainSafeDivide ( ) . __call__ ( self . _data , other_data ) <NEWLINE> other_mask = getmask ( other ) <NEWLINE> new_mask = mask_or ( other_mask , dom_mask ) <NEWLINE> <NEWLINE> if dom_mask . any ( ) : <NEWLINE> <TAB> ( _ , fval ) = ufunc_fills [ np . divide ] <NEWLINE> other_data = np . where ( dom_mask , fval , other_data ) <NEWLINE> <UNTAB> self . _mask |= new_mask <NEWLINE> self . _data . __idiv__ ( np . where ( self . _mask , self . dtype . type ( <NUMBER> ) , <NEWLINE> other_data ) ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def make_node ( self , coding_dist , true_one_of_n ) : <NEWLINE> <TAB> <NEWLINE> _coding_dist = tensor . as_tensor_variable ( coding_dist ) <NEWLINE> _true_one_of_n = tensor . as_tensor_variable ( true_one_of_n ) <NEWLINE> if _coding_dist . type . ndim != <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if _true_one_of_n . type not in ( tensor . lvector , tensor . ivector ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ( _true_one_of_n . type , <NEWLINE> tensor . lvector ) ) <NEWLINE> <NEWLINE> <UNTAB> return Apply ( self , [ _coding_dist , _true_one_of_n ] , <NEWLINE> [ tensor . Tensor ( dtype = _coding_dist . dtype , <NEWLINE> broadcastable = [ False ] ) ( ) ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ Substitution ( name = <STRING> ) <NEWLINE> @ Appender ( _doc_template ) <NEWLINE> def rolling ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> from pandas . core . window import RollingGroupby <NEWLINE> return RollingGroupby ( self , * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def downcast ( self , dtypes = None , mgr = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if dtypes is False : <NEWLINE> <TAB> return self <NEWLINE> <NEWLINE> <UNTAB> values = self . values <NEWLINE> <NEWLINE> <NEWLINE> if self . _is_single_block : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if dtypes is None : <NEWLINE> <TAB> dtypes = <STRING> <NEWLINE> <NEWLINE> <UNTAB> nv = maybe_downcast_to_dtype ( values , dtypes ) <NEWLINE> return self . make_block ( nv ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if dtypes is None : <NEWLINE> <TAB> return self <NEWLINE> <NEWLINE> <UNTAB> if not ( dtypes == <STRING> or isinstance ( dtypes , dict ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> def f ( m , v , i ) : <NEWLINE> <NEWLINE> <TAB> if dtypes == <STRING> : <NEWLINE> <TAB> dtype = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise AssertionError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if dtype is not None : <NEWLINE> <TAB> v = maybe_downcast_to_dtype ( v , dtype ) <NEWLINE> <UNTAB> return v <NEWLINE> <NEWLINE> <UNTAB> return self . split_and_operate ( None , f , False ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def circulant_graph ( n , offsets , create_using = None ) : <NEWLINE> <TAB> <NEWLINE> G = empty_graph ( n , create_using ) <NEWLINE> for i in range ( n ) : <NEWLINE> <TAB> for j in offsets : <NEWLINE> <TAB> G . add_edge ( i , ( i - j ) % n ) <NEWLINE> G . add_edge ( i , ( i + j ) % n ) <NEWLINE> <UNTAB> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rewriter ( condition , rewrite ) : <NEWLINE> <TAB> <NEWLINE> def _rewriter ( integral ) : <NEWLINE> <TAB> integrand , symbol = integral <NEWLINE> if condition ( * integral ) : <NEWLINE> <TAB> rewritten = rewrite ( * integral ) <NEWLINE> if rewritten != integrand : <NEWLINE> <TAB> substep = integral_steps ( rewritten , symbol ) <NEWLINE> if not isinstance ( substep , DontKnowRule ) and substep : <NEWLINE> <TAB> return RewriteRule ( <NEWLINE> rewritten , <NEWLINE> substep , <NEWLINE> integrand , symbol ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> return _rewriter <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def parallel_stack ( values , name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name ) : <NEWLINE> <TAB> value_t = ops . convert_to_tensor ( values [ <NUMBER> ] ) <NEWLINE> value_shape = ops . convert_to_tensor ( value_t ) . get_shape ( ) <NEWLINE> <NEWLINE> output_shape = tensor_shape . TensorShape ( [ len ( values ) ] ) <NEWLINE> output_shape = output_shape . concatenate ( value_shape ) <NEWLINE> <NEWLINE> return gen_array_ops . parallel_concat ( <NEWLINE> [ expand_dims ( value , <NUMBER> ) for value in values ] , shape = output_shape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def should_use_ideep ( level ) : <NEWLINE> <TAB> <NEWLINE> if not is_ideep_available ( ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if level not in _SHOULD_USE_IDEEP : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % <NEWLINE> repr ( level ) ) <NEWLINE> <NEWLINE> <UNTAB> flags = _SHOULD_USE_IDEEP [ level ] <NEWLINE> <NEWLINE> use_ideep = config . use_ideep <NEWLINE> if use_ideep not in flags : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % <NEWLINE> repr ( use_ideep ) ) <NEWLINE> <UNTAB> return flags [ use_ideep ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def datalim_to_dt ( self ) : <NEWLINE> <TAB> <NEWLINE> dmin , dmax = self . axis . get_data_interval ( ) <NEWLINE> if dmin > dmax : <NEWLINE> <TAB> dmin , dmax = dmax , dmin <NEWLINE> <UNTAB> if dmin < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> . format ( dmin ) ) <NEWLINE> <UNTAB> return num2date ( dmin , self . tz ) , num2date ( dmax , self . tz ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def compare ( self , other , ** kw ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( other , ClauseList ) and len ( self . clauses ) == <NUMBER> : <NEWLINE> <TAB> return self . clauses [ <NUMBER> ] . compare ( other , ** kw ) <NEWLINE> <UNTAB> elif isinstance ( other , ClauseList ) and len ( self . clauses ) == len ( other . clauses ) and self . operator is other . operator : <NEWLINE> <NEWLINE> <TAB> if self . operator in ( operators . and_ , operators . or_ ) : <NEWLINE> <TAB> completed = set ( ) <NEWLINE> for clause in self . clauses : <NEWLINE> <TAB> for other_clause in set ( other . clauses ) . difference ( completed ) : <NEWLINE> <TAB> if clause . compare ( other_clause , ** kw ) : <NEWLINE> <TAB> completed . add ( other_clause ) <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return len ( completed ) == len ( other . clauses ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for i in range ( <NUMBER> , len ( self . clauses ) ) : <NEWLINE> <TAB> if not self . clauses [ i ] . compare ( other . clauses [ i ] , ** kw ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _linear_2eq_order1_type7 ( x , y , t , r , eq ) : <NEWLINE> <TAB> <NEWLINE> C1 , C2 , C3 , C4 = get_numbered_constants ( eq , num = <NUMBER> ) <NEWLINE> e1 = r [ <STRING> ] * r [ <STRING> ] * r [ <STRING> ] - r [ <STRING> ] ** <NUMBER> * r [ <STRING> ] + r [ <STRING> ] * diff ( r [ <STRING> ] , t ) - diff ( r [ <STRING> ] , t ) * r [ <STRING> ] <NEWLINE> e2 = r [ <STRING> ] * r [ <STRING> ] * r [ <STRING> ] - r [ <STRING> ] * r [ <STRING> ] ** <NUMBER> + diff ( r [ <STRING> ] , t ) * r [ <STRING> ] - r [ <STRING> ] * diff ( r [ <STRING> ] , t ) <NEWLINE> m1 = r [ <STRING> ] * r [ <STRING> ] + r [ <STRING> ] * r [ <STRING> ] + diff ( r [ <STRING> ] , t ) <NEWLINE> m2 = r [ <STRING> ] * r [ <STRING> ] + r [ <STRING> ] * r [ <STRING> ] + diff ( r [ <STRING> ] , t ) <NEWLINE> if e1 == <NUMBER> : <NEWLINE> <TAB> sol1 = dsolve ( r [ <STRING> ] * diff ( x ( t ) , t , t ) - m1 * diff ( x ( t ) , t ) ) . rhs <NEWLINE> sol2 = dsolve ( diff ( y ( t ) , t ) - r [ <STRING> ] * sol1 - r [ <STRING> ] * y ( t ) ) . rhs <NEWLINE> <UNTAB> elif e2 == <NUMBER> : <NEWLINE> <TAB> sol2 = dsolve ( r [ <STRING> ] * diff ( y ( t ) , t , t ) - m2 * diff ( y ( t ) , t ) ) . rhs <NEWLINE> sol1 = dsolve ( diff ( x ( t ) , t ) - r [ <STRING> ] * x ( t ) - r [ <STRING> ] * sol2 ) . rhs <NEWLINE> <UNTAB> elif not ( e1 / r [ <STRING> ] ) . has ( t ) and not ( m1 / r [ <STRING> ] ) . has ( t ) : <NEWLINE> <TAB> sol1 = dsolve ( diff ( x ( t ) , t , t ) - ( m1 / r [ <STRING> ] ) * diff ( x ( t ) , t ) - ( e1 / r [ <STRING> ] ) * x ( t ) ) . rhs <NEWLINE> sol2 = dsolve ( diff ( y ( t ) , t ) - r [ <STRING> ] * sol1 - r [ <STRING> ] * y ( t ) ) . rhs <NEWLINE> <UNTAB> elif not ( e2 / r [ <STRING> ] ) . has ( t ) and not ( m2 / r [ <STRING> ] ) . has ( t ) : <NEWLINE> <TAB> sol2 = dsolve ( diff ( y ( t ) , t , t ) - ( m2 / r [ <STRING> ] ) * diff ( y ( t ) , t ) - ( e2 / r [ <STRING> ] ) * y ( t ) ) . rhs <NEWLINE> sol1 = dsolve ( diff ( x ( t ) , t ) - r [ <STRING> ] * x ( t ) - r [ <STRING> ] * sol2 ) . rhs <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x0 = Function ( <STRING> ) ( t ) <NEWLINE> y0 = Function ( <STRING> ) ( t ) <NEWLINE> F = exp ( Integral ( r [ <STRING> ] , t ) ) <NEWLINE> P = exp ( Integral ( r [ <STRING> ] , t ) ) <NEWLINE> sol1 = C1 * x0 + C2 * x0 * Integral ( r [ <STRING> ] * F * P / x0 ** <NUMBER> , t ) <NEWLINE> sol2 = C1 * y0 + C2 * ( F * P / x0 + y0 * Integral ( r [ <STRING> ] * F * P / x0 ** <NUMBER> , t ) ) <NEWLINE> <UNTAB> return [ Eq ( x ( t ) , sol1 ) , Eq ( y ( t ) , sol2 ) ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _finalize_grid ( self , axlabels ) : <NEWLINE> <TAB> <NEWLINE> self . set_axis_labels ( * axlabels ) <NEWLINE> self . set_titles ( ) <NEWLINE> self . fig . tight_layout ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def intersection ( self , o ) : <NEWLINE> <TAB> <NEWLINE> from sympy . geometry . line import LinearEntity , LinearEntity3D <NEWLINE> if not isinstance ( o , GeometryEntity ) : <NEWLINE> <TAB> o = Point ( o , dim = <NUMBER> ) <NEWLINE> <UNTAB> if isinstance ( o , Point ) : <NEWLINE> <TAB> if o in self : <NEWLINE> <TAB> return [ o ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> <UNTAB> if isinstance ( o , ( LinearEntity , LinearEntity3D ) ) : <NEWLINE> <TAB> if o in self : <NEWLINE> <TAB> p1 , p2 = o . p1 , o . p2 <NEWLINE> if isinstance ( o , Segment ) : <NEWLINE> <TAB> o = Segment3D ( p1 , p2 ) <NEWLINE> <UNTAB> elif isinstance ( o , Ray ) : <NEWLINE> <TAB> o = Ray3D ( p1 , p2 ) <NEWLINE> <UNTAB> elif isinstance ( o , Line ) : <NEWLINE> <TAB> o = Line3D ( p1 , p2 ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % o . func ) <NEWLINE> <UNTAB> return [ o ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x , y , z = map ( Dummy , <STRING> ) <NEWLINE> t = Dummy ( ) <NEWLINE> a = Point3D ( o . arbitrary_point ( t ) ) <NEWLINE> b = self . equation ( x , y , z ) <NEWLINE> <NEWLINE> <NEWLINE> c = solve ( b . subs ( list ( zip ( ( x , y , z ) , a . args ) ) ) , t ) <NEWLINE> if not c : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> p = a . subs ( t , c [ <NUMBER> ] ) <NEWLINE> if p not in self : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> return [ p ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if isinstance ( o , Plane ) : <NEWLINE> <TAB> if self . equals ( o ) : <NEWLINE> <TAB> return [ self ] <NEWLINE> <UNTAB> if self . is_parallel ( o ) : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x , y , z = map ( Dummy , <STRING> ) <NEWLINE> a , b = Matrix ( [ self . normal_vector ] ) , Matrix ( [ o . normal_vector ] ) <NEWLINE> c = list ( a . cross ( b ) ) <NEWLINE> d = self . equation ( x , y , z ) <NEWLINE> e = o . equation ( x , y , z ) <NEWLINE> result = list ( linsolve ( [ d , e ] , x , y , z ) ) [ <NUMBER> ] <NEWLINE> for i in ( x , y , z ) : result = result . subs ( i , <NUMBER> ) <NEWLINE> return [ Line3D ( Point3D ( result ) , direction_ratio = c ) ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _fermat_spiral ( theta , theta_offset = <NUMBER> , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> x , y = np . sqrt ( theta ) * np . cos ( theta + theta_offset ) , np . sqrt ( theta ) * np . sin ( <NEWLINE> theta + theta_offset ) <NEWLINE> x_norm = np . max ( np . abs ( x ) ) <NEWLINE> y_norm = np . max ( np . abs ( y ) ) <NEWLINE> x , y = x / x_norm , y / y_norm <NEWLINE> return x , y <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _validate_names ( names ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if names is not None : <NEWLINE> <TAB> if len ( names ) != len ( set ( names ) ) : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> warnings . warn ( msg , UserWarning , stacklevel = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return names <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def createVariable ( self , name , type , dimensions ) : <NEWLINE> <TAB> <NEWLINE> shape = tuple ( [ self . dimensions [ dim ] for dim in dimensions ] ) <NEWLINE> shape_ = tuple ( [ dim or <NUMBER> for dim in shape ] ) <NEWLINE> <NEWLINE> type = dtype ( type ) <NEWLINE> typecode , size = type . char , type . itemsize <NEWLINE> if ( typecode , size ) not in REVERSE : <NEWLINE> <TAB> raise ValueError ( <STRING> % type ) <NEWLINE> <NEWLINE> <UNTAB> data = empty ( shape_ , dtype = type . newbyteorder ( <STRING> ) ) <NEWLINE> self . variables [ name ] = netcdf_variable ( <NEWLINE> data , typecode , size , shape , dimensions , <NEWLINE> maskandscale = self . maskandscale ) <NEWLINE> return self . variables [ name ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def filter_ops_from_regex ( ops , regex ) : <NEWLINE> <TAB> <NEWLINE> ops = util . make_list_of_op ( ops ) <NEWLINE> regex_obj = make_regex ( regex ) <NEWLINE> return filter_ops ( ops , lambda op : regex_obj . search ( op . name ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def make_dvi_preview ( self , tex , fontsize ) : <NEWLINE> <TAB> <NEWLINE> basefile = self . get_basefile ( tex , fontsize ) <NEWLINE> dvifile = <STRING> % basefile <NEWLINE> baselinefile = <STRING> % basefile <NEWLINE> <NEWLINE> if not os . path . exists ( dvifile ) or not os . path . exists ( baselinefile ) : <NEWLINE> <TAB> texfile = self . make_tex_preview ( tex , fontsize ) <NEWLINE> report = self . _run_checked_subprocess ( <NEWLINE> [ <STRING> , <STRING> , <STRING> , <NEWLINE> texfile ] , tex ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> m = TexManager . _re_vbox . search ( report . decode ( <STRING> ) ) <NEWLINE> with open ( basefile + <STRING> , <STRING> ) as fh : <NEWLINE> <TAB> fh . write ( <STRING> . join ( m . groups ( ) ) ) <NEWLINE> <NEWLINE> <UNTAB> for fname in glob . glob ( basefile + <STRING> ) : <NEWLINE> <TAB> if not fname . endswith ( ( <STRING> , <STRING> , <STRING> ) ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> os . remove ( fname ) <NEWLINE> <UNTAB> except OSError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> return dvifile <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def limit_range_for_scale ( self , vmin , vmax , minpos ) : <NEWLINE> <TAB> <NEWLINE> return vmin , vmax <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_view_interval ( self , vmin , vmax , ignore = False ) : <NEWLINE> <TAB> <NEWLINE> if ignore : <NEWLINE> <TAB> self . axes . viewLim . intervaly = vmin , vmax <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> Vmin , Vmax = self . get_view_interval ( ) <NEWLINE> if Vmin < Vmax : <NEWLINE> <TAB> self . axes . viewLim . intervaly = ( min ( vmin , vmax , Vmin ) , <NEWLINE> max ( vmin , vmax , Vmax ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . axes . viewLim . intervaly = ( max ( vmin , vmax , Vmin ) , <NEWLINE> min ( vmin , vmax , Vmax ) ) <NEWLINE> <UNTAB> <UNTAB> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _transform_banded_jac ( bjac ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> newjac = zeros ( ( bjac . shape [ <NUMBER> ] + <NUMBER> , bjac . shape [ <NUMBER> ] ) ) <NEWLINE> newjac [ <NUMBER> : , : : <NUMBER> ] = bjac [ : , : : <NUMBER> ] <NEWLINE> newjac [ : - <NUMBER> , <NUMBER> : : <NUMBER> ] = bjac [ : , <NUMBER> : : <NUMBER> ] <NEWLINE> return newjac <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_expr ( self , x = None ) : <NEWLINE> <TAB> <NEWLINE> return self . as_poly ( x or self . root ) . as_expr ( ) . expand ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def get_word_index ( path = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> origin_folder = <STRING> <NEWLINE> path = get_file ( <NEWLINE> path , <NEWLINE> origin = origin_folder + <STRING> , <NEWLINE> file_hash = <STRING> ) <NEWLINE> with open ( path ) as f : <NEWLINE> <TAB> return json . load ( f ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __div__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return self . operate ( div , other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _buffered_line ( self ) : <NEWLINE> <TAB> <NEWLINE> if len ( self . buf ) > <NUMBER> : <NEWLINE> <TAB> return self . buf [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . _next_line ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_nonnegative ( self , a ) : <NEWLINE> <TAB> <NEWLINE> return self . domain . is_nonnegative ( a . LC ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _get_scaffold ( captured_scaffold_fn ) : <NEWLINE> <TAB> <NEWLINE> scaffold_fn = captured_scaffold_fn . get ( ) <NEWLINE> <NEWLINE> if not scaffold_fn : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> scaffold = scaffold_fn ( ) <NEWLINE> if scaffold is None : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return scaffold <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ _generative <NEWLINE> @ util . deprecated ( <STRING> , <NEWLINE> message = <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> def autocommit ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . _execution_options = self . _execution_options . union ( { <STRING> : True } ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _preprocess_roots ( cls , poly ) : <NEWLINE> <TAB> <NEWLINE> dom = poly . get_domain ( ) <NEWLINE> <NEWLINE> if not dom . is_Exact : <NEWLINE> <TAB> poly = poly . to_exact ( ) <NEWLINE> <NEWLINE> <UNTAB> coeff , poly = preprocess_roots ( poly ) <NEWLINE> dom = poly . get_domain ( ) <NEWLINE> <NEWLINE> if not dom . is_ZZ : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> % dom ) <NEWLINE> <NEWLINE> <UNTAB> return coeff , poly <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def isfunction ( object ) : <NEWLINE> <TAB> <NEWLINE> return isinstance ( object , types . FunctionType ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def moments_hu ( nu ) : <NEWLINE> <TAB> <NEWLINE> return _moments_cy . moments_hu ( nu . astype ( np . double ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def open ( self , fullurl , data = None ) : <NEWLINE> <TAB> <NEWLINE> fullurl = unwrap ( to_bytes ( fullurl ) ) <NEWLINE> fullurl = quote ( fullurl , safe = <STRING> ) <NEWLINE> if self . tempcache and fullurl in self . tempcache : <NEWLINE> <TAB> filename , headers = self . tempcache [ fullurl ] <NEWLINE> fp = open ( filename , <STRING> ) <NEWLINE> return addinfourl ( fp , headers , fullurl ) <NEWLINE> <UNTAB> urltype , url = splittype ( fullurl ) <NEWLINE> if not urltype : <NEWLINE> <TAB> urltype = <STRING> <NEWLINE> <UNTAB> if urltype in self . proxies : <NEWLINE> <TAB> proxy = self . proxies [ urltype ] <NEWLINE> urltype , proxyhost = splittype ( proxy ) <NEWLINE> host , selector = splithost ( proxyhost ) <NEWLINE> url = ( host , fullurl ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> proxy = None <NEWLINE> <UNTAB> name = <STRING> + urltype <NEWLINE> self . type = urltype <NEWLINE> name = name . replace ( <STRING> , <STRING> ) <NEWLINE> if not hasattr ( self , name ) : <NEWLINE> <TAB> if proxy : <NEWLINE> <TAB> return self . open_unknown_proxy ( proxy , fullurl , data ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . open_unknown ( fullurl , data ) <NEWLINE> <UNTAB> <UNTAB> try : <NEWLINE> <TAB> if data is None : <NEWLINE> <TAB> return getattr ( self , name ) ( url ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return getattr ( self , name ) ( url , data ) <NEWLINE> <UNTAB> <UNTAB> except ( HTTPError , URLError ) : <NEWLINE> <TAB> raise <NEWLINE> <UNTAB> except OSError as msg : <NEWLINE> <TAB> raise OSError ( <STRING> , msg ) . with_traceback ( sys . exc_info ( ) [ <NUMBER> ] ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , left , right = None , op = None ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( left , Cycler ) : <NEWLINE> <TAB> self . _left = Cycler ( left . _left , left . _right , left . _op ) <NEWLINE> <UNTAB> elif left is not None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> self . _left = [ copy . copy ( v ) for v in left ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _left = None <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( right , Cycler ) : <NEWLINE> <TAB> self . _right = Cycler ( right . _left , right . _right , right . _op ) <NEWLINE> <UNTAB> elif right is not None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> self . _right = [ copy . copy ( v ) for v in right ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _right = None <NEWLINE> <NEWLINE> <UNTAB> self . _keys = _process_keys ( self . _left , self . _right ) <NEWLINE> self . _op = op <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _copy_arrays_if_base_present ( T ) : <NEWLINE> <TAB> <NEWLINE> l = [ _copy_array_if_base_present ( a ) for a in T ] <NEWLINE> return l <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ docstring . Substitution ( make_axes_kw_doc ) <NEWLINE> def make_axes_gridspec ( parent , * , fraction = <NUMBER> , shrink = <NUMBER> , aspect = <NUMBER> , ** kw ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> orientation = kw . setdefault ( <STRING> , <STRING> ) <NEWLINE> kw [ <STRING> ] = <STRING> <NEWLINE> <NEWLINE> x1 = <NUMBER> - fraction <NEWLINE> <NEWLINE> <NEWLINE> pad_s = ( <NUMBER> - shrink ) * <NUMBER> <NEWLINE> wh_ratios = [ pad_s , shrink , pad_s ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> gs = parent . get_subplotspec ( ) . get_gridspec ( ) <NEWLINE> layoutbox . nonetree ( gs . _layoutbox ) <NEWLINE> gs_from_subplotspec = gridspec . GridSpecFromSubplotSpec <NEWLINE> if orientation == <STRING> : <NEWLINE> <TAB> pad = kw . pop ( <STRING> , <NUMBER> ) <NEWLINE> wh_space = <NUMBER> * pad / ( <NUMBER> - pad ) <NEWLINE> gs = gs_from_subplotspec ( <NUMBER> , <NUMBER> , <NEWLINE> subplot_spec = parent . get_subplotspec ( ) , <NEWLINE> wspace = wh_space , <NEWLINE> width_ratios = [ x1 - pad , fraction ] ) <NEWLINE> gs2 = gs_from_subplotspec ( <NUMBER> , <NUMBER> , <NEWLINE> subplot_spec = gs [ <NUMBER> ] , <NEWLINE> hspace = <NUMBER> , <NEWLINE> height_ratios = wh_ratios ) <NEWLINE> anchor = ( <NUMBER> , <NUMBER> ) <NEWLINE> panchor = ( <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pad = kw . pop ( <STRING> , <NUMBER> ) <NEWLINE> wh_space = <NUMBER> * pad / ( <NUMBER> - pad ) <NEWLINE> gs = gs_from_subplotspec ( <NUMBER> , <NUMBER> , <NEWLINE> subplot_spec = parent . get_subplotspec ( ) , <NEWLINE> hspace = wh_space , <NEWLINE> height_ratios = [ x1 - pad , fraction ] ) <NEWLINE> gs2 = gs_from_subplotspec ( <NUMBER> , <NUMBER> , <NEWLINE> subplot_spec = gs [ <NUMBER> ] , <NEWLINE> wspace = <NUMBER> , <NEWLINE> width_ratios = wh_ratios ) <NEWLINE> aspect = <NUMBER> / aspect <NEWLINE> anchor = ( <NUMBER> , <NUMBER> ) <NEWLINE> panchor = ( <NUMBER> , <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> parent . set_subplotspec ( gs [ <NUMBER> ] ) <NEWLINE> parent . update_params ( ) <NEWLINE> parent . _set_position ( parent . figbox ) <NEWLINE> parent . set_anchor ( panchor ) <NEWLINE> <NEWLINE> fig = parent . get_figure ( ) <NEWLINE> cax = fig . add_subplot ( gs2 [ <NUMBER> ] ) <NEWLINE> cax . set_aspect ( aspect , anchor = anchor , adjustable = <STRING> ) <NEWLINE> return cax , kw <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _process_records ( self , lines ) : <NEWLINE> <TAB> <NEWLINE> if self . _column_dtypes is None : <NEWLINE> <TAB> default_values = [ ( array_ops . zeros ( [ ] , dtypes . int64 ) , ) <NEWLINE> if column_name == feature_keys . TrainEvalFeatures . TIMES <NEWLINE> else ( ) for column_name in self . _column_names ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> default_values = [ ( array_ops . zeros ( [ ] , dtype ) , ) <NEWLINE> for dtype in self . _column_dtypes ] <NEWLINE> <UNTAB> columns = parsing_ops . decode_csv ( lines , default_values ) <NEWLINE> features_lists = { } <NEWLINE> for column_name , value in zip ( self . _column_names , columns ) : <NEWLINE> <TAB> features_lists . setdefault ( column_name , [ ] ) . append ( value ) <NEWLINE> <UNTAB> features = { } <NEWLINE> for column_name , values in features_lists . items ( ) : <NEWLINE> <TAB> if column_name == feature_keys . TrainEvalFeatures . TIMES : <NEWLINE> <TAB> features [ column_name ] = values [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> features [ column_name ] = array_ops . stack ( values , axis = <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> return features <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def barh ( self , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> return self ( kind = <STRING> , ** kwds ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_extent ( self ) : <NEWLINE> <TAB> <NEWLINE> numrows , numcols = self . get_size ( ) <NEWLINE> return ( - <NUMBER> + self . ox , numcols - <NUMBER> + self . ox , <NEWLINE> - <NUMBER> + self . oy , numrows - <NUMBER> + self . oy ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def assert_array_less ( x , y , err_msg = <STRING> , verbose = True ) : <NEWLINE> <TAB> <NEWLINE> __tracebackhide__ = True <NEWLINE> assert_array_compare ( operator . __lt__ , x , y , err_msg = err_msg , <NEWLINE> verbose = verbose , <NEWLINE> header = <STRING> , <NEWLINE> equal_inf = False ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def softmin ( input , dim = None , _stacklevel = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if dim is None : <NEWLINE> <TAB> dim = _get_softmax_dim ( <STRING> , input . dim ( ) , _stacklevel ) <NEWLINE> <UNTAB> return - input . softmax ( dim ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def subquery ( alias , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return Select ( * args , ** kwargs ) . alias ( alias ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _eval_as_leading_term ( self , x ) : <NEWLINE> <TAB> <NEWLINE> from sympy import Order <NEWLINE> args = [ a . as_leading_term ( x ) for a in self . args ] <NEWLINE> o = Order ( <NUMBER> , x ) <NEWLINE> if any ( x in a . free_symbols and o . contains ( a ) for a in args ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> % self . func ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . func ( * args ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def bisplev ( x , y , tck , dx = <NUMBER> , dy = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> tx , ty , c , kx , ky = tck <NEWLINE> if not ( <NUMBER> <= dx < kx ) : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( dx , kx ) ) <NEWLINE> <UNTAB> if not ( <NUMBER> <= dy < ky ) : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( dy , ky ) ) <NEWLINE> <UNTAB> x , y = map ( atleast_1d , [ x , y ] ) <NEWLINE> if ( len ( x . shape ) != <NUMBER> ) or ( len ( y . shape ) != <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> z , ier = _fitpack . _bispev ( tx , ty , c , kx , ky , x , y , dx , dy ) <NEWLINE> if ier == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if ier : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> z . shape = len ( x ) , len ( y ) <NEWLINE> if len ( z ) > <NUMBER> : <NEWLINE> <TAB> return z <NEWLINE> <UNTAB> if len ( z [ <NUMBER> ] ) > <NUMBER> : <NEWLINE> <TAB> return z [ <NUMBER> ] <NEWLINE> <UNTAB> return z [ <NUMBER> ] [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _init_local_init_op ( self , local_init_op = USE_DEFAULT ) : <NEWLINE> <TAB> <NEWLINE> if local_init_op is Supervisor . USE_DEFAULT : <NEWLINE> <TAB> local_init_op = self . _get_first_op_from_collection ( <NEWLINE> ops . GraphKeys . LOCAL_INIT_OP ) <NEWLINE> if local_init_op is None : <NEWLINE> <TAB> op_list = [ <NEWLINE> variables . local_variables_initializer ( ) , <NEWLINE> lookup_ops . tables_initializer ( ) <NEWLINE> ] <NEWLINE> if op_list : <NEWLINE> <TAB> local_init_op = control_flow_ops . group ( * op_list ) <NEWLINE> ops . add_to_collection ( ops . GraphKeys . LOCAL_INIT_OP , local_init_op ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> self . _local_init_op = local_init_op <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _bool_method_SERIES ( cls , op , special ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def na_op ( x , y ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> result = op ( x , y ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> if isinstance ( y , list ) : <NEWLINE> <TAB> y = construct_1d_object_array_from_listlike ( y ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( y , ( np . ndarray , ABCSeries ) ) : <NEWLINE> <TAB> if ( is_bool_dtype ( x . dtype ) and is_bool_dtype ( y . dtype ) ) : <NEWLINE> <TAB> result = op ( x , y ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x = _ensure_object ( x ) <NEWLINE> y = _ensure_object ( y ) <NEWLINE> result = libops . vec_binop ( x , y , op ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> if not isna ( y ) : <NEWLINE> <TAB> y = bool ( y ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> result = libops . scalar_binop ( x , y , op ) <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> <NEWLINE> . format ( dtype = x . dtype , <NEWLINE> typ = type ( y ) . __name__ ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return result <NEWLINE> <NEWLINE> <UNTAB> fill_int = lambda x : x . fillna ( <NUMBER> ) <NEWLINE> fill_bool = lambda x : x . fillna ( False ) . astype ( bool ) <NEWLINE> <NEWLINE> def wrapper ( self , other ) : <NEWLINE> <TAB> is_self_int_dtype = is_integer_dtype ( self . dtype ) <NEWLINE> <NEWLINE> self , other = _align_method_SERIES ( self , other , align_asobject = True ) <NEWLINE> <NEWLINE> if isinstance ( other , ABCDataFrame ) : <NEWLINE> <NEWLINE> <TAB> return NotImplemented <NEWLINE> <NEWLINE> <UNTAB> elif isinstance ( other , ABCSeries ) : <NEWLINE> <TAB> name = get_op_result_name ( self , other ) <NEWLINE> is_other_int_dtype = is_integer_dtype ( other . dtype ) <NEWLINE> other = fill_int ( other ) if is_other_int_dtype else fill_bool ( other ) <NEWLINE> <NEWLINE> filler = ( fill_int if is_self_int_dtype and is_other_int_dtype <NEWLINE> else fill_bool ) <NEWLINE> <NEWLINE> res_values = na_op ( self . values , other . values ) <NEWLINE> unfilled = self . _constructor ( res_values , <NEWLINE> index = self . index , name = name ) <NEWLINE> return filler ( unfilled ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> filler = ( fill_int if is_self_int_dtype and <NEWLINE> is_integer_dtype ( np . asarray ( other ) ) else fill_bool ) <NEWLINE> <NEWLINE> res_values = na_op ( self . values , other ) <NEWLINE> unfilled = self . _constructor ( res_values , index = self . index ) <NEWLINE> return filler ( unfilled ) . __finalize__ ( self ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return wrapper <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def lagfit ( x , y , deg , rcond = None , full = False , w = None ) : <NEWLINE> <TAB> <NEWLINE> x = np . asarray ( x ) + <NUMBER> <NEWLINE> y = np . asarray ( y ) + <NUMBER> <NEWLINE> deg = np . asarray ( deg ) <NEWLINE> <NEWLINE> <NEWLINE> if deg . ndim > <NUMBER> or deg . dtype . kind not in <STRING> or deg . size == <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if deg . min ( ) < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if x . ndim != <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if x . size == <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if y . ndim < <NUMBER> or y . ndim > <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if len ( x ) != len ( y ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if deg . ndim == <NUMBER> : <NEWLINE> <TAB> lmax = deg <NEWLINE> order = lmax + <NUMBER> <NEWLINE> van = lagvander ( x , lmax ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> deg = np . sort ( deg ) <NEWLINE> lmax = deg [ - <NUMBER> ] <NEWLINE> order = len ( deg ) <NEWLINE> van = lagvander ( x , lmax ) [ : , deg ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> lhs = van . T <NEWLINE> rhs = y . T <NEWLINE> if w is not None : <NEWLINE> <TAB> w = np . asarray ( w ) + <NUMBER> <NEWLINE> if w . ndim != <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if len ( x ) != len ( w ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> lhs = lhs * w <NEWLINE> rhs = rhs * w <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if rcond is None : <NEWLINE> <TAB> rcond = len ( x ) * np . finfo ( x . dtype ) . eps <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if issubclass ( lhs . dtype . type , np . complexfloating ) : <NEWLINE> <TAB> scl = np . sqrt ( ( np . square ( lhs . real ) + np . square ( lhs . imag ) ) . sum ( <NUMBER> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> scl = np . sqrt ( np . square ( lhs ) . sum ( <NUMBER> ) ) <NEWLINE> <UNTAB> scl [ scl == <NUMBER> ] = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> c , resids , rank , s = la . lstsq ( lhs . T / scl , rhs . T , rcond ) <NEWLINE> c = ( c . T / scl ) . T <NEWLINE> <NEWLINE> <NEWLINE> if deg . ndim > <NUMBER> : <NEWLINE> <TAB> if c . ndim == <NUMBER> : <NEWLINE> <TAB> cc = np . zeros ( ( lmax + <NUMBER> , c . shape [ <NUMBER> ] ) , dtype = c . dtype ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cc = np . zeros ( lmax + <NUMBER> , dtype = c . dtype ) <NEWLINE> <UNTAB> cc [ deg ] = c <NEWLINE> c = cc <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if rank != order and not full : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> warnings . warn ( msg , pu . RankWarning , stacklevel = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> if full : <NEWLINE> <TAB> return c , [ resids , rank , s , rcond ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return c <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def convert ( cls , style_dict , num_format_str = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> props = { } <NEWLINE> <NEWLINE> if num_format_str is not None : <NEWLINE> <TAB> props [ <STRING> ] = num_format_str <NEWLINE> <NEWLINE> <UNTAB> if style_dict is None : <NEWLINE> <TAB> return props <NEWLINE> <NEWLINE> <UNTAB> if <STRING> in style_dict : <NEWLINE> <TAB> style_dict = style_dict . copy ( ) <NEWLINE> style_dict [ <STRING> ] = style_dict . pop ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> for style_group_key , style_group in style_dict . items ( ) : <NEWLINE> <TAB> for src , dst in cls . STYLE_MAPPING . get ( style_group_key , [ ] ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if dst in props : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> v = style_group <NEWLINE> for k in src : <NEWLINE> <TAB> try : <NEWLINE> <TAB> v = v [ k ] <NEWLINE> <UNTAB> except ( KeyError , TypeError ) : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> props [ dst ] = v <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if isinstance ( props . get ( <STRING> ) , string_types ) : <NEWLINE> <NEWLINE> <TAB> props [ <STRING> ] = <NUMBER> if props [ <STRING> ] == <STRING> else <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> for k in [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> if isinstance ( props . get ( k ) , string_types ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> props [ k ] = [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> ] . index ( props [ k ] ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> props [ k ] = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if isinstance ( props . get ( <STRING> ) , string_types ) : <NEWLINE> <TAB> props [ <STRING> ] = [ <STRING> , <STRING> , <STRING> ] . index ( props [ <STRING> ] ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( props . get ( <STRING> ) , string_types ) : <NEWLINE> <TAB> props [ <STRING> ] = { <STRING> : <NUMBER> , <STRING> : <NUMBER> , <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> , <NEWLINE> <STRING> : <NUMBER> } [ props [ <STRING> ] ] <NEWLINE> <NEWLINE> <UNTAB> return props <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _updated_config ( self ) : <NEWLINE> <TAB> <NEWLINE> from tensorflow . python . keras import __version__ as keras_version <NEWLINE> <NEWLINE> config = self . get_config ( ) <NEWLINE> model_config = { <NEWLINE> <STRING> : self . __class__ . __name__ , <NEWLINE> <STRING> : config , <NEWLINE> <STRING> : keras_version , <NEWLINE> <STRING> : backend . backend ( ) <NEWLINE> } <NEWLINE> return model_config <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_module_cache ( init_args = None ) : <NEWLINE> <TAB> <NEWLINE> return cmodule . get_module_cache ( config . compiledir , init_args = init_args ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def evaluates_none ( self ) : <NEWLINE> <TAB> <NEWLINE> typ = self . copy ( ) <NEWLINE> typ . should_evaluate_none = True <NEWLINE> return typ <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . _lock = threading . RLock ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . _group_lock = lock_util . GroupLock ( num_groups = <NUMBER> ) <NEWLINE> self . _nodes_by_id = dict ( ) <NEWLINE> self . _next_id_counter = <NUMBER> <NEWLINE> self . _nodes_by_name = dict ( ) <NEWLINE> self . _version = <NUMBER> <NEWLINE> <NEWLINE> self . _names_in_use = { } <NEWLINE> self . _stack_state_is_thread_local = False <NEWLINE> self . _thread_local = threading . local ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . _graph_device_function_stack = traceable_stack . TraceableStack ( ) <NEWLINE> <NEWLINE> self . _default_original_op = None <NEWLINE> <NEWLINE> <NEWLINE> self . _control_flow_context = None <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . _graph_control_dependencies_stack = [ ] <NEWLINE> <NEWLINE> self . _collections = { } <NEWLINE> <NEWLINE> self . _seed = None <NEWLINE> <NEWLINE> self . _attr_scope_map = { } <NEWLINE> <NEWLINE> self . _op_to_kernel_label_map = { } <NEWLINE> <NEWLINE> <NEWLINE> self . _gradient_override_map = { } <NEWLINE> <NEWLINE> <NEWLINE> self . _finalized = False <NEWLINE> <NEWLINE> self . _functions = collections . OrderedDict ( ) <NEWLINE> <NEWLINE> self . _graph_def_versions = versions_pb2 . VersionDef ( <NEWLINE> producer = versions . GRAPH_DEF_VERSION , <NEWLINE> min_consumer = versions . GRAPH_DEF_VERSION_MIN_CONSUMER ) <NEWLINE> self . _building_function = False <NEWLINE> <NEWLINE> <NEWLINE> self . _graph_colocation_stack = traceable_stack . TraceableStack ( ) <NEWLINE> <NEWLINE> self . _unfeedable_tensors = set ( ) <NEWLINE> <NEWLINE> self . _unfetchable_ops = set ( ) <NEWLINE> <NEWLINE> self . _handle_feeders = { } <NEWLINE> <NEWLINE> self . _handle_readers = { } <NEWLINE> <NEWLINE> self . _handle_movers = { } <NEWLINE> <NEWLINE> self . _handle_deleters = { } <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . _graph_key = <STRING> % ( uid ( ) , ) <NEWLINE> <NEWLINE> <NEWLINE> self . _last_loss_reduction = None <NEWLINE> self . _container = <STRING> <NEWLINE> self . _registered_ops = op_def_registry . get_registered_ops ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . _scoped_c_graph = c_api_util . ScopedTFGraph ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> c_api . SetRequireShapeInferenceFns ( self . _c_graph , False ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def rem ( f , g , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> options . allowed_flags ( args , [ <STRING> , <STRING> ] ) <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> ( F , G ) , opt = parallel_poly_from_expr ( ( f , g ) , * gens , ** args ) <NEWLINE> <UNTAB> except PolificationFailed as exc : <NEWLINE> <TAB> raise ComputationFailed ( <STRING> , <NUMBER> , exc ) <NEWLINE> <NEWLINE> <UNTAB> r = F . rem ( G , auto = opt . auto ) <NEWLINE> <NEWLINE> if not opt . polys : <NEWLINE> <TAB> return r . as_expr ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return r <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , * args ) : <NEWLINE> <TAB> <NEWLINE> super ( UnionClusterResolver , self ) . __init__ ( ) <NEWLINE> <NEWLINE> if not args : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> for cluster_resolver in args : <NEWLINE> <TAB> if not isinstance ( cluster_resolver , ClusterResolver ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> self . _cluster_resolvers = args <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( v1 = [ <STRING> ] ) <NEWLINE> def enable_v2_tensorshape ( ) : <NEWLINE> <TAB> <NEWLINE> global _TENSORSHAPE_V2_OVERRIDE , TensorShape <NEWLINE> _TENSORSHAPE_V2_OVERRIDE = True <NEWLINE> TensorShape = TensorShapeV2 <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def init_population_lhs ( self ) : <NEWLINE> <TAB> <NEWLINE> rng = self . random_number_generator <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> segsize = <NUMBER> / self . num_population_members <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> samples = ( segsize * rng . random_sample ( self . population_shape ) <NEWLINE> <NEWLINE> <NEWLINE> + np . linspace ( <NUMBER> , <NUMBER> , self . num_population_members , <NEWLINE> endpoint = False ) [ : , np . newaxis ] ) <NEWLINE> <NEWLINE> <NEWLINE> self . population = np . zeros_like ( samples ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for j in range ( self . parameter_count ) : <NEWLINE> <TAB> order = rng . permutation ( range ( self . num_population_members ) ) <NEWLINE> self . population [ : , j ] = samples [ order , j ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . population_energies = ( np . ones ( self . num_population_members ) * <NEWLINE> np . inf ) <NEWLINE> <NEWLINE> <NEWLINE> self . _nfev = <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _central_N ( self ) : <NEWLINE> <TAB> <NEWLINE> nb = len ( self . _boundaries ) <NEWLINE> if self . extend == <STRING> : <NEWLINE> <TAB> nb -= <NUMBER> <NEWLINE> <UNTAB> elif self . extend in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> nb -= <NUMBER> <NEWLINE> <UNTAB> return nb <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _replace ( reps ) : <NEWLINE> <TAB> <NEWLINE> if not reps : <NEWLINE> <TAB> return lambda x : x <NEWLINE> <UNTAB> D = lambda match : reps [ match . group ( <NUMBER> ) ] <NEWLINE> pattern = _re . compile ( <STRING> . join ( <NEWLINE> [ _re . escape ( k ) for k , v in reps . items ( ) ] ) , _re . M ) <NEWLINE> return lambda string : pattern . sub ( D , string ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _pow_float ( inter , power ) : <NEWLINE> <TAB> <NEWLINE> power_rational = nsimplify ( power ) <NEWLINE> num , denom = power_rational . as_numer_denom ( ) <NEWLINE> if num % <NUMBER> == <NUMBER> : <NEWLINE> <TAB> start = abs ( inter . start ) ** power <NEWLINE> end = abs ( inter . end ) ** power <NEWLINE> if start < <NUMBER> : <NEWLINE> <TAB> ret = interval ( <NUMBER> , max ( start , end ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ret = interval ( start , end ) <NEWLINE> <UNTAB> return ret <NEWLINE> <UNTAB> elif denom % <NUMBER> == <NUMBER> : <NEWLINE> <TAB> if inter . end < <NUMBER> : <NEWLINE> <TAB> return interval ( - float ( <STRING> ) , float ( <STRING> ) , is_valid = False ) <NEWLINE> <UNTAB> elif inter . start < <NUMBER> : <NEWLINE> <TAB> return interval ( <NUMBER> , inter . end ** power , is_valid = None ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return interval ( inter . start ** power , inter . end ** power ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if inter . start < <NUMBER> : <NEWLINE> <TAB> start = - abs ( inter . start ) ** power <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> start = inter . start ** power <NEWLINE> <NEWLINE> <UNTAB> if inter . end < <NUMBER> : <NEWLINE> <TAB> end = - abs ( inter . end ) ** power <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> end = inter . end ** power <NEWLINE> <NEWLINE> <UNTAB> return interval ( start , end , is_valid = inter . is_valid ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_init_op ( self , task_index ) : <NEWLINE> <TAB> <NEWLINE> init_ops = [ ] <NEWLINE> local_vars = variables . trainable_variables ( ) <NEWLINE> global_center_vars = [ self . _global_map [ var ] for var in local_vars ] <NEWLINE> grad_vars = [ self . _grad_map [ var ] for var in local_vars ] <NEWLINE> if not ( local_vars and global_center_vars and grad_vars ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> for lvar , gc_var in zip ( local_vars , global_center_vars ) : <NEWLINE> <TAB> init_ops . append ( state_ops . assign ( lvar , gc_var ) ) <NEWLINE> <UNTAB> for g in grad_vars : <NEWLINE> <TAB> init_ops . append ( state_ops . assign ( g , array_ops . zeros_like ( g ) ) ) <NEWLINE> <UNTAB> init_op = control_flow_ops . group ( * ( init_ops ) ) <NEWLINE> return init_op <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def convert ( values ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> dtype = values . dtype <NEWLINE> <NEWLINE> if is_categorical_dtype ( values ) : <NEWLINE> <TAB> return values <NEWLINE> <NEWLINE> <UNTAB> elif is_object_dtype ( dtype ) : <NEWLINE> <TAB> return values . ravel ( ) . tolist ( ) <NEWLINE> <NEWLINE> <UNTAB> if needs_i8_conversion ( dtype ) : <NEWLINE> <TAB> values = values . view ( <STRING> ) <NEWLINE> <UNTAB> v = values . ravel ( ) <NEWLINE> <NEWLINE> if compressor == <STRING> : <NEWLINE> <TAB> _check_zlib ( ) <NEWLINE> <NEWLINE> <NEWLINE> if dtype == np . object_ : <NEWLINE> <TAB> return v . tolist ( ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> v = v . tostring ( ) <NEWLINE> return ExtType ( <NUMBER> , zlib . compress ( v ) ) <NEWLINE> <NEWLINE> <UNTAB> elif compressor == <STRING> : <NEWLINE> <TAB> _check_blosc ( ) <NEWLINE> <NEWLINE> <NEWLINE> if dtype == np . object_ : <NEWLINE> <TAB> return v . tolist ( ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> v = v . tostring ( ) <NEWLINE> return ExtType ( <NUMBER> , blosc . compress ( v , typesize = dtype . itemsize ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return ExtType ( <NUMBER> , v . tostring ( ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def isinf ( a ) : <NEWLINE> <TAB> <NEWLINE> a = as_tensor_variable ( a ) <NEWLINE> if a . dtype in discrete_dtypes : <NEWLINE> <TAB> return alloc ( np . asarray ( False , dtype = <STRING> ) , <NEWLINE> * [ a . shape [ i ] for i in range ( a . ndim ) ] ) <NEWLINE> <UNTAB> return isinf_ ( a ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def copy ( self , share_memory = False , swap = None , delete_updates = False , <NEWLINE> name = None , profile = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def checkSV ( sv_ori , sv_rpl ) : <NEWLINE> <TAB> <NEWLINE> SharedVariable = theano . tensor . sharedvar . SharedVariable <NEWLINE> assert isinstance ( sv_ori , SharedVariable ) , ( <NEWLINE> <STRING> , sv_ori , <NEWLINE> <STRING> , type ( sv_ori ) ) <NEWLINE> assert isinstance ( sv_rpl , SharedVariable ) , ( <NEWLINE> <STRING> , sv_rpl , <NEWLINE> <STRING> , type ( sv_ori ) ) <NEWLINE> assert sv_ori . type == sv_rpl . type , ( <NEWLINE> <STRING> , <NEWLINE> <STRING> , sv_rpl . type , <NEWLINE> <STRING> , sv_ori . type ) <NEWLINE> <NEWLINE> <UNTAB> maker = self . maker <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> ins = [ copy . copy ( input ) for input in maker . inputs ] <NEWLINE> <NEWLINE> <NEWLINE> if delete_updates : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> out_vars = maker . fgraph . outputs [ : len ( maker . outputs ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> out_vars = maker . fgraph . outputs <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> memo = graph . clone_get_equiv ( maker . fgraph . inputs , out_vars ) <NEWLINE> fg_cpy = gof . fg . FunctionGraph ( [ memo [ i ] for i in maker . fgraph . inputs ] , <NEWLINE> [ memo [ o ] for o in out_vars ] , <NEWLINE> clone = False ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> outs = list ( map ( SymbolicOutput , fg_cpy . outputs [ : len ( maker . outputs ) ] ) ) <NEWLINE> for out_ori , out_cpy in zip ( maker . outputs , outs ) : <NEWLINE> <TAB> out_cpy . borrow = out_ori . borrow <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if swap is not None : <NEWLINE> <TAB> exist_svs = [ i . variable for i in maker . inputs ] <NEWLINE> <NEWLINE> <NEWLINE> for sv in iterkeys ( swap ) : <NEWLINE> <TAB> if sv not in exist_svs : <NEWLINE> <TAB> raise ValueError ( <STRING> % <NEWLINE> ( sv . name ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for index , ( i , in_v ) in enumerate ( zip ( ins , fg_cpy . inputs ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> var = maker . inputs [ index ] . variable <NEWLINE> <NEWLINE> if var in swap : <NEWLINE> <TAB> swap_sv = swap [ var ] <NEWLINE> checkSV ( i . variable , swap_sv ) <NEWLINE> <NEWLINE> <NEWLINE> i . variable = swap_sv <NEWLINE> i . value = swap_sv . container <NEWLINE> <NEWLINE> <NEWLINE> swap_sv = swap_sv . clone ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> fg_cpy . inputs [ index ] = swap_sv <NEWLINE> fg_cpy . replace ( in_v , swap_sv , reason = <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> update_i = len ( outs ) <NEWLINE> for i , in_var in zip ( ins , fg_cpy . inputs ) : <NEWLINE> <TAB> i . variable = in_var <NEWLINE> if not delete_updates and i . update is not None : <NEWLINE> <TAB> i . update = fg_cpy . outputs [ update_i ] <NEWLINE> update_i += <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> i . update = None <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> storage_map = self . fn . storage_map <NEWLINE> new_storage_map = { } <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if share_memory : <NEWLINE> <TAB> i_o_vars = maker . fgraph . inputs + maker . fgraph . outputs <NEWLINE> for key in storage_map . keys ( ) : <NEWLINE> <TAB> if key not in i_o_vars : <NEWLINE> <TAB> new_storage_map [ memo [ key ] ] = storage_map [ key ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if not name and self . name : <NEWLINE> <TAB> name = self . name + <STRING> <NEWLINE> <NEWLINE> <UNTAB> input_storage = [ i . value for i in ins ] <NEWLINE> <NEWLINE> if profile is None : <NEWLINE> <TAB> profile = config . profile or config . print_global_stats <NEWLINE> <NEWLINE> <UNTAB> if profile is True : <NEWLINE> <TAB> if name : <NEWLINE> <TAB> message = name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = str ( profile . message ) + <STRING> <NEWLINE> <UNTAB> profile = theano . compile . profiling . ProfileStats ( message = message ) <NEWLINE> <NEWLINE> <UNTAB> elif type ( profile ) == str : <NEWLINE> <TAB> profile = theano . compile . profiling . ProfileStats ( message = profile ) <NEWLINE> <NEWLINE> <UNTAB> f_cpy = maker . __class__ ( inputs = ins , outputs = outs , fgraph = fg_cpy , <NEWLINE> mode = maker . mode , profile = profile , <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> on_unused_input = <STRING> , <NEWLINE> function_builder = maker . function_builder , <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> accept_inplace = True , <NEWLINE> ) . create ( input_storage , <NEWLINE> storage_map = new_storage_map ) <NEWLINE> <NEWLINE> for in_ori , in_cpy , ori , cpy in zip ( maker . inputs , f_cpy . maker . inputs , <NEWLINE> self . input_storage , <NEWLINE> f_cpy . input_storage ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> swapped = swap is not None and in_ori . variable in swap <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if not in_ori . mutable and not swapped : <NEWLINE> <TAB> cpy . data = ori . data <NEWLINE> in_cpy . value = in_ori . value <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> container = f_cpy . finder . pop ( in_cpy . variable ) <NEWLINE> if not swapped : <NEWLINE> <TAB> f_cpy . finder [ in_ori . variable ] = container <NEWLINE> in_cpy . vairable = in_ori . variable <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> f_cpy . finder [ swap [ in_ori . variable ] ] = container <NEWLINE> in_cpy . variable = swap [ in_ori . variable ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> f_cpy . name = name <NEWLINE> f_cpy . maker . fgraph . name = name <NEWLINE> return f_cpy <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def truncated_cube_graph ( create_using = None ) : <NEWLINE> <TAB> <NEWLINE> description = [ <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <NUMBER> , <NEWLINE> [ [ <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , <NEWLINE> [ <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , <NEWLINE> [ <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , [ <NUMBER> ] , <NEWLINE> [ <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , [ <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , <NEWLINE> [ <NUMBER> , <NUMBER> ] , [ <NUMBER> ] , [ <NUMBER> ] , [ <NUMBER> ] , <NEWLINE> [ <NUMBER> ] , [ <NUMBER> ] , [ <NUMBER> ] , [ ] ] <NEWLINE> ] <NEWLINE> G = make_small_undirected_graph ( description , create_using ) <NEWLINE> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def sfield ( exprs , * symbols , ** options ) : <NEWLINE> <TAB> <NEWLINE> single = False <NEWLINE> if not is_sequence ( exprs ) : <NEWLINE> <TAB> exprs , single = [ exprs ] , True <NEWLINE> <NEWLINE> <UNTAB> exprs = list ( map ( sympify , exprs ) ) <NEWLINE> opt = build_options ( symbols , options ) <NEWLINE> numdens = [ ] <NEWLINE> for expr in exprs : <NEWLINE> <TAB> numdens . extend ( expr . as_numer_denom ( ) ) <NEWLINE> <UNTAB> reps , opt = _parallel_dict_from_expr ( numdens , opt ) <NEWLINE> <NEWLINE> if opt . domain is None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> coeffs = sum ( [ list ( rep . values ( ) ) for rep in reps ] , [ ] ) <NEWLINE> opt . domain , _ = construct_domain ( coeffs , opt = opt ) <NEWLINE> <NEWLINE> <UNTAB> _field = FracField ( opt . gens , opt . domain , opt . order ) <NEWLINE> fracs = [ ] <NEWLINE> for i in range ( <NUMBER> , len ( reps ) , <NUMBER> ) : <NEWLINE> <TAB> fracs . append ( _field ( tuple ( reps [ i : i + <NUMBER> ] ) ) ) <NEWLINE> <NEWLINE> <UNTAB> if single : <NEWLINE> <TAB> return ( _field , fracs [ <NUMBER> ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return ( _field , fracs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _prepare_fit_binary ( est , y , i ) : <NEWLINE> <TAB> <NEWLINE> y_i = np . ones ( y . shape , dtype = np . float64 , order = <STRING> ) <NEWLINE> y_i [ y != est . classes_ [ i ] ] = - <NUMBER> <NEWLINE> average_intercept = <NUMBER> <NEWLINE> average_coef = None <NEWLINE> <NEWLINE> if len ( est . classes_ ) == <NUMBER> : <NEWLINE> <TAB> if not est . average : <NEWLINE> <TAB> coef = est . coef_ . ravel ( ) <NEWLINE> intercept = est . intercept_ [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> coef = est . standard_coef_ . ravel ( ) <NEWLINE> intercept = est . standard_intercept_ [ <NUMBER> ] <NEWLINE> average_coef = est . average_coef_ . ravel ( ) <NEWLINE> average_intercept = est . average_intercept_ [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if not est . average : <NEWLINE> <TAB> coef = est . coef_ [ i ] <NEWLINE> intercept = est . intercept_ [ i ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> coef = est . standard_coef_ [ i ] <NEWLINE> intercept = est . standard_intercept_ [ i ] <NEWLINE> average_coef = est . average_coef_ [ i ] <NEWLINE> average_intercept = est . average_intercept_ [ i ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return y_i , coef , intercept , average_coef , average_intercept <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _approximate_mode ( class_counts , n_draws , rng ) : <NEWLINE> <TAB> <NEWLINE> rng = check_random_state ( rng ) <NEWLINE> <NEWLINE> <NEWLINE> continuous = n_draws * class_counts / class_counts . sum ( ) <NEWLINE> <NEWLINE> floored = np . floor ( continuous ) <NEWLINE> <NEWLINE> <NEWLINE> need_to_add = int ( n_draws - floored . sum ( ) ) <NEWLINE> if need_to_add > <NUMBER> : <NEWLINE> <TAB> remainder = continuous - floored <NEWLINE> values = np . sort ( np . unique ( remainder ) ) [ : : - <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> for value in values : <NEWLINE> <TAB> inds , = np . where ( remainder == value ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> add_now = min ( len ( inds ) , need_to_add ) <NEWLINE> inds = rng . choice ( inds , size = add_now , replace = False ) <NEWLINE> floored [ inds ] += <NUMBER> <NEWLINE> need_to_add -= add_now <NEWLINE> if need_to_add == <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return floored . astype ( np . int ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def clear_old ( self , age_thresh_del = None , delete_if_problem = False ) : <NEWLINE> <TAB> <NEWLINE> if age_thresh_del is None : <NEWLINE> <TAB> age_thresh_del = self . age_thresh_del <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if age_thresh_del < self . age_thresh_use : <NEWLINE> <TAB> if age_thresh_del > <NUMBER> : <NEWLINE> <TAB> _logger . warning ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> , <NEWLINE> age_thresh_del , <NEWLINE> self . age_thresh_use ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> _logger . info ( <STRING> ) <NEWLINE> <UNTAB> age_thresh_use = age_thresh_del <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> age_thresh_use = None <NEWLINE> <NEWLINE> <UNTAB> too_old_to_use = self . refresh ( <NEWLINE> age_thresh_use = age_thresh_use , <NEWLINE> delete_if_problem = delete_if_problem , <NEWLINE> <NEWLINE> cleanup = False ) <NEWLINE> if not too_old_to_use : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> with compilelock . lock_ctx ( ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> for entry in too_old_to_use : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> assert entry not in self . module_from_name <NEWLINE> parent = os . path . dirname ( entry ) <NEWLINE> assert parent . startswith ( os . path . join ( self . dirname , <STRING> ) ) <NEWLINE> _rmtree ( parent , msg = <STRING> , level = logging . INFO , <NEWLINE> ignore_nocleanup = True ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _compare_version ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if self . major == other . major : <NEWLINE> <TAB> if self . minor == other . minor : <NEWLINE> <TAB> if self . bugfix == other . bugfix : <NEWLINE> <TAB> vercmp = <NUMBER> <NEWLINE> <UNTAB> elif self . bugfix > other . bugfix : <NEWLINE> <TAB> vercmp = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> vercmp = - <NUMBER> <NEWLINE> <UNTAB> <UNTAB> elif self . minor > other . minor : <NEWLINE> <TAB> vercmp = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> vercmp = - <NUMBER> <NEWLINE> <UNTAB> <UNTAB> elif self . major > other . major : <NEWLINE> <TAB> vercmp = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> vercmp = - <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> return vercmp <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( v1 = [ <STRING> ] ) <NEWLINE> @ tf_should_use . should_use_result <NEWLINE> @ deprecated ( <STRING> , <STRING> ) <NEWLINE> def initialize_local_variables ( ) : <NEWLINE> <TAB> <NEWLINE> return local_variables_initializer ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def skip ( self , count ) : <NEWLINE> <TAB> <NEWLINE> return SkipDataset ( self , count ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def l1_norm ( f ) : <NEWLINE> <TAB> <NEWLINE> return dmp_l1_norm ( f . rep , f . lev , f . dom ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def copy ( self , deep = True ) : <NEWLINE> <TAB> <NEWLINE> data = self . _data . copy ( deep = deep ) <NEWLINE> return self . _constructor ( data ) . __finalize__ ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _get_info ( info , name ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> idx = info [ name ] <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> idx = info [ name ] = dict ( ) <NEWLINE> <UNTAB> return idx <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def shift ( self , periods = <NUMBER> , freq = None , axis = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if freq : <NEWLINE> <TAB> return self . tshift ( periods , freq , axis = axis ) <NEWLINE> <NEWLINE> <UNTAB> return super ( Panel , self ) . slice_shift ( periods , axis = axis ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def poly_TC ( f , K ) : <NEWLINE> <TAB> <NEWLINE> if not f : <NEWLINE> <TAB> return K . zero <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return f [ - <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _expm_multiply_simple_core ( A , B , t , mu , m_star , s , tol = None , balance = False ) : <NEWLINE> <TAB> <NEWLINE> if balance : <NEWLINE> <TAB> raise NotImplementedError <NEWLINE> <UNTAB> if tol is None : <NEWLINE> <TAB> u_d = <NUMBER> ** - <NUMBER> <NEWLINE> tol = u_d <NEWLINE> <UNTAB> F = B <NEWLINE> eta = np . exp ( t * mu / float ( s ) ) <NEWLINE> for i in range ( s ) : <NEWLINE> <TAB> c1 = _exact_inf_norm ( B ) <NEWLINE> for j in range ( m_star ) : <NEWLINE> <TAB> coeff = t / float ( s * ( j + <NUMBER> ) ) <NEWLINE> B = coeff * A . dot ( B ) <NEWLINE> c2 = _exact_inf_norm ( B ) <NEWLINE> F = F + B <NEWLINE> if c1 + c2 <= tol * _exact_inf_norm ( F ) : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> c1 = c2 <NEWLINE> <UNTAB> F = eta * F <NEWLINE> B = F <NEWLINE> <UNTAB> return F <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def ndarray_to_pil ( arr , format_str = None ) : <NEWLINE> <TAB> <NEWLINE> if arr . ndim == <NUMBER> : <NEWLINE> <TAB> arr = img_as_ubyte ( arr ) <NEWLINE> mode = { <NUMBER> : <STRING> , <NUMBER> : <STRING> } [ arr . shape [ <NUMBER> ] ] <NEWLINE> <NEWLINE> <UNTAB> elif format_str in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> mode = <STRING> <NEWLINE> mode_base = <STRING> <NEWLINE> <NEWLINE> if arr . dtype . kind == <STRING> : <NEWLINE> <TAB> arr = img_as_uint ( arr ) <NEWLINE> <NEWLINE> <UNTAB> elif arr . max ( ) < <NUMBER> and arr . min ( ) >= <NUMBER> : <NEWLINE> <TAB> arr = arr . astype ( np . uint8 ) <NEWLINE> mode = mode_base = <STRING> <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> arr = img_as_uint ( arr ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> arr = img_as_ubyte ( arr ) <NEWLINE> mode = <STRING> <NEWLINE> mode_base = <STRING> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> array_buffer = arr . tobytes ( ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> array_buffer = arr . tostring ( ) <NEWLINE> <NEWLINE> <UNTAB> if arr . ndim == <NUMBER> : <NEWLINE> <TAB> im = Image . new ( mode_base , arr . T . shape ) <NEWLINE> try : <NEWLINE> <TAB> im . frombytes ( array_buffer , <STRING> , mode ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> im . fromstring ( array_buffer , <STRING> , mode ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> image_shape = ( arr . shape [ <NUMBER> ] , arr . shape [ <NUMBER> ] ) <NEWLINE> try : <NEWLINE> <TAB> im = Image . frombytes ( mode , image_shape , array_buffer ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> im = Image . fromstring ( mode , image_shape , array_buffer ) <NEWLINE> <UNTAB> <UNTAB> return im <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _is_dtype_compat ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if is_categorical_dtype ( other ) : <NEWLINE> <TAB> if isinstance ( other , CategoricalIndex ) : <NEWLINE> <TAB> other = other . _values <NEWLINE> <UNTAB> if not other . is_dtype_equal ( self ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> values = other <NEWLINE> if not is_list_like ( values ) : <NEWLINE> <TAB> values = [ values ] <NEWLINE> <UNTAB> other = CategoricalIndex ( self . _create_categorical ( <NEWLINE> self , other , categories = self . categories , ordered = self . ordered ) ) <NEWLINE> if not other . isin ( values ) . all ( ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return other <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _YT_loop ( ker_pole , transfer_matrix , poles , B , maxiter , rtol ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> nb_real = poles [ np . isreal ( poles ) ] . shape [ <NUMBER> ] <NEWLINE> <NEWLINE> hnb = nb_real // <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if nb_real > <NUMBER> : <NEWLINE> <NEWLINE> <TAB> update_order = [ [ nb_real ] , [ <NUMBER> ] ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> update_order = [ [ ] , [ ] ] <NEWLINE> <NEWLINE> <UNTAB> r_comp = np . arange ( nb_real + <NUMBER> , len ( poles ) + <NUMBER> , <NUMBER> ) <NEWLINE> <NEWLINE> r_p = np . arange ( <NUMBER> , hnb + nb_real % <NUMBER> ) <NEWLINE> update_order [ <NUMBER> ] . extend ( <NUMBER> * r_p ) <NEWLINE> update_order [ <NUMBER> ] . extend ( <NUMBER> * r_p + <NUMBER> ) <NEWLINE> <NEWLINE> update_order [ <NUMBER> ] . extend ( r_comp ) <NEWLINE> update_order [ <NUMBER> ] . extend ( r_comp + <NUMBER> ) <NEWLINE> <NEWLINE> r_p = np . arange ( <NUMBER> , hnb + <NUMBER> ) <NEWLINE> update_order [ <NUMBER> ] . extend ( <NUMBER> * r_p - <NUMBER> ) <NEWLINE> update_order [ <NUMBER> ] . extend ( <NUMBER> * r_p ) <NEWLINE> <NEWLINE> if hnb == <NUMBER> and np . isreal ( poles [ <NUMBER> ] ) : <NEWLINE> <TAB> update_order [ <NUMBER> ] . append ( <NUMBER> ) <NEWLINE> update_order [ <NUMBER> ] . append ( <NUMBER> ) <NEWLINE> <UNTAB> update_order [ <NUMBER> ] . extend ( r_comp ) <NEWLINE> update_order [ <NUMBER> ] . extend ( r_comp + <NUMBER> ) <NEWLINE> <NEWLINE> r_j = np . arange ( <NUMBER> , hnb + nb_real % <NUMBER> ) <NEWLINE> for j in r_j : <NEWLINE> <TAB> for i in range ( <NUMBER> , hnb + <NUMBER> ) : <NEWLINE> <TAB> update_order [ <NUMBER> ] . append ( i ) <NEWLINE> update_order [ <NUMBER> ] . append ( i + j ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if hnb == <NUMBER> and np . isreal ( poles [ <NUMBER> ] ) : <NEWLINE> <TAB> update_order [ <NUMBER> ] . append ( <NUMBER> ) <NEWLINE> update_order [ <NUMBER> ] . append ( <NUMBER> ) <NEWLINE> <UNTAB> update_order [ <NUMBER> ] . extend ( r_comp ) <NEWLINE> update_order [ <NUMBER> ] . extend ( r_comp + <NUMBER> ) <NEWLINE> <NEWLINE> r_j = np . arange ( <NUMBER> , hnb + nb_real % <NUMBER> ) <NEWLINE> for j in r_j : <NEWLINE> <TAB> for i in range ( hnb + <NUMBER> , nb_real + <NUMBER> ) : <NEWLINE> <TAB> idx_1 = i + j <NEWLINE> if idx_1 > nb_real : <NEWLINE> <TAB> idx_1 = i + j - nb_real <NEWLINE> <UNTAB> update_order [ <NUMBER> ] . append ( i ) <NEWLINE> update_order [ <NUMBER> ] . append ( idx_1 ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if hnb == <NUMBER> and np . isreal ( poles [ <NUMBER> ] ) : <NEWLINE> <TAB> update_order [ <NUMBER> ] . append ( <NUMBER> ) <NEWLINE> update_order [ <NUMBER> ] . append ( <NUMBER> ) <NEWLINE> <UNTAB> update_order [ <NUMBER> ] . extend ( r_comp ) <NEWLINE> update_order [ <NUMBER> ] . extend ( r_comp + <NUMBER> ) <NEWLINE> <NEWLINE> for i in range ( <NUMBER> , hnb + <NUMBER> ) : <NEWLINE> <TAB> update_order [ <NUMBER> ] . append ( i ) <NEWLINE> update_order [ <NUMBER> ] . append ( i + hnb ) <NEWLINE> <NEWLINE> <UNTAB> if hnb == <NUMBER> and np . isreal ( poles [ <NUMBER> ] ) : <NEWLINE> <TAB> update_order [ <NUMBER> ] . append ( <NUMBER> ) <NEWLINE> update_order [ <NUMBER> ] . append ( <NUMBER> ) <NEWLINE> <UNTAB> update_order [ <NUMBER> ] . extend ( r_comp ) <NEWLINE> update_order [ <NUMBER> ] . extend ( r_comp + <NUMBER> ) <NEWLINE> <NEWLINE> update_order = np . array ( update_order ) . T - <NUMBER> <NEWLINE> stop = False <NEWLINE> nb_try = <NUMBER> <NEWLINE> while nb_try < maxiter and not stop : <NEWLINE> <TAB> det_transfer_matrixb = np . abs ( np . linalg . det ( transfer_matrix ) ) <NEWLINE> for i , j in update_order : <NEWLINE> <TAB> if i == j : <NEWLINE> <TAB> assert i == <NUMBER> , <STRING> <NEWLINE> assert np . isreal ( poles [ i ] ) , <STRING> <NEWLINE> _KNV0 ( B , ker_pole , transfer_matrix , i , poles ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> transfer_matrix_not_i_j = np . delete ( transfer_matrix , ( i , j ) , <NEWLINE> axis = <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> Q , _ = s_qr ( transfer_matrix_not_i_j , mode = <STRING> ) <NEWLINE> <NEWLINE> if np . isreal ( poles [ i ] ) : <NEWLINE> <TAB> assert np . isreal ( poles [ j ] ) , <STRING> + <STRING> + str ( poles ) <NEWLINE> _YT_real ( ker_pole , Q , transfer_matrix , i , j ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> assert ~ np . isreal ( poles [ i ] ) , <STRING> + <STRING> + str ( poles ) <NEWLINE> _YT_complex ( ker_pole , Q , transfer_matrix , i , j ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> det_transfer_matrix = np . max ( ( np . sqrt ( np . spacing ( <NUMBER> ) ) , <NEWLINE> np . abs ( np . linalg . det ( transfer_matrix ) ) ) ) <NEWLINE> cur_rtol = np . abs ( <NEWLINE> ( det_transfer_matrix - <NEWLINE> det_transfer_matrixb ) / <NEWLINE> det_transfer_matrix ) <NEWLINE> if cur_rtol < rtol and det_transfer_matrix > np . sqrt ( np . spacing ( <NUMBER> ) ) : <NEWLINE> <NEWLINE> <TAB> stop = True <NEWLINE> <UNTAB> nb_try += <NUMBER> <NEWLINE> <UNTAB> return stop , cur_rtol , nb_try <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _index_labels_to_array ( labels , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( labels , ( compat . string_types , tuple ) ) : <NEWLINE> <TAB> labels = [ labels ] <NEWLINE> <NEWLINE> <UNTAB> if not isinstance ( labels , ( list , np . ndarray ) ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> labels = list ( labels ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> labels = [ labels ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> labels = _asarray_tuplesafe ( labels , dtype = dtype ) <NEWLINE> <NEWLINE> return labels <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , cell , compile_stateful = False ) : <NEWLINE> <TAB> <NEWLINE> self . _cell = cell <NEWLINE> self . _compile_stateful = compile_stateful <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __imul__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> m = getmask ( other ) <NEWLINE> if self . _mask is nomask : <NEWLINE> <TAB> if m is not nomask and m . any ( ) : <NEWLINE> <TAB> self . _mask = make_mask_none ( self . shape , self . dtype ) <NEWLINE> self . _mask += m <NEWLINE> <UNTAB> <UNTAB> elif m is not nomask : <NEWLINE> <TAB> self . _mask += m <NEWLINE> <UNTAB> self . _data . __imul__ ( np . where ( self . _mask , self . dtype . type ( <NUMBER> ) , <NEWLINE> getdata ( other ) ) ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def infer_reuse_pattern ( fgraph , outputs_to_disown ) : <NEWLINE> <TAB> <NEWLINE> rval = set ( ) <NEWLINE> for o in outputs_to_disown : <NEWLINE> <TAB> view_tree_set ( alias_root ( o ) , rval ) <NEWLINE> <NEWLINE> <UNTAB> rval = set ( r for r in rval if r . owner is not None ) <NEWLINE> <NEWLINE> return rval <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def jiffies ( _load_time = [ ] ) : <NEWLINE> <TAB> <NEWLINE> import time <NEWLINE> if not _load_time : <NEWLINE> <TAB> _load_time . append ( time . time ( ) ) <NEWLINE> <UNTAB> return int ( <NUMBER> * ( time . time ( ) - _load_time [ <NUMBER> ] ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_label_coords ( self , distances , XX , YY , ysize , lw ) : <NEWLINE> <TAB> <NEWLINE> hysize = int ( ysize / <NUMBER> ) <NEWLINE> adist = np . argsort ( distances ) <NEWLINE> <NEWLINE> for ind in adist : <NEWLINE> <TAB> x , y = XX [ ind ] [ hysize ] , YY [ ind ] [ hysize ] <NEWLINE> if self . too_close ( x , y , lw ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> return x , y , ind <NEWLINE> <NEWLINE> <UNTAB> ind = adist [ <NUMBER> ] <NEWLINE> x , y = XX [ ind ] [ hysize ] , YY [ ind ] [ hysize ] <NEWLINE> return x , y , ind <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def flag_type ( self ) : <NEWLINE> <TAB> <NEWLINE> return <STRING> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def new_figure_manager_given_figure ( cls , num , figure ) : <NEWLINE> <TAB> <NEWLINE> with _restore_foreground_window_at_end ( ) : <NEWLINE> <TAB> window = Tk . Tk ( className = <STRING> ) <NEWLINE> window . withdraw ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> icon_fname = os . path . join ( <NEWLINE> rcParams [ <STRING> ] , <STRING> , <STRING> ) <NEWLINE> icon_img = Tk . PhotoImage ( file = icon_fname , master = window ) <NEWLINE> try : <NEWLINE> <TAB> window . iconphoto ( False , icon_img ) <NEWLINE> <UNTAB> except Exception as exc : <NEWLINE> <NEWLINE> <TAB> _log . info ( <STRING> , exc ) <NEWLINE> <NEWLINE> <UNTAB> canvas = cls . FigureCanvas ( figure , master = window ) <NEWLINE> manager = cls . FigureManager ( canvas , num , window ) <NEWLINE> if matplotlib . is_interactive ( ) : <NEWLINE> <TAB> manager . show ( ) <NEWLINE> canvas . draw_idle ( ) <NEWLINE> <UNTAB> return manager <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def argsort ( a , axis = - <NUMBER> , kind = <STRING> , order = None ) : <NEWLINE> <TAB> <NEWLINE> if axis is None : <NEWLINE> <TAB> a = a . flatten ( ) <NEWLINE> axis = <NUMBER> <NEWLINE> <UNTAB> return ArgSortOp ( kind , order ) ( a , axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <NEWLINE> <STRING> , <NEWLINE> v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecation . deprecated_endpoints ( <STRING> ) <NEWLINE> def verify_tensor_all_finite ( t , msg , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ t ] ) as name : <NEWLINE> <TAB> t = ops . convert_to_tensor ( t , name = <STRING> ) <NEWLINE> with ops . colocate_with ( t ) : <NEWLINE> <TAB> verify_input = array_ops . check_numerics ( t , message = msg ) <NEWLINE> out = control_flow_ops . with_dependencies ( [ verify_input ] , t ) <NEWLINE> <UNTAB> <UNTAB> return out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _maybe_coerce_values ( self , values ) : <NEWLINE> <TAB> <NEWLINE> if values . dtype != _NS_DTYPE : <NEWLINE> <TAB> values = conversion . ensure_datetime64ns ( values ) <NEWLINE> <UNTAB> return values <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _expand ( self , ** hints ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _init_dict ( self , data , index = None , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if data : <NEWLINE> <TAB> keys , values = zip ( * compat . iteritems ( data ) ) <NEWLINE> values = list ( values ) <NEWLINE> <UNTAB> elif index is not None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> values = na_value_for_dtype ( dtype ) <NEWLINE> keys = index <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> keys , values = [ ] , [ ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> s = Series ( values , index = keys , dtype = dtype ) <NEWLINE> <NEWLINE> <NEWLINE> if data and index is not None : <NEWLINE> <TAB> s = s . reindex ( index , copy = False ) <NEWLINE> <UNTAB> elif not PY36 and not isinstance ( data , OrderedDict ) and data : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> s = s . sort_index ( ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> return s . _data , s . index <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def spread_part_multiplicity ( self ) : <NEWLINE> <TAB> <NEWLINE> j = self . f [ self . lpart ] <NEWLINE> k = self . f [ self . lpart + <NUMBER> ] <NEWLINE> base = k <NEWLINE> <NEWLINE> changed = False <NEWLINE> <NEWLINE> <NEWLINE> for j in range ( self . f [ self . lpart ] , self . f [ self . lpart + <NUMBER> ] ) : <NEWLINE> <TAB> self . pstack [ k ] . u = self . pstack [ j ] . u - self . pstack [ j ] . v <NEWLINE> if self . pstack [ k ] . u == <NUMBER> : <NEWLINE> <TAB> changed = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . pstack [ k ] . c = self . pstack [ j ] . c <NEWLINE> if changed : <NEWLINE> <TAB> self . pstack [ k ] . v = self . pstack [ k ] . u <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if self . pstack [ k ] . u < self . pstack [ j ] . v : <NEWLINE> <TAB> self . pstack [ k ] . v = self . pstack [ k ] . u <NEWLINE> changed = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . pstack [ k ] . v = self . pstack [ j ] . v <NEWLINE> <UNTAB> <UNTAB> k = k + <NUMBER> <NEWLINE> <UNTAB> <UNTAB> if k > base : <NEWLINE> <NEWLINE> <TAB> self . lpart = self . lpart + <NUMBER> <NEWLINE> self . f [ self . lpart + <NUMBER> ] = k <NEWLINE> return True <NEWLINE> <UNTAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def abort_everything ( self , ensure_ready = True ) : <NEWLINE> <TAB> <NEWLINE> self . _workers . shutdown ( kill_workers = True ) <NEWLINE> delete_folder ( self . _workers . _temp_folder ) <NEWLINE> self . _workers = None <NEWLINE> if ensure_ready : <NEWLINE> <TAB> self . configure ( n_jobs = self . parallel . n_jobs , parallel = self . parallel ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _word_ngrams ( self , tokens , stop_words = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if stop_words is not None : <NEWLINE> <TAB> tokens = [ w for w in tokens if w not in stop_words ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> min_n , max_n = self . ngram_range <NEWLINE> if max_n != <NUMBER> : <NEWLINE> <TAB> original_tokens = tokens <NEWLINE> if min_n == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> tokens = list ( original_tokens ) <NEWLINE> min_n += <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> tokens = [ ] <NEWLINE> <NEWLINE> <UNTAB> n_original_tokens = len ( original_tokens ) <NEWLINE> <NEWLINE> <NEWLINE> tokens_append = tokens . append <NEWLINE> space_join = <STRING> . join <NEWLINE> <NEWLINE> for n in xrange ( min_n , <NEWLINE> min ( max_n + <NUMBER> , n_original_tokens + <NUMBER> ) ) : <NEWLINE> <TAB> for i in xrange ( n_original_tokens - n + <NUMBER> ) : <NEWLINE> <TAB> tokens_append ( space_join ( original_tokens [ i : i + n ] ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return tokens <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_dense ( self ) : <NEWLINE> <TAB> <NEWLINE> ret = np . zeros ( [ self . n , self . m ] , dtype = np . float64 ) <NEWLINE> nvals = self . vals . size <NEWLINE> for i in range ( nvals ) : <NEWLINE> <TAB> ret [ self . rows [ i ] , self . cols [ i ] ] += self . vals [ i ] <NEWLINE> <UNTAB> return ret <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def check_gradient ( fcn , Dfcn , x0 , args = ( ) , col_deriv = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> x = atleast_1d ( x0 ) <NEWLINE> n = len ( x ) <NEWLINE> x = x . reshape ( ( n , ) ) <NEWLINE> fvec = atleast_1d ( fcn ( x , * args ) ) <NEWLINE> m = len ( fvec ) <NEWLINE> fvec = fvec . reshape ( ( m , ) ) <NEWLINE> ldfjac = m <NEWLINE> fjac = atleast_1d ( Dfcn ( x , * args ) ) <NEWLINE> fjac = fjac . reshape ( ( m , n ) ) <NEWLINE> if col_deriv == <NUMBER> : <NEWLINE> <TAB> fjac = transpose ( fjac ) <NEWLINE> <NEWLINE> <UNTAB> xp = zeros ( ( n , ) , float ) <NEWLINE> err = zeros ( ( m , ) , float ) <NEWLINE> fvecp = None <NEWLINE> with _MINPACK_LOCK : <NEWLINE> <TAB> _minpack . _chkder ( m , n , x , fvec , fjac , ldfjac , xp , fvecp , <NUMBER> , err ) <NEWLINE> <NEWLINE> <UNTAB> fvecp = atleast_1d ( fcn ( xp , * args ) ) <NEWLINE> fvecp = fvecp . reshape ( ( m , ) ) <NEWLINE> with _MINPACK_LOCK : <NEWLINE> <TAB> _minpack . _chkder ( m , n , x , fvec , fjac , ldfjac , xp , fvecp , <NUMBER> , err ) <NEWLINE> <NEWLINE> <UNTAB> good = ( product ( greater ( err , <NUMBER> ) , axis = <NUMBER> ) ) <NEWLINE> <NEWLINE> return ( good , err ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _get_batch_shape ( bmat , bvec ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> vec_shape = torch . _C . _infer_size ( bvec . shape , bmat . shape [ : - <NUMBER> ] ) <NEWLINE> <UNTAB> except RuntimeError : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( bvec . shape , bmat . shape ) ) <NEWLINE> <UNTAB> return torch . Size ( vec_shape [ : - <NUMBER> ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def value_zeros ( self , shape ) : <NEWLINE> <TAB> <NEWLINE> return np . zeros ( shape , dtype = self . dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_exquo_ground ( f , c , u , K ) : <NEWLINE> <TAB> <NEWLINE> if not u : <NEWLINE> <TAB> return dup_exquo_ground ( f , c , K ) <NEWLINE> <NEWLINE> <UNTAB> v = u - <NUMBER> <NEWLINE> <NEWLINE> return [ dmp_exquo_ground ( cf , c , v , K ) for cf in f ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def tensors_to_item ( self , keys_to_tensors ) : <NEWLINE> <TAB> <NEWLINE> sides = [ ] <NEWLINE> for key in self . _full_keys : <NEWLINE> <TAB> side = keys_to_tensors [ key ] <NEWLINE> if isinstance ( side , sparse_tensor . SparseTensor ) : <NEWLINE> <TAB> side = side . values <NEWLINE> <UNTAB> side = array_ops . expand_dims ( side , <NUMBER> ) <NEWLINE> sides . append ( side ) <NEWLINE> <NEWLINE> <UNTAB> bounding_box = array_ops . concat ( sides , <NUMBER> ) <NEWLINE> return array_ops . transpose ( bounding_box ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def njoin ( * path ) : <NEWLINE> <TAB> <NEWLINE> paths = [ ] <NEWLINE> for p in path : <NEWLINE> <TAB> if is_sequence ( p ) : <NEWLINE> <NEWLINE> <TAB> paths . append ( njoin ( * p ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> assert is_string ( p ) <NEWLINE> paths . append ( p ) <NEWLINE> <UNTAB> <UNTAB> path = paths <NEWLINE> if not path : <NEWLINE> <NEWLINE> <TAB> joined = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> joined = os . path . join ( * path ) <NEWLINE> <UNTAB> if os . path . sep != <STRING> : <NEWLINE> <TAB> joined = joined . replace ( <STRING> , os . path . sep ) <NEWLINE> <UNTAB> return minrelpath ( joined ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def last_access_time ( path ) : <NEWLINE> <TAB> <NEWLINE> return os . stat ( path ) [ stat . ST_ATIME ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def record ( self , category = Warning , message = <STRING> , module = None ) : <NEWLINE> <TAB> <NEWLINE> return self . _filter ( category = category , message = message , module = module , <NEWLINE> record = True ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def log_poisson_loss ( targets , log_input , compute_full_loss = False , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ log_input , targets ] ) as name : <NEWLINE> <TAB> log_input = ops . convert_to_tensor ( log_input , name = <STRING> ) <NEWLINE> targets = ops . convert_to_tensor ( targets , name = <STRING> ) <NEWLINE> try : <NEWLINE> <TAB> targets . get_shape ( ) . merge_with ( log_input . get_shape ( ) ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % <NEWLINE> ( log_input . get_shape ( ) , targets . get_shape ( ) ) ) <NEWLINE> <NEWLINE> <UNTAB> result = math_ops . exp ( log_input ) - log_input * targets <NEWLINE> if compute_full_loss : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> point_five = constant_op . constant ( <NUMBER> , dtype = targets . dtype ) <NEWLINE> two_pi = constant_op . constant ( <NUMBER> * math . pi , dtype = targets . dtype ) <NEWLINE> <NEWLINE> stirling_approx = ( targets * math_ops . log ( targets ) ) - targets + ( <NEWLINE> point_five * math_ops . log ( two_pi * targets ) ) <NEWLINE> zeros = array_ops . zeros_like ( targets , dtype = targets . dtype ) <NEWLINE> ones = array_ops . ones_like ( targets , dtype = targets . dtype ) <NEWLINE> cond = math_ops . logical_and ( targets >= zeros , targets <= ones ) <NEWLINE> result += array_ops . where ( cond , zeros , stirling_approx ) <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def perform ( self , node , inputs , outputs ) : <NEWLINE> <TAB> <NEWLINE> x , w , v , W , V = inputs <NEWLINE> N = x . shape [ <NUMBER> ] <NEWLINE> outer = np . outer <NEWLINE> <NEWLINE> def G ( n ) : <NEWLINE> <TAB> return sum ( v [ : , m ] * V . T [ n ] . dot ( v [ : , m ] ) / ( w [ n ] - w [ m ] ) <NEWLINE> for m in xrange ( N ) if m != n ) <NEWLINE> <NEWLINE> <UNTAB> g = sum ( outer ( v [ : , n ] , v [ : , n ] * W [ n ] + G ( n ) ) <NEWLINE> for n in xrange ( N ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> out = self . tri0 ( g ) + self . tri1 ( g ) . T <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> outputs [ <NUMBER> ] [ <NUMBER> ] = np . asarray ( out , dtype = node . outputs [ <NUMBER> ] . dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def samples ( sound ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return numpy . array ( sound , copy = False ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def scale_area ( self , density , max_density , scale_hue ) : <NEWLINE> <TAB> <NEWLINE> if self . hue_names is None : <NEWLINE> <TAB> for d in density : <NEWLINE> <TAB> if d . size > <NUMBER> : <NEWLINE> <TAB> d /= max_density . max ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for i , group in enumerate ( density ) : <NEWLINE> <TAB> for d in group : <NEWLINE> <TAB> if scale_hue : <NEWLINE> <TAB> max = max_density [ i ] . max ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> max = max_density . max ( ) <NEWLINE> <UNTAB> if d . size > <NUMBER> : <NEWLINE> <TAB> d /= max <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , seq ) : <NEWLINE> <TAB> <NEWLINE> self . seq = seq <NEWLINE> self . offset_string = <STRING> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _dot0 ( a , b ) : <NEWLINE> <TAB> <NEWLINE> if b . ndim <= <NUMBER> : <NEWLINE> <TAB> return dot ( a , b ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> axes = list ( range ( b . ndim ) ) <NEWLINE> axes . insert ( - <NUMBER> , <NUMBER> ) <NEWLINE> axes . pop ( <NUMBER> ) <NEWLINE> return dot ( a , b . transpose ( axes ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def fnmatch ( name , pat ) : <NEWLINE> <TAB> <NEWLINE> name = os . path . normcase ( name ) <NEWLINE> pat = os . path . normcase ( pat ) <NEWLINE> return fnmatchcase ( name , pat ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def bfs_predecessors ( G , source , depth_limit = None ) : <NEWLINE> <TAB> <NEWLINE> for s , t in bfs_edges ( G , source , depth_limit = depth_limit ) : <NEWLINE> <TAB> yield ( t , s ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def node_redundancy ( G , nodes = None ) : <NEWLINE> <TAB> <NEWLINE> if nodes is None : <NEWLINE> <TAB> nodes = G <NEWLINE> <UNTAB> if any ( len ( G [ v ] ) < <NUMBER> for v in nodes ) : <NEWLINE> <TAB> raise NetworkXError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return { v : _node_redundancy ( G , v ) for v in nodes } <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def new_subplotspec ( self , loc , rowspan = <NUMBER> , colspan = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> loc1 , loc2 = loc <NEWLINE> subplotspec = self [ loc1 : loc1 + rowspan , loc2 : loc2 + colspan ] <NEWLINE> return subplotspec <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _transform_fast ( self , result , obj , func_nm ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> cast = self . _transform_should_cast ( func_nm ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> ids , _ , ngroup = self . grouper . group_info <NEWLINE> output = [ ] <NEWLINE> for i , _ in enumerate ( result . columns ) : <NEWLINE> <TAB> res = algorithms . take_1d ( result . iloc [ : , i ] . values , ids ) <NEWLINE> if cast : <NEWLINE> <TAB> res = self . _try_cast ( res , obj . iloc [ : , i ] ) <NEWLINE> <UNTAB> output . append ( res ) <NEWLINE> <NEWLINE> <UNTAB> return DataFrame . _from_arrays ( output , columns = result . columns , <NEWLINE> index = obj . index ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ estimator_export ( <STRING> ) <NEWLINE> def build_raw_serving_input_receiver_fn ( features , default_batch_size = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def serving_input_receiver_fn ( ) : <NEWLINE> <TAB> <NEWLINE> receiver_tensors = _placeholders_from_receiver_tensors_dict ( <NEWLINE> features , default_batch_size ) <NEWLINE> return ServingInputReceiver ( receiver_tensors , receiver_tensors ) <NEWLINE> <NEWLINE> <UNTAB> return serving_input_receiver_fn <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def sparsify ( self ) : <NEWLINE> <TAB> <NEWLINE> msg = <STRING> <NEWLINE> check_is_fitted ( self , <STRING> , msg = msg ) <NEWLINE> self . coef_ = sp . csr_matrix ( self . coef_ ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def poisson ( random_state , size = None , lam = <NUMBER> , ndim = None , dtype = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> lam = tensor . as_tensor_variable ( lam ) <NEWLINE> <NEWLINE> ndim , size , bcast = _infer_ndim_bcast ( ndim , size ) <NEWLINE> <NEWLINE> op = RandomFunction ( <STRING> , tensor . TensorType ( dtype = dtype , <NEWLINE> broadcastable = bcast ) ) <NEWLINE> return op ( random_state , size , lam ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_square ( n , prep = True ) : <NEWLINE> <TAB> <NEWLINE> if prep : <NEWLINE> <TAB> n = as_int ( n ) <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> if n in [ <NUMBER> , <NUMBER> ] : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> <UNTAB> m = n & <NUMBER> <NEWLINE> if not ( ( m * <NUMBER> ) & ( m * <NUMBER> ) & <NUMBER> ) : <NEWLINE> <TAB> m = n % <NUMBER> <NEWLINE> if not ( ( m * <NUMBER> ) & ( m * <NUMBER> ) & <NUMBER> ) : <NEWLINE> <TAB> from sympy . ntheory import perfect_power <NEWLINE> if perfect_power ( n , [ <NUMBER> ] ) : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return False <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def degree ( G , nbunch = None , weight = None ) : <NEWLINE> <TAB> <NEWLINE> return G . degree ( nbunch , weight ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __iter__ ( self ) : <NEWLINE> <TAB> <NEWLINE> for i in range ( len ( self ) ) : <NEWLINE> <TAB> yield self [ i ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _lower_triangular_solve ( self , rhs ) : <NEWLINE> <TAB> <NEWLINE> X = zeros ( self . rows , rhs . cols ) <NEWLINE> for j in range ( rhs . cols ) : <NEWLINE> <TAB> for i in range ( self . rows ) : <NEWLINE> <TAB> if self [ i , i ] == <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> X [ i , j ] = ( rhs [ i , j ] - sum ( self [ i , k ] * X [ k , j ] <NEWLINE> for k in range ( i ) ) ) / self [ i , i ] <NEWLINE> <UNTAB> <UNTAB> return self . _new ( X ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _wrap_results ( result , dtype ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if is_datetime64_dtype ( dtype ) : <NEWLINE> <TAB> if not isinstance ( result , np . ndarray ) : <NEWLINE> <TAB> result = tslib . Timestamp ( result ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result = result . view ( dtype ) <NEWLINE> <UNTAB> <UNTAB> elif is_timedelta64_dtype ( dtype ) : <NEWLINE> <TAB> if not isinstance ( result , np . ndarray ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if np . fabs ( result ) > _int64_max : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> result = tslib . Timedelta ( result , unit = <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result = result . astype ( <STRING> ) . view ( dtype ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def pdiv ( f , g ) : <NEWLINE> <TAB> <NEWLINE> lev , dom , per , F , G = f . unify ( g ) <NEWLINE> q , r = dmp_pdiv ( F , G , lev , dom ) <NEWLINE> return per ( q ) , per ( r ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ docfiller <NEWLINE> def __init__ ( self , mat_stream , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> super ( MatFile4Reader , self ) . __init__ ( mat_stream , * args , ** kwargs ) <NEWLINE> self . _matrix_reader = None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sparse_segment_sqrt_n_eager_fallback ( data , indices , segment_ids , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , ( data , ) = _execute . args_to_matching_eager ( [ data ] , _ctx ) <NEWLINE> _attr_Tidx , ( indices , ) = _execute . args_to_matching_eager ( [ indices ] , _ctx , _dtypes . int32 ) <NEWLINE> segment_ids = _ops . convert_to_tensor ( segment_ids , _dtypes . int32 ) <NEWLINE> _inputs_flat = [ data , indices , segment_ids ] <NEWLINE> _attrs = ( <STRING> , _attr_T , <STRING> , _attr_Tidx ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def mean_absolute_error ( x0 , x1 ) : <NEWLINE> <TAB> <NEWLINE> return MeanAbsoluteError ( ) . apply ( ( x0 , x1 ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def sum_regularizer ( regularizer_list , scope = None ) : <NEWLINE> <TAB> <NEWLINE> regularizer_list = [ reg for reg in regularizer_list if reg is not None ] <NEWLINE> if not regularizer_list : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> def sum_reg ( weights ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( scope , <STRING> , [ weights ] ) as name : <NEWLINE> <TAB> regularizer_tensors = [ reg ( weights ) for reg in regularizer_list ] <NEWLINE> return math_ops . add_n ( regularizer_tensors , name = name ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return sum_reg <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def compute_jac_scale ( J , scale_inv_old = None ) : <NEWLINE> <TAB> <NEWLINE> if issparse ( J ) : <NEWLINE> <TAB> scale_inv = np . asarray ( J . power ( <NUMBER> ) . sum ( axis = <NUMBER> ) ) . ravel ( ) ** <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> scale_inv = np . sum ( J ** <NUMBER> , axis = <NUMBER> ) ** <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> if scale_inv_old is None : <NEWLINE> <TAB> scale_inv [ scale_inv == <NUMBER> ] = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> scale_inv = np . maximum ( scale_inv , scale_inv_old ) <NEWLINE> <NEWLINE> <UNTAB> return <NUMBER> / scale_inv , scale_inv <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def singularities ( expression , symbol ) : <NEWLINE> <TAB> <NEWLINE> if not expression . is_rational_function ( symbol ) : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> domain = S . Reals if symbol . is_real else S . Complexes <NEWLINE> return solveset ( simplify ( <NUMBER> / expression ) , symbol , domain ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def comb ( N , k , exact = False , repetition = False ) : <NEWLINE> <TAB> <NEWLINE> if repetition : <NEWLINE> <TAB> return comb ( N + k - <NUMBER> , k , exact ) <NEWLINE> <UNTAB> if exact : <NEWLINE> <TAB> return _comb_int ( N , k ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> k , N = asarray ( k ) , asarray ( N ) <NEWLINE> cond = ( k <= N ) & ( N >= <NUMBER> ) & ( k >= <NUMBER> ) <NEWLINE> vals = binom ( N , k ) <NEWLINE> if isinstance ( vals , np . ndarray ) : <NEWLINE> <TAB> vals [ ~ cond ] = <NUMBER> <NEWLINE> <UNTAB> elif not cond : <NEWLINE> <TAB> vals = np . float64 ( <NUMBER> ) <NEWLINE> <UNTAB> return vals <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def restore ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if self . G1_node is not None and self . G2_node is not None : <NEWLINE> <TAB> del self . GM . core_1 [ self . G1_node ] <NEWLINE> del self . GM . core_2 [ self . G2_node ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for vector in ( self . GM . inout_1 , self . GM . inout_2 ) : <NEWLINE> <TAB> for node in list ( vector . keys ( ) ) : <NEWLINE> <TAB> if vector [ node ] == self . depth : <NEWLINE> <TAB> del vector [ node ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_consolidated ( self ) : <NEWLINE> <TAB> <NEWLINE> if not self . _known_consolidated : <NEWLINE> <TAB> self . _consolidate_check ( ) <NEWLINE> <UNTAB> return self . _is_consolidated <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def freeze ( self , object_map = None , to_graph = None ) : <NEWLINE> <TAB> <NEWLINE> checkpointable_objects , path_to_root = ( <NEWLINE> _breadth_first_checkpointable_traversal ( self . _root_checkpointable ) ) <NEWLINE> if to_graph : <NEWLINE> <TAB> target_context = to_graph . as_default <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> target_context = ops . NullContextmanager <NEWLINE> <UNTAB> with target_context ( ) : <NEWLINE> <TAB> named_saveable_objects , graph_proto , _ = _serialize_gathered_objects ( <NEWLINE> checkpointable_objects , <NEWLINE> path_to_root , <NEWLINE> saveables_cache = None , <NEWLINE> object_map = object_map ) <NEWLINE> with ops . device ( <STRING> ) : <NEWLINE> <TAB> object_graph_tensor = constant_op . constant ( <NEWLINE> graph_proto . SerializeToString ( ) , dtype = dtypes . string ) <NEWLINE> <UNTAB> named_saveable_objects . append ( <NEWLINE> base . NoRestoreSaveable ( <NEWLINE> tensor = object_graph_tensor , <NEWLINE> name = base . OBJECT_GRAPH_PROTO_KEY ) ) <NEWLINE> <NEWLINE> return saver_lib . Saver ( <NEWLINE> var_list = named_saveable_objects , max_to_keep = None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def process_axes ( self , obj , columns = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if columns is not None : <NEWLINE> <TAB> columns = list ( columns ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if columns is not None and self . is_multi_index : <NEWLINE> <TAB> for n in self . levels : <NEWLINE> <TAB> if n not in columns : <NEWLINE> <TAB> columns . insert ( <NUMBER> , n ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> for axis , labels in self . non_index_axes : <NEWLINE> <TAB> obj = _reindex_axis ( obj , axis , labels , columns ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . selection . filter is not None : <NEWLINE> <TAB> for field , op , filt in self . selection . filter . format ( ) : <NEWLINE> <NEWLINE> <TAB> def process_filter ( field , filt ) : <NEWLINE> <NEWLINE> <TAB> for axis_name in obj . _AXIS_NAMES . values ( ) : <NEWLINE> <TAB> axis_number = obj . _get_axis_number ( axis_name ) <NEWLINE> axis_values = obj . _get_axis ( axis_name ) <NEWLINE> <NEWLINE> <NEWLINE> if field == axis_name : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if self . is_multi_index : <NEWLINE> <TAB> filt = filt . union ( Index ( self . levels ) ) <NEWLINE> <NEWLINE> <UNTAB> takers = op ( axis_values , filt ) <NEWLINE> return obj . loc . _getitem_axis ( takers , <NEWLINE> axis = axis_number ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif field in axis_values : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> values = _ensure_index ( getattr ( obj , field ) . values ) <NEWLINE> filt = _ensure_index ( filt ) <NEWLINE> <NEWLINE> <NEWLINE> if isinstance ( obj , DataFrame ) : <NEWLINE> <TAB> axis_number = <NUMBER> - axis_number <NEWLINE> <UNTAB> takers = op ( values , filt ) <NEWLINE> return obj . loc . _getitem_axis ( takers , <NEWLINE> axis = axis_number ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> raise ValueError ( <NEWLINE> <STRING> % field ) <NEWLINE> <NEWLINE> <UNTAB> obj = process_filter ( field , filt ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return obj <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_figure ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . figure <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _construct_axes_from_arguments ( self , args , kwargs , require_all = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> args = list ( args ) <NEWLINE> for a in self . _AXIS_ORDERS : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> alias = self . _AXIS_IALIASES . get ( a ) <NEWLINE> if alias is not None : <NEWLINE> <TAB> if a in kwargs : <NEWLINE> <TAB> if alias in kwargs : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> % ( a , alias ) ) <NEWLINE> <UNTAB> continue <NEWLINE> <UNTAB> if alias in kwargs : <NEWLINE> <TAB> kwargs [ a ] = kwargs . pop ( alias ) <NEWLINE> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if a not in kwargs : <NEWLINE> <TAB> try : <NEWLINE> <TAB> kwargs [ a ] = args . pop ( <NUMBER> ) <NEWLINE> <UNTAB> except IndexError : <NEWLINE> <TAB> if require_all : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> axes = { a : kwargs . pop ( a , None ) for a in self . _AXIS_ORDERS } <NEWLINE> return axes , kwargs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def argmax_crf1d ( cost , xs ) : <NEWLINE> <TAB> <NEWLINE> alpha = xs [ <NUMBER> ] <NEWLINE> alphas = [ ] <NEWLINE> max_inds = [ ] <NEWLINE> for x in xs [ <NUMBER> : ] : <NEWLINE> <TAB> batch = x . shape [ <NUMBER> ] <NEWLINE> if alpha . shape [ <NUMBER> ] > batch : <NEWLINE> <TAB> alpha , alpha_rest = split_axis . split_axis ( alpha , [ batch ] , axis = <NUMBER> ) <NEWLINE> alphas . append ( alpha_rest ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> alphas . append ( None ) <NEWLINE> <UNTAB> b_alpha , b_cost = broadcast . broadcast ( alpha [ ... , None ] , cost ) <NEWLINE> scores = b_alpha + b_cost <NEWLINE> max_ind = minmax . argmax ( scores , axis = <NUMBER> ) <NEWLINE> max_inds . append ( max_ind ) <NEWLINE> alpha = minmax . max ( scores , axis = <NUMBER> ) + x <NEWLINE> <NEWLINE> <UNTAB> inds = minmax . argmax ( alpha , axis = <NUMBER> ) <NEWLINE> path = [ inds . data ] <NEWLINE> for m , a in zip ( max_inds [ : : - <NUMBER> ] , alphas [ : : - <NUMBER> ] ) : <NEWLINE> <TAB> inds = select_item . select_item ( m , inds ) <NEWLINE> if a is not None : <NEWLINE> <TAB> inds = concat . concat ( [ inds , minmax . argmax ( a , axis = <NUMBER> ) ] , axis = <NUMBER> ) <NEWLINE> <UNTAB> path . append ( inds . data ) <NEWLINE> <UNTAB> path . reverse ( ) <NEWLINE> <NEWLINE> score = minmax . max ( alpha , axis = <NUMBER> ) <NEWLINE> for a in alphas [ : : - <NUMBER> ] : <NEWLINE> <TAB> if a is None : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> score = concat . concat ( [ score , minmax . max ( a , axis = <NUMBER> ) ] , axis = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> return score , path <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rs_cos_sin ( p , x , prec ) : <NEWLINE> <TAB> <NEWLINE> if rs_is_puiseux ( p , x ) : <NEWLINE> <TAB> return rs_puiseux ( rs_cos_sin , p , x , prec ) <NEWLINE> <UNTAB> t = rs_tan ( p / <NUMBER> , x , prec ) <NEWLINE> t2 = rs_square ( t , x , prec ) <NEWLINE> p1 = rs_series_inversion ( <NUMBER> + t2 , x , prec ) <NEWLINE> return ( rs_mul ( p1 , <NUMBER> - t2 , x , prec ) , rs_mul ( p1 , <NUMBER> * t , x , prec ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def grad ( self , inp , cost_grad ) : <NEWLINE> <TAB> <NEWLINE> a , val = inp <NEWLINE> grad = cost_grad [ <NUMBER> ] <NEWLINE> if ( a . dtype . startswith ( <STRING> ) ) : <NEWLINE> <TAB> return [ None , None ] <NEWLINE> <UNTAB> elif a . ndim > <NUMBER> : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> <NEWLINE> <STRING> % <NEWLINE> self . __class__ . __name__ ) <NEWLINE> <UNTAB> wr_a = fill_diagonal ( grad , <NUMBER> ) <NEWLINE> <NEWLINE> wr_val = theano . tensor . nlinalg . diag ( grad ) . sum ( ) <NEWLINE> return [ wr_a , wr_val ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def as_common_dtype ( in1 , in2 ) : <NEWLINE> <TAB> <NEWLINE> dtype = theano . scalar . upcast ( in1 . dtype , in2 . dtype ) <NEWLINE> return in1 . astype ( dtype ) , in2 . astype ( dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _compute_covariance ( self ) : <NEWLINE> <TAB> <NEWLINE> self . factor = self . covariance_factor ( ) <NEWLINE> <NEWLINE> if not hasattr ( self , <STRING> ) : <NEWLINE> <TAB> self . _data_covariance = atleast_2d ( np . cov ( self . dataset , rowvar = <NUMBER> , <NEWLINE> bias = False ) ) <NEWLINE> self . _data_inv_cov = linalg . inv ( self . _data_covariance ) <NEWLINE> <NEWLINE> <UNTAB> self . covariance = self . _data_covariance * self . factor ** <NUMBER> <NEWLINE> self . inv_cov = self . _data_inv_cov / self . factor ** <NUMBER> <NEWLINE> self . _norm_factor = sqrt ( linalg . det ( <NUMBER> * pi * self . covariance ) ) * self . n <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def override_from_dict ( self , values_dict ) : <NEWLINE> <TAB> <NEWLINE> for name , value in values_dict . items ( ) : <NEWLINE> <TAB> self . set_hparam ( name , value ) <NEWLINE> <UNTAB> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , filenames , compression_type = None , buffer_size = None ) : <NEWLINE> <TAB> <NEWLINE> super ( TextLineDataset , self ) . __init__ ( ) <NEWLINE> self . _filenames = ops . convert_to_tensor ( <NEWLINE> filenames , dtype = dtypes . string , name = <STRING> ) <NEWLINE> self . _compression_type = convert . optional_param_to_tensor ( <NEWLINE> <STRING> , <NEWLINE> compression_type , <NEWLINE> argument_default = <STRING> , <NEWLINE> argument_dtype = dtypes . string ) <NEWLINE> self . _buffer_size = convert . optional_param_to_tensor ( <NEWLINE> <STRING> , buffer_size , _DEFAULT_READER_BUFFER_SIZE_BYTES ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit ( self , X , y , sample_weight = None ) : <NEWLINE> <TAB> <NEWLINE> X , y = check_X_y ( X , y , dtype = np . float64 , y_numeric = True ) <NEWLINE> X , y , X_offset_ , y_offset_ , X_scale_ = self . _preprocess_data ( <NEWLINE> X , y , self . fit_intercept , self . normalize , self . copy_X , <NEWLINE> sample_weight = sample_weight ) <NEWLINE> <NEWLINE> if sample_weight is not None : <NEWLINE> <NEWLINE> <TAB> X , y = _rescale_data ( X , y , sample_weight ) <NEWLINE> <NEWLINE> <UNTAB> self . X_offset_ = X_offset_ <NEWLINE> self . X_scale_ = X_scale_ <NEWLINE> n_samples , n_features = X . shape <NEWLINE> <NEWLINE> <NEWLINE> eps = np . finfo ( np . float64 ) . eps <NEWLINE> <NEWLINE> <NEWLINE> alpha_ = <NUMBER> / ( np . var ( y ) + eps ) <NEWLINE> lambda_ = <NUMBER> <NEWLINE> <NEWLINE> verbose = self . verbose <NEWLINE> lambda_1 = self . lambda_1 <NEWLINE> lambda_2 = self . lambda_2 <NEWLINE> alpha_1 = self . alpha_1 <NEWLINE> alpha_2 = self . alpha_2 <NEWLINE> <NEWLINE> self . scores_ = list ( ) <NEWLINE> coef_old_ = None <NEWLINE> <NEWLINE> XT_y = np . dot ( X . T , y ) <NEWLINE> U , S , Vh = linalg . svd ( X , full_matrices = False ) <NEWLINE> eigen_vals_ = S ** <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> for iter_ in range ( self . n_iter ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if n_samples > n_features : <NEWLINE> <TAB> coef_ = np . dot ( Vh . T , <NEWLINE> Vh / ( eigen_vals_ + <NEWLINE> lambda_ / alpha_ ) [ : , np . newaxis ] ) <NEWLINE> coef_ = np . dot ( coef_ , XT_y ) <NEWLINE> if self . compute_score : <NEWLINE> <TAB> logdet_sigma_ = - np . sum ( <NEWLINE> np . log ( lambda_ + alpha_ * eigen_vals_ ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> coef_ = np . dot ( X . T , np . dot ( <NEWLINE> U / ( eigen_vals_ + lambda_ / alpha_ ) [ None , : ] , U . T ) ) <NEWLINE> coef_ = np . dot ( coef_ , y ) <NEWLINE> if self . compute_score : <NEWLINE> <TAB> logdet_sigma_ = np . full ( n_features , lambda_ , <NEWLINE> dtype = np . array ( lambda_ ) . dtype ) <NEWLINE> logdet_sigma_ [ : n_samples ] += alpha_ * eigen_vals_ <NEWLINE> logdet_sigma_ = - np . sum ( np . log ( logdet_sigma_ ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . alpha_ = alpha_ <NEWLINE> self . lambda_ = lambda_ <NEWLINE> <NEWLINE> <NEWLINE> rmse_ = np . sum ( ( y - np . dot ( X , coef_ ) ) ** <NUMBER> ) <NEWLINE> gamma_ = ( np . sum ( ( alpha_ * eigen_vals_ ) / <NEWLINE> ( lambda_ + alpha_ * eigen_vals_ ) ) ) <NEWLINE> lambda_ = ( ( gamma_ + <NUMBER> * lambda_1 ) / <NEWLINE> ( np . sum ( coef_ ** <NUMBER> ) + <NUMBER> * lambda_2 ) ) <NEWLINE> alpha_ = ( ( n_samples - gamma_ + <NUMBER> * alpha_1 ) / <NEWLINE> ( rmse_ + <NUMBER> * alpha_2 ) ) <NEWLINE> <NEWLINE> <NEWLINE> if self . compute_score : <NEWLINE> <TAB> s = lambda_1 * log ( lambda_ ) - lambda_2 * lambda_ <NEWLINE> s += alpha_1 * log ( alpha_ ) - alpha_2 * alpha_ <NEWLINE> s += <NUMBER> * ( n_features * log ( lambda_ ) + <NEWLINE> n_samples * log ( alpha_ ) - <NEWLINE> alpha_ * rmse_ - <NEWLINE> ( lambda_ * np . sum ( coef_ ** <NUMBER> ) ) - <NEWLINE> logdet_sigma_ - <NEWLINE> n_samples * log ( <NUMBER> * np . pi ) ) <NEWLINE> self . scores_ . append ( s ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if iter_ != <NUMBER> and np . sum ( np . abs ( coef_old_ - coef_ ) ) < self . tol : <NEWLINE> <TAB> if verbose : <NEWLINE> <TAB> print ( <STRING> , str ( iter_ ) , <STRING> ) <NEWLINE> <UNTAB> break <NEWLINE> <UNTAB> coef_old_ = np . copy ( coef_ ) <NEWLINE> <NEWLINE> <UNTAB> self . coef_ = coef_ <NEWLINE> sigma_ = np . dot ( Vh . T , <NEWLINE> Vh / ( eigen_vals_ + lambda_ / alpha_ ) [ : , np . newaxis ] ) <NEWLINE> self . sigma_ = ( <NUMBER> / alpha_ ) * sigma_ <NEWLINE> <NEWLINE> self . _set_intercept ( X_offset_ , y_offset_ , X_scale_ ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _maybe_coerce_indexer ( self , indexer ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( indexer , np . ndarray ) and indexer . dtype . kind == <STRING> : <NEWLINE> <TAB> indexer = indexer . astype ( self . _codes . dtype ) <NEWLINE> <UNTAB> return indexer <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def laguerre ( n , monic = False ) : <NEWLINE> <TAB> <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if n == <NUMBER> : <NEWLINE> <TAB> n1 = n + <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> n1 = n <NEWLINE> <UNTAB> x , w , mu0 = roots_laguerre ( n1 , mu = True ) <NEWLINE> if n == <NUMBER> : <NEWLINE> <TAB> x , w = [ ] , [ ] <NEWLINE> <UNTAB> hn = <NUMBER> <NEWLINE> kn = ( - <NUMBER> ) ** n / _gam ( n + <NUMBER> ) <NEWLINE> p = orthopoly1d ( x , w , hn , kn , lambda x : exp ( - x ) , ( <NUMBER> , inf ) , monic , <NEWLINE> lambda x : eval_laguerre ( n , x ) ) <NEWLINE> return p <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def sin ( x ) : <NEWLINE> <TAB> <NEWLINE> return math_ops . sin ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def postorder_traversal ( node , keys = None ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( node , Basic ) : <NEWLINE> <TAB> args = node . args <NEWLINE> if keys : <NEWLINE> <TAB> if keys != True : <NEWLINE> <TAB> args = ordered ( args , keys , default = False ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> args = ordered ( args ) <NEWLINE> <UNTAB> <UNTAB> for arg in args : <NEWLINE> <TAB> for subtree in postorder_traversal ( arg , keys ) : <NEWLINE> <TAB> yield subtree <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif iterable ( node ) : <NEWLINE> <TAB> for item in node : <NEWLINE> <TAB> for subtree in postorder_traversal ( item , keys ) : <NEWLINE> <TAB> yield subtree <NEWLINE> <UNTAB> <UNTAB> <UNTAB> yield node <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _gather_saveables_for_checkpoint ( self ) : <NEWLINE> <TAB> <NEWLINE> return { <STRING> : functools . partial ( MutableHashTable . _Saveable , table = self ) } <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _execcmd ( self , cmdstr ) : <NEWLINE> <TAB> <NEWLINE> frame = self . parent_frame <NEWLINE> try : <NEWLINE> <TAB> exec ( cmdstr , frame . f_globals , frame . f_locals ) <NEWLINE> <UNTAB> except Exception as msg : <NEWLINE> <TAB> self . error ( <STRING> % ( cmdstr , msg ) ) <NEWLINE> return True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . log ( <STRING> % ( cmdstr ) ) <NEWLINE> <UNTAB> return <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __array_wrap__ ( self , obj , context = None ) : <NEWLINE> <TAB> <NEWLINE> if obj is self : <NEWLINE> <TAB> result = obj <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result = obj . view ( type ( self ) ) <NEWLINE> result . _update_from ( self ) <NEWLINE> <NEWLINE> <UNTAB> if context is not None : <NEWLINE> <TAB> result . _mask = result . _mask . copy ( ) <NEWLINE> func , args , out_i = context <NEWLINE> <NEWLINE> input_args = args [ : func . nin ] <NEWLINE> m = reduce ( mask_or , [ getmaskarray ( arg ) for arg in input_args ] ) <NEWLINE> <NEWLINE> domain = ufunc_domain . get ( func , None ) <NEWLINE> if domain is not None : <NEWLINE> <NEWLINE> <TAB> if len ( input_args ) > <NUMBER> : <NEWLINE> <TAB> with np . errstate ( divide = <STRING> , invalid = <STRING> ) : <NEWLINE> <TAB> d = filled ( reduce ( domain , input_args ) , True ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> with np . errstate ( divide = <STRING> , invalid = <STRING> ) : <NEWLINE> <TAB> d = filled ( domain ( * input_args ) , True ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if d . any ( ) : <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <NEWLINE> <TAB> fill_value = ufunc_fills [ func ] [ - <NUMBER> ] <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <NEWLINE> <TAB> fill_value = ufunc_fills [ func ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <NEWLINE> <TAB> fill_value = self . fill_value <NEWLINE> <NEWLINE> <UNTAB> np . copyto ( result , fill_value , where = d ) <NEWLINE> <NEWLINE> <NEWLINE> if m is nomask : <NEWLINE> <TAB> m = d <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> m = ( m | d ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if result is not self and result . shape == ( ) and m : <NEWLINE> <TAB> return masked <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result . _mask = m <NEWLINE> result . _sharedmask = False <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ contextlib . contextmanager <NEWLINE> def scope ( self , observation ) : <NEWLINE> <TAB> <NEWLINE> old = self . observation <NEWLINE> self . observation = observation <NEWLINE> self . __enter__ ( ) <NEWLINE> yield <NEWLINE> self . __exit__ ( None , None , None ) <NEWLINE> self . observation = old <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_ring ( f ) : <NEWLINE> <TAB> <NEWLINE> return f . convert ( f . dom . get_ring ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def square ( x , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ x ] ) as name : <NEWLINE> <TAB> if isinstance ( x , sparse_tensor . SparseTensor ) : <NEWLINE> <TAB> x_square = gen_math_ops . square ( x . values , name = name ) <NEWLINE> return sparse_tensor . SparseTensor ( <NEWLINE> indices = x . indices , values = x_square , dense_shape = x . dense_shape ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return gen_math_ops . square ( x , name = name ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def insert ( self , key , value , allow_increase = False ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def perpendicular_line ( self , p ) : <NEWLINE> <TAB> <NEWLINE> p = Point ( p , dim = self . ambient_dimension ) <NEWLINE> if p in self : <NEWLINE> <TAB> p = p + self . direction . orthogonal_direction <NEWLINE> <UNTAB> return Line ( p , self . projection ( p ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _check_xy ( self , renderer , xy_pixel ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> b = self . get_annotation_clip ( ) <NEWLINE> <NEWLINE> if b or ( b is None and self . xycoords == <STRING> ) : <NEWLINE> <NEWLINE> <TAB> if not self . axes . contains_point ( xy_pixel ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def to_agraph ( N ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> import pygraphviz <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> raise ImportError ( <STRING> , <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> directed = N . is_directed ( ) <NEWLINE> strict = nx . number_of_selfloops ( N ) == <NUMBER> and not N . is_multigraph ( ) <NEWLINE> A = pygraphviz . AGraph ( name = N . name , strict = strict , directed = directed ) <NEWLINE> <NEWLINE> <NEWLINE> A . graph_attr . update ( N . graph . get ( <STRING> , { } ) ) <NEWLINE> A . node_attr . update ( N . graph . get ( <STRING> , { } ) ) <NEWLINE> A . edge_attr . update ( N . graph . get ( <STRING> , { } ) ) <NEWLINE> <NEWLINE> A . graph_attr . update ( ( k , v ) for k , v in N . graph . items ( ) <NEWLINE> if k not in ( <STRING> , <STRING> , <STRING> ) ) <NEWLINE> <NEWLINE> <NEWLINE> for n , nodedata in N . nodes ( data = True ) : <NEWLINE> <TAB> A . add_node ( n ) <NEWLINE> if nodedata is not None : <NEWLINE> <TAB> a = A . get_node ( n ) <NEWLINE> a . attr . update ( { k : str ( v ) for k , v in nodedata . items ( ) } ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if N . is_multigraph ( ) : <NEWLINE> <TAB> for u , v , key , edgedata in N . edges ( data = True , keys = True ) : <NEWLINE> <TAB> str_edgedata = { k : str ( v ) for k , v in edgedata . items ( ) <NEWLINE> if k != <STRING> } <NEWLINE> A . add_edge ( u , v , key = str ( key ) ) <NEWLINE> if edgedata is not None : <NEWLINE> <TAB> a = A . get_edge ( u , v ) <NEWLINE> a . attr . update ( str_edgedata ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for u , v , edgedata in N . edges ( data = True ) : <NEWLINE> <TAB> str_edgedata = { k : str ( v ) for k , v in edgedata . items ( ) } <NEWLINE> A . add_edge ( u , v ) <NEWLINE> if edgedata is not None : <NEWLINE> <TAB> a = A . get_edge ( u , v ) <NEWLINE> a . attr . update ( str_edgedata ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return A <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _multinomial_loss ( w , X , Y , alpha , sample_weight ) : <NEWLINE> <TAB> <NEWLINE> n_classes = Y . shape [ <NUMBER> ] <NEWLINE> n_features = X . shape [ <NUMBER> ] <NEWLINE> fit_intercept = w . size == ( n_classes * ( n_features + <NUMBER> ) ) <NEWLINE> w = w . reshape ( n_classes , - <NUMBER> ) <NEWLINE> sample_weight = sample_weight [ : , np . newaxis ] <NEWLINE> if fit_intercept : <NEWLINE> <TAB> intercept = w [ : , - <NUMBER> ] <NEWLINE> w = w [ : , : - <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> intercept = <NUMBER> <NEWLINE> <UNTAB> p = safe_sparse_dot ( X , w . T ) <NEWLINE> p += intercept <NEWLINE> p -= logsumexp ( p , axis = <NUMBER> ) [ : , np . newaxis ] <NEWLINE> loss = - ( sample_weight * Y * p ) . sum ( ) <NEWLINE> loss += <NUMBER> * alpha * squared_norm ( w ) <NEWLINE> p = np . exp ( p , p ) <NEWLINE> return loss , p , w <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( None , <STRING> ) <NEWLINE> def extract_pandas_labels ( labels ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( labels , <NEWLINE> pd . DataFrame ) : <NEWLINE> <TAB> if len ( labels . columns ) > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> bad_data = [ column for column in labels <NEWLINE> if labels [ column ] . dtype . name not in PANDAS_DTYPES ] <NEWLINE> if not bad_data : <NEWLINE> <TAB> return labels . values <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> error_report = [ <STRING> + str ( column ) + <STRING> <NEWLINE> + str ( labels [ column ] . dtype . name ) for column in bad_data ] <NEWLINE> raise ValueError ( <STRING> <NEWLINE> <STRING> + <STRING> . join ( error_report ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return labels <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fdiff ( self , argindex = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if argindex == <NUMBER> : <NEWLINE> <TAB> return - coth ( self . args [ <NUMBER> ] ) * csch ( self . args [ <NUMBER> ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ArgumentIndexError ( self , argindex ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _convert_to_border ( cls , border_dict ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> from openpyxl . styles import Border <NEWLINE> <NEWLINE> _border_key_map = { <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> } <NEWLINE> <NEWLINE> border_kwargs = { } <NEWLINE> for k , v in border_dict . items ( ) : <NEWLINE> <TAB> if k in _border_key_map : <NEWLINE> <TAB> k = _border_key_map [ k ] <NEWLINE> <UNTAB> if k == <STRING> : <NEWLINE> <TAB> v = cls . _convert_to_color ( v ) <NEWLINE> <UNTAB> if k in [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> v = cls . _convert_to_side ( v ) <NEWLINE> <UNTAB> border_kwargs [ k ] = v <NEWLINE> <NEWLINE> <UNTAB> return Border ( ** border_kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ contextlib . contextmanager <NEWLINE> def _read_fileobject ( fileobj , filename , mmap_mode = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> compressor = _detect_compressor ( fileobj ) <NEWLINE> <NEWLINE> if compressor == <STRING> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % filename , <NEWLINE> DeprecationWarning , stacklevel = <NUMBER> ) <NEWLINE> yield filename <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if compressor in _COMPRESSORS : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> compressor_wrapper = _COMPRESSORS [ compressor ] <NEWLINE> inst = compressor_wrapper . decompressor_file ( fileobj ) <NEWLINE> fileobj = _buffered_read_file ( inst ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if mmap_mode is not None : <NEWLINE> <TAB> if isinstance ( fileobj , io . BytesIO ) : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> % locals ( ) , stacklevel = <NUMBER> ) <NEWLINE> <UNTAB> elif compressor != <STRING> : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> % locals ( ) , stacklevel = <NUMBER> ) <NEWLINE> <UNTAB> elif not _is_raw_file ( fileobj ) : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> % locals ( ) , stacklevel = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> yield fileobj <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def clear ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _pos = - <NUMBER> <NEWLINE> self . _elements = [ ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def validate_read ( self , kwargs ) : <NEWLINE> <TAB> <NEWLINE> kwargs = copy . copy ( kwargs ) <NEWLINE> <NEWLINE> columns = kwargs . pop ( <STRING> , None ) <NEWLINE> if columns is not None : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> where = kwargs . pop ( <STRING> , None ) <NEWLINE> if where is not None : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> return kwargs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def from_product ( cls , iterables , sortorder = None , names = None ) : <NEWLINE> <TAB> <NEWLINE> from pandas . core . arrays . categorical import _factorize_from_iterables <NEWLINE> from pandas . core . reshape . util import cartesian_product <NEWLINE> <NEWLINE> if not is_list_like ( iterables ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> elif is_iterator ( iterables ) : <NEWLINE> <TAB> iterables = list ( iterables ) <NEWLINE> <NEWLINE> <UNTAB> labels , levels = _factorize_from_iterables ( iterables ) <NEWLINE> labels = cartesian_product ( labels ) <NEWLINE> return MultiIndex ( levels , labels , sortorder = sortorder , names = names ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def union ( self , other ) : <NEWLINE> <TAB> <NEWLINE> self . _assert_can_do_setop ( other ) <NEWLINE> if not isinstance ( other , TimedeltaIndex ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> other = TimedeltaIndex ( other ) <NEWLINE> <UNTAB> except ( TypeError , ValueError ) : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> this , other = self , other <NEWLINE> <NEWLINE> if this . _can_fast_union ( other ) : <NEWLINE> <TAB> return this . _fast_union ( other ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result = Index . union ( this , other ) <NEWLINE> if isinstance ( result , TimedeltaIndex ) : <NEWLINE> <TAB> if result . freq is None : <NEWLINE> <TAB> result . freq = to_offset ( result . inferred_freq ) <NEWLINE> <UNTAB> <UNTAB> return result <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> def _weighted_triangles_and_degree_iter ( G , nodes = None , weight = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if weight is None or G . number_of_edges ( ) == <NUMBER> : <NEWLINE> <TAB> max_weight = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> max_weight = max ( d . get ( weight , <NUMBER> ) for u , v , d in G . edges ( data = True ) ) <NEWLINE> <UNTAB> if nodes is None : <NEWLINE> <TAB> nodes_nbrs = G . adj . items ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nodes_nbrs = ( ( n , G [ n ] ) for n in G . nbunch_iter ( nodes ) ) <NEWLINE> <NEWLINE> <UNTAB> def wt ( u , v ) : <NEWLINE> <TAB> return G [ u ] [ v ] . get ( weight , <NUMBER> ) / max_weight <NEWLINE> <NEWLINE> <UNTAB> for i , nbrs in nodes_nbrs : <NEWLINE> <TAB> inbrs = set ( nbrs ) - { i } <NEWLINE> weighted_triangles = <NUMBER> <NEWLINE> seen = set ( ) <NEWLINE> for j in inbrs : <NEWLINE> <TAB> seen . add ( j ) <NEWLINE> <NEWLINE> jnbrs = set ( G [ j ] ) - seen <NEWLINE> <NEWLINE> <NEWLINE> wij = wt ( i , j ) <NEWLINE> weighted_triangles += sum ( ( wij * wt ( j , k ) * wt ( k , i ) ) ** ( <NUMBER> / <NUMBER> ) <NEWLINE> for k in inbrs & jnbrs ) <NEWLINE> <UNTAB> yield ( i , len ( inbrs ) , <NUMBER> * weighted_triangles ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_sorted_table_and_fkc_names ( self , schema = None ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( self . dialect , <STRING> ) : <NEWLINE> <TAB> tnames = self . dialect . get_table_names ( <NEWLINE> self . bind , schema , info_cache = self . info_cache ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> tnames = self . engine . table_names ( schema ) <NEWLINE> <NEWLINE> <UNTAB> tuples = set ( ) <NEWLINE> remaining_fkcs = set ( ) <NEWLINE> <NEWLINE> fknames_for_table = { } <NEWLINE> for tname in tnames : <NEWLINE> <TAB> fkeys = self . get_foreign_keys ( tname , schema ) <NEWLINE> fknames_for_table [ tname ] = set ( <NEWLINE> [ fk [ <STRING> ] for fk in fkeys ] <NEWLINE> ) <NEWLINE> for fkey in fkeys : <NEWLINE> <TAB> if tname != fkey [ <STRING> ] : <NEWLINE> <TAB> tuples . add ( ( fkey [ <STRING> ] , tname ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> try : <NEWLINE> <TAB> candidate_sort = list ( topological . sort ( tuples , tnames ) ) <NEWLINE> <UNTAB> except exc . CircularDependencyError as err : <NEWLINE> <TAB> for edge in err . edges : <NEWLINE> <TAB> tuples . remove ( edge ) <NEWLINE> remaining_fkcs . update ( <NEWLINE> ( edge [ <NUMBER> ] , fkc ) <NEWLINE> for fkc in fknames_for_table [ edge [ <NUMBER> ] ] <NEWLINE> ) <NEWLINE> <NEWLINE> <UNTAB> candidate_sort = list ( topological . sort ( tuples , tnames ) ) <NEWLINE> <UNTAB> return [ <NEWLINE> ( tname , fknames_for_table [ tname ] . difference ( remaining_fkcs ) ) <NEWLINE> for tname in candidate_sort <NEWLINE> ] + [ ( None , list ( remaining_fkcs ) ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def erfc_eager_fallback ( x , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , ( x , ) = _execute . args_to_matching_eager ( [ x ] , _ctx ) <NEWLINE> _inputs_flat = [ x ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _leading_trailing ( a , edgeitems , index = ( ) ) : <NEWLINE> <TAB> <NEWLINE> axis = len ( index ) <NEWLINE> if axis == a . ndim : <NEWLINE> <TAB> return a [ index ] <NEWLINE> <NEWLINE> <UNTAB> if a . shape [ axis ] > <NUMBER> * edgeitems : <NEWLINE> <TAB> return concatenate ( ( <NEWLINE> _leading_trailing ( a , edgeitems , index + np . index_exp [ : edgeitems ] ) , <NEWLINE> _leading_trailing ( a , edgeitems , index + np . index_exp [ - edgeitems : ] ) <NEWLINE> ) , axis = axis ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _leading_trailing ( a , edgeitems , index + np . index_exp [ : ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def bool ( self ) : <NEWLINE> <TAB> <NEWLINE> v = self . squeeze ( ) <NEWLINE> if isinstance ( v , ( bool , np . bool_ ) ) : <NEWLINE> <TAB> return bool ( v ) <NEWLINE> <UNTAB> elif is_scalar ( v ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( self . __class__ . __name__ ) ) <NEWLINE> <NEWLINE> <UNTAB> self . __nonzero__ ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _as_float_array ( x , check_finite = False ) : <NEWLINE> <TAB> <NEWLINE> x = np . ascontiguousarray ( x ) <NEWLINE> dtyp = _get_dtype ( x . dtype ) <NEWLINE> x = x . astype ( dtyp , copy = False ) <NEWLINE> if check_finite and not np . isfinite ( x ) . all ( ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return x <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def unregularized_loss ( self , examples ) : <NEWLINE> <TAB> <NEWLINE> self . _assertSpecified ( [ <NEWLINE> <STRING> , <STRING> , <STRING> , <STRING> <NEWLINE> ] , examples ) <NEWLINE> self . _assertList ( [ <STRING> , <STRING> ] , examples ) <NEWLINE> with name_scope ( <STRING> ) : <NEWLINE> <TAB> predictions = math_ops . cast ( <NEWLINE> self . _linear_predictions ( examples ) , dtypes . float64 ) <NEWLINE> labels = math_ops . cast ( <NEWLINE> internal_convert_to_tensor ( examples [ <STRING> ] ) , <NEWLINE> dtypes . float64 ) <NEWLINE> weights = math_ops . cast ( <NEWLINE> internal_convert_to_tensor ( examples [ <STRING> ] ) , <NEWLINE> dtypes . float64 ) <NEWLINE> <NEWLINE> if self . _options [ <STRING> ] == <STRING> : <NEWLINE> <TAB> return math_ops . reduce_sum ( math_ops . multiply ( <NEWLINE> sigmoid_cross_entropy_with_logits ( labels = labels , <NEWLINE> logits = predictions ) , <NEWLINE> weights ) ) / math_ops . reduce_sum ( weights ) <NEWLINE> <NEWLINE> <UNTAB> if self . _options [ <STRING> ] == <STRING> : <NEWLINE> <TAB> return math_ops . reduce_sum ( math_ops . multiply ( <NEWLINE> log_poisson_loss ( targets = labels , log_input = predictions ) , <NEWLINE> weights ) ) / math_ops . reduce_sum ( weights ) <NEWLINE> <NEWLINE> <UNTAB> if self . _options [ <STRING> ] in [ <STRING> , <STRING> ] : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> all_ones = array_ops . ones_like ( predictions ) <NEWLINE> adjusted_labels = math_ops . subtract ( <NUMBER> * labels , all_ones ) <NEWLINE> <NEWLINE> <NEWLINE> error = nn_ops . relu ( <NEWLINE> math_ops . subtract ( all_ones , <NEWLINE> math_ops . multiply ( adjusted_labels , predictions ) ) ) <NEWLINE> weighted_error = math_ops . multiply ( error , weights ) <NEWLINE> return math_ops . reduce_sum ( weighted_error ) / math_ops . reduce_sum ( <NEWLINE> weights ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> err = math_ops . subtract ( labels , predictions ) <NEWLINE> <NEWLINE> weighted_squared_err = math_ops . multiply ( math_ops . square ( err ) , weights ) <NEWLINE> <NEWLINE> return ( math_ops . reduce_sum ( weighted_squared_err ) / <NEWLINE> ( <NUMBER> * math_ops . reduce_sum ( weights ) ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_integrator ( u , v , dmap , minlength , maxlength , integration_direction ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> u , v = dmap . data2grid ( u , v ) <NEWLINE> <NEWLINE> <NEWLINE> u_ax = u / dmap . grid . nx <NEWLINE> v_ax = v / dmap . grid . ny <NEWLINE> speed = np . ma . sqrt ( u_ax ** <NUMBER> + v_ax ** <NUMBER> ) <NEWLINE> <NEWLINE> def forward_time ( xi , yi ) : <NEWLINE> <TAB> ds_dt = interpgrid ( speed , xi , yi ) <NEWLINE> if ds_dt == <NUMBER> : <NEWLINE> <TAB> raise TerminateTrajectory ( ) <NEWLINE> <UNTAB> dt_ds = <NUMBER> / ds_dt <NEWLINE> ui = interpgrid ( u , xi , yi ) <NEWLINE> vi = interpgrid ( v , xi , yi ) <NEWLINE> return ui * dt_ds , vi * dt_ds <NEWLINE> <NEWLINE> <UNTAB> def backward_time ( xi , yi ) : <NEWLINE> <TAB> dxi , dyi = forward_time ( xi , yi ) <NEWLINE> return - dxi , - dyi <NEWLINE> <NEWLINE> <UNTAB> def integrate ( x0 , y0 ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> stotal , x_traj , y_traj = <NUMBER> , [ ] , [ ] <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> dmap . start_trajectory ( x0 , y0 ) <NEWLINE> <UNTAB> except InvalidIndexError : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> if integration_direction in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> s , xt , yt = _integrate_rk12 ( x0 , y0 , dmap , backward_time , maxlength ) <NEWLINE> stotal += s <NEWLINE> x_traj += xt [ : : - <NUMBER> ] <NEWLINE> y_traj += yt [ : : - <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> if integration_direction in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> dmap . reset_start_point ( x0 , y0 ) <NEWLINE> s , xt , yt = _integrate_rk12 ( x0 , y0 , dmap , forward_time , maxlength ) <NEWLINE> if len ( x_traj ) > <NUMBER> : <NEWLINE> <TAB> xt = xt [ <NUMBER> : ] <NEWLINE> yt = yt [ <NUMBER> : ] <NEWLINE> <UNTAB> stotal += s <NEWLINE> x_traj += xt <NEWLINE> y_traj += yt <NEWLINE> <NEWLINE> <UNTAB> if stotal > minlength : <NEWLINE> <TAB> return x_traj , y_traj <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dmap . undo_trajectory ( ) <NEWLINE> return None <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return integrate <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _compute_tri_eccentricities ( tris_pts ) : <NEWLINE> <TAB> <NEWLINE> a = np . expand_dims ( tris_pts [ : , <NUMBER> , : ] - tris_pts [ : , <NUMBER> , : ] , axis = <NUMBER> ) <NEWLINE> b = np . expand_dims ( tris_pts [ : , <NUMBER> , : ] - tris_pts [ : , <NUMBER> , : ] , axis = <NUMBER> ) <NEWLINE> c = np . expand_dims ( tris_pts [ : , <NUMBER> , : ] - tris_pts [ : , <NUMBER> , : ] , axis = <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> dot_a = _prod_vectorized ( _transpose_vectorized ( a ) , a ) [ : , <NUMBER> , <NUMBER> ] <NEWLINE> dot_b = _prod_vectorized ( _transpose_vectorized ( b ) , b ) [ : , <NUMBER> , <NUMBER> ] <NEWLINE> dot_c = _prod_vectorized ( _transpose_vectorized ( c ) , c ) [ : , <NUMBER> , <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> return _to_matrix_vectorized ( [ [ ( dot_c - dot_b ) / dot_a ] , <NEWLINE> [ ( dot_a - dot_c ) / dot_b ] , <NEWLINE> [ ( dot_b - dot_a ) / dot_c ] ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def transform_tree ( tree , fn , iterable_type = tuple ) : <NEWLINE> <TAB> <NEWLINE> if is_iterable ( tree ) : <NEWLINE> <TAB> if isinstance ( tree , dict ) : <NEWLINE> <TAB> res = tree . __new__ ( type ( tree ) ) <NEWLINE> res . __init__ ( <NEWLINE> ( k , transform_tree ( child , fn ) ) for k , child in iteritems ( tree ) ) <NEWLINE> return res <NEWLINE> <UNTAB> elif isinstance ( tree , tuple ) : <NEWLINE> <NEWLINE> <TAB> if hasattr ( tree , <STRING> ) : <NEWLINE> <TAB> res = tree . __new__ ( type ( tree ) , ** transform_tree ( tree . _asdict ( ) , fn ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> res = tree . __new__ ( type ( tree ) , <NEWLINE> ( transform_tree ( child , fn ) for child in tree ) ) <NEWLINE> <UNTAB> return res <NEWLINE> <UNTAB> elif isinstance ( tree , collections . Sequence ) : <NEWLINE> <TAB> res = tree . __new__ ( type ( tree ) ) <NEWLINE> res . __init__ ( transform_tree ( child , fn ) for child in tree ) <NEWLINE> return res <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return iterable_type ( transform_tree ( child , fn ) for child in tree ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return fn ( tree ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def tensordot ( a , b , axes , name = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def _tensordot_reshape ( a , axes , flipped = False ) : <NEWLINE> <TAB> <NEWLINE> if a . get_shape ( ) . is_fully_defined ( ) and isinstance ( axes , ( list , tuple ) ) : <NEWLINE> <TAB> shape_a = a . get_shape ( ) . as_list ( ) <NEWLINE> axes = [ i if i >= <NUMBER> else i + len ( shape_a ) for i in axes ] <NEWLINE> free = [ i for i in xrange ( len ( shape_a ) ) if i not in axes ] <NEWLINE> free_dims = [ shape_a [ i ] for i in free ] <NEWLINE> prod_free = int ( np . prod ( [ shape_a [ i ] for i in free ] ) ) <NEWLINE> prod_axes = int ( np . prod ( [ shape_a [ i ] for i in axes ] ) ) <NEWLINE> perm = list ( axes ) + free if flipped else free + list ( axes ) <NEWLINE> new_shape = [ prod_axes , prod_free ] if flipped else [ prod_free , prod_axes ] <NEWLINE> reshaped_a = array_ops . reshape ( array_ops . transpose ( a , perm ) , new_shape ) <NEWLINE> return reshaped_a , free_dims , free_dims <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if a . get_shape ( ) . ndims is not None and isinstance ( axes , ( list , tuple ) ) : <NEWLINE> <TAB> shape_a = a . get_shape ( ) . as_list ( ) <NEWLINE> axes = [ i if i >= <NUMBER> else i + len ( shape_a ) for i in axes ] <NEWLINE> free = [ i for i in xrange ( len ( shape_a ) ) if i not in axes ] <NEWLINE> axes_dims = [ shape_a [ i ] for i in axes ] <NEWLINE> free_dims = [ shape_a [ i ] for i in free ] <NEWLINE> free_dims_static = free_dims <NEWLINE> axes = ops . convert_to_tensor ( axes , dtype = dtypes . int32 , name = <STRING> ) <NEWLINE> free = ops . convert_to_tensor ( free , dtype = dtypes . int32 , name = <STRING> ) <NEWLINE> shape_a = array_ops . shape ( a ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> free_dims_static = None <NEWLINE> shape_a = array_ops . shape ( a ) <NEWLINE> rank_a = array_ops . rank ( a ) <NEWLINE> axes = ops . convert_to_tensor ( axes , dtype = dtypes . int32 , name = <STRING> ) <NEWLINE> axes = array_ops . where ( axes >= <NUMBER> , axes , axes + rank_a ) <NEWLINE> free , _ = array_ops . setdiff1d ( range ( rank_a ) , axes ) <NEWLINE> <UNTAB> free_dims = array_ops . gather ( shape_a , free ) <NEWLINE> axes_dims = array_ops . gather ( shape_a , axes ) <NEWLINE> prod_free_dims = reduce_prod ( free_dims ) <NEWLINE> prod_axes_dims = reduce_prod ( axes_dims ) <NEWLINE> if flipped : <NEWLINE> <TAB> perm = array_ops . concat ( [ axes , free ] , <NUMBER> ) <NEWLINE> new_shape = array_ops . stack ( [ prod_axes_dims , prod_free_dims ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> perm = array_ops . concat ( [ free , axes ] , <NUMBER> ) <NEWLINE> new_shape = array_ops . stack ( [ prod_free_dims , prod_axes_dims ] ) <NEWLINE> <UNTAB> reshaped_a = array_ops . reshape ( array_ops . transpose ( a , perm ) , new_shape ) <NEWLINE> return reshaped_a , free_dims , free_dims_static <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def _tensordot_axes ( a , axes ) : <NEWLINE> <TAB> <NEWLINE> a_shape = a . get_shape ( ) <NEWLINE> if isinstance ( axes , compat . integral_types ) : <NEWLINE> <TAB> if axes < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if a_shape . ndims is not None : <NEWLINE> <TAB> if axes > a_shape . ndims : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % a ) <NEWLINE> <UNTAB> return ( list ( xrange ( a_shape . ndims - axes , a_shape . ndims ) ) , <NEWLINE> list ( xrange ( axes ) ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rank = array_ops . rank ( a ) <NEWLINE> return ( range ( rank - axes , rank , dtype = dtypes . int32 ) , <NEWLINE> range ( axes , dtype = dtypes . int32 ) ) <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( axes , ( list , tuple ) ) : <NEWLINE> <TAB> if len ( axes ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> a_axes = axes [ <NUMBER> ] <NEWLINE> b_axes = axes [ <NUMBER> ] <NEWLINE> if isinstance ( a_axes , compat . integral_types ) and isinstance ( b_axes , compat . integral_types ) : <NEWLINE> <TAB> a_axes = [ a_axes ] <NEWLINE> b_axes = [ b_axes ] <NEWLINE> <UNTAB> if len ( a_axes ) != len ( b_axes ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % <NEWLINE> ( len ( a_axes ) , len ( b_axes ) ) ) <NEWLINE> <UNTAB> return a_axes , b_axes <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> axes = ops . convert_to_tensor ( axes , name = <STRING> , dtype = dtypes . int32 ) <NEWLINE> return axes [ <NUMBER> ] , axes [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> with ops . name_scope ( name , <STRING> , [ a , b , axes ] ) as name : <NEWLINE> <TAB> a = ops . convert_to_tensor ( a , name = <STRING> ) <NEWLINE> b = ops . convert_to_tensor ( b , name = <STRING> ) <NEWLINE> a_axes , b_axes = _tensordot_axes ( a , axes ) <NEWLINE> a_reshape , a_free_dims , a_free_dims_static = _tensordot_reshape ( a , a_axes ) <NEWLINE> b_reshape , b_free_dims , b_free_dims_static = _tensordot_reshape ( <NEWLINE> b , b_axes , True ) <NEWLINE> ab_matmul = matmul ( a_reshape , b_reshape ) <NEWLINE> if isinstance ( a_free_dims , list ) and isinstance ( b_free_dims , list ) : <NEWLINE> <TAB> return array_ops . reshape ( ab_matmul , a_free_dims + b_free_dims , name = name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> a_free_dims = ops . convert_to_tensor ( a_free_dims , dtype = dtypes . int32 ) <NEWLINE> b_free_dims = ops . convert_to_tensor ( b_free_dims , dtype = dtypes . int32 ) <NEWLINE> product = array_ops . reshape ( <NEWLINE> ab_matmul , array_ops . concat ( [ a_free_dims , b_free_dims ] , <NUMBER> ) , name = name ) <NEWLINE> if a_free_dims_static is not None and b_free_dims_static is not None : <NEWLINE> <TAB> product . set_shape ( a_free_dims_static + b_free_dims_static ) <NEWLINE> <UNTAB> return product <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def LDLsolve ( self , rhs ) : <NEWLINE> <TAB> <NEWLINE> if self . is_hermitian : <NEWLINE> <TAB> L , D = self . LDLdecomposition ( ) <NEWLINE> <UNTAB> elif self . rows >= self . cols : <NEWLINE> <TAB> L , D = ( self . H * self ) . LDLdecomposition ( ) <NEWLINE> rhs = self . H * rhs <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> Y = L . _lower_triangular_solve ( rhs ) <NEWLINE> Z = D . _diagonal_solve ( Y ) <NEWLINE> return ( L . H ) . _upper_triangular_solve ( Z ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def stack ( self , name = None ) : <NEWLINE> <TAB> <NEWLINE> return self . _implementation . stack ( name = name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , X , alpha = None , bytes = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not self . _isinit : <NEWLINE> <TAB> self . _init ( ) <NEWLINE> <UNTAB> mask_bad = None <NEWLINE> if not cbook . iterable ( X ) : <NEWLINE> <TAB> vtype = <STRING> <NEWLINE> xa = np . array ( [ X ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> vtype = <STRING> <NEWLINE> xma = np . ma . array ( X , copy = True ) <NEWLINE> mask_bad = xma . mask <NEWLINE> xa = xma . filled ( ) <NEWLINE> del xma <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if not xa . dtype . isnative : <NEWLINE> <TAB> xa = xa . byteswap ( ) . newbyteorder ( ) <NEWLINE> <NEWLINE> <UNTAB> if xa . dtype . kind == <STRING> : <NEWLINE> <TAB> xa *= self . N <NEWLINE> <NEWLINE> <NEWLINE> xa [ xa < <NUMBER> ] = - <NUMBER> <NEWLINE> <NEWLINE> xa [ xa == self . N ] = self . N - <NUMBER> <NEWLINE> <NEWLINE> np . clip ( xa , - <NUMBER> , self . N , out = xa ) <NEWLINE> xa = xa . astype ( int ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> xa [ xa > self . N - <NUMBER> ] = self . _i_over <NEWLINE> xa [ xa < <NUMBER> ] = self . _i_under <NEWLINE> if mask_bad is not None : <NEWLINE> <TAB> if mask_bad . shape == xa . shape : <NEWLINE> <TAB> np . copyto ( xa , self . _i_bad , where = mask_bad ) <NEWLINE> <UNTAB> elif mask_bad : <NEWLINE> <TAB> xa . fill ( self . _i_bad ) <NEWLINE> <UNTAB> <UNTAB> if bytes : <NEWLINE> <TAB> lut = ( self . _lut * <NUMBER> ) . astype ( np . uint8 ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> lut = self . _lut . copy ( ) <NEWLINE> <NEWLINE> <UNTAB> if alpha is not None : <NEWLINE> <TAB> alpha = np . clip ( alpha , <NUMBER> , <NUMBER> ) <NEWLINE> if bytes : <NEWLINE> <TAB> alpha = int ( alpha * <NUMBER> ) <NEWLINE> <UNTAB> if ( lut [ - <NUMBER> ] == <NUMBER> ) . all ( ) : <NEWLINE> <TAB> lut [ : - <NUMBER> , - <NUMBER> ] = alpha <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> lut [ : , - <NUMBER> ] = alpha <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> rgba = np . empty ( shape = xa . shape + ( <NUMBER> , ) , dtype = lut . dtype ) <NEWLINE> lut . take ( xa , axis = <NUMBER> , mode = <STRING> , out = rgba ) <NEWLINE> if vtype == <STRING> : <NEWLINE> <TAB> rgba = tuple ( rgba [ <NUMBER> , : ] ) <NEWLINE> <UNTAB> return rgba <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _add_pruned_saver ( base_meta_graph_def , meta_graph_def , removed_op_names ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if base_meta_graph_def . HasField ( <STRING> ) : <NEWLINE> <TAB> filename_tensor_name = base_meta_graph_def . saver_def . filename_tensor_name <NEWLINE> save_tensor_name = base_meta_graph_def . saver_def . save_tensor_name <NEWLINE> restore_op_name = base_meta_graph_def . saver_def . restore_op_name <NEWLINE> <NEWLINE> _check_tensor_not_removed ( filename_tensor_name , removed_op_names ) <NEWLINE> _check_tensor_not_removed ( save_tensor_name , removed_op_names ) <NEWLINE> _check_tensor_not_removed ( restore_op_name , removed_op_names ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> meta_graph_def . saver_def . CopyFrom ( base_meta_graph_def . saver_def ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def drop ( self , bind = None , checkfirst = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if bind is None : <NEWLINE> <TAB> bind = _bind_or_error ( self ) <NEWLINE> <UNTAB> t = self . dialect_impl ( bind . dialect ) <NEWLINE> if t . __class__ is not self . __class__ and isinstance ( t , SchemaType ) : <NEWLINE> <TAB> t . drop ( bind = bind , checkfirst = checkfirst ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def finalize_tree ( tree_handle , stats_handle , params , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> params = _execute . make_str ( params , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , tree_handle = tree_handle , stats_handle = stats_handle , <NEWLINE> params = params , name = name ) <NEWLINE> return _op <NEWLINE> _result = None <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , tree_handle , stats_handle , <NEWLINE> <STRING> , params ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return finalize_tree_eager_fallback ( <NEWLINE> tree_handle , stats_handle , params = params , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_fifo ( self ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return S_ISFIFO ( self . stat ( ) . st_mode ) <NEWLINE> <UNTAB> except OSError as e : <NEWLINE> <TAB> if e . errno not in ( ENOENT , ENOTDIR ) : <NEWLINE> <TAB> raise <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def uifft2 ( inarray ) : <NEWLINE> <TAB> <NEWLINE> return uifftn ( inarray , <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ util . dependencies ( <STRING> ) <NEWLINE> def _bind_to ( self , url , bind ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( bind , util . string_types + ( url . URL , ) ) : <NEWLINE> <TAB> self . _bind = sqlalchemy . create_engine ( bind ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _bind = bind <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _tanh ( p , x , prec ) : <NEWLINE> <TAB> <NEWLINE> R = p . ring <NEWLINE> p1 = R ( <NUMBER> ) <NEWLINE> for precx in _giant_steps ( prec ) : <NEWLINE> <TAB> tmp = p - rs_atanh ( p1 , x , precx ) <NEWLINE> tmp = rs_mul ( tmp , <NUMBER> - rs_square ( p1 , x , prec ) , x , precx ) <NEWLINE> p1 += tmp <NEWLINE> <UNTAB> return p1 <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def argtopk ( self , k , axis = - <NUMBER> , split_every = None ) : <NEWLINE> <TAB> <NEWLINE> from . reductions import argtopk <NEWLINE> return argtopk ( self , k , axis = axis , split_every = split_every ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sub_eager_fallback ( x , y , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ x , y ] , _ctx ) <NEWLINE> ( x , y ) = _inputs_T <NEWLINE> _inputs_flat = [ x , y ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def with_empty_output ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _options [ <STRING> ] = <STRING> <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __eq__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return isinstance ( other , AlgebraicField ) and self . dtype == other . dtype and self . ext == other . ext <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def multinomial_coefficients_iterator ( m , n , _tuple = tuple ) : <NEWLINE> <TAB> <NEWLINE> if m < <NUMBER> * n or n == <NUMBER> : <NEWLINE> <TAB> mc = multinomial_coefficients ( m , n ) <NEWLINE> for k , v in mc . items ( ) : <NEWLINE> <TAB> yield ( k , v ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> mc = multinomial_coefficients ( n , n ) <NEWLINE> mc1 = { } <NEWLINE> for k , v in mc . items ( ) : <NEWLINE> <TAB> mc1 [ _tuple ( filter ( None , k ) ) ] = v <NEWLINE> <UNTAB> mc = mc1 <NEWLINE> <NEWLINE> t = [ n ] + [ <NUMBER> ] * ( m - <NUMBER> ) <NEWLINE> t1 = _tuple ( t ) <NEWLINE> b = _tuple ( filter ( None , t1 ) ) <NEWLINE> yield ( t1 , mc [ b ] ) <NEWLINE> if n : <NEWLINE> <TAB> j = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> j = m <NEWLINE> <NEWLINE> <UNTAB> while j < m - <NUMBER> : <NEWLINE> <NEWLINE> <TAB> tj = t [ j ] <NEWLINE> if j : <NEWLINE> <TAB> t [ j ] = <NUMBER> <NEWLINE> t [ <NUMBER> ] = tj <NEWLINE> <UNTAB> if tj > <NUMBER> : <NEWLINE> <TAB> t [ j + <NUMBER> ] += <NUMBER> <NEWLINE> j = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> j += <NUMBER> <NEWLINE> t [ j ] += <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> t [ <NUMBER> ] -= <NUMBER> <NEWLINE> t1 = _tuple ( t ) <NEWLINE> b = _tuple ( filter ( None , t1 ) ) <NEWLINE> yield ( t1 , mc [ b ] ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_label_clabeltext ( self , x , y , rotation , lev , cvalue ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> t = self . _get_label_clabeltext ( x , y , rotation ) <NEWLINE> self . _add_label ( t , x , y , lev , cvalue ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _is_connected_by_alternating_path ( G , v , matched_edges , unmatched_edges , <NEWLINE> targets ) : <NEWLINE> <TAB> <NEWLINE> def _alternating_dfs ( u , along_matched = True ) : <NEWLINE> <TAB> <NEWLINE> if along_matched : <NEWLINE> <TAB> edges = itertools . cycle ( [ matched_edges , unmatched_edges ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> edges = itertools . cycle ( [ unmatched_edges , matched_edges ] ) <NEWLINE> <UNTAB> visited = set ( ) <NEWLINE> stack = [ ( u , iter ( G [ u ] ) , next ( edges ) ) ] <NEWLINE> while stack : <NEWLINE> <TAB> parent , children , valid_edges = stack [ - <NUMBER> ] <NEWLINE> try : <NEWLINE> <TAB> child = next ( children ) <NEWLINE> if child not in visited : <NEWLINE> <TAB> if ( ( parent , child ) in valid_edges <NEWLINE> or ( child , parent ) in valid_edges ) : <NEWLINE> <TAB> if child in targets : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> visited . add ( child ) <NEWLINE> stack . append ( ( child , iter ( G [ child ] ) , next ( edges ) ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> except StopIteration : <NEWLINE> <TAB> stack . pop ( ) <NEWLINE> <UNTAB> <UNTAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return ( _alternating_dfs ( v , along_matched = True ) or <NEWLINE> _alternating_dfs ( v , along_matched = False ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _is_full_circle_rad ( thetamin , thetamax ) : <NEWLINE> <TAB> <NEWLINE> return abs ( abs ( thetamax - thetamin ) - <NUMBER> * np . pi ) < <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def laggrid2d ( x , y , c ) : <NEWLINE> <TAB> <NEWLINE> c = lagval ( x , c ) <NEWLINE> c = lagval ( y , c ) <NEWLINE> return c <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ deprecation . deprecated ( <NEWLINE> None , <STRING> <NEWLINE> <STRING> ) <NEWLINE> def __init__ ( self , skip_header_lines = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> rr = gen_io_ops . text_line_reader_v2 ( skip_header_lines = skip_header_lines , <NEWLINE> name = name ) <NEWLINE> super ( TextLineReader , self ) . __init__ ( rr ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def scatter_params ( link , array ) : <NEWLINE> <TAB> <NEWLINE> return _scatter ( link , array , <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def cumsum ( self , axis = <NUMBER> , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> nv . validate_cumsum ( args , kwargs ) <NEWLINE> <NEWLINE> if axis is not None and axis >= self . ndim : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( axis = axis ) ) <NEWLINE> <NEWLINE> <UNTAB> if not self . _null_fill_value : <NEWLINE> <TAB> return SparseArray ( self . to_dense ( ) ) . cumsum ( ) <NEWLINE> <NEWLINE> <UNTAB> return SparseArray ( self . sp_values . cumsum ( ) , sparse_index = self . sp_index , <NEWLINE> fill_value = self . fill_value ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def algebraic_field ( self , * extension ) : <NEWLINE> <TAB> <NEWLINE> raise DomainError ( <STRING> % self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def arccos ( x ) : <NEWLINE> <TAB> <NEWLINE> return Arccos ( ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def pts_to_midstep ( x , * args ) : <NEWLINE> <TAB> <NEWLINE> steps = np . zeros ( ( <NUMBER> + len ( args ) , <NUMBER> * len ( x ) ) ) <NEWLINE> x = np . asanyarray ( x ) <NEWLINE> steps [ <NUMBER> , <NUMBER> : - <NUMBER> : <NUMBER> ] = steps [ <NUMBER> , <NUMBER> : : <NUMBER> ] = ( x [ : - <NUMBER> ] + x [ <NUMBER> : ] ) / <NUMBER> <NEWLINE> steps [ <NUMBER> , : <NUMBER> ] = x [ : <NUMBER> ] <NEWLINE> steps [ <NUMBER> , - <NUMBER> : ] = x [ - <NUMBER> : ] <NEWLINE> steps [ <NUMBER> : , <NUMBER> : : <NUMBER> ] = args <NEWLINE> steps [ <NUMBER> : , <NUMBER> : : <NUMBER> ] = steps [ <NUMBER> : , <NUMBER> : : <NUMBER> ] <NEWLINE> return steps <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ artist . allow_rasterization <NEWLINE> def draw ( self , renderer ) : <NEWLINE> <TAB> <NEWLINE> if renderer is not None : <NEWLINE> <TAB> self . _renderer = renderer <NEWLINE> <UNTAB> if not self . get_visible ( ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> if self . get_text ( ) == <STRING> : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> renderer . open_group ( <STRING> , self . get_gid ( ) ) <NEWLINE> <NEWLINE> with _wrap_text ( self ) as textobj : <NEWLINE> <TAB> bbox , info , descent = textobj . _get_layout ( renderer ) <NEWLINE> trans = textobj . get_transform ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> posx = float ( textobj . convert_xunits ( textobj . _x ) ) <NEWLINE> posy = float ( textobj . convert_yunits ( textobj . _y ) ) <NEWLINE> posx , posy = trans . transform_point ( ( posx , posy ) ) <NEWLINE> if not np . isfinite ( posx ) or not np . isfinite ( posy ) : <NEWLINE> <TAB> _log . warning ( <STRING> ) <NEWLINE> return <NEWLINE> <UNTAB> canvasw , canvash = renderer . get_canvas_width_height ( ) <NEWLINE> <NEWLINE> <NEWLINE> if textobj . _bbox_patch : <NEWLINE> <TAB> textobj . _draw_bbox ( renderer , posx , posy ) <NEWLINE> <NEWLINE> <UNTAB> gc = renderer . new_gc ( ) <NEWLINE> gc . set_foreground ( textobj . get_color ( ) ) <NEWLINE> gc . set_alpha ( textobj . get_alpha ( ) ) <NEWLINE> gc . set_url ( textobj . _url ) <NEWLINE> textobj . _set_gc_clip ( gc ) <NEWLINE> <NEWLINE> angle = textobj . get_rotation ( ) <NEWLINE> <NEWLINE> for line , wh , x , y in info : <NEWLINE> <NEWLINE> <TAB> mtext = textobj if len ( info ) == <NUMBER> else None <NEWLINE> x = x + posx <NEWLINE> y = y + posy <NEWLINE> if renderer . flipy ( ) : <NEWLINE> <TAB> y = canvash - y <NEWLINE> <UNTAB> clean_line , ismath = textobj . is_math_text ( line , <NEWLINE> self . get_usetex ( ) ) <NEWLINE> <NEWLINE> if textobj . get_path_effects ( ) : <NEWLINE> <TAB> from matplotlib . patheffects import PathEffectRenderer <NEWLINE> textrenderer = PathEffectRenderer ( <NEWLINE> textobj . get_path_effects ( ) , renderer ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> textrenderer = renderer <NEWLINE> <NEWLINE> <UNTAB> if textobj . get_usetex ( ) : <NEWLINE> <TAB> textrenderer . draw_tex ( gc , x , y , clean_line , <NEWLINE> textobj . _fontproperties , angle , <NEWLINE> mtext = mtext ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> textrenderer . draw_text ( gc , x , y , clean_line , <NEWLINE> textobj . _fontproperties , angle , <NEWLINE> ismath = ismath , mtext = mtext ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> gc . restore ( ) <NEWLINE> renderer . close_group ( <STRING> ) <NEWLINE> self . stale = False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def cast ( self , type_ ) : <NEWLINE> <TAB> <NEWLINE> return Cast ( self , type_ ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def LDLdecomposition ( self ) : <NEWLINE> <TAB> <NEWLINE> from sympy . core . numbers import nan , oo <NEWLINE> if not self . is_symmetric ( ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> L , D = self . as_mutable ( ) . _LDL_sparse ( ) <NEWLINE> if L . has ( nan ) or L . has ( oo ) or D . has ( nan ) or D . has ( oo ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return self . _new ( L ) , self . _new ( D ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def predict ( self , input ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> head_output = self . head ( input ) <NEWLINE> output = torch . argmax ( head_output , dim = <NUMBER> ) <NEWLINE> not_in_shortlist = ( output >= self . shortlist_size ) <NEWLINE> all_in_shortlist = not ( not_in_shortlist . any ( ) ) <NEWLINE> <NEWLINE> if all_in_shortlist : <NEWLINE> <TAB> return output <NEWLINE> <NEWLINE> <UNTAB> elif not_in_shortlist . all ( ) : <NEWLINE> <TAB> log_prob = self . _get_full_log_prob ( input , head_output ) <NEWLINE> return torch . argmax ( log_prob , dim = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> log_prob = self . _get_full_log_prob ( input [ not_in_shortlist ] , <NEWLINE> head_output [ not_in_shortlist ] ) <NEWLINE> output [ not_in_shortlist ] = torch . argmax ( log_prob , dim = <NUMBER> ) <NEWLINE> return output <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_zz_mignotte_bound ( f , K ) : <NEWLINE> <TAB> <NEWLINE> a = dup_max_norm ( f , K ) <NEWLINE> b = abs ( dup_LC ( f , K ) ) <NEWLINE> n = dup_degree ( f ) <NEWLINE> <NEWLINE> return K . sqrt ( K ( n + <NUMBER> ) ) * <NUMBER> ** n * a * b <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def uuid4 ( ) : <NEWLINE> <TAB> <NEWLINE> return UUID ( bytes = os . urandom ( <NUMBER> ) , version = <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def has_alias ( self , alias ) : <NEWLINE> <TAB> <NEWLINE> return alias in self . aliases <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def Flatten ( nested ) : <NEWLINE> <TAB> <NEWLINE> return _pywrap_tensorflow_internal . Flatten ( nested ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tc . returns ( core . LabeledTensor ) <NEWLINE> @ tc . accepts ( core . LabeledTensorLike , string_types , tc . Optional ( string_types ) ) <NEWLINE> def verify_tensor_all_finite ( labeled_tensor , message , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , <NEWLINE> [ labeled_tensor ] ) as scope : <NEWLINE> <TAB> labeled_tensor = core . convert_to_labeled_tensor ( labeled_tensor ) <NEWLINE> op = numerics . verify_tensor_all_finite ( <NEWLINE> labeled_tensor . tensor , msg = message , name = scope ) <NEWLINE> return core . LabeledTensor ( op , labeled_tensor . axes ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def c_code_cleanup ( self , node , name , inputs , outputs , sub ) : <NEWLINE> <TAB> <NEWLINE> raise utils . MethodNotDefined ( <STRING> % <NEWLINE> self . __class__ . __name__ ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecation . deprecated_endpoints ( <STRING> ) <NEWLINE> def lbeta ( x , name = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> with ops . name_scope ( name , <STRING> , [ x ] ) : <NEWLINE> <TAB> x = ops . convert_to_tensor ( x , name = <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> log_prod_gamma_x = math_ops . reduce_sum ( <NEWLINE> math_ops . lgamma ( x ) , reduction_indices = [ - <NUMBER> ] ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> sum_x = math_ops . reduce_sum ( x , axis = [ - <NUMBER> ] ) <NEWLINE> log_gamma_sum_x = math_ops . lgamma ( sum_x ) <NEWLINE> result = log_prod_gamma_x - log_gamma_sum_x <NEWLINE> <NEWLINE> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _node_func ( G ) : <NEWLINE> <TAB> <NEWLINE> if G . is_multigraph ( ) : <NEWLINE> <TAB> def sorted_node ( u , v , key ) : <NEWLINE> <TAB> return ( u , v , key ) if u <= v else ( v , u , key ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> def sorted_node ( u , v ) : <NEWLINE> <TAB> return ( u , v ) if u <= v else ( v , u ) <NEWLINE> <UNTAB> <UNTAB> return sorted_node <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dup_half_gcdex ( f , g , K ) : <NEWLINE> <TAB> <NEWLINE> if not K . is_Field : <NEWLINE> <TAB> raise DomainError ( <STRING> % K ) <NEWLINE> <NEWLINE> <UNTAB> a , b = [ K . one ] , [ ] <NEWLINE> <NEWLINE> while g : <NEWLINE> <TAB> q , r = dup_div ( f , g , K ) <NEWLINE> f , g = g , r <NEWLINE> a , b = b , dup_sub_mul ( a , q , b , K ) <NEWLINE> <NEWLINE> <UNTAB> a = dup_quo_ground ( a , dup_LC ( f , K ) , K ) <NEWLINE> f = dup_monic ( f , K ) <NEWLINE> <NEWLINE> return a , f <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( <STRING> , <NEWLINE> <STRING> ) <NEWLINE> def union ( lf , rf ) : <NEWLINE> <TAB> <NEWLINE> def keep ( paths ) : <NEWLINE> <TAB> l = set ( lf ( paths ) ) <NEWLINE> r = set ( rf ( paths ) ) <NEWLINE> return sorted ( list ( l | r ) ) <NEWLINE> <UNTAB> return keep <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_pixel_distance_along_axis ( self , where , perturb ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if self . axes . name == <STRING> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> trans = self . axes . transData <NEWLINE> <NEWLINE> transinv = trans . inverted ( ) <NEWLINE> pix = trans . transform_point ( ( where , <NUMBER> ) ) <NEWLINE> <NEWLINE> ptp = transinv . transform_point ( ( pix [ <NUMBER> ] + perturb , pix [ <NUMBER> ] ) ) <NEWLINE> dx = abs ( ptp [ <NUMBER> ] - where ) <NEWLINE> <NEWLINE> return dx <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def field_isomorphism_factor ( a , b ) : <NEWLINE> <TAB> <NEWLINE> _ , factors = factor_list ( a . minpoly , extension = b ) <NEWLINE> <NEWLINE> for f , _ in factors : <NEWLINE> <TAB> if f . degree ( ) == <NUMBER> : <NEWLINE> <TAB> coeffs = f . rep . TC ( ) . to_sympy_list ( ) <NEWLINE> d , terms = len ( coeffs ) - <NUMBER> , [ ] <NEWLINE> <NEWLINE> for i , coeff in enumerate ( coeffs ) : <NEWLINE> <TAB> terms . append ( coeff * b . root ** ( d - i ) ) <NEWLINE> <NEWLINE> <UNTAB> root = Add ( * terms ) <NEWLINE> <NEWLINE> if ( a . root - root ) . evalf ( chop = True ) == <NUMBER> : <NEWLINE> <TAB> return coeffs <NEWLINE> <NEWLINE> <UNTAB> if ( a . root + root ) . evalf ( chop = True ) == <NUMBER> : <NEWLINE> <TAB> return [ - c for c in coeffs ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_params ( self , subs = None , numticks = None ) : <NEWLINE> <TAB> <NEWLINE> if numticks is not None : <NEWLINE> <TAB> self . numticks = numticks <NEWLINE> <UNTAB> if subs is not None : <NEWLINE> <TAB> self . _subs = subs <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ open_file ( <NUMBER> , mode = <STRING> ) <NEWLINE> def read_gml ( path , label = <STRING> , destringizer = None ) : <NEWLINE> <TAB> <NEWLINE> def filter_lines ( lines ) : <NEWLINE> <TAB> for line in lines : <NEWLINE> <TAB> try : <NEWLINE> <TAB> line = line . decode ( <STRING> ) <NEWLINE> <UNTAB> except UnicodeDecodeError : <NEWLINE> <TAB> raise NetworkXError ( <STRING> ) <NEWLINE> <UNTAB> if not isinstance ( line , str ) : <NEWLINE> <TAB> lines = str ( lines ) <NEWLINE> <UNTAB> if line and line [ - <NUMBER> ] == <STRING> : <NEWLINE> <TAB> line = line [ : - <NUMBER> ] <NEWLINE> <UNTAB> yield line <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> G = parse_gml_lines ( filter_lines ( path ) , label , destringizer ) <NEWLINE> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _vode_banded_jac_wrapper ( jacfunc , ml , jac_params ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def jac_wrapper ( t , y ) : <NEWLINE> <TAB> jac = asarray ( jacfunc ( t , y , * jac_params ) ) <NEWLINE> padded_jac = vstack ( ( jac , zeros ( ( ml , jac . shape [ <NUMBER> ] ) ) ) ) <NEWLINE> return padded_jac <NEWLINE> <NEWLINE> <UNTAB> return jac_wrapper <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_real_imag ( self , deep = True , ** hints ) : <NEWLINE> <TAB> <NEWLINE> sargs , terms = self . args , [ ] <NEWLINE> re_part , im_part = [ ] , [ ] <NEWLINE> for term in sargs : <NEWLINE> <TAB> re , im = term . as_real_imag ( deep = deep ) <NEWLINE> re_part . append ( re ) <NEWLINE> im_part . append ( im ) <NEWLINE> <UNTAB> return ( self . func ( * re_part ) , self . func ( * im_part ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _inflate_fox_h ( g , a ) : <NEWLINE> <TAB> <NEWLINE> if a < <NUMBER> : <NEWLINE> <TAB> return _inflate_fox_h ( _flip_g ( g ) , - a ) <NEWLINE> <UNTAB> p = S ( a . p ) <NEWLINE> q = S ( a . q ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> D , g = _inflate_g ( g , q ) <NEWLINE> z = g . argument <NEWLINE> D /= ( <NUMBER> * pi ) ** ( ( <NUMBER> - p ) / <NUMBER> ) * p ** ( - S ( <NUMBER> ) / <NUMBER> ) <NEWLINE> z /= p ** p <NEWLINE> bs = [ ( n + <NUMBER> ) / p for n in range ( p ) ] <NEWLINE> return D , meijerg ( g . an , g . aother , g . bm , list ( g . bother ) + bs , z ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __rfloordiv__ ( b , a ) : <NEWLINE> <TAB> <NEWLINE> return math . floor ( a / b ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def binary_partitions ( n ) : <NEWLINE> <TAB> <NEWLINE> from math import ceil , log <NEWLINE> pow = int ( <NUMBER> ** ( ceil ( log ( n , <NUMBER> ) ) ) ) <NEWLINE> sum = <NUMBER> <NEWLINE> partition = [ ] <NEWLINE> while pow : <NEWLINE> <TAB> if sum + pow <= n : <NEWLINE> <TAB> partition . append ( pow ) <NEWLINE> sum += pow <NEWLINE> <UNTAB> pow >>= <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> last_num = len ( partition ) - <NUMBER> - ( n & <NUMBER> ) <NEWLINE> while last_num >= <NUMBER> : <NEWLINE> <TAB> yield partition <NEWLINE> if partition [ last_num ] == <NUMBER> : <NEWLINE> <TAB> partition [ last_num ] = <NUMBER> <NEWLINE> partition . append ( <NUMBER> ) <NEWLINE> last_num -= <NUMBER> <NEWLINE> continue <NEWLINE> <UNTAB> partition . append ( <NUMBER> ) <NEWLINE> partition [ last_num ] >>= <NUMBER> <NEWLINE> x = partition [ last_num + <NUMBER> ] = partition [ last_num ] <NEWLINE> last_num += <NUMBER> <NEWLINE> while x > <NUMBER> : <NEWLINE> <TAB> if x <= len ( partition ) - last_num - <NUMBER> : <NEWLINE> <TAB> del partition [ - x + <NUMBER> : ] <NEWLINE> last_num += <NUMBER> <NEWLINE> partition [ last_num ] = x <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x >>= <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> yield [ <NUMBER> ] * n <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def round_eager_fallback ( x , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , ( x , ) = _execute . args_to_matching_eager ( [ x ] , _ctx ) <NEWLINE> _inputs_flat = [ x ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rs_puiseux ( f , p , x , prec ) : <NEWLINE> <TAB> <NEWLINE> index = p . ring . gens . index ( x ) <NEWLINE> n = <NUMBER> <NEWLINE> for k in p : <NEWLINE> <TAB> power = k [ index ] <NEWLINE> if isinstance ( power , Rational ) : <NEWLINE> <TAB> num , den = power . as_numer_denom ( ) <NEWLINE> n = int ( n * den // igcd ( n , den ) ) <NEWLINE> <UNTAB> elif power != int ( power ) : <NEWLINE> <TAB> num , den = power . numerator , power . denominator <NEWLINE> n = int ( n * den // igcd ( n , den ) ) <NEWLINE> <UNTAB> <UNTAB> if n != <NUMBER> : <NEWLINE> <TAB> p1 = pow_xin ( p , index , n ) <NEWLINE> r = f ( p1 , x , prec * n ) <NEWLINE> n1 = QQ ( <NUMBER> , n ) <NEWLINE> if isinstance ( r , tuple ) : <NEWLINE> <TAB> r = tuple ( [ pow_xin ( rx , index , n1 ) for rx in r ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> r = pow_xin ( r , index , n1 ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> r = f ( p , x , prec ) <NEWLINE> <UNTAB> return r <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def last ( self , offset ) : <NEWLINE> <TAB> <NEWLINE> from pandas . tseries . frequencies import to_offset <NEWLINE> if not isinstance ( self . index , DatetimeIndex ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if len ( self . index ) == <NUMBER> : <NEWLINE> <TAB> return self <NEWLINE> <NEWLINE> <UNTAB> offset = to_offset ( offset ) <NEWLINE> <NEWLINE> start_date = self . index [ - <NUMBER> ] - offset <NEWLINE> start = self . index . searchsorted ( start_date , side = <STRING> ) <NEWLINE> return self . iloc [ start : ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def max ( x , axis = None , keepdims = False ) : <NEWLINE> <TAB> <NEWLINE> return tf . reduce_max ( x , axis , keepdims ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def erfcinv ( x ) : <NEWLINE> <TAB> <NEWLINE> return ErfcInv ( ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _add_to_index ( df , start ) : <NEWLINE> <TAB> <NEWLINE> df = df . copy ( ) <NEWLINE> df . index += start <NEWLINE> return df <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_label ( self , s ) : <NEWLINE> <TAB> <NEWLINE> if s is not None : <NEWLINE> <TAB> self . _label = str ( s ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _label = None <NEWLINE> <UNTAB> self . pchanged ( ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ _generative <NEWLINE> def correlate ( self , * fromclauses ) : <NEWLINE> <TAB> <NEWLINE> self . _auto_correlate = False <NEWLINE> if fromclauses and fromclauses [ <NUMBER> ] is None : <NEWLINE> <TAB> self . _correlate = ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _correlate = set ( self . _correlate ) . union ( <NEWLINE> _interpret_as_from ( f ) for f in fromclauses ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def notnull ( values ) : <NEWLINE> <TAB> <NEWLINE> return ~ isnull ( values ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _str_equal ( obj , s ) : <NEWLINE> <TAB> <NEWLINE> return isinstance ( obj , str ) and obj == s <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_linestyle ( self , ls ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( ls , str ) : <NEWLINE> <TAB> ds , ls = self . _split_drawstyle_linestyle ( ls ) <NEWLINE> if ds is not None : <NEWLINE> <TAB> self . set_drawstyle ( ds ) <NEWLINE> <NEWLINE> <UNTAB> if ls in [ <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> ls = <STRING> <NEWLINE> <NEWLINE> <UNTAB> if ls not in self . _lineStyles : <NEWLINE> <TAB> try : <NEWLINE> <TAB> ls = ls_mapper_r [ ls ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> . format ( ls ) ) <NEWLINE> <UNTAB> <UNTAB> self . _linestyle = ls <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _linestyle = <STRING> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . _us_dashOffset , self . _us_dashSeq = _get_dash_pattern ( ls ) <NEWLINE> <NEWLINE> self . _dashOffset , self . _dashSeq = _scale_dashes ( <NEWLINE> self . _us_dashOffset , self . _us_dashSeq , self . _linewidth ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def count_partitions ( self , multiplicities ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . pcount = <NUMBER> <NEWLINE> <NEWLINE> self . dp_stack = [ ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if not hasattr ( self , <STRING> ) : <NEWLINE> <TAB> self . dp_map = { } <NEWLINE> <NEWLINE> <UNTAB> self . _initialize_enumeration ( multiplicities ) <NEWLINE> pkey = part_key ( self . top_part ( ) ) <NEWLINE> self . dp_stack . append ( [ ( pkey , <NUMBER> ) , ] ) <NEWLINE> while True : <NEWLINE> <TAB> while self . spread_part_multiplicity ( ) : <NEWLINE> <TAB> pkey = part_key ( self . top_part ( ) ) <NEWLINE> if pkey in self . dp_map : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> self . pcount += ( self . dp_map [ pkey ] - <NUMBER> ) <NEWLINE> self . lpart -= <NUMBER> <NEWLINE> break <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . dp_stack . append ( [ ( pkey , self . pcount ) , ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . pcount += <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> while not self . decrement_part ( self . top_part ( ) ) : <NEWLINE> <NEWLINE> <TAB> for key , oldcount in self . dp_stack . pop ( ) : <NEWLINE> <TAB> self . dp_map [ key ] = self . pcount - oldcount <NEWLINE> <UNTAB> if self . lpart == <NUMBER> : <NEWLINE> <TAB> return self . pcount <NEWLINE> <UNTAB> self . lpart -= <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> pkey = part_key ( self . top_part ( ) ) <NEWLINE> self . dp_stack [ - <NUMBER> ] . append ( ( pkey , self . pcount ) , ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def contains ( self , mouseevent ) : <NEWLINE> <TAB> <NEWLINE> if callable ( self . _contains ) : <NEWLINE> <TAB> return self . _contains ( self , mouseevent ) <NEWLINE> <NEWLINE> <UNTAB> if not isinstance ( self . pickradius , Number ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . _invalidy or self . _invalidx : <NEWLINE> <TAB> self . recache ( ) <NEWLINE> <UNTAB> if len ( self . _xy ) == <NUMBER> : <NEWLINE> <TAB> return False , { } <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> transformed_path = self . _get_transformed_path ( ) <NEWLINE> path , affine = transformed_path . get_transformed_path_and_affine ( ) <NEWLINE> path = affine . transform_path ( path ) <NEWLINE> xy = path . vertices <NEWLINE> xt = xy [ : , <NUMBER> ] <NEWLINE> yt = xy [ : , <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> if self . figure is None : <NEWLINE> <TAB> warnings . warn ( <STRING> ) <NEWLINE> pixels = self . pickradius <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pixels = self . figure . dpi / <NUMBER> * self . pickradius <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> with np . errstate ( all = <STRING> ) : <NEWLINE> <NEWLINE> <TAB> if self . _linestyle in [ <STRING> , None ] : <NEWLINE> <NEWLINE> <TAB> d = ( xt - mouseevent . x ) ** <NUMBER> + ( yt - mouseevent . y ) ** <NUMBER> <NEWLINE> ind , = np . nonzero ( np . less_equal ( d , pixels ** <NUMBER> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> ind = segment_hits ( mouseevent . x , mouseevent . y , xt , yt , pixels ) <NEWLINE> if self . _drawstyle . startswith ( <STRING> ) : <NEWLINE> <TAB> ind //= <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> ind += self . ind_offset <NEWLINE> <NEWLINE> <NEWLINE> return len ( ind ) > <NUMBER> , dict ( ind = ind ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def yvp ( v , z , n = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> n = _nonneg_int_or_fail ( n , <STRING> ) <NEWLINE> if n == <NUMBER> : <NEWLINE> <TAB> return yv ( v , z ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _bessel_diff_formula ( v , z , n , yv , - <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def current_stream ( ) : <NEWLINE> <TAB> <NEWLINE> _lazy_init ( ) <NEWLINE> return torch . cuda . Stream ( _cdata = torch . _C . _cuda_getCurrentStream ( ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def union ( self , other ) : <NEWLINE> <TAB> <NEWLINE> self . _assert_can_do_setop ( other ) <NEWLINE> other , result_names = self . _convert_can_do_setop ( other ) <NEWLINE> <NEWLINE> if len ( other ) == <NUMBER> or self . equals ( other ) : <NEWLINE> <TAB> return self <NEWLINE> <NEWLINE> <UNTAB> uniq_tuples = lib . fast_unique_multiple ( [ self . _ndarray_values , <NEWLINE> other . _ndarray_values ] ) <NEWLINE> return MultiIndex . from_arrays ( lzip ( * uniq_tuples ) , sortorder = <NUMBER> , <NEWLINE> names = result_names ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def readline ( self , size = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( size , int ) : <NEWLINE> <TAB> if not hasattr ( size , <STRING> ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> size = size . __index__ ( ) <NEWLINE> <UNTAB> with self . _lock : <NEWLINE> <TAB> self . _check_can_read ( ) <NEWLINE> return self . _buffer . readline ( size ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def kl_connected_subgraph ( G , k , l , low_memory = False , same_as_graph = False ) : <NEWLINE> <TAB> <NEWLINE> H = copy . deepcopy ( G ) <NEWLINE> <NEWLINE> graphOK = True <NEWLINE> deleted_some = True <NEWLINE> while deleted_some : <NEWLINE> <TAB> deleted_some = False <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for edge in list ( H . edges ( ) ) : <NEWLINE> <TAB> ( u , v ) = edge <NEWLINE> <NEWLINE> if low_memory : <NEWLINE> <TAB> verts = set ( [ u , v ] ) <NEWLINE> for i in range ( k ) : <NEWLINE> <TAB> for w in verts . copy ( ) : <NEWLINE> <TAB> verts . update ( G [ w ] ) <NEWLINE> <UNTAB> <UNTAB> G2 = G . subgraph ( verts ) . copy ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> G2 = copy . deepcopy ( G ) <NEWLINE> <NEWLINE> <UNTAB> path = [ u , v ] <NEWLINE> cnt = <NUMBER> <NEWLINE> accept = <NUMBER> <NEWLINE> while path : <NEWLINE> <TAB> cnt += <NUMBER> <NEWLINE> if cnt >= l : <NEWLINE> <TAB> accept = <NUMBER> <NEWLINE> break <NEWLINE> <NEWLINE> <UNTAB> prev = u <NEWLINE> for w in path : <NEWLINE> <TAB> if prev != w : <NEWLINE> <TAB> G2 . remove_edge ( prev , w ) <NEWLINE> prev = w <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> try : <NEWLINE> <TAB> path = nx . shortest_path ( G2 , u , v ) <NEWLINE> <UNTAB> except nx . NetworkXNoPath : <NEWLINE> <TAB> path = False <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if accept == <NUMBER> : <NEWLINE> <TAB> H . remove_edge ( u , v ) <NEWLINE> deleted_some = True <NEWLINE> if graphOK : <NEWLINE> <TAB> graphOK = False <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> if same_as_graph : <NEWLINE> <TAB> return ( H , graphOK ) <NEWLINE> <UNTAB> return H <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_graphs ( self , graph_list ) : <NEWLINE> <TAB> <NEWLINE> for G in graph_list : <NEWLINE> <TAB> self . add_graph_element ( G ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def minutes ( m ) : <NEWLINE> <TAB> <NEWLINE> return m / MINUTES_PER_DAY <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def detrend ( data , axis = - <NUMBER> , type = <STRING> , bp = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if type not in [ <STRING> , <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> data = asarray ( data ) <NEWLINE> dtype = data . dtype . char <NEWLINE> if dtype not in <STRING> : <NEWLINE> <TAB> dtype = <STRING> <NEWLINE> <UNTAB> if type in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> ret = data - expand_dims ( mean ( data , axis ) , axis ) <NEWLINE> return ret <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dshape = data . shape <NEWLINE> N = dshape [ axis ] <NEWLINE> bp = sort ( unique ( r_ [ <NUMBER> , bp , N ] ) ) <NEWLINE> if np . any ( bp > N ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> Nreg = len ( bp ) - <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> rnk = len ( dshape ) <NEWLINE> if axis < <NUMBER> : <NEWLINE> <TAB> axis = axis + rnk <NEWLINE> <UNTAB> newdims = r_ [ axis , <NUMBER> : axis , axis + <NUMBER> : rnk ] <NEWLINE> newdata = reshape ( transpose ( data , tuple ( newdims ) ) , <NEWLINE> ( N , _prod ( dshape ) // N ) ) <NEWLINE> newdata = newdata . copy ( ) <NEWLINE> if newdata . dtype . char not in <STRING> : <NEWLINE> <TAB> newdata = newdata . astype ( dtype ) <NEWLINE> <NEWLINE> <UNTAB> for m in range ( Nreg ) : <NEWLINE> <TAB> Npts = bp [ m + <NUMBER> ] - bp [ m ] <NEWLINE> A = ones ( ( Npts , <NUMBER> ) , dtype ) <NEWLINE> A [ : , <NUMBER> ] = cast [ dtype ] ( arange ( <NUMBER> , Npts + <NUMBER> ) * <NUMBER> / Npts ) <NEWLINE> sl = slice ( bp [ m ] , bp [ m + <NUMBER> ] ) <NEWLINE> coef , resids , rank , s = linalg . lstsq ( A , newdata [ sl ] ) <NEWLINE> newdata [ sl ] = newdata [ sl ] - dot ( A , coef ) <NEWLINE> <NEWLINE> <UNTAB> tdshape = take ( dshape , newdims , <NUMBER> ) <NEWLINE> ret = reshape ( newdata , tuple ( tdshape ) ) <NEWLINE> vals = list ( range ( <NUMBER> , rnk ) ) <NEWLINE> olddims = vals [ : axis ] + [ <NUMBER> ] + vals [ axis : ] <NEWLINE> ret = transpose ( ret , tuple ( olddims ) ) <NEWLINE> return ret <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __array__ ( self , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> return np . array ( self . _data , dtype = dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _lazywhere ( cond , arrays , f , fillvalue = None , f2 = None ) : <NEWLINE> <TAB> <NEWLINE> if fillvalue is None : <NEWLINE> <TAB> if f2 is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> fillvalue = np . nan <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if f2 is not None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> arrays = np . broadcast_arrays ( * arrays ) <NEWLINE> temp = tuple ( np . extract ( cond , arr ) for arr in arrays ) <NEWLINE> tcode = np . mintypecode ( [ a . dtype . char for a in arrays ] ) <NEWLINE> out = _valarray ( np . shape ( arrays [ <NUMBER> ] ) , value = fillvalue , typecode = tcode ) <NEWLINE> np . place ( out , cond , f ( * temp ) ) <NEWLINE> if f2 is not None : <NEWLINE> <TAB> temp = tuple ( np . extract ( ~ cond , arr ) for arr in arrays ) <NEWLINE> np . place ( out , ~ cond , f2 ( * temp ) ) <NEWLINE> <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def expand_dims ( x , axis ) : <NEWLINE> <TAB> <NEWLINE> result = n_expand_dims ( x , axis ) <NEWLINE> if isinstance ( x , MaskedArray ) : <NEWLINE> <TAB> new_shape = result . shape <NEWLINE> result = x . view ( ) <NEWLINE> result . shape = new_shape <NEWLINE> if result . _mask is not nomask : <NEWLINE> <TAB> result . _mask . shape = new_shape <NEWLINE> <UNTAB> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ Substitution ( name = <STRING> ) <NEWLINE> @ Appender ( _doc_template ) <NEWLINE> def sem ( self , ddof = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return self . std ( ddof = ddof ) / np . sqrt ( self . count ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def nquad ( func , ranges , args = None , opts = None , full_output = False ) : <NEWLINE> <TAB> <NEWLINE> depth = len ( ranges ) <NEWLINE> ranges = [ rng if callable ( rng ) else _RangeFunc ( rng ) for rng in ranges ] <NEWLINE> if args is None : <NEWLINE> <TAB> args = ( ) <NEWLINE> <UNTAB> if opts is None : <NEWLINE> <TAB> opts = [ dict ( [ ] ) ] * depth <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( opts , dict ) : <NEWLINE> <TAB> opts = [ _OptFunc ( opts ) ] * depth <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> opts = [ opt if callable ( opt ) else _OptFunc ( opt ) for opt in opts ] <NEWLINE> <UNTAB> return _NQuad ( func , ranges , opts , full_output ) . integrate ( * args ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def identity ( input , name = None ) : <NEWLINE> <TAB> <NEWLINE> if context . executing_eagerly ( ) : <NEWLINE> <TAB> input = ops . convert_to_tensor ( input ) <NEWLINE> in_device = input . device <NEWLINE> <NEWLINE> context_device = context . context ( ) . device_name <NEWLINE> if not context_device : <NEWLINE> <TAB> context_device = <STRING> <NEWLINE> <UNTAB> if context_device != in_device : <NEWLINE> <TAB> return input . _copy ( ) <NEWLINE> <UNTAB> return input <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return gen_array_ops . identity ( input , name = name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def identity ( ) : <NEWLINE> <TAB> <NEWLINE> return Affine2D ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _cache ( self , path ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if sys . version_info [ <NUMBER> ] >= <NUMBER> : <NEWLINE> <TAB> from urllib . request import urlopen <NEWLINE> from urllib . error import URLError <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> from urllib2 import urlopen <NEWLINE> from urllib2 import URLError <NEWLINE> <NEWLINE> <UNTAB> upath = self . abspath ( path ) <NEWLINE> <NEWLINE> <NEWLINE> if not os . path . exists ( os . path . dirname ( upath ) ) : <NEWLINE> <TAB> os . makedirs ( os . path . dirname ( upath ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . _isurl ( path ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> openedurl = urlopen ( path ) <NEWLINE> f = _open ( upath , <STRING> ) <NEWLINE> try : <NEWLINE> <TAB> shutil . copyfileobj ( openedurl , f ) <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> f . close ( ) <NEWLINE> openedurl . close ( ) <NEWLINE> <UNTAB> <UNTAB> except URLError : <NEWLINE> <TAB> raise URLError ( <STRING> % path ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> shutil . copyfile ( path , upath ) <NEWLINE> <UNTAB> return upath <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def ensure_string_list ( self , option ) : <NEWLINE> <TAB> <NEWLINE> val = getattr ( self , option ) <NEWLINE> if val is None : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> elif isinstance ( val , str ) : <NEWLINE> <TAB> setattr ( self , option , re . split ( <STRING> , val ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if isinstance ( val , list ) : <NEWLINE> <TAB> ok = all ( isinstance ( v , str ) for v in val ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ok = False <NEWLINE> <UNTAB> if not ok : <NEWLINE> <TAB> raise DistutilsOptionError ( <NEWLINE> <STRING> <NEWLINE> % ( option , val ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _reverse_seq ( input_seq , lengths ) : <NEWLINE> <TAB> <NEWLINE> if lengths is None : <NEWLINE> <TAB> return list ( reversed ( input_seq ) ) <NEWLINE> <NEWLINE> <UNTAB> for input_ in input_seq : <NEWLINE> <TAB> input_ . set_shape ( input_ . get_shape ( ) . with_rank ( <NUMBER> ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> s_joined = array_ops_ . pack ( input_seq ) <NEWLINE> <NEWLINE> <NEWLINE> s_reversed = array_ops_ . reverse_sequence ( s_joined , lengths , <NUMBER> , <NUMBER> ) <NEWLINE> <NEWLINE> result = array_ops_ . unpack ( s_reversed ) <NEWLINE> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def sstr ( expr , ** settings ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> p = StrPrinter ( settings ) <NEWLINE> s = p . doprint ( expr ) <NEWLINE> <NEWLINE> return s <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def mpl_disconnect ( self , cid ) : <NEWLINE> <TAB> <NEWLINE> return self . callbacks . disconnect ( cid ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def build ( cls , node ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( node , gast . FunctionDef ) : <NEWLINE> <TAB> raise ValueError <NEWLINE> <UNTAB> namer = cls ( ) <NEWLINE> namer . names . update ( get_names ( node ) ) <NEWLINE> return namer <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_empty_dataspace ( obj ) : <NEWLINE> <TAB> <NEWLINE> if obj . get_space ( ) . get_simple_extent_type ( ) == h5s . NULL : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> return False <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ Substitution ( name = <STRING> ) <NEWLINE> @ Appender ( _doc_template ) <NEWLINE> def ohlc ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return self . _apply_to_column_groupbys ( <NEWLINE> lambda x : x . _cython_agg_general ( <STRING> ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def make_strictly_feasible ( x , lb , ub , rstep = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> x_new = x . copy ( ) <NEWLINE> <NEWLINE> active = find_active_constraints ( x , lb , ub , rstep ) <NEWLINE> lower_mask = np . equal ( active , - <NUMBER> ) <NEWLINE> upper_mask = np . equal ( active , <NUMBER> ) <NEWLINE> <NEWLINE> if rstep == <NUMBER> : <NEWLINE> <TAB> x_new [ lower_mask ] = np . nextafter ( lb [ lower_mask ] , ub [ lower_mask ] ) <NEWLINE> x_new [ upper_mask ] = np . nextafter ( ub [ upper_mask ] , lb [ upper_mask ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x_new [ lower_mask ] = ( lb [ lower_mask ] + <NEWLINE> rstep * np . maximum ( <NUMBER> , np . abs ( lb [ lower_mask ] ) ) ) <NEWLINE> x_new [ upper_mask ] = ( ub [ upper_mask ] - <NEWLINE> rstep * np . maximum ( <NUMBER> , np . abs ( ub [ upper_mask ] ) ) ) <NEWLINE> <NEWLINE> <UNTAB> tight_bounds = ( x_new < lb ) | ( x_new > ub ) <NEWLINE> x_new [ tight_bounds ] = <NUMBER> * ( lb [ tight_bounds ] + ub [ tight_bounds ] ) <NEWLINE> <NEWLINE> return x_new <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def intersection ( self , o ) : <NEWLINE> <TAB> <NEWLINE> x , y = symbols ( <STRING> , real = True ) <NEWLINE> parabola_eq = self . equation ( ) <NEWLINE> if isinstance ( o , Parabola ) : <NEWLINE> <TAB> if o in self : <NEWLINE> <TAB> return [ o ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return list ( ordered ( [ Point ( i ) for i in solve ( [ parabola_eq , o . equation ( ) ] , [ x , y ] ) ] ) ) <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( o , Point2D ) : <NEWLINE> <TAB> if simplify ( parabola_eq . subs ( ( [ ( x , o . _args [ <NUMBER> ] ) , ( y , o . _args [ <NUMBER> ] ) ] ) ) ) == <NUMBER> : <NEWLINE> <TAB> return [ o ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( o , ( Segment2D , Ray2D ) ) : <NEWLINE> <TAB> result = solve ( [ parabola_eq , Line2D ( o . points [ <NUMBER> ] , o . points [ <NUMBER> ] ) . equation ( ) ] , [ x , y ] ) <NEWLINE> return list ( ordered ( [ Point2D ( i ) for i in result if i in o ] ) ) <NEWLINE> <UNTAB> elif isinstance ( o , ( Line2D , Ellipse ) ) : <NEWLINE> <TAB> return list ( ordered ( [ Point2D ( i ) for i in solve ( [ parabola_eq , o . equation ( ) ] , [ x , y ] ) ] ) ) <NEWLINE> <UNTAB> elif isinstance ( o , LinearEntity3D ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def isnan ( tensor ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( tensor , torch . Tensor ) : <NEWLINE> <TAB> raise ValueError ( <STRING> , str ( tensor ) ) <NEWLINE> <UNTAB> return tensor != tensor <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def integrate ( self , a , b , extrapolate = None ) : <NEWLINE> <TAB> <NEWLINE> if extrapolate is None : <NEWLINE> <TAB> extrapolate = self . extrapolate <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> sign = <NUMBER> <NEWLINE> if b < a : <NEWLINE> <TAB> a , b = b , a <NEWLINE> sign = - <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> range_int = np . empty ( ( prod ( self . c . shape [ <NUMBER> : ] ) , ) , dtype = self . c . dtype ) <NEWLINE> self . _ensure_c_contiguous ( ) <NEWLINE> <NEWLINE> <NEWLINE> if extrapolate == <STRING> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> xs , xe = self . x [ <NUMBER> ] , self . x [ - <NUMBER> ] <NEWLINE> period = xe - xs <NEWLINE> interval = b - a <NEWLINE> n_periods , left = divmod ( interval , period ) <NEWLINE> <NEWLINE> if n_periods > <NUMBER> : <NEWLINE> <TAB> _ppoly . integrate ( <NEWLINE> self . c . reshape ( self . c . shape [ <NUMBER> ] , self . c . shape [ <NUMBER> ] , - <NUMBER> ) , <NEWLINE> self . x , xs , xe , False , out = range_int ) <NEWLINE> range_int *= n_periods <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> range_int . fill ( <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> a = xs + ( a - xs ) % period <NEWLINE> b = a + left <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> remainder_int = np . empty_like ( range_int ) <NEWLINE> if b <= xe : <NEWLINE> <TAB> _ppoly . integrate ( <NEWLINE> self . c . reshape ( self . c . shape [ <NUMBER> ] , self . c . shape [ <NUMBER> ] , - <NUMBER> ) , <NEWLINE> self . x , a , b , False , out = remainder_int ) <NEWLINE> range_int += remainder_int <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> _ppoly . integrate ( <NEWLINE> self . c . reshape ( self . c . shape [ <NUMBER> ] , self . c . shape [ <NUMBER> ] , - <NUMBER> ) , <NEWLINE> self . x , a , xe , False , out = remainder_int ) <NEWLINE> range_int += remainder_int <NEWLINE> <NEWLINE> _ppoly . integrate ( <NEWLINE> self . c . reshape ( self . c . shape [ <NUMBER> ] , self . c . shape [ <NUMBER> ] , - <NUMBER> ) , <NEWLINE> self . x , xs , xs + left + a - xe , False , out = remainder_int ) <NEWLINE> range_int += remainder_int <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> _ppoly . integrate ( <NEWLINE> self . c . reshape ( self . c . shape [ <NUMBER> ] , self . c . shape [ <NUMBER> ] , - <NUMBER> ) , <NEWLINE> self . x , a , b , bool ( extrapolate ) , out = range_int ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> range_int *= sign <NEWLINE> return range_int . reshape ( self . c . shape [ <NUMBER> : ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def quo ( self , a , b ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_rop_overrides ( self , rop_overrides ) : <NEWLINE> <TAB> <NEWLINE> self . _rop_op = rop_overrides <NEWLINE> self . _rop_op_is_cached = False <NEWLINE> self . _rop_is_default = ( rop_overrides == <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def named_parameters ( self , memo = None , prefix = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if memo is None : <NEWLINE> <TAB> memo = set ( ) <NEWLINE> <UNTAB> for name , p in self . _parameters . items ( ) : <NEWLINE> <TAB> if p is not None and p not in memo : <NEWLINE> <TAB> memo . add ( p ) <NEWLINE> yield prefix + ( <STRING> if prefix else <STRING> ) + name , p <NEWLINE> <UNTAB> <UNTAB> for mname , module in self . named_children ( ) : <NEWLINE> <TAB> submodule_prefix = prefix + ( <STRING> if prefix else <STRING> ) + mname <NEWLINE> for name , p in module . named_parameters ( memo , submodule_prefix ) : <NEWLINE> <TAB> yield name , p <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def make_sampling_table ( size , sampling_factor = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> gamma = <NUMBER> <NEWLINE> rank = np . arange ( size ) <NEWLINE> rank [ <NUMBER> ] = <NUMBER> <NEWLINE> inv_fq = rank * ( np . log ( rank ) + gamma ) + <NUMBER> - <NUMBER> / ( <NUMBER> * rank ) <NEWLINE> f = sampling_factor * inv_fq <NEWLINE> <NEWLINE> return np . minimum ( <NUMBER> , f / np . sqrt ( f ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dup_prs_resultant ( f , g , K ) : <NEWLINE> <TAB> <NEWLINE> if not f or not g : <NEWLINE> <TAB> return ( K . zero , [ ] ) <NEWLINE> <NEWLINE> <UNTAB> R , S = dup_inner_subresultants ( f , g , K ) <NEWLINE> <NEWLINE> if dup_degree ( R [ - <NUMBER> ] ) > <NUMBER> : <NEWLINE> <TAB> return ( K . zero , R ) <NEWLINE> <NEWLINE> <UNTAB> return S [ - <NUMBER> ] , R <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def seterr ( inf_or_nan = None ) : <NEWLINE> <TAB> <NEWLINE> if inf_or_nan not in _VALID_CALLBACK_ACTIONS : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ( inf_or_nan , _VALID_CALLBACK_ACTIONS ) ) <NEWLINE> <NEWLINE> <UNTAB> old_settings = { <STRING> : <STRING> } <NEWLINE> default_context = context . context ( ) <NEWLINE> <NEWLINE> carryover_callbacks = [ ] <NEWLINE> for callback in default_context . post_execution_callbacks : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if ( callback == inf_nan_callback or <NEWLINE> isinstance ( callback , functools . partial ) and <NEWLINE> callback . func == inf_nan_callback ) : <NEWLINE> <TAB> if callback == inf_nan_callback : <NEWLINE> <TAB> old_settings [ <STRING> ] = _DEFAULT_CALLBACK_ACTION <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> old_settings [ <STRING> ] = callback . keywords . get ( <NEWLINE> <STRING> , _DEFAULT_CALLBACK_ACTION ) <NEWLINE> <UNTAB> <UNTAB> elif inf_or_nan is not None : <NEWLINE> <TAB> carryover_callbacks . append ( callback ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if inf_or_nan is not None : <NEWLINE> <TAB> default_context . clear_post_execution_callbacks ( ) <NEWLINE> for callback in carryover_callbacks : <NEWLINE> <TAB> default_context . add_post_execution_callback ( callback ) <NEWLINE> <UNTAB> if inf_or_nan != <STRING> : <NEWLINE> <TAB> default_context . add_post_execution_callback ( <NEWLINE> functools . partial ( inf_nan_callback , action = inf_or_nan ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return old_settings <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _nth_root1 ( p , n , x , prec ) : <NEWLINE> <TAB> <NEWLINE> if rs_is_puiseux ( p , x ) : <NEWLINE> <TAB> return rs_puiseux2 ( _nth_root1 , p , n , x , prec ) <NEWLINE> <UNTAB> R = p . ring <NEWLINE> zm = R . zero_monom <NEWLINE> if zm not in p : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> n = as_int ( n ) <NEWLINE> assert p [ zm ] == <NUMBER> <NEWLINE> p1 = R ( <NUMBER> ) <NEWLINE> if p == <NUMBER> : <NEWLINE> <TAB> return p <NEWLINE> <UNTAB> if n == <NUMBER> : <NEWLINE> <TAB> return R ( <NUMBER> ) <NEWLINE> <UNTAB> if n == <NUMBER> : <NEWLINE> <TAB> return p <NEWLINE> <UNTAB> if n < <NUMBER> : <NEWLINE> <TAB> n = - n <NEWLINE> sign = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> sign = <NUMBER> <NEWLINE> <UNTAB> for precx in _giant_steps ( prec ) : <NEWLINE> <TAB> tmp = rs_pow ( p1 , n + <NUMBER> , x , precx ) <NEWLINE> tmp = rs_mul ( tmp , p , x , precx ) <NEWLINE> p1 += p1 / n - tmp / n <NEWLINE> <UNTAB> if sign : <NEWLINE> <TAB> return p1 <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _series_inversion1 ( p1 , x , prec ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_norm ( f , u , K ) : <NEWLINE> <TAB> <NEWLINE> if not K . is_Algebraic : <NEWLINE> <TAB> raise DomainError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> g = dmp_raise ( K . mod . rep , u + <NUMBER> , <NUMBER> , K . dom ) <NEWLINE> h , _ = dmp_inject ( f , u , K , front = True ) <NEWLINE> <NEWLINE> return dmp_resultant ( g , h , u + <NUMBER> , K . dom ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def huber_loss ( x , t , delta , reduce = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return HuberLoss ( delta = delta , reduce = reduce ) . apply ( ( x , t ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def sign ( x , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , x = x , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , x ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return sign_eager_fallback ( <NEWLINE> x , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def duplicated ( self , keep = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return super ( Index , self ) . duplicated ( keep = keep ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def round ( x ) : <NEWLINE> <TAB> <NEWLINE> return tf . round ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def accept ( self , fgraph , no_recycling = None , profile = None ) : <NEWLINE> <TAB> <NEWLINE> if no_recycling is None : <NEWLINE> <TAB> no_recycling = [ ] <NEWLINE> <UNTAB> if self . fgraph is not None and self . fgraph is not fgraph : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return type ( self ) ( <NEWLINE> allow_gc = self . allow_gc , <NEWLINE> use_cloop = self . use_cloop , <NEWLINE> callback = self . callback , <NEWLINE> callback_input = self . callback_input , <NEWLINE> lazy = self . lazy , <NEWLINE> schedule = self . schedule , <NEWLINE> c_thunks = self . c_thunks , <NEWLINE> allow_partial_eval = self . allow_partial_eval <NEWLINE> ) . accept ( fgraph , no_recycling , profile ) <NEWLINE> <UNTAB> self . fgraph = fgraph <NEWLINE> self . no_recycling = no_recycling <NEWLINE> self . profile = profile <NEWLINE> <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def visit_With ( self , node ) : <NEWLINE> <TAB> <NEWLINE> if ast_ . is_insert_grad_of_statement ( node ) : <NEWLINE> <TAB> primal = [ ] <NEWLINE> adjoint = node . body <NEWLINE> if isinstance ( adjoint [ <NUMBER> ] , gast . With ) : <NEWLINE> <TAB> _ , adjoint = self . visit ( adjoint [ <NUMBER> ] ) <NEWLINE> <UNTAB> node . body [ <NUMBER> ] = comments . add_comment ( node . body [ <NUMBER> ] , <STRING> ) <NEWLINE> <NEWLINE> replacements = { } <NEWLINE> for item in node . items : <NEWLINE> <TAB> if ( not isinstance ( item . context_expr . args [ <NUMBER> ] , gast . Name ) or <NEWLINE> not isinstance ( item . optional_vars , gast . Name ) ) : <NEWLINE> <TAB> raise ValueError <NEWLINE> <UNTAB> replacements [ item . optional_vars . id ] = create . create_grad ( <NEWLINE> item . context_expr . args [ <NUMBER> ] , self . namer ) <NEWLINE> <UNTAB> template . ReplaceTransformer ( replacements ) . visit ( node ) <NEWLINE> return primal , adjoint <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return node , [ ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_text_bounds ( self , renderer ) : <NEWLINE> <TAB> <NEWLINE> bbox = self . _text . get_window_extent ( renderer ) <NEWLINE> bboxa = bbox . inverse_transformed ( self . get_data_transform ( ) ) <NEWLINE> return bboxa . bounds <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def center ( self , x ) : <NEWLINE> <TAB> <NEWLINE> if self . standardize : <NEWLINE> <TAB> return ( x - self . mu ) / self . sigma <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return ( x - self . mu ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _ensure_safe ( self ) : <NEWLINE> <TAB> <NEWLINE> if not self . _safe_to_run ( ) : <NEWLINE> <TAB> raise RuntimeError ( " " " T h e r e   i s   a t   l e a s t   1   r e f e r e n c e   t o   i n t e r n a l   d a t a 
             i n   t h e   i n t e r p r e t e r   i n   t h e   f o r m   o f   a   n u m p y   a r r a y   o r   s l i c e .   B e   s u r e   t o 
             o n l y   h o l d   t h e   f u n c t i o n   r e t u r n e d   f r o m   t e n s o r ( )   i f   y o u   a r e   u s i n g   r a w 
             d a t a   a c c e s s . " " " ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def minkowski_distance ( x , y , p = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> x = np . asarray ( x ) <NEWLINE> y = np . asarray ( y ) <NEWLINE> if p == np . inf or p == <NUMBER> : <NEWLINE> <TAB> return minkowski_distance_p ( x , y , p ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return minkowski_distance_p ( x , y , p ) ** ( <NUMBER> / p ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_sum ( self , n = None , method = <STRING> , evaluate = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> from sympy . concrete . summations import Sum <NEWLINE> limits = self . limits <NEWLINE> if len ( limits ) > <NUMBER> : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> limit = limits [ <NUMBER> ] <NEWLINE> if ( len ( limit ) != <NUMBER> or limit [ <NUMBER> ] . is_finite is False or <NEWLINE> limit [ <NUMBER> ] . is_finite is False ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> if n is None : <NEWLINE> <TAB> n = Dummy ( <STRING> , integer = True , positive = True ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> n = sympify ( n ) <NEWLINE> <UNTAB> if ( n . is_positive is False or n . is_integer is False or <NEWLINE> n . is_finite is False ) : <NEWLINE> <TAB> raise ValueError ( <STRING> % n ) <NEWLINE> <UNTAB> x , a , b = limit <NEWLINE> dx = ( b - a ) / n <NEWLINE> k = Dummy ( <STRING> , integer = True , positive = True ) <NEWLINE> f = self . function <NEWLINE> <NEWLINE> if method == <STRING> : <NEWLINE> <TAB> result = dx * Sum ( f . subs ( x , a + ( k - <NUMBER> ) * dx ) , ( k , <NUMBER> , n ) ) <NEWLINE> <UNTAB> elif method == <STRING> : <NEWLINE> <TAB> result = dx * Sum ( f . subs ( x , a + k * dx ) , ( k , <NUMBER> , n ) ) <NEWLINE> <UNTAB> elif method == <STRING> : <NEWLINE> <TAB> result = dx * Sum ( f . subs ( x , a + k * dx - dx / <NUMBER> ) , ( k , <NUMBER> , n ) ) <NEWLINE> <UNTAB> elif method == <STRING> : <NEWLINE> <TAB> result = dx * ( ( f . subs ( x , a ) + f . subs ( x , b ) ) / <NUMBER> + <NEWLINE> Sum ( f . subs ( x , a + k * dx ) , ( k , <NUMBER> , n - <NUMBER> ) ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % method ) <NEWLINE> <UNTAB> return result . doit ( ) if evaluate else result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _ureduce ( a , func , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> a = np . asanyarray ( a ) <NEWLINE> axis = kwargs . get ( <STRING> , None ) <NEWLINE> if axis is not None : <NEWLINE> <TAB> keepdim = list ( a . shape ) <NEWLINE> nd = a . ndim <NEWLINE> axis = _nx . normalize_axis_tuple ( axis , nd ) <NEWLINE> <NEWLINE> for ax in axis : <NEWLINE> <TAB> keepdim [ ax ] = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> if len ( axis ) == <NUMBER> : <NEWLINE> <TAB> kwargs [ <STRING> ] = axis [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> keep = set ( range ( nd ) ) - set ( axis ) <NEWLINE> nkeep = len ( keep ) <NEWLINE> <NEWLINE> for i , s in enumerate ( sorted ( keep ) ) : <NEWLINE> <TAB> a = a . swapaxes ( i , s ) <NEWLINE> <NEWLINE> <UNTAB> a = a . reshape ( a . shape [ : nkeep ] + ( - <NUMBER> , ) ) <NEWLINE> kwargs [ <STRING> ] = - <NUMBER> <NEWLINE> <UNTAB> keepdim = tuple ( keepdim ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> keepdim = ( <NUMBER> , ) * a . ndim <NEWLINE> <NEWLINE> <UNTAB> r = func ( a , ** kwargs ) <NEWLINE> return r , keepdim <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def map ( self , func , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> kw_color = kwargs . pop ( <STRING> , None ) <NEWLINE> for i , y_var in enumerate ( self . y_vars ) : <NEWLINE> <TAB> for j , x_var in enumerate ( self . x_vars ) : <NEWLINE> <TAB> hue_grouped = self . data . groupby ( self . hue_vals ) <NEWLINE> for k , label_k in enumerate ( self . hue_names ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> data_k = hue_grouped . get_group ( label_k ) <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> data_k = pd . DataFrame ( columns = self . data . columns , <NEWLINE> dtype = np . float ) <NEWLINE> <NEWLINE> <UNTAB> ax = self . axes [ i , j ] <NEWLINE> plt . sca ( ax ) <NEWLINE> <NEWLINE> <NEWLINE> for kw , val_list in self . hue_kws . items ( ) : <NEWLINE> <TAB> kwargs [ kw ] = val_list [ k ] <NEWLINE> <NEWLINE> <UNTAB> color = self . palette [ k ] if kw_color is None else kw_color <NEWLINE> func ( data_k [ x_var ] , data_k [ y_var ] , <NEWLINE> label = label_k , color = color , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> self . _clean_axis ( ax ) <NEWLINE> self . _update_legend_data ( ax ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if kw_color is not None : <NEWLINE> <TAB> kwargs [ <STRING> ] = kw_color <NEWLINE> <UNTAB> self . _add_axis_labels ( ) <NEWLINE> <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def from_tuples ( cls , tuples , sortorder = None , names = None ) : <NEWLINE> <TAB> <NEWLINE> if not is_list_like ( tuples ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> elif is_iterator ( tuples ) : <NEWLINE> <TAB> tuples = list ( tuples ) <NEWLINE> <NEWLINE> <UNTAB> if len ( tuples ) == <NUMBER> : <NEWLINE> <TAB> if names is None : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise TypeError ( msg ) <NEWLINE> <UNTAB> arrays = [ [ ] ] * len ( names ) <NEWLINE> <UNTAB> elif isinstance ( tuples , ( np . ndarray , Index ) ) : <NEWLINE> <TAB> if isinstance ( tuples , Index ) : <NEWLINE> <TAB> tuples = tuples . _values <NEWLINE> <NEWLINE> <UNTAB> arrays = list ( lib . tuples_to_object_array ( tuples ) . T ) <NEWLINE> <UNTAB> elif isinstance ( tuples , list ) : <NEWLINE> <TAB> arrays = list ( lib . to_object_array_tuples ( tuples ) . T ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> arrays = lzip ( * tuples ) <NEWLINE> <NEWLINE> <UNTAB> return MultiIndex . from_arrays ( arrays , sortorder = sortorder , names = names ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __radd__ ( self , a ) : <NEWLINE> <TAB> <NEWLINE> return a . __add__ ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sawtooth ( t , width = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> t , w = asarray ( t ) , asarray ( width ) <NEWLINE> w = asarray ( w + ( t - t ) ) <NEWLINE> t = asarray ( t + ( w - w ) ) <NEWLINE> if t . dtype . char in [ <STRING> ] : <NEWLINE> <TAB> ytype = t . dtype . char <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ytype = <STRING> <NEWLINE> <UNTAB> y = zeros ( t . shape , ytype ) <NEWLINE> <NEWLINE> <NEWLINE> mask1 = ( w > <NUMBER> ) | ( w < <NUMBER> ) <NEWLINE> place ( y , mask1 , nan ) <NEWLINE> <NEWLINE> <NEWLINE> tmod = mod ( t , <NUMBER> * pi ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> mask2 = ( <NUMBER> - mask1 ) & ( tmod < w * <NUMBER> * pi ) <NEWLINE> tsub = extract ( mask2 , tmod ) <NEWLINE> wsub = extract ( mask2 , w ) <NEWLINE> place ( y , mask2 , tsub / ( pi * wsub ) - <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> mask3 = ( <NUMBER> - mask1 ) & ( <NUMBER> - mask2 ) <NEWLINE> tsub = extract ( mask3 , tmod ) <NEWLINE> wsub = extract ( mask3 , w ) <NEWLINE> place ( y , mask3 , ( pi * ( wsub + <NUMBER> ) - tsub ) / ( pi * ( <NUMBER> - wsub ) ) ) <NEWLINE> return y <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _minpoly_rootof ( ex , x ) : <NEWLINE> <TAB> <NEWLINE> p = ex . expr <NEWLINE> p = p . subs ( { ex . poly . gens [ <NUMBER> ] : x } ) <NEWLINE> _ , factors = factor_list ( p , x ) <NEWLINE> result = _choose_factor ( factors , x , ex ) <NEWLINE> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def color_lookup ( self , key ) : <NEWLINE> <TAB> <NEWLINE> if self . hue_type == <STRING> : <NEWLINE> <TAB> normed = self . hue_norm ( key ) <NEWLINE> if np . ma . is_masked ( normed ) : <NEWLINE> <TAB> normed = np . nan <NEWLINE> <UNTAB> return self . cmap ( normed ) <NEWLINE> <UNTAB> elif self . hue_type == <STRING> : <NEWLINE> <TAB> return self . palette [ key ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def compute_gradients ( self , loss , var_list = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> num_shards = tpu_function . get_tpu_context ( ) . number_of_shards <NEWLINE> if num_shards is None : <NEWLINE> <TAB> logging . warning ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> num_shards = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> subgroup_size = self . _verify_and_get_subgroup_size ( self . _group_assignment , <NEWLINE> num_shards ) <NEWLINE> <NEWLINE> if num_shards > <NUMBER> and self . _reduction == losses . Reduction . MEAN : <NEWLINE> <TAB> if self . _group_assignment : <NEWLINE> <TAB> scale = <NUMBER> / subgroup_size <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> scale = <NUMBER> / num_shards <NEWLINE> <UNTAB> loss *= scale <NEWLINE> <NEWLINE> <UNTAB> return self . _opt . compute_gradients ( loss , var_list = var_list , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def lsim ( system , U , T , X0 = None , interp = True ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( system , lti ) : <NEWLINE> <TAB> sys = system . _as_ss ( ) <NEWLINE> <UNTAB> elif isinstance ( system , dlti ) : <NEWLINE> <TAB> raise AttributeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> sys = lti ( * system ) . _as_ss ( ) <NEWLINE> <UNTAB> T = atleast_1d ( T ) <NEWLINE> if len ( T . shape ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> A , B , C , D = map ( np . asarray , ( sys . A , sys . B , sys . C , sys . D ) ) <NEWLINE> n_states = A . shape [ <NUMBER> ] <NEWLINE> n_inputs = B . shape [ <NUMBER> ] <NEWLINE> <NEWLINE> n_steps = T . size <NEWLINE> if X0 is None : <NEWLINE> <TAB> X0 = zeros ( n_states , sys . A . dtype ) <NEWLINE> <UNTAB> xout = zeros ( ( n_steps , n_states ) , sys . A . dtype ) <NEWLINE> <NEWLINE> if T [ <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> xout [ <NUMBER> ] = X0 <NEWLINE> <UNTAB> elif T [ <NUMBER> ] > <NUMBER> : <NEWLINE> <NEWLINE> <TAB> xout [ <NUMBER> ] = dot ( X0 , linalg . expm ( transpose ( A ) * T [ <NUMBER> ] ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> no_input = ( U is None or <NEWLINE> ( isinstance ( U , ( int , float ) ) and U == <NUMBER> ) or <NEWLINE> not np . any ( U ) ) <NEWLINE> <NEWLINE> if n_steps == <NUMBER> : <NEWLINE> <TAB> yout = squeeze ( dot ( xout , transpose ( C ) ) ) <NEWLINE> if not no_input : <NEWLINE> <TAB> yout += squeeze ( dot ( U , transpose ( D ) ) ) <NEWLINE> <UNTAB> return T , squeeze ( yout ) , squeeze ( xout ) <NEWLINE> <NEWLINE> <UNTAB> dt = T [ <NUMBER> ] - T [ <NUMBER> ] <NEWLINE> if not np . allclose ( ( T [ <NUMBER> : ] - T [ : - <NUMBER> ] ) / dt , <NUMBER> ) : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> , DeprecationWarning ) <NEWLINE> return lsim2 ( system , U , T , X0 ) <NEWLINE> <NEWLINE> <UNTAB> if no_input : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> expAT_dt = linalg . expm ( transpose ( A ) * dt ) <NEWLINE> for i in xrange ( <NUMBER> , n_steps ) : <NEWLINE> <TAB> xout [ i ] = dot ( xout [ i - <NUMBER> ] , expAT_dt ) <NEWLINE> <UNTAB> yout = squeeze ( dot ( xout , transpose ( C ) ) ) <NEWLINE> return T , squeeze ( yout ) , squeeze ( xout ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> U = atleast_1d ( U ) <NEWLINE> if U . ndim == <NUMBER> : <NEWLINE> <TAB> U = U [ : , np . newaxis ] <NEWLINE> <NEWLINE> <UNTAB> if U . shape [ <NUMBER> ] != n_steps : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if U . shape [ <NUMBER> ] != n_inputs : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if not interp : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> M = np . vstack ( [ np . hstack ( [ A * dt , B * dt ] ) , <NEWLINE> np . zeros ( ( n_inputs , n_states + n_inputs ) ) ] ) <NEWLINE> <NEWLINE> expMT = linalg . expm ( transpose ( M ) ) <NEWLINE> Ad = expMT [ : n_states , : n_states ] <NEWLINE> Bd = expMT [ n_states : , : n_states ] <NEWLINE> for i in xrange ( <NUMBER> , n_steps ) : <NEWLINE> <TAB> xout [ i ] = dot ( xout [ i - <NUMBER> ] , Ad ) + dot ( U [ i - <NUMBER> ] , Bd ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> M = np . vstack ( [ np . hstack ( [ A * dt , B * dt , <NEWLINE> np . zeros ( ( n_states , n_inputs ) ) ] ) , <NEWLINE> np . hstack ( [ np . zeros ( ( n_inputs , n_states + n_inputs ) ) , <NEWLINE> np . identity ( n_inputs ) ] ) , <NEWLINE> np . zeros ( ( n_inputs , n_states + <NUMBER> * n_inputs ) ) ] ) <NEWLINE> expMT = linalg . expm ( transpose ( M ) ) <NEWLINE> Ad = expMT [ : n_states , : n_states ] <NEWLINE> Bd1 = expMT [ n_states + n_inputs : , : n_states ] <NEWLINE> Bd0 = expMT [ n_states : n_states + n_inputs , : n_states ] - Bd1 <NEWLINE> for i in xrange ( <NUMBER> , n_steps ) : <NEWLINE> <TAB> xout [ i ] = ( dot ( xout [ i - <NUMBER> ] , Ad ) + dot ( U [ i - <NUMBER> ] , Bd0 ) + dot ( U [ i ] , Bd1 ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> yout = ( squeeze ( dot ( xout , transpose ( C ) ) ) + squeeze ( dot ( U , transpose ( D ) ) ) ) <NEWLINE> return T , squeeze ( yout ) , squeeze ( xout ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _convert_for_op ( self , value ) : <NEWLINE> <TAB> <NEWLINE> return value <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def sample_keys ( self ) : <NEWLINE> <TAB> <NEWLINE> return _BigtableSampleKeysDataset ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _arith_method_SPARSE_SERIES ( cls , op , special ) : <NEWLINE> <TAB> <NEWLINE> op_name = _get_op_name ( op , special ) <NEWLINE> <NEWLINE> def wrapper ( self , other ) : <NEWLINE> <TAB> if isinstance ( other , ABCDataFrame ) : <NEWLINE> <TAB> return NotImplemented <NEWLINE> <UNTAB> elif isinstance ( other , ABCSeries ) : <NEWLINE> <TAB> if not isinstance ( other , ABCSparseSeries ) : <NEWLINE> <TAB> other = other . to_sparse ( fill_value = self . fill_value ) <NEWLINE> <UNTAB> return _sparse_series_op ( self , other , op , op_name ) <NEWLINE> <UNTAB> elif is_scalar ( other ) : <NEWLINE> <TAB> with np . errstate ( all = <STRING> ) : <NEWLINE> <TAB> new_values = op ( self . values , other ) <NEWLINE> <UNTAB> return self . _constructor ( new_values , <NEWLINE> index = self . index , <NEWLINE> name = self . name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> . format ( other = type ( other ) ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> wrapper . __name__ = op_name <NEWLINE> return wrapper <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , f , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> ParserBase . __init__ ( self , kwds ) <NEWLINE> <NEWLINE> self . data = None <NEWLINE> self . buf = [ ] <NEWLINE> self . pos = <NUMBER> <NEWLINE> self . line_pos = <NUMBER> <NEWLINE> <NEWLINE> self . encoding = kwds [ <STRING> ] <NEWLINE> self . compression = kwds [ <STRING> ] <NEWLINE> self . memory_map = kwds [ <STRING> ] <NEWLINE> self . skiprows = kwds [ <STRING> ] <NEWLINE> <NEWLINE> if callable ( self . skiprows ) : <NEWLINE> <TAB> self . skipfunc = self . skiprows <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . skipfunc = lambda x : x in self . skiprows <NEWLINE> <NEWLINE> <UNTAB> self . skipfooter = _validate_skipfooter_arg ( kwds [ <STRING> ] ) <NEWLINE> self . delimiter = kwds [ <STRING> ] <NEWLINE> <NEWLINE> self . quotechar = kwds [ <STRING> ] <NEWLINE> if isinstance ( self . quotechar , compat . text_type ) : <NEWLINE> <TAB> self . quotechar = str ( self . quotechar ) <NEWLINE> <NEWLINE> <UNTAB> self . escapechar = kwds [ <STRING> ] <NEWLINE> self . doublequote = kwds [ <STRING> ] <NEWLINE> self . skipinitialspace = kwds [ <STRING> ] <NEWLINE> self . lineterminator = kwds [ <STRING> ] <NEWLINE> self . quoting = kwds [ <STRING> ] <NEWLINE> self . usecols , _ = _validate_usecols_arg ( kwds [ <STRING> ] ) <NEWLINE> self . skip_blank_lines = kwds [ <STRING> ] <NEWLINE> <NEWLINE> self . warn_bad_lines = kwds [ <STRING> ] <NEWLINE> self . error_bad_lines = kwds [ <STRING> ] <NEWLINE> <NEWLINE> self . names_passed = kwds [ <STRING> ] or None <NEWLINE> <NEWLINE> self . has_index_names = False <NEWLINE> if <STRING> in kwds : <NEWLINE> <TAB> self . has_index_names = kwds [ <STRING> ] <NEWLINE> <NEWLINE> <UNTAB> self . verbose = kwds [ <STRING> ] <NEWLINE> self . converters = kwds [ <STRING> ] <NEWLINE> self . dtype = kwds [ <STRING> ] <NEWLINE> <NEWLINE> self . thousands = kwds [ <STRING> ] <NEWLINE> self . decimal = kwds [ <STRING> ] <NEWLINE> <NEWLINE> self . comment = kwds [ <STRING> ] <NEWLINE> self . _comment_lines = [ ] <NEWLINE> <NEWLINE> mode = <STRING> if PY3 else <STRING> <NEWLINE> f , handles = _get_handle ( f , mode , encoding = self . encoding , <NEWLINE> compression = self . compression , <NEWLINE> memory_map = self . memory_map ) <NEWLINE> self . handles . extend ( handles ) <NEWLINE> <NEWLINE> <NEWLINE> if hasattr ( f , <STRING> ) : <NEWLINE> <TAB> self . _make_reader ( f ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . data = f <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . _col_indices = None <NEWLINE> self . columns , self . num_original_columns = self . _infer_columns ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if len ( self . columns ) > <NUMBER> : <NEWLINE> <NEWLINE> <TAB> self . columns , self . index_names , self . col_names , _ = ( <NEWLINE> self . _extract_multi_indexer_columns ( <NEWLINE> self . columns , self . index_names , self . col_names <NEWLINE> ) <NEWLINE> ) <NEWLINE> <NEWLINE> self . num_original_columns = len ( self . columns ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . columns = self . columns [ <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . orig_names = list ( self . columns ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if not self . _has_complex_date_col : <NEWLINE> <TAB> ( index_names , self . orig_names , self . columns ) = ( <NEWLINE> self . _get_index_name ( self . columns ) ) <NEWLINE> self . _name_processed = True <NEWLINE> if self . index_names is None : <NEWLINE> <TAB> self . index_names = index_names <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if self . parse_dates : <NEWLINE> <TAB> self . _no_thousands_columns = self . _set_no_thousands_columns ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _no_thousands_columns = None <NEWLINE> <NEWLINE> <UNTAB> if len ( self . decimal ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if self . thousands is None : <NEWLINE> <TAB> self . nonnum = re . compile ( <STRING> % self . decimal ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . nonnum = re . compile ( <STRING> % ( self . thousands , <NEWLINE> self . decimal ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _read_float32 ( f ) : <NEWLINE> <TAB> <NEWLINE> return np . float32 ( struct . unpack ( <STRING> , f . read ( <NUMBER> ) ) [ <NUMBER> ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def hstack ( cls , * args ) : <NEWLINE> <TAB> <NEWLINE> if len ( args ) == <NUMBER> : <NEWLINE> <TAB> return cls . _new ( ) <NEWLINE> <NEWLINE> <UNTAB> kls = type ( args [ <NUMBER> ] ) <NEWLINE> return reduce ( kls . row_join , args ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def ilike ( self , other , escape = None ) : <NEWLINE> <TAB> <NEWLINE> return self . operate ( ilike_op , other , escape = escape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_superset ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( other , Set ) : <NEWLINE> <TAB> return other . is_subset ( self ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % other ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def transpose ( self , axes = None , copy = False ) : <NEWLINE> <TAB> <NEWLINE> return self . tocsr ( copy = copy ) . transpose ( axes = axes , copy = False ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def slice_with_int_dask_array ( x , index ) : <NEWLINE> <TAB> <NEWLINE> from . core import Array <NEWLINE> <NEWLINE> assert len ( index ) == x . ndim <NEWLINE> fancy_indexes = [ <NEWLINE> isinstance ( idx , ( tuple , list ) ) or <NEWLINE> ( isinstance ( idx , ( np . ndarray , Array ) ) and idx . ndim > <NUMBER> ) <NEWLINE> for idx in index <NEWLINE> ] <NEWLINE> if sum ( fancy_indexes ) > <NUMBER> : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> out_index = [ ] <NEWLINE> dropped_axis_cnt = <NUMBER> <NEWLINE> for in_axis , idx in enumerate ( index ) : <NEWLINE> <TAB> out_axis = in_axis - dropped_axis_cnt <NEWLINE> if isinstance ( idx , Array ) and idx . dtype . kind in <STRING> : <NEWLINE> <TAB> if idx . ndim == <NUMBER> : <NEWLINE> <TAB> idx = idx [ np . newaxis ] <NEWLINE> x = slice_with_int_dask_array_on_axis ( x , idx , out_axis ) <NEWLINE> x = x [ tuple ( <NEWLINE> <NUMBER> if i == out_axis else slice ( None ) <NEWLINE> for i in range ( x . ndim ) <NEWLINE> ) ] <NEWLINE> dropped_axis_cnt += <NUMBER> <NEWLINE> <UNTAB> elif idx . ndim == <NUMBER> : <NEWLINE> <TAB> x = slice_with_int_dask_array_on_axis ( x , idx , out_axis ) <NEWLINE> out_index . append ( slice ( None ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> out_index . append ( idx ) <NEWLINE> <UNTAB> <UNTAB> return x , tuple ( out_index ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def error ( self , msg , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> self . log ( logging . ERROR , msg , * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _mark_every_path ( markevery , tpath , affine , ax_transform ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> codes , verts = tpath . codes , tpath . vertices <NEWLINE> <NEWLINE> def _slice_or_none ( in_v , slc ) : <NEWLINE> <TAB> <NEWLINE> if in_v is None : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> return in_v [ slc ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( markevery , Integral ) : <NEWLINE> <TAB> markevery = ( <NUMBER> , markevery ) <NEWLINE> <NEWLINE> <UNTAB> elif isinstance ( markevery , Real ) : <NEWLINE> <TAB> markevery = ( <NUMBER> , markevery ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( markevery , tuple ) : <NEWLINE> <TAB> if len ( markevery ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( markevery ) ) <NEWLINE> <UNTAB> start , step = markevery <NEWLINE> <NEWLINE> if isinstance ( step , Integral ) : <NEWLINE> <NEWLINE> <TAB> if not isinstance ( start , Integral ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> . format ( markevery ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return Path ( verts [ slice ( start , None , step ) ] , <NEWLINE> _slice_or_none ( codes , slice ( start , None , step ) ) ) <NEWLINE> <NEWLINE> <UNTAB> elif isinstance ( step , Real ) : <NEWLINE> <TAB> if not isinstance ( start , Real ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( markevery ) ) <NEWLINE> <NEWLINE> <UNTAB> disp_coords = affine . transform ( tpath . vertices ) <NEWLINE> delta = np . empty ( ( len ( disp_coords ) , <NUMBER> ) ) <NEWLINE> delta [ <NUMBER> , : ] = <NUMBER> <NEWLINE> delta [ <NUMBER> : , : ] = disp_coords [ <NUMBER> : , : ] - disp_coords [ : - <NUMBER> , : ] <NEWLINE> delta = np . sum ( delta ** <NUMBER> , axis = <NUMBER> ) <NEWLINE> delta = np . sqrt ( delta ) <NEWLINE> delta = np . cumsum ( delta ) <NEWLINE> <NEWLINE> <NEWLINE> scale = ax_transform . transform ( np . array ( [ [ <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] ] ) ) <NEWLINE> scale = np . diff ( scale , axis = <NUMBER> ) <NEWLINE> scale = np . sum ( scale ** <NUMBER> ) <NEWLINE> scale = np . sqrt ( scale ) <NEWLINE> marker_delta = np . arange ( start * scale , delta [ - <NUMBER> ] , step * scale ) <NEWLINE> <NEWLINE> <NEWLINE> inds = np . abs ( delta [ np . newaxis , : ] - marker_delta [ : , np . newaxis ] ) <NEWLINE> inds = inds . argmin ( axis = <NUMBER> ) <NEWLINE> inds = np . unique ( inds ) <NEWLINE> <NEWLINE> return Path ( verts [ inds ] , <NEWLINE> _slice_or_none ( codes , inds ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ( markevery , ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( markevery , slice ) : <NEWLINE> <NEWLINE> <TAB> return Path ( verts [ markevery ] , _slice_or_none ( codes , markevery ) ) <NEWLINE> <NEWLINE> <UNTAB> elif iterable ( markevery ) : <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> return Path ( verts [ markevery ] , _slice_or_none ( codes , markevery ) ) <NEWLINE> <NEWLINE> <UNTAB> except ( ValueError , IndexError ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % ( markevery , ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % ( markevery , ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_params ( self , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if <STRING> in kwargs : <NEWLINE> <TAB> self . _nbins = kwargs [ <STRING> ] <NEWLINE> if self . _nbins != <STRING> : <NEWLINE> <TAB> self . _nbins = int ( self . _nbins ) <NEWLINE> <UNTAB> <UNTAB> if <STRING> in kwargs : <NEWLINE> <TAB> self . _symmetric = kwargs [ <STRING> ] <NEWLINE> <UNTAB> if <STRING> in kwargs : <NEWLINE> <TAB> prune = kwargs [ <STRING> ] <NEWLINE> if prune is not None and prune not in [ <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> self . _prune = prune <NEWLINE> <UNTAB> if <STRING> in kwargs : <NEWLINE> <TAB> self . _min_n_ticks = max ( <NUMBER> , kwargs [ <STRING> ] ) <NEWLINE> <UNTAB> if <STRING> in kwargs : <NEWLINE> <TAB> steps = kwargs [ <STRING> ] <NEWLINE> if steps is None : <NEWLINE> <TAB> self . _steps = np . array ( [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _steps = self . _validate_steps ( steps ) <NEWLINE> <UNTAB> self . _extended_steps = self . _staircase ( self . _steps ) <NEWLINE> <UNTAB> if <STRING> in kwargs : <NEWLINE> <TAB> self . _integer = kwargs [ <STRING> ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def sparse_read ( self , indices , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( <STRING> if name is None else name ) as name : <NEWLINE> <TAB> if self . trainable : <NEWLINE> <TAB> tape . variable_accessed ( self ) <NEWLINE> <UNTAB> value = gen_resource_variable_ops . resource_gather ( <NEWLINE> self . _handle , indices , dtype = self . _dtype , name = name ) <NEWLINE> <UNTAB> return array_ops . identity ( value ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def call ( self , inputs , state ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> U = math_ops . matmul ( inputs , self . _kernel ) <NEWLINE> x_bar , f_intermediate , r_intermediate , x_tx = array_ops . split ( <NEWLINE> value = U , num_or_size_splits = <NUMBER> , axis = <NUMBER> ) <NEWLINE> <NEWLINE> f_r = math_ops . sigmoid ( <NEWLINE> nn_ops . bias_add ( <NEWLINE> array_ops . concat ( [ f_intermediate , r_intermediate ] , <NUMBER> ) , self . _bias ) ) <NEWLINE> f , r = array_ops . split ( value = f_r , num_or_size_splits = <NUMBER> , axis = <NUMBER> ) <NEWLINE> <NEWLINE> c = f * state + ( <NUMBER> - f ) * x_bar <NEWLINE> h = r * self . _activation ( c ) + ( <NUMBER> - r ) * x_tx <NEWLINE> <NEWLINE> return h , c <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _register_style ( style_list , cls = None , * , name = None ) : <NEWLINE> <TAB> <NEWLINE> if cls is None : <NEWLINE> <TAB> return functools . partial ( _register_style , style_list , name = name ) <NEWLINE> <UNTAB> style_list [ name or cls . __name__ . lower ( ) ] = cls <NEWLINE> return cls <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def spritecollide ( sprite , group , dokill , collided = None ) : <NEWLINE> <TAB> <NEWLINE> if dokill : <NEWLINE> <NEWLINE> <TAB> crashed = [ ] <NEWLINE> append = crashed . append <NEWLINE> <NEWLINE> if collided : <NEWLINE> <TAB> for s in group . sprites ( ) : <NEWLINE> <TAB> if collided ( sprite , s ) : <NEWLINE> <TAB> s . kill ( ) <NEWLINE> append ( s ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> spritecollide = sprite . rect . colliderect <NEWLINE> for s in group . sprites ( ) : <NEWLINE> <TAB> if spritecollide ( s . rect ) : <NEWLINE> <TAB> s . kill ( ) <NEWLINE> append ( s ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return crashed <NEWLINE> <NEWLINE> <UNTAB> elif collided : <NEWLINE> <TAB> return [ s for s in group if collided ( sprite , s ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> spritecollide = sprite . rect . colliderect <NEWLINE> return [ s for s in group if spritecollide ( s . rect ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def lagder ( c , m = <NUMBER> , scl = <NUMBER> , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> c = np . array ( c , ndmin = <NUMBER> , copy = <NUMBER> ) <NEWLINE> if c . dtype . char in <STRING> : <NEWLINE> <TAB> c = c . astype ( np . double ) <NEWLINE> <UNTAB> cnt , iaxis = [ int ( t ) for t in [ m , axis ] ] <NEWLINE> <NEWLINE> if cnt != m : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if cnt < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if iaxis != axis : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> iaxis = normalize_axis_index ( iaxis , c . ndim ) <NEWLINE> <NEWLINE> if cnt == <NUMBER> : <NEWLINE> <TAB> return c <NEWLINE> <NEWLINE> <UNTAB> c = np . moveaxis ( c , iaxis , <NUMBER> ) <NEWLINE> n = len ( c ) <NEWLINE> if cnt >= n : <NEWLINE> <TAB> c = c [ : <NUMBER> ] * <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for i in range ( cnt ) : <NEWLINE> <TAB> n = n - <NUMBER> <NEWLINE> c *= scl <NEWLINE> der = np . empty ( ( n , ) + c . shape [ <NUMBER> : ] , dtype = c . dtype ) <NEWLINE> for j in range ( n , <NUMBER> , - <NUMBER> ) : <NEWLINE> <TAB> der [ j - <NUMBER> ] = - c [ j ] <NEWLINE> c [ j - <NUMBER> ] += c [ j ] <NEWLINE> <UNTAB> der [ <NUMBER> ] = - c [ <NUMBER> ] <NEWLINE> c = der <NEWLINE> <UNTAB> <UNTAB> c = np . moveaxis ( c , <NUMBER> , iaxis ) <NEWLINE> return c <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def sum ( self , axis = None , dtype = None , keepdims = False , acc_dtype = None ) : <NEWLINE> <TAB> <NEWLINE> return theano . tensor . basic . sum ( self , axis = axis , <NEWLINE> dtype = dtype , keepdims = keepdims , <NEWLINE> acc_dtype = acc_dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rollaxis ( a , axis , start = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> n = a . ndim <NEWLINE> axis = normalize_axis_index ( axis , n ) <NEWLINE> if start < <NUMBER> : <NEWLINE> <TAB> start += n <NEWLINE> <UNTAB> msg = <STRING> <NEWLINE> if not ( <NUMBER> <= start < n + <NUMBER> ) : <NEWLINE> <TAB> raise AxisError ( msg % ( <STRING> , - n , <STRING> , n + <NUMBER> , start ) ) <NEWLINE> <UNTAB> if axis < start : <NEWLINE> <NEWLINE> <TAB> start -= <NUMBER> <NEWLINE> <UNTAB> if axis == start : <NEWLINE> <TAB> return a [ ... ] <NEWLINE> <UNTAB> axes = list ( range ( <NUMBER> , n ) ) <NEWLINE> axes . remove ( axis ) <NEWLINE> axes . insert ( start , axis ) <NEWLINE> return a . transpose ( axes ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def make_sparse_uncorrelated ( n_samples = <NUMBER> , n_features = <NUMBER> , random_state = None ) : <NEWLINE> <TAB> <NEWLINE> generator = check_random_state ( random_state ) <NEWLINE> <NEWLINE> X = generator . normal ( loc = <NUMBER> , scale = <NUMBER> , size = ( n_samples , n_features ) ) <NEWLINE> y = generator . normal ( loc = ( X [ : , <NUMBER> ] + <NEWLINE> <NUMBER> * X [ : , <NUMBER> ] - <NEWLINE> <NUMBER> * X [ : , <NUMBER> ] - <NEWLINE> <NUMBER> * X [ : , <NUMBER> ] ) , scale = np . ones ( n_samples ) ) <NEWLINE> <NEWLINE> return X , y <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def print_jpg ( self , filename_or_obj , * args , dryrun = False , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> buf , size = self . print_to_buffer ( ) <NEWLINE> if dryrun : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> image = Image . frombuffer ( <STRING> , size , buf , <STRING> , <STRING> , <NUMBER> , <NUMBER> ) <NEWLINE> rgba = mcolors . to_rgba ( rcParams [ <STRING> ] ) <NEWLINE> color = tuple ( [ int ( x * <NUMBER> ) for x in rgba [ : <NUMBER> ] ] ) <NEWLINE> background = Image . new ( <STRING> , size , color ) <NEWLINE> background . paste ( image , image ) <NEWLINE> options = { k : kwargs [ k ] <NEWLINE> for k in [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> if k in kwargs } <NEWLINE> options . setdefault ( <STRING> , rcParams [ <STRING> ] ) <NEWLINE> if <STRING> in options : <NEWLINE> <NEWLINE> <TAB> options [ <STRING> ] = ( options [ <STRING> ] , options [ <STRING> ] ) <NEWLINE> <NEWLINE> <UNTAB> return background . save ( filename_or_obj , format = <STRING> , ** options ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_facecolor ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . patch . get_facecolor ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_offset_position ( self , position ) : <NEWLINE> <TAB> <NEWLINE> x , y = self . offsetText . get_position ( ) <NEWLINE> if position == <STRING> : <NEWLINE> <TAB> x = <NUMBER> <NEWLINE> <UNTAB> elif position == <STRING> : <NEWLINE> <TAB> x = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> self . offsetText . set_ha ( position ) <NEWLINE> self . offsetText . set_position ( ( x , y ) ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _torational_factor_list ( p , x ) : <NEWLINE> <TAB> <NEWLINE> from sympy . simplify . simplify import simplify <NEWLINE> p1 = Poly ( p , x , domain = <STRING> ) <NEWLINE> n = p1 . degree ( ) <NEWLINE> res = to_rational_coeffs ( p1 ) <NEWLINE> if not res : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> lc , r , t , g = res <NEWLINE> factors = factor_list ( g . as_expr ( ) ) <NEWLINE> if lc : <NEWLINE> <TAB> c = simplify ( factors [ <NUMBER> ] * lc * r ** n ) <NEWLINE> r1 = simplify ( <NUMBER> / r ) <NEWLINE> a = [ ] <NEWLINE> for z in factors [ <NUMBER> : ] [ <NUMBER> ] : <NEWLINE> <TAB> a . append ( ( simplify ( z [ <NUMBER> ] . subs ( { x : x * r1 } ) ) , z [ <NUMBER> ] ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> c = factors [ <NUMBER> ] <NEWLINE> a = [ ] <NEWLINE> for z in factors [ <NUMBER> : ] [ <NUMBER> ] : <NEWLINE> <TAB> a . append ( ( z [ <NUMBER> ] . subs ( { x : x - t } ) , z [ <NUMBER> ] ) ) <NEWLINE> <UNTAB> <UNTAB> return ( c , a ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_celld ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _cells <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def try_compile ( self , body , headers = None , include_dirs = None , lang = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> from distutils . ccompiler import CompileError <NEWLINE> self . _check_compiler ( ) <NEWLINE> try : <NEWLINE> <TAB> self . _compile ( body , headers , include_dirs , lang ) <NEWLINE> ok = True <NEWLINE> <UNTAB> except CompileError : <NEWLINE> <TAB> ok = False <NEWLINE> <NEWLINE> <UNTAB> log . info ( ok and <STRING> or <STRING> ) <NEWLINE> self . _clean ( ) <NEWLINE> return ok <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def perplexity ( self ) : <NEWLINE> <TAB> <NEWLINE> return torch . exp ( self . entropy ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sets ( G , top_nodes = None ) : <NEWLINE> <TAB> <NEWLINE> if G . is_directed ( ) : <NEWLINE> <TAB> is_connected = nx . is_weakly_connected <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> is_connected = nx . is_connected <NEWLINE> <UNTAB> if top_nodes is not None : <NEWLINE> <TAB> X = set ( top_nodes ) <NEWLINE> Y = set ( G ) - X <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if not is_connected ( G ) : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise nx . AmbiguousSolution ( msg ) <NEWLINE> <UNTAB> c = color ( G ) <NEWLINE> X = { n for n , is_top in c . items ( ) if is_top } <NEWLINE> Y = { n for n , is_top in c . items ( ) if not is_top } <NEWLINE> <UNTAB> return ( X , Y ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def mark ( msg ) : <NEWLINE> <TAB> <NEWLINE> if _libnvToolsExt ( ) is None : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> return lib . nvtxMarkA ( ctypes . c_char_p ( msg . encode ( <STRING> ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _build_re_values ( ) : <NEWLINE> <TAB> quoted_re = <NEWLINE> <NEWLINE> value_re = r ' ' ' ( ? : 
                 % s |                     #   a   v a l u e   m a y   b e   s u r r o u n d e d   b y   " 
                 % s |                     #   o r   b y   ' 
                 [ ^ , \ s " ' { } ] +     #   o r   m a y   c o n t a i n   n o   c h a r a c t e r s   r e q u i r i n g   q u o t i n g 
                 ) ' ' ' % ( quoted_re , <NEWLINE> quoted_re . replace ( <STRING> , <STRING> ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> dense = re . compile ( r ' ' ' ( ? x ) 
                 ,                                 #   m a y   f o l l o w   ' , ' 
                 \ s * 
                 ( ( ? = , ) | $ | % ( v a l u e _ r e ) s )     #   e m p t y   o r   v a l u e 
                 | 
                 ( \ S . * )                       #   e r r o r 
                 ' ' ' % { <STRING> : value_re } ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> sparse = re . compile ( r ' ' ' ( ? x ) 
                 ( ? : ^ \ s * \ { | , )       #   m a y   f o l l o w   ' , ' ,   o r   ' { '   a t   l i n e   s t a r t 
                 \ s * 
                 ( \ d + )                     #   a t t r i b u t e   k e y 
                 \ s + 
                 ( % ( v a l u e _ r e ) s )   #   v a l u e 
                 | 
                 ( ? ! } \ s * $ )             #   n o t   a n   e r r o r   i f   i t ' s   } $ 
                 ( ? ! ^ \ s * { \ s * } \ s * $ )     #   n o t   a n   e r r o r   i f   i t ' s   ^ { } $ 
                 \ S . *                       #   e r r o r 
                 ' ' ' % { <STRING> : value_re } ) <NEWLINE> return dense , sparse <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def rotate ( self , angle , pt = None ) : <NEWLINE> <TAB> <NEWLINE> from sympy import cos , sin , Point <NEWLINE> <NEWLINE> c = cos ( angle ) <NEWLINE> s = sin ( angle ) <NEWLINE> <NEWLINE> rv = self <NEWLINE> if pt is not None : <NEWLINE> <TAB> pt = Point ( pt , dim = <NUMBER> ) <NEWLINE> rv -= pt <NEWLINE> <UNTAB> x , y = rv . args <NEWLINE> rv = Point ( c * x - s * y , s * x + c * y ) <NEWLINE> if pt is not None : <NEWLINE> <TAB> rv += pt <NEWLINE> <UNTAB> return rv <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def translate ( self , x = <NUMBER> , y = <NUMBER> , z = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return Point3D ( self . x + x , self . y + y , self . z + z ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def zeros ( shape , dtype = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . init_scope ( ) : <NEWLINE> <TAB> if dtype is None : <NEWLINE> <TAB> dtype = floatx ( ) <NEWLINE> <UNTAB> tf_dtype = dtypes_module . as_dtype ( dtype ) <NEWLINE> v = array_ops . zeros ( shape = shape , dtype = tf_dtype , name = name ) <NEWLINE> if py_all ( v . shape . as_list ( ) ) : <NEWLINE> <TAB> return variable ( v , dtype = dtype , name = name ) <NEWLINE> <UNTAB> track_variable ( v ) <NEWLINE> return v <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def roots_chebyu ( n , mu = False ) : <NEWLINE> <TAB> <NEWLINE> m = int ( n ) <NEWLINE> if n < <NUMBER> or n != m : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> t = np . arange ( m , <NUMBER> , - <NUMBER> ) * pi / ( m + <NUMBER> ) <NEWLINE> x = np . cos ( t ) <NEWLINE> w = pi * np . sin ( t ) ** <NUMBER> / ( m + <NUMBER> ) <NEWLINE> if mu : <NEWLINE> <TAB> return x , w , pi / <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return x , w <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def equality_constrained_sqp ( fun_and_constr , grad_and_jac , lagr_hess , <NEWLINE> x0 , fun0 , grad0 , constr0 , <NEWLINE> jac0 , stop_criteria , <NEWLINE> state , <NEWLINE> initial_penalty , <NEWLINE> initial_trust_radius , <NEWLINE> factorization_method , <NEWLINE> trust_lb = None , <NEWLINE> trust_ub = None , <NEWLINE> scaling = default_scaling ) : <NEWLINE> <TAB> <NEWLINE> PENALTY_FACTOR = <NUMBER> <NEWLINE> LARGE_REDUCTION_RATIO = <NUMBER> <NEWLINE> INTERMEDIARY_REDUCTION_RATIO = <NUMBER> <NEWLINE> SUFFICIENT_REDUCTION_RATIO = <NUMBER> <NEWLINE> TRUST_ENLARGEMENT_FACTOR_L = <NUMBER> <NEWLINE> TRUST_ENLARGEMENT_FACTOR_S = <NUMBER> <NEWLINE> MAX_TRUST_REDUCTION = <NUMBER> <NEWLINE> MIN_TRUST_REDUCTION = <NUMBER> <NEWLINE> SOC_THRESHOLD = <NUMBER> <NEWLINE> TR_FACTOR = <NUMBER> <NEWLINE> BOX_FACTOR = <NUMBER> <NEWLINE> <NEWLINE> n , = np . shape ( x0 ) <NEWLINE> <NEWLINE> <NEWLINE> if trust_lb is None : <NEWLINE> <TAB> trust_lb = np . full ( n , - np . inf ) <NEWLINE> <UNTAB> if trust_ub is None : <NEWLINE> <TAB> trust_ub = np . full ( n , np . inf ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> x = np . copy ( x0 ) <NEWLINE> trust_radius = initial_trust_radius <NEWLINE> penalty = initial_penalty <NEWLINE> <NEWLINE> f = fun0 <NEWLINE> c = grad0 <NEWLINE> b = constr0 <NEWLINE> A = jac0 <NEWLINE> S = scaling ( x ) <NEWLINE> <NEWLINE> Z , LS , Y = projections ( A , factorization_method ) <NEWLINE> <NEWLINE> v = - LS . dot ( c ) <NEWLINE> <NEWLINE> H = lagr_hess ( x , v ) <NEWLINE> <NEWLINE> <NEWLINE> optimality = norm ( c + A . T . dot ( v ) , np . inf ) <NEWLINE> constr_violation = norm ( b , np . inf ) if len ( b ) > <NUMBER> else <NUMBER> <NEWLINE> cg_info = { <STRING> : <NUMBER> , <STRING> : <NUMBER> , <NEWLINE> <STRING> : False } <NEWLINE> <NEWLINE> last_iteration_failed = False <NEWLINE> while not stop_criteria ( state , x , last_iteration_failed , <NEWLINE> optimality , constr_violation , <NEWLINE> trust_radius , penalty , cg_info ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> dn = modified_dogleg ( A , Y , b , <NEWLINE> TR_FACTOR * trust_radius , <NEWLINE> BOX_FACTOR * trust_lb , <NEWLINE> BOX_FACTOR * trust_ub ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> c_t = H . dot ( dn ) + c <NEWLINE> b_t = np . zeros_like ( b ) <NEWLINE> trust_radius_t = np . sqrt ( trust_radius ** <NUMBER> - np . linalg . norm ( dn ) ** <NUMBER> ) <NEWLINE> lb_t = trust_lb - dn <NEWLINE> ub_t = trust_ub - dn <NEWLINE> dt , cg_info = projected_cg ( H , c_t , Z , Y , b_t , <NEWLINE> trust_radius_t , <NEWLINE> lb_t , ub_t ) <NEWLINE> <NEWLINE> <NEWLINE> d = dn + dt <NEWLINE> <NEWLINE> <NEWLINE> quadratic_model = <NUMBER> / <NUMBER> * ( H . dot ( d ) ) . dot ( d ) + c . T . dot ( d ) <NEWLINE> <NEWLINE> linearized_constr = A . dot ( d ) + b <NEWLINE> <NEWLINE> <NEWLINE> vpred = norm ( b ) - norm ( linearized_constr ) <NEWLINE> <NEWLINE> <NEWLINE> vpred = max ( <NUMBER> , vpred ) <NEWLINE> previous_penalty = penalty <NEWLINE> if quadratic_model > <NUMBER> : <NEWLINE> <TAB> new_penalty = quadratic_model / ( ( <NUMBER> - PENALTY_FACTOR ) * vpred ) <NEWLINE> penalty = max ( penalty , new_penalty ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> predicted_reduction = - quadratic_model + penalty * vpred <NEWLINE> <NEWLINE> <NEWLINE> merit_function = f + penalty * norm ( b ) <NEWLINE> <NEWLINE> x_next = x + S . dot ( d ) <NEWLINE> f_next , b_next = fun_and_constr ( x_next ) <NEWLINE> <NEWLINE> merit_function_next = f_next + penalty * norm ( b_next ) <NEWLINE> <NEWLINE> <NEWLINE> actual_reduction = merit_function - merit_function_next <NEWLINE> <NEWLINE> reduction_ratio = actual_reduction / predicted_reduction <NEWLINE> <NEWLINE> <NEWLINE> if reduction_ratio < SUFFICIENT_REDUCTION_RATIO and norm ( dn ) <= SOC_THRESHOLD * norm ( dt ) : <NEWLINE> <NEWLINE> <TAB> y = - Y . dot ( b_next ) <NEWLINE> <NEWLINE> _ , t , intersect = box_intersections ( d , y , trust_lb , trust_ub ) <NEWLINE> <NEWLINE> x_soc = x + S . dot ( d + t * y ) <NEWLINE> f_soc , b_soc = fun_and_constr ( x_soc ) <NEWLINE> <NEWLINE> merit_function_soc = f_soc + penalty * norm ( b_soc ) <NEWLINE> actual_reduction_soc = merit_function - merit_function_soc <NEWLINE> <NEWLINE> reduction_ratio_soc = actual_reduction_soc / predicted_reduction <NEWLINE> if intersect and reduction_ratio_soc >= SUFFICIENT_REDUCTION_RATIO : <NEWLINE> <TAB> x_next = x_soc <NEWLINE> f_next = f_soc <NEWLINE> b_next = b_soc <NEWLINE> reduction_ratio = reduction_ratio_soc <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if reduction_ratio >= LARGE_REDUCTION_RATIO : <NEWLINE> <TAB> trust_radius = max ( TRUST_ENLARGEMENT_FACTOR_L * norm ( d ) , <NEWLINE> trust_radius ) <NEWLINE> <UNTAB> elif reduction_ratio >= INTERMEDIARY_REDUCTION_RATIO : <NEWLINE> <TAB> trust_radius = max ( TRUST_ENLARGEMENT_FACTOR_S * norm ( d ) , <NEWLINE> trust_radius ) <NEWLINE> <NEWLINE> <UNTAB> elif reduction_ratio < SUFFICIENT_REDUCTION_RATIO : <NEWLINE> <TAB> trust_reduction = ( <NUMBER> - SUFFICIENT_REDUCTION_RATIO ) / ( <NUMBER> - reduction_ratio ) <NEWLINE> new_trust_radius = trust_reduction * norm ( d ) <NEWLINE> if new_trust_radius >= MAX_TRUST_REDUCTION * trust_radius : <NEWLINE> <TAB> trust_radius *= MAX_TRUST_REDUCTION <NEWLINE> <UNTAB> elif new_trust_radius >= MIN_TRUST_REDUCTION * trust_radius : <NEWLINE> <TAB> trust_radius = new_trust_radius <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> trust_radius *= MIN_TRUST_REDUCTION <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if reduction_ratio >= SUFFICIENT_REDUCTION_RATIO : <NEWLINE> <TAB> x = x_next <NEWLINE> f , b = f_next , b_next <NEWLINE> c , A = grad_and_jac ( x ) <NEWLINE> S = scaling ( x ) <NEWLINE> <NEWLINE> Z , LS , Y = projections ( A , factorization_method ) <NEWLINE> <NEWLINE> v = - LS . dot ( c ) <NEWLINE> <NEWLINE> H = lagr_hess ( x , v ) <NEWLINE> <NEWLINE> last_iteration_failed = False <NEWLINE> <NEWLINE> optimality = norm ( c + A . T . dot ( v ) , np . inf ) <NEWLINE> constr_violation = norm ( b , np . inf ) if len ( b ) > <NUMBER> else <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> penalty = previous_penalty <NEWLINE> last_iteration_failed = True <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return x , state <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_init_tokens_op ( self , num_tokens = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if self . _gradients_applied is False : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> tokens_needed = self . _replicas_to_aggregate - self . _total_num_replicas <NEWLINE> if num_tokens == - <NUMBER> : <NEWLINE> <TAB> num_tokens = self . _replicas_to_aggregate <NEWLINE> <UNTAB> elif num_tokens < tokens_needed : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % <NEWLINE> ( num_tokens , tokens_needed ) ) <NEWLINE> <NEWLINE> <UNTAB> if num_tokens > <NUMBER> : <NEWLINE> <TAB> with ops . device ( self . _global_step . device ) , ops . name_scope ( <STRING> ) : <NEWLINE> <TAB> tokens = array_ops . fill ( [ num_tokens ] , self . _global_step ) <NEWLINE> init_tokens = self . _sync_token_queue . enqueue_many ( ( tokens , ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> init_tokens = control_flow_ops . no_op ( name = <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return init_tokens <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , num_gpus_per_worker = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> super ( ParameterServerStrategy , self ) . __init__ ( ) <NEWLINE> self . _num_gpus_per_worker = num_gpus_per_worker <NEWLINE> self . _initialize_local ( num_gpus_per_worker ) <NEWLINE> <NEWLINE> <NEWLINE> self . _cross_tower_ops = ( <NEWLINE> cross_tower_ops_lib . ReductionToOneDeviceCrossDeviceOps ( <NEWLINE> reduce_to_device = _LOCAL_CPU ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_push_pop ( ) : <NEWLINE> <TAB> <NEWLINE> push = copy . deepcopy ( PUSH ) <NEWLINE> pop = copy . deepcopy ( POP ) <NEWLINE> anno . setanno ( push , <STRING> , pop ) <NEWLINE> anno . setanno ( push , <STRING> , True ) <NEWLINE> anno . setanno ( pop , <STRING> , push ) <NEWLINE> op_id = _generate_op_id ( ) <NEWLINE> return push , pop , op_id <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dmp_gff_list ( f , u , K ) : <NEWLINE> <TAB> <NEWLINE> if not u : <NEWLINE> <TAB> return dup_gff_list ( f , K ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise MultivariatePolynomialError ( f ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , incoming_graph_data = None , ** attr ) : <NEWLINE> <TAB> <NEWLINE> self . node_dict_factory = self . node_dict_factory <NEWLINE> self . adjlist_outer_dict_factory = self . adjlist_outer_dict_factory <NEWLINE> self . adjlist_inner_dict_factory = self . adjlist_inner_dict_factory <NEWLINE> self . edge_attr_dict_factory = self . edge_attr_dict_factory <NEWLINE> <NEWLINE> self . graph = { } <NEWLINE> self . _node = self . node_dict_factory ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . _adj = self . adjlist_outer_dict_factory ( ) <NEWLINE> self . _pred = self . adjlist_outer_dict_factory ( ) <NEWLINE> self . _succ = self . _adj <NEWLINE> <NEWLINE> <NEWLINE> if incoming_graph_data is not None : <NEWLINE> <TAB> convert . to_networkx_graph ( incoming_graph_data , create_using = self ) <NEWLINE> <NEWLINE> <UNTAB> self . graph . update ( attr ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_navigate ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _navigate <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def rem ( self , a , b ) : <NEWLINE> <TAB> <NEWLINE> return self . zero <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def maximum_eager_fallback ( x , y , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ x , y ] , _ctx ) <NEWLINE> ( x , y ) = _inputs_T <NEWLINE> _inputs_flat = [ x , y ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _low_degree_nodes ( G , k , nbunch = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if G . is_directed ( ) : <NEWLINE> <NEWLINE> <TAB> seen = set ( ) <NEWLINE> for node , degree in G . out_degree ( nbunch ) : <NEWLINE> <TAB> if degree < k : <NEWLINE> <TAB> seen . add ( node ) <NEWLINE> yield node <NEWLINE> <UNTAB> <UNTAB> for node , degree in G . in_degree ( nbunch ) : <NEWLINE> <TAB> if node not in seen and degree < k : <NEWLINE> <TAB> seen . add ( node ) <NEWLINE> yield node <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> for node , degree in G . degree ( nbunch ) : <NEWLINE> <TAB> if degree < k : <NEWLINE> <TAB> yield node <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def engine_disposed ( self , engine ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_window_extent ( self , renderer ) : <NEWLINE> <TAB> <NEWLINE> w , h , xd , yd = self . get_extent ( renderer ) <NEWLINE> ox , oy = self . get_offset ( ) <NEWLINE> return mtransforms . Bbox . from_bounds ( ox - xd , oy - yd , w , h ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def trace ( expr ) : <NEWLINE> <TAB> <NEWLINE> return Trace ( expr ) . doit ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def digamma ( x ) : <NEWLINE> <TAB> <NEWLINE> return DiGamma ( ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __round__ ( self , ndigits = None ) : <NEWLINE> <TAB> <NEWLINE> if ndigits is None : <NEWLINE> <TAB> floor , remainder = divmod ( self . numerator , self . denominator ) <NEWLINE> if remainder * <NUMBER> < self . denominator : <NEWLINE> <TAB> return floor <NEWLINE> <UNTAB> elif remainder * <NUMBER> > self . denominator : <NEWLINE> <TAB> return floor + <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> elif floor % <NUMBER> == <NUMBER> : <NEWLINE> <TAB> return floor <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return floor + <NUMBER> <NEWLINE> <UNTAB> <UNTAB> shift = <NUMBER> ** abs ( ndigits ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if ndigits > <NUMBER> : <NEWLINE> <TAB> return Fraction ( round ( self * shift ) , shift ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return Fraction ( round ( self / shift ) * shift ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def write ( self , file_content ) : <NEWLINE> <TAB> <NEWLINE> self . _prewrite_check ( ) <NEWLINE> with errors . raise_exception_on_not_ok_status ( ) as status : <NEWLINE> <TAB> pywrap_tensorflow . AppendToFile ( <NEWLINE> compat . as_bytes ( file_content ) , self . _writable_file , status ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def draw_bbox ( bbox , renderer , color = <STRING> , trans = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> l , b , w , h = bbox . bounds <NEWLINE> r = Rectangle ( xy = ( l , b ) , <NEWLINE> width = w , <NEWLINE> height = h , <NEWLINE> edgecolor = color , <NEWLINE> fill = False , <NEWLINE> ) <NEWLINE> if trans is not None : <NEWLINE> <TAB> r . set_transform ( trans ) <NEWLINE> <UNTAB> r . set_clip_on ( False ) <NEWLINE> r . draw ( renderer ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_immutable ( self ) : <NEWLINE> <TAB> <NEWLINE> from . immutable import ImmutableSparseMatrix <NEWLINE> return ImmutableSparseMatrix ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __copy__ ( self ) : <NEWLINE> <TAB> <NEWLINE> other = self . __class__ ( <NEWLINE> linkers = [ copy ( l ) for l in self . linkers ] , <NEWLINE> wrapper = self . wrapper ) <NEWLINE> return other <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def batched_dot ( a , b ) : <NEWLINE> <TAB> <NEWLINE> a , b = as_tensor_variable ( a ) , as_tensor_variable ( b ) <NEWLINE> <NEWLINE> if a . ndim == <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> elif b . ndim == <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> elif a . ndim == <NUMBER> : <NEWLINE> <TAB> return a . dimshuffle ( * ( [ <NUMBER> ] + [ <STRING> ] * ( b . ndim - <NUMBER> ) ) ) * b <NEWLINE> <UNTAB> elif b . ndim == <NUMBER> : <NEWLINE> <TAB> return a * b . dimshuffle ( * ( [ <NUMBER> ] + [ <STRING> ] * ( a . ndim - <NUMBER> ) ) ) <NEWLINE> <UNTAB> elif a . ndim > <NUMBER> or b . ndim > <NUMBER> : <NEWLINE> <TAB> return batched_tensordot ( <NEWLINE> a , b , [ [ a . ndim - <NUMBER> ] , [ np . maximum ( <NUMBER> , b . ndim - <NUMBER> ) ] ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> return theano . tensor . blas . BatchedDot ( ) ( a , b ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def has ( self , * patterns ) : <NEWLINE> <TAB> <NEWLINE> return self . _eval_has ( * patterns ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_width_height ( self ) : <NEWLINE> <TAB> <NEWLINE> return int ( self . figure . bbox . width ) , int ( self . figure . bbox . height ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def spectral_layout ( G , weight = <STRING> , scale = <NUMBER> , center = None , dim = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> import numpy as np <NEWLINE> <NEWLINE> G , center = _process_params ( G , center , dim ) <NEWLINE> <NEWLINE> if len ( G ) <= <NUMBER> : <NEWLINE> <TAB> if len ( G ) == <NUMBER> : <NEWLINE> <TAB> pos = np . array ( [ ] ) <NEWLINE> <UNTAB> elif len ( G ) == <NUMBER> : <NEWLINE> <TAB> pos = np . array ( [ center ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pos = np . array ( [ np . zeros ( dim ) , np . array ( center ) * <NUMBER> ] ) <NEWLINE> <UNTAB> return dict ( zip ( G , pos ) ) <NEWLINE> <UNTAB> try : <NEWLINE> <NEWLINE> <TAB> if len ( G ) < <NUMBER> : <NEWLINE> <TAB> raise ValueError <NEWLINE> <UNTAB> A = nx . to_scipy_sparse_matrix ( G , weight = weight , dtype = <STRING> ) <NEWLINE> <NEWLINE> if G . is_directed ( ) : <NEWLINE> <TAB> A = A + np . transpose ( A ) <NEWLINE> <UNTAB> pos = _sparse_spectral ( A , dim ) <NEWLINE> <UNTAB> except ( ImportError , ValueError ) : <NEWLINE> <NEWLINE> <TAB> A = nx . to_numpy_array ( G , weight = weight ) <NEWLINE> <NEWLINE> if G . is_directed ( ) : <NEWLINE> <TAB> A += A . T <NEWLINE> <UNTAB> pos = _spectral ( A , dim ) <NEWLINE> <NEWLINE> <UNTAB> pos = rescale_layout ( pos , scale ) + center <NEWLINE> pos = dict ( zip ( G , pos ) ) <NEWLINE> return pos <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def prod ( self , axis = None , dtype = None , keepdims = False , acc_dtype = None ) : <NEWLINE> <TAB> <NEWLINE> return theano . tensor . basic . prod ( self , axis = axis , <NEWLINE> dtype = dtype , keepdims = keepdims , <NEWLINE> acc_dtype = acc_dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def projections ( A , method = None , orth_tol = <NUMBER> , max_refin = <NUMBER> , tol = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> m , n = np . shape ( A ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if m * n == <NUMBER> : <NEWLINE> <TAB> A = csc_matrix ( A ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if issparse ( A ) : <NEWLINE> <TAB> if method is None : <NEWLINE> <TAB> method = <STRING> <NEWLINE> <UNTAB> if method not in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if method == <STRING> and not sksparse_available : <NEWLINE> <TAB> warnings . warn ( ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) , <NEWLINE> ImportWarning ) <NEWLINE> method = <STRING> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if method is None : <NEWLINE> <TAB> method = <STRING> <NEWLINE> <UNTAB> if method not in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if method == <STRING> : <NEWLINE> <TAB> null_space , least_squares , row_space = normal_equation_projections ( A , m , n , orth_tol , max_refin , tol ) <NEWLINE> <UNTAB> elif method == <STRING> : <NEWLINE> <TAB> null_space , least_squares , row_space = augmented_system_projections ( A , m , n , orth_tol , max_refin , tol ) <NEWLINE> <UNTAB> elif method == <STRING> : <NEWLINE> <TAB> null_space , least_squares , row_space = qr_factorization_projections ( A , m , n , orth_tol , max_refin , tol ) <NEWLINE> <UNTAB> elif method == <STRING> : <NEWLINE> <TAB> null_space , least_squares , row_space = svd_factorization_projections ( A , m , n , orth_tol , max_refin , tol ) <NEWLINE> <NEWLINE> <UNTAB> Z = LinearOperator ( ( n , n ) , null_space ) <NEWLINE> LS = LinearOperator ( ( m , n ) , least_squares ) <NEWLINE> Y = LinearOperator ( ( n , m ) , row_space ) <NEWLINE> <NEWLINE> return Z , LS , Y <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def after_create ( self , target , connection , ** kw ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __len__ ( self ) : <NEWLINE> <TAB> <NEWLINE> return len ( self . _children ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_poly ( self , x = None ) : <NEWLINE> <TAB> <NEWLINE> from sympy import Dummy , Poly , PurePoly <NEWLINE> if x is not None : <NEWLINE> <TAB> return Poly . new ( self . rep , x ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if self . alias is not None : <NEWLINE> <TAB> return Poly . new ( self . rep , self . alias ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return PurePoly . new ( self . rep , Dummy ( <STRING> ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , reduce_to_device = None , accumulation_fn = math_ops . add_n ) : <NEWLINE> <TAB> <NEWLINE> self . reduce_to_device = reduce_to_device <NEWLINE> self . accumulation_fn = accumulation_fn <NEWLINE> super ( ReductionToOneDeviceCrossDeviceOps , self ) . __init__ ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _from_iter ( cls , label , itr ) : <NEWLINE> <TAB> <NEWLINE> ret = cls ( None ) <NEWLINE> ret . _left = list ( { label : v } for v in itr ) <NEWLINE> ret . _keys = set ( [ label ] ) <NEWLINE> return ret <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def winfo_pathname ( self , id , displayof = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> args = ( <STRING> , <STRING> ) + self . _displayof ( displayof ) + ( id , ) <NEWLINE> return self . tk . call ( args ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _float_zeros_like ( x ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> rval = x . zeros_like ( ) <NEWLINE> <NEWLINE> if rval . type . dtype . find ( <STRING> ) != - <NUMBER> : <NEWLINE> <TAB> return rval <NEWLINE> <NEWLINE> <UNTAB> return rval . astype ( theano . config . floatX ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_FF_python ( K1 , a , K0 ) : <NEWLINE> <TAB> <NEWLINE> return GMPYInteger ( a . to_int ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def unique_name ( self , name , mark_as_used = True ) : <NEWLINE> <TAB> <NEWLINE> if self . _name_stack : <NEWLINE> <TAB> name = self . _name_stack + <STRING> + name <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> name_key = name . lower ( ) <NEWLINE> i = self . _names_in_use . get ( name_key , <NUMBER> ) <NEWLINE> <NEWLINE> if mark_as_used : <NEWLINE> <TAB> self . _names_in_use [ name_key ] = i + <NUMBER> <NEWLINE> <UNTAB> if i > <NUMBER> : <NEWLINE> <TAB> base_name_key = name_key <NEWLINE> <NEWLINE> while name_key in self . _names_in_use : <NEWLINE> <TAB> name_key = <STRING> % ( base_name_key , i ) <NEWLINE> i += <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if mark_as_used : <NEWLINE> <TAB> self . _names_in_use [ name_key ] = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> name = <STRING> % ( name , i - <NUMBER> ) <NEWLINE> <UNTAB> return name <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def read_up_to ( self , queue , num_records , name = None ) : <NEWLINE> <TAB> <NEWLINE> self . _configure_readers_by ( queue ) <NEWLINE> return self . _common_queue . dequeue_up_to ( num_records , name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , ** storage_options ) : <NEWLINE> <TAB> <NEWLINE> self . cwd = os . getcwd ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set ( self , locs , values , check = False ) : <NEWLINE> <TAB> <NEWLINE> self . values [ locs ] = values <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def non_edges ( graph ) : <NEWLINE> <TAB> <NEWLINE> if graph . is_directed ( ) : <NEWLINE> <TAB> for u in graph : <NEWLINE> <TAB> for v in non_neighbors ( graph , u ) : <NEWLINE> <TAB> yield ( u , v ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> nodes = set ( graph ) <NEWLINE> while nodes : <NEWLINE> <TAB> u = nodes . pop ( ) <NEWLINE> for v in nodes - set ( graph [ u ] ) : <NEWLINE> <TAB> yield ( u , v ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def configure ( self , n_jobs = <NUMBER> , parallel = None , ** backend_args ) : <NEWLINE> <TAB> <NEWLINE> n_jobs = self . effective_n_jobs ( n_jobs ) <NEWLINE> if n_jobs == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> raise FallbackToBackend ( <NEWLINE> SequentialBackend ( nesting_level = self . nesting_level ) ) <NEWLINE> <UNTAB> self . parallel = parallel <NEWLINE> self . _n_jobs = n_jobs <NEWLINE> return n_jobs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def winfo_geometry ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . tk . call ( <STRING> , <STRING> , self . _w ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def invert ( image , signed_float = False ) : <NEWLINE> <TAB> <NEWLINE> if image . dtype == <STRING> : <NEWLINE> <TAB> inverted = ~ image <NEWLINE> <UNTAB> elif np . issubdtype ( image . dtype , np . unsignedinteger ) : <NEWLINE> <TAB> max_val = dtype_limits ( image , clip_negative = False ) [ <NUMBER> ] <NEWLINE> inverted = np . subtract ( max_val , image , dtype = image . dtype ) <NEWLINE> <UNTAB> elif np . issubdtype ( image . dtype , np . signedinteger ) : <NEWLINE> <TAB> inverted = np . subtract ( - <NUMBER> , image , dtype = image . dtype ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if signed_float : <NEWLINE> <TAB> inverted = - image <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> inverted = np . subtract ( <NUMBER> , image , dtype = image . dtype ) <NEWLINE> <UNTAB> <UNTAB> return inverted <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def call ( self , inputs , state ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> gate_inputs = math_ops . matmul ( inputs , self . _kernel_w ) + ( <NEWLINE> state * self . _kernel_u ) <NEWLINE> gate_inputs = nn_ops . bias_add ( gate_inputs , self . _bias ) <NEWLINE> output = self . _activation ( gate_inputs ) <NEWLINE> return output , output <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gf_mul_ground ( f , a , p , K ) : <NEWLINE> <TAB> <NEWLINE> if not a : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return [ ( a * b ) % p for b in f ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def vpack ( self , h = <NUMBER> , m = <STRING> , l = np . inf ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> w = <NUMBER> <NEWLINE> d = <NUMBER> <NEWLINE> x = <NUMBER> <NEWLINE> total_stretch = [ <NUMBER> ] * <NUMBER> <NEWLINE> total_shrink = [ <NUMBER> ] * <NUMBER> <NEWLINE> for p in self . children : <NEWLINE> <TAB> if isinstance ( p , Box ) : <NEWLINE> <TAB> x += d + p . height <NEWLINE> d = p . depth <NEWLINE> if not np . isinf ( p . width ) : <NEWLINE> <TAB> s = getattr ( p , <STRING> , <NUMBER> ) <NEWLINE> w = max ( w , p . width + s ) <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( p , Glue ) : <NEWLINE> <TAB> x += d <NEWLINE> d = <NUMBER> <NEWLINE> glue_spec = p . glue_spec <NEWLINE> x += glue_spec . width <NEWLINE> total_stretch [ glue_spec . stretch_order ] += glue_spec . stretch <NEWLINE> total_shrink [ glue_spec . shrink_order ] += glue_spec . shrink <NEWLINE> <UNTAB> elif isinstance ( p , Kern ) : <NEWLINE> <TAB> x += d + p . width <NEWLINE> d = <NUMBER> <NEWLINE> <UNTAB> elif isinstance ( p , Char ) : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . width = w <NEWLINE> if d > l : <NEWLINE> <TAB> x += d - l <NEWLINE> self . depth = l <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . depth = d <NEWLINE> <NEWLINE> <UNTAB> if m == <STRING> : <NEWLINE> <TAB> h += x <NEWLINE> <UNTAB> self . height = h <NEWLINE> x = h - x <NEWLINE> <NEWLINE> if x == <NUMBER> : <NEWLINE> <TAB> self . glue_sign = <NUMBER> <NEWLINE> self . glue_order = <NUMBER> <NEWLINE> self . glue_ratio = <NUMBER> <NEWLINE> return <NEWLINE> <NEWLINE> <UNTAB> if x > <NUMBER> : <NEWLINE> <TAB> self . _set_glue ( x , <NUMBER> , total_stretch , <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _set_glue ( x , - <NUMBER> , total_shrink , <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _ith_point ( self , i ) : <NEWLINE> <TAB> <NEWLINE> if self . start is S . NegativeInfinity : <NEWLINE> <TAB> initial = self . stop <NEWLINE> step = - <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> initial = self . start <NEWLINE> step = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> return initial + i * step <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def matshow ( A , fignum = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> A = np . asanyarray ( A ) <NEWLINE> if fignum is False or fignum is <NUMBER> : <NEWLINE> <TAB> ax = gca ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> fig = figure ( fignum , figsize = figaspect ( A ) ) <NEWLINE> ax = fig . add_axes ( [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] ) <NEWLINE> <NEWLINE> <UNTAB> im = ax . matshow ( A , ** kwargs ) <NEWLINE> sci ( im ) <NEWLINE> <NEWLINE> return im <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def GetWhileContext ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _outer_context : <NEWLINE> <TAB> return self . _outer_context . GetWhileContext ( ) <NEWLINE> <UNTAB> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _eval_as_set ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . args [ <NUMBER> ] . as_set ( ) . complement ( S . Reals ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def update ( * args , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if not args : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> self , * args = args <NEWLINE> if len ( args ) > <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> % len ( args ) ) <NEWLINE> <UNTAB> iterable = args [ <NUMBER> ] if args else None <NEWLINE> if iterable is not None : <NEWLINE> <TAB> if isinstance ( iterable , Mapping ) : <NEWLINE> <TAB> if self : <NEWLINE> <TAB> self_get = self . get <NEWLINE> for elem , count in iterable . items ( ) : <NEWLINE> <TAB> self [ elem ] = count + self_get ( elem , <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> super ( Counter , self ) . update ( iterable ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> _count_elements ( self , iterable ) <NEWLINE> <UNTAB> <UNTAB> if kwds : <NEWLINE> <TAB> self . update ( kwds ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _transform_feature ( self , inputs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def _collect_leaf_level_columns ( cross ) : <NEWLINE> <TAB> <NEWLINE> leaf_level_columns = [ ] <NEWLINE> for c in cross . columns : <NEWLINE> <TAB> if isinstance ( c , _CrossedColumn ) : <NEWLINE> <TAB> leaf_level_columns . extend ( _collect_leaf_level_columns ( c ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> leaf_level_columns . append ( c ) <NEWLINE> <UNTAB> <UNTAB> return leaf_level_columns <NEWLINE> <NEWLINE> <UNTAB> feature_tensors = [ ] <NEWLINE> for c in _collect_leaf_level_columns ( self ) : <NEWLINE> <TAB> if isinstance ( c , _SparseColumn ) : <NEWLINE> <TAB> feature_tensors . append ( inputs . get ( c . name ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if isinstance ( c , _BucketizedColumn ) : <NEWLINE> <TAB> feature_tensors . append ( c . to_sparse_tensor ( inputs . get ( c ) ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> feature_tensors . append ( inputs . get ( c ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return sparse_feature_cross_op . sparse_feature_cross ( <NEWLINE> feature_tensors , <NEWLINE> hashed_output = True , <NEWLINE> num_buckets = self . hash_bucket_size , <NEWLINE> hash_key = self . hash_key , <NEWLINE> name = <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def JoinableQueue ( self , maxsize = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> from . queues import JoinableQueue <NEWLINE> return JoinableQueue ( maxsize , ctx = self . get_context ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def getstate ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . VERSION , super ( ) . getstate ( ) , self . gauss_next <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , vmin = None , vmax = None , clip = False ) : <NEWLINE> <TAB> <NEWLINE> self . vmin = _sanitize_extrema ( vmin ) <NEWLINE> self . vmax = _sanitize_extrema ( vmax ) <NEWLINE> self . clip = clip <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_fontname ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _fontproperties . get_name ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _write_array_header ( fp , d , version = None ) : <NEWLINE> <TAB> <NEWLINE> import struct <NEWLINE> header = [ <STRING> ] <NEWLINE> for key , value in sorted ( d . items ( ) ) : <NEWLINE> <NEWLINE> <TAB> header . append ( <STRING> % ( key , repr ( value ) ) ) <NEWLINE> <UNTAB> header . append ( <STRING> ) <NEWLINE> header = <STRING> . join ( header ) <NEWLINE> header = asbytes ( _filter_header ( header ) ) <NEWLINE> <NEWLINE> hlen = len ( header ) + <NUMBER> <NEWLINE> padlen_v1 = ARRAY_ALIGN - ( ( MAGIC_LEN + struct . calcsize ( <STRING> ) + hlen ) % ARRAY_ALIGN ) <NEWLINE> padlen_v2 = ARRAY_ALIGN - ( ( MAGIC_LEN + struct . calcsize ( <STRING> ) + hlen ) % ARRAY_ALIGN ) <NEWLINE> <NEWLINE> <NEWLINE> if hlen + padlen_v1 < <NUMBER> ** <NUMBER> and version in ( None , ( <NUMBER> , <NUMBER> ) ) : <NEWLINE> <TAB> version = ( <NUMBER> , <NUMBER> ) <NEWLINE> header_prefix = magic ( <NUMBER> , <NUMBER> ) + struct . pack ( <STRING> , hlen + padlen_v1 ) <NEWLINE> topad = padlen_v1 <NEWLINE> <UNTAB> elif hlen + padlen_v2 < <NUMBER> ** <NUMBER> and version in ( None , ( <NUMBER> , <NUMBER> ) ) : <NEWLINE> <TAB> version = ( <NUMBER> , <NUMBER> ) <NEWLINE> header_prefix = magic ( <NUMBER> , <NUMBER> ) + struct . pack ( <STRING> , hlen + padlen_v2 ) <NEWLINE> topad = padlen_v2 <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> msg %= ( hlen , version ) <NEWLINE> raise ValueError ( msg ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> header = header + <STRING> * topad + <STRING> <NEWLINE> <NEWLINE> fp . write ( header_prefix ) <NEWLINE> fp . write ( header ) <NEWLINE> return version <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def fixed_point ( func , x0 , args = ( ) , xtol = <NUMBER> , maxiter = <NUMBER> , method = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> use_accel = { <STRING> : True , <STRING> : False } [ method ] <NEWLINE> x0 = _asarray_validated ( x0 , as_inexact = True ) <NEWLINE> return _fixed_point_helper ( func , x0 , args , xtol , maxiter , use_accel ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def advise ( self , options ) : <NEWLINE> <TAB> <NEWLINE> advise_pb = tfprof_output_pb2 . AdviceProto ( ) <NEWLINE> opts = _build_advisor_options ( options ) <NEWLINE> advise_pb . ParseFromString ( <NEWLINE> print_mdl . Profile ( <STRING> . encode ( <STRING> ) , opts . SerializeToString ( ) ) ) <NEWLINE> return advise_pb <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def as_strided ( x , shape = None , strides = None , subok = False , writeable = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> x = np . array ( x , copy = False , subok = subok ) <NEWLINE> interface = dict ( x . __array_interface__ ) <NEWLINE> if shape is not None : <NEWLINE> <TAB> interface [ <STRING> ] = tuple ( shape ) <NEWLINE> <UNTAB> if strides is not None : <NEWLINE> <TAB> interface [ <STRING> ] = tuple ( strides ) <NEWLINE> <NEWLINE> <UNTAB> array = np . asarray ( DummyArray ( interface , base = x ) ) <NEWLINE> <NEWLINE> <NEWLINE> array . dtype = x . dtype <NEWLINE> <NEWLINE> view = _maybe_view_as_subclass ( x , array ) <NEWLINE> <NEWLINE> if view . flags . writeable and not writeable : <NEWLINE> <TAB> view . flags . writeable = False <NEWLINE> <NEWLINE> <UNTAB> return view <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def clear ( self , warn = True ) : <NEWLINE> <TAB> <NEWLINE> func_id = _build_func_identifier ( self . func ) <NEWLINE> <NEWLINE> if self . _verbose > <NUMBER> and warn : <NEWLINE> <TAB> self . warn ( <STRING> % func_id ) <NEWLINE> <UNTAB> self . store_backend . clear_path ( [ func_id , ] ) <NEWLINE> <NEWLINE> func_code , _ , first_line = get_func_code ( self . func ) <NEWLINE> self . _write_func_code ( func_code , first_line ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def read ( self , queue , name = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . _configure_readers_by ( queue ) <NEWLINE> return self . _common_queue . dequeue ( name = name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_logger ( self ) : <NEWLINE> <TAB> <NEWLINE> from . util import get_logger <NEWLINE> return get_logger ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_timestamp ( self , freq = None , how = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> how = _validate_end_alias ( how ) <NEWLINE> <NEWLINE> if freq is None : <NEWLINE> <TAB> base , mult = _gfc ( self . freq ) <NEWLINE> freq = frequencies . get_to_timestamp_base ( base ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> freq = Period . _maybe_convert_freq ( freq ) <NEWLINE> <NEWLINE> <UNTAB> base , mult = _gfc ( freq ) <NEWLINE> new_data = self . asfreq ( freq , how ) <NEWLINE> <NEWLINE> new_data = period . periodarr_to_dt64arr ( new_data . _ndarray_values , base ) <NEWLINE> return DatetimeIndex ( new_data , freq = <STRING> , name = self . name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_data_ratio_log ( self ) : <NEWLINE> <TAB> <NEWLINE> xmin , xmax = self . get_xbound ( ) <NEWLINE> ymin , ymax = self . get_ybound ( ) <NEWLINE> <NEWLINE> xsize = max ( abs ( math . log10 ( xmax ) - math . log10 ( xmin ) ) , <NUMBER> ) <NEWLINE> ysize = max ( abs ( math . log10 ( ymax ) - math . log10 ( ymin ) ) , <NUMBER> ) <NEWLINE> <NEWLINE> return ysize / xsize <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def update ( self , param ) : <NEWLINE> <TAB> <NEWLINE> if not self . enabled : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> self . t += <NUMBER> <NEWLINE> <NEWLINE> if self . _use_fp32_update and param . dtype == numpy . float16 : <NEWLINE> <TAB> if self . _fp32_param is None : <NEWLINE> <TAB> self . _fp32_param = variable . Variable ( <NEWLINE> param . array . astype ( numpy . float32 ) , <NEWLINE> name = param . name ) <NEWLINE> <UNTAB> fp32_param = self . _fp32_param <NEWLINE> fp32_param . grad = param . grad . astype ( numpy . float32 ) <NEWLINE> <NEWLINE> if fp32_param . data is not None : <NEWLINE> <TAB> self . _prepare ( fp32_param ) <NEWLINE> <UNTAB> if param . _loss_scale is not None : <NEWLINE> <TAB> fp32_param . grad /= param . _loss_scale <NEWLINE> <UNTAB> for hook in six . itervalues ( self . _pre_update_hooks ) : <NEWLINE> <TAB> hook ( self , fp32_param ) <NEWLINE> <UNTAB> self . update_core ( fp32_param ) <NEWLINE> for hook in six . itervalues ( self . _post_update_hooks ) : <NEWLINE> <TAB> hook ( self , fp32_param ) <NEWLINE> <NEWLINE> <UNTAB> param . data = fp32_param . data . astype ( param . dtype ) <NEWLINE> fp32_param . grad = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if param . data is not None : <NEWLINE> <TAB> self . _prepare ( param ) <NEWLINE> <UNTAB> if param . _loss_scale is not None : <NEWLINE> <TAB> param . grad /= param . _loss_scale <NEWLINE> <UNTAB> for hook in six . itervalues ( self . _pre_update_hooks ) : <NEWLINE> <TAB> hook ( self , param ) <NEWLINE> <UNTAB> self . update_core ( param ) <NEWLINE> for hook in six . itervalues ( self . _post_update_hooks ) : <NEWLINE> <TAB> hook ( self , param ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def inject_addons ( self ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _scipy_univariate_kde ( data , bw , gridsize , cut , clip ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> kde = stats . gaussian_kde ( data , bw_method = bw ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> kde = stats . gaussian_kde ( data ) <NEWLINE> if bw != <STRING> : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> warnings . warn ( msg , UserWarning ) <NEWLINE> <UNTAB> <UNTAB> if isinstance ( bw , string_types ) : <NEWLINE> <TAB> bw = <STRING> if bw == <STRING> else bw <NEWLINE> bw = getattr ( kde , <STRING> % bw ) ( ) * np . std ( data ) <NEWLINE> <UNTAB> grid = _kde_support ( data , bw , gridsize , cut , clip ) <NEWLINE> y = kde ( grid ) <NEWLINE> return grid , y <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def lagrangian_hessian_x ( self , z , v ) : <NEWLINE> <TAB> <NEWLINE> x = self . get_variables ( z ) <NEWLINE> <NEWLINE> v_eq = v [ : self . n_eq ] <NEWLINE> <NEWLINE> v_ineq = v [ self . n_eq : self . n_eq + self . n_ineq ] <NEWLINE> lagr_hess = self . lagr_hess <NEWLINE> return lagr_hess ( x , v_eq , v_ineq ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def greater ( x1 , x2 ) : <NEWLINE> <TAB> <NEWLINE> return compare_chararrays ( x1 , x2 , <STRING> , True ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def convert ( self , copy = True , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return self . copy ( ) if copy else self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _tf_to_cudnn_weights ( self , layer , * tf_weights ) : <NEWLINE> <TAB> <NEWLINE> input_size = self . _input_size <NEWLINE> num_units = self . _num_units <NEWLINE> if layer == <NUMBER> : <NEWLINE> <TAB> input_weight_width = input_size <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> input_weight_width = num_units <NEWLINE> if self . _direction == CUDNN_RNN_BIDIRECTION : <NEWLINE> <TAB> input_weight_width *= <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> ( tf_weight , ) = tf_weights <NEWLINE> <NEWLINE> W = array_ops . transpose ( tf_weight ) <NEWLINE> w_i , w_h = array_ops . split ( W , [ input_weight_width , num_units ] , axis = <NUMBER> ) <NEWLINE> return w_i , w_h <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def scale_count ( self , density , counts , scale_hue ) : <NEWLINE> <TAB> <NEWLINE> if self . hue_names is None : <NEWLINE> <TAB> if counts . max ( ) == <NUMBER> : <NEWLINE> <TAB> d = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for count , d in zip ( counts , density ) : <NEWLINE> <TAB> d /= d . max ( ) <NEWLINE> d *= count / counts . max ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for i , group in enumerate ( density ) : <NEWLINE> <TAB> for j , d in enumerate ( group ) : <NEWLINE> <TAB> if counts [ i ] . max ( ) == <NUMBER> : <NEWLINE> <TAB> d = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> count = counts [ i , j ] <NEWLINE> if scale_hue : <NEWLINE> <TAB> scaler = count / counts [ i ] . max ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> scaler = count / counts . max ( ) <NEWLINE> <UNTAB> d /= d . max ( ) <NEWLINE> d *= scaler <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def c_support_code ( self ) : <NEWLINE> <TAB> <NEWLINE> raise utils . MethodNotDefined ( <NEWLINE> <STRING> , <NEWLINE> type ( self ) , <NEWLINE> self . __class__ . __name__ ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def bottom_up_once ( rule , fns = basic_fns ) : <NEWLINE> <TAB> <NEWLINE> return do_one ( lambda expr : sall ( bottom_up ( rule , fns ) , fns ) ( expr ) , rule ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _check_percentile ( self , q ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> q = np . asarray ( q ) <NEWLINE> if q . ndim == <NUMBER> : <NEWLINE> <TAB> if not <NUMBER> <= q <= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( msg . format ( q / <NUMBER> ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if not all ( <NUMBER> <= qs <= <NUMBER> for qs in q ) : <NEWLINE> <TAB> raise ValueError ( msg . format ( q / <NUMBER> ) ) <NEWLINE> <UNTAB> <UNTAB> return q <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def resolve ( self , types ) : <NEWLINE> <TAB> <NEWLINE> warn ( <STRING> , <NEWLINE> DeprecationWarning ) <NEWLINE> <NEWLINE> return self . dispatch ( * types ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sum ( a , axis = None , dtype = None , out = None , keepdims = np . _NoValue ) : <NEWLINE> <TAB> <NEWLINE> kwargs = { } <NEWLINE> if keepdims is not np . _NoValue : <NEWLINE> <TAB> kwargs [ <STRING> ] = keepdims <NEWLINE> <UNTAB> if isinstance ( a , _gentype ) : <NEWLINE> <TAB> res = _sum_ ( a ) <NEWLINE> if out is not None : <NEWLINE> <TAB> out [ ... ] = res <NEWLINE> return out <NEWLINE> <UNTAB> return res <NEWLINE> <UNTAB> if type ( a ) is not mu . ndarray : <NEWLINE> <TAB> try : <NEWLINE> <TAB> sum = a . sum <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return sum ( axis = axis , dtype = dtype , out = out , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> return _methods . _sum ( a , axis = axis , dtype = dtype , <NEWLINE> out = out , ** kwargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def check_graphs ( * args ) : <NEWLINE> <TAB> <NEWLINE> graph = None <NEWLINE> for i , sgv in enumerate ( args ) : <NEWLINE> <TAB> if graph is None and sgv . graph is not None : <NEWLINE> <TAB> graph = sgv . graph <NEWLINE> <UNTAB> elif sgv . graph is not None and sgv . graph is not graph : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( i ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def warp_coords ( coord_map , shape , dtype = np . float64 ) : <NEWLINE> <TAB> <NEWLINE> shape = safe_as_int ( shape ) <NEWLINE> rows , cols = shape [ <NUMBER> ] , shape [ <NUMBER> ] <NEWLINE> coords_shape = [ len ( shape ) , rows , cols ] <NEWLINE> if len ( shape ) == <NUMBER> : <NEWLINE> <TAB> coords_shape . append ( shape [ <NUMBER> ] ) <NEWLINE> <UNTAB> coords = np . empty ( coords_shape , dtype = dtype ) <NEWLINE> <NEWLINE> <NEWLINE> tf_coords = np . indices ( ( cols , rows ) , dtype = dtype ) . reshape ( <NUMBER> , - <NUMBER> ) . T <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> tf_coords = coord_map ( tf_coords ) <NEWLINE> <NEWLINE> <NEWLINE> tf_coords = tf_coords . T . reshape ( ( - <NUMBER> , cols , rows ) ) . swapaxes ( <NUMBER> , <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> _stackcopy ( coords [ <NUMBER> , ... ] , tf_coords [ <NUMBER> , ... ] ) <NEWLINE> <NEWLINE> <NEWLINE> _stackcopy ( coords [ <NUMBER> , ... ] , tf_coords [ <NUMBER> , ... ] ) <NEWLINE> <NEWLINE> if len ( shape ) == <NUMBER> : <NEWLINE> <TAB> coords [ <NUMBER> , ... ] = range ( shape [ <NUMBER> ] ) <NEWLINE> <NEWLINE> <UNTAB> return coords <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def draw ( self , renderer ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> for c in self . _children : <NEWLINE> <TAB> c . draw ( renderer ) <NEWLINE> <NEWLINE> <UNTAB> bbox_artist ( self , renderer , fill = False , props = dict ( pad = <NUMBER> ) ) <NEWLINE> self . stale = False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _trim_zeros ( str_floats , na_rep = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> trimmed = str_floats <NEWLINE> <NEWLINE> def _cond ( values ) : <NEWLINE> <TAB> non_na = [ x for x in values if x != na_rep ] <NEWLINE> return ( len ( non_na ) > <NUMBER> and all ( x . endswith ( <STRING> ) for x in non_na ) and <NEWLINE> not ( any ( ( <STRING> in x ) or ( <STRING> in x ) for x in non_na ) ) ) <NEWLINE> <NEWLINE> <UNTAB> while _cond ( trimmed ) : <NEWLINE> <TAB> trimmed = [ x [ : - <NUMBER> ] if x != na_rep else x for x in trimmed ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return [ x + <STRING> if x . endswith ( <STRING> ) and x != na_rep else x for x in trimmed ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def argmax ( self , dim = None , keepdim = False ) : <NEWLINE> <TAB> <NEWLINE> return torch . argmax ( self , dim , keepdim ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_figure ( self , figure ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if figure not in self . views : <NEWLINE> <TAB> self . views [ figure ] = cbook . Stack ( ) <NEWLINE> self . positions [ figure ] = cbook . Stack ( ) <NEWLINE> self . home_views [ figure ] = WeakKeyDictionary ( ) <NEWLINE> <NEWLINE> self . push_current ( figure ) <NEWLINE> <NEWLINE> figure . add_axobserver ( lambda fig : self . update_home_views ( fig ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _make_tf_features ( self , input_feat ) : <NEWLINE> <TAB> <NEWLINE> input_size = input_feat . get_shape ( ) . with_rank ( <NUMBER> ) . dims [ - <NUMBER> ] . value <NEWLINE> if input_size is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> num_feats = int ( <NEWLINE> ( input_size - self . _feature_size ) / ( self . _frequency_skip ) ) + <NUMBER> <NEWLINE> freq_inputs = [ ] <NEWLINE> for f in range ( num_feats ) : <NEWLINE> <TAB> cur_input = array_ops . slice ( input_feat , [ <NUMBER> , f * self . _frequency_skip ] , <NEWLINE> [ - <NUMBER> , self . _feature_size ] ) <NEWLINE> freq_inputs . append ( cur_input ) <NEWLINE> <UNTAB> return freq_inputs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _write_expansion_fields ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _write ( _pad_bytes ( <STRING> , <NUMBER> ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_nnf ( expr , simplified = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> expr = sympify ( expr ) <NEWLINE> if is_literal ( expr ) : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <UNTAB> stack = [ expr ] <NEWLINE> <NEWLINE> while stack : <NEWLINE> <TAB> expr = stack . pop ( ) <NEWLINE> if expr . func in ( And , Or ) : <NEWLINE> <TAB> if simplified : <NEWLINE> <TAB> args = expr . args <NEWLINE> for arg in args : <NEWLINE> <TAB> if Not ( arg ) in args : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> stack . extend ( expr . args ) <NEWLINE> <NEWLINE> <UNTAB> elif not is_literal ( expr ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _rec_eval_tail ( g , i , A , u , K ) : <NEWLINE> <TAB> <NEWLINE> if i == u : <NEWLINE> <TAB> return dup_eval ( g , A [ - <NUMBER> ] , K ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> h = [ _rec_eval_tail ( c , i + <NUMBER> , A , u , K ) for c in g ] <NEWLINE> <NEWLINE> if i < u - len ( A ) + <NUMBER> : <NEWLINE> <TAB> return h <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return dup_eval ( h , A [ - u + i - <NUMBER> ] , K ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_string ( self ) : <NEWLINE> <TAB> <NEWLINE> from pandas import Series <NEWLINE> <NEWLINE> frame = self . frame <NEWLINE> <NEWLINE> if len ( frame . columns ) == <NUMBER> or len ( frame . index ) == <NUMBER> : <NEWLINE> <TAB> info_line = ( u ( <STRING> ) <NEWLINE> . format ( name = type ( self . frame ) . __name__ , <NEWLINE> col = pprint_thing ( frame . columns ) , <NEWLINE> idx = pprint_thing ( frame . index ) ) ) <NEWLINE> text = info_line <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> strcols = self . _to_str_columns ( ) <NEWLINE> if self . line_width is None : <NEWLINE> <NEWLINE> <TAB> text = self . adj . adjoin ( <NUMBER> , * strcols ) <NEWLINE> <UNTAB> elif ( not isinstance ( self . max_cols , int ) or <NEWLINE> self . max_cols > <NUMBER> ) : <NEWLINE> <TAB> text = self . _join_multiline ( * strcols ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> text = self . adj . adjoin ( <NUMBER> , * strcols ) . split ( <STRING> ) <NEWLINE> max_len = Series ( text ) . str . len ( ) . max ( ) <NEWLINE> headers = [ ele [ <NUMBER> ] for ele in strcols ] <NEWLINE> <NEWLINE> <NEWLINE> size_tr_col = len ( headers [ self . tr_size_col ] ) <NEWLINE> max_len += size_tr_col <NEWLINE> <NEWLINE> dif = max_len - self . w <NEWLINE> <NEWLINE> adj_dif = dif + <NUMBER> <NEWLINE> col_lens = Series ( [ Series ( ele ) . apply ( len ) . max ( ) <NEWLINE> for ele in strcols ] ) <NEWLINE> n_cols = len ( col_lens ) <NEWLINE> counter = <NUMBER> <NEWLINE> while adj_dif > <NUMBER> and n_cols > <NUMBER> : <NEWLINE> <TAB> counter += <NUMBER> <NEWLINE> mid = int ( round ( n_cols / <NUMBER> ) ) <NEWLINE> mid_ix = col_lens . index [ mid ] <NEWLINE> col_len = col_lens [ mid_ix ] <NEWLINE> <NEWLINE> adj_dif -= ( col_len + <NUMBER> ) <NEWLINE> col_lens = col_lens . drop ( mid_ix ) <NEWLINE> n_cols = len ( col_lens ) <NEWLINE> <NEWLINE> <UNTAB> max_cols_adj = n_cols - self . index <NEWLINE> <NEWLINE> max_cols_adj = max ( max_cols_adj , <NUMBER> ) <NEWLINE> self . max_cols_adj = max_cols_adj <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . _chk_truncate ( ) <NEWLINE> strcols = self . _to_str_columns ( ) <NEWLINE> text = self . adj . adjoin ( <NUMBER> , * strcols ) <NEWLINE> <UNTAB> <UNTAB> if not self . index : <NEWLINE> <TAB> text = text . replace ( <STRING> , <STRING> ) . strip ( ) <NEWLINE> <UNTAB> self . buf . writelines ( text ) <NEWLINE> <NEWLINE> if self . should_show_dimensions : <NEWLINE> <TAB> self . buf . write ( <STRING> <NEWLINE> . format ( nrows = len ( frame ) , ncols = len ( frame . columns ) ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def cycle_consistency_loss ( cyclegan_model , scope = None , add_summaries = False ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( cyclegan_model , namedtuples . CycleGANModel ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % <NEWLINE> type ( cyclegan_model ) ) <NEWLINE> <UNTAB> return losses_impl . cycle_consistency_loss ( <NEWLINE> cyclegan_model . model_x2y . generator_inputs , cyclegan_model . reconstructed_x , <NEWLINE> cyclegan_model . model_y2x . generator_inputs , cyclegan_model . reconstructed_y , <NEWLINE> scope , add_summaries ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def spawn ( cmd , search_path = <NUMBER> , verbose = <NUMBER> , dry_run = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> cmd = list ( cmd ) <NEWLINE> if os . name == <STRING> : <NEWLINE> <TAB> _spawn_posix ( cmd , search_path , dry_run = dry_run ) <NEWLINE> <UNTAB> elif os . name == <STRING> : <NEWLINE> <TAB> _spawn_nt ( cmd , search_path , dry_run = dry_run ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise DistutilsPlatformError ( <NEWLINE> <STRING> % os . name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rs_series_from_list ( p , c , x , prec , concur = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> R = p . ring <NEWLINE> n = len ( c ) <NEWLINE> if not concur : <NEWLINE> <TAB> q = R ( <NUMBER> ) <NEWLINE> s = c [ <NUMBER> ] * q <NEWLINE> for i in range ( <NUMBER> , n ) : <NEWLINE> <TAB> q = rs_mul ( q , p , x , prec ) <NEWLINE> s += c [ i ] * q <NEWLINE> <UNTAB> return s <NEWLINE> <UNTAB> J = int ( math . sqrt ( n ) + <NUMBER> ) <NEWLINE> K , r = divmod ( n , J ) <NEWLINE> if r : <NEWLINE> <TAB> K += <NUMBER> <NEWLINE> <UNTAB> ax = [ R ( <NUMBER> ) ] <NEWLINE> b = <NUMBER> <NEWLINE> q = R ( <NUMBER> ) <NEWLINE> if len ( p ) < <NUMBER> : <NEWLINE> <TAB> for i in range ( <NUMBER> , J ) : <NEWLINE> <TAB> q = rs_mul ( q , p , x , prec ) <NEWLINE> ax . append ( q ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for i in range ( <NUMBER> , J ) : <NEWLINE> <TAB> if i % <NUMBER> == <NUMBER> : <NEWLINE> <TAB> q = rs_square ( ax [ i // <NUMBER> ] , x , prec ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> q = rs_mul ( q , p , x , prec ) <NEWLINE> <UNTAB> ax . append ( q ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> pj = rs_mul ( ax [ - <NUMBER> ] , p , x , prec ) <NEWLINE> b = R ( <NUMBER> ) <NEWLINE> s = R ( <NUMBER> ) <NEWLINE> for k in range ( K - <NUMBER> ) : <NEWLINE> <TAB> r = J * k <NEWLINE> s1 = c [ r ] <NEWLINE> for j in range ( <NUMBER> , J ) : <NEWLINE> <TAB> s1 += c [ r + j ] * ax [ j ] <NEWLINE> <UNTAB> s1 = rs_mul ( s1 , b , x , prec ) <NEWLINE> s += s1 <NEWLINE> b = rs_mul ( b , pj , x , prec ) <NEWLINE> if not b : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> k = K - <NUMBER> <NEWLINE> r = J * k <NEWLINE> if r < n : <NEWLINE> <TAB> s1 = c [ r ] * R ( <NUMBER> ) <NEWLINE> for j in range ( <NUMBER> , J ) : <NEWLINE> <TAB> if r + j >= n : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> s1 += c [ r + j ] * ax [ j ] <NEWLINE> <UNTAB> s1 = rs_mul ( s1 , b , x , prec ) <NEWLINE> s += s1 <NEWLINE> <UNTAB> return s <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def scatter_nd_sub ( self , indices , updates , name = None ) : <NEWLINE> <TAB> <NEWLINE> return self . _lazy_read ( gen_state_ops . resource_scatter_nd_sub ( <NEWLINE> self . handle , indices , ops . convert_to_tensor ( updates , self . dtype ) , <NEWLINE> name = name ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def cost_of_flow ( G , flowDict , weight = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return sum ( ( flowDict [ u ] [ v ] * d . get ( weight , <NUMBER> ) <NEWLINE> for u , v , d in G . edges ( data = True ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def getfullargspec ( func ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> try : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> sig = _signature_from_callable ( func , <NEWLINE> follow_wrapper_chains = False , <NEWLINE> skip_bound_arg = False , <NEWLINE> sigcls = Signature ) <NEWLINE> <UNTAB> except Exception as ex : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> raise TypeError ( <STRING> ) from ex <NEWLINE> <NEWLINE> <UNTAB> args = [ ] <NEWLINE> varargs = None <NEWLINE> varkw = None <NEWLINE> kwonlyargs = [ ] <NEWLINE> defaults = ( ) <NEWLINE> annotations = { } <NEWLINE> defaults = ( ) <NEWLINE> kwdefaults = { } <NEWLINE> <NEWLINE> if sig . return_annotation is not sig . empty : <NEWLINE> <TAB> annotations [ <STRING> ] = sig . return_annotation <NEWLINE> <NEWLINE> <UNTAB> for param in sig . parameters . values ( ) : <NEWLINE> <TAB> kind = param . kind <NEWLINE> name = param . name <NEWLINE> <NEWLINE> if kind is _POSITIONAL_ONLY : <NEWLINE> <TAB> args . append ( name ) <NEWLINE> <UNTAB> elif kind is _POSITIONAL_OR_KEYWORD : <NEWLINE> <TAB> args . append ( name ) <NEWLINE> if param . default is not param . empty : <NEWLINE> <TAB> defaults += ( param . default , ) <NEWLINE> <UNTAB> <UNTAB> elif kind is _VAR_POSITIONAL : <NEWLINE> <TAB> varargs = name <NEWLINE> <UNTAB> elif kind is _KEYWORD_ONLY : <NEWLINE> <TAB> kwonlyargs . append ( name ) <NEWLINE> if param . default is not param . empty : <NEWLINE> <TAB> kwdefaults [ name ] = param . default <NEWLINE> <UNTAB> <UNTAB> elif kind is _VAR_KEYWORD : <NEWLINE> <TAB> varkw = name <NEWLINE> <NEWLINE> <UNTAB> if param . annotation is not param . empty : <NEWLINE> <TAB> annotations [ name ] = param . annotation <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not kwdefaults : <NEWLINE> <NEWLINE> <TAB> kwdefaults = None <NEWLINE> <NEWLINE> <UNTAB> if not defaults : <NEWLINE> <NEWLINE> <TAB> defaults = None <NEWLINE> <NEWLINE> <UNTAB> return FullArgSpec ( args , varargs , varkw , defaults , <NEWLINE> kwonlyargs , kwdefaults , annotations ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def erfc ( x ) : <NEWLINE> <TAB> <NEWLINE> return Erfc ( ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def map ( self , seq ) : <NEWLINE> <TAB> <NEWLINE> result = [ ] <NEWLINE> <NEWLINE> for elt in seq : <NEWLINE> <TAB> if isinstance ( elt , list ) : <NEWLINE> <TAB> result . append ( self . map ( elt ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result . append ( self ( elt ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_help ( self , prefix = <STRING> , include_special_flags = True ) : <NEWLINE> <TAB> <NEWLINE> flags_by_module = self . flags_by_module_dict ( ) <NEWLINE> if flags_by_module : <NEWLINE> <TAB> modules = sorted ( flags_by_module ) <NEWLINE> <NEWLINE> main_module = sys . argv [ <NUMBER> ] <NEWLINE> if main_module in modules : <NEWLINE> <TAB> modules . remove ( main_module ) <NEWLINE> modules = [ main_module ] + modules <NEWLINE> <UNTAB> return self . _get_help_for_modules ( modules , prefix , include_special_flags ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> output_lines = [ ] <NEWLINE> <NEWLINE> values = six . itervalues ( self . _flags ( ) ) <NEWLINE> if include_special_flags : <NEWLINE> <TAB> values = itertools . chain ( <NEWLINE> values , six . itervalues ( _helpers . SPECIAL_FLAGS . _flags ( ) ) ) <NEWLINE> <UNTAB> self . _render_flag_list ( values , output_lines , prefix ) <NEWLINE> return <STRING> . join ( output_lines ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def read_uic_tag ( fh , tagid , plane_count , offset ) : <NEWLINE> <TAB> <NEWLINE> def read_int ( count = <NUMBER> ) : <NEWLINE> <TAB> value = struct . unpack ( <STRING> % count , fh . read ( <NUMBER> * count ) ) <NEWLINE> return value [ <NUMBER> ] if count == <NUMBER> else value <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> name , dtype = UIC_TAGS [ tagid ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <NEWLINE> <TAB> return <STRING> % tagid , read_int ( ) <NEWLINE> <NEWLINE> <UNTAB> if offset : <NEWLINE> <TAB> pos = fh . tell ( ) <NEWLINE> if dtype not in ( int , None ) : <NEWLINE> <TAB> off = read_int ( ) <NEWLINE> if off < <NUMBER> : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> % ( name , off ) ) <NEWLINE> return name , off <NEWLINE> <UNTAB> fh . seek ( off ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if dtype is None : <NEWLINE> <NEWLINE> <TAB> name = <STRING> + name <NEWLINE> value = read_int ( ) <NEWLINE> <UNTAB> elif dtype is int : <NEWLINE> <NEWLINE> <TAB> value = read_int ( ) <NEWLINE> <UNTAB> elif dtype is Fraction : <NEWLINE> <NEWLINE> <TAB> value = read_int ( <NUMBER> ) <NEWLINE> value = value [ <NUMBER> ] / value [ <NUMBER> ] <NEWLINE> <UNTAB> elif dtype is julian_datetime : <NEWLINE> <NEWLINE> <TAB> value = julian_datetime ( * read_int ( <NUMBER> ) ) <NEWLINE> <UNTAB> elif dtype is read_uic_image_property : <NEWLINE> <NEWLINE> <TAB> value = read_uic_image_property ( fh ) <NEWLINE> <UNTAB> elif dtype is str : <NEWLINE> <NEWLINE> <TAB> size = read_int ( ) <NEWLINE> if <NUMBER> <= size < <NUMBER> ** <NUMBER> : <NEWLINE> <TAB> value = struct . unpack ( <STRING> % size , fh . read ( size ) ) [ <NUMBER> ] [ : - <NUMBER> ] <NEWLINE> value = stripnull ( value ) <NEWLINE> <UNTAB> elif offset : <NEWLINE> <TAB> value = <STRING> <NEWLINE> warnings . warn ( <STRING> % name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % size ) <NEWLINE> <UNTAB> <UNTAB> elif dtype == <STRING> : <NEWLINE> <NEWLINE> <TAB> value = [ ] <NEWLINE> for _ in range ( plane_count ) : <NEWLINE> <TAB> size = read_int ( ) <NEWLINE> if <NUMBER> <= size < <NUMBER> ** <NUMBER> : <NEWLINE> <TAB> string = struct . unpack ( <STRING> % size , fh . read ( size ) ) [ <NUMBER> ] [ : - <NUMBER> ] <NEWLINE> string = stripnull ( string ) <NEWLINE> value . append ( string ) <NEWLINE> <UNTAB> elif offset : <NEWLINE> <TAB> warnings . warn ( <STRING> % name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % size ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> dtype = <STRING> + dtype <NEWLINE> if <STRING> in dtype : <NEWLINE> <TAB> dtype = dtype % plane_count <NEWLINE> <UNTAB> if <STRING> in dtype : <NEWLINE> <NEWLINE> <TAB> value = fh . read_array ( dtype , <NUMBER> ) [ <NUMBER> ] <NEWLINE> if value . shape [ - <NUMBER> ] == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> value = value [ ... , <NUMBER> ] / value [ ... , <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> value = struct . unpack ( dtype , fh . read ( struct . calcsize ( dtype ) ) ) <NEWLINE> if len ( value ) == <NUMBER> : <NEWLINE> <TAB> value = value [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if offset : <NEWLINE> <TAB> fh . seek ( pos + <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> return name , value <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , name , * clauses , ** kw ) : <NEWLINE> <TAB> <NEWLINE> self . packagenames = kw . pop ( <STRING> , None ) or [ ] <NEWLINE> self . name = name <NEWLINE> self . _bind = kw . get ( <STRING> , None ) <NEWLINE> self . type = sqltypes . to_instance ( kw . get ( <STRING> , None ) ) <NEWLINE> <NEWLINE> FunctionElement . __init__ ( self , * clauses , ** kw ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def update ( self , elt , new ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> pos = self . d [ elt ] <NEWLINE> self . h [ pos ] = new <NEWLINE> del self . d [ elt ] <NEWLINE> self . d [ new ] = pos <NEWLINE> <NEWLINE> pos = self . _siftup ( pos ) <NEWLINE> self . _siftdown ( pos ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def to_float ( x , name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return cast ( x , dtypes . float32 , name = name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def sum ( self , axis = <NUMBER> , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> nv . validate_sum ( args , kwargs ) <NEWLINE> valid_vals = self . _valid_sp_values <NEWLINE> sp_sum = valid_vals . sum ( ) <NEWLINE> if self . _null_fill_value : <NEWLINE> <TAB> return sp_sum <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nsparse = self . sp_index . ngaps <NEWLINE> return sp_sum + self . fill_value * nsparse <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_command_packages ( self ) : <NEWLINE> <TAB> <NEWLINE> pkgs = self . command_packages <NEWLINE> if not isinstance ( pkgs , list ) : <NEWLINE> <TAB> if pkgs is None : <NEWLINE> <TAB> pkgs = <STRING> <NEWLINE> <UNTAB> pkgs = [ pkg . strip ( ) for pkg in pkgs . split ( <STRING> ) if pkg != <STRING> ] <NEWLINE> if <STRING> not in pkgs : <NEWLINE> <TAB> pkgs . insert ( <NUMBER> , <STRING> ) <NEWLINE> <UNTAB> self . command_packages = pkgs <NEWLINE> <UNTAB> return pkgs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def c_code ( self , node , name , inputs , outputs , sub ) : <NEWLINE> <TAB> <NEWLINE> raise utils . MethodNotDefined ( <STRING> % self . __class__ . __name__ ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _expr_big ( cls , x , n ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def release_mouse ( self , ax ) : <NEWLINE> <TAB> <NEWLINE> if self . mouse_grabber is ax : <NEWLINE> <TAB> self . mouse_grabber = None <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _should_read_directly ( f ) : <NEWLINE> <TAB> <NEWLINE> if _is_compressed_file ( f ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> return f . fileno ( ) >= <NUMBER> <NEWLINE> <UNTAB> except io . UnsupportedOperation : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def out2in ( * local_opts , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> name = ( kwargs and kwargs . pop ( <STRING> , None ) ) <NEWLINE> if len ( local_opts ) > <NUMBER> : <NEWLINE> <NEWLINE> <TAB> local_opts = LocalOptGroup ( * local_opts ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> local_opts , = local_opts <NEWLINE> if not name : <NEWLINE> <TAB> name = local_opts . __name__ <NEWLINE> <UNTAB> <UNTAB> ret = TopoOptimizer ( local_opts , <NEWLINE> order = <STRING> , <NEWLINE> failure_callback = TopoOptimizer . warn_inplace , <NEWLINE> ** kwargs ) <NEWLINE> if name : <NEWLINE> <TAB> ret . __name__ = name <NEWLINE> <UNTAB> return ret <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def openblas_threads_text ( ) : <NEWLINE> <TAB> <NEWLINE> header = <NEWLINE> return header <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def build_product_order ( arg , gens ) : <NEWLINE> <TAB> <NEWLINE> gens2idx = { } <NEWLINE> for i , g in enumerate ( gens ) : <NEWLINE> <TAB> gens2idx [ g ] = i <NEWLINE> <UNTAB> order = [ ] <NEWLINE> for expr in arg : <NEWLINE> <TAB> name = expr [ <NUMBER> ] <NEWLINE> var = expr [ <NUMBER> : ] <NEWLINE> <NEWLINE> def makelambda ( var ) : <NEWLINE> <TAB> return _ItemGetter ( gens2idx [ g ] for g in var ) <NEWLINE> <UNTAB> order . append ( ( monomial_key ( name ) , makelambda ( var ) ) ) <NEWLINE> <UNTAB> return ProductOrder ( * order ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _count ( a , axis = None ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( a , <STRING> ) : <NEWLINE> <TAB> num = a . count ( axis = axis ) <NEWLINE> if isinstance ( num , np . ndarray ) and num . ndim == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> num = int ( num ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if axis is None : <NEWLINE> <TAB> num = a . size <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> num = a . shape [ axis ] <NEWLINE> <UNTAB> <UNTAB> return num <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def diagonalize ( self , reals_only = False , sort = False , normalize = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not self . is_square : <NEWLINE> <TAB> raise NonSquareMatrixError ( ) <NEWLINE> <NEWLINE> <UNTAB> if not self . is_diagonalizable ( reals_only = reals_only , clear_cache = False ) : <NEWLINE> <TAB> raise MatrixError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> eigenvecs = self . _cache_eigenvects <NEWLINE> if eigenvecs is None : <NEWLINE> <TAB> eigenvecs = self . eigenvects ( simplify = True ) <NEWLINE> <NEWLINE> <UNTAB> if sort : <NEWLINE> <TAB> eigenvecs = sorted ( eigenvecs , key = default_sort_key ) <NEWLINE> <NEWLINE> <UNTAB> p_cols , diag = [ ] , [ ] <NEWLINE> for val , mult , basis in eigenvecs : <NEWLINE> <TAB> diag += [ val ] * mult <NEWLINE> p_cols += basis <NEWLINE> <NEWLINE> <UNTAB> if normalize : <NEWLINE> <TAB> p_cols = [ v / v . norm ( ) for v in p_cols ] <NEWLINE> <NEWLINE> <UNTAB> return self . hstack ( * p_cols ) , self . diag ( * diag ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def astype ( self , dtype , copy = True ) : <NEWLINE> <TAB> <NEWLINE> if is_categorical_dtype ( dtype ) : <NEWLINE> <NEWLINE> <TAB> dtype = self . dtype . update_dtype ( dtype ) <NEWLINE> self = self . copy ( ) if copy else self <NEWLINE> if dtype == self . dtype : <NEWLINE> <TAB> return self <NEWLINE> <UNTAB> return self . _set_dtype ( dtype ) <NEWLINE> <UNTAB> return np . array ( self , dtype = dtype , copy = copy ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def append ( self , to_append , ignore_index = False , verify_integrity = False ) : <NEWLINE> <TAB> <NEWLINE> from pandas . core . reshape . concat import concat <NEWLINE> <NEWLINE> if isinstance ( to_append , ( list , tuple ) ) : <NEWLINE> <TAB> to_concat = [ self ] + to_append <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> to_concat = [ self , to_append ] <NEWLINE> <UNTAB> return concat ( to_concat , ignore_index = ignore_index , <NEWLINE> verify_integrity = verify_integrity ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def has_dups ( seq ) : <NEWLINE> <TAB> <NEWLINE> from sympy . core . containers import Dict <NEWLINE> from sympy . sets . sets import Set <NEWLINE> if isinstance ( seq , ( dict , set , Dict , Set ) ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> uniq = set ( ) <NEWLINE> return any ( True for s in seq if s in uniq or uniq . add ( s ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def values ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _modules . values ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , name , * columns ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> super ( TableClause , self ) . __init__ ( ) <NEWLINE> self . name = self . fullname = name <NEWLINE> self . _columns = ColumnCollection ( ) <NEWLINE> self . primary_key = ColumnSet ( ) <NEWLINE> self . foreign_keys = set ( ) <NEWLINE> for c in columns : <NEWLINE> <TAB> self . append_column ( c ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tc . returns ( core . LabeledTensor ) <NEWLINE> @ tc . accepts ( core . LabeledTensorLike , <NEWLINE> tc . Optional ( tc . Collection ( string_types ) ) , tc . Optional ( string_types ) ) <NEWLINE> def squeeze ( labeled_tensor , axis_names = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ labeled_tensor ] ) as scope : <NEWLINE> <TAB> labeled_tensor = core . convert_to_labeled_tensor ( labeled_tensor ) <NEWLINE> <NEWLINE> if axis_names is None : <NEWLINE> <TAB> axis_names = [ a . name for a in labeled_tensor . axes . values ( ) if len ( a ) == <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> for axis_name in axis_names : <NEWLINE> <TAB> if axis_name not in labeled_tensor . axes : <NEWLINE> <TAB> raise ValueError ( <STRING> % <NEWLINE> ( axis_name , labeled_tensor . axes ) ) <NEWLINE> <UNTAB> elif len ( labeled_tensor . axes [ axis_name ] ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % <NEWLINE> ( axis_name , labeled_tensor . axes [ axis_name ] ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> squeeze_dimensions = [ ] <NEWLINE> axes = [ ] <NEWLINE> for i , axis in enumerate ( labeled_tensor . axes . values ( ) ) : <NEWLINE> <TAB> if axis . name in axis_names : <NEWLINE> <TAB> squeeze_dimensions . append ( i ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> axes . append ( axis ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if squeeze_dimensions : <NEWLINE> <TAB> squeeze_op = array_ops . squeeze ( <NEWLINE> labeled_tensor . tensor , squeeze_dimensions , name = scope ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> squeeze_op = array_ops . identity ( labeled_tensor . tensor , name = scope ) <NEWLINE> <NEWLINE> <UNTAB> return core . LabeledTensor ( squeeze_op , axes ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def key_to_cmp ( key ) : <NEWLINE> <TAB> <NEWLINE> def key_cmp ( a , b ) : <NEWLINE> <TAB> return cmp ( key ( a ) , key ( b ) ) <NEWLINE> <UNTAB> return key_cmp <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def ellip_harm ( h2 , k2 , n , p , s , signm = <NUMBER> , signn = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return _ellip_harm ( h2 , k2 , n , p , s , signm , signn ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def to_manager ( sdf , columns , index ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> axes = [ _ensure_index ( columns ) , _ensure_index ( index ) ] <NEWLINE> <NEWLINE> return create_block_manager_from_arrays ( <NEWLINE> [ sdf [ c ] for c in columns ] , columns , axes ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def ci ( a , which = <NUMBER> , axis = None ) : <NEWLINE> <TAB> <NEWLINE> p = <NUMBER> - which / <NUMBER> , <NUMBER> + which / <NUMBER> <NEWLINE> return percentiles ( a , p , axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def peak_prominences ( x , peaks , wlen = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> x = np . asarray ( x , order = <STRING> , dtype = np . float64 ) <NEWLINE> if x . ndim != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> peaks = np . asarray ( peaks ) <NEWLINE> if peaks . size == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> peaks = np . array ( [ ] , dtype = np . intp ) <NEWLINE> <UNTAB> try : <NEWLINE> <NEWLINE> <TAB> peaks = peaks . astype ( np . intp , order = <STRING> , casting = <STRING> , <NEWLINE> subok = False , copy = False ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if peaks . ndim != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if wlen is None : <NEWLINE> <TAB> wlen = - <NUMBER> <NEWLINE> <UNTAB> elif <NUMBER> < wlen : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> wlen = int ( math . ceil ( wlen ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> raise ValueError ( <STRING> + str ( wlen ) ) <NEWLINE> <NEWLINE> <UNTAB> return _peak_prominences ( x , peaks , wlen ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def random_flip_up_down ( image , seed = None ) : <NEWLINE> <TAB> <NEWLINE> return _random_flip ( image , <NUMBER> , seed , <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dctn ( x , type = <NUMBER> , shape = None , axes = None , norm = None , overwrite_x = False ) : <NEWLINE> <TAB> <NEWLINE> x = np . asanyarray ( x ) <NEWLINE> shape , axes = _init_nd_shape_and_axes ( x , shape , axes ) <NEWLINE> for n , ax in zip ( shape , axes ) : <NEWLINE> <TAB> x = dct ( x , type = type , n = n , axis = ax , norm = norm , overwrite_x = overwrite_x ) <NEWLINE> <UNTAB> return x <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def triu ( m , k = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> m = asanyarray ( m ) <NEWLINE> mask = tri ( * m . shape [ - <NUMBER> : ] , k = k - <NUMBER> , dtype = bool ) <NEWLINE> <NEWLINE> return where ( mask , zeros ( <NUMBER> , m . dtype ) , m ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def asarray ( a , dtype = None , order = None ) : <NEWLINE> <TAB> <NEWLINE> return array ( a , dtype , copy = False , order = order ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def gaussian_nll ( x , mean , ln_var , reduce = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if reduce not in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % reduce ) <NEWLINE> <NEWLINE> <UNTAB> x_prec = exponential . exp ( - ln_var ) <NEWLINE> x_diff = x - mean <NEWLINE> x_power = ( x_diff * x_diff ) * x_prec * - <NUMBER> <NEWLINE> loss = ( ln_var + math . log ( <NUMBER> * math . pi ) ) / <NUMBER> - x_power <NEWLINE> if reduce == <STRING> : <NEWLINE> <TAB> return sum . sum ( loss ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return loss <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gf_eval ( f , a , p , K ) : <NEWLINE> <TAB> <NEWLINE> result = K . zero <NEWLINE> <NEWLINE> for c in f : <NEWLINE> <TAB> result *= a <NEWLINE> result += c <NEWLINE> result %= p <NEWLINE> <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def bohman ( M , sym = True ) : <NEWLINE> <TAB> <NEWLINE> if _len_guards ( M ) : <NEWLINE> <TAB> return np . ones ( M ) <NEWLINE> <UNTAB> M , needs_trunc = _extend ( M , sym ) <NEWLINE> <NEWLINE> fac = np . abs ( np . linspace ( - <NUMBER> , <NUMBER> , M ) [ <NUMBER> : - <NUMBER> ] ) <NEWLINE> w = ( <NUMBER> - fac ) * np . cos ( np . pi * fac ) + <NUMBER> / np . pi * np . sin ( np . pi * fac ) <NEWLINE> w = np . r_ [ <NUMBER> , w , <NUMBER> ] <NEWLINE> <NEWLINE> return _truncate ( w , needs_trunc ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _findfile ( self , path ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if not self . _isurl ( path ) : <NEWLINE> <NEWLINE> <TAB> filelist = self . _possible_names ( path ) <NEWLINE> <NEWLINE> filelist += self . _possible_names ( self . abspath ( path ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> filelist = self . _possible_names ( self . abspath ( path ) ) <NEWLINE> <NEWLINE> filelist = filelist + self . _possible_names ( path ) <NEWLINE> <NEWLINE> <UNTAB> for name in filelist : <NEWLINE> <TAB> if self . exists ( name ) : <NEWLINE> <TAB> if self . _isurl ( name ) : <NEWLINE> <TAB> name = self . _cache ( name ) <NEWLINE> <UNTAB> return name <NEWLINE> <UNTAB> <UNTAB> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def constrain_same ( self , other , strength = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> hc = [ self . left == other . left , <NEWLINE> self . right == other . right , <NEWLINE> self . bottom == other . bottom , <NEWLINE> self . top == other . top ] <NEWLINE> for c in hc : <NEWLINE> <TAB> self . solver . addConstraint ( ( c | strength ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def establish_colors ( self , color , palette , saturation ) : <NEWLINE> <TAB> <NEWLINE> if self . hue_names is None : <NEWLINE> <TAB> n_colors = len ( self . plot_data ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> n_colors = len ( self . hue_names ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if color is None and palette is None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> current_palette = utils . get_color_cycle ( ) <NEWLINE> if n_colors <= len ( current_palette ) : <NEWLINE> <TAB> colors = color_palette ( n_colors = n_colors ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> colors = husl_palette ( n_colors , l = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif palette is None : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if self . hue_names is None : <NEWLINE> <TAB> colors = [ color ] * n_colors <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if self . default_palette == <STRING> : <NEWLINE> <TAB> colors = light_palette ( color , n_colors ) <NEWLINE> <UNTAB> elif self . default_palette == <STRING> : <NEWLINE> <TAB> colors = dark_palette ( color , n_colors ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if isinstance ( palette , dict ) : <NEWLINE> <TAB> if self . hue_names is None : <NEWLINE> <TAB> levels = self . group_names <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> levels = self . hue_names <NEWLINE> <UNTAB> palette = [ palette [ l ] for l in levels ] <NEWLINE> <NEWLINE> <UNTAB> colors = color_palette ( palette , n_colors ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if saturation < <NUMBER> : <NEWLINE> <TAB> colors = color_palette ( colors , desat = saturation ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> rgb_colors = color_palette ( colors ) <NEWLINE> <NEWLINE> <NEWLINE> light_vals = [ colorsys . rgb_to_hls ( * c ) [ <NUMBER> ] for c in rgb_colors ] <NEWLINE> lum = min ( light_vals ) * <NUMBER> <NEWLINE> gray = mpl . colors . rgb2hex ( ( lum , lum , lum ) ) <NEWLINE> <NEWLINE> <NEWLINE> self . colors = rgb_colors <NEWLINE> self . gray = gray <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_dict ( self , into = dict ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> into_c = com . standardize_mapping ( into ) <NEWLINE> return into_c ( compat . iteritems ( self ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def cycler ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if args and kwargs : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if len ( args ) == <NUMBER> : <NEWLINE> <TAB> if not isinstance ( args [ <NUMBER> ] , Cycler ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> return Cycler ( args [ <NUMBER> ] ) <NEWLINE> <UNTAB> elif len ( args ) == <NUMBER> : <NEWLINE> <TAB> return _cycler ( * args ) <NEWLINE> <UNTAB> elif len ( args ) > <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if kwargs : <NEWLINE> <TAB> return reduce ( add , ( _cycler ( k , v ) for k , v in six . iteritems ( kwargs ) ) ) <NEWLINE> <NEWLINE> <UNTAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def alias ( selectable , name = None , flat = False ) : <NEWLINE> <TAB> <NEWLINE> return _interpret_as_from ( selectable ) . alias ( name = name , flat = flat ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def minimum_eager_fallback ( x , y , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ x , y ] , _ctx ) <NEWLINE> ( x , y ) = _inputs_T <NEWLINE> _inputs_flat = [ x , y ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _arith_method_SERIES ( cls , op , special ) : <NEWLINE> <TAB> <NEWLINE> str_rep = _get_opstr ( op , cls ) <NEWLINE> op_name = _get_op_name ( op , special ) <NEWLINE> eval_kwargs = _gen_eval_kwargs ( op_name ) <NEWLINE> fill_zeros = _gen_fill_zeros ( op_name ) <NEWLINE> construct_result = ( _construct_divmod_result <NEWLINE> if op is divmod else _construct_result ) <NEWLINE> <NEWLINE> def na_op ( x , y ) : <NEWLINE> <TAB> import pandas . core . computation . expressions as expressions <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> result = expressions . evaluate ( op , str_rep , x , y , ** eval_kwargs ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> if isinstance ( y , ( np . ndarray , ABCSeries , pd . Index ) ) : <NEWLINE> <TAB> dtype = find_common_type ( [ x . dtype , y . dtype ] ) <NEWLINE> result = np . empty ( x . size , dtype = dtype ) <NEWLINE> mask = notna ( x ) & notna ( y ) <NEWLINE> result [ mask ] = op ( x [ mask ] , com . _values_from_object ( y [ mask ] ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> assert isinstance ( x , np . ndarray ) <NEWLINE> result = np . empty ( len ( x ) , dtype = x . dtype ) <NEWLINE> mask = notna ( x ) <NEWLINE> result [ mask ] = op ( x [ mask ] , y ) <NEWLINE> <NEWLINE> <UNTAB> result , changed = maybe_upcast_putmask ( result , ~ mask , np . nan ) <NEWLINE> <NEWLINE> <UNTAB> result = missing . fill_zeros ( result , x , y , op_name , fill_zeros ) <NEWLINE> return result <NEWLINE> <NEWLINE> <UNTAB> def safe_na_op ( lvalues , rvalues ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> with np . errstate ( all = <STRING> ) : <NEWLINE> <TAB> return na_op ( lvalues , rvalues ) <NEWLINE> <UNTAB> <UNTAB> except Exception : <NEWLINE> <TAB> if is_object_dtype ( lvalues ) : <NEWLINE> <TAB> return libalgos . arrmap_object ( lvalues , <NEWLINE> lambda x : op ( x , rvalues ) ) <NEWLINE> <UNTAB> raise <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def wrapper ( left , right ) : <NEWLINE> <NEWLINE> <TAB> if isinstance ( right , ABCDataFrame ) : <NEWLINE> <TAB> return NotImplemented <NEWLINE> <NEWLINE> <UNTAB> left , right = _align_method_SERIES ( left , right ) <NEWLINE> res_name = get_op_result_name ( left , right ) <NEWLINE> <NEWLINE> if is_datetime64_dtype ( left ) or is_datetime64tz_dtype ( left ) : <NEWLINE> <TAB> result = dispatch_to_index_op ( op , left , right , pd . DatetimeIndex ) <NEWLINE> return construct_result ( left , result , <NEWLINE> index = left . index , name = res_name , <NEWLINE> dtype = result . dtype ) <NEWLINE> <NEWLINE> <UNTAB> elif is_timedelta64_dtype ( left ) : <NEWLINE> <TAB> result = dispatch_to_index_op ( op , left , right , pd . TimedeltaIndex ) <NEWLINE> return construct_result ( left , result , <NEWLINE> index = left . index , name = res_name , <NEWLINE> dtype = result . dtype ) <NEWLINE> <NEWLINE> <UNTAB> elif is_categorical_dtype ( left ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> . format ( typ = type ( left ) . __name__ , op = str_rep ) ) <NEWLINE> <NEWLINE> <UNTAB> lvalues = left . values <NEWLINE> rvalues = right <NEWLINE> if isinstance ( rvalues , ABCSeries ) : <NEWLINE> <TAB> rvalues = rvalues . values <NEWLINE> <NEWLINE> <UNTAB> result = safe_na_op ( lvalues , rvalues ) <NEWLINE> return construct_result ( left , result , <NEWLINE> index = left . index , name = res_name , dtype = None ) <NEWLINE> <NEWLINE> <UNTAB> return wrapper <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _multi_blockify ( tuples , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> grouper = itertools . groupby ( tuples , lambda x : x [ <NUMBER> ] . dtype ) <NEWLINE> <NEWLINE> new_blocks = [ ] <NEWLINE> for dtype , tup_block in grouper : <NEWLINE> <NEWLINE> <TAB> values , placement = _stack_arrays ( list ( tup_block ) , dtype ) <NEWLINE> <NEWLINE> block = make_block ( values , placement = placement ) <NEWLINE> new_blocks . append ( block ) <NEWLINE> <NEWLINE> <UNTAB> return new_blocks <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _check_bounds ( self , x_new ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> below_bounds = x_new < self . x [ <NUMBER> ] <NEWLINE> above_bounds = x_new > self . x [ - <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> if self . bounds_error and below_bounds . any ( ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if self . bounds_error and above_bounds . any ( ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return below_bounds , above_bounds <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def assign_sub ( self , delta , use_locking = False , name = None , read_value = True ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , n = None ) : <NEWLINE> <TAB> <NEWLINE> self . ndivs = n <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _slice ( self , slicer ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if isinstance ( slicer , tuple ) and len ( slicer ) == <NUMBER> : <NEWLINE> <TAB> if not com . is_null_slice ( slicer [ <NUMBER> ] ) : <NEWLINE> <TAB> raise AssertionError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> slicer = slicer [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> return self . values [ slicer ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def argmin ( self , axis = None ) : <NEWLINE> <TAB> <NEWLINE> return nanops . nanargmin ( self . values ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_named_colors_mapping ( ) : <NEWLINE> <TAB> <NEWLINE> return _colors_full_map <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def keys ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . files <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def encode_base64 ( input , pad = False , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if pad is None : <NEWLINE> <TAB> pad = False <NEWLINE> <UNTAB> pad = _execute . make_bool ( pad , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , pad = pad , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , input , <STRING> , pad ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return encode_base64_eager_fallback ( <NEWLINE> input , pad = pad , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_smoothing_factor ( self , s ) : <NEWLINE> <TAB> <NEWLINE> data = self . _data <NEWLINE> if data [ <NUMBER> ] == - <NUMBER> : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> return <NEWLINE> <UNTAB> args = data [ : <NUMBER> ] + ( s , ) + data [ <NUMBER> : ] <NEWLINE> data = dfitpack . fpcurf1 ( * args ) <NEWLINE> if data [ - <NUMBER> ] == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> data = self . _reset_nest ( data ) <NEWLINE> <UNTAB> self . _data = data <NEWLINE> self . _reset_class ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def reorder_levels ( self , order ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( self . index , MultiIndex ) : <NEWLINE> <TAB> raise Exception ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> result = self . copy ( ) <NEWLINE> result . index = result . index . reorder_levels ( order ) <NEWLINE> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_block_type ( values , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> dtype = dtype or values . dtype <NEWLINE> vtype = dtype . type <NEWLINE> <NEWLINE> if is_sparse ( values ) : <NEWLINE> <TAB> cls = SparseBlock <NEWLINE> <UNTAB> elif issubclass ( vtype , np . floating ) : <NEWLINE> <TAB> cls = FloatBlock <NEWLINE> <UNTAB> elif issubclass ( vtype , np . timedelta64 ) : <NEWLINE> <TAB> assert issubclass ( vtype , np . integer ) <NEWLINE> cls = TimeDeltaBlock <NEWLINE> <UNTAB> elif issubclass ( vtype , np . complexfloating ) : <NEWLINE> <TAB> cls = ComplexBlock <NEWLINE> <UNTAB> elif issubclass ( vtype , np . datetime64 ) : <NEWLINE> <TAB> assert not is_datetimetz ( values ) <NEWLINE> cls = DatetimeBlock <NEWLINE> <UNTAB> elif is_datetimetz ( values ) : <NEWLINE> <TAB> cls = DatetimeTZBlock <NEWLINE> <UNTAB> elif issubclass ( vtype , np . integer ) : <NEWLINE> <TAB> cls = IntBlock <NEWLINE> <UNTAB> elif dtype == np . bool_ : <NEWLINE> <TAB> cls = BoolBlock <NEWLINE> <UNTAB> elif is_categorical ( values ) : <NEWLINE> <TAB> cls = CategoricalBlock <NEWLINE> <UNTAB> elif is_extension_array_dtype ( values ) : <NEWLINE> <TAB> cls = ExtensionBlock <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cls = ObjectBlock <NEWLINE> <UNTAB> return cls <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_patch_circle ( self , center , radius ) : <NEWLINE> <TAB> <NEWLINE> self . _patch_type = <STRING> <NEWLINE> self . _center = center <NEWLINE> self . _width = radius * <NUMBER> <NEWLINE> self . _height = radius * <NUMBER> <NEWLINE> <NEWLINE> self . set_transform ( self . axes . transAxes ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def is_gpu_available ( cuda_only = False , min_cuda_compute_capability = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def compute_capability_from_device_desc ( device_desc ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> match = re . search ( <STRING> , device_desc ) <NEWLINE> <NEWLINE> <NEWLINE> if not match : <NEWLINE> <TAB> return <NUMBER> , <NUMBER> <NEWLINE> <UNTAB> return int ( match . group ( <NUMBER> ) ) , int ( match . group ( <NUMBER> ) ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> for local_device in device_lib . list_local_devices ( ) : <NEWLINE> <TAB> if local_device . device_type == <STRING> : <NEWLINE> <TAB> if ( min_cuda_compute_capability is None or <NEWLINE> compute_capability_from_device_desc ( <NEWLINE> local_device . physical_device_desc ) >= <NEWLINE> min_cuda_compute_capability ) : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> <UNTAB> if local_device . device_type == <STRING> and not cuda_only : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> <UNTAB> return False <NEWLINE> <UNTAB> except errors_impl . NotFoundError as e : <NEWLINE> <TAB> if not all ( [ x in str ( e ) for x in [ <STRING> , <STRING> ] ] ) : <NEWLINE> <TAB> raise e <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> logging . error ( str ( e ) ) <NEWLINE> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gf_compose ( f , g , p , K ) : <NEWLINE> <TAB> <NEWLINE> if len ( g ) <= <NUMBER> : <NEWLINE> <TAB> return gf_strip ( [ gf_eval ( f , gf_LC ( g , K ) , p , K ) ] ) <NEWLINE> <NEWLINE> <UNTAB> if not f : <NEWLINE> <TAB> return [ ] <NEWLINE> <NEWLINE> <UNTAB> h = [ f [ <NUMBER> ] ] <NEWLINE> <NEWLINE> for c in f [ <NUMBER> : ] : <NEWLINE> <TAB> h = gf_mul ( h , g , p , K ) <NEWLINE> h = gf_add_ground ( h , c , p , K ) <NEWLINE> <NEWLINE> <UNTAB> return h <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def lp2bs ( b , a , wo = <NUMBER> , bw = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> a , b = map ( atleast_1d , ( a , b ) ) <NEWLINE> D = len ( a ) - <NUMBER> <NEWLINE> N = len ( b ) - <NUMBER> <NEWLINE> artype = mintypecode ( ( a , b ) ) <NEWLINE> M = max ( [ N , D ] ) <NEWLINE> Np = M + M <NEWLINE> Dp = M + M <NEWLINE> bprime = numpy . zeros ( Np + <NUMBER> , artype ) <NEWLINE> aprime = numpy . zeros ( Dp + <NUMBER> , artype ) <NEWLINE> wosq = wo * wo <NEWLINE> for j in range ( Np + <NUMBER> ) : <NEWLINE> <TAB> val = <NUMBER> <NEWLINE> for i in range ( <NUMBER> , N + <NUMBER> ) : <NEWLINE> <TAB> for k in range ( <NUMBER> , M - i + <NUMBER> ) : <NEWLINE> <TAB> if i + <NUMBER> * k == j : <NEWLINE> <TAB> val += ( comb ( M - i , k ) * b [ N - i ] * <NEWLINE> ( wosq ) ** ( M - i - k ) * bw ** i ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> bprime [ Np - j ] = val <NEWLINE> <UNTAB> for j in range ( Dp + <NUMBER> ) : <NEWLINE> <TAB> val = <NUMBER> <NEWLINE> for i in range ( <NUMBER> , D + <NUMBER> ) : <NEWLINE> <TAB> for k in range ( <NUMBER> , M - i + <NUMBER> ) : <NEWLINE> <TAB> if i + <NUMBER> * k == j : <NEWLINE> <TAB> val += ( comb ( M - i , k ) * a [ D - i ] * <NEWLINE> ( wosq ) ** ( M - i - k ) * bw ** i ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> aprime [ Dp - j ] = val <NEWLINE> <NEWLINE> <UNTAB> return normalize ( bprime , aprime ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def register ( cls , name , style ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not issubclass ( style , cls . _Base ) : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( style , <NEWLINE> cls . _Base ) ) <NEWLINE> <UNTAB> cls . _style_list [ name ] = style <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def equalContents ( arr1 , arr2 ) : <NEWLINE> <TAB> <NEWLINE> return frozenset ( arr1 ) == frozenset ( arr2 ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def compute_mask ( self , inputs , mask = None ) : <NEWLINE> <TAB> <NEWLINE> if not self . supports_masking : <NEWLINE> <TAB> if mask is not None : <NEWLINE> <TAB> if isinstance ( mask , list ) : <NEWLINE> <TAB> if any ( m is not None for m in mask ) : <NEWLINE> <TAB> raise TypeError ( <STRING> + self . name + <NEWLINE> <STRING> <NEWLINE> <STRING> + <NEWLINE> str ( mask ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> + self . name + <NEWLINE> <STRING> <NEWLINE> <STRING> + <NEWLINE> str ( mask ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return None <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return mask <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _add_comparison_methods ( cls ) : <NEWLINE> <TAB> <NEWLINE> cls . __eq__ = _dt_index_cmp ( <STRING> , cls ) <NEWLINE> cls . __ne__ = _dt_index_cmp ( <STRING> , cls ) <NEWLINE> cls . __lt__ = _dt_index_cmp ( <STRING> , cls ) <NEWLINE> cls . __gt__ = _dt_index_cmp ( <STRING> , cls ) <NEWLINE> cls . __le__ = _dt_index_cmp ( <STRING> , cls ) <NEWLINE> cls . __ge__ = _dt_index_cmp ( <STRING> , cls ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _write_image_description ( self ) : <NEWLINE> <TAB> <NEWLINE> if ( not self . _data_shape or self . _data_shape [ <NUMBER> ] == <NUMBER> or <NEWLINE> self . _description_offset <= <NUMBER> ) : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> colormapped = self . _colormap is not None <NEWLINE> if self . _imagej : <NEWLINE> <TAB> isrgb = self . _shape [ - <NUMBER> ] in ( <NUMBER> , <NUMBER> ) <NEWLINE> description = imagej_description ( <NEWLINE> self . _data_shape , isrgb , colormapped , ** self . _metadata ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> description = image_description ( <NEWLINE> self . _data_shape , colormapped , ** self . _metadata ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> description = description [ : self . _description_len - <NUMBER> ] <NEWLINE> pos = self . _fh . tell ( ) <NEWLINE> self . _fh . seek ( self . _description_offset ) <NEWLINE> self . _fh . write ( description ) <NEWLINE> self . _fh . seek ( self . _description_len_offset ) <NEWLINE> self . _fh . write ( struct . pack ( self . _byteorder + self . _offset_format , <NEWLINE> len ( description ) + <NUMBER> ) ) <NEWLINE> self . _fh . seek ( pos ) <NEWLINE> <NEWLINE> self . _description_offset = <NUMBER> <NEWLINE> self . _description_len_offset = <NUMBER> <NEWLINE> self . _description_len = <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _var ( self , dim , df , scale ) : <NEWLINE> <TAB> <NEWLINE> if df > dim + <NUMBER> : <NEWLINE> <TAB> var = ( df - dim + <NUMBER> ) * scale ** <NUMBER> <NEWLINE> diag = scale . diagonal ( ) <NEWLINE> var += ( df - dim - <NUMBER> ) * np . outer ( diag , diag ) <NEWLINE> var /= ( df - dim ) * ( df - dim - <NUMBER> ) ** <NUMBER> * ( df - dim - <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> var = None <NEWLINE> <UNTAB> return var <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def update ( self , current , values = None ) : <NEWLINE> <TAB> <NEWLINE> values = values or [ ] <NEWLINE> for k , v in values : <NEWLINE> <TAB> if k not in self . stateful_metrics : <NEWLINE> <TAB> if k not in self . _values : <NEWLINE> <TAB> self . _values [ k ] = [ v * ( current - self . _seen_so_far ) , <NEWLINE> current - self . _seen_so_far ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _values [ k ] [ <NUMBER> ] += v * ( current - self . _seen_so_far ) <NEWLINE> self . _values [ k ] [ <NUMBER> ] += ( current - self . _seen_so_far ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> self . _values [ k ] = [ v , <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> self . _seen_so_far = current <NEWLINE> <NEWLINE> now = time . time ( ) <NEWLINE> info = <STRING> % ( now - self . _start ) <NEWLINE> if self . verbose == <NUMBER> : <NEWLINE> <TAB> if ( now - self . _last_update < self . interval and <NEWLINE> self . target is not None and current < self . target ) : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> prev_total_width = self . _total_width <NEWLINE> if self . _dynamic_display : <NEWLINE> <TAB> sys . stdout . write ( <STRING> * prev_total_width ) <NEWLINE> sys . stdout . write ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> sys . stdout . write ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if self . target is not None : <NEWLINE> <TAB> numdigits = int ( np . floor ( np . log10 ( self . target ) ) ) + <NUMBER> <NEWLINE> barstr = <STRING> % ( numdigits , self . target ) <NEWLINE> bar = barstr % current <NEWLINE> prog = float ( current ) / self . target <NEWLINE> prog_width = int ( self . width * prog ) <NEWLINE> if prog_width > <NUMBER> : <NEWLINE> <TAB> bar += ( <STRING> * ( prog_width - <NUMBER> ) ) <NEWLINE> if current < self . target : <NEWLINE> <TAB> bar += <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> bar += <STRING> <NEWLINE> <UNTAB> <UNTAB> bar += ( <STRING> * ( self . width - prog_width ) ) <NEWLINE> bar += <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> bar = <STRING> % current <NEWLINE> <NEWLINE> <UNTAB> self . _total_width = len ( bar ) <NEWLINE> sys . stdout . write ( bar ) <NEWLINE> <NEWLINE> if current : <NEWLINE> <TAB> time_per_unit = ( now - self . _start ) / current <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> time_per_unit = <NUMBER> <NEWLINE> <UNTAB> if self . target is not None and current < self . target : <NEWLINE> <TAB> eta = time_per_unit * ( self . target - current ) <NEWLINE> if eta > <NUMBER> : <NEWLINE> <TAB> eta_format = ( <STRING> % <NEWLINE> ( eta // <NUMBER> , ( eta % <NUMBER> ) // <NUMBER> , eta % <NUMBER> ) ) <NEWLINE> <UNTAB> elif eta > <NUMBER> : <NEWLINE> <TAB> eta_format = <STRING> % ( eta // <NUMBER> , eta % <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> eta_format = <STRING> % eta <NEWLINE> <NEWLINE> <UNTAB> info = <STRING> % eta_format <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if time_per_unit >= <NUMBER> : <NEWLINE> <TAB> info += <STRING> % time_per_unit <NEWLINE> <UNTAB> elif time_per_unit >= <NUMBER> : <NEWLINE> <TAB> info += <STRING> % ( time_per_unit * <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> info += <STRING> % ( time_per_unit * <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for k in self . _values : <NEWLINE> <TAB> info += <STRING> % k <NEWLINE> if isinstance ( self . _values [ k ] , list ) : <NEWLINE> <TAB> avg = np . mean ( <NEWLINE> self . _values [ k ] [ <NUMBER> ] / max ( <NUMBER> , self . _values [ k ] [ <NUMBER> ] ) ) <NEWLINE> if abs ( avg ) > <NUMBER> : <NEWLINE> <TAB> info += <STRING> % avg <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> info += <STRING> % avg <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> info += <STRING> % self . _values [ k ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . _total_width += len ( info ) <NEWLINE> if prev_total_width > self . _total_width : <NEWLINE> <TAB> info += ( <STRING> * ( prev_total_width - self . _total_width ) ) <NEWLINE> <NEWLINE> <UNTAB> if self . target is not None and current >= self . target : <NEWLINE> <TAB> info += <STRING> <NEWLINE> <NEWLINE> <UNTAB> sys . stdout . write ( info ) <NEWLINE> sys . stdout . flush ( ) <NEWLINE> <NEWLINE> <UNTAB> elif self . verbose == <NUMBER> : <NEWLINE> <TAB> if self . target is None or current >= self . target : <NEWLINE> <TAB> for k in self . _values : <NEWLINE> <TAB> info += <STRING> % k <NEWLINE> avg = np . mean ( <NEWLINE> self . _values [ k ] [ <NUMBER> ] / max ( <NUMBER> , self . _values [ k ] [ <NUMBER> ] ) ) <NEWLINE> if avg > <NUMBER> : <NEWLINE> <TAB> info += <STRING> % avg <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> info += <STRING> % avg <NEWLINE> <UNTAB> <UNTAB> info += <STRING> <NEWLINE> <NEWLINE> sys . stdout . write ( info ) <NEWLINE> sys . stdout . flush ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . _last_update = now <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def select_step ( x , J_h , diag_h , g_h , p , p_h , d , Delta , lb , ub , theta ) : <NEWLINE> <TAB> <NEWLINE> if in_bounds ( x + p , lb , ub ) : <NEWLINE> <TAB> p_value = evaluate_quadratic ( J_h , g_h , p_h , diag = diag_h ) <NEWLINE> return p , p_h , - p_value <NEWLINE> <NEWLINE> <UNTAB> p_stride , hits = step_size_to_bound ( x , p , lb , ub ) <NEWLINE> <NEWLINE> <NEWLINE> r_h = np . copy ( p_h ) <NEWLINE> r_h [ hits . astype ( bool ) ] *= - <NUMBER> <NEWLINE> r = d * r_h <NEWLINE> <NEWLINE> <NEWLINE> p *= p_stride <NEWLINE> p_h *= p_stride <NEWLINE> x_on_bound = x + p <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> _ , to_tr = intersect_trust_region ( p_h , r_h , Delta ) <NEWLINE> to_bound , _ = step_size_to_bound ( x_on_bound , r , lb , ub ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> r_stride = min ( to_bound , to_tr ) <NEWLINE> if r_stride > <NUMBER> : <NEWLINE> <TAB> r_stride_l = ( <NUMBER> - theta ) * p_stride / r_stride <NEWLINE> if r_stride == to_bound : <NEWLINE> <TAB> r_stride_u = theta * to_bound <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> r_stride_u = to_tr <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> r_stride_l = <NUMBER> <NEWLINE> r_stride_u = - <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if r_stride_l <= r_stride_u : <NEWLINE> <TAB> a , b , c = build_quadratic_1d ( J_h , g_h , r_h , s0 = p_h , diag = diag_h ) <NEWLINE> r_stride , r_value = minimize_quadratic_1d ( <NEWLINE> a , b , r_stride_l , r_stride_u , c = c ) <NEWLINE> r_h *= r_stride <NEWLINE> r_h += p_h <NEWLINE> r = r_h * d <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> r_value = np . inf <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> p *= theta <NEWLINE> p_h *= theta <NEWLINE> p_value = evaluate_quadratic ( J_h , g_h , p_h , diag = diag_h ) <NEWLINE> <NEWLINE> ag_h = - g_h <NEWLINE> ag = d * ag_h <NEWLINE> <NEWLINE> to_tr = Delta / norm ( ag_h ) <NEWLINE> to_bound , _ = step_size_to_bound ( x , ag , lb , ub ) <NEWLINE> if to_bound < to_tr : <NEWLINE> <TAB> ag_stride = theta * to_bound <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ag_stride = to_tr <NEWLINE> <NEWLINE> <UNTAB> a , b = build_quadratic_1d ( J_h , g_h , ag_h , diag = diag_h ) <NEWLINE> ag_stride , ag_value = minimize_quadratic_1d ( a , b , <NUMBER> , ag_stride ) <NEWLINE> ag_h *= ag_stride <NEWLINE> ag *= ag_stride <NEWLINE> <NEWLINE> if p_value < r_value and p_value < ag_value : <NEWLINE> <TAB> return p , p_h , - p_value <NEWLINE> <UNTAB> elif r_value < p_value and r_value < ag_value : <NEWLINE> <TAB> return r , r_h , - r_value <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return ag , ag_h , - ag_value <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def bias_add_v1 ( value , bias , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , value = value , bias = bias , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , value , bias ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return bias_add_v1_eager_fallback ( <NEWLINE> value , bias , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def any ( a , axis = None , out = None , keepdims = np . _NoValue ) : <NEWLINE> <TAB> <NEWLINE> arr = asanyarray ( a ) <NEWLINE> kwargs = { } <NEWLINE> if keepdims is not np . _NoValue : <NEWLINE> <TAB> kwargs [ <STRING> ] = keepdims <NEWLINE> <UNTAB> return arr . any ( axis = axis , out = out , ** kwargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def validate_take_with_convert ( convert , args , kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( convert , ndarray ) or convert is None : <NEWLINE> <TAB> args = ( convert , ) + args <NEWLINE> convert = True <NEWLINE> <NEWLINE> <UNTAB> validate_take ( args , kwargs , max_fname_arg_count = <NUMBER> , method = <STRING> ) <NEWLINE> return convert <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def reduce_rational_inequalities ( exprs , gen , relational = True ) : <NEWLINE> <TAB> <NEWLINE> exact = True <NEWLINE> eqs = [ ] <NEWLINE> solution = S . Reals if exprs else S . EmptySet <NEWLINE> for _exprs in exprs : <NEWLINE> <TAB> _eqs = [ ] <NEWLINE> <NEWLINE> for expr in _exprs : <NEWLINE> <TAB> if isinstance ( expr , tuple ) : <NEWLINE> <TAB> expr , rel = expr <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if expr . is_Relational : <NEWLINE> <TAB> expr , rel = expr . lhs - expr . rhs , expr . rel_op <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> expr , rel = expr , <STRING> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if expr is S . true : <NEWLINE> <TAB> numer , denom , rel = S . Zero , S . One , <STRING> <NEWLINE> <UNTAB> elif expr is S . false : <NEWLINE> <TAB> numer , denom , rel = S . One , S . One , <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> numer , denom = expr . together ( ) . as_numer_denom ( ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> ( numer , denom ) , opt = parallel_poly_from_expr ( <NEWLINE> ( numer , denom ) , gen ) <NEWLINE> <UNTAB> except PolynomialError : <NEWLINE> <TAB> raise PolynomialError ( filldedent ( ' ' ' 
                                         o n l y   p o l y n o m i a l s   a n d   r a t i o n a l   f u n c t i o n s   a r e 
                                         s u p p o r t e d   i n   t h i s   c o n t e x t . 
                                         ' ' ' ) ) <NEWLINE> <NEWLINE> <UNTAB> if not opt . domain . is_Exact : <NEWLINE> <TAB> numer , denom , exact = numer . to_exact ( ) , denom . to_exact ( ) , False <NEWLINE> <NEWLINE> <UNTAB> domain = opt . domain . get_exact ( ) <NEWLINE> <NEWLINE> if not ( domain . is_ZZ or domain . is_QQ ) : <NEWLINE> <TAB> expr = numer / denom <NEWLINE> expr = Relational ( expr , <NUMBER> , rel ) <NEWLINE> solution &= solve_univariate_inequality ( expr , gen , relational = False ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> _eqs . append ( ( ( numer , denom ) , rel ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if _eqs : <NEWLINE> <TAB> eqs . append ( _eqs ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if eqs : <NEWLINE> <TAB> solution &= solve_rational_inequalities ( eqs ) <NEWLINE> exclude = solve_rational_inequalities ( [ [ ( ( d , d . one ) , <STRING> ) <NEWLINE> for i in eqs for ( ( n , d ) , _ ) in i if d . has ( gen ) ] ] ) <NEWLINE> solution -= exclude <NEWLINE> <NEWLINE> <UNTAB> if not exact and solution : <NEWLINE> <TAB> solution = solution . evalf ( ) <NEWLINE> <NEWLINE> <UNTAB> if relational : <NEWLINE> <TAB> solution = solution . as_relational ( gen ) <NEWLINE> <NEWLINE> <UNTAB> return solution <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_QQ_python ( K1 , a , K0 ) : <NEWLINE> <TAB> <NEWLINE> return K1 ( K1 . domain . convert ( a , K0 ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def split_and_operate ( self , mask , f , inplace ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if mask is None : <NEWLINE> <TAB> mask = np . ones ( self . shape , dtype = bool ) <NEWLINE> <UNTAB> new_values = self . values <NEWLINE> <NEWLINE> def make_a_block ( nv , ref_loc ) : <NEWLINE> <TAB> if isinstance ( nv , Block ) : <NEWLINE> <TAB> block = nv <NEWLINE> <UNTAB> elif isinstance ( nv , list ) : <NEWLINE> <TAB> block = nv [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> nv = _block_shape ( nv , ndim = self . ndim ) <NEWLINE> <UNTAB> except ( AttributeError , NotImplementedError ) : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> block = self . make_block ( values = nv , <NEWLINE> placement = ref_loc ) <NEWLINE> <UNTAB> return block <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . ndim == <NUMBER> : <NEWLINE> <TAB> if mask . any ( ) : <NEWLINE> <TAB> nv = f ( mask , new_values , None ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nv = new_values if inplace else new_values . copy ( ) <NEWLINE> <UNTAB> block = make_a_block ( nv , self . mgr_locs ) <NEWLINE> return [ block ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> new_blocks = [ ] <NEWLINE> for i , ref_loc in enumerate ( self . mgr_locs ) : <NEWLINE> <TAB> m = mask [ i ] <NEWLINE> v = new_values [ i ] <NEWLINE> <NEWLINE> <NEWLINE> if m . any ( ) : <NEWLINE> <TAB> nv = f ( m , v , i ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nv = v if inplace else v . copy ( ) <NEWLINE> <NEWLINE> <UNTAB> block = make_a_block ( nv , [ ref_loc ] ) <NEWLINE> new_blocks . append ( block ) <NEWLINE> <NEWLINE> <UNTAB> return new_blocks <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit ( self , X , y = None ) : <NEWLINE> <TAB> <NEWLINE> feature_names = [ ] <NEWLINE> vocab = { } <NEWLINE> <NEWLINE> for x in X : <NEWLINE> <TAB> for f , v in six . iteritems ( x ) : <NEWLINE> <TAB> if isinstance ( v , six . string_types ) : <NEWLINE> <TAB> f = <STRING> % ( f , self . separator , v ) <NEWLINE> <UNTAB> if f not in vocab : <NEWLINE> <TAB> feature_names . append ( f ) <NEWLINE> vocab [ f ] = len ( vocab ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if self . sort : <NEWLINE> <TAB> feature_names . sort ( ) <NEWLINE> vocab = dict ( ( f , i ) for i , f in enumerate ( feature_names ) ) <NEWLINE> <NEWLINE> <UNTAB> self . feature_names_ = feature_names <NEWLINE> self . vocabulary_ = vocab <NEWLINE> <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def matrix_dot ( * args ) : <NEWLINE> <TAB> <NEWLINE> rval = args [ <NUMBER> ] <NEWLINE> for a in args [ <NUMBER> : ] : <NEWLINE> <TAB> rval = theano . tensor . dot ( rval , a ) <NEWLINE> <UNTAB> return rval <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _get_cython_type ( dtype ) : <NEWLINE> <TAB> <NEWLINE> type_name = _get_dtype ( dtype ) . name <NEWLINE> ctype = _cython_types . get ( type_name , <STRING> ) <NEWLINE> if ctype == <STRING> : <NEWLINE> <TAB> raise MergeError ( <STRING> . format ( type = type_name ) ) <NEWLINE> <UNTAB> return ctype <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def fillna ( self , value = None , downcast = None ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def update_defaults ( new , config = config , defaults = defaults ) : <NEWLINE> <TAB> <NEWLINE> defaults . append ( new ) <NEWLINE> update ( config , new , priority = <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def random_poly ( x , n , inf , sup , domain = ZZ , polys = False ) : <NEWLINE> <TAB> <NEWLINE> poly = Poly ( dup_random ( n , inf , sup , domain ) , x , domain = domain ) <NEWLINE> <NEWLINE> return poly if polys else poly . as_expr ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def compressor_file ( self , fileobj , compresslevel = None ) : <NEWLINE> <TAB> <NEWLINE> if compresslevel is None : <NEWLINE> <TAB> return self . fileobj_factory ( fileobj , <STRING> , check = lzma . CHECK_NONE ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . fileobj_factory ( fileobj , <STRING> , check = lzma . CHECK_NONE , <NEWLINE> preset = compresslevel ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def probplot ( x , sparams = ( ) , dist = <STRING> , fit = True , plot = None , rvalue = False ) : <NEWLINE> <TAB> <NEWLINE> x = np . asarray ( x ) <NEWLINE> _perform_fit = fit or ( plot is not None ) <NEWLINE> if x . size == <NUMBER> : <NEWLINE> <TAB> if _perform_fit : <NEWLINE> <TAB> return ( x , x ) , ( np . nan , np . nan , <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return x , x <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> osm_uniform = _calc_uniform_order_statistic_medians ( len ( x ) ) <NEWLINE> dist = _parse_dist_kw ( dist , enforce_subclass = False ) <NEWLINE> if sparams is None : <NEWLINE> <TAB> sparams = ( ) <NEWLINE> <UNTAB> if isscalar ( sparams ) : <NEWLINE> <TAB> sparams = ( sparams , ) <NEWLINE> <UNTAB> if not isinstance ( sparams , tuple ) : <NEWLINE> <TAB> sparams = tuple ( sparams ) <NEWLINE> <NEWLINE> <UNTAB> osm = dist . ppf ( osm_uniform , * sparams ) <NEWLINE> osr = sort ( x ) <NEWLINE> if _perform_fit : <NEWLINE> <NEWLINE> <TAB> slope , intercept , r , prob , sterrest = stats . linregress ( osm , osr ) <NEWLINE> <NEWLINE> <UNTAB> if plot is not None : <NEWLINE> <TAB> plot . plot ( osm , osr , <STRING> , osm , slope * osm + intercept , <STRING> ) <NEWLINE> _add_axis_labels_title ( plot , xlabel = <STRING> , <NEWLINE> ylabel = <STRING> , <NEWLINE> title = <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> if rvalue : <NEWLINE> <TAB> xmin = amin ( osm ) <NEWLINE> xmax = amax ( osm ) <NEWLINE> ymin = amin ( x ) <NEWLINE> ymax = amax ( x ) <NEWLINE> posx = xmin + <NUMBER> * ( xmax - xmin ) <NEWLINE> posy = ymin + <NUMBER> * ( ymax - ymin ) <NEWLINE> plot . text ( posx , posy , <STRING> % r ** <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if fit : <NEWLINE> <TAB> return ( osm , osr ) , ( slope , intercept , r ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return osm , osr <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def astype_nansafe ( arr , dtype , copy = True ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( dtype , np . dtype ) : <NEWLINE> <TAB> dtype = pandas_dtype ( dtype ) <NEWLINE> <NEWLINE> <UNTAB> if issubclass ( dtype . type , text_type ) : <NEWLINE> <NEWLINE> <TAB> return lib . astype_unicode ( arr . ravel ( ) ) . reshape ( arr . shape ) <NEWLINE> <NEWLINE> <UNTAB> elif issubclass ( dtype . type , string_types ) : <NEWLINE> <TAB> return lib . astype_str ( arr . ravel ( ) ) . reshape ( arr . shape ) <NEWLINE> <NEWLINE> <UNTAB> elif is_datetime64_dtype ( arr ) : <NEWLINE> <TAB> if is_object_dtype ( dtype ) : <NEWLINE> <TAB> return tslib . ints_to_pydatetime ( arr . view ( np . int64 ) ) <NEWLINE> <UNTAB> elif dtype == np . int64 : <NEWLINE> <TAB> return arr . view ( dtype ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if dtype . kind == <STRING> : <NEWLINE> <TAB> return arr . astype ( dtype ) <NEWLINE> <NEWLINE> <UNTAB> raise TypeError ( <STRING> <NEWLINE> <STRING> . format ( from_dtype = arr . dtype , <NEWLINE> to_dtype = dtype ) ) <NEWLINE> <NEWLINE> <UNTAB> elif is_timedelta64_dtype ( arr ) : <NEWLINE> <TAB> if is_object_dtype ( dtype ) : <NEWLINE> <TAB> return tslib . ints_to_pytimedelta ( arr . view ( np . int64 ) ) <NEWLINE> <UNTAB> elif dtype == np . int64 : <NEWLINE> <TAB> return arr . view ( dtype ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if ( ( PY3 and dtype not in [ _INT64_DTYPE , _TD_DTYPE ] ) or <NEWLINE> ( not PY3 and dtype != _TD_DTYPE ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if dtype . kind == <STRING> : <NEWLINE> <TAB> mask = isna ( arr ) <NEWLINE> result = arr . astype ( dtype ) . astype ( np . float64 ) <NEWLINE> result [ mask ] = np . nan <NEWLINE> return result <NEWLINE> <UNTAB> <UNTAB> elif dtype == _TD_DTYPE : <NEWLINE> <TAB> return arr . astype ( _TD_DTYPE , copy = copy ) <NEWLINE> <NEWLINE> <UNTAB> raise TypeError ( <STRING> <NEWLINE> <STRING> . format ( from_dtype = arr . dtype , <NEWLINE> to_dtype = dtype ) ) <NEWLINE> <NEWLINE> <UNTAB> elif ( np . issubdtype ( arr . dtype , np . floating ) and <NEWLINE> np . issubdtype ( dtype , np . integer ) ) : <NEWLINE> <NEWLINE> <TAB> if not np . isfinite ( arr ) . all ( ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif is_object_dtype ( arr ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if np . issubdtype ( dtype . type , np . integer ) : <NEWLINE> <TAB> return lib . astype_intsafe ( arr . ravel ( ) , dtype ) . reshape ( arr . shape ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif is_datetime64_dtype ( dtype ) : <NEWLINE> <TAB> from pandas import to_datetime <NEWLINE> return astype_nansafe ( to_datetime ( arr ) . values , dtype , copy = copy ) <NEWLINE> <UNTAB> elif is_timedelta64_dtype ( dtype ) : <NEWLINE> <TAB> from pandas import to_timedelta <NEWLINE> return astype_nansafe ( to_timedelta ( arr ) . values , dtype , copy = copy ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if dtype . name in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> warnings . warn ( msg . format ( dtype = dtype . name ) , <NEWLINE> FutureWarning , stacklevel = <NUMBER> ) <NEWLINE> dtype = np . dtype ( dtype . name + <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if copy : <NEWLINE> <TAB> return arr . astype ( dtype , copy = True ) <NEWLINE> <UNTAB> return arr . view ( dtype ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def polyvander ( x , deg ) : <NEWLINE> <TAB> <NEWLINE> ideg = int ( deg ) <NEWLINE> if ideg != deg : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if ideg < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> x = np . array ( x , copy = <NUMBER> , ndmin = <NUMBER> ) + <NUMBER> <NEWLINE> dims = ( ideg + <NUMBER> , ) + x . shape <NEWLINE> dtyp = x . dtype <NEWLINE> v = np . empty ( dims , dtype = dtyp ) <NEWLINE> v [ <NUMBER> ] = x * <NUMBER> + <NUMBER> <NEWLINE> if ideg > <NUMBER> : <NEWLINE> <TAB> v [ <NUMBER> ] = x <NEWLINE> for i in range ( <NUMBER> , ideg + <NUMBER> ) : <NEWLINE> <TAB> v [ i ] = v [ i - <NUMBER> ] * x <NEWLINE> <UNTAB> <UNTAB> return np . moveaxis ( v , <NUMBER> , - <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _is_closed ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _coordinated_creator . tf_sess is None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def ceil_eager_fallback ( x , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , ( x , ) = _execute . args_to_matching_eager ( [ x ] , _ctx ) <NEWLINE> _inputs_flat = [ x ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def load_wine ( return_X_y = False ) : <NEWLINE> <TAB> <NEWLINE> module_path = dirname ( __file__ ) <NEWLINE> data , target , target_names = load_data ( module_path , <STRING> ) <NEWLINE> <NEWLINE> with open ( join ( module_path , <STRING> , <STRING> ) ) as rst_file : <NEWLINE> <TAB> fdescr = rst_file . read ( ) <NEWLINE> <NEWLINE> <UNTAB> if return_X_y : <NEWLINE> <TAB> return data , target <NEWLINE> <NEWLINE> <UNTAB> return Bunch ( data = data , target = target , <NEWLINE> target_names = target_names , <NEWLINE> DESCR = fdescr , <NEWLINE> feature_names = [ <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def eval ( cls , * _args ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not _args : <NEWLINE> <TAB> return Undefined <NEWLINE> <NEWLINE> <UNTAB> if len ( _args ) == <NUMBER> and _args [ <NUMBER> ] [ - <NUMBER> ] == True : <NEWLINE> <TAB> return _args [ <NUMBER> ] [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> newargs = [ ] <NEWLINE> current_cond = set ( ) <NEWLINE> <NEWLINE> args = [ ] <NEWLINE> for e , c in _args : <NEWLINE> <TAB> if not c . is_Atom and not isinstance ( c , Relational ) : <NEWLINE> <TAB> free = c . free_symbols <NEWLINE> if len ( free ) == <NUMBER> : <NEWLINE> <TAB> funcs = [ i for i in c . atoms ( Function ) <NEWLINE> if not isinstance ( i , Boolean ) ] <NEWLINE> if len ( funcs ) == <NUMBER> and len ( <NEWLINE> c . xreplace ( { list ( funcs ) [ <NUMBER> ] : Dummy ( ) } <NEWLINE> ) . free_symbols ) == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> free = funcs <NEWLINE> <UNTAB> _c = c <NEWLINE> x = free . pop ( ) <NEWLINE> try : <NEWLINE> <TAB> c = c . as_set ( ) . as_relational ( x ) <NEWLINE> <UNTAB> except NotImplementedError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> reps = { } <NEWLINE> for i in c . atoms ( Relational ) : <NEWLINE> <TAB> ic = i . canonical <NEWLINE> if ic . rhs in ( S . Infinity , S . NegativeInfinity ) : <NEWLINE> <TAB> if not _c . has ( ic . rhs ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> reps [ i ] = S . true <NEWLINE> <UNTAB> elif ( <STRING> not in ic . rel_op and <NEWLINE> c . xreplace ( { x : i . rhs } ) != <NEWLINE> _c . xreplace ( { x : i . rhs } ) ) : <NEWLINE> <TAB> reps [ i ] = Relational ( <NEWLINE> i . lhs , i . rhs , i . rel_op + <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> c = c . xreplace ( reps ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> args . append ( ( e , _canonical ( c ) ) ) <NEWLINE> <NEWLINE> <UNTAB> for expr , cond in args : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if isinstance ( expr , Piecewise ) : <NEWLINE> <TAB> unmatching = [ ] <NEWLINE> for i , ( e , c ) in enumerate ( expr . args ) : <NEWLINE> <TAB> if c in current_cond : <NEWLINE> <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> if c == cond : <NEWLINE> <TAB> if c != True : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if unmatching : <NEWLINE> <TAB> expr = Piecewise ( * ( <NEWLINE> unmatching + [ ( e , c ) ] ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> expr = e <NEWLINE> <UNTAB> <UNTAB> break <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> unmatching . append ( ( e , c ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> got = False <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for i in ( [ cond ] + <NEWLINE> ( list ( cond . args ) if isinstance ( cond , And ) else <NEWLINE> [ ] ) ) : <NEWLINE> <TAB> if i in current_cond : <NEWLINE> <TAB> got = True <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> if got : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( cond , And ) : <NEWLINE> <TAB> nonredundant = [ ] <NEWLINE> for c in cond . args : <NEWLINE> <TAB> if ( isinstance ( c , Relational ) and <NEWLINE> ( ~ c ) . canonical in current_cond ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> nonredundant . append ( c ) <NEWLINE> <UNTAB> cond = cond . func ( * nonredundant ) <NEWLINE> <UNTAB> elif isinstance ( cond , Relational ) : <NEWLINE> <TAB> if ( ~ cond ) . canonical in current_cond : <NEWLINE> <TAB> cond = S . true <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> current_cond . add ( cond ) <NEWLINE> <NEWLINE> <NEWLINE> if newargs : <NEWLINE> <TAB> if newargs [ - <NUMBER> ] . expr == expr : <NEWLINE> <TAB> orcond = Or ( cond , newargs [ - <NUMBER> ] . cond ) <NEWLINE> if isinstance ( orcond , ( And , Or ) ) : <NEWLINE> <TAB> orcond = distribute_and_over_or ( orcond ) <NEWLINE> <UNTAB> newargs [ - <NUMBER> ] = ExprCondPair ( expr , orcond ) <NEWLINE> continue <NEWLINE> <UNTAB> elif newargs [ - <NUMBER> ] . cond == cond : <NEWLINE> <TAB> orexpr = Or ( expr , newargs [ - <NUMBER> ] . expr ) <NEWLINE> if isinstance ( orexpr , ( And , Or ) ) : <NEWLINE> <TAB> orexpr = distribute_and_over_or ( orexpr ) <NEWLINE> <UNTAB> newargs [ - <NUMBER> ] == ExprCondPair ( orexpr , cond ) <NEWLINE> continue <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> newargs . append ( ExprCondPair ( expr , cond ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> missing = len ( newargs ) != len ( _args ) <NEWLINE> <NEWLINE> same = all ( a == b for a , b in zip ( newargs , _args ) ) <NEWLINE> <NEWLINE> <NEWLINE> if not newargs : <NEWLINE> <TAB> raise ValueError ( filldedent ( ' ' ' 
                                 T h e r e   a r e   n o   c o n d i t i o n s   ( o r   n o n e   t h a t 
                                 a r e   n o t   t r i v i a l l y   f a l s e )   t o   d e f i n e   a n 
                                 e x p r e s s i o n . ' ' ' ) ) <NEWLINE> <UNTAB> if missing or not same : <NEWLINE> <TAB> return cls ( * newargs ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def DEFINE_multi_string ( <NEWLINE> name , default , help , flag_values = _flagvalues . FLAGS , ** args ) : <NEWLINE> <TAB> <NEWLINE> parser = _argument_parser . ArgumentParser ( ) <NEWLINE> serializer = _argument_parser . ArgumentSerializer ( ) <NEWLINE> DEFINE_multi ( parser , serializer , name , default , help , flag_values , ** args ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def read_dot ( path ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> import pygraphviz <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> raise ImportError ( <STRING> , <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> A = pygraphviz . AGraph ( file = path ) <NEWLINE> return from_agraph ( A ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def inverse ( self , argindex = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return tanh <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecation . deprecated_endpoints ( <STRING> ) <NEWLINE> def sparse_softmax ( sp_input , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , <NEWLINE> [ sp_input . indices , sp_input . values ] ) as name : <NEWLINE> <TAB> out_vals = gen_sparse_ops . sparse_softmax ( sp_input . indices , sp_input . values , <NEWLINE> sp_input . dense_shape ) <NEWLINE> return sparse_tensor . SparseTensor ( sp_input . indices , out_vals , <NEWLINE> sp_input . dense_shape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def try_all_threshold ( image , figsize = ( <NUMBER> , <NUMBER> ) , verbose = True ) : <NEWLINE> <TAB> <NEWLINE> def thresh ( func ) : <NEWLINE> <TAB> <NEWLINE> def wrapper ( im ) : <NEWLINE> <TAB> return im > func ( im ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> wrapper . __orifunc__ = func . __orifunc__ <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> wrapper . __orifunc__ = func . __module__ + <STRING> + func . __name__ <NEWLINE> <UNTAB> return wrapper <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> methods = OrderedDict ( { <STRING> : thresh ( threshold_isodata ) , <NEWLINE> <STRING> : thresh ( threshold_li ) , <NEWLINE> <STRING> : thresh ( threshold_mean ) , <NEWLINE> <STRING> : thresh ( threshold_minimum ) , <NEWLINE> <STRING> : thresh ( threshold_otsu ) , <NEWLINE> <STRING> : thresh ( threshold_triangle ) , <NEWLINE> <STRING> : thresh ( threshold_yen ) } ) <NEWLINE> <NEWLINE> return _try_all ( image , figsize = figsize , <NEWLINE> methods = methods , verbose = verbose ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _rcm_estimate ( G , nodelist ) : <NEWLINE> <TAB> <NEWLINE> G = G . subgraph ( nodelist ) <NEWLINE> order = reverse_cuthill_mckee_ordering ( G ) <NEWLINE> n = len ( nodelist ) <NEWLINE> index = dict ( zip ( nodelist , range ( n ) ) ) <NEWLINE> x = ndarray ( n , dtype = float ) <NEWLINE> for i , u in enumerate ( order ) : <NEWLINE> <TAB> x [ index [ u ] ] = i <NEWLINE> <UNTAB> x -= ( n - <NUMBER> ) / <NUMBER> <NEWLINE> return x <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_sympy ( self , a ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def estimate_bc_jac ( bc , ya , yb , p , bc0 = None ) : <NEWLINE> <TAB> <NEWLINE> n = ya . shape [ <NUMBER> ] <NEWLINE> k = p . shape [ <NUMBER> ] <NEWLINE> <NEWLINE> if bc0 is None : <NEWLINE> <TAB> bc0 = bc ( ya , yb , p ) <NEWLINE> <NEWLINE> <UNTAB> dtype = ya . dtype <NEWLINE> <NEWLINE> dbc_dya = np . empty ( ( n , n + k ) , dtype = dtype ) <NEWLINE> h = EPS ** <NUMBER> * ( <NUMBER> + np . abs ( ya ) ) <NEWLINE> for i in range ( n ) : <NEWLINE> <TAB> ya_new = ya . copy ( ) <NEWLINE> ya_new [ i ] += h [ i ] <NEWLINE> hi = ya_new [ i ] - ya [ i ] <NEWLINE> bc_new = bc ( ya_new , yb , p ) <NEWLINE> dbc_dya [ i ] = ( bc_new - bc0 ) / hi <NEWLINE> <UNTAB> dbc_dya = dbc_dya . T <NEWLINE> <NEWLINE> h = EPS ** <NUMBER> * ( <NUMBER> + np . abs ( yb ) ) <NEWLINE> dbc_dyb = np . empty ( ( n , n + k ) , dtype = dtype ) <NEWLINE> for i in range ( n ) : <NEWLINE> <TAB> yb_new = yb . copy ( ) <NEWLINE> yb_new [ i ] += h [ i ] <NEWLINE> hi = yb_new [ i ] - yb [ i ] <NEWLINE> bc_new = bc ( ya , yb_new , p ) <NEWLINE> dbc_dyb [ i ] = ( bc_new - bc0 ) / hi <NEWLINE> <UNTAB> dbc_dyb = dbc_dyb . T <NEWLINE> <NEWLINE> if k == <NUMBER> : <NEWLINE> <TAB> dbc_dp = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> h = EPS ** <NUMBER> * ( <NUMBER> + np . abs ( p ) ) <NEWLINE> dbc_dp = np . empty ( ( k , n + k ) , dtype = dtype ) <NEWLINE> for i in range ( k ) : <NEWLINE> <TAB> p_new = p . copy ( ) <NEWLINE> p_new [ i ] += h [ i ] <NEWLINE> hi = p_new [ i ] - p [ i ] <NEWLINE> bc_new = bc ( ya , yb , p_new ) <NEWLINE> dbc_dp [ i ] = ( bc_new - bc0 ) / hi <NEWLINE> <UNTAB> dbc_dp = dbc_dp . T <NEWLINE> <NEWLINE> <UNTAB> return dbc_dya , dbc_dyb , dbc_dp <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def poly_LC ( f , K ) : <NEWLINE> <TAB> <NEWLINE> if not f : <NEWLINE> <TAB> return K . zero <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return f [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _validate_dtype ( self , dtype ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if dtype is not None : <NEWLINE> <TAB> dtype = pandas_dtype ( dtype ) <NEWLINE> <NEWLINE> <NEWLINE> if dtype . kind == <STRING> : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> <NEWLINE> <STRING> <NEWLINE> . format ( self . __class__ . __name__ ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return dtype <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def calculate_gain ( nonlinearity , param = None ) : <NEWLINE> <TAB> <NEWLINE> linear_fns = [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> if nonlinearity in linear_fns or nonlinearity == <STRING> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> elif nonlinearity == <STRING> : <NEWLINE> <TAB> return <NUMBER> / <NUMBER> <NEWLINE> <UNTAB> elif nonlinearity == <STRING> : <NEWLINE> <TAB> return math . sqrt ( <NUMBER> ) <NEWLINE> <UNTAB> elif nonlinearity == <STRING> : <NEWLINE> <TAB> if param is None : <NEWLINE> <TAB> negative_slope = <NUMBER> <NEWLINE> <UNTAB> elif not isinstance ( param , bool ) and isinstance ( param , int ) or isinstance ( param , float ) : <NEWLINE> <NEWLINE> <TAB> negative_slope = param <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( param ) ) <NEWLINE> <UNTAB> return math . sqrt ( <NUMBER> / ( <NUMBER> + negative_slope ** <NUMBER> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( nonlinearity ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def cdist ( XA , XB , metric = <STRING> , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> kwargs = _args_to_kwargs_xdist ( args , kwargs , metric , <STRING> ) <NEWLINE> <NEWLINE> XA = np . asarray ( XA , order = <STRING> ) <NEWLINE> XB = np . asarray ( XB , order = <STRING> ) <NEWLINE> <NEWLINE> s = XA . shape <NEWLINE> sB = XB . shape <NEWLINE> <NEWLINE> if len ( s ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if len ( sB ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if s [ <NUMBER> ] != sB [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> mA = s [ <NUMBER> ] <NEWLINE> mB = sB [ <NUMBER> ] <NEWLINE> n = s [ <NUMBER> ] <NEWLINE> out = kwargs . pop ( <STRING> , None ) <NEWLINE> if out is None : <NEWLINE> <TAB> dm = np . empty ( ( mA , mB ) , dtype = np . double ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if out . shape != ( mA , mB ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if not out . flags . c_contiguous : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if out . dtype != np . double : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> dm = out <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if ( metric in _METRICS [ <STRING> ] . aka or <NEWLINE> metric in _METRICS [ <STRING> ] . aka or <NEWLINE> metric in [ <STRING> , <STRING> ] or <NEWLINE> metric in [ minkowski , wminkowski ] ) : <NEWLINE> <TAB> kwargs_blacklist = [ <STRING> , <STRING> ] <NEWLINE> <UNTAB> elif ( metric in _METRICS [ <STRING> ] . aka or <NEWLINE> metric == <STRING> or metric == seuclidean ) : <NEWLINE> <TAB> kwargs_blacklist = [ <STRING> , <STRING> , <STRING> ] <NEWLINE> <UNTAB> elif ( metric in _METRICS [ <STRING> ] . aka or <NEWLINE> metric == <STRING> or metric == mahalanobis ) : <NEWLINE> <TAB> kwargs_blacklist = [ <STRING> , <STRING> , <STRING> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> kwargs_blacklist = [ <STRING> , <STRING> , <STRING> ] <NEWLINE> <NEWLINE> <UNTAB> _filter_deprecated_kwargs ( kwargs , kwargs_blacklist ) <NEWLINE> <NEWLINE> if callable ( metric ) : <NEWLINE> <NEWLINE> <TAB> mstr = getattr ( metric , <STRING> , <STRING> ) <NEWLINE> metric_name = _METRIC_ALIAS . get ( mstr , None ) <NEWLINE> <NEWLINE> XA , XB , typ , kwargs = _validate_cdist_input ( XA , XB , mA , mB , n , <NEWLINE> metric_name , ** kwargs ) <NEWLINE> <NEWLINE> for i in xrange ( <NUMBER> , mA ) : <NEWLINE> <TAB> for j in xrange ( <NUMBER> , mB ) : <NEWLINE> <TAB> dm [ i , j ] = metric ( XA [ i ] , XB [ j ] , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif isinstance ( metric , string_types ) : <NEWLINE> <TAB> mstr = metric . lower ( ) <NEWLINE> <NEWLINE> <NEWLINE> if <STRING> in kwargs and not mstr . startswith ( <STRING> ) : <NEWLINE> <TAB> if ( mstr in _METRICS [ <STRING> ] . aka or <NEWLINE> mstr in _METRICS [ <STRING> ] . aka ) : <NEWLINE> <TAB> raise ValueError ( <STRING> % mstr ) <NEWLINE> <NEWLINE> <UNTAB> kwargs [ <STRING> ] = out <NEWLINE> mstr = <STRING> % mstr <NEWLINE> <NEWLINE> <UNTAB> metric_name = _METRIC_ALIAS . get ( mstr , None ) <NEWLINE> if metric_name is not None : <NEWLINE> <TAB> XA , XB , typ , kwargs = _validate_cdist_input ( XA , XB , mA , mB , n , <NEWLINE> metric_name , ** kwargs ) <NEWLINE> <NEWLINE> cdist_fn = getattr ( _distance_wrap , <NEWLINE> <STRING> % ( metric_name , typ ) ) <NEWLINE> cdist_fn ( XA , XB , dm , ** kwargs ) <NEWLINE> return dm <NEWLINE> <NEWLINE> <UNTAB> elif mstr . startswith ( <STRING> ) : <NEWLINE> <TAB> if mstr in _TEST_METRICS : <NEWLINE> <TAB> dm = cdist ( XA , XB , _TEST_METRICS [ mstr ] , ** kwargs ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % mstr [ <NUMBER> : ] ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % mstr ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> return dm <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , num_units , num_proj = None , use_biases = False , reuse = None ) : <NEWLINE> <TAB> <NEWLINE> super ( NASCell , self ) . __init__ ( _reuse = reuse ) <NEWLINE> self . _num_units = num_units <NEWLINE> self . _num_proj = num_proj <NEWLINE> self . _use_biases = use_biases <NEWLINE> self . _reuse = reuse <NEWLINE> <NEWLINE> if num_proj is not None : <NEWLINE> <TAB> self . _state_size = rnn_cell_impl . LSTMStateTuple ( num_units , num_proj ) <NEWLINE> self . _output_size = num_proj <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _state_size = rnn_cell_impl . LSTMStateTuple ( num_units , num_units ) <NEWLINE> self . _output_size = num_units <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def homogenize ( f , s ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( s , Symbol ) : <NEWLINE> <TAB> raise TypeError ( <STRING> % type ( s ) ) <NEWLINE> <UNTAB> if s in f . gens : <NEWLINE> <TAB> i = f . gens . index ( s ) <NEWLINE> gens = f . gens <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> i = len ( f . gens ) <NEWLINE> gens = f . gens + ( s , ) <NEWLINE> <UNTAB> if hasattr ( f . rep , <STRING> ) : <NEWLINE> <TAB> return f . per ( f . rep . homogenize ( i ) , gens = gens ) <NEWLINE> <UNTAB> raise OperationNotSupported ( f , <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _replace_dtype_fields ( dtype , primitive_dtype ) : <NEWLINE> <TAB> <NEWLINE> dtype = np . dtype ( dtype ) <NEWLINE> primitive_dtype = np . dtype ( primitive_dtype ) <NEWLINE> return _replace_dtype_fields_recursive ( dtype , primitive_dtype ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> @ not_implemented_for ( <STRING> ) <NEWLINE> def is_strongly_connected ( G ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return all ( is_reachable ( G , u , v ) for u in G for v in G ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def isinf ( ctx , x ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( x , <STRING> ) : <NEWLINE> <TAB> return x . _mpf_ in ( finf , fninf ) <NEWLINE> <UNTAB> if hasattr ( x , <STRING> ) : <NEWLINE> <TAB> re , im = x . _mpc_ <NEWLINE> return re in ( finf , fninf ) or im in ( finf , fninf ) <NEWLINE> <UNTAB> if isinstance ( x , int_types ) or isinstance ( x , rational . mpq ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> x = ctx . convert ( x ) <NEWLINE> if hasattr ( x , <STRING> ) or hasattr ( x , <STRING> ) : <NEWLINE> <TAB> return ctx . isinf ( x ) <NEWLINE> <UNTAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def label_minor ( self , labelOnlyBase ) : <NEWLINE> <TAB> <NEWLINE> self . labelOnlyBase = labelOnlyBase <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def links ( self , skipself = False ) : <NEWLINE> <TAB> <NEWLINE> if not skipself : <NEWLINE> <TAB> yield self <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , step , offset ) : <NEWLINE> <TAB> <NEWLINE> if step <= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> self . step = step <NEWLINE> self . _offset = abs ( offset ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _cast_sparse_series_op ( left , right , opname ) : <NEWLINE> <TAB> <NEWLINE> opname = opname . strip ( <STRING> ) <NEWLINE> <NEWLINE> if is_integer_dtype ( left ) and is_integer_dtype ( right ) : <NEWLINE> <NEWLINE> <TAB> if opname in ( <STRING> , <STRING> ) and ( right . values == <NUMBER> ) . any ( ) : <NEWLINE> <TAB> left = left . astype ( np . float64 ) <NEWLINE> right = right . astype ( np . float64 ) <NEWLINE> <UNTAB> elif opname in ( <STRING> , <STRING> ) and ( left . values == <NUMBER> ) . any ( ) : <NEWLINE> <TAB> left = left . astype ( np . float64 ) <NEWLINE> right = right . astype ( np . float64 ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return left , right <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def eqp_kktfact ( H , c , A , b ) : <NEWLINE> <TAB> <NEWLINE> n , = np . shape ( c ) <NEWLINE> m , = np . shape ( b ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> kkt_matrix = csc_matrix ( bmat ( [ [ H , A . T ] , [ A , None ] ] ) ) <NEWLINE> <NEWLINE> kkt_vec = np . hstack ( [ - c , - b ] ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> lu = linalg . splu ( kkt_matrix ) <NEWLINE> kkt_sol = lu . solve ( kkt_vec ) <NEWLINE> x = kkt_sol [ : n ] <NEWLINE> lagrange_multipliers = - kkt_sol [ n : n + m ] <NEWLINE> <NEWLINE> return x , lagrange_multipliers <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def var ( self , * args , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> kwds [ <STRING> ] = <STRING> <NEWLINE> res = self . stats ( * args , ** kwds ) <NEWLINE> if isinstance ( res , ndarray ) and res . ndim == <NUMBER> : <NEWLINE> <TAB> return res [ ( ) ] <NEWLINE> <UNTAB> return res <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_object_dtype ( arr_or_dtype ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if arr_or_dtype is None : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> tipo = _get_dtype_type ( arr_or_dtype ) <NEWLINE> return issubclass ( tipo , np . object_ ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def bind_C ( name = None ) : <NEWLINE> <TAB> <NEWLINE> return Attribute ( <STRING> , [ String ( name ) ] if name else [ ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _new_args_filter ( cls , arg_sequence ) : <NEWLINE> <TAB> <NEWLINE> for arg in arg_sequence : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if not isinstance ( arg , Expr ) or arg . is_real is False or ( <NEWLINE> arg . is_number and <NEWLINE> not arg . is_comparable ) : <NEWLINE> <TAB> raise ValueError ( <STRING> % arg ) <NEWLINE> <NEWLINE> <UNTAB> if arg == cls . zero : <NEWLINE> <TAB> raise ShortCircuit ( arg ) <NEWLINE> <UNTAB> elif arg == cls . identity : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> elif arg . func == cls : <NEWLINE> <TAB> for x in arg . args : <NEWLINE> <TAB> yield x <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> yield arg <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _compute_p_max ( m_max ) : <NEWLINE> <TAB> <NEWLINE> sqrt_m_max = np . sqrt ( m_max ) <NEWLINE> p_low = int ( np . floor ( sqrt_m_max ) ) <NEWLINE> p_high = int ( np . ceil ( sqrt_m_max + <NUMBER> ) ) <NEWLINE> return max ( p for p in range ( p_low , p_high + <NUMBER> ) if p * ( p - <NUMBER> ) <= m_max + <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def normalize ( input , p = <NUMBER> , dim = <NUMBER> , eps = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return input / input . norm ( p , dim , True ) . clamp ( min = eps ) . expand_as ( input ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def choose_ncv ( k ) : <NEWLINE> <TAB> <NEWLINE> return max ( <NUMBER> * k + <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def render_rect_filled ( self , x1 , y1 , x2 , y2 ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _repr_latex_ ( self ) : <NEWLINE> <TAB> <NEWLINE> if config . get_option ( <STRING> ) : <NEWLINE> <TAB> return self . to_latex ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , optimizer ) : <NEWLINE> <TAB> <NEWLINE> self . _optimizer = optimizer <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_zz_cyclotomic_poly ( n , K ) : <NEWLINE> <TAB> <NEWLINE> h = [ K . one , - K . one ] <NEWLINE> <NEWLINE> for p , k in factorint ( n ) . items ( ) : <NEWLINE> <TAB> h = dup_quo ( dup_inflate ( h , p , K ) , h , K ) <NEWLINE> h = dup_inflate ( h , p ** ( k - <NUMBER> ) , K ) <NEWLINE> <NEWLINE> <UNTAB> return h <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _find_closest_point_on_path ( lc , point ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> ds = np . sum ( ( lc - point [ None , : ] ) ** <NUMBER> , <NUMBER> ) <NEWLINE> imin = np . argmin ( ds ) <NEWLINE> <NEWLINE> dmin = np . inf <NEWLINE> xcmin = None <NEWLINE> legmin = ( None , None ) <NEWLINE> <NEWLINE> closed = _is_closed_polygon ( lc ) <NEWLINE> <NEWLINE> <NEWLINE> legs = [ ] <NEWLINE> if imin > <NUMBER> or closed : <NEWLINE> <TAB> legs . append ( ( ( imin - <NUMBER> ) % len ( lc ) , imin ) ) <NEWLINE> <UNTAB> if imin < len ( lc ) - <NUMBER> or closed : <NEWLINE> <TAB> legs . append ( ( imin , ( imin + <NUMBER> ) % len ( lc ) ) ) <NEWLINE> <NEWLINE> <UNTAB> for leg in legs : <NEWLINE> <TAB> d , xc = _find_closest_point_on_leg ( lc [ leg [ <NUMBER> ] ] , lc [ leg [ <NUMBER> ] ] , point ) <NEWLINE> if d < dmin : <NEWLINE> <TAB> dmin = d <NEWLINE> xcmin = xc <NEWLINE> legmin = leg <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return ( dmin , xcmin , legmin ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def camera ( ) : <NEWLINE> <TAB> <NEWLINE> return load ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_base_exp ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> b , e = self . args <NEWLINE> if b . is_Rational and b . p == <NUMBER> and b . q != <NUMBER> : <NEWLINE> <TAB> return Integer ( b . q ) , - e <NEWLINE> <UNTAB> return b , e <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def to_int32 ( x , name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return cast ( x , dtypes . int32 , name = name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def latest_summaries ( base_dir ) : <NEWLINE> <TAB> <NEWLINE> return [ e for e in latest_events ( base_dir ) if e . HasField ( <STRING> ) ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _find_range ( self ) : <NEWLINE> <TAB> <NEWLINE> b = self . _boundaries [ self . _inside ] <NEWLINE> self . vmin = b [ <NUMBER> ] <NEWLINE> self . vmax = b [ - <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_rasterization_zorder ( self , z ) : <NEWLINE> <TAB> <NEWLINE> self . _rasterization_zorder = z <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def module_help ( self , module ) : <NEWLINE> <TAB> <NEWLINE> helplist = [ ] <NEWLINE> self . _render_our_module_key_flags ( module , helplist ) <NEWLINE> return <STRING> . join ( helplist ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_ordered_terms ( self , order = None , data = False ) : <NEWLINE> <TAB> <NEWLINE> key , reverse = self . _parse_order ( order ) <NEWLINE> terms , gens = self . as_terms ( ) <NEWLINE> <NEWLINE> if not any ( term . is_Order for term , _ in terms ) : <NEWLINE> <TAB> ordered = sorted ( terms , key = key , reverse = reverse ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> _terms , _order = [ ] , [ ] <NEWLINE> <NEWLINE> for term , repr in terms : <NEWLINE> <TAB> if not term . is_Order : <NEWLINE> <TAB> _terms . append ( ( term , repr ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> _order . append ( ( term , repr ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> ordered = sorted ( _terms , key = key , reverse = True ) + sorted ( _order , key = key , reverse = True ) <NEWLINE> <NEWLINE> <UNTAB> if data : <NEWLINE> <TAB> return ordered , gens <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return [ term for term , _ in ordered ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _to_m8 ( key ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( key , Timedelta ) : <NEWLINE> <NEWLINE> <TAB> key = Timedelta ( key ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return np . int64 ( key . value ) . view ( _TD_DTYPE ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_position ( self , figure , return_all = False ) : <NEWLINE> <TAB> <NEWLINE> gridspec = self . get_gridspec ( ) <NEWLINE> nrows , ncols = gridspec . get_geometry ( ) <NEWLINE> rows , cols = np . unravel_index ( <NEWLINE> [ self . num1 ] if self . num2 is None else [ self . num1 , self . num2 ] , <NEWLINE> ( nrows , ncols ) ) <NEWLINE> fig_bottoms , fig_tops , fig_lefts , fig_rights = gridspec . get_grid_positions ( figure ) <NEWLINE> <NEWLINE> fig_bottom = fig_bottoms [ rows ] . min ( ) <NEWLINE> fig_top = fig_tops [ rows ] . max ( ) <NEWLINE> fig_left = fig_lefts [ cols ] . min ( ) <NEWLINE> fig_right = fig_rights [ cols ] . max ( ) <NEWLINE> figbox = Bbox . from_extents ( fig_left , fig_bottom , fig_right , fig_top ) <NEWLINE> <NEWLINE> if return_all : <NEWLINE> <TAB> return figbox , rows [ <NUMBER> ] , cols [ <NUMBER> ] , nrows , ncols <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return figbox <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def savepoint ( self , conn , savepoint , name = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return savepoint ( name = name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def step ( self , closure = None ) : <NEWLINE> <TAB> <NEWLINE> loss = None <NEWLINE> if closure is not None : <NEWLINE> <TAB> loss = closure ( ) <NEWLINE> <NEWLINE> <UNTAB> for group in self . param_groups : <NEWLINE> <TAB> for p in group [ <STRING> ] : <NEWLINE> <TAB> if p . grad is None : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> grad = p . grad . data <NEWLINE> if grad . is_sparse : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> amsgrad = group [ <STRING> ] <NEWLINE> <NEWLINE> state = self . state [ p ] <NEWLINE> <NEWLINE> <NEWLINE> if len ( state ) == <NUMBER> : <NEWLINE> <TAB> state [ <STRING> ] = <NUMBER> <NEWLINE> <NEWLINE> state [ <STRING> ] = torch . zeros_like ( p . data ) <NEWLINE> <NEWLINE> state [ <STRING> ] = torch . zeros_like ( p . data ) <NEWLINE> if amsgrad : <NEWLINE> <NEWLINE> <TAB> state [ <STRING> ] = torch . zeros_like ( p . data ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> exp_avg , exp_avg_sq = state [ <STRING> ] , state [ <STRING> ] <NEWLINE> if amsgrad : <NEWLINE> <TAB> max_exp_avg_sq = state [ <STRING> ] <NEWLINE> <UNTAB> beta1 , beta2 = group [ <STRING> ] <NEWLINE> <NEWLINE> state [ <STRING> ] += <NUMBER> <NEWLINE> <NEWLINE> if group [ <STRING> ] != <NUMBER> : <NEWLINE> <TAB> grad = grad . add ( group [ <STRING> ] , p . data ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> exp_avg . mul_ ( beta1 ) . add_ ( <NUMBER> - beta1 , grad ) <NEWLINE> exp_avg_sq . mul_ ( beta2 ) . addcmul_ ( <NUMBER> - beta2 , grad , grad ) <NEWLINE> if amsgrad : <NEWLINE> <NEWLINE> <TAB> torch . max ( max_exp_avg_sq , exp_avg_sq , out = max_exp_avg_sq ) <NEWLINE> <NEWLINE> denom = max_exp_avg_sq . sqrt ( ) . add_ ( group [ <STRING> ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> denom = exp_avg_sq . sqrt ( ) . add_ ( group [ <STRING> ] ) <NEWLINE> <NEWLINE> <UNTAB> bias_correction1 = <NUMBER> - beta1 ** state [ <STRING> ] <NEWLINE> bias_correction2 = <NUMBER> - beta2 ** state [ <STRING> ] <NEWLINE> step_size = group [ <STRING> ] * math . sqrt ( bias_correction2 ) / bias_correction1 <NEWLINE> <NEWLINE> p . data . addcdiv_ ( - step_size , exp_avg , denom ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return loss <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def bucketized_column ( source_column , boundaries ) : <NEWLINE> <TAB> <NEWLINE> return _BucketizedColumn ( source_column , boundaries ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_fontstyle ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _fontproperties . get_style ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_bounds ( self , * args ) : <NEWLINE> <TAB> <NEWLINE> if len ( args ) == <NUMBER> : <NEWLINE> <TAB> l , b , w , h = args [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> l , b , w , h = args <NEWLINE> <UNTAB> self . _x = l <NEWLINE> self . _y = b <NEWLINE> self . _width = w <NEWLINE> self . _height = h <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def tril ( m , k = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if m . ndim != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if not len ( set ( m . chunks [ <NUMBER> ] + m . chunks [ <NUMBER> ] ) ) == <NUMBER> : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> raise ValueError ( msg ) <NEWLINE> <NEWLINE> <UNTAB> rdim = len ( m . chunks [ <NUMBER> ] ) <NEWLINE> hdim = len ( m . chunks [ <NUMBER> ] ) <NEWLINE> chunk = m . chunks [ <NUMBER> ] [ <NUMBER> ] <NEWLINE> <NEWLINE> token = tokenize ( m , k ) <NEWLINE> name = <STRING> + token <NEWLINE> <NEWLINE> dsk = { } <NEWLINE> for i in range ( rdim ) : <NEWLINE> <TAB> for j in range ( hdim ) : <NEWLINE> <TAB> if chunk * ( j - i + <NUMBER> ) < k : <NEWLINE> <TAB> dsk [ ( name , i , j ) ] = ( m . name , i , j ) <NEWLINE> <UNTAB> elif chunk * ( j - i - <NUMBER> ) < k <= chunk * ( j - i + <NUMBER> ) : <NEWLINE> <TAB> dsk [ ( name , i , j ) ] = ( np . tril , ( m . name , i , j ) , k - ( chunk * ( j - i ) ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dsk [ ( name , i , j ) ] = ( np . zeros , ( m . chunks [ <NUMBER> ] [ i ] , m . chunks [ <NUMBER> ] [ j ] ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> dsk = sharedict . merge ( m . dask , ( name , dsk ) , dependencies = { name : { m . name } } ) <NEWLINE> return Array ( dsk , name , shape = m . shape , chunks = m . chunks , dtype = m . dtype ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dmp_gf_sqf_part ( f , K ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def plot ( self , ax , kws ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> scout , = ax . plot ( [ ] , [ ] , ** kws ) <NEWLINE> <NEWLINE> orig_color = kws . pop ( <STRING> , scout . get_color ( ) ) <NEWLINE> orig_marker = kws . pop ( <STRING> , scout . get_marker ( ) ) <NEWLINE> orig_linewidth = kws . pop ( <STRING> , <NEWLINE> kws . pop ( <STRING> , scout . get_linewidth ( ) ) ) <NEWLINE> <NEWLINE> orig_dashes = kws . pop ( <STRING> , <STRING> ) <NEWLINE> <NEWLINE> kws . setdefault ( <STRING> , kws . pop ( <STRING> , <NUMBER> ) ) <NEWLINE> kws . setdefault ( <STRING> , kws . pop ( <STRING> , <STRING> ) ) <NEWLINE> <NEWLINE> scout . remove ( ) <NEWLINE> <NEWLINE> <NEWLINE> err_kws = self . err_kws . copy ( ) <NEWLINE> if self . err_style == <STRING> : <NEWLINE> <TAB> err_kws . setdefault ( <STRING> , <NUMBER> ) <NEWLINE> <UNTAB> elif self . err_style == <STRING> : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> elif self . err_style is not None : <NEWLINE> <TAB> err = <STRING> <NEWLINE> raise ValueError ( err . format ( self . err_style ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for semantics , data in self . subset_data ( ) : <NEWLINE> <NEWLINE> <TAB> hue , size , style = semantics <NEWLINE> x , y , units = data [ <STRING> ] , data [ <STRING> ] , data . get ( <STRING> , None ) <NEWLINE> <NEWLINE> if self . estimator is not None : <NEWLINE> <TAB> if self . units is not None : <NEWLINE> <TAB> err = <STRING> <NEWLINE> raise ValueError ( err ) <NEWLINE> <UNTAB> x , y , y_ci = self . aggregate ( y , x , units ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> y_ci = None <NEWLINE> <NEWLINE> <UNTAB> kws [ <STRING> ] = self . palette . get ( hue , orig_color ) <NEWLINE> kws [ <STRING> ] = self . dashes . get ( style , orig_dashes ) <NEWLINE> kws [ <STRING> ] = self . markers . get ( style , orig_marker ) <NEWLINE> kws [ <STRING> ] = self . sizes . get ( size , orig_linewidth ) <NEWLINE> <NEWLINE> line , = ax . plot ( [ ] , [ ] , ** kws ) <NEWLINE> line_color = line . get_color ( ) <NEWLINE> line_alpha = line . get_alpha ( ) <NEWLINE> line_capstyle = line . get_solid_capstyle ( ) <NEWLINE> line . remove ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> x , y = np . asarray ( x ) , np . asarray ( y ) <NEWLINE> <NEWLINE> if self . units is None : <NEWLINE> <TAB> line , = ax . plot ( x , y , ** kws ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for u in units . unique ( ) : <NEWLINE> <TAB> rows = np . asarray ( units == u ) <NEWLINE> ax . plot ( x [ rows ] , y [ rows ] , ** kws ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if y_ci is not None : <NEWLINE> <NEWLINE> <TAB> low , high = np . asarray ( y_ci [ <STRING> ] ) , np . asarray ( y_ci [ <STRING> ] ) <NEWLINE> <NEWLINE> if self . err_style == <STRING> : <NEWLINE> <NEWLINE> <TAB> ax . fill_between ( x , low , high , color = line_color , ** err_kws ) <NEWLINE> <NEWLINE> <UNTAB> elif self . err_style == <STRING> : <NEWLINE> <NEWLINE> <TAB> y_err = ci_to_errsize ( ( low , high ) , y ) <NEWLINE> ebars = ax . errorbar ( x , y , y_err , linestyle = <STRING> , <NEWLINE> color = line_color , alpha = line_alpha , <NEWLINE> ** err_kws ) <NEWLINE> <NEWLINE> <NEWLINE> for obj in ebars . get_children ( ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> obj . set_capstyle ( line_capstyle ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> self . label_axes ( ax ) <NEWLINE> if self . legend : <NEWLINE> <TAB> self . add_legend_data ( ax ) <NEWLINE> handles , _ = ax . get_legend_handles_labels ( ) <NEWLINE> if handles : <NEWLINE> <TAB> ax . legend ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _transform_labels ( self , mode , labels ) : <NEWLINE> <TAB> <NEWLINE> if ( mode == model_fn . ModeKeys . INFER ) or ( labels is None ) : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> labels_tensor = _to_labels_tensor ( labels , self . _label_name ) <NEWLINE> _check_no_sparse_tensor ( labels_tensor ) <NEWLINE> return labels_tensor <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _smooth ( image , sigma , mode , cval , multichannel = None ) : <NEWLINE> <TAB> <NEWLINE> multichannel = _multichannel_default ( multichannel , image . ndim ) <NEWLINE> smoothed = np . empty ( image . shape , dtype = np . double ) <NEWLINE> <NEWLINE> <NEWLINE> if multichannel : <NEWLINE> <TAB> sigma = ( sigma , ) * ( image . ndim - <NUMBER> ) + ( <NUMBER> , ) <NEWLINE> <UNTAB> ndi . gaussian_filter ( image , sigma , output = smoothed , <NEWLINE> mode = mode , cval = cval ) <NEWLINE> return smoothed <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def restart_reduce ( self , rank ) : <NEWLINE> <TAB> <NEWLINE> if self . collapsed is not None : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> assert rank > <NUMBER> <NEWLINE> if len ( self . cs ) > rank : <NEWLINE> <TAB> del self . cs [ : ] <NEWLINE> del self . ds [ : ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def flag_values_dict ( self ) : <NEWLINE> <TAB> <NEWLINE> return { name : flag . value for name , flag in six . iteritems ( self . _flags ( ) ) } <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def solve_poly_system ( seq , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> polys , opt = parallel_poly_from_expr ( seq , * gens , ** args ) <NEWLINE> <UNTAB> except PolificationFailed as exc : <NEWLINE> <TAB> raise ComputationFailed ( <STRING> , len ( seq ) , exc ) <NEWLINE> <NEWLINE> <UNTAB> if len ( polys ) == len ( opt . gens ) == <NUMBER> : <NEWLINE> <TAB> f , g = polys <NEWLINE> <NEWLINE> if all ( i <= <NUMBER> for i in f . degree_list ( ) + g . degree_list ( ) ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> return solve_biquadratic ( f , g , opt ) <NEWLINE> <UNTAB> except SolveFailed : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return solve_generic ( polys , opt ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rosen_hess_prod ( x , p ) : <NEWLINE> <TAB> <NEWLINE> x = atleast_1d ( x ) <NEWLINE> Hp = numpy . zeros ( len ( x ) , dtype = x . dtype ) <NEWLINE> Hp [ <NUMBER> ] = ( <NUMBER> * x [ <NUMBER> ] ** <NUMBER> - <NUMBER> * x [ <NUMBER> ] + <NUMBER> ) * p [ <NUMBER> ] - <NUMBER> * x [ <NUMBER> ] * p [ <NUMBER> ] <NEWLINE> Hp [ <NUMBER> : - <NUMBER> ] = ( - <NUMBER> * x [ : - <NUMBER> ] * p [ : - <NUMBER> ] + <NEWLINE> ( <NUMBER> + <NUMBER> * x [ <NUMBER> : - <NUMBER> ] ** <NUMBER> - <NUMBER> * x [ <NUMBER> : ] ) * p [ <NUMBER> : - <NUMBER> ] - <NEWLINE> <NUMBER> * x [ <NUMBER> : - <NUMBER> ] * p [ <NUMBER> : ] ) <NEWLINE> Hp [ - <NUMBER> ] = - <NUMBER> * x [ - <NUMBER> ] * p [ - <NUMBER> ] + <NUMBER> * p [ - <NUMBER> ] <NEWLINE> return Hp <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def persist ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> traverse = kwargs . pop ( <STRING> , True ) <NEWLINE> optimize_graph = kwargs . pop ( <STRING> , True ) <NEWLINE> <NEWLINE> collections , repack = unpack_collections ( * args , traverse = traverse ) <NEWLINE> if not collections : <NEWLINE> <TAB> return args <NEWLINE> <NEWLINE> <UNTAB> schedule = get_scheduler ( scheduler = kwargs . pop ( <STRING> , None ) , <NEWLINE> collections = collections ) <NEWLINE> <NEWLINE> if inspect . ismethod ( schedule ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> from distributed . client import default_client <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> client = default_client ( ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if client . get == schedule : <NEWLINE> <TAB> results = client . persist ( collections , <NEWLINE> optimize_graph = optimize_graph , <NEWLINE> ** kwargs ) <NEWLINE> return repack ( results ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> dsk = collections_to_dsk ( collections , optimize_graph , ** kwargs ) <NEWLINE> keys , postpersists = [ ] , [ ] <NEWLINE> for a in collections : <NEWLINE> <TAB> a_keys = list ( flatten ( a . __dask_keys__ ( ) ) ) <NEWLINE> rebuild , state = a . __dask_postpersist__ ( ) <NEWLINE> keys . extend ( a_keys ) <NEWLINE> postpersists . append ( ( rebuild , a_keys , state ) ) <NEWLINE> <NEWLINE> <UNTAB> results = schedule ( dsk , keys , ** kwargs ) <NEWLINE> d = dict ( zip ( keys , results ) ) <NEWLINE> results2 = [ r ( { k : d [ k ] for k in ks } , * s ) for r , ks , s in postpersists ] <NEWLINE> return repack ( results2 ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def reload ( module ) : <NEWLINE> <TAB> <NEWLINE> if not module or not isinstance ( module , types . ModuleType ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> name = module . __spec__ . name <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> name = module . __name__ <NEWLINE> <NEWLINE> <UNTAB> if sys . modules . get ( name ) is not module : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise ImportError ( msg . format ( name ) , name = name ) <NEWLINE> <UNTAB> if name in _RELOADING : <NEWLINE> <TAB> return _RELOADING [ name ] <NEWLINE> <UNTAB> _RELOADING [ name ] = module <NEWLINE> try : <NEWLINE> <TAB> parent_name = name . rpartition ( <STRING> ) [ <NUMBER> ] <NEWLINE> if parent_name : <NEWLINE> <TAB> try : <NEWLINE> <TAB> parent = sys . modules [ parent_name ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise ImportError ( msg . format ( parent_name ) , <NEWLINE> name = parent_name ) from None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pkgpath = parent . __path__ <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> pkgpath = None <NEWLINE> <UNTAB> target = module <NEWLINE> spec = module . __spec__ = _bootstrap . _find_spec ( name , pkgpath , target ) <NEWLINE> _bootstrap . _exec ( spec , module ) <NEWLINE> <NEWLINE> return sys . modules [ name ] <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> try : <NEWLINE> <TAB> del _RELOADING [ name ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def exception_matches ( self , exc_type , exc_value , trace_back ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if issubclass ( exc_type , self . exception ) : <NEWLINE> <TAB> if self . regexp is not None : <NEWLINE> <TAB> val = str ( exc_value ) <NEWLINE> <NEWLINE> if not self . regexp . search ( val ) : <NEWLINE> <TAB> msg = <STRING> . format ( <NEWLINE> pat = self . regexp . pattern , val = val ) <NEWLINE> e = AssertionError ( msg ) <NEWLINE> raise_with_traceback ( e , trace_back ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , func_files , func_name = None ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( func_files , list ) : <NEWLINE> <TAB> func_files = [ func_files ] <NEWLINE> <NEWLINE> <UNTAB> self . func_name = func_name <NEWLINE> <NEWLINE> <NEWLINE> self . func_files = func_files <NEWLINE> self . load_c_code ( func_files ) <NEWLINE> <NEWLINE> if len ( self . code_sections ) == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if self . func_name is not None : <NEWLINE> <TAB> if <STRING> in self . code_sections : <NEWLINE> <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if <STRING> in self . code_sections : <NEWLINE> <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def assert_global_step ( global_step_tensor ) : <NEWLINE> <TAB> <NEWLINE> if not ( isinstance ( global_step_tensor , variables . Variable ) or <NEWLINE> isinstance ( global_step_tensor , ops . Tensor ) or <NEWLINE> resource_variable_ops . is_resource_variable ( global_step_tensor ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> % <NEWLINE> global_step_tensor ) <NEWLINE> <NEWLINE> <UNTAB> if not global_step_tensor . dtype . base_dtype . is_integer : <NEWLINE> <TAB> raise TypeError ( <STRING> % <NEWLINE> global_step_tensor . dtype ) <NEWLINE> <NEWLINE> <UNTAB> if ( global_step_tensor . get_shape ( ) . ndims != <NUMBER> and <NEWLINE> global_step_tensor . get_shape ( ) . is_fully_defined ( ) ) : <NEWLINE> <TAB> raise TypeError ( <STRING> % <NEWLINE> global_step_tensor . get_shape ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_fontsize ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _fontproperties . get_size_in_points ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def draggable ( self , state = None , use_blit = False , update = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> warn_deprecated ( <STRING> , <NEWLINE> message = <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> if state is None : <NEWLINE> <TAB> state = not self . get_draggable ( ) <NEWLINE> <NEWLINE> <UNTAB> self . set_draggable ( state , use_blit , update ) <NEWLINE> <NEWLINE> return self . _draggable <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def polyder ( c , m = <NUMBER> , scl = <NUMBER> , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> c = np . array ( c , ndmin = <NUMBER> , copy = <NUMBER> ) <NEWLINE> if c . dtype . char in <STRING> : <NEWLINE> <NEWLINE> <TAB> c = c + <NUMBER> <NEWLINE> <UNTAB> cdt = c . dtype <NEWLINE> cnt , iaxis = [ int ( t ) for t in [ m , axis ] ] <NEWLINE> <NEWLINE> if cnt != m : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if cnt < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if iaxis != axis : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> iaxis = normalize_axis_index ( iaxis , c . ndim ) <NEWLINE> <NEWLINE> if cnt == <NUMBER> : <NEWLINE> <TAB> return c <NEWLINE> <NEWLINE> <UNTAB> c = np . moveaxis ( c , iaxis , <NUMBER> ) <NEWLINE> n = len ( c ) <NEWLINE> if cnt >= n : <NEWLINE> <TAB> c = c [ : <NUMBER> ] * <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for i in range ( cnt ) : <NEWLINE> <TAB> n = n - <NUMBER> <NEWLINE> c *= scl <NEWLINE> der = np . empty ( ( n , ) + c . shape [ <NUMBER> : ] , dtype = cdt ) <NEWLINE> for j in range ( n , <NUMBER> , - <NUMBER> ) : <NEWLINE> <TAB> der [ j - <NUMBER> ] = j * c [ j ] <NEWLINE> <UNTAB> c = der <NEWLINE> <UNTAB> <UNTAB> c = np . moveaxis ( c , <NUMBER> , iaxis ) <NEWLINE> return c <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ checkpointable . no_automatic_dependency_tracking <NEWLINE> def pop ( self ) : <NEWLINE> <TAB> <NEWLINE> if not self . layers : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> self . _layers . pop ( ) <NEWLINE> if not self . layers : <NEWLINE> <TAB> self . outputs = None <NEWLINE> self . inputs = None <NEWLINE> self . built = False <NEWLINE> <UNTAB> elif self . _is_graph_network : <NEWLINE> <TAB> self . layers [ - <NUMBER> ] . _outbound_nodes = [ ] <NEWLINE> self . outputs = [ self . layers [ - <NUMBER> ] . output ] <NEWLINE> self . _init_graph_network ( self . inputs , self . outputs , name = self . name ) <NEWLINE> self . built = True <NEWLINE> <UNTAB> self . _can_use_graph_functions = all ( <NEWLINE> layer . _can_use_graph_functions for layer in self . layers ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def logsf ( self , x , * args , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> args , loc , scale = self . _parse_args ( * args , ** kwds ) <NEWLINE> x , loc , scale = map ( asarray , ( x , loc , scale ) ) <NEWLINE> args = tuple ( map ( asarray , args ) ) <NEWLINE> dtyp = np . find_common_type ( [ x . dtype , np . float64 ] , [ ] ) <NEWLINE> x = np . asarray ( ( x - loc ) / scale , dtype = dtyp ) <NEWLINE> cond0 = self . _argcheck ( * args ) & ( scale > <NUMBER> ) <NEWLINE> cond1 = self . _open_support_mask ( x ) & ( scale > <NUMBER> ) <NEWLINE> cond2 = cond0 & ( x <= self . a ) <NEWLINE> cond = cond0 & cond1 <NEWLINE> output = empty ( shape ( cond ) , dtyp ) <NEWLINE> output . fill ( NINF ) <NEWLINE> place ( output , ( <NUMBER> - cond0 ) + np . isnan ( x ) , self . badvalue ) <NEWLINE> place ( output , cond2 , <NUMBER> ) <NEWLINE> if np . any ( cond ) : <NEWLINE> <TAB> goodargs = argsreduce ( cond , * ( ( x , ) + args ) ) <NEWLINE> place ( output , cond , self . _logsf ( * goodargs ) ) <NEWLINE> <UNTAB> if output . ndim == <NUMBER> : <NEWLINE> <TAB> return output [ ( ) ] <NEWLINE> <UNTAB> return output <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_empty ( G ) : <NEWLINE> <TAB> <NEWLINE> return not any ( G . adj . values ( ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def isalnum ( a ) : <NEWLINE> <TAB> <NEWLINE> return _vec_string ( a , bool_ , <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def put ( self , key , value , format = None , append = False , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if format is None : <NEWLINE> <TAB> format = get_option ( <STRING> ) or <STRING> <NEWLINE> <UNTAB> kwargs = self . _validate_format ( format , kwargs ) <NEWLINE> self . _write_to_group ( key , value , append = append , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def remove_callback ( self , oid ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> del self . _propobservers [ oid ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def sequences_to_texts ( self , sequences ) : <NEWLINE> <TAB> <NEWLINE> return list ( self . sequences_to_texts_generator ( sequences ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def render_glyph ( self , ox , oy , facename , font_class , sym , fontsize , dpi ) : <NEWLINE> <TAB> <NEWLINE> info = self . _get_info ( facename , font_class , sym , fontsize , dpi ) <NEWLINE> realpath , stat_key = get_realpath_and_stat ( info . font . fname ) <NEWLINE> used_characters = self . used_characters . setdefault ( <NEWLINE> stat_key , ( realpath , set ( ) ) ) <NEWLINE> used_characters [ <NUMBER> ] . add ( info . num ) <NEWLINE> self . mathtext_backend . render_glyph ( ox , oy , info ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _replace ( self , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> if <STRING> in kwds : <NEWLINE> <TAB> if self . mode != kwds [ <STRING> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> new_fields = map ( kwds . pop , self . _fields , list ( self ) ) <NEWLINE> return EstimatorSpec ( * new_fields ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def owner ( self ) : <NEWLINE> <TAB> <NEWLINE> import pwd <NEWLINE> return pwd . getpwuid ( self . stat ( ) . st_uid ) . pw_name <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def nancumsum ( a , axis = None , dtype = None , out = None ) : <NEWLINE> <TAB> <NEWLINE> a , mask = _replace_nan ( a , <NUMBER> ) <NEWLINE> return np . cumsum ( a , axis = axis , dtype = dtype , out = out ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_figure ( self , figure ) : <NEWLINE> <TAB> <NEWLINE> self . _figure = figure <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __matmul__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return self . dot ( other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def pdf ( self , X , mean = None , rowcov = <NUMBER> , colcov = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return np . exp ( self . logpdf ( X , mean , rowcov , colcov ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def restore ( self , save_path ) : <NEWLINE> <TAB> <NEWLINE> status = self . _saver . restore ( save_path = save_path ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . _maybe_create_save_counter ( ) <NEWLINE> return status <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _apply_device_functions ( self , op ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for device_spec in self . _device_function_stack . peek_objs ( ) : <NEWLINE> <TAB> if device_spec . function is None : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> op . _set_device ( device_spec . function ( op ) ) <NEWLINE> <UNTAB> op . _device_code_locations = self . _snapshot_device_function_stack_metadata ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> @ not_implemented_for ( <STRING> ) <NEWLINE> def communicability_exp ( G ) : <NEWLINE> <TAB> <NEWLINE> import scipy . linalg <NEWLINE> nodelist = list ( G ) <NEWLINE> A = nx . to_numpy_matrix ( G , nodelist ) <NEWLINE> <NEWLINE> A [ A != <NUMBER> ] = <NUMBER> <NEWLINE> <NEWLINE> expA = scipy . linalg . expm ( A . A ) <NEWLINE> mapping = dict ( zip ( nodelist , range ( len ( nodelist ) ) ) ) <NEWLINE> c = { } <NEWLINE> for u in G : <NEWLINE> <TAB> c [ u ] = { } <NEWLINE> for v in G : <NEWLINE> <TAB> c [ u ] [ v ] = float ( expA [ mapping [ u ] , mapping [ v ] ] ) <NEWLINE> <UNTAB> <UNTAB> return c <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def concrete ( seq ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( seq , Iterator ) : <NEWLINE> <TAB> seq = list ( seq ) <NEWLINE> <UNTAB> if isinstance ( seq , ( tuple , list ) ) : <NEWLINE> <TAB> seq = list ( map ( concrete , seq ) ) <NEWLINE> <UNTAB> return seq <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def save_pkl ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> with open ( self . key_pkl , <STRING> ) as f : <NEWLINE> <TAB> pickle . dump ( self , f , protocol = pickle . HIGHEST_PROTOCOL ) <NEWLINE> <UNTAB> <UNTAB> except pickle . PicklingError : <NEWLINE> <TAB> _logger . warning ( <STRING> , <NEWLINE> self . keys ) <NEWLINE> os . remove ( self . key_pkl ) <NEWLINE> raise <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _root_linearmixing_doc ( ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dilation2d_backprop_filter ( input , filter , out_backprop , strides , rates , padding , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if not isinstance ( strides , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % strides ) <NEWLINE> <UNTAB> strides = [ _execute . make_int ( _i , <STRING> ) for _i in strides ] <NEWLINE> if not isinstance ( rates , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % rates ) <NEWLINE> <UNTAB> rates = [ _execute . make_int ( _i , <STRING> ) for _i in rates ] <NEWLINE> padding = _execute . make_str ( padding , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , filter = filter , <NEWLINE> out_backprop = out_backprop , strides = strides , rates = rates , <NEWLINE> padding = padding , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) , <NEWLINE> <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , <NEWLINE> input , filter , out_backprop , <STRING> , strides , <STRING> , rates , <NEWLINE> <STRING> , padding ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return dilation2d_backprop_filter_eager_fallback ( <NEWLINE> input , filter , out_backprop , strides = strides , rates = rates , <NEWLINE> padding = padding , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def herm2poly ( c ) : <NEWLINE> <TAB> <NEWLINE> from . polynomial import polyadd , polysub , polymulx <NEWLINE> <NEWLINE> [ c ] = pu . as_series ( [ c ] ) <NEWLINE> n = len ( c ) <NEWLINE> if n == <NUMBER> : <NEWLINE> <TAB> return c <NEWLINE> <UNTAB> if n == <NUMBER> : <NEWLINE> <TAB> c [ <NUMBER> ] *= <NUMBER> <NEWLINE> return c <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> c0 = c [ - <NUMBER> ] <NEWLINE> c1 = c [ - <NUMBER> ] <NEWLINE> <NEWLINE> for i in range ( n - <NUMBER> , <NUMBER> , - <NUMBER> ) : <NEWLINE> <TAB> tmp = c0 <NEWLINE> c0 = polysub ( c [ i - <NUMBER> ] , c1 * ( <NUMBER> * ( i - <NUMBER> ) ) ) <NEWLINE> c1 = polyadd ( tmp , polymulx ( c1 ) * <NUMBER> ) <NEWLINE> <UNTAB> return polyadd ( c0 , polymulx ( c1 ) * <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_size ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _size <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_xaxis_text2_transform ( self , pad_points ) : <NEWLINE> <TAB> <NEWLINE> labels_align = matplotlib . rcParams [ <STRING> ] <NEWLINE> return ( self . get_xaxis_transform ( which = <STRING> ) + <NEWLINE> mtransforms . ScaledTranslation ( <NUMBER> , pad_points / <NUMBER> , <NEWLINE> self . figure . dpi_scale_trans ) , <NEWLINE> <STRING> , labels_align ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def LC ( f , order = None ) : <NEWLINE> <TAB> <NEWLINE> if order is not None : <NEWLINE> <TAB> return f . coeffs ( order ) [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> if hasattr ( f . rep , <STRING> ) : <NEWLINE> <TAB> result = f . rep . LC ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise OperationNotSupported ( f , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return f . rep . dom . to_sympy ( result ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _sha256 ( path ) : <NEWLINE> <TAB> <NEWLINE> sha256hash = hashlib . sha256 ( ) <NEWLINE> chunk_size = <NUMBER> <NEWLINE> with open ( path , <STRING> ) as f : <NEWLINE> <TAB> while True : <NEWLINE> <TAB> buffer = f . read ( chunk_size ) <NEWLINE> if not buffer : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> sha256hash . update ( buffer ) <NEWLINE> <UNTAB> <UNTAB> return sha256hash . hexdigest ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _process_tags ( self ) : <NEWLINE> <TAB> <NEWLINE> tags = self . tags <NEWLINE> for code , ( name , default , dtype , count , validate ) in TIFF_TAGS . items ( ) : <NEWLINE> <TAB> if name in tags : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if validate : <NEWLINE> <TAB> try : <NEWLINE> <TAB> if tags [ name ] . count == <NUMBER> : <NEWLINE> <TAB> setattr ( self , name , validate [ tags [ name ] . value ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> setattr ( self , name , tuple ( <NEWLINE> validate [ value ] for value in tags [ name ] . value ) ) <NEWLINE> <UNTAB> <UNTAB> except KeyError : <NEWLINE> <TAB> raise ValueError ( <STRING> % <NEWLINE> ( name , tags [ name ] . value ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif default is not None : <NEWLINE> <TAB> setattr ( self , name , validate [ default ] if validate else default ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if <STRING> in tags : <NEWLINE> <TAB> tag = tags [ <STRING> ] <NEWLINE> if tag . count == <NUMBER> : <NEWLINE> <TAB> self . bits_per_sample = tag . value <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> value = tag . value [ : self . samples_per_pixel ] <NEWLINE> if any ( ( v - value [ <NUMBER> ] for v in value ) ) : <NEWLINE> <TAB> self . bits_per_sample = value <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . bits_per_sample = value [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if <STRING> in tags : <NEWLINE> <TAB> tag = tags [ <STRING> ] <NEWLINE> if tag . count == <NUMBER> : <NEWLINE> <TAB> self . sample_format = TIFF_SAMPLE_FORMATS [ tag . value ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> value = tag . value [ : self . samples_per_pixel ] <NEWLINE> if any ( ( v - value [ <NUMBER> ] for v in value ) ) : <NEWLINE> <TAB> self . sample_format = [ TIFF_SAMPLE_FORMATS [ v ] <NEWLINE> for v in value ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . sample_format = TIFF_SAMPLE_FORMATS [ value [ <NUMBER> ] ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if <STRING> not in tags : <NEWLINE> <TAB> self . photometric = None <NEWLINE> <NEWLINE> <UNTAB> if <STRING> in tags : <NEWLINE> <TAB> if <STRING> not in tags : <NEWLINE> <TAB> self . rows_per_strip = self . image_length <NEWLINE> <UNTAB> self . strips_per_image = int ( math . floor ( <NEWLINE> float ( self . image_length + self . rows_per_strip - <NUMBER> ) / <NEWLINE> self . rows_per_strip ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . strips_per_image = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> key = ( self . sample_format , self . bits_per_sample ) <NEWLINE> self . dtype = self . _dtype = TIFF_SAMPLE_DTYPES . get ( key , None ) <NEWLINE> <NEWLINE> if <STRING> not in self . tags or <STRING> not in self . tags : <NEWLINE> <NEWLINE> <TAB> self . image_length = <NUMBER> <NEWLINE> self . image_width = <NUMBER> <NEWLINE> self . image_depth = <NUMBER> <NEWLINE> self . strip_offsets = <NUMBER> <NEWLINE> self . _shape = ( ) <NEWLINE> self . shape = ( ) <NEWLINE> self . axes = <STRING> <NEWLINE> <NEWLINE> <UNTAB> if self . is_vista or self . parent . is_vista : <NEWLINE> <NEWLINE> <TAB> self . image_depth = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> if self . is_indexed : <NEWLINE> <TAB> self . dtype = self . tags [ <STRING> ] . dtype [ <NUMBER> ] <NEWLINE> self . color_map = numpy . array ( self . color_map , self . dtype ) <NEWLINE> dmax = self . color_map . max ( ) <NEWLINE> if dmax < <NUMBER> : <NEWLINE> <TAB> self . dtype = numpy . uint8 <NEWLINE> self . color_map = self . color_map . astype ( self . dtype ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . color_map . shape = ( <NUMBER> , - <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> image_length = self . image_length <NEWLINE> image_width = self . image_width <NEWLINE> image_depth = self . image_depth <NEWLINE> samples_per_pixel = self . samples_per_pixel <NEWLINE> <NEWLINE> if self . is_stk : <NEWLINE> <TAB> assert self . image_depth == <NUMBER> <NEWLINE> planes = self . tags [ <STRING> ] . count <NEWLINE> if self . is_contig : <NEWLINE> <TAB> self . _shape = ( planes , <NUMBER> , <NUMBER> , image_length , image_width , <NEWLINE> samples_per_pixel ) <NEWLINE> if samples_per_pixel == <NUMBER> : <NEWLINE> <TAB> self . shape = ( planes , image_length , image_width ) <NEWLINE> self . axes = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . shape = ( planes , image_length , image_width , <NEWLINE> samples_per_pixel ) <NEWLINE> self . axes = <STRING> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> self . _shape = ( planes , samples_per_pixel , <NUMBER> , image_length , <NEWLINE> image_width , <NUMBER> ) <NEWLINE> if samples_per_pixel == <NUMBER> : <NEWLINE> <TAB> self . shape = ( planes , image_length , image_width ) <NEWLINE> self . axes = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . shape = ( planes , samples_per_pixel , image_length , <NEWLINE> image_width ) <NEWLINE> self . axes = <STRING> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if planes == <NUMBER> : <NEWLINE> <TAB> self . shape = self . shape [ <NUMBER> : ] <NEWLINE> <UNTAB> elif numpy . all ( self . uic2tag . z_distance != <NUMBER> ) : <NEWLINE> <TAB> self . axes = <STRING> + self . axes <NEWLINE> <UNTAB> elif numpy . all ( numpy . diff ( self . uic2tag . time_created ) != <NUMBER> ) : <NEWLINE> <TAB> self . axes = <STRING> + self . axes <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . axes = <STRING> + self . axes <NEWLINE> <NEWLINE> <UNTAB> if self . is_indexed : <NEWLINE> <TAB> assert False , <STRING> <NEWLINE> if self . color_map . shape [ <NUMBER> ] >= <NUMBER> ** self . bits_per_sample : <NEWLINE> <TAB> if image_depth == <NUMBER> : <NEWLINE> <TAB> self . shape = ( planes , image_length , image_width , <NEWLINE> self . color_map . shape [ <NUMBER> ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . shape = ( planes , image_depth , image_length , <NEWLINE> image_width , self . color_map . shape [ <NUMBER> ] ) <NEWLINE> <UNTAB> self . axes = self . axes + <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> warnings . warn ( <STRING> ) <NEWLINE> self . is_indexed = False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif self . is_indexed : <NEWLINE> <TAB> samples = <NUMBER> <NEWLINE> if <STRING> in self . tags : <NEWLINE> <TAB> samples += self . tags [ <STRING> ] . count <NEWLINE> <UNTAB> if self . is_contig : <NEWLINE> <TAB> self . _shape = ( <NUMBER> , <NUMBER> , image_depth , image_length , image_width , <NEWLINE> samples ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _shape = ( <NUMBER> , samples , image_depth , image_length , <NEWLINE> image_width , <NUMBER> ) <NEWLINE> <UNTAB> if self . color_map . shape [ <NUMBER> ] >= <NUMBER> ** self . bits_per_sample : <NEWLINE> <TAB> if image_depth == <NUMBER> : <NEWLINE> <TAB> self . shape = ( image_length , image_width , <NEWLINE> self . color_map . shape [ <NUMBER> ] ) <NEWLINE> self . axes = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . shape = ( image_depth , image_length , image_width , <NEWLINE> self . color_map . shape [ <NUMBER> ] ) <NEWLINE> self . axes = <STRING> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> warnings . warn ( <STRING> ) <NEWLINE> self . is_indexed = False <NEWLINE> if image_depth == <NUMBER> : <NEWLINE> <TAB> self . shape = ( image_length , image_width ) <NEWLINE> self . axes = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . shape = ( image_depth , image_length , image_width ) <NEWLINE> self . axes = <STRING> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif self . is_rgb or samples_per_pixel > <NUMBER> : <NEWLINE> <TAB> if self . is_contig : <NEWLINE> <TAB> self . _shape = ( <NUMBER> , <NUMBER> , image_depth , image_length , image_width , <NEWLINE> samples_per_pixel ) <NEWLINE> if image_depth == <NUMBER> : <NEWLINE> <TAB> self . shape = ( image_length , image_width , samples_per_pixel ) <NEWLINE> self . axes = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . shape = ( image_depth , image_length , image_width , <NEWLINE> samples_per_pixel ) <NEWLINE> self . axes = <STRING> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> self . _shape = ( <NUMBER> , samples_per_pixel , image_depth , <NEWLINE> image_length , image_width , <NUMBER> ) <NEWLINE> if image_depth == <NUMBER> : <NEWLINE> <TAB> self . shape = ( samples_per_pixel , image_length , image_width ) <NEWLINE> self . axes = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . shape = ( samples_per_pixel , image_depth , <NEWLINE> image_length , image_width ) <NEWLINE> self . axes = <STRING> <NEWLINE> <UNTAB> <UNTAB> if False and self . is_rgb and <STRING> in self . tags : <NEWLINE> <NEWLINE> <TAB> extra_samples = self . extra_samples <NEWLINE> if self . tags [ <STRING> ] . count == <NUMBER> : <NEWLINE> <TAB> extra_samples = ( extra_samples , ) <NEWLINE> <UNTAB> for exs in extra_samples : <NEWLINE> <TAB> if exs in ( <STRING> , <STRING> , <STRING> ) : <NEWLINE> <TAB> if self . is_contig : <NEWLINE> <TAB> self . shape = self . shape [ : - <NUMBER> ] + ( <NUMBER> , ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . shape = ( <NUMBER> , ) + self . shape [ <NUMBER> : ] <NEWLINE> <UNTAB> break <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> self . _shape = ( <NUMBER> , <NUMBER> , image_depth , image_length , image_width , <NUMBER> ) <NEWLINE> if image_depth == <NUMBER> : <NEWLINE> <TAB> self . shape = ( image_length , image_width ) <NEWLINE> self . axes = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . shape = ( image_depth , image_length , image_width ) <NEWLINE> self . axes = <STRING> <NEWLINE> <UNTAB> <UNTAB> if not self . compression and <STRING> not in tags : <NEWLINE> <TAB> self . strip_byte_counts = ( <NEWLINE> product ( self . shape ) * ( self . bits_per_sample // <NUMBER> ) , ) <NEWLINE> <NEWLINE> <UNTAB> assert len ( self . shape ) == len ( self . axes ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_timedelta64_dtype ( arr_or_dtype ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if arr_or_dtype is None : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> tipo = _get_dtype_type ( arr_or_dtype ) <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> return issubclass ( tipo , np . timedelta64 ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_bounds ( self , * args ) : <NEWLINE> <TAB> <NEWLINE> if len ( args ) == <NUMBER> : <NEWLINE> <TAB> l , b , w , h = args [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> l , b , w , h = args <NEWLINE> <UNTAB> self . _x0 = l <NEWLINE> self . _y0 = b <NEWLINE> self . _width = w <NEWLINE> self . _height = h <NEWLINE> self . _update_x1 ( ) <NEWLINE> self . _update_y1 ( ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _set_device ( self , device ) : <NEWLINE> <TAB> <NEWLINE> c_api . SetRequestedDevice ( <NEWLINE> self . _graph . _c_graph , <NEWLINE> self . _c_op , <NEWLINE> compat . as_str ( _device_string ( device ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> @ deprecated ( None , <STRING> ) <NEWLINE> def initialize_all_tables ( name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return tables_initializer ( name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def range_push ( msg ) : <NEWLINE> <TAB> <NEWLINE> if _libnvToolsExt ( ) is None : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> return lib . nvtxRangePushA ( ctypes . c_char_p ( msg . encode ( <STRING> ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def sub ( f , g ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( g , DMP ) : <NEWLINE> <TAB> lev , dom , per , ( F_num , F_den ) , G = f . poly_unify ( g ) <NEWLINE> num , den = dmp_sub_mul ( F_num , F_den , G , lev , dom ) , F_den <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> lev , dom , per , F , G = f . frac_unify ( g ) <NEWLINE> ( F_num , F_den ) , ( G_num , G_den ) = F , G <NEWLINE> <NEWLINE> num = dmp_sub ( dmp_mul ( F_num , G_den , lev , dom ) , <NEWLINE> dmp_mul ( F_den , G_num , lev , dom ) , lev , dom ) <NEWLINE> den = dmp_mul ( F_den , G_den , lev , dom ) <NEWLINE> <NEWLINE> <UNTAB> return per ( num , den ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def Lf ( lo , hi ) : <NEWLINE> <TAB> <NEWLINE> return math . exp ( random . uniform ( math . log ( lo ) , math . log ( hi ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __dir__ ( self ) : <NEWLINE> <TAB> <NEWLINE> return sorted ( self . __dict__ [ <STRING> ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sig_mult ( s , m ) : <NEWLINE> <TAB> <NEWLINE> return sig ( monomial_mul ( s [ <NUMBER> ] , m ) , s [ <NUMBER> ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def mpf_bernoulli ( n , prec , rnd = None ) : <NEWLINE> <TAB> <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> if n < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if n == <NUMBER> : <NEWLINE> <TAB> return fone <NEWLINE> <UNTAB> if n == <NUMBER> : <NEWLINE> <TAB> return mpf_neg ( fhalf ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if n & <NUMBER> : <NEWLINE> <TAB> return fzero <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if prec > BERNOULLI_PREC_CUTOFF and prec > bernoulli_size ( n ) * <NUMBER> + <NUMBER> : <NEWLINE> <TAB> p , q = bernfrac ( n ) <NEWLINE> return from_rational ( p , q , prec , rnd or round_floor ) <NEWLINE> <UNTAB> if n > MAX_BERNOULLI_CACHE : <NEWLINE> <TAB> return mpf_bernoulli_huge ( n , prec , rnd ) <NEWLINE> <UNTAB> wp = prec + <NUMBER> <NEWLINE> <NEWLINE> wp += <NUMBER> - ( prec & <NUMBER> ) <NEWLINE> cached = bernoulli_cache . get ( wp ) <NEWLINE> if cached : <NEWLINE> <TAB> numbers , state = cached <NEWLINE> if n in numbers : <NEWLINE> <TAB> if not rnd : <NEWLINE> <TAB> return numbers [ n ] <NEWLINE> <UNTAB> return mpf_pos ( numbers [ n ] , prec , rnd ) <NEWLINE> <UNTAB> m , bin , bin1 = state <NEWLINE> if n - m > <NUMBER> : <NEWLINE> <TAB> return mpf_bernoulli_huge ( n , prec , rnd ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if n > <NUMBER> : <NEWLINE> <TAB> return mpf_bernoulli_huge ( n , prec , rnd ) <NEWLINE> <UNTAB> numbers = { <NUMBER> : fone } <NEWLINE> m , bin , bin1 = state = [ <NUMBER> , MPZ ( <NUMBER> ) , MPZ_ONE ] <NEWLINE> bernoulli_cache [ wp ] = ( numbers , state ) <NEWLINE> <UNTAB> while m <= n : <NEWLINE> <NEWLINE> <TAB> case = m % <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> szbm = bernoulli_size ( m ) <NEWLINE> s = <NUMBER> <NEWLINE> sexp = max ( <NUMBER> , szbm ) - wp <NEWLINE> if m < <NUMBER> : <NEWLINE> <TAB> a = MPZ_ZERO <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> a = bin1 <NEWLINE> <UNTAB> for j in xrange ( <NUMBER> , m // <NUMBER> + <NUMBER> ) : <NEWLINE> <TAB> usign , uman , uexp , ubc = u = numbers [ m - <NUMBER> * j ] <NEWLINE> if usign : <NEWLINE> <TAB> uman = - uman <NEWLINE> <UNTAB> s += lshift ( a * uman , uexp - sexp ) <NEWLINE> <NEWLINE> j6 = <NUMBER> * j <NEWLINE> a *= ( ( m - <NUMBER> - j6 ) * ( m - <NUMBER> - j6 ) * ( m - <NUMBER> - j6 ) * ( m - <NUMBER> - j6 ) * ( m - <NUMBER> - j6 ) * ( m - j6 ) ) <NEWLINE> a //= ( ( <NUMBER> + j6 ) * ( <NUMBER> + j6 ) * ( <NUMBER> + j6 ) * ( <NUMBER> + j6 ) * ( <NUMBER> + j6 ) * ( <NUMBER> + j6 ) ) <NEWLINE> <UNTAB> if case == <NUMBER> : b = mpf_rdiv_int ( m + <NUMBER> , f3 , wp ) <NEWLINE> if case == <NUMBER> : b = mpf_rdiv_int ( m + <NUMBER> , f3 , wp ) <NEWLINE> if case == <NUMBER> : b = mpf_rdiv_int ( - m - <NUMBER> , f6 , wp ) <NEWLINE> s = from_man_exp ( s , sexp , wp ) <NEWLINE> b = mpf_div ( mpf_sub ( b , s , wp ) , from_int ( bin ) , wp ) <NEWLINE> numbers [ m ] = b <NEWLINE> m += <NUMBER> <NEWLINE> <NEWLINE> bin = bin * ( ( m + <NUMBER> ) * ( m + <NUMBER> ) ) // ( m * ( m - <NUMBER> ) ) <NEWLINE> if m > <NUMBER> : <NEWLINE> <TAB> bin1 = bin1 * ( ( <NUMBER> + m ) * ( <NUMBER> + m ) ) // ( ( m - <NUMBER> ) * ( m - <NUMBER> ) ) <NEWLINE> <UNTAB> state [ : ] = [ m , bin , bin1 ] <NEWLINE> <UNTAB> return numbers [ n ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _fast_count_smallints ( arr ) : <NEWLINE> <TAB> <NEWLINE> if len ( arr ) == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> return np . empty ( ( <NUMBER> , <NUMBER> ) , dtype = arr . dtype ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> counts = np . bincount ( arr . astype ( np . int_ ) ) <NEWLINE> nz = counts . nonzero ( ) [ <NUMBER> ] <NEWLINE> return np . c_ [ nz , counts [ nz ] ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def erfc ( x , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , x = x , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , x ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return erfc_eager_fallback ( <NEWLINE> x , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __exit__ ( self , etype , evalue , etrace ) : <NEWLINE> <TAB> <NEWLINE> self . close ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def unchain ( self ) : <NEWLINE> <TAB> <NEWLINE> self . node . unchain ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def mean_iou ( labels , <NEWLINE> predictions , <NEWLINE> num_classes , <NEWLINE> weights = None , <NEWLINE> metrics_collections = None , <NEWLINE> updates_collections = None , <NEWLINE> name = None ) : <NEWLINE> <TAB> <NEWLINE> if context . executing_eagerly ( ) : <NEWLINE> <TAB> raise RuntimeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> with variable_scope . variable_scope ( name , <STRING> , <NEWLINE> ( predictions , labels , weights ) ) : <NEWLINE> <NEWLINE> <TAB> predictions . get_shape ( ) . assert_is_compatible_with ( labels . get_shape ( ) ) <NEWLINE> <NEWLINE> total_cm , update_op = _streaming_confusion_matrix ( labels , predictions , <NEWLINE> num_classes , weights ) <NEWLINE> <NEWLINE> def compute_mean_iou ( _ , total_cm ) : <NEWLINE> <TAB> <NEWLINE> sum_over_row = math_ops . to_float ( math_ops . reduce_sum ( total_cm , <NUMBER> ) ) <NEWLINE> sum_over_col = math_ops . to_float ( math_ops . reduce_sum ( total_cm , <NUMBER> ) ) <NEWLINE> cm_diag = math_ops . to_float ( array_ops . diag_part ( total_cm ) ) <NEWLINE> denominator = sum_over_row + sum_over_col - cm_diag <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> num_valid_entries = math_ops . reduce_sum ( <NEWLINE> math_ops . cast ( <NEWLINE> math_ops . not_equal ( denominator , <NUMBER> ) , dtype = dtypes . float32 ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> denominator = array_ops . where ( <NEWLINE> math_ops . greater ( denominator , <NUMBER> ) , denominator , <NEWLINE> array_ops . ones_like ( denominator ) ) <NEWLINE> iou = math_ops . div ( cm_diag , denominator ) <NEWLINE> <NEWLINE> <NEWLINE> result = array_ops . where ( <NEWLINE> math_ops . greater ( num_valid_entries , <NUMBER> ) , <NEWLINE> math_ops . reduce_sum ( iou , name = <STRING> ) / num_valid_entries , <NUMBER> ) <NEWLINE> return result <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> mean_iou_v = _aggregate_across_replicas ( <NEWLINE> metrics_collections , compute_mean_iou , total_cm ) <NEWLINE> <NEWLINE> if updates_collections : <NEWLINE> <TAB> ops . add_to_collections ( updates_collections , update_op ) <NEWLINE> <NEWLINE> <UNTAB> return mean_iou_v , update_op <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , trainer ) : <NEWLINE> <TAB> <NEWLINE> updater = trainer . updater <NEWLINE> if self . unit == <STRING> : <NEWLINE> <TAB> epoch_detail = updater . epoch_detail <NEWLINE> previous_epoch_detail = self . _previous_epoch_detail <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if previous_epoch_detail < <NUMBER> : <NEWLINE> <TAB> previous_epoch_detail = updater . previous_epoch_detail <NEWLINE> <NEWLINE> <UNTAB> fire = any ( <NEWLINE> previous_epoch_detail < p <= epoch_detail <NEWLINE> for p in self . points ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> iteration = updater . iteration <NEWLINE> previous_iteration = self . _previous_iteration <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if previous_iteration < <NUMBER> : <NEWLINE> <TAB> previous_iteration = iteration - <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> fire = any ( <NEWLINE> previous_iteration < p <= iteration <NEWLINE> for p in self . points ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . _previous_iteration = updater . iteration <NEWLINE> if hasattr ( updater , <STRING> ) : <NEWLINE> <TAB> self . _previous_epoch_detail = updater . epoch_detail <NEWLINE> <NEWLINE> <UNTAB> return fire <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _compare_sequence ( a , b ) : <NEWLINE> <TAB> <NEWLINE> if type ( a ) is type ( b ) : <NEWLINE> <NEWLINE> <TAB> return a == b <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return tuple ( a ) == tuple ( b ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _simplifyconds ( expr , s , a ) : <NEWLINE> <TAB> <NEWLINE> from sympy . core . relational import ( StrictGreaterThan , StrictLessThan , <NEWLINE> Unequality ) <NEWLINE> from sympy import Abs <NEWLINE> <NEWLINE> def power ( ex ) : <NEWLINE> <TAB> if ex == s : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> if ex . is_Pow and ex . base == s : <NEWLINE> <TAB> return ex . exp <NEWLINE> <UNTAB> return None <NEWLINE> <NEWLINE> <UNTAB> def bigger ( ex1 , ex2 ) : <NEWLINE> <TAB> <NEWLINE> if ex1 . has ( s ) and ex2 . has ( s ) : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> if isinstance ( ex1 , Abs ) : <NEWLINE> <TAB> ex1 = ex1 . args [ <NUMBER> ] <NEWLINE> <UNTAB> if isinstance ( ex2 , Abs ) : <NEWLINE> <TAB> ex2 = ex2 . args [ <NUMBER> ] <NEWLINE> <UNTAB> if ex1 . has ( s ) : <NEWLINE> <TAB> return bigger ( <NUMBER> / ex2 , <NUMBER> / ex1 ) <NEWLINE> <UNTAB> n = power ( ex2 ) <NEWLINE> if n is None : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> if n > <NUMBER> and ( abs ( ex1 ) <= abs ( a ) ** n ) == True : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> if n < <NUMBER> and ( abs ( ex1 ) >= abs ( a ) ** n ) == True : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> <UNTAB> except TypeError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def replie ( x , y ) : <NEWLINE> <TAB> <NEWLINE> if not ( x . is_positive or isinstance ( x , Abs ) ) or not ( y . is_positive or isinstance ( y , Abs ) ) : <NEWLINE> <TAB> return ( x < y ) <NEWLINE> <UNTAB> r = bigger ( x , y ) <NEWLINE> if r is not None : <NEWLINE> <TAB> return not r <NEWLINE> <UNTAB> return ( x < y ) <NEWLINE> <NEWLINE> <UNTAB> def replue ( x , y ) : <NEWLINE> <TAB> b = bigger ( x , y ) <NEWLINE> if b == True or b == False : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> return Unequality ( x , y ) <NEWLINE> <NEWLINE> <UNTAB> def repl ( ex , * args ) : <NEWLINE> <TAB> if ex == True or ex == False : <NEWLINE> <TAB> return bool ( ex ) <NEWLINE> <UNTAB> return ex . replace ( * args ) <NEWLINE> <UNTAB> expr = repl ( expr , StrictLessThan , replie ) <NEWLINE> expr = repl ( expr , StrictGreaterThan , lambda x , y : replie ( y , x ) ) <NEWLINE> expr = repl ( expr , Unequality , replue ) <NEWLINE> return S ( expr ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _asarray ( a , dtype , order = None ) : <NEWLINE> <TAB> <NEWLINE> if str ( dtype ) == <STRING> : <NEWLINE> <TAB> dtype = theano . config . floatX <NEWLINE> <UNTAB> dtype = np . dtype ( dtype ) <NEWLINE> rval = np . asarray ( a , dtype = dtype , order = order ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if rval . dtype . num != dtype . num : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if ( dtype . str == rval . dtype . str ) : <NEWLINE> <NEWLINE> <TAB> return rval . view ( dtype = dtype ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % <NEWLINE> ( dtype , dtype . str , dtype . num , rval . dtype , rval . str , <NEWLINE> rval . dtype . num ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return rval <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ require_partition <NEWLINE> def coverage ( G , partition ) : <NEWLINE> <TAB> <NEWLINE> intra_edges = intra_community_edges ( G , partition ) <NEWLINE> total_edges = G . number_of_edges ( ) <NEWLINE> return intra_edges / total_edges <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def total_variation ( images , name = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> with ops . name_scope ( name , <STRING> ) : <NEWLINE> <TAB> ndims = images . get_shape ( ) . ndims <NEWLINE> <NEWLINE> if ndims == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> pixel_dif1 = images [ <NUMBER> : , : , : ] - images [ : - <NUMBER> , : , : ] <NEWLINE> pixel_dif2 = images [ : , <NUMBER> : , : ] - images [ : , : - <NUMBER> , : ] <NEWLINE> <NEWLINE> <NEWLINE> sum_axis = None <NEWLINE> <UNTAB> elif ndims == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> pixel_dif1 = images [ : , <NUMBER> : , : , : ] - images [ : , : - <NUMBER> , : , : ] <NEWLINE> pixel_dif2 = images [ : , : , <NUMBER> : , : ] - images [ : , : , : - <NUMBER> , : ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> sum_axis = [ <NUMBER> , <NUMBER> , <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> tot_var = ( <NEWLINE> math_ops . reduce_sum ( math_ops . abs ( pixel_dif1 ) , axis = sum_axis ) + <NEWLINE> math_ops . reduce_sum ( math_ops . abs ( pixel_dif2 ) , axis = sum_axis ) ) <NEWLINE> <NEWLINE> <UNTAB> return tot_var <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def singular_leading_submatrix ( A , U , k ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> delta = np . sum ( U [ : k - <NUMBER> , k - <NUMBER> ] ** <NUMBER> ) - A [ k - <NUMBER> , k - <NUMBER> ] <NEWLINE> <NEWLINE> n = len ( A ) <NEWLINE> <NEWLINE> <NEWLINE> v = np . zeros ( n ) <NEWLINE> v [ k - <NUMBER> ] = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> if k != <NUMBER> : <NEWLINE> <TAB> v [ : k - <NUMBER> ] = solve_triangular ( U [ : k - <NUMBER> , : k - <NUMBER> ] , - U [ : k - <NUMBER> , k - <NUMBER> ] ) <NEWLINE> <NEWLINE> <UNTAB> return delta , v <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _root_broyden1_doc ( ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def solve ( self , rhs , method = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if not self . is_square : <NEWLINE> <TAB> if self . rows < self . cols : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> elif self . rows > self . cols : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return self . inv ( method = method ) * rhs <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def block_collapse ( expr ) : <NEWLINE> <TAB> <NEWLINE> hasbm = lambda expr : isinstance ( expr , MatrixExpr ) and expr . has ( BlockMatrix ) <NEWLINE> rule = exhaust ( <NEWLINE> bottom_up ( exhaust ( condition ( hasbm , typed ( <NEWLINE> { MatAdd : do_one ( bc_matadd , bc_block_plus_ident ) , <NEWLINE> MatMul : do_one ( bc_matmul , bc_dist ) , <NEWLINE> Transpose : bc_transpose , <NEWLINE> Inverse : bc_inverse , <NEWLINE> BlockMatrix : do_one ( bc_unpack , deblock ) } ) ) ) ) ) <NEWLINE> result = rule ( expr ) <NEWLINE> try : <NEWLINE> <TAB> return result . doit ( ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_any_int_dtype ( arr_or_dtype ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if arr_or_dtype is None : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> tipo = _get_dtype_type ( arr_or_dtype ) <NEWLINE> return issubclass ( tipo , np . integer ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def gf_crt2 ( U , M , p , E , S , K ) : <NEWLINE> <TAB> <NEWLINE> v = K . zero <NEWLINE> <NEWLINE> for u , m , e , s in zip ( U , M , E , S ) : <NEWLINE> <TAB> v += e * ( u * s % m ) <NEWLINE> <NEWLINE> <UNTAB> return v % p <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __getstate__ ( self ) : <NEWLINE> <TAB> <NEWLINE> d = self . __dict__ . copy ( ) <NEWLINE> for feature in self . _features : <NEWLINE> <TAB> for attr in getattr ( feature , <STRING> , [ ] ) : <NEWLINE> <TAB> del d [ attr ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if <STRING> in d : <NEWLINE> <TAB> del d [ <STRING> ] <NEWLINE> <NEWLINE> <UNTAB> return d <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , gridspec , num1 , num2 = None ) : <NEWLINE> <TAB> <NEWLINE> self . _gridspec = gridspec <NEWLINE> self . num1 = num1 <NEWLINE> self . num2 = num2 <NEWLINE> if gridspec . _layoutbox is not None : <NEWLINE> <TAB> glb = gridspec . _layoutbox <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . _layoutbox = layoutbox . LayoutBox ( <NEWLINE> parent = glb , <NEWLINE> name = glb . name + <STRING> + layoutbox . seq_id ( ) , <NEWLINE> artist = self ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _layoutbox = None <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> def k_random_intersection_graph ( n , m , k , seed = None ) : <NEWLINE> <TAB> <NEWLINE> G = nx . empty_graph ( n + m ) <NEWLINE> mset = range ( n , n + m ) <NEWLINE> for v in range ( n ) : <NEWLINE> <TAB> targets = seed . sample ( mset , k ) <NEWLINE> G . add_edges_from ( zip ( [ v ] * len ( targets ) , targets ) ) <NEWLINE> <UNTAB> return nx . projected_graph ( G , range ( n ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def cosine_similarity ( X , Y = None , dense_output = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> X , Y = check_pairwise_arrays ( X , Y ) <NEWLINE> <NEWLINE> X_normalized = normalize ( X , copy = True ) <NEWLINE> if X is Y : <NEWLINE> <TAB> Y_normalized = X_normalized <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> Y_normalized = normalize ( Y , copy = True ) <NEWLINE> <NEWLINE> <UNTAB> K = safe_sparse_dot ( X_normalized , Y_normalized . T , <NEWLINE> dense_output = dense_output ) <NEWLINE> <NEWLINE> return K <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def pmf_hist ( a , bins = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> n , x = np . histogram ( a , bins ) <NEWLINE> h = n / n . sum ( ) <NEWLINE> w = x [ <NUMBER> ] - x [ <NUMBER> ] <NEWLINE> return x [ : - <NUMBER> ] , h , w <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def remove_control_inputs ( op , cops ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( op , _tf_ops . Operation ) : <NEWLINE> <TAB> raise TypeError ( <STRING> , type ( op ) ) <NEWLINE> <UNTAB> cops = _util . make_list_of_op ( cops , allow_graph = False ) <NEWLINE> for cop in cops : <NEWLINE> <TAB> if cop not in op . control_inputs : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( op . name , <NEWLINE> cop . name ) ) <NEWLINE> <UNTAB> <UNTAB> control_inputs = [ cop for cop in op . control_inputs if cop not in cops ] <NEWLINE> <NEWLINE> op . _remove_all_control_inputs ( ) <NEWLINE> op . _add_control_inputs ( control_inputs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __delattr__ ( self , flag_name ) : <NEWLINE> <TAB> <NEWLINE> fl = self . _flags ( ) <NEWLINE> if flag_name not in fl : <NEWLINE> <TAB> raise AttributeError ( flag_name ) <NEWLINE> <NEWLINE> <UNTAB> flag_obj = fl [ flag_name ] <NEWLINE> del fl [ flag_name ] <NEWLINE> <NEWLINE> self . _cleanup_unregistered_flag_from_module_dicts ( flag_obj ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __new__ ( cls , rep , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> opt = options . build_options ( gens , args ) <NEWLINE> <NEWLINE> if <STRING> in opt : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if iterable ( rep , exclude = str ) : <NEWLINE> <TAB> if isinstance ( rep , dict ) : <NEWLINE> <TAB> return cls . _from_dict ( rep , opt ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return cls . _from_list ( list ( rep ) , opt ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> rep = sympify ( rep ) <NEWLINE> <NEWLINE> if rep . is_Poly : <NEWLINE> <TAB> return cls . _from_poly ( rep , opt ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return cls . _from_expr ( rep , opt ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _eval_det_lu ( self , iszerofunc = _iszero , simpfunc = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if self . rows == <NUMBER> : <NEWLINE> <TAB> return S . One <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> lu , row_swaps = self . LUdecomposition_Simple ( iszerofunc = iszerofunc , simpfunc = None ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if iszerofunc ( lu [ lu . rows - <NUMBER> , lu . rows - <NUMBER> ] ) : <NEWLINE> <TAB> return S . Zero <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> det = - S . One if len ( row_swaps ) % <NUMBER> else S . One <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for k in range ( lu . rows ) : <NEWLINE> <TAB> det *= lu [ k , k ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return det <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def clump_unmasked ( a ) : <NEWLINE> <TAB> <NEWLINE> mask = getattr ( a , <STRING> , nomask ) <NEWLINE> if mask is nomask : <NEWLINE> <TAB> return [ slice ( <NUMBER> , a . size ) ] <NEWLINE> <UNTAB> return _ezclump ( ~ mask ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def layer_normalization ( x , gamma , beta , eps = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return LayerNormalization ( eps ) . apply ( ( x , gamma , beta ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def array_equivalent ( left , right , strict_nan = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> left , right = np . asarray ( left ) , np . asarray ( right ) <NEWLINE> <NEWLINE> <NEWLINE> if left . shape != right . shape : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if is_string_dtype ( left ) or is_string_dtype ( right ) : <NEWLINE> <NEWLINE> <TAB> if not strict_nan : <NEWLINE> <NEWLINE> <TAB> return lib . array_equivalent_object ( <NEWLINE> _ensure_object ( left . ravel ( ) ) , _ensure_object ( right . ravel ( ) ) ) <NEWLINE> <NEWLINE> <UNTAB> for left_value , right_value in zip ( left , right ) : <NEWLINE> <TAB> if left_value is NaT and right_value is not NaT : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> elif isinstance ( left_value , float ) and np . isnan ( left_value ) : <NEWLINE> <TAB> if ( not isinstance ( right_value , float ) or <NEWLINE> not np . isnan ( right_value ) ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if left_value != right_value : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return True <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if is_float_dtype ( left ) or is_complex_dtype ( left ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if not ( np . prod ( left . shape ) and np . prod ( right . shape ) ) : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> return ( ( left == right ) | ( isna ( left ) & isna ( right ) ) ) . all ( ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif is_datetimelike_v_numeric ( left , right ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif needs_i8_conversion ( left ) and needs_i8_conversion ( right ) : <NEWLINE> <TAB> if not is_dtype_equal ( left . dtype , right . dtype ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> left = left . view ( <STRING> ) <NEWLINE> right = right . view ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if ( left . dtype . type is np . void or <NEWLINE> right . dtype . type is np . void ) : <NEWLINE> <TAB> if left . dtype != right . dtype : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return np . array_equal ( left , right ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _index_param_value ( X , v , indices ) : <NEWLINE> <TAB> <NEWLINE> if not _is_arraylike ( v ) or _num_samples ( v ) != _num_samples ( X ) : <NEWLINE> <NEWLINE> <TAB> return v <NEWLINE> <UNTAB> if sp . issparse ( v ) : <NEWLINE> <TAB> v = v . tocsr ( ) <NEWLINE> <UNTAB> return safe_indexing ( v , indices ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def he_normal ( seed = None ) : <NEWLINE> <TAB> <NEWLINE> return VarianceScaling ( <NEWLINE> scale = <NUMBER> , mode = <STRING> , distribution = <STRING> , seed = seed ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def arctan ( x ) : <NEWLINE> <TAB> <NEWLINE> return Arctan ( ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def round ( self , mode = None ) : <NEWLINE> <TAB> <NEWLINE> return theano . tensor . basic . round ( self , mode ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_gf_sqf_list ( f , u , K , all = False ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_executor_init ( self , workers ) : <NEWLINE> <TAB> <NEWLINE> def pool_fn ( seqs ) : <NEWLINE> <TAB> return multiprocessing . Pool ( workers , <NEWLINE> initializer = init_pool_generator , <NEWLINE> initargs = ( seqs , self . random_seed ) ) <NEWLINE> <UNTAB> return pool_fn <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def root_to_leaf_paths ( G ) : <NEWLINE> <TAB> <NEWLINE> roots = ( v for v , d in G . in_degree ( ) if d == <NUMBER> ) <NEWLINE> leaves = ( v for v , d in G . out_degree ( ) if d == <NUMBER> ) <NEWLINE> all_paths = partial ( nx . all_simple_paths , G ) <NEWLINE> <NEWLINE> return chaini ( starmap ( all_paths , product ( roots , leaves ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _astype ( self , dtype , mgr = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if is_datetime64tz_dtype ( dtype ) : <NEWLINE> <TAB> dtype = DatetimeTZDtype ( dtype ) <NEWLINE> <NEWLINE> values = self . values <NEWLINE> if getattr ( values , <STRING> , None ) is None : <NEWLINE> <TAB> values = DatetimeIndex ( values ) . tz_localize ( <STRING> ) <NEWLINE> <UNTAB> values = values . tz_convert ( dtype . tz ) <NEWLINE> return self . make_block ( values ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return super ( DatetimeBlock , self ) . _astype ( dtype = dtype , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_field ( f ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( f . rep , <STRING> ) : <NEWLINE> <TAB> result = f . rep . to_field ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise OperationNotSupported ( f , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return f . per ( result ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def qcut ( x , q , labels = None , retbins = False , precision = <NUMBER> , duplicates = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> x_is_series , series_index , name , x = _preprocess_for_cut ( x ) <NEWLINE> <NEWLINE> x , dtype = _coerce_to_type ( x ) <NEWLINE> <NEWLINE> if is_integer ( q ) : <NEWLINE> <TAB> quantiles = np . linspace ( <NUMBER> , <NUMBER> , q + <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> quantiles = q <NEWLINE> <UNTAB> bins = algos . quantile ( x , quantiles ) <NEWLINE> fac , bins = _bins_to_cuts ( x , bins , labels = labels , <NEWLINE> precision = precision , include_lowest = True , <NEWLINE> dtype = dtype , duplicates = duplicates ) <NEWLINE> <NEWLINE> return _postprocess_for_cut ( fac , bins , retbins , x_is_series , <NEWLINE> series_index , name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def chvatal_graph ( create_using = None ) : <NEWLINE> <TAB> <NEWLINE> description = [ <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <NUMBER> , <NEWLINE> [ [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> , <NUMBER> ] , <NEWLINE> [ <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , <NEWLINE> [ <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , [ ] , [ ] ] <NEWLINE> ] <NEWLINE> G = make_small_undirected_graph ( description , create_using ) <NEWLINE> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def pop ( self , item ) : <NEWLINE> <TAB> <NEWLINE> result = self [ item ] <NEWLINE> del self [ item ] <NEWLINE> try : <NEWLINE> <TAB> result . _reset_cacher ( ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def mingw32 ( ) : <NEWLINE> <TAB> <NEWLINE> if sys . platform == <STRING> : <NEWLINE> <TAB> if os . environ . get ( <STRING> , <STRING> ) == <STRING> : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> if os . environ . get ( <STRING> , <STRING> ) == <STRING> : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> <UNTAB> return False <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rebuild_collect_shared ( outputs , <NEWLINE> inputs = None , <NEWLINE> replace = None , <NEWLINE> updates = None , <NEWLINE> rebuild_strict = True , <NEWLINE> copy_inputs_over = True , <NEWLINE> no_default_updates = False , <NEWLINE> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( outputs , tuple ) : <NEWLINE> <TAB> outputs = list ( outputs ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> clone_d = { } <NEWLINE> update_d = { } <NEWLINE> update_expr = [ ] <NEWLINE> <NEWLINE> shared_inputs = [ ] <NEWLINE> <NEWLINE> def clone_v_get_shared_updates ( v , copy_inputs_over ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> assert v is not None <NEWLINE> if v in clone_d : <NEWLINE> <TAB> return clone_d [ v ] <NEWLINE> <UNTAB> if v . owner : <NEWLINE> <TAB> owner = v . owner <NEWLINE> if owner not in clone_d : <NEWLINE> <TAB> for i in owner . inputs : <NEWLINE> <TAB> clone_v_get_shared_updates ( i , copy_inputs_over ) <NEWLINE> <NEWLINE> <UNTAB> clone_d [ owner ] = owner . clone_with_new_inputs ( <NEWLINE> [ clone_d [ i ] for i in owner . inputs ] , strict = rebuild_strict ) <NEWLINE> for old_o , new_o in zip ( owner . outputs , clone_d [ owner ] . outputs ) : <NEWLINE> <TAB> clone_d . setdefault ( old_o , new_o ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return clone_d . setdefault ( v , v ) <NEWLINE> <UNTAB> elif isinstance ( v , SharedVariable ) : <NEWLINE> <TAB> if v not in shared_inputs : <NEWLINE> <TAB> shared_inputs . append ( v ) <NEWLINE> <UNTAB> if hasattr ( v , <STRING> ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if ( no_default_updates is False or <NEWLINE> ( isinstance ( no_default_updates , list ) and <NEWLINE> v not in no_default_updates ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if v not in update_d : <NEWLINE> <TAB> v_update = v . type . filter_variable ( v . default_update , <NEWLINE> allow_convert = False ) <NEWLINE> if v_update . type != v . type : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> , <NEWLINE> ( v , v . type , v_update , v_update . type ) ) <NEWLINE> <UNTAB> update_d [ v ] = v_update <NEWLINE> update_expr . append ( ( v , v_update ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> if not copy_inputs_over or ( isinstance ( v , Constant ) and <NEWLINE> hasattr ( v , <STRING> ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return clone_d . setdefault ( v , v . clone ( ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return clone_d . setdefault ( v , v ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if replace is None : <NEWLINE> <TAB> replace = [ ] <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> replace_pairs = list ( replace . items ( ) ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> replace_pairs = replace <NEWLINE> <NEWLINE> <UNTAB> for v_orig , v_repl in replace_pairs : <NEWLINE> <TAB> if not isinstance ( v_orig , Variable ) : <NEWLINE> <TAB> raise TypeError ( <STRING> , v_orig ) <NEWLINE> <UNTAB> if not isinstance ( v_repl , Variable ) : <NEWLINE> <TAB> v_repl = shared ( v_repl ) <NEWLINE> <NEWLINE> <UNTAB> if v_orig in clone_d : <NEWLINE> <TAB> raise AssertionError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % ( v_orig , v_repl ) ) <NEWLINE> <NEWLINE> <UNTAB> clone_d [ v_orig ] = clone_v_get_shared_updates ( v_repl , <NEWLINE> copy_inputs_over ) <NEWLINE> <NEWLINE> <UNTAB> if inputs is None : <NEWLINE> <TAB> inputs = [ ] <NEWLINE> <NEWLINE> <UNTAB> def clone_inputs ( i ) : <NEWLINE> <TAB> if not copy_inputs_over : <NEWLINE> <TAB> return clone_d . setdefault ( i , i . clone ( ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return clone_d . setdefault ( i , i ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> input_variables = [ clone_inputs ( i ) for i in inputs ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for v in input_variables : <NEWLINE> <TAB> if isinstance ( v , SharedVariable ) : <NEWLINE> <TAB> raise TypeError ( ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) % v ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if updates is None : <NEWLINE> <TAB> updates = [ ] <NEWLINE> <UNTAB> for ( store_into , update_val ) in iter_over_pairs ( updates ) : <NEWLINE> <TAB> if not isinstance ( store_into , SharedVariable ) : <NEWLINE> <TAB> raise TypeError ( <STRING> , <NEWLINE> store_into ) <NEWLINE> <UNTAB> if store_into in update_d : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> , <NEWLINE> ( store_into , update_d [ store_into ] ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> update_val = store_into . type . filter_variable ( update_val , <NEWLINE> allow_convert = False ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> err_msg = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % ( <NEWLINE> store_into , <NEWLINE> store_into . type , <NEWLINE> update_val , <NEWLINE> getattr ( update_val , <STRING> , None ) ) ) <NEWLINE> err_sug = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> raise TypeError ( err_msg , err_sug ) <NEWLINE> <UNTAB> assert update_val . type == store_into . type <NEWLINE> <NEWLINE> update_d [ store_into ] = update_val <NEWLINE> update_expr . append ( ( store_into , update_val ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( outputs , list ) : <NEWLINE> <TAB> cloned_outputs = [ ] <NEWLINE> for v in outputs : <NEWLINE> <TAB> if isinstance ( v , Variable ) : <NEWLINE> <TAB> cloned_v = clone_v_get_shared_updates ( v , copy_inputs_over ) <NEWLINE> cloned_outputs . append ( cloned_v ) <NEWLINE> <UNTAB> elif isinstance ( v , Out ) : <NEWLINE> <TAB> cloned_v = clone_v_get_shared_updates ( v . variable , <NEWLINE> copy_inputs_over ) <NEWLINE> cloned_outputs . append ( Out ( cloned_v , borrow = v . borrow ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> + str ( v ) + <NEWLINE> <STRING> + str ( type ( v ) ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if isinstance ( outputs , Variable ) : <NEWLINE> <TAB> cloned_v = clone_v_get_shared_updates ( outputs , copy_inputs_over ) <NEWLINE> cloned_outputs = cloned_v <NEWLINE> <NEWLINE> <UNTAB> elif isinstance ( outputs , Out ) : <NEWLINE> <TAB> cloned_v = clone_v_get_shared_updates ( outputs . variable , <NEWLINE> copy_inputs_over ) <NEWLINE> cloned_outputs = Out ( cloned_v , borrow = outputs . borrow ) <NEWLINE> <NEWLINE> <UNTAB> elif outputs is None : <NEWLINE> <TAB> cloned_outputs = [ ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> , <NEWLINE> outputs ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> i = <NUMBER> <NEWLINE> while i < len ( update_expr ) : <NEWLINE> <TAB> v , v_update = update_expr [ i ] <NEWLINE> cloned_v_update = clone_v_get_shared_updates ( v_update , <NEWLINE> copy_inputs_over ) <NEWLINE> update_d [ v ] = cloned_v_update <NEWLINE> if isinstance ( v , SharedVariable ) and v not in shared_inputs : <NEWLINE> <TAB> shared_inputs . append ( v ) <NEWLINE> <UNTAB> i += <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> return ( input_variables , cloned_outputs , <NEWLINE> [ clone_d , update_d , update_expr , shared_inputs ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _create_op_from_tf_operation ( self , c_op , compute_device = True ) : <NEWLINE> <TAB> <NEWLINE> self . _check_not_finalized ( ) <NEWLINE> ret = Operation ( c_op , self ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> name_key = ret . name . lower ( ) <NEWLINE> if name_key not in self . _names_in_use : <NEWLINE> <TAB> self . _names_in_use [ name_key ] = <NUMBER> <NEWLINE> <UNTAB> self . _create_op_helper ( ret , compute_device = compute_device ) <NEWLINE> return ret <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def compute_geom_grads ( self ) : <NEWLINE> <TAB> <NEWLINE> tris_pts = self . _tris_pts <NEWLINE> tris_f = self . z [ self . _triangles ] <NEWLINE> <NEWLINE> dM1 = tris_pts [ : , <NUMBER> , : ] - tris_pts [ : , <NUMBER> , : ] <NEWLINE> dM2 = tris_pts [ : , <NUMBER> , : ] - tris_pts [ : , <NUMBER> , : ] <NEWLINE> dM = np . dstack ( [ dM1 , dM2 ] ) <NEWLINE> <NEWLINE> <NEWLINE> dM_inv = _safe_inv22_vectorized ( dM ) <NEWLINE> <NEWLINE> dZ1 = tris_f [ : , <NUMBER> ] - tris_f [ : , <NUMBER> ] <NEWLINE> dZ2 = tris_f [ : , <NUMBER> ] - tris_f [ : , <NUMBER> ] <NEWLINE> dZ = np . vstack ( [ dZ1 , dZ2 ] ) . T <NEWLINE> df = np . empty_like ( dZ ) <NEWLINE> <NEWLINE> <NEWLINE> df [ : , <NUMBER> ] = dZ [ : , <NUMBER> ] * dM_inv [ : , <NUMBER> , <NUMBER> ] + dZ [ : , <NUMBER> ] * dM_inv [ : , <NUMBER> , <NUMBER> ] <NEWLINE> df [ : , <NUMBER> ] = dZ [ : , <NUMBER> ] * dM_inv [ : , <NUMBER> , <NUMBER> ] + dZ [ : , <NUMBER> ] * dM_inv [ : , <NUMBER> , <NUMBER> ] <NEWLINE> return df <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_ybound ( self ) : <NEWLINE> <TAB> <NEWLINE> bottom , top = self . get_ylim ( ) <NEWLINE> if bottom < top : <NEWLINE> <TAB> return bottom , top <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return top , bottom <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dice ( u , v , w = None ) : <NEWLINE> <TAB> <NEWLINE> u = _validate_vector ( u ) <NEWLINE> v = _validate_vector ( v ) <NEWLINE> if w is not None : <NEWLINE> <TAB> w = _validate_weights ( w ) <NEWLINE> <UNTAB> if u . dtype == v . dtype == bool and w is None : <NEWLINE> <TAB> ntt = ( u & v ) . sum ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dtype = np . find_common_type ( [ int ] , [ u . dtype , v . dtype ] ) <NEWLINE> u = u . astype ( dtype ) <NEWLINE> v = v . astype ( dtype ) <NEWLINE> if w is None : <NEWLINE> <TAB> ntt = ( u * v ) . sum ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ntt = ( u * v * w ) . sum ( ) <NEWLINE> <UNTAB> <UNTAB> ( nft , ntf ) = _nbool_correspond_ft_tf ( u , v , w = w ) <NEWLINE> return float ( ( ntf + nft ) / np . array ( <NUMBER> * ntt + ntf + nft ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def compare_nrmse ( im_true , im_test , norm_type = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> _assert_compatible ( im_true , im_test ) <NEWLINE> im_true , im_test = _as_floats ( im_true , im_test ) <NEWLINE> <NEWLINE> norm_type = norm_type . lower ( ) <NEWLINE> if norm_type == <STRING> : <NEWLINE> <TAB> denom = np . sqrt ( np . mean ( ( im_true * im_true ) , dtype = np . float64 ) ) <NEWLINE> <UNTAB> elif norm_type == <STRING> : <NEWLINE> <TAB> denom = im_true . max ( ) - im_true . min ( ) <NEWLINE> <UNTAB> elif norm_type == <STRING> : <NEWLINE> <TAB> denom = im_true . mean ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return np . sqrt ( compare_mse ( im_true , im_test ) ) / denom <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _batch_trace_XXT ( bmat ) : <NEWLINE> <TAB> <NEWLINE> mat_size = bmat . size ( - <NUMBER> ) <NEWLINE> flat_trace = bmat . reshape ( - <NUMBER> , mat_size * mat_size ) . pow ( <NUMBER> ) . sum ( - <NUMBER> ) <NEWLINE> return flat_trace . view ( bmat . shape [ : - <NUMBER> ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_passthrough ( self , t ) : <NEWLINE> <TAB> <NEWLINE> return t in self . _passthrough_ts <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_func_code ( func ) : <NEWLINE> <TAB> <NEWLINE> source_file = None <NEWLINE> try : <NEWLINE> <TAB> code = func . __code__ <NEWLINE> source_file = code . co_filename <NEWLINE> if not os . path . exists ( source_file ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> source_code = <STRING> . join ( inspect . getsourcelines ( func ) [ <NUMBER> ] ) <NEWLINE> line_no = <NUMBER> <NEWLINE> if source_file . startswith ( <STRING> ) : <NEWLINE> <TAB> source_file , line_no = re . match ( <NEWLINE> <STRING> , source_file ) . groups ( ) <NEWLINE> line_no = int ( line_no ) <NEWLINE> source_file = <STRING> % source_file <NEWLINE> <UNTAB> return source_code , source_file , line_no <NEWLINE> <NEWLINE> <UNTAB> with open_py_source ( source_file ) as source_file_obj : <NEWLINE> <TAB> first_line = code . co_firstlineno <NEWLINE> <NEWLINE> source_lines = list ( islice ( source_file_obj , first_line - <NUMBER> , None ) ) <NEWLINE> <UNTAB> return <STRING> . join ( inspect . getblock ( source_lines ) ) , source_file , first_line <NEWLINE> <UNTAB> except : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if hasattr ( func , <STRING> ) : <NEWLINE> <NEWLINE> <TAB> return str ( func . __code__ . __hash__ ( ) ) , source_file , - <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return repr ( func ) , source_file , - <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_pseudographical ( sequence ) : <NEWLINE> <TAB> <NEWLINE> s = list ( sequence ) <NEWLINE> if not nx . utils . is_list_of_ints ( s ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> return sum ( s ) % <NUMBER> == <NUMBER> and min ( s ) >= <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def assert_copy ( iter1 , iter2 , ** eql_kwargs ) : <NEWLINE> <TAB> <NEWLINE> for elem1 , elem2 in zip ( iter1 , iter2 ) : <NEWLINE> <TAB> assert_almost_equal ( elem1 , elem2 , ** eql_kwargs ) <NEWLINE> msg = ( <STRING> <NEWLINE> <STRING> <NEWLINE> ) . format ( obj1 = type ( elem1 ) , obj2 = type ( elem2 ) ) <NEWLINE> assert elem1 is not elem2 , msg <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def struct_variable_codeblocks ( variable , policies , id , symbol_table , sub ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> name = <STRING> % id <NEWLINE> if variable not in symbol_table : <NEWLINE> <TAB> symbol_table [ variable ] = name <NEWLINE> <UNTAB> sub = dict ( sub ) <NEWLINE> <NEWLINE> sub [ <STRING> ] = id <NEWLINE> sub [ <STRING> ] = failure_code_init ( sub ) <NEWLINE> sub [ <STRING> ] = <STRING> % name <NEWLINE> sub [ <STRING> ] = <STRING> % name <NEWLINE> <NEWLINE> struct_builder = CodeBlock ( * [ apply_policy ( policy , variable , name , sub ) <NEWLINE> for policy in policies [ <NUMBER> ] ] + [ sub ] ) <NEWLINE> sub [ <STRING> ] = id + <NUMBER> <NEWLINE> sub [ <STRING> ] = failure_code ( sub ) <NEWLINE> sub [ <STRING> ] = <STRING> % name <NEWLINE> sub [ <STRING> ] = <STRING> % name <NEWLINE> <NEWLINE> block = CodeBlock ( * [ apply_policy ( policy , variable , name , sub ) <NEWLINE> for policy in policies [ <NUMBER> ] ] + [ sub ] ) <NEWLINE> <NEWLINE> return struct_builder , block <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def doc_to_help ( doc ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> doc = doc . strip ( ) <NEWLINE> <NEWLINE> <NEWLINE> whitespace_only_line = re . compile ( <STRING> , re . M ) <NEWLINE> doc = whitespace_only_line . sub ( <STRING> , doc ) <NEWLINE> <NEWLINE> <NEWLINE> doc = trim_docstring ( doc ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> doc = re . sub ( <STRING> , <STRING> , doc , flags = re . M ) <NEWLINE> <NEWLINE> return doc <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __ge__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_model_fn ( params , <NEWLINE> graph_builder_class , <NEWLINE> device_assigner , <NEWLINE> feature_columns = None , <NEWLINE> weights_name = None , <NEWLINE> model_head = None , <NEWLINE> keys_name = None , <NEWLINE> early_stopping_rounds = <NUMBER> , <NEWLINE> early_stopping_loss_threshold = <NUMBER> , <NEWLINE> num_trainers = <NUMBER> , <NEWLINE> trainer_id = <NUMBER> , <NEWLINE> report_feature_importances = False , <NEWLINE> local_eval = False , <NEWLINE> head_scope = None , <NEWLINE> include_all_in_serving = False , <NEWLINE> output_type = ModelBuilderOutputType . MODEL_FN_OPS ) : <NEWLINE> <TAB> <NEWLINE> if model_head is None : <NEWLINE> <TAB> model_head = _get_default_head ( params , weights_name , output_type ) <NEWLINE> <NEWLINE> <UNTAB> def _model_fn ( features , labels , mode ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if ( isinstance ( features , ops . Tensor ) or <NEWLINE> isinstance ( features , sparse_tensor . SparseTensor ) ) : <NEWLINE> <TAB> features = { <STRING> : features } <NEWLINE> <UNTAB> if feature_columns : <NEWLINE> <TAB> features = features . copy ( ) <NEWLINE> <NEWLINE> if output_type == ModelBuilderOutputType . MODEL_FN_OPS : <NEWLINE> <TAB> features . update ( layers . transform_features ( features , feature_columns ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for fc in feature_columns : <NEWLINE> <TAB> tensor = fc_core . _transform_features ( features , [ fc ] ) [ fc ] <NEWLINE> features [ fc . name ] = tensor <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> weights = None <NEWLINE> if weights_name and weights_name in features : <NEWLINE> <TAB> weights = features . pop ( weights_name ) <NEWLINE> <NEWLINE> <UNTAB> keys = None <NEWLINE> if keys_name and keys_name in features : <NEWLINE> <TAB> keys = features . pop ( keys_name ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> dev_assn = device_assigner <NEWLINE> if ( mode == model_fn_lib . ModeKeys . INFER or <NEWLINE> ( local_eval and mode == model_fn_lib . ModeKeys . EVAL ) ) : <NEWLINE> <TAB> dev_assn = None <NEWLINE> <NEWLINE> <UNTAB> graph_builder = graph_builder_class ( params , <NEWLINE> device_assigner = dev_assn ) <NEWLINE> <NEWLINE> logits , tree_paths , regression_variance = graph_builder . inference_graph ( <NEWLINE> features ) <NEWLINE> <NEWLINE> summary . scalar ( <STRING> , graph_builder . average_size ( ) ) <NEWLINE> <NEWLINE> <NEWLINE> if not params . regression and params . num_classes == <NUMBER> : <NEWLINE> <TAB> class_1_probs = array_ops . slice ( logits , [ <NUMBER> , <NUMBER> ] , [ - <NUMBER> , <NUMBER> ] ) <NEWLINE> logits = math_ops . log ( <NEWLINE> math_ops . maximum ( class_1_probs / math_ops . maximum ( <NEWLINE> <NUMBER> - class_1_probs , EPSILON ) , EPSILON ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> training_graph = None <NEWLINE> training_hooks = [ ] <NEWLINE> if labels is not None and mode == model_fn_lib . ModeKeys . TRAIN : <NEWLINE> <TAB> with ops . control_dependencies ( [ logits . op ] ) : <NEWLINE> <TAB> training_graph = control_flow_ops . group ( <NEWLINE> graph_builder . training_graph ( <NEWLINE> features , labels , input_weights = weights , <NEWLINE> num_trainers = num_trainers , <NEWLINE> trainer_id = trainer_id ) , <NEWLINE> state_ops . assign_add ( training_util . get_global_step ( ) , <NUMBER> ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if weights is not None : <NEWLINE> <TAB> features [ weights_name ] = weights <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> def _train_fn ( unused_loss ) : <NEWLINE> <TAB> return training_graph <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> all_handles = graph_builder . get_all_resource_handles ( ) <NEWLINE> ops_at_end = { <NEWLINE> <STRING> : <NEWLINE> control_flow_ops . group ( * [ <NEWLINE> resource_variable_ops . destroy_resource_op ( handle ) <NEWLINE> for handle in all_handles <NEWLINE> ] ) <NEWLINE> } <NEWLINE> <NEWLINE> if report_feature_importances : <NEWLINE> <TAB> ops_at_end [ <STRING> ] = ( <NEWLINE> graph_builder . feature_importances ( ) ) <NEWLINE> <NEWLINE> <UNTAB> training_hooks = [ TensorForestRunOpAtEndHook ( ops_at_end ) ] <NEWLINE> <NEWLINE> if output_type == ModelBuilderOutputType . MODEL_FN_OPS : <NEWLINE> <TAB> model_ops = model_head . create_model_fn_ops ( <NEWLINE> features = features , <NEWLINE> labels = labels , <NEWLINE> mode = mode , <NEWLINE> train_op_fn = _train_fn , <NEWLINE> logits = logits , <NEWLINE> scope = head_scope ) <NEWLINE> <NEWLINE> if early_stopping_rounds : <NEWLINE> <TAB> training_hooks . append ( <NEWLINE> TensorForestLossHook ( <NEWLINE> early_stopping_rounds , <NEWLINE> early_stopping_loss_threshold = early_stopping_loss_threshold , <NEWLINE> loss_op = model_ops . loss ) ) <NEWLINE> <NEWLINE> <UNTAB> model_ops . training_hooks . extend ( training_hooks ) <NEWLINE> <NEWLINE> if keys is not None : <NEWLINE> <TAB> model_ops . predictions [ keys_name ] = keys <NEWLINE> <NEWLINE> <UNTAB> if params . inference_tree_paths : <NEWLINE> <TAB> model_ops . predictions [ TREE_PATHS_PREDICTION_KEY ] = tree_paths <NEWLINE> <NEWLINE> <UNTAB> model_ops . predictions [ VARIANCE_PREDICTION_KEY ] = regression_variance <NEWLINE> <NEWLINE> if include_all_in_serving : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if not model_ops . output_alternatives : <NEWLINE> <TAB> model_ops . output_alternatives = { } <NEWLINE> <UNTAB> model_ops . output_alternatives [ ALL_SERVING_KEY ] = ( <NEWLINE> constants . ProblemType . UNSPECIFIED , model_ops . predictions ) <NEWLINE> <NEWLINE> <UNTAB> return model_ops <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> estimator_spec = model_head . create_estimator_spec ( <NEWLINE> features = features , <NEWLINE> mode = mode , <NEWLINE> labels = labels , <NEWLINE> train_op_fn = _train_fn , <NEWLINE> logits = logits ) <NEWLINE> <NEWLINE> if early_stopping_rounds : <NEWLINE> <TAB> training_hooks . append ( <NEWLINE> TensorForestLossHook ( <NEWLINE> early_stopping_rounds , <NEWLINE> early_stopping_loss_threshold = early_stopping_loss_threshold , <NEWLINE> loss_op = estimator_spec . loss ) ) <NEWLINE> <NEWLINE> <UNTAB> estimator_spec = estimator_spec . _replace ( <NEWLINE> training_hooks = training_hooks + list ( estimator_spec . training_hooks ) ) <NEWLINE> if keys is not None : <NEWLINE> <TAB> estimator_spec . predictions [ keys_name ] = keys <NEWLINE> <UNTAB> if params . inference_tree_paths : <NEWLINE> <TAB> estimator_spec . predictions [ TREE_PATHS_PREDICTION_KEY ] = tree_paths <NEWLINE> <UNTAB> estimator_spec . predictions [ VARIANCE_PREDICTION_KEY ] = regression_variance <NEWLINE> <NEWLINE> if include_all_in_serving : <NEWLINE> <TAB> outputs = estimator_spec . export_outputs <NEWLINE> if not outputs : <NEWLINE> <TAB> outputs = { } <NEWLINE> <UNTAB> outputs = { ALL_SERVING_KEY : PredictOutput ( estimator_spec . predictions ) } <NEWLINE> print ( estimator_spec . export_outputs ) <NEWLINE> <NEWLINE> <NEWLINE> estimator_spec = estimator_spec . _replace ( export_outputs = outputs ) <NEWLINE> <NEWLINE> <UNTAB> return estimator_spec <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return _model_fn <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _add_control_inputs ( self , ops ) : <NEWLINE> <TAB> <NEWLINE> for op in ops : <NEWLINE> <TAB> if not isinstance ( op , Operation ) : <NEWLINE> <TAB> raise TypeError ( <STRING> % op ) <NEWLINE> <UNTAB> c_api . AddControlInput ( self . _graph . _c_graph , self . _c_op , op . _c_op ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def laguerre_poly ( n , x = None , alpha = None , polys = False ) : <NEWLINE> <TAB> <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % n ) <NEWLINE> <NEWLINE> <UNTAB> if alpha is not None : <NEWLINE> <TAB> K , alpha = construct_domain ( <NEWLINE> alpha , field = True ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> K , alpha = QQ , QQ ( <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> poly = DMP ( dup_laguerre ( int ( n ) , alpha , K ) , K ) <NEWLINE> <NEWLINE> if x is not None : <NEWLINE> <TAB> poly = Poly . new ( poly , x ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> poly = PurePoly . new ( poly , Dummy ( <STRING> ) ) <NEWLINE> <NEWLINE> <UNTAB> return poly if polys else poly . as_expr ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def eval ( x ) : <NEWLINE> <TAB> <NEWLINE> return get_value ( to_dense ( x ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def axisinfo ( unit , axis ) : <NEWLINE> <TAB> <NEWLINE> tz = unit <NEWLINE> <NEWLINE> majloc = PandasAutoDateLocator ( tz = tz ) <NEWLINE> majfmt = PandasAutoDateFormatter ( majloc , tz = tz ) <NEWLINE> datemin = pydt . date ( <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> datemax = pydt . date ( <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> <NEWLINE> return units . AxisInfo ( majloc = majloc , majfmt = majfmt , label = <STRING> , <NEWLINE> default_limits = ( datemin , datemax ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def remove ( self ) : <NEWLINE> <TAB> <NEWLINE> self . Q . ax . figure . callbacks . disconnect ( self . _cid ) <NEWLINE> self . _cid = None <NEWLINE> <NEWLINE> martist . Artist . remove ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def doit ( self , ** hints ) : <NEWLINE> <TAB> <NEWLINE> if hints . get ( <STRING> , True ) : <NEWLINE> <TAB> terms = [ term . doit ( ** hints ) if isinstance ( term , Basic ) else term <NEWLINE> for term in self . args ] <NEWLINE> return self . func ( * terms ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def exists ( path ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> os . stat ( path ) <NEWLINE> <UNTAB> except OSError : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_sympy ( self , a ) : <NEWLINE> <TAB> <NEWLINE> return SymPyRational ( int ( gmpy_numer ( a ) ) , <NEWLINE> int ( gmpy_denom ( a ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def pop ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> elt = self . h [ <NUMBER> ] <NEWLINE> del self . d [ elt ] <NEWLINE> <NEWLINE> if len ( self . h ) == <NUMBER> : <NEWLINE> <TAB> self . h . pop ( ) <NEWLINE> return elt <NEWLINE> <NEWLINE> <UNTAB> last = self . h . pop ( ) <NEWLINE> self . h [ <NUMBER> ] = last <NEWLINE> self . d [ last ] = <NUMBER> <NEWLINE> <NEWLINE> pos = self . _siftup ( <NUMBER> ) <NEWLINE> self . _siftdown ( pos ) <NEWLINE> <NEWLINE> return elt <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ contextlib . contextmanager <NEWLINE> def temppath ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> fd , path = mkstemp ( * args , ** kwargs ) <NEWLINE> os . close ( fd ) <NEWLINE> try : <NEWLINE> <TAB> yield path <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> os . remove ( path ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sall ( brule , fns = basic_fns ) : <NEWLINE> <TAB> <NEWLINE> op , new , children , leaf = map ( fns . get , ( <STRING> , <STRING> , <STRING> , <STRING> ) ) <NEWLINE> def all_rl ( expr ) : <NEWLINE> <TAB> if leaf ( expr ) : <NEWLINE> <TAB> yield expr <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> myop = op ( expr ) <NEWLINE> argss = product ( * map ( brule , children ( expr ) ) ) <NEWLINE> for args in argss : <NEWLINE> <TAB> yield new ( myop , * args ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return all_rl <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _find ( self , tests , obj , name , module , source_lines , globs , seen ) : <NEWLINE> <TAB> <NEWLINE> if self . _verbose : <NEWLINE> <TAB> print ( <STRING> % name ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if id ( obj ) in seen : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> seen [ id ( obj ) ] = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if inspect . isclass ( obj ) : <NEWLINE> <TAB> if obj . __module__ . split ( <STRING> ) [ <NUMBER> ] != <STRING> : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> test = self . _get_test ( obj , name , module , globs , source_lines ) <NEWLINE> if test is not None : <NEWLINE> <TAB> tests . append ( test ) <NEWLINE> <NEWLINE> <UNTAB> if not self . _recurse : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if inspect . ismodule ( obj ) : <NEWLINE> <TAB> for rawname , val in obj . __dict__ . items ( ) : <NEWLINE> <NEWLINE> <TAB> if inspect . isfunction ( val ) or inspect . isclass ( val ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if val . __module__ != module . __name__ : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> assert self . _from_module ( module , val ) , <STRING> % ( val , module , rawname ) <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> valname = <STRING> % ( name , rawname ) <NEWLINE> self . _find ( tests , val , valname , module , <NEWLINE> source_lines , globs , seen ) <NEWLINE> <UNTAB> except KeyboardInterrupt : <NEWLINE> <TAB> raise <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> for valname , val in getattr ( obj , <STRING> , { } ) . items ( ) : <NEWLINE> <TAB> if not isinstance ( valname , string_types ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % <NEWLINE> ( type ( valname ) , ) ) <NEWLINE> <UNTAB> if not ( inspect . isfunction ( val ) or inspect . isclass ( val ) or <NEWLINE> inspect . ismethod ( val ) or inspect . ismodule ( val ) or <NEWLINE> isinstance ( val , string_types ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % <NEWLINE> ( type ( val ) , ) ) <NEWLINE> <UNTAB> valname = <STRING> % ( name , valname ) <NEWLINE> self . _find ( tests , val , valname , module , source_lines , <NEWLINE> globs , seen ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if inspect . isclass ( obj ) : <NEWLINE> <TAB> for valname , val in obj . __dict__ . items ( ) : <NEWLINE> <NEWLINE> <TAB> if isinstance ( val , staticmethod ) : <NEWLINE> <TAB> val = getattr ( obj , valname ) <NEWLINE> <UNTAB> if isinstance ( val , classmethod ) : <NEWLINE> <TAB> val = getattr ( obj , valname ) . __func__ <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if ( ( inspect . isfunction ( unwrap ( val ) ) or <NEWLINE> inspect . isclass ( val ) or <NEWLINE> isinstance ( val , property ) ) and <NEWLINE> self . _from_module ( module , val ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if isinstance ( val , property ) : <NEWLINE> <TAB> if hasattr ( val . fget , <STRING> ) : <NEWLINE> <TAB> if val . fget . __module__ != module . __name__ : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if val . __module__ != module . __name__ : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> assert self . _from_module ( module , val ) , <STRING> % ( <NEWLINE> val , module , valname ) <NEWLINE> <NEWLINE> valname = <STRING> % ( name , valname ) <NEWLINE> self . _find ( tests , val , valname , module , source_lines , <NEWLINE> globs , seen ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _extend_blocks ( result , blocks = None ) : <NEWLINE> <TAB> <NEWLINE> if blocks is None : <NEWLINE> <TAB> blocks = [ ] <NEWLINE> <UNTAB> if isinstance ( result , list ) : <NEWLINE> <TAB> for r in result : <NEWLINE> <TAB> if isinstance ( r , list ) : <NEWLINE> <TAB> blocks . extend ( r ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> blocks . append ( r ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif isinstance ( result , BlockManager ) : <NEWLINE> <TAB> blocks . extend ( result . blocks ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> blocks . append ( result ) <NEWLINE> <UNTAB> return blocks <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ constructor <NEWLINE> def stack ( * tensors , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not tensors and not kwargs : <NEWLINE> <TAB> raise Exception ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if not kwargs and not isinstance ( tensors [ <NUMBER> ] , ( list , tuple ) ) : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> , DeprecationWarning , <NEWLINE> stacklevel = <NUMBER> ) <NEWLINE> axis = <NUMBER> <NEWLINE> <UNTAB> elif <STRING> in kwargs : <NEWLINE> <TAB> tensors = kwargs [ <STRING> ] <NEWLINE> if <STRING> in kwargs : <NEWLINE> <TAB> axis = kwargs [ <STRING> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> axis = <NUMBER> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if len ( tensors ) == <NUMBER> : <NEWLINE> <TAB> axis = tensors [ <NUMBER> ] <NEWLINE> <UNTAB> elif <STRING> in kwargs : <NEWLINE> <TAB> axis = kwargs [ <STRING> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> axis = <NUMBER> <NEWLINE> <UNTAB> tensors = tensors [ <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if len ( tensors ) == <NUMBER> : <NEWLINE> <TAB> raise Exception ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if np . all ( <NEWLINE> [ <NEWLINE> isinstance ( t , ( np . number , float , integer_types , <NEWLINE> python_complex ) ) or <NEWLINE> ( isinstance ( t , Variable ) and <NEWLINE> isinstance ( t . type , TensorType ) and <NEWLINE> t . ndim == <NUMBER> ) <NEWLINE> for t in tensors ] ) : <NEWLINE> <NEWLINE> <TAB> tensors = list ( map ( as_tensor_variable , tensors ) ) <NEWLINE> dtype = scal . upcast ( * [ i . dtype for i in tensors ] ) <NEWLINE> return theano . tensor . opt . MakeVector ( dtype ) ( * tensors ) <NEWLINE> <UNTAB> return join ( axis , * [ shape_padaxis ( t , axis ) for t in tensors ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def open_group ( self , s , gid = None ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def save_file ( self , obj ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> import StringIO as pystringIO <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> import io as pystringIO <NEWLINE> <NEWLINE> <UNTAB> if not hasattr ( obj , <STRING> ) or not hasattr ( obj , <STRING> ) : <NEWLINE> <TAB> raise pickle . PicklingError ( <STRING> ) <NEWLINE> <UNTAB> if obj is sys . stdout : <NEWLINE> <TAB> return self . save_reduce ( getattr , ( sys , <STRING> ) , obj = obj ) <NEWLINE> <UNTAB> if obj is sys . stderr : <NEWLINE> <TAB> return self . save_reduce ( getattr , ( sys , <STRING> ) , obj = obj ) <NEWLINE> <UNTAB> if obj is sys . stdin : <NEWLINE> <TAB> raise pickle . PicklingError ( <STRING> ) <NEWLINE> <UNTAB> if obj . closed : <NEWLINE> <TAB> raise pickle . PicklingError ( <STRING> ) <NEWLINE> <UNTAB> if hasattr ( obj , <STRING> ) and obj . isatty ( ) : <NEWLINE> <TAB> raise pickle . PicklingError ( <STRING> ) <NEWLINE> <UNTAB> if <STRING> not in obj . mode and <STRING> not in obj . mode : <NEWLINE> <TAB> raise pickle . PicklingError ( <STRING> % obj . mode ) <NEWLINE> <NEWLINE> <UNTAB> name = obj . name <NEWLINE> <NEWLINE> retval = pystringIO . StringIO ( ) <NEWLINE> <NEWLINE> try : <NEWLINE> <NEWLINE> <TAB> curloc = obj . tell ( ) <NEWLINE> obj . seek ( <NUMBER> ) <NEWLINE> contents = obj . read ( ) <NEWLINE> obj . seek ( curloc ) <NEWLINE> <UNTAB> except IOError : <NEWLINE> <TAB> raise pickle . PicklingError ( <STRING> % name ) <NEWLINE> <UNTAB> retval . write ( contents ) <NEWLINE> retval . seek ( curloc ) <NEWLINE> <NEWLINE> retval . name = name <NEWLINE> self . save ( retval ) <NEWLINE> self . memoize ( obj ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def eye ( kls , rows , cols = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if cols is None : <NEWLINE> <TAB> cols = rows <NEWLINE> <UNTAB> klass = kwargs . get ( <STRING> , kls ) <NEWLINE> rows , cols = as_int ( rows ) , as_int ( cols ) <NEWLINE> <NEWLINE> return klass . _eval_eye ( rows , cols ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def hfft ( a , n = None , axis = - <NUMBER> , norm = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> a = array ( a , copy = True , dtype = complex ) <NEWLINE> if n is None : <NEWLINE> <TAB> n = ( a . shape [ axis ] - <NUMBER> ) * <NUMBER> <NEWLINE> <UNTAB> unitary = _unitary ( norm ) <NEWLINE> return irfft ( conjugate ( a ) , n , axis ) * ( sqrt ( n ) if unitary else n ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def from_mlab_linkage ( Z ) : <NEWLINE> <TAB> <NEWLINE> Z = np . asarray ( Z , dtype = np . double , order = <STRING> ) <NEWLINE> Zs = Z . shape <NEWLINE> <NEWLINE> <NEWLINE> if len ( Zs ) == <NUMBER> or ( len ( Zs ) == <NUMBER> and Zs [ <NUMBER> ] == <NUMBER> ) : <NEWLINE> <TAB> return Z . copy ( ) <NEWLINE> <NEWLINE> <UNTAB> if len ( Zs ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if Zs [ <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> return Z . copy ( ) <NEWLINE> <NEWLINE> <UNTAB> Zpart = Z . copy ( ) <NEWLINE> if Zpart [ : , <NUMBER> : <NUMBER> ] . min ( ) != <NUMBER> and Zpart [ : , <NUMBER> : <NUMBER> ] . max ( ) != <NUMBER> * Zs [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> Zpart [ : , <NUMBER> : <NUMBER> ] -= <NUMBER> <NEWLINE> CS = np . zeros ( ( Zs [ <NUMBER> ] , ) , dtype = np . double ) <NEWLINE> _hierarchy . calculate_cluster_sizes ( Zpart , CS , int ( Zs [ <NUMBER> ] ) + <NUMBER> ) <NEWLINE> return np . hstack ( [ Zpart , CS . reshape ( Zs [ <NUMBER> ] , <NUMBER> ) ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def make_qstr ( t ) : <NEWLINE> <TAB> <NEWLINE> if not is_string_like ( t ) : <NEWLINE> <TAB> t = str ( t ) <NEWLINE> <UNTAB> if <STRING> in t : <NEWLINE> <TAB> t = <STRING> % t <NEWLINE> <UNTAB> return t <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def or_ ( cls , * clauses ) : <NEWLINE> <TAB> <NEWLINE> return cls . _construct ( operators . or_ , False_ , True_ , * clauses ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _logits_to_predictions ( self , logits ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( None , <STRING> , ( logits , ) ) : <NEWLINE> <TAB> class_ids = math_ops . argmax ( <NEWLINE> logits , <NUMBER> , name = prediction_key . PredictionKey . CLASSES ) <NEWLINE> if self . _label_keys : <NEWLINE> <TAB> table = lookup_ops . index_to_string_table_from_tensor ( <NEWLINE> self . _label_keys , name = <STRING> ) <NEWLINE> classes = table . lookup ( class_ids ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> classes = class_ids <NEWLINE> <UNTAB> return { <NEWLINE> prediction_key . PredictionKey . LOGITS : logits , <NEWLINE> prediction_key . PredictionKey . PROBABILITIES : <NEWLINE> nn . softmax ( <NEWLINE> logits , name = prediction_key . PredictionKey . PROBABILITIES ) , <NEWLINE> prediction_key . PredictionKey . CLASSES : classes <NEWLINE> } <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ cacheit <NEWLINE> def _subs ( self , old , new , ** hints ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def fallback ( self , old , new ) : <NEWLINE> <TAB> <NEWLINE> hit = False <NEWLINE> args = list ( self . args ) <NEWLINE> for i , arg in enumerate ( args ) : <NEWLINE> <TAB> if not hasattr ( arg , <STRING> ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> arg = arg . _subs ( old , new , ** hints ) <NEWLINE> if not _aresame ( arg , args [ i ] ) : <NEWLINE> <TAB> hit = True <NEWLINE> args [ i ] = arg <NEWLINE> <UNTAB> <UNTAB> if hit : <NEWLINE> <TAB> rv = self . func ( * args ) <NEWLINE> hack2 = hints . get ( <STRING> , False ) <NEWLINE> if hack2 and self . is_Mul and not rv . is_Mul : <NEWLINE> <TAB> coeff = S . One <NEWLINE> nonnumber = [ ] <NEWLINE> for i in args : <NEWLINE> <TAB> if i . is_Number : <NEWLINE> <TAB> coeff *= i <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nonnumber . append ( i ) <NEWLINE> <UNTAB> <UNTAB> nonnumber = self . func ( * nonnumber ) <NEWLINE> if coeff is S . One : <NEWLINE> <TAB> return nonnumber <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . func ( coeff , nonnumber , evaluate = False ) <NEWLINE> <UNTAB> <UNTAB> return rv <NEWLINE> <UNTAB> return self <NEWLINE> <NEWLINE> <UNTAB> if _aresame ( self , old ) : <NEWLINE> <TAB> return new <NEWLINE> <NEWLINE> <UNTAB> rv = self . _eval_subs ( old , new ) <NEWLINE> if rv is None : <NEWLINE> <TAB> rv = fallback ( self , old , new ) <NEWLINE> <UNTAB> return rv <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def grid_slaves ( self , row = None , column = None ) : <NEWLINE> <TAB> <NEWLINE> args = ( ) <NEWLINE> if row is not None : <NEWLINE> <TAB> args = args + ( <STRING> , row ) <NEWLINE> <UNTAB> if column is not None : <NEWLINE> <TAB> args = args + ( <STRING> , column ) <NEWLINE> <UNTAB> return [ self . _nametowidget ( x ) for x in <NEWLINE> self . tk . splitlist ( self . tk . call ( <NEWLINE> ( <STRING> , <STRING> , self . _w ) + args ) ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def uirfftn ( inarray , dim = None , shape = None ) : <NEWLINE> <TAB> <NEWLINE> if dim is None : <NEWLINE> <TAB> dim = inarray . ndim <NEWLINE> <UNTAB> outarray = np . fft . irfftn ( inarray , shape , axes = range ( - dim , <NUMBER> ) ) <NEWLINE> return outarray * np . sqrt ( np . prod ( outarray . shape [ - dim : ] ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _wait_queue ( self ) : <NEWLINE> <TAB> <NEWLINE> while True : <NEWLINE> <TAB> time . sleep ( <NUMBER> ) <NEWLINE> if self . queue . unfinished_tasks == <NUMBER> or self . stop_signal . is_set ( ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def closeness_vitality ( G , node = None , weight = None , wiener_index = None ) : <NEWLINE> <TAB> <NEWLINE> if wiener_index is None : <NEWLINE> <TAB> wiener_index = nx . wiener_index ( G , weight = weight ) <NEWLINE> <UNTAB> if node is not None : <NEWLINE> <TAB> after = nx . wiener_index ( G . subgraph ( set ( G ) - { node } ) , weight = weight ) <NEWLINE> return wiener_index - after <NEWLINE> <UNTAB> vitality = partial ( closeness_vitality , G , weight = weight , <NEWLINE> wiener_index = wiener_index ) <NEWLINE> <NEWLINE> return { v : vitality ( node = v ) for v in G } <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , inputs , state , scope = None ) : <NEWLINE> <TAB> <NEWLINE> def _should_dropout ( p ) : <NEWLINE> <TAB> return ( not isinstance ( p , float ) ) or p < <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> if _should_dropout ( self . _input_keep_prob ) : <NEWLINE> <TAB> inputs = self . _dropout ( inputs , <STRING> , <NEWLINE> self . _recurrent_input_noise , <NEWLINE> self . _input_keep_prob ) <NEWLINE> <UNTAB> output , new_state = self . _cell ( inputs , state , scope = scope ) <NEWLINE> if _should_dropout ( self . _state_keep_prob ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> shallow_filtered_substructure = nest . get_traverse_shallow_structure ( <NEWLINE> self . _dropout_state_filter , new_state ) <NEWLINE> new_state = self . _dropout ( new_state , <STRING> , <NEWLINE> self . _recurrent_state_noise , <NEWLINE> self . _state_keep_prob , <NEWLINE> shallow_filtered_substructure ) <NEWLINE> <UNTAB> if _should_dropout ( self . _output_keep_prob ) : <NEWLINE> <TAB> output = self . _dropout ( output , <STRING> , <NEWLINE> self . _recurrent_output_noise , <NEWLINE> self . _output_keep_prob ) <NEWLINE> <UNTAB> return output , new_state <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_units ( self , u ) : <NEWLINE> <TAB> <NEWLINE> pchanged = False <NEWLINE> if u is None : <NEWLINE> <TAB> self . units = None <NEWLINE> pchanged = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if u != self . units : <NEWLINE> <TAB> self . units = u <NEWLINE> pchanged = True <NEWLINE> <UNTAB> <UNTAB> if pchanged : <NEWLINE> <TAB> self . _update_axisinfo ( ) <NEWLINE> self . callbacks . process ( <STRING> ) <NEWLINE> self . callbacks . process ( <STRING> ) <NEWLINE> <UNTAB> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_feed_dict_fn ( self ) : <NEWLINE> <TAB> <NEWLINE> x_is_dict , y_is_dict = isinstance ( <NEWLINE> self . _x , dict ) , self . _y is not None and isinstance ( self . _y , dict ) <NEWLINE> <NEWLINE> <NEWLINE> def extract ( data , indices ) : <NEWLINE> <TAB> return ( np . array ( _access ( data , indices ) ) . reshape ( ( indices . shape [ <NUMBER> ] , <NUMBER> ) ) <NEWLINE> if len ( data . shape ) == <NUMBER> else _access ( data , indices ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> def assign_label ( data , shape , dtype , n_classes , indices ) : <NEWLINE> <TAB> shape [ <NUMBER> ] = indices . shape [ <NUMBER> ] <NEWLINE> out = np . zeros ( shape , dtype = dtype ) <NEWLINE> for i in xrange ( out . shape [ <NUMBER> ] ) : <NEWLINE> <TAB> sample = indices [ i ] <NEWLINE> <NEWLINE> if n_classes is None : <NEWLINE> <TAB> out [ i ] = _access ( data , sample ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if n_classes > <NUMBER> : <NEWLINE> <TAB> if len ( shape ) == <NUMBER> : <NEWLINE> <TAB> out . itemset ( ( i , int ( _access ( data , sample ) ) ) , <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for idx , value in enumerate ( _access ( data , sample ) ) : <NEWLINE> <TAB> out . itemset ( tuple ( [ i , idx , value ] ) , <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> out [ i ] = _access ( data , sample ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return out <NEWLINE> <NEWLINE> <UNTAB> def _feed_dict_fn ( ) : <NEWLINE> <TAB> <NEWLINE> if self . max_epochs is not None and self . epoch + <NUMBER> > self . max_epochs : <NEWLINE> <TAB> raise StopIteration <NEWLINE> <UNTAB> assert self . _input_placeholder is not None <NEWLINE> feed_dict = { } <NEWLINE> if self . _epoch_placeholder is not None : <NEWLINE> <TAB> feed_dict [ self . _epoch_placeholder . name ] = [ self . epoch ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> x_len = list ( <NEWLINE> self . _x . values ( ) ) [ <NUMBER> ] . shape [ <NUMBER> ] if x_is_dict else self . _x . shape [ <NUMBER> ] <NEWLINE> end = min ( x_len , self . offset + self . _batch_size ) <NEWLINE> batch_indices = self . indices [ self . offset : end ] <NEWLINE> <NEWLINE> <NEWLINE> feed_dict . update ( <NEWLINE> dict ( [ ( self . _input_placeholder [ k ] . name , extract ( v , batch_indices ) ) <NEWLINE> for k , v in list ( self . _x . items ( ) ) ] ) if x_is_dict else { <NEWLINE> self . _input_placeholder . name : <NEWLINE> extract ( self . _x , batch_indices ) <NEWLINE> } ) <NEWLINE> <NEWLINE> <NEWLINE> self . offset += self . _batch_size <NEWLINE> if self . offset >= x_len : <NEWLINE> <TAB> self . indices = self . random_state . permutation ( <NEWLINE> x_len ) if self . _shuffle else np . array ( range ( x_len ) ) <NEWLINE> self . offset = <NUMBER> <NEWLINE> self . epoch += <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . _output_placeholder is None : <NEWLINE> <TAB> return feed_dict <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if y_is_dict : <NEWLINE> <TAB> for k , v in list ( self . _y . items ( ) ) : <NEWLINE> <TAB> n_classes = ( self . n_classes [ k ] if k in self . n_classes else <NEWLINE> None ) if self . n_classes is not None else None <NEWLINE> shape , dtype = self . output_shape [ k ] , self . _output_dtype [ k ] <NEWLINE> feed_dict . update ( { <NEWLINE> self . _output_placeholder [ k ] . name : <NEWLINE> assign_label ( v , shape , dtype , n_classes , batch_indices ) <NEWLINE> } ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> shape , dtype , n_classes = ( self . output_shape , self . _output_dtype , <NEWLINE> self . n_classes ) <NEWLINE> feed_dict . update ( { <NEWLINE> self . _output_placeholder . name : <NEWLINE> assign_label ( self . _y , shape , dtype , n_classes , batch_indices ) <NEWLINE> } ) <NEWLINE> <NEWLINE> <UNTAB> return feed_dict <NEWLINE> <NEWLINE> <UNTAB> return _feed_dict_fn <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def canberra_distance ( self , p ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> s , p = Point . _normalize_dimension ( self , Point ( p ) ) <NEWLINE> if self . is_zero and p . is_zero : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return Add ( * ( ( abs ( a - b ) / ( abs ( a ) + abs ( b ) ) ) for a , b in zip ( s , p ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_toplevel_options ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . global_options + [ <NEWLINE> ( <STRING> , None , <NEWLINE> <STRING> ) , <NEWLINE> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dtype ( x ) : <NEWLINE> <TAB> <NEWLINE> return x . dtype . base_dtype . name <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _train_ops ( self , features ) : <NEWLINE> <TAB> <NEWLINE> mode = estimator_lib . ModeKeys . TRAIN <NEWLINE> with variable_scope . variable_scope ( <NEWLINE> <STRING> , <NEWLINE> <NEWLINE> use_resource = True ) : <NEWLINE> <TAB> model_outputs = self . create_loss ( features , mode ) <NEWLINE> <NEWLINE> <UNTAB> train_op = self . optimizer . minimize ( <NEWLINE> model_outputs . loss , <NEWLINE> global_step = training_util . get_global_step ( ) ) <NEWLINE> return estimator_lib . EstimatorSpec ( <NEWLINE> loss = model_outputs . loss , <NEWLINE> mode = mode , <NEWLINE> train_op = train_op ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def color_list_to_matrix_and_cmap ( colors , ind , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if any ( issubclass ( type ( x ) , list ) for x in colors ) : <NEWLINE> <TAB> all_colors = set ( itertools . chain ( * colors ) ) <NEWLINE> n = len ( colors ) <NEWLINE> m = len ( colors [ <NUMBER> ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> all_colors = set ( colors ) <NEWLINE> n = <NUMBER> <NEWLINE> m = len ( colors ) <NEWLINE> colors = [ colors ] <NEWLINE> <UNTAB> color_to_value = dict ( ( col , i ) for i , col in enumerate ( all_colors ) ) <NEWLINE> <NEWLINE> matrix = np . array ( [ color_to_value [ c ] <NEWLINE> for color in colors for c in color ] ) <NEWLINE> <NEWLINE> shape = ( n , m ) <NEWLINE> matrix = matrix . reshape ( shape ) <NEWLINE> matrix = matrix [ : , ind ] <NEWLINE> if axis == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> matrix = matrix . T <NEWLINE> <NEWLINE> <UNTAB> cmap = mpl . colors . ListedColormap ( all_colors ) <NEWLINE> return matrix , cmap <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pappus_graph ( ) : <NEWLINE> <TAB> <NEWLINE> G = LCF_graph ( <NUMBER> , [ <NUMBER> , <NUMBER> , - <NUMBER> , <NUMBER> , - <NUMBER> , - <NUMBER> ] , <NUMBER> ) <NEWLINE> G . name = <STRING> <NEWLINE> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _guess_expansion ( f , x ) : <NEWLINE> <TAB> <NEWLINE> from sympy import expand_trig <NEWLINE> from sympy . functions . elementary . trigonometric import TrigonometricFunction <NEWLINE> res = [ ( f , <STRING> ) ] <NEWLINE> <NEWLINE> orig = res [ - <NUMBER> ] [ <NUMBER> ] <NEWLINE> saw = { orig } <NEWLINE> expanded = expand_mul ( orig ) <NEWLINE> if expanded not in saw : <NEWLINE> <TAB> res += [ ( expanded , <STRING> ) ] <NEWLINE> saw . add ( expanded ) <NEWLINE> <NEWLINE> <UNTAB> expanded = expand ( orig ) <NEWLINE> if expanded not in saw : <NEWLINE> <TAB> res += [ ( expanded , <STRING> ) ] <NEWLINE> saw . add ( expanded ) <NEWLINE> <NEWLINE> <UNTAB> if orig . has ( TrigonometricFunction , HyperbolicFunction ) : <NEWLINE> <TAB> expanded = expand_mul ( expand_trig ( orig ) ) <NEWLINE> if expanded not in saw : <NEWLINE> <TAB> res += [ ( expanded , <STRING> ) ] <NEWLINE> saw . add ( expanded ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if orig . has ( cos , sin ) : <NEWLINE> <TAB> reduced = sincos_to_sum ( orig ) <NEWLINE> if reduced not in saw : <NEWLINE> <TAB> res += [ ( reduced , <STRING> ) ] <NEWLINE> saw . add ( reduced ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return res <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _select_single_value ( self , structured ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def _select_fn ( x ) : <NEWLINE> <TAB> if isinstance ( x , values . Mirrored ) : <NEWLINE> <TAB> if len ( x . devices ) == <NUMBER> : <NEWLINE> <TAB> return list ( x . _index . values ( ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % x ) <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( x , values . PerDevice ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % x ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return x <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return nest . map_structure ( _select_fn , structured ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _update_trajectory ( self , xm , ym ) : <NEWLINE> <TAB> <NEWLINE> if self . _current_xy != ( xm , ym ) : <NEWLINE> <TAB> if self [ ym , xm ] == <NUMBER> : <NEWLINE> <TAB> self . _traj . append ( ( ym , xm ) ) <NEWLINE> self . _mask [ ym , xm ] = <NUMBER> <NEWLINE> self . _current_xy = ( xm , ym ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise InvalidIndexError <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def announce ( self , msg , level = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> log . log ( level , msg ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _hist_bin_auto ( x ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> return min ( _hist_bin_fd ( x ) , _hist_bin_sturges ( x ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def parametrize ( vars , input ) : <NEWLINE> <TAB> <NEWLINE> from . parameterized import parameterized <NEWLINE> <NEWLINE> return parameterized ( input ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dmp_neg ( f , u , K ) : <NEWLINE> <TAB> <NEWLINE> if not u : <NEWLINE> <TAB> return dup_neg ( f , K ) <NEWLINE> <NEWLINE> <UNTAB> v = u - <NUMBER> <NEWLINE> <NEWLINE> return [ dmp_neg ( cf , v , K ) for cf in f ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def has_fit_parameter ( estimator , parameter ) : <NEWLINE> <TAB> <NEWLINE> return parameter in signature ( estimator . fit ) . parameters <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dup_isolate_all_roots ( f , K , eps = None , inf = None , sup = None , fast = False ) : <NEWLINE> <TAB> <NEWLINE> if not K . is_ZZ and not K . is_QQ : <NEWLINE> <TAB> raise DomainError ( <STRING> % K ) <NEWLINE> <NEWLINE> <UNTAB> _ , factors = dup_sqf_list ( f , K ) <NEWLINE> <NEWLINE> if len ( factors ) == <NUMBER> : <NEWLINE> <TAB> ( ( f , k ) , ) = factors <NEWLINE> <NEWLINE> real_part , complex_part = dup_isolate_all_roots_sqf ( <NEWLINE> f , K , eps = eps , inf = inf , sup = sup , fast = fast ) <NEWLINE> <NEWLINE> real_part = [ ( ( a , b ) , k ) for ( a , b ) in real_part ] <NEWLINE> complex_part = [ ( ( a , b ) , k ) for ( a , b ) in complex_part ] <NEWLINE> <NEWLINE> return real_part , complex_part <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def local_variables ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . get_collection ( ops . GraphKeys . LOCAL_VARIABLES ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def as_op ( itypes , otypes , infer_shape = None ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( itypes , ( list , tuple ) ) : <NEWLINE> <TAB> itypes = [ itypes ] <NEWLINE> <UNTAB> if any ( not isinstance ( t , theano . Type ) for t in itypes ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if not isinstance ( otypes , ( list , tuple ) ) : <NEWLINE> <TAB> otypes = [ otypes ] <NEWLINE> <UNTAB> if any ( not isinstance ( t , theano . Type ) for t in otypes ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> itypes = list ( itypes ) <NEWLINE> otypes = list ( otypes ) <NEWLINE> <NEWLINE> if infer_shape is not None and not callable ( infer_shape ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> def make_op ( fn ) : <NEWLINE> <TAB> return FromFunctionOp ( fn , itypes , otypes , infer_shape ) <NEWLINE> <UNTAB> return make_op <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def max ( x , axis = None , keepdims = False ) : <NEWLINE> <TAB> <NEWLINE> return math_ops . reduce_max ( x , axis , keepdims ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _draw_bbox ( self , renderer , posx , posy ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> x_box , y_box , w_box , h_box = _get_textbox ( self , renderer ) <NEWLINE> self . _bbox_patch . set_bounds ( <NUMBER> , <NUMBER> , w_box , h_box ) <NEWLINE> theta = np . deg2rad ( self . get_rotation ( ) ) <NEWLINE> tr = Affine2D ( ) . rotate ( theta ) <NEWLINE> tr = tr . translate ( posx + x_box , posy + y_box ) <NEWLINE> self . _bbox_patch . set_transform ( tr ) <NEWLINE> fontsize_in_pixel = renderer . points_to_pixels ( self . get_size ( ) ) <NEWLINE> self . _bbox_patch . set_mutation_scale ( fontsize_in_pixel ) <NEWLINE> self . _bbox_patch . draw ( renderer ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def debug_decorator ( func ) : <NEWLINE> <TAB> <NEWLINE> from sympy import SYMPY_DEBUG <NEWLINE> <NEWLINE> if not SYMPY_DEBUG : <NEWLINE> <TAB> return func <NEWLINE> <NEWLINE> <UNTAB> def maketree ( f , * args , ** kw ) : <NEWLINE> <TAB> global _debug_tmp <NEWLINE> global _debug_iter <NEWLINE> oldtmp = _debug_tmp <NEWLINE> _debug_tmp = [ ] <NEWLINE> _debug_iter += <NUMBER> <NEWLINE> <NEWLINE> def tree ( subtrees ) : <NEWLINE> <TAB> def indent ( s , type = <NUMBER> ) : <NEWLINE> <TAB> x = s . split ( <STRING> ) <NEWLINE> r = <STRING> % x [ <NUMBER> ] <NEWLINE> for a in x [ <NUMBER> : ] : <NEWLINE> <TAB> if a == <STRING> : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> if type == <NUMBER> : <NEWLINE> <TAB> r += <STRING> % a <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> r += <STRING> % a <NEWLINE> <UNTAB> <UNTAB> return r <NEWLINE> <UNTAB> if len ( subtrees ) == <NUMBER> : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> f = [ ] <NEWLINE> for a in subtrees [ : - <NUMBER> ] : <NEWLINE> <TAB> f . append ( indent ( a ) ) <NEWLINE> <UNTAB> f . append ( indent ( subtrees [ - <NUMBER> ] , <NUMBER> ) ) <NEWLINE> return <STRING> . join ( f ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> r = f ( * args , ** kw ) <NEWLINE> <NEWLINE> _debug_iter -= <NUMBER> <NEWLINE> s = <STRING> % ( get_function_name ( f ) , args , r ) <NEWLINE> if _debug_tmp != [ ] : <NEWLINE> <TAB> s += tree ( _debug_tmp ) <NEWLINE> <UNTAB> _debug_tmp = oldtmp <NEWLINE> _debug_tmp . append ( s ) <NEWLINE> if _debug_iter == <NUMBER> : <NEWLINE> <TAB> print ( ( _debug_tmp [ <NUMBER> ] ) ) <NEWLINE> _debug_tmp = [ ] <NEWLINE> <UNTAB> return r <NEWLINE> <NEWLINE> <UNTAB> def decorated ( * args , ** kwargs ) : <NEWLINE> <TAB> return maketree ( func , * args , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> return decorated <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def number_of_edges ( self , u = None , v = None ) : <NEWLINE> <TAB> <NEWLINE> if u is None : <NEWLINE> <TAB> return int ( self . size ( ) ) <NEWLINE> <UNTAB> if v in self . _adj [ u ] : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> return <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __isub__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> for elem , count in other . items ( ) : <NEWLINE> <TAB> self [ elem ] -= count <NEWLINE> <UNTAB> return self . _keep_positive ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sparse_segment_mean_with_num_segments ( data , indices , segment_ids , num_segments , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , data = data , indices = indices , <NEWLINE> segment_ids = segment_ids , num_segments = num_segments , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) , <NEWLINE> <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , data , indices , segment_ids , <NEWLINE> num_segments ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return sparse_segment_mean_with_num_segments_eager_fallback ( <NEWLINE> data , indices , segment_ids , num_segments , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _eval_rewrite_as_Piecewise ( self , * args ) : <NEWLINE> <TAB> <NEWLINE> x = self . args [ <NUMBER> ] <NEWLINE> a = self . args [ <NUMBER> ] <NEWLINE> n = sympify ( self . args [ <NUMBER> ] ) <NEWLINE> <NEWLINE> if n == - <NUMBER> or n == - <NUMBER> : <NEWLINE> <TAB> return Piecewise ( ( oo , Eq ( ( x - a ) , <NUMBER> ) ) , ( <NUMBER> , True ) ) <NEWLINE> <UNTAB> elif n . is_nonnegative : <NEWLINE> <TAB> return Piecewise ( ( ( x - a ) ** n , ( x - a ) > <NUMBER> ) , ( <NUMBER> , True ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def transpose ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _eval_transpose ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , enum_values , case_sensitive = True ) : <NEWLINE> <TAB> <NEWLINE> if not enum_values : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> . format ( enum_values ) ) <NEWLINE> <UNTAB> super ( EnumParser , self ) . __init__ ( ) <NEWLINE> self . enum_values = enum_values <NEWLINE> self . case_sensitive = case_sensitive <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _setfieldnames ( self , names , titles ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if ( names ) : <NEWLINE> <TAB> if ( type ( names ) in [ list , tuple ] ) : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> elif isinstance ( names , str ) : <NEWLINE> <TAB> names = names . split ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise NameError ( <STRING> % repr ( names ) ) <NEWLINE> <NEWLINE> <UNTAB> self . _names = [ n . strip ( ) for n in names [ : self . _nfields ] ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _names = [ ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . _names += [ <STRING> % i for i in range ( len ( self . _names ) , <NEWLINE> self . _nfields ) ] <NEWLINE> <NEWLINE> _dup = find_duplicate ( self . _names ) <NEWLINE> if _dup : <NEWLINE> <TAB> raise ValueError ( <STRING> % _dup ) <NEWLINE> <NEWLINE> <UNTAB> if ( titles ) : <NEWLINE> <TAB> self . _titles = [ n . strip ( ) for n in titles [ : self . _nfields ] ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _titles = [ ] <NEWLINE> titles = [ ] <NEWLINE> <NEWLINE> <UNTAB> if ( self . _nfields > len ( titles ) ) : <NEWLINE> <TAB> self . _titles += [ None ] * ( self . _nfields - len ( titles ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def complete ( y ) : <NEWLINE> <TAB> <NEWLINE> return linkage ( y , method = <STRING> , metric = <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def report_unexpected_exception ( self , out , test , example , exc_info ) : <NEWLINE> <TAB> <NEWLINE> out ( self . _failure_header ( test , example ) + <NEWLINE> <STRING> + _indent ( _exception_traceback ( exc_info ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_bbox_to_anchor ( self , bbox , transform = None ) : <NEWLINE> <TAB> <NEWLINE> if bbox is None : <NEWLINE> <TAB> self . _bbox_to_anchor = None <NEWLINE> return <NEWLINE> <UNTAB> elif isinstance ( bbox , BboxBase ) : <NEWLINE> <TAB> self . _bbox_to_anchor = bbox <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> l = len ( bbox ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> raise ValueError ( <STRING> % str ( bbox ) ) <NEWLINE> <NEWLINE> <UNTAB> if l == <NUMBER> : <NEWLINE> <TAB> bbox = [ bbox [ <NUMBER> ] , bbox [ <NUMBER> ] , <NUMBER> , <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> self . _bbox_to_anchor = Bbox . from_bounds ( * bbox ) <NEWLINE> <NEWLINE> <UNTAB> if transform is None : <NEWLINE> <TAB> transform = BboxTransformTo ( self . parent . bbox ) <NEWLINE> <NEWLINE> <UNTAB> self . _bbox_to_anchor = TransformedBbox ( self . _bbox_to_anchor , <NEWLINE> transform ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def tick_values ( self , vmin , vmax ) : <NEWLINE> <TAB> <NEWLINE> return [ ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def rem ( f , g ) : <NEWLINE> <TAB> <NEWLINE> lev , dom , per , F , G = f . unify ( g ) <NEWLINE> return per ( dmp_rem ( F , G , lev , dom ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def expand_empty ( tensor_var , size ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if size == <NUMBER> : <NEWLINE> <TAB> return tensor_var <NEWLINE> <UNTAB> shapes = [ tensor_var . shape [ x ] for x in xrange ( tensor_var . ndim ) ] <NEWLINE> new_shape = [ size + shapes [ <NUMBER> ] ] + shapes [ <NUMBER> : ] <NEWLINE> empty = tensor . AllocEmpty ( tensor_var . dtype ) ( * new_shape ) <NEWLINE> <NEWLINE> ret = tensor . set_subtensor ( empty [ : shapes [ <NUMBER> ] ] , tensor_var ) <NEWLINE> ret . tag . nan_guard_mode_check = False <NEWLINE> return ret <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def consolidate ( self , inplace = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> warnings . warn ( <STRING> <NEWLINE> <STRING> , FutureWarning , stacklevel = <NUMBER> ) <NEWLINE> return self . _consolidate ( inplace ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def plugin_info ( plugin ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return plugin_meta_data [ plugin ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> raise ValueError ( <STRING> % plugin ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def apply_gradients ( self , grads_and_vars , global_step = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> grads = [ g for ( g , _ ) in grads_and_vars ] <NEWLINE> <NEWLINE> is_finite_grad = [ ] <NEWLINE> for g in grads : <NEWLINE> <TAB> is_finite_grad . append ( math_ops . reduce_all ( gen_math_ops . is_finite ( g ) ) ) <NEWLINE> <UNTAB> is_overall_finite = math_ops . reduce_all ( is_finite_grad ) <NEWLINE> <NEWLINE> <NEWLINE> def true_apply_gradients_fn ( ) : <NEWLINE> <TAB> return self . _opt . apply_gradients ( grads_and_vars , global_step , name ) <NEWLINE> <NEWLINE> <UNTAB> update_vars = control_flow_ops . cond ( <NEWLINE> is_overall_finite , true_apply_gradients_fn , gen_control_flow_ops . no_op ) <NEWLINE> <NEWLINE> return control_flow_ops . group ( <NEWLINE> update_vars , <NEWLINE> self . _loss_scale_manager . update_loss_scale ( is_overall_finite ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _broadcast_shape ( * args ) : <NEWLINE> <TAB> <NEWLINE> if not args : <NEWLINE> <TAB> return ( ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> b = np . broadcast ( * args [ : <NUMBER> ] ) <NEWLINE> <NEWLINE> for pos in range ( <NUMBER> , len ( args ) , <NUMBER> ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> b = broadcast_to ( <NUMBER> , b . shape ) <NEWLINE> b = np . broadcast ( b , * args [ pos : ( pos + <NUMBER> ) ] ) <NEWLINE> <UNTAB> return b . shape <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def count_up_to ( self , limit ) : <NEWLINE> <TAB> <NEWLINE> return gen_state_ops . resource_count_up_to ( self . handle , limit = limit , <NEWLINE> T = self . dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def windmill_graph ( n , k ) : <NEWLINE> <TAB> <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise nx . NetworkXError ( msg ) <NEWLINE> <UNTAB> if k < <NUMBER> : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> G = nx . disjoint_union_all ( itertools . chain ( [ nx . complete_graph ( k ) ] , <NEWLINE> ( nx . complete_graph ( k - <NUMBER> ) <NEWLINE> for _ in range ( n - <NUMBER> ) ) ) ) <NEWLINE> G . add_edges_from ( ( <NUMBER> , i ) for i in range ( k , G . number_of_nodes ( ) ) ) <NEWLINE> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def forward ( self , x ) : <NEWLINE> <TAB> <NEWLINE> if self . W . data is None : <NEWLINE> <TAB> self . _initialize_params ( x . shape [ <NUMBER> ] ) <NEWLINE> <UNTAB> return dilated_convolution_2d . dilated_convolution_2d ( <NEWLINE> x , self . W , self . b , self . stride , self . pad , self . dilate ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def ids ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _mask is nomask : <NEWLINE> <TAB> return ( self . ctypes . data , id ( nomask ) ) <NEWLINE> <UNTAB> return ( self . ctypes . data , self . _mask . ctypes . data ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _drop_labels_or_levels ( self , keys , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> axis = self . _get_axis_number ( axis ) <NEWLINE> <NEWLINE> if self . ndim > <NUMBER> : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> <NEWLINE> . format ( type = type ( self ) ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> keys = com . _maybe_make_list ( keys ) <NEWLINE> invalid_keys = [ k for k in keys if not <NEWLINE> self . _is_label_or_level_reference ( k , axis = axis ) ] <NEWLINE> <NEWLINE> if invalid_keys : <NEWLINE> <TAB> raise ValueError ( ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> . format ( axis = axis , <NEWLINE> invalid_keys = invalid_keys ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> levels_to_drop = [ k for k in keys <NEWLINE> if self . _is_level_reference ( k , axis = axis ) ] <NEWLINE> <NEWLINE> labels_to_drop = [ k for k in keys <NEWLINE> if not self . _is_level_reference ( k , axis = axis ) ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> dropped = self . copy ( ) <NEWLINE> <NEWLINE> if axis == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> if levels_to_drop : <NEWLINE> <TAB> dropped . reset_index ( levels_to_drop , drop = True , inplace = True ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if labels_to_drop : <NEWLINE> <TAB> dropped . drop ( labels_to_drop , axis = <NUMBER> , inplace = True ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> if levels_to_drop : <NEWLINE> <TAB> if isinstance ( dropped . columns , MultiIndex ) : <NEWLINE> <NEWLINE> <TAB> dropped . columns = dropped . columns . droplevel ( levels_to_drop ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> dropped . columns = RangeIndex ( dropped . columns . size ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if labels_to_drop : <NEWLINE> <TAB> dropped . drop ( labels_to_drop , axis = <NUMBER> , inplace = True ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return dropped <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_forced_alpha ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _forced_alpha <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def close_event ( self , guiEvent = None ) : <NEWLINE> <TAB> <NEWLINE> s = <STRING> <NEWLINE> try : <NEWLINE> <TAB> event = CloseEvent ( s , self , guiEvent = guiEvent ) <NEWLINE> self . callbacks . process ( s , event ) <NEWLINE> <UNTAB> except ( TypeError , AttributeError ) : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def acos ( x ) : <NEWLINE> <TAB> <NEWLINE> np = import_module ( <STRING> ) <NEWLINE> if isinstance ( x , ( int , float ) ) : <NEWLINE> <TAB> if abs ( x ) > <NUMBER> : <NEWLINE> <NEWLINE> <TAB> return interval ( - np . inf , np . inf , is_valid = False ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return interval ( np . arccos ( x ) , np . arccos ( x ) ) <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( x , interval ) : <NEWLINE> <NEWLINE> <TAB> if x . is_valid is False or x . start > <NUMBER> or x . end < - <NUMBER> : <NEWLINE> <TAB> return interval ( - np . inf , np . inf , is_valid = False ) <NEWLINE> <NEWLINE> <UNTAB> elif x . start < - <NUMBER> or x . end > <NUMBER> : <NEWLINE> <TAB> return interval ( - np . inf , np . inf , is_valid = None ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> start = np . arccos ( x . start ) <NEWLINE> end = np . arccos ( x . end ) <NEWLINE> return interval ( start , end , is_valid = x . is_valid ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_session_log ( self , session_log , global_step = None ) : <NEWLINE> <TAB> <NEWLINE> event = event_pb2 . Event ( session_log = session_log ) <NEWLINE> self . _add_event ( event , global_step ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def to_int_repr ( clauses , symbols ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> symbols = dict ( list ( zip ( symbols , list ( range ( <NUMBER> , len ( symbols ) + <NUMBER> ) ) ) ) ) <NEWLINE> <NEWLINE> def append_symbol ( arg , symbols ) : <NEWLINE> <TAB> if isinstance ( arg , Not ) : <NEWLINE> <TAB> return - symbols [ arg . args [ <NUMBER> ] ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return symbols [ arg ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return [ set ( append_symbol ( arg , symbols ) for arg in Or . make_args ( c ) ) <NEWLINE> for c in clauses ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def entropy ( self , alpha ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> alpha = _dirichlet_check_parameters ( alpha ) <NEWLINE> <NEWLINE> alpha0 = np . sum ( alpha ) <NEWLINE> lnB = _lnB ( alpha ) <NEWLINE> K = alpha . shape [ <NUMBER> ] <NEWLINE> <NEWLINE> out = lnB + ( alpha0 - K ) * scipy . special . psi ( alpha0 ) - np . sum ( <NEWLINE> ( alpha - <NUMBER> ) * scipy . special . psi ( alpha ) ) <NEWLINE> return _squeeze_output ( out ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def insert ( arr , obj , values , axis = None ) : <NEWLINE> <TAB> <NEWLINE> wrap = None <NEWLINE> if type ( arr ) is not ndarray : <NEWLINE> <TAB> try : <NEWLINE> <TAB> wrap = arr . __array_wrap__ <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> arr = asarray ( arr ) <NEWLINE> ndim = arr . ndim <NEWLINE> arrorder = <STRING> if arr . flags . fnc else <STRING> <NEWLINE> if axis is None : <NEWLINE> <TAB> if ndim != <NUMBER> : <NEWLINE> <TAB> arr = arr . ravel ( ) <NEWLINE> <UNTAB> ndim = arr . ndim <NEWLINE> axis = ndim - <NUMBER> <NEWLINE> <UNTAB> elif ndim == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> , DeprecationWarning , stacklevel = <NUMBER> ) <NEWLINE> arr = arr . copy ( order = arrorder ) <NEWLINE> arr [ ... ] = values <NEWLINE> if wrap : <NEWLINE> <TAB> return wrap ( arr ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return arr <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> axis = normalize_axis_index ( axis , ndim ) <NEWLINE> <UNTAB> slobj = [ slice ( None ) ] * ndim <NEWLINE> N = arr . shape [ axis ] <NEWLINE> newshape = list ( arr . shape ) <NEWLINE> <NEWLINE> if isinstance ( obj , slice ) : <NEWLINE> <NEWLINE> <TAB> indices = arange ( * obj . indices ( N ) , ** { <STRING> : intp } ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> indices = np . array ( obj ) <NEWLINE> if indices . dtype == bool : <NEWLINE> <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> , FutureWarning , stacklevel = <NUMBER> ) <NEWLINE> indices = indices . astype ( intp ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif indices . ndim > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> if indices . size == <NUMBER> : <NEWLINE> <TAB> index = indices . item ( ) <NEWLINE> if index < - N or index > N : <NEWLINE> <TAB> raise IndexError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ( obj , axis , N ) ) <NEWLINE> <UNTAB> if ( index < <NUMBER> ) : <NEWLINE> <TAB> index += N <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> values = array ( values , copy = False , ndmin = arr . ndim , dtype = arr . dtype ) <NEWLINE> if indices . ndim == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> values = np . moveaxis ( values , <NUMBER> , axis ) <NEWLINE> <UNTAB> numnew = values . shape [ axis ] <NEWLINE> newshape [ axis ] += numnew <NEWLINE> new = empty ( newshape , arr . dtype , arrorder ) <NEWLINE> slobj [ axis ] = slice ( None , index ) <NEWLINE> new [ slobj ] = arr [ slobj ] <NEWLINE> slobj [ axis ] = slice ( index , index + numnew ) <NEWLINE> new [ slobj ] = values <NEWLINE> slobj [ axis ] = slice ( index + numnew , None ) <NEWLINE> slobj2 = [ slice ( None ) ] * ndim <NEWLINE> slobj2 [ axis ] = slice ( index , None ) <NEWLINE> new [ slobj ] = arr [ slobj2 ] <NEWLINE> if wrap : <NEWLINE> <TAB> return wrap ( new ) <NEWLINE> <UNTAB> return new <NEWLINE> <UNTAB> elif indices . size == <NUMBER> and not isinstance ( obj , np . ndarray ) : <NEWLINE> <NEWLINE> <TAB> indices = indices . astype ( intp ) <NEWLINE> <NEWLINE> <UNTAB> if not np . can_cast ( indices , intp , <STRING> ) : <NEWLINE> <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> , DeprecationWarning , stacklevel = <NUMBER> ) <NEWLINE> indices = indices . astype ( intp ) <NEWLINE> <NEWLINE> <UNTAB> indices [ indices < <NUMBER> ] += N <NEWLINE> <NEWLINE> numnew = len ( indices ) <NEWLINE> order = indices . argsort ( kind = <STRING> ) <NEWLINE> indices [ order ] += np . arange ( numnew ) <NEWLINE> <NEWLINE> newshape [ axis ] += numnew <NEWLINE> old_mask = ones ( newshape [ axis ] , dtype = bool ) <NEWLINE> old_mask [ indices ] = False <NEWLINE> <NEWLINE> new = empty ( newshape , arr . dtype , arrorder ) <NEWLINE> slobj2 = [ slice ( None ) ] * ndim <NEWLINE> slobj [ axis ] = indices <NEWLINE> slobj2 [ axis ] = old_mask <NEWLINE> new [ slobj ] = values <NEWLINE> new [ slobj2 ] = arr <NEWLINE> <NEWLINE> if wrap : <NEWLINE> <TAB> return wrap ( new ) <NEWLINE> <UNTAB> return new <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _from_iterable ( cls , it ) : <NEWLINE> <TAB> <NEWLINE> return cls ( it ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def zeros ( shape , dtype = None , order = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> a = ndarray . __new__ ( matrix , shape , dtype , order = order ) <NEWLINE> a . fill ( <NUMBER> ) <NEWLINE> return a <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_FF_gmpy ( K1 , a , K0 = None ) : <NEWLINE> <TAB> <NEWLINE> return K1 . dtype ( K1 . dom . from_ZZ_gmpy ( a . val , K0 . dom ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def plot_interval ( self , parameter = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> t = _symbol ( parameter , self . parameter , real = True ) <NEWLINE> return [ t ] + list ( self . limits [ <NUMBER> : ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _make_layout_margins ( ax , renderer , h_pad , w_pad ) : <NEWLINE> <TAB> <NEWLINE> fig = ax . figure <NEWLINE> invTransFig = fig . transFigure . inverted ( ) . transform_bbox <NEWLINE> <NEWLINE> pos = ax . get_position ( original = True ) <NEWLINE> tightbbox = ax . get_tightbbox ( renderer = renderer ) <NEWLINE> bbox = invTransFig ( tightbbox ) <NEWLINE> <NEWLINE> h_padt = ax . _poslayoutbox . h_pad <NEWLINE> if h_padt is None : <NEWLINE> <TAB> h_padt = h_pad <NEWLINE> <UNTAB> w_padt = ax . _poslayoutbox . w_pad <NEWLINE> if w_padt is None : <NEWLINE> <TAB> w_padt = w_pad <NEWLINE> <UNTAB> ax . _poslayoutbox . edit_left_margin_min ( - bbox . x0 + <NEWLINE> pos . x0 + w_padt ) <NEWLINE> ax . _poslayoutbox . edit_right_margin_min ( bbox . x1 - <NEWLINE> pos . x1 + w_padt ) <NEWLINE> ax . _poslayoutbox . edit_bottom_margin_min ( <NEWLINE> - bbox . y0 + pos . y0 + h_padt ) <NEWLINE> ax . _poslayoutbox . edit_top_margin_min ( bbox . y1 - pos . y1 + h_padt ) <NEWLINE> _log . debug ( <STRING> , ( - bbox . x0 + pos . x0 + w_pad ) ) <NEWLINE> _log . debug ( <STRING> , ( bbox . x1 - pos . x1 + w_pad ) ) <NEWLINE> _log . debug ( <STRING> , ( - bbox . y0 + pos . y0 + h_padt ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if fig . _layoutbox . constrained_layout_called < <NUMBER> : <NEWLINE> <TAB> ax . _poslayoutbox . constrain_height_min ( <NUMBER> , strength = <STRING> ) <NEWLINE> ax . _poslayoutbox . constrain_width_min ( <NUMBER> , strength = <STRING> ) <NEWLINE> ax . _layoutbox . constrain_height_min ( <NUMBER> , strength = <STRING> ) <NEWLINE> ax . _layoutbox . constrain_width_min ( <NUMBER> , strength = <STRING> ) <NEWLINE> ax . _poslayoutbox . constrain_top_margin ( <NUMBER> , strength = <STRING> ) <NEWLINE> ax . _poslayoutbox . constrain_bottom_margin ( <NUMBER> , <NEWLINE> strength = <STRING> ) <NEWLINE> ax . _poslayoutbox . constrain_right_margin ( <NUMBER> , strength = <STRING> ) <NEWLINE> ax . _poslayoutbox . constrain_left_margin ( <NUMBER> , strength = <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def primitive ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> terms = [ ] <NEWLINE> inf = False <NEWLINE> for a in self . args : <NEWLINE> <TAB> c , m = a . as_coeff_Mul ( ) <NEWLINE> if not c . is_Rational : <NEWLINE> <TAB> c = S . One <NEWLINE> m = a <NEWLINE> <UNTAB> inf = inf or m is S . ComplexInfinity <NEWLINE> terms . append ( ( c . p , c . q , m ) ) <NEWLINE> <NEWLINE> <UNTAB> if not inf : <NEWLINE> <TAB> ngcd = reduce ( igcd , [ t [ <NUMBER> ] for t in terms ] , <NUMBER> ) <NEWLINE> dlcm = reduce ( ilcm , [ t [ <NUMBER> ] for t in terms ] , <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ngcd = reduce ( igcd , [ t [ <NUMBER> ] for t in terms if t [ <NUMBER> ] ] , <NUMBER> ) <NEWLINE> dlcm = reduce ( ilcm , [ t [ <NUMBER> ] for t in terms if t [ <NUMBER> ] ] , <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> if ngcd == dlcm == <NUMBER> : <NEWLINE> <TAB> return S . One , self <NEWLINE> <UNTAB> if not inf : <NEWLINE> <TAB> for i , ( p , q , term ) in enumerate ( terms ) : <NEWLINE> <TAB> terms [ i ] = _keep_coeff ( Rational ( ( p // ngcd ) * ( dlcm // q ) ) , term ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for i , ( p , q , term ) in enumerate ( terms ) : <NEWLINE> <TAB> if q : <NEWLINE> <TAB> terms [ i ] = _keep_coeff ( Rational ( ( p // ngcd ) * ( dlcm // q ) ) , term ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> terms [ i ] = _keep_coeff ( Rational ( p , q ) , term ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if terms [ <NUMBER> ] . is_Number or terms [ <NUMBER> ] is S . ComplexInfinity : <NEWLINE> <TAB> c = terms . pop ( <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> c = None <NEWLINE> <UNTAB> _addsort ( terms ) <NEWLINE> if c : <NEWLINE> <TAB> terms . insert ( <NUMBER> , c ) <NEWLINE> <UNTAB> return Rational ( ngcd , dlcm ) , self . _new_rawargs ( * terms ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def extract_jpeg_shape ( contents , output_type = _dtypes . int32 , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if output_type is None : <NEWLINE> <TAB> output_type = _dtypes . int32 <NEWLINE> <UNTAB> output_type = _execute . make_type ( output_type , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , contents = contents , output_type = output_type , <NEWLINE> name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , contents , <NEWLINE> <STRING> , output_type ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return extract_jpeg_shape_eager_fallback ( <NEWLINE> contents , output_type = output_type , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , histogram , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> self . _histogram = histogram <NEWLINE> if len ( histogram ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> self . _hpdf = np . asarray ( histogram [ <NUMBER> ] ) <NEWLINE> self . _hbins = np . asarray ( histogram [ <NUMBER> ] ) <NEWLINE> if len ( self . _hpdf ) + <NUMBER> != len ( self . _hbins ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> self . _hbin_widths = self . _hbins [ <NUMBER> : ] - self . _hbins [ : - <NUMBER> ] <NEWLINE> self . _hpdf = self . _hpdf / float ( np . sum ( self . _hpdf * self . _hbin_widths ) ) <NEWLINE> self . _hcdf = np . cumsum ( self . _hpdf * self . _hbin_widths ) <NEWLINE> self . _hpdf = np . hstack ( [ <NUMBER> , self . _hpdf , <NUMBER> ] ) <NEWLINE> self . _hcdf = np . hstack ( [ <NUMBER> , self . _hcdf ] ) <NEWLINE> <NEWLINE> kwargs [ <STRING> ] = self . _hbins [ <NUMBER> ] <NEWLINE> kwargs [ <STRING> ] = self . _hbins [ - <NUMBER> ] <NEWLINE> super ( rv_histogram , self ) . __init__ ( * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _cast_types ( self , values , cast_type , column ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if is_categorical_dtype ( cast_type ) : <NEWLINE> <TAB> known_cats = ( isinstance ( cast_type , CategoricalDtype ) and <NEWLINE> cast_type . categories is not None ) <NEWLINE> <NEWLINE> if not is_object_dtype ( values ) and not known_cats : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> values = astype_nansafe ( values , str ) <NEWLINE> <NEWLINE> <UNTAB> cats = Index ( values ) . unique ( ) . dropna ( ) <NEWLINE> values = Categorical . _from_inferred_categories ( <NEWLINE> cats , cats . get_indexer ( values ) , cast_type <NEWLINE> ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> values = astype_nansafe ( values , cast_type , copy = True ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % ( column , cast_type ) ) <NEWLINE> <UNTAB> <UNTAB> return values <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_raise ( f , l , u , K ) : <NEWLINE> <TAB> <NEWLINE> if not l : <NEWLINE> <TAB> return f <NEWLINE> <NEWLINE> <UNTAB> if not u : <NEWLINE> <TAB> if not f : <NEWLINE> <TAB> return dmp_zero ( l ) <NEWLINE> <NEWLINE> <UNTAB> k = l - <NUMBER> <NEWLINE> <NEWLINE> return [ dmp_ground ( c , k ) for c in f ] <NEWLINE> <NEWLINE> <UNTAB> v = u - <NUMBER> <NEWLINE> <NEWLINE> return [ dmp_raise ( c , l , v , K ) for c in f ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def getitem_block ( self , slicer , new_mgr_locs = None ) : <NEWLINE> <TAB> <NEWLINE> if new_mgr_locs is None : <NEWLINE> <TAB> if isinstance ( slicer , tuple ) : <NEWLINE> <TAB> axis0_slicer = slicer [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> axis0_slicer = slicer <NEWLINE> <UNTAB> new_mgr_locs = self . mgr_locs [ axis0_slicer ] <NEWLINE> <NEWLINE> <UNTAB> new_values = self . _slice ( slicer ) <NEWLINE> <NEWLINE> if self . _validate_ndim and new_values . ndim != self . ndim : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return self . make_block_same_class ( new_values , new_mgr_locs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def checkout ( self , dbapi_connection , connection_record , connection_proxy ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def last_inserted_params ( self ) : <NEWLINE> <TAB> <NEWLINE> if not self . context . compiled : <NEWLINE> <TAB> raise exc . InvalidRequestError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> elif not self . context . isinsert : <NEWLINE> <TAB> raise exc . InvalidRequestError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> elif self . context . executemany : <NEWLINE> <TAB> return self . context . compiled_parameters <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . context . compiled_parameters [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _broadcast_shape ( shapes ) : <NEWLINE> <TAB> <NEWLINE> shape = torch . Size ( ) <NEWLINE> for s in shapes : <NEWLINE> <TAB> shape = torch . _C . _infer_size ( s , shape ) <NEWLINE> <UNTAB> return shape <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dedent ( text ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> margin = None <NEWLINE> text = _whitespace_only_re . sub ( <STRING> , text ) <NEWLINE> indents = _leading_whitespace_re . findall ( text ) <NEWLINE> for indent in indents : <NEWLINE> <TAB> if margin is None : <NEWLINE> <TAB> margin = indent <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif indent . startswith ( margin ) : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif margin . startswith ( indent ) : <NEWLINE> <TAB> margin = indent <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for i , ( x , y ) in enumerate ( zip ( margin , indent ) ) : <NEWLINE> <TAB> if x != y : <NEWLINE> <TAB> margin = margin [ : i ] <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> margin = margin [ : len ( indent ) ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if <NUMBER> and margin : <NEWLINE> <TAB> for line in text . split ( <STRING> ) : <NEWLINE> <TAB> assert not line or line . startswith ( margin ) , <STRING> % ( line , margin ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if margin : <NEWLINE> <TAB> text = re . sub ( <STRING> + margin , <STRING> , text ) <NEWLINE> <UNTAB> return text <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _fft_out_chunks ( a , s , axes ) : <NEWLINE> <TAB> <NEWLINE> if s is None : <NEWLINE> <TAB> return a . chunks <NEWLINE> <UNTAB> chunks = list ( a . chunks ) <NEWLINE> for i , axis in enumerate ( axes ) : <NEWLINE> <TAB> chunks [ axis ] = ( s [ i ] , ) <NEWLINE> <UNTAB> return chunks <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def expandtabs ( a , tabsize = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return _to_string_or_unicode_array ( <NEWLINE> _vec_string ( a , object_ , <STRING> , ( tabsize , ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _skip_ticks ( self , labels , tickevery ) : <NEWLINE> <TAB> <NEWLINE> n = len ( labels ) <NEWLINE> if tickevery == <NUMBER> : <NEWLINE> <TAB> ticks , labels = [ ] , [ ] <NEWLINE> <UNTAB> elif tickevery == <NUMBER> : <NEWLINE> <TAB> ticks , labels = np . arange ( n ) + <NUMBER> , labels <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> start , end , step = <NUMBER> , n , tickevery <NEWLINE> ticks = np . arange ( start , end , step ) + <NUMBER> <NEWLINE> labels = labels [ start : end : step ] <NEWLINE> <UNTAB> return ticks , labels <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def lower ( a ) : <NEWLINE> <TAB> <NEWLINE> a_arr = numpy . asarray ( a ) <NEWLINE> return _vec_string ( a_arr , a_arr . dtype , <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_data_files ( self , * files ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if len ( files ) > <NUMBER> : <NEWLINE> <TAB> for f in files : <NEWLINE> <TAB> self . add_data_files ( f ) <NEWLINE> <UNTAB> return <NEWLINE> <UNTAB> assert len ( files ) == <NUMBER> <NEWLINE> if is_sequence ( files [ <NUMBER> ] ) : <NEWLINE> <TAB> d , files = files [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> d = None <NEWLINE> <UNTAB> if is_string ( files ) : <NEWLINE> <TAB> filepat = files <NEWLINE> <UNTAB> elif is_sequence ( files ) : <NEWLINE> <TAB> if len ( files ) == <NUMBER> : <NEWLINE> <TAB> filepat = files [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for f in files : <NEWLINE> <TAB> self . add_data_files ( ( d , f ) ) <NEWLINE> <UNTAB> return <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( repr ( type ( files ) ) ) <NEWLINE> <NEWLINE> <UNTAB> if d is None : <NEWLINE> <TAB> if hasattr ( filepat , <STRING> ) : <NEWLINE> <TAB> d = <STRING> <NEWLINE> <UNTAB> elif os . path . isabs ( filepat ) : <NEWLINE> <TAB> d = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> d = os . path . dirname ( filepat ) <NEWLINE> <UNTAB> self . add_data_files ( ( d , files ) ) <NEWLINE> return <NEWLINE> <NEWLINE> <UNTAB> paths = self . paths ( filepat , include_non_existing = False ) <NEWLINE> if is_glob_pattern ( filepat ) : <NEWLINE> <TAB> if is_glob_pattern ( d ) : <NEWLINE> <TAB> pattern_list = d . split ( os . sep ) <NEWLINE> pattern_list . reverse ( ) <NEWLINE> for path in paths : <NEWLINE> <TAB> path_list = path . split ( os . sep ) <NEWLINE> path_list . reverse ( ) <NEWLINE> path_list . pop ( ) <NEWLINE> target_list = [ ] <NEWLINE> i = <NUMBER> <NEWLINE> for s in pattern_list : <NEWLINE> <TAB> if is_glob_pattern ( s ) : <NEWLINE> <TAB> target_list . append ( path_list [ i ] ) <NEWLINE> i += <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> target_list . append ( s ) <NEWLINE> <UNTAB> <UNTAB> target_list . reverse ( ) <NEWLINE> self . add_data_files ( ( os . sep . join ( target_list ) , path ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> self . add_data_files ( ( d , paths ) ) <NEWLINE> <UNTAB> return <NEWLINE> <UNTAB> assert not is_glob_pattern ( d ) , repr ( ( d , filepat ) ) <NEWLINE> <NEWLINE> dist = self . get_distribution ( ) <NEWLINE> if dist is not None and dist . data_files is not None : <NEWLINE> <TAB> data_files = dist . data_files <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> data_files = self . data_files <NEWLINE> <NEWLINE> <UNTAB> data_files . append ( ( os . path . join ( self . path_in_package , d ) , paths ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def compress_csr ( self ) : <NEWLINE> <TAB> <NEWLINE> _ , unique , indices = np . unique ( <NEWLINE> self . m * self . rows + self . cols , <NEWLINE> return_index = True , return_inverse = True ) <NEWLINE> self . rows = self . rows [ unique ] <NEWLINE> self . cols = self . cols [ unique ] <NEWLINE> self . vals = np . bincount ( indices , weights = self . vals ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _compute_mi_cc ( x , y , n_neighbors ) : <NEWLINE> <TAB> <NEWLINE> n_samples = x . size <NEWLINE> <NEWLINE> x = x . reshape ( ( - <NUMBER> , <NUMBER> ) ) <NEWLINE> y = y . reshape ( ( - <NUMBER> , <NUMBER> ) ) <NEWLINE> xy = np . hstack ( ( x , y ) ) <NEWLINE> <NEWLINE> <NEWLINE> nn = NearestNeighbors ( metric = <STRING> , n_neighbors = n_neighbors ) <NEWLINE> <NEWLINE> nn . fit ( xy ) <NEWLINE> radius = nn . kneighbors ( ) [ <NUMBER> ] <NEWLINE> radius = np . nextafter ( radius [ : , - <NUMBER> ] , <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> nn . set_params ( algorithm = <STRING> ) <NEWLINE> <NEWLINE> nn . fit ( x ) <NEWLINE> ind = nn . radius_neighbors ( radius = radius , return_distance = False ) <NEWLINE> nx = np . array ( [ i . size for i in ind ] ) <NEWLINE> <NEWLINE> nn . fit ( y ) <NEWLINE> ind = nn . radius_neighbors ( radius = radius , return_distance = False ) <NEWLINE> ny = np . array ( [ i . size for i in ind ] ) <NEWLINE> <NEWLINE> mi = ( digamma ( n_samples ) + digamma ( n_neighbors ) - <NEWLINE> np . mean ( digamma ( nx + <NUMBER> ) ) - np . mean ( digamma ( ny + <NUMBER> ) ) ) <NEWLINE> <NEWLINE> return max ( <NUMBER> , mi ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def quantized_mat_mul ( a , b , min_a , max_a , min_b , max_b , Toutput = _dtypes . qint32 , transpose_a = False , transpose_b = False , Tactivation = _dtypes . quint8 , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if Toutput is None : <NEWLINE> <TAB> Toutput = _dtypes . qint32 <NEWLINE> <UNTAB> Toutput = _execute . make_type ( Toutput , <STRING> ) <NEWLINE> if transpose_a is None : <NEWLINE> <TAB> transpose_a = False <NEWLINE> <UNTAB> transpose_a = _execute . make_bool ( transpose_a , <STRING> ) <NEWLINE> if transpose_b is None : <NEWLINE> <TAB> transpose_b = False <NEWLINE> <UNTAB> transpose_b = _execute . make_bool ( transpose_b , <STRING> ) <NEWLINE> if Tactivation is None : <NEWLINE> <TAB> Tactivation = _dtypes . quint8 <NEWLINE> <UNTAB> Tactivation = _execute . make_type ( Tactivation , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , a = a , b = b , min_a = min_a , max_a = max_a , min_b = min_b , <NEWLINE> max_b = max_b , Toutput = Toutput , transpose_a = transpose_a , <NEWLINE> transpose_b = transpose_b , Tactivation = Tactivation , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result = _QuantizedMatMulOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , a , b , min_a , <NEWLINE> max_a , min_b , max_b , <STRING> , Toutput , <STRING> , transpose_a , <NEWLINE> <STRING> , transpose_b , <STRING> , Tactivation ) <NEWLINE> _result = _QuantizedMatMulOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return quantized_mat_mul_eager_fallback ( <NEWLINE> a , b , min_a , max_a , min_b , max_b , Toutput = Toutput , <NEWLINE> transpose_a = transpose_a , transpose_b = transpose_b , <NEWLINE> Tactivation = Tactivation , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def insert ( self , loc , item ) : <NEWLINE> <TAB> <NEWLINE> if is_scalar ( item ) and isna ( item ) : <NEWLINE> <NEWLINE> <TAB> item = self . _na_value <NEWLINE> <NEWLINE> <UNTAB> _self = np . asarray ( self ) <NEWLINE> item = self . _coerce_scalar_to_index ( item ) . _ndarray_values <NEWLINE> idx = np . concatenate ( ( _self [ : loc ] , item , _self [ loc : ] ) ) <NEWLINE> return self . _shallow_copy_with_infer ( idx ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , dtypes , shapes , names , queue_ref ) : <NEWLINE> <TAB> <NEWLINE> self . _dtypes = dtypes <NEWLINE> if shapes is not None : <NEWLINE> <TAB> if len ( shapes ) != len ( dtypes ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> self . _shapes = [ tensor_shape . TensorShape ( s ) for s in shapes ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _shapes = [ tensor_shape . unknown_shape ( ) for _ in self . _dtypes ] <NEWLINE> <UNTAB> if names is not None : <NEWLINE> <TAB> if len ( names ) != len ( dtypes ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> self . _names = names <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _names = None <NEWLINE> <UNTAB> self . _queue_ref = queue_ref <NEWLINE> if context . executing_eagerly ( ) : <NEWLINE> <TAB> self . _name = context . context ( ) . scope_name <NEWLINE> self . _resource_deleter = resource_variable_ops . EagerResourceDeleter ( <NEWLINE> queue_ref , None ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _name = self . _queue_ref . op . name . split ( <STRING> ) [ - <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def crf_decode ( potentials , transition_params , sequence_length ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> def _single_seq_fn ( ) : <NEWLINE> <TAB> squeezed_potentials = array_ops . squeeze ( potentials , [ <NUMBER> ] ) <NEWLINE> decode_tags = array_ops . expand_dims ( <NEWLINE> math_ops . argmax ( squeezed_potentials , axis = <NUMBER> ) , <NUMBER> ) <NEWLINE> best_score = math_ops . reduce_max ( squeezed_potentials , axis = <NUMBER> ) <NEWLINE> return math_ops . cast ( decode_tags , dtype = dtypes . int32 ) , best_score <NEWLINE> <NEWLINE> <UNTAB> def _multi_seq_fn ( ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> num_tags = tensor_shape . dimension_value ( potentials . shape [ <NUMBER> ] ) <NEWLINE> <NEWLINE> <NEWLINE> crf_fwd_cell = CrfDecodeForwardRnnCell ( transition_params ) <NEWLINE> initial_state = array_ops . slice ( potentials , [ <NUMBER> , <NUMBER> , <NUMBER> ] , [ - <NUMBER> , <NUMBER> , - <NUMBER> ] ) <NEWLINE> initial_state = array_ops . squeeze ( initial_state , axis = [ <NUMBER> ] ) <NEWLINE> inputs = array_ops . slice ( potentials , [ <NUMBER> , <NUMBER> , <NUMBER> ] , [ - <NUMBER> , - <NUMBER> , - <NUMBER> ] ) <NEWLINE> <NEWLINE> sequence_length_less_one = math_ops . maximum ( <NEWLINE> constant_op . constant ( <NUMBER> , dtype = sequence_length . dtype ) , <NEWLINE> sequence_length - <NUMBER> ) <NEWLINE> backpointers , last_score = rnn . dynamic_rnn ( <NEWLINE> crf_fwd_cell , <NEWLINE> inputs = inputs , <NEWLINE> sequence_length = sequence_length_less_one , <NEWLINE> initial_state = initial_state , <NEWLINE> time_major = False , <NEWLINE> dtype = dtypes . int32 ) <NEWLINE> backpointers = gen_array_ops . reverse_sequence ( <NEWLINE> backpointers , sequence_length_less_one , seq_dim = <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> crf_bwd_cell = CrfDecodeBackwardRnnCell ( num_tags ) <NEWLINE> initial_state = math_ops . cast ( math_ops . argmax ( last_score , axis = <NUMBER> ) , <NEWLINE> dtype = dtypes . int32 ) <NEWLINE> initial_state = array_ops . expand_dims ( initial_state , axis = - <NUMBER> ) <NEWLINE> decode_tags , _ = rnn . dynamic_rnn ( <NEWLINE> crf_bwd_cell , <NEWLINE> inputs = backpointers , <NEWLINE> sequence_length = sequence_length_less_one , <NEWLINE> initial_state = initial_state , <NEWLINE> time_major = False , <NEWLINE> dtype = dtypes . int32 ) <NEWLINE> decode_tags = array_ops . squeeze ( decode_tags , axis = [ <NUMBER> ] ) <NEWLINE> decode_tags = array_ops . concat ( [ initial_state , decode_tags ] , <NEWLINE> axis = <NUMBER> ) <NEWLINE> decode_tags = gen_array_ops . reverse_sequence ( <NEWLINE> decode_tags , sequence_length , seq_dim = <NUMBER> ) <NEWLINE> <NEWLINE> best_score = math_ops . reduce_max ( last_score , axis = <NUMBER> ) <NEWLINE> return decode_tags , best_score <NEWLINE> <NEWLINE> <UNTAB> return utils . smart_cond ( <NEWLINE> pred = math_ops . equal ( tensor_shape . dimension_value ( potentials . shape [ <NUMBER> ] ) or <NEWLINE> array_ops . shape ( potentials ) [ <NUMBER> ] , <NUMBER> ) , <NEWLINE> true_fn = _single_seq_fn , <NEWLINE> false_fn = _multi_seq_fn ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _clean_nans ( scores ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> scores = as_float_array ( scores , copy = True ) <NEWLINE> scores [ np . isnan ( scores ) ] = np . finfo ( scores . dtype ) . min <NEWLINE> return scores <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> def common_neighbors ( G , u , v ) : <NEWLINE> <TAB> <NEWLINE> if u not in G : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <UNTAB> if v not in G : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return ( w for w in G [ u ] if w in G [ v ] and w not in ( u , v ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _maybe_update_attributes ( self , attrs ) : <NEWLINE> <TAB> <NEWLINE> freq = attrs . get ( <STRING> , None ) <NEWLINE> if freq is not None : <NEWLINE> <NEWLINE> <TAB> attrs [ <STRING> ] = <STRING> <NEWLINE> <UNTAB> return attrs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_extent ( self , renderer ) : <NEWLINE> <TAB> <NEWLINE> w , h , xd , yd = self . get_child ( ) . get_extent ( renderer ) <NEWLINE> fontsize = renderer . points_to_pixels ( self . prop . get_size_in_points ( ) ) <NEWLINE> pad = self . pad * fontsize <NEWLINE> <NEWLINE> return w + <NUMBER> * pad , h + <NUMBER> * pad , xd + pad , yd + pad <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _handle_irel ( self , x , handler ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> rel = self . atoms ( Relational ) <NEWLINE> irel = list ( ordered ( [ r for r in rel if x not in r . free_symbols <NEWLINE> and r not in ( S . true , S . false ) ] ) ) <NEWLINE> if irel : <NEWLINE> <TAB> args = { } <NEWLINE> exprinorder = [ ] <NEWLINE> for truth in product ( ( <NUMBER> , <NUMBER> ) , repeat = len ( irel ) ) : <NEWLINE> <TAB> reps = dict ( zip ( irel , truth ) ) <NEWLINE> <NEWLINE> <NEWLINE> if <NUMBER> not in truth : <NEWLINE> <TAB> cond = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> andargs = Tuple ( * [ i for i in reps if reps [ i ] ] ) <NEWLINE> free = list ( andargs . free_symbols ) <NEWLINE> if len ( free ) == <NUMBER> : <NEWLINE> <TAB> from sympy . solvers . inequalities import ( <NEWLINE> reduce_inequalities , _solve_inequality ) <NEWLINE> try : <NEWLINE> <TAB> t = reduce_inequalities ( andargs , free [ <NUMBER> ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> except ( ValueError , NotImplementedError ) : <NEWLINE> <NEWLINE> <TAB> t = And ( * [ _solve_inequality ( <NEWLINE> a , free [ <NUMBER> ] , linear = True ) <NEWLINE> for a in andargs ] ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> t = And ( * andargs ) <NEWLINE> <UNTAB> if t is S . false : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> cond = t <NEWLINE> <UNTAB> expr = handler ( self . xreplace ( reps ) ) <NEWLINE> if isinstance ( expr , self . func ) and len ( expr . args ) == <NUMBER> : <NEWLINE> <TAB> expr , econd = expr . args [ <NUMBER> ] <NEWLINE> cond = And ( econd , True if cond is None else cond ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if cond is not None : <NEWLINE> <TAB> args . setdefault ( expr , [ ] ) . append ( cond ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> exprinorder . append ( expr ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for k in args : <NEWLINE> <TAB> args [ k ] = Or ( * args [ k ] ) <NEWLINE> <NEWLINE> <UNTAB> args = [ ( e , args [ e ] ) for e in uniq ( exprinorder ) ] <NEWLINE> <NEWLINE> args . append ( ( expr , True ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> trues = [ i for i in range ( len ( args ) ) if args [ i ] [ <NUMBER> ] is S . true ] <NEWLINE> if not trues : <NEWLINE> <NEWLINE> <TAB> e , c = args [ - <NUMBER> ] <NEWLINE> args [ - <NUMBER> ] = ( e , S . true ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> assert len ( set ( [ e for e , c in [ args [ i ] for i in trues ] ] ) ) == <NUMBER> <NEWLINE> args . append ( args . pop ( trues . pop ( ) ) ) <NEWLINE> while trues : <NEWLINE> <TAB> args . pop ( trues . pop ( ) ) <NEWLINE> <UNTAB> <UNTAB> return Piecewise ( * args ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_function_derivatives ( self , alpha , J , ecc , dofs ) : <NEWLINE> <TAB> <NEWLINE> subtri = np . argmin ( alpha , axis = <NUMBER> ) [ : , <NUMBER> ] <NEWLINE> ksi = _roll_vectorized ( alpha , - subtri , axis = <NUMBER> ) <NEWLINE> E = _roll_vectorized ( ecc , - subtri , axis = <NUMBER> ) <NEWLINE> x = ksi [ : , <NUMBER> , <NUMBER> ] <NEWLINE> y = ksi [ : , <NUMBER> , <NUMBER> ] <NEWLINE> z = ksi [ : , <NUMBER> , <NUMBER> ] <NEWLINE> x_sq = x * x <NEWLINE> y_sq = y * y <NEWLINE> z_sq = z * z <NEWLINE> dV = _to_matrix_vectorized ( [ <NEWLINE> [ - <NUMBER> * x_sq , - <NUMBER> * x_sq ] , <NEWLINE> [ <NUMBER> * y_sq , <NUMBER> ] , <NEWLINE> [ <NUMBER> , <NUMBER> * z_sq ] , <NEWLINE> [ - <NUMBER> * x * z , - <NUMBER> * x * z + x_sq ] , <NEWLINE> [ - <NUMBER> * x * y + x_sq , - <NUMBER> * x * y ] , <NEWLINE> [ <NUMBER> * x * y - y_sq , - y_sq ] , <NEWLINE> [ <NUMBER> * y * z , y_sq ] , <NEWLINE> [ z_sq , <NUMBER> * y * z ] , <NEWLINE> [ - z_sq , <NUMBER> * x * z - z_sq ] , <NEWLINE> [ x * z - y * z , x * y - y * z ] ] ) <NEWLINE> <NEWLINE> dV = _prod_vectorized ( dV , _extract_submatrices ( <NEWLINE> self . rotate_dV , subtri , block_size = <NUMBER> , axis = <NUMBER> ) ) <NEWLINE> <NEWLINE> prod = _prod_vectorized ( self . M , dV ) <NEWLINE> prod += _scalar_vectorized ( E [ : , <NUMBER> , <NUMBER> ] , <NEWLINE> _prod_vectorized ( self . M0 , dV ) ) <NEWLINE> prod += _scalar_vectorized ( E [ : , <NUMBER> , <NUMBER> ] , <NEWLINE> _prod_vectorized ( self . M1 , dV ) ) <NEWLINE> prod += _scalar_vectorized ( E [ : , <NUMBER> , <NUMBER> ] , <NEWLINE> _prod_vectorized ( self . M2 , dV ) ) <NEWLINE> dsdksi = _roll_vectorized ( prod , <NUMBER> * subtri , axis = <NUMBER> ) <NEWLINE> dfdksi = _prod_vectorized ( dofs , dsdksi ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> J_inv = _safe_inv22_vectorized ( J ) <NEWLINE> dfdx = _prod_vectorized ( J_inv , _transpose_vectorized ( dfdksi ) ) <NEWLINE> return dfdx <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def telescopic_direct ( L , R , n , limits ) : <NEWLINE> <TAB> <NEWLINE> ( i , a , b ) = limits <NEWLINE> s = <NUMBER> <NEWLINE> for m in range ( n ) : <NEWLINE> <TAB> s += L . subs ( i , a + m ) + R . subs ( i , b - m ) <NEWLINE> <UNTAB> return s <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def mul ( x , y , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , x = x , y = y , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , x , y ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return mul_eager_fallback ( <NEWLINE> x , y , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecation . deprecated ( None , <NEWLINE> <STRING> ) <NEWLINE> def choose_from_datasets ( datasets , choice_dataset ) : <NEWLINE> <TAB> <NEWLINE> return interleave_ops . choose_from_datasets ( datasets , choice_dataset ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_floating_dtype ( arr_or_dtype ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if arr_or_dtype is None : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> tipo = _get_dtype_type ( arr_or_dtype ) <NEWLINE> return isinstance ( tipo , np . floating ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def toarray ( self , order = None , out = None ) : <NEWLINE> <TAB> <NEWLINE> B = self . _process_toarray_args ( order , out ) <NEWLINE> fortran = int ( B . flags . f_contiguous ) <NEWLINE> if not fortran and not B . flags . c_contiguous : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> M , N = self . shape <NEWLINE> coo_todense ( M , N , self . nnz , self . row , self . col , self . data , <NEWLINE> B . ravel ( <STRING> ) , fortran ) <NEWLINE> return B <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _merge_batch_beams ( self , t , s = None ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( s , ops . Tensor ) : <NEWLINE> <TAB> s = tensor_shape . as_shape ( tensor_util . constant_value ( s ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> s = tensor_shape . TensorShape ( s ) <NEWLINE> <UNTAB> t_shape = array_ops . shape ( t ) <NEWLINE> static_batch_size = tensor_util . constant_value ( self . _batch_size ) <NEWLINE> batch_size_beam_width = ( <NEWLINE> None <NEWLINE> if static_batch_size is None else static_batch_size * self . _beam_width ) <NEWLINE> reshaped_t = array_ops . reshape ( <NEWLINE> t , <NEWLINE> array_ops . concat ( ( [ self . _batch_size * self . _beam_width ] , t_shape [ <NUMBER> : ] ) , <NEWLINE> <NUMBER> ) ) <NEWLINE> reshaped_t . set_shape ( <NEWLINE> ( tensor_shape . TensorShape ( [ batch_size_beam_width ] ) . concatenate ( s ) ) ) <NEWLINE> return reshaped_t <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_compatible_with ( self , other ) : <NEWLINE> <TAB> <NEWLINE> other = as_shape ( other ) <NEWLINE> if self . _dims is not None and other . dims is not None : <NEWLINE> <TAB> if self . rank != other . rank : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> for x_dim , y_dim in zip ( self . _dims , other . dims ) : <NEWLINE> <TAB> if not x_dim . is_compatible_with ( y_dim ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def bottomhat ( image , selem , out = None , mask = None , shift_x = False , shift_y = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return _apply_scalar_per_pixel ( generic_cy . _bottomhat , image , selem , <NEWLINE> out = out , mask = mask , <NEWLINE> shift_x = shift_x , shift_y = shift_y ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _zseries_mul ( z1 , z2 ) : <NEWLINE> <TAB> <NEWLINE> return np . convolve ( z1 , z2 ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def node_connectivity ( G , s = None , t = None , flow_func = None ) : <NEWLINE> <TAB> <NEWLINE> if ( s is not None and t is None ) or ( s is None and t is not None ) : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if s is not None and t is not None : <NEWLINE> <TAB> if s not in G : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> % s ) <NEWLINE> <UNTAB> if t not in G : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> % t ) <NEWLINE> <UNTAB> return local_node_connectivity ( G , s , t , flow_func = flow_func ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if G . is_directed ( ) : <NEWLINE> <TAB> if not nx . is_weakly_connected ( G ) : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> iter_func = itertools . permutations <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> def neighbors ( v ) : <NEWLINE> <TAB> return itertools . chain . from_iterable ( [ G . predecessors ( v ) , <NEWLINE> G . successors ( v ) ] ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if not nx . is_connected ( G ) : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> iter_func = itertools . combinations <NEWLINE> neighbors = G . neighbors <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> H = build_auxiliary_node_connectivity ( G ) <NEWLINE> R = build_residual_network ( H , <STRING> ) <NEWLINE> kwargs = dict ( flow_func = flow_func , auxiliary = H , residual = R ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> v , K = min ( G . degree ( ) , key = itemgetter ( <NUMBER> ) ) <NEWLINE> <NEWLINE> for w in set ( G ) - set ( neighbors ( v ) ) - set ( [ v ] ) : <NEWLINE> <TAB> kwargs [ <STRING> ] = K <NEWLINE> K = min ( K , local_node_connectivity ( G , v , w , ** kwargs ) ) <NEWLINE> <NEWLINE> <UNTAB> for x , y in iter_func ( neighbors ( v ) , <NUMBER> ) : <NEWLINE> <TAB> if y in G [ x ] : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> kwargs [ <STRING> ] = K <NEWLINE> K = min ( K , local_node_connectivity ( G , x , y , ** kwargs ) ) <NEWLINE> <NEWLINE> <UNTAB> return K <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def reset_ticks ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> del self . majorTicks <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> del self . minorTicks <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> self . set_clip_path ( self . axes . patch ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def assert_almost_equal ( actual , desired , decimal = <NUMBER> , err_msg = <STRING> , verbose = True ) : <NEWLINE> <TAB> <NEWLINE> __tracebackhide__ = True <NEWLINE> from numpy . core import ndarray <NEWLINE> from numpy . lib import iscomplexobj , real , imag <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> usecomplex = iscomplexobj ( actual ) or iscomplexobj ( desired ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> usecomplex = False <NEWLINE> <NEWLINE> <UNTAB> def _build_err_msg ( ) : <NEWLINE> <TAB> header = ( <STRING> % decimal ) <NEWLINE> return build_err_msg ( [ actual , desired ] , err_msg , verbose = verbose , <NEWLINE> header = header ) <NEWLINE> <NEWLINE> <UNTAB> if usecomplex : <NEWLINE> <TAB> if iscomplexobj ( actual ) : <NEWLINE> <TAB> actualr = real ( actual ) <NEWLINE> actuali = imag ( actual ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> actualr = actual <NEWLINE> actuali = <NUMBER> <NEWLINE> <UNTAB> if iscomplexobj ( desired ) : <NEWLINE> <TAB> desiredr = real ( desired ) <NEWLINE> desiredi = imag ( desired ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> desiredr = desired <NEWLINE> desiredi = <NUMBER> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> assert_almost_equal ( actualr , desiredr , decimal = decimal ) <NEWLINE> assert_almost_equal ( actuali , desiredi , decimal = decimal ) <NEWLINE> <UNTAB> except AssertionError : <NEWLINE> <TAB> raise AssertionError ( _build_err_msg ( ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if isinstance ( actual , ( ndarray , tuple , list ) ) or isinstance ( desired , ( ndarray , tuple , list ) ) : <NEWLINE> <TAB> return assert_array_almost_equal ( actual , desired , decimal , err_msg ) <NEWLINE> <UNTAB> try : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if not ( gisfinite ( desired ) and gisfinite ( actual ) ) : <NEWLINE> <TAB> if gisnan ( desired ) or gisnan ( actual ) : <NEWLINE> <TAB> if not ( gisnan ( desired ) and gisnan ( actual ) ) : <NEWLINE> <TAB> raise AssertionError ( _build_err_msg ( ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if not desired == actual : <NEWLINE> <TAB> raise AssertionError ( _build_err_msg ( ) ) <NEWLINE> <UNTAB> <UNTAB> return <NEWLINE> <UNTAB> <UNTAB> except ( NotImplementedError , TypeError ) : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> if abs ( desired - actual ) >= <NUMBER> * <NUMBER> ** ( - decimal ) : <NEWLINE> <TAB> raise AssertionError ( _build_err_msg ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def derivative ( self , x , der = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> x , x_shape = self . _prepare_x ( x ) <NEWLINE> y = self . _evaluate_derivatives ( x , der + <NUMBER> ) <NEWLINE> return self . _finish_y ( y [ der ] , x_shape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rsolve_poly ( coeffs , f , n , ** hints ) : <NEWLINE> <TAB> <NEWLINE> f = sympify ( f ) <NEWLINE> <NEWLINE> if not f . is_polynomial ( n ) : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> homogeneous = f . is_zero <NEWLINE> <NEWLINE> r = len ( coeffs ) - <NUMBER> <NEWLINE> <NEWLINE> coeffs = [ Poly ( coeff , n ) for coeff in coeffs ] <NEWLINE> <NEWLINE> polys = [ Poly ( <NUMBER> , n ) ] * ( r + <NUMBER> ) <NEWLINE> terms = [ ( S . Zero , S . NegativeInfinity ) ] * ( r + <NUMBER> ) <NEWLINE> <NEWLINE> for i in range ( r + <NUMBER> ) : <NEWLINE> <TAB> for j in range ( i , r + <NUMBER> ) : <NEWLINE> <TAB> polys [ i ] += coeffs [ j ] * binomial ( j , i ) <NEWLINE> <NEWLINE> <UNTAB> if not polys [ i ] . is_zero : <NEWLINE> <TAB> ( exp , ) , coeff = polys [ i ] . LT ( ) <NEWLINE> terms [ i ] = ( coeff , exp ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> d = b = terms [ <NUMBER> ] [ <NUMBER> ] <NEWLINE> <NEWLINE> for i in range ( <NUMBER> , r + <NUMBER> ) : <NEWLINE> <TAB> if terms [ i ] [ <NUMBER> ] > d : <NEWLINE> <TAB> d = terms [ i ] [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> if terms [ i ] [ <NUMBER> ] - i > b : <NEWLINE> <TAB> b = terms [ i ] [ <NUMBER> ] - i <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> d , b = int ( d ) , int ( b ) <NEWLINE> <NEWLINE> x = Dummy ( <STRING> ) <NEWLINE> <NEWLINE> degree_poly = S . Zero <NEWLINE> <NEWLINE> for i in range ( r + <NUMBER> ) : <NEWLINE> <TAB> if terms [ i ] [ <NUMBER> ] - i == b : <NEWLINE> <TAB> degree_poly += terms [ i ] [ <NUMBER> ] * FallingFactorial ( x , i ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> nni_roots = list ( roots ( degree_poly , x , filter = <STRING> , <NEWLINE> predicate = lambda r : r >= <NUMBER> ) . keys ( ) ) <NEWLINE> <NEWLINE> if nni_roots : <NEWLINE> <TAB> N = [ max ( nni_roots ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> N = [ ] <NEWLINE> <NEWLINE> <UNTAB> if homogeneous : <NEWLINE> <TAB> N += [ - b - <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> N += [ f . as_poly ( n ) . degree ( ) - b , - b - <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> N = int ( max ( N ) ) <NEWLINE> <NEWLINE> if N < <NUMBER> : <NEWLINE> <TAB> if homogeneous : <NEWLINE> <TAB> if hints . get ( <STRING> , False ) : <NEWLINE> <TAB> return ( S . Zero , [ ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return S . Zero <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if N <= r : <NEWLINE> <TAB> C = [ ] <NEWLINE> y = E = S . Zero <NEWLINE> <NEWLINE> for i in range ( N + <NUMBER> ) : <NEWLINE> <TAB> C . append ( Symbol ( <STRING> + str ( i ) ) ) <NEWLINE> y += C [ i ] * n ** i <NEWLINE> <NEWLINE> <UNTAB> for i in range ( r + <NUMBER> ) : <NEWLINE> <TAB> E += coeffs [ i ] . as_expr ( ) * y . subs ( n , n + i ) <NEWLINE> <NEWLINE> <UNTAB> solutions = solve_undetermined_coeffs ( E - f , C , n ) <NEWLINE> <NEWLINE> if solutions is not None : <NEWLINE> <TAB> C = [ c for c in C if ( c not in solutions ) ] <NEWLINE> result = y . subs ( solutions ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> A = r <NEWLINE> U = N + A + b + <NUMBER> <NEWLINE> <NEWLINE> nni_roots = list ( roots ( polys [ r ] , filter = <STRING> , <NEWLINE> predicate = lambda r : r >= <NUMBER> ) . keys ( ) ) <NEWLINE> <NEWLINE> if nni_roots != [ ] : <NEWLINE> <TAB> a = max ( nni_roots ) + <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> a = S . Zero <NEWLINE> <NEWLINE> <UNTAB> def _zero_vector ( k ) : <NEWLINE> <TAB> return [ S . Zero ] * k <NEWLINE> <NEWLINE> <UNTAB> def _one_vector ( k ) : <NEWLINE> <TAB> return [ S . One ] * k <NEWLINE> <NEWLINE> <UNTAB> def _delta ( p , k ) : <NEWLINE> <TAB> B = S . One <NEWLINE> D = p . subs ( n , a + k ) <NEWLINE> <NEWLINE> for i in range ( <NUMBER> , k + <NUMBER> ) : <NEWLINE> <TAB> B *= - Rational ( k - i + <NUMBER> , i ) <NEWLINE> D += B * p . subs ( n , a + k - i ) <NEWLINE> <NEWLINE> <UNTAB> return D <NEWLINE> <NEWLINE> <UNTAB> alpha = { } <NEWLINE> <NEWLINE> for i in range ( - A , d + <NUMBER> ) : <NEWLINE> <TAB> I = _one_vector ( d + <NUMBER> ) <NEWLINE> <NEWLINE> for k in range ( <NUMBER> , d + <NUMBER> ) : <NEWLINE> <TAB> I [ k ] = I [ k - <NUMBER> ] * ( x + i - k + <NUMBER> ) / k <NEWLINE> <NEWLINE> <UNTAB> alpha [ i ] = S . Zero <NEWLINE> <NEWLINE> for j in range ( A + <NUMBER> ) : <NEWLINE> <TAB> for k in range ( d + <NUMBER> ) : <NEWLINE> <TAB> B = binomial ( k , i + j ) <NEWLINE> D = _delta ( polys [ j ] . as_expr ( ) , k ) <NEWLINE> <NEWLINE> alpha [ i ] += I [ k ] * B * D <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> V = Matrix ( U , A , lambda i , j : int ( i == j ) ) <NEWLINE> <NEWLINE> if homogeneous : <NEWLINE> <TAB> for i in range ( A , U ) : <NEWLINE> <TAB> v = _zero_vector ( A ) <NEWLINE> <NEWLINE> for k in range ( <NUMBER> , A + b + <NUMBER> ) : <NEWLINE> <TAB> if i - k < <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <UNTAB> B = alpha [ k - A ] . subs ( x , i - k ) <NEWLINE> <NEWLINE> for j in range ( A ) : <NEWLINE> <TAB> v [ j ] += B * V [ i - k , j ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> denom = alpha [ - A ] . subs ( x , i ) <NEWLINE> <NEWLINE> for j in range ( A ) : <NEWLINE> <TAB> V [ i , j ] = - v [ j ] / denom <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> G = _zero_vector ( U ) <NEWLINE> <NEWLINE> for i in range ( A , U ) : <NEWLINE> <TAB> v = _zero_vector ( A ) <NEWLINE> g = S . Zero <NEWLINE> <NEWLINE> for k in range ( <NUMBER> , A + b + <NUMBER> ) : <NEWLINE> <TAB> if i - k < <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <UNTAB> B = alpha [ k - A ] . subs ( x , i - k ) <NEWLINE> <NEWLINE> for j in range ( A ) : <NEWLINE> <TAB> v [ j ] += B * V [ i - k , j ] <NEWLINE> <NEWLINE> <UNTAB> g += B * G [ i - k ] <NEWLINE> <NEWLINE> <UNTAB> denom = alpha [ - A ] . subs ( x , i ) <NEWLINE> <NEWLINE> for j in range ( A ) : <NEWLINE> <TAB> V [ i , j ] = - v [ j ] / denom <NEWLINE> <NEWLINE> <UNTAB> G [ i ] = ( _delta ( f , i - A ) - g ) / denom <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> P , Q = _one_vector ( U ) , _zero_vector ( A ) <NEWLINE> <NEWLINE> for i in range ( <NUMBER> , U ) : <NEWLINE> <TAB> P [ i ] = ( P [ i - <NUMBER> ] * ( n - a - i + <NUMBER> ) / i ) . expand ( ) <NEWLINE> <NEWLINE> <UNTAB> for i in range ( A ) : <NEWLINE> <TAB> Q [ i ] = Add ( * [ ( v * p ) . expand ( ) for v , p in zip ( V [ : , i ] , P ) ] ) <NEWLINE> <NEWLINE> <UNTAB> if not homogeneous : <NEWLINE> <TAB> h = Add ( * [ ( g * p ) . expand ( ) for g , p in zip ( G , P ) ] ) <NEWLINE> <NEWLINE> <UNTAB> C = [ Symbol ( <STRING> + str ( i ) ) for i in range ( A ) ] <NEWLINE> <NEWLINE> g = lambda i : Add ( * [ c * _delta ( q , i ) for c , q in zip ( C , Q ) ] ) <NEWLINE> <NEWLINE> if homogeneous : <NEWLINE> <TAB> E = [ g ( i ) for i in range ( N + <NUMBER> , U ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> E = [ g ( i ) + _delta ( h , i ) for i in range ( N + <NUMBER> , U ) ] <NEWLINE> <NEWLINE> <UNTAB> if E != [ ] : <NEWLINE> <TAB> solutions = solve ( E , * C ) <NEWLINE> <NEWLINE> if not solutions : <NEWLINE> <TAB> if homogeneous : <NEWLINE> <TAB> if hints . get ( <STRING> , False ) : <NEWLINE> <TAB> return ( S . Zero , [ ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return S . Zero <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> solutions = { } <NEWLINE> <NEWLINE> <UNTAB> if homogeneous : <NEWLINE> <TAB> result = S . Zero <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result = h <NEWLINE> <NEWLINE> <UNTAB> for c , q in list ( zip ( C , Q ) ) : <NEWLINE> <TAB> if c in solutions : <NEWLINE> <TAB> s = solutions [ c ] * q <NEWLINE> C . remove ( c ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> s = c * q <NEWLINE> <NEWLINE> <UNTAB> result += s . expand ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if hints . get ( <STRING> , False ) : <NEWLINE> <TAB> return ( result , C ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_true_LT ( f , u , K ) : <NEWLINE> <TAB> <NEWLINE> monom = [ ] <NEWLINE> <NEWLINE> while u : <NEWLINE> <TAB> monom . append ( len ( f ) - <NUMBER> ) <NEWLINE> f , u = f [ <NUMBER> ] , u - <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> if not f : <NEWLINE> <TAB> monom . append ( <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> monom . append ( len ( f ) - <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> return tuple ( monom ) , dup_LC ( f , K ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def boykov_kolmogorov_impl ( G , s , t , capacity , residual , cutoff ) : <NEWLINE> <TAB> if s not in G : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> % str ( s ) ) <NEWLINE> <UNTAB> if t not in G : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> % str ( t ) ) <NEWLINE> <UNTAB> if s == t : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if residual is None : <NEWLINE> <TAB> R = build_residual_network ( G , capacity ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> R = residual <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for u in R : <NEWLINE> <TAB> for e in R [ u ] . values ( ) : <NEWLINE> <TAB> e [ <STRING> ] = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> INF = R . graph [ <STRING> ] <NEWLINE> <NEWLINE> if cutoff is None : <NEWLINE> <TAB> cutoff = INF <NEWLINE> <NEWLINE> <UNTAB> R_succ = R . succ <NEWLINE> R_pred = R . pred <NEWLINE> <NEWLINE> def grow ( ) : <NEWLINE> <TAB> <NEWLINE> while active : <NEWLINE> <TAB> u = active [ <NUMBER> ] <NEWLINE> if u in source_tree : <NEWLINE> <TAB> this_tree = source_tree <NEWLINE> other_tree = target_tree <NEWLINE> neighbors = R_succ <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> this_tree = target_tree <NEWLINE> other_tree = source_tree <NEWLINE> neighbors = R_pred <NEWLINE> <UNTAB> for v , attr in neighbors [ u ] . items ( ) : <NEWLINE> <TAB> if attr [ <STRING> ] - attr [ <STRING> ] > <NUMBER> : <NEWLINE> <TAB> if v not in this_tree : <NEWLINE> <TAB> if v in other_tree : <NEWLINE> <TAB> return ( u , v ) if this_tree is source_tree else ( v , u ) <NEWLINE> <UNTAB> this_tree [ v ] = u <NEWLINE> dist [ v ] = dist [ u ] + <NUMBER> <NEWLINE> timestamp [ v ] = timestamp [ u ] <NEWLINE> active . append ( v ) <NEWLINE> <UNTAB> elif v in this_tree and _is_closer ( u , v ) : <NEWLINE> <TAB> this_tree [ v ] = u <NEWLINE> dist [ v ] = dist [ u ] + <NUMBER> <NEWLINE> timestamp [ v ] = timestamp [ u ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> _ = active . popleft ( ) <NEWLINE> <UNTAB> return None , None <NEWLINE> <NEWLINE> <UNTAB> def augment ( u , v ) : <NEWLINE> <TAB> <NEWLINE> attr = R_succ [ u ] [ v ] <NEWLINE> flow = min ( INF , attr [ <STRING> ] - attr [ <STRING> ] ) <NEWLINE> path = [ u ] <NEWLINE> <NEWLINE> w = u <NEWLINE> while w != s : <NEWLINE> <TAB> n = w <NEWLINE> w = source_tree [ n ] <NEWLINE> attr = R_pred [ n ] [ w ] <NEWLINE> flow = min ( flow , attr [ <STRING> ] - attr [ <STRING> ] ) <NEWLINE> path . append ( w ) <NEWLINE> <UNTAB> path . reverse ( ) <NEWLINE> <NEWLINE> path . append ( v ) <NEWLINE> w = v <NEWLINE> while w != t : <NEWLINE> <TAB> n = w <NEWLINE> w = target_tree [ n ] <NEWLINE> attr = R_succ [ n ] [ w ] <NEWLINE> flow = min ( flow , attr [ <STRING> ] - attr [ <STRING> ] ) <NEWLINE> path . append ( w ) <NEWLINE> <NEWLINE> <UNTAB> it = iter ( path ) <NEWLINE> u = next ( it ) <NEWLINE> these_orphans = [ ] <NEWLINE> for v in it : <NEWLINE> <TAB> R_succ [ u ] [ v ] [ <STRING> ] += flow <NEWLINE> R_succ [ v ] [ u ] [ <STRING> ] -= flow <NEWLINE> if R_succ [ u ] [ v ] [ <STRING> ] == R_succ [ u ] [ v ] [ <STRING> ] : <NEWLINE> <TAB> if v in source_tree : <NEWLINE> <TAB> source_tree [ v ] = None <NEWLINE> these_orphans . append ( v ) <NEWLINE> <UNTAB> if u in target_tree : <NEWLINE> <TAB> target_tree [ u ] = None <NEWLINE> these_orphans . append ( u ) <NEWLINE> <UNTAB> <UNTAB> u = v <NEWLINE> <UNTAB> orphans . extend ( sorted ( these_orphans , key = dist . get ) ) <NEWLINE> return flow <NEWLINE> <NEWLINE> <UNTAB> def adopt ( ) : <NEWLINE> <TAB> <NEWLINE> while orphans : <NEWLINE> <TAB> u = orphans . popleft ( ) <NEWLINE> if u in source_tree : <NEWLINE> <TAB> tree = source_tree <NEWLINE> neighbors = R_pred <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> tree = target_tree <NEWLINE> neighbors = R_succ <NEWLINE> <UNTAB> nbrs = ( ( n , attr , dist [ n ] ) for n , attr in neighbors [ u ] . items ( ) <NEWLINE> if n in tree ) <NEWLINE> for v , attr , d in sorted ( nbrs , key = itemgetter ( <NUMBER> ) ) : <NEWLINE> <TAB> if attr [ <STRING> ] - attr [ <STRING> ] > <NUMBER> : <NEWLINE> <TAB> if _has_valid_root ( v , tree ) : <NEWLINE> <TAB> tree [ u ] = v <NEWLINE> dist [ u ] = dist [ v ] + <NUMBER> <NEWLINE> timestamp [ u ] = time <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> nbrs = ( ( n , attr , dist [ n ] ) for n , attr in neighbors [ u ] . items ( ) <NEWLINE> if n in tree ) <NEWLINE> for v , attr , d in sorted ( nbrs , key = itemgetter ( <NUMBER> ) ) : <NEWLINE> <TAB> if attr [ <STRING> ] - attr [ <STRING> ] > <NUMBER> : <NEWLINE> <TAB> if v not in active : <NEWLINE> <TAB> active . append ( v ) <NEWLINE> <UNTAB> <UNTAB> if tree [ v ] == u : <NEWLINE> <TAB> tree [ v ] = None <NEWLINE> orphans . appendleft ( v ) <NEWLINE> <UNTAB> <UNTAB> if u in active : <NEWLINE> <TAB> active . remove ( u ) <NEWLINE> <UNTAB> del tree [ u ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> def _has_valid_root ( n , tree ) : <NEWLINE> <TAB> path = [ ] <NEWLINE> v = n <NEWLINE> while v is not None : <NEWLINE> <TAB> path . append ( v ) <NEWLINE> if v == s or v == t : <NEWLINE> <TAB> base_dist = <NUMBER> <NEWLINE> break <NEWLINE> <UNTAB> elif timestamp [ v ] == time : <NEWLINE> <TAB> base_dist = dist [ v ] <NEWLINE> break <NEWLINE> <UNTAB> v = tree [ v ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> length = len ( path ) <NEWLINE> for i , u in enumerate ( path , <NUMBER> ) : <NEWLINE> <TAB> dist [ u ] = base_dist + length - i <NEWLINE> timestamp [ u ] = time <NEWLINE> <UNTAB> return True <NEWLINE> <NEWLINE> <UNTAB> def _is_closer ( u , v ) : <NEWLINE> <TAB> return timestamp [ v ] <= timestamp [ u ] and dist [ v ] > dist [ u ] + <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> source_tree = { s : None } <NEWLINE> target_tree = { t : None } <NEWLINE> active = deque ( [ s , t ] ) <NEWLINE> orphans = deque ( ) <NEWLINE> flow_value = <NUMBER> <NEWLINE> <NEWLINE> time = <NUMBER> <NEWLINE> timestamp = { s : time , t : time } <NEWLINE> dist = { s : <NUMBER> , t : <NUMBER> } <NEWLINE> while flow_value < cutoff : <NEWLINE> <NEWLINE> <TAB> u , v = grow ( ) <NEWLINE> if u is None : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> time += <NUMBER> <NEWLINE> <NEWLINE> flow_value += augment ( u , v ) <NEWLINE> <NEWLINE> adopt ( ) <NEWLINE> <NEWLINE> <UNTAB> if flow_value * <NUMBER> > INF : <NEWLINE> <TAB> raise nx . NetworkXUnbounded ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> R . graph [ <STRING> ] = ( source_tree , target_tree ) <NEWLINE> <NEWLINE> R . graph [ <STRING> ] = flow_value <NEWLINE> return R <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def yn_zeros ( n , nt ) : <NEWLINE> <TAB> <NEWLINE> return jnyn_zeros ( n , nt ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def contains ( self , x , y ) : <NEWLINE> <TAB> <NEWLINE> return self . containsx ( x ) and self . containsy ( y ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( v1 = [ <STRING> ] ) <NEWLINE> def model_variables ( scope = None ) : <NEWLINE> <TAB> <NEWLINE> return ops . get_collection ( ops . GraphKeys . MODEL_VARIABLES , scope ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def cos_eager_fallback ( x , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , ( x , ) = _execute . args_to_matching_eager ( [ x ] , _ctx ) <NEWLINE> _inputs_flat = [ x ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_pinned ( self ) : <NEWLINE> <TAB> <NEWLINE> storage = self . storage ( ) <NEWLINE> return storage . is_pinned ( ) if storage else False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def text_wrap ( text , length = None , indent = <STRING> , firstline_indent = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if length is None : <NEWLINE> <TAB> length = get_help_width ( ) <NEWLINE> <UNTAB> if indent is None : <NEWLINE> <TAB> indent = <STRING> <NEWLINE> <UNTAB> if firstline_indent is None : <NEWLINE> <TAB> firstline_indent = indent <NEWLINE> <NEWLINE> <UNTAB> if len ( indent ) >= length : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if len ( firstline_indent ) >= length : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> text = text . expandtabs ( <NUMBER> ) <NEWLINE> <NEWLINE> result = [ ] <NEWLINE> <NEWLINE> <NEWLINE> wrapper = textwrap . TextWrapper ( <NEWLINE> width = length , initial_indent = firstline_indent , subsequent_indent = indent ) <NEWLINE> subsequent_wrapper = textwrap . TextWrapper ( <NEWLINE> width = length , initial_indent = indent , subsequent_indent = indent ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for paragraph in ( p . strip ( ) for p in text . splitlines ( ) ) : <NEWLINE> <TAB> if paragraph : <NEWLINE> <TAB> result . extend ( wrapper . wrap ( paragraph ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result . append ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> wrapper = subsequent_wrapper <NEWLINE> <NEWLINE> <UNTAB> return <STRING> . join ( result ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def read_cz_lsm_positions ( fh ) : <NEWLINE> <TAB> <NEWLINE> size = struct . unpack ( <STRING> , fh . read ( <NUMBER> ) ) [ <NUMBER> ] <NEWLINE> return fh . read_array ( <STRING> , count = size ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ abstractmethod <NEWLINE> def _get_executor_init ( self , workers ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _decode_comment ( self , s ) : <NEWLINE> <TAB> <NEWLINE> res = re . sub ( <STRING> , <STRING> , s ) <NEWLINE> return res <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def poly_unify ( f , g ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( g , DMP ) or f . lev != g . lev : <NEWLINE> <TAB> raise UnificationFailed ( <STRING> % ( f , g ) ) <NEWLINE> <NEWLINE> <UNTAB> if f . dom == g . dom and f . ring == g . ring : <NEWLINE> <TAB> return ( f . lev , f . dom , f . per , ( f . num , f . den ) , g . rep ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> lev , dom = f . lev , f . dom . unify ( g . dom ) <NEWLINE> ring = f . ring <NEWLINE> if g . ring is not None : <NEWLINE> <TAB> if ring is not None : <NEWLINE> <TAB> ring = ring . unify ( g . ring ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ring = g . ring <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> F = ( dmp_convert ( f . num , lev , f . dom , dom ) , <NEWLINE> dmp_convert ( f . den , lev , f . dom , dom ) ) <NEWLINE> <NEWLINE> G = dmp_convert ( g . rep , lev , g . dom , dom ) <NEWLINE> <NEWLINE> def per ( num , den , cancel = True , kill = False , lev = lev ) : <NEWLINE> <TAB> if kill : <NEWLINE> <TAB> if not lev : <NEWLINE> <TAB> return num / den <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> lev = lev - <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if cancel : <NEWLINE> <TAB> num , den = dmp_cancel ( num , den , lev , dom ) <NEWLINE> <NEWLINE> <UNTAB> return f . __class__ . new ( ( num , den ) , dom , lev , ring = ring ) <NEWLINE> <NEWLINE> <UNTAB> return lev , dom , per , F , G <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _c_api_shape ( self ) : <NEWLINE> <TAB> <NEWLINE> c_graph = self . _op . _graph . _c_graph <NEWLINE> shape_vector , unknown_shape = c_api . TF_GraphGetTensorShapeHelper ( <NEWLINE> c_graph , self . _as_tf_output ( ) ) <NEWLINE> if unknown_shape : <NEWLINE> <TAB> return tensor_shape . unknown_shape ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> shape_vector = [ None if d == - <NUMBER> else d for d in shape_vector ] <NEWLINE> return tensor_shape . TensorShape ( shape_vector ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rs_is_puiseux ( p , x ) : <NEWLINE> <TAB> <NEWLINE> index = p . ring . gens . index ( x ) <NEWLINE> for k in p : <NEWLINE> <TAB> if k [ index ] != int ( k [ index ] ) : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> if k [ index ] < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % x ) <NEWLINE> <UNTAB> <UNTAB> return False <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ open_file ( <NUMBER> , mode = <STRING> ) <NEWLINE> def read_graphml ( path , node_type = str , edge_key_type = int ) : <NEWLINE> <TAB> <NEWLINE> reader = GraphMLReader ( node_type = node_type , edge_key_type = edge_key_type ) <NEWLINE> <NEWLINE> glist = list ( reader ( path = path ) ) <NEWLINE> if len ( glist ) == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> header = <STRING> <NEWLINE> path . seek ( <NUMBER> ) <NEWLINE> old_bytes = path . read ( ) <NEWLINE> new_bytes = old_bytes . replace ( <STRING> , header ) <NEWLINE> glist = list ( reader ( string = new_bytes ) ) <NEWLINE> if len ( glist ) == <NUMBER> : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> return glist [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( None , <STRING> ) <NEWLINE> def get_output_alternatives ( model_fn_ops , default_output_alternative_key = None ) : <NEWLINE> <TAB> <NEWLINE> output_alternatives = model_fn_ops . output_alternatives <NEWLINE> <NEWLINE> if not output_alternatives : <NEWLINE> <TAB> if default_output_alternative_key : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( <NEWLINE> default_output_alternative_key ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> default_problem_type = constants . ProblemType . UNSPECIFIED <NEWLINE> default_outputs = model_fn_ops . predictions <NEWLINE> if not isinstance ( default_outputs , dict ) : <NEWLINE> <TAB> default_outputs = { prediction_key . PredictionKey . GENERIC : default_outputs } <NEWLINE> <UNTAB> actual_default_output_alternative_key = ( <NEWLINE> _FALLBACK_DEFAULT_OUTPUT_ALTERNATIVE_KEY ) <NEWLINE> output_alternatives = { <NEWLINE> actual_default_output_alternative_key : ( default_problem_type , <NEWLINE> default_outputs ) <NEWLINE> } <NEWLINE> return output_alternatives , actual_default_output_alternative_key <NEWLINE> <NEWLINE> <UNTAB> if default_output_alternative_key : <NEWLINE> <NEWLINE> <TAB> if default_output_alternative_key in output_alternatives : <NEWLINE> <TAB> return output_alternatives , default_output_alternative_key <NEWLINE> <NEWLINE> <UNTAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( <NEWLINE> default_output_alternative_key , <NEWLINE> sorted ( output_alternatives . keys ( ) ) ) ) <NEWLINE> <NEWLINE> <UNTAB> if len ( output_alternatives ) == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> ( actual_default_output_alternative_key , _ ) , = output_alternatives . items ( ) <NEWLINE> return output_alternatives , actual_default_output_alternative_key <NEWLINE> <NEWLINE> <UNTAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( <NEWLINE> sorted ( output_alternatives . keys ( ) ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dup_zz_heu_gcd ( f , g , K ) : <NEWLINE> <TAB> <NEWLINE> result = _dup_rr_trivial_gcd ( f , g , K ) <NEWLINE> <NEWLINE> if result is not None : <NEWLINE> <TAB> return result <NEWLINE> <NEWLINE> <UNTAB> df = dup_degree ( f ) <NEWLINE> dg = dup_degree ( g ) <NEWLINE> <NEWLINE> gcd , f , g = dup_extract ( f , g , K ) <NEWLINE> <NEWLINE> if df == <NUMBER> or dg == <NUMBER> : <NEWLINE> <TAB> return [ gcd ] , f , g <NEWLINE> <NEWLINE> <UNTAB> f_norm = dup_max_norm ( f , K ) <NEWLINE> g_norm = dup_max_norm ( g , K ) <NEWLINE> <NEWLINE> B = K ( <NUMBER> * min ( f_norm , g_norm ) + <NUMBER> ) <NEWLINE> <NEWLINE> x = max ( min ( B , <NUMBER> * K . sqrt ( B ) ) , <NEWLINE> <NUMBER> * min ( f_norm // abs ( dup_LC ( f , K ) ) , <NEWLINE> g_norm // abs ( dup_LC ( g , K ) ) ) + <NUMBER> ) <NEWLINE> <NEWLINE> for i in range ( <NUMBER> , HEU_GCD_MAX ) : <NEWLINE> <TAB> ff = dup_eval ( f , x , K ) <NEWLINE> gg = dup_eval ( g , x , K ) <NEWLINE> <NEWLINE> if ff and gg : <NEWLINE> <TAB> h = K . gcd ( ff , gg ) <NEWLINE> <NEWLINE> cff = ff // h <NEWLINE> cfg = gg // h <NEWLINE> <NEWLINE> h = _dup_zz_gcd_interpolate ( h , x , K ) <NEWLINE> h = dup_primitive ( h , K ) [ <NUMBER> ] <NEWLINE> <NEWLINE> cff_ , r = dup_div ( f , h , K ) <NEWLINE> <NEWLINE> if not r : <NEWLINE> <TAB> cfg_ , r = dup_div ( g , h , K ) <NEWLINE> <NEWLINE> if not r : <NEWLINE> <TAB> h = dup_mul_ground ( h , gcd , K ) <NEWLINE> return h , cff_ , cfg_ <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> cff = _dup_zz_gcd_interpolate ( cff , x , K ) <NEWLINE> <NEWLINE> h , r = dup_div ( f , cff , K ) <NEWLINE> <NEWLINE> if not r : <NEWLINE> <TAB> cfg_ , r = dup_div ( g , h , K ) <NEWLINE> <NEWLINE> if not r : <NEWLINE> <TAB> h = dup_mul_ground ( h , gcd , K ) <NEWLINE> return h , cff , cfg_ <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> cfg = _dup_zz_gcd_interpolate ( cfg , x , K ) <NEWLINE> <NEWLINE> h , r = dup_div ( g , cfg , K ) <NEWLINE> <NEWLINE> if not r : <NEWLINE> <TAB> cff_ , r = dup_div ( f , h , K ) <NEWLINE> <NEWLINE> if not r : <NEWLINE> <TAB> h = dup_mul_ground ( h , gcd , K ) <NEWLINE> return h , cff_ , cfg <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> x = <NUMBER> * x * K . sqrt ( K . sqrt ( x ) ) // <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> raise HeuristicGCDFailed ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def ancestors ( variable_list , blockers = None ) : <NEWLINE> <TAB> <NEWLINE> def expand ( r ) : <NEWLINE> <TAB> if r . owner and ( not blockers or r not in blockers ) : <NEWLINE> <TAB> return reversed ( r . owner . inputs ) <NEWLINE> <UNTAB> <UNTAB> dfs_variables = stack_search ( deque ( variable_list ) , expand , <STRING> ) <NEWLINE> return dfs_variables <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def load_attributes_from_hdf5_group ( group , name ) : <NEWLINE> <TAB> <NEWLINE> if name in group . attrs : <NEWLINE> <TAB> data = [ n . decode ( <STRING> ) for n in group . attrs [ name ] ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> data = [ ] <NEWLINE> chunk_id = <NUMBER> <NEWLINE> while ( <STRING> % ( name , chunk_id ) ) in group . attrs : <NEWLINE> <TAB> data . extend ( [ n . decode ( <STRING> ) <NEWLINE> for n in group . attrs [ <STRING> % ( name , chunk_id ) ] ] ) <NEWLINE> chunk_id += <NUMBER> <NEWLINE> <UNTAB> <UNTAB> return data <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_data_as_items ( self ) : <NEWLINE> <TAB> <NEWLINE> return [ ( <STRING> , self . _start ) , <NEWLINE> ( <STRING> , self . _stop ) , <NEWLINE> ( <STRING> , self . _step ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def log ( x ) : <NEWLINE> <TAB> <NEWLINE> return tf . log ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rgb2ypbpr ( rgb ) : <NEWLINE> <TAB> <NEWLINE> return _convert ( ypbpr_from_rgb , rgb ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_ss ( self ) : <NEWLINE> <TAB> <NEWLINE> return StateSpace ( * zpk2ss ( self . zeros , self . poles , self . gain ) , <NEWLINE> ** self . _dt_dict ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def indexable ( * iterables ) : <NEWLINE> <TAB> <NEWLINE> result = [ ] <NEWLINE> for X in iterables : <NEWLINE> <TAB> if sp . issparse ( X ) : <NEWLINE> <TAB> result . append ( X . tocsr ( ) ) <NEWLINE> <UNTAB> elif hasattr ( X , <STRING> ) or hasattr ( X , <STRING> ) : <NEWLINE> <TAB> result . append ( X ) <NEWLINE> <UNTAB> elif X is None : <NEWLINE> <TAB> result . append ( X ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result . append ( np . array ( X ) ) <NEWLINE> <UNTAB> <UNTAB> check_consistent_length ( * result ) <NEWLINE> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def load ( self , value , session = None ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def delete ( self , loc ) : <NEWLINE> <TAB> <NEWLINE> return self . _create_from_codes ( np . delete ( self . codes , loc ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pixels_blue ( surface ) : <NEWLINE> <TAB> <NEWLINE> return numpy . array ( surface . get_view ( <STRING> ) , copy = False ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def mark_flag_as_required ( flag_name , flag_values = _flagvalues . FLAGS ) : <NEWLINE> <TAB> <NEWLINE> if flag_values [ flag_name ] . default is not None : <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % flag_name ) <NEWLINE> <UNTAB> register_validator ( flag_name , <NEWLINE> lambda value : value is not None , <NEWLINE> message = <STRING> % flag_name , <NEWLINE> flag_values = flag_values ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def inner ( a , b ) : <NEWLINE> <TAB> <NEWLINE> fa = filled ( a , <NUMBER> ) <NEWLINE> fb = filled ( b , <NUMBER> ) <NEWLINE> if fa . ndim == <NUMBER> : <NEWLINE> <TAB> fa . shape = ( <NUMBER> , ) <NEWLINE> <UNTAB> if fb . ndim == <NUMBER> : <NEWLINE> <TAB> fb . shape = ( <NUMBER> , ) <NEWLINE> <UNTAB> return np . inner ( fa , fb ) . view ( MaskedArray ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def pop_event ( self , index = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> self . events . pop ( index ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_coefficients ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( other , ABCPolyBase ) : <NEWLINE> <TAB> if not isinstance ( other , self . __class__ ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> elif not np . all ( self . domain == other . domain ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> elif not np . all ( self . window == other . window ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> return other . coef <NEWLINE> <UNTAB> return other <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def equals ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if self . is_ ( other ) : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if not isinstance ( other , IntervalIndex ) : <NEWLINE> <TAB> if not is_interval_dtype ( other ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> other = Index ( getattr ( other , <STRING> , other ) ) <NEWLINE> <NEWLINE> <UNTAB> return ( self . left . equals ( other . left ) and <NEWLINE> self . right . equals ( other . right ) and <NEWLINE> self . closed == other . closed ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _contains ( self , other ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( other , Set ) and other . is_FiniteSet : <NEWLINE> <TAB> return all ( self . __contains__ ( i ) for i in other ) <NEWLINE> <NEWLINE> <UNTAB> return self . __contains__ ( other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def Set ( self , parent , child_name , new_child ) : <NEWLINE> <TAB> <NEWLINE> old_child = getattr ( parent , child_name ) <NEWLINE> <NEWLINE> old_attribute = parent . __dict__ . get ( child_name ) <NEWLINE> if old_attribute is not None and isinstance ( old_attribute , staticmethod ) : <NEWLINE> <TAB> old_child = staticmethod ( old_child ) <NEWLINE> <NEWLINE> <UNTAB> self . cache . append ( ( parent , old_child , child_name ) ) <NEWLINE> setattr ( parent , child_name , new_child ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_valid_degree_sequence_havel_hakimi ( deg_sequence ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> dmax , dmin , dsum , n , num_degs = _basic_graphical_tests ( deg_sequence ) <NEWLINE> <UNTAB> except nx . NetworkXUnfeasible : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> if n == <NUMBER> or <NUMBER> * dmin * n >= ( dmax + dmin + <NUMBER> ) * ( dmax + dmin + <NUMBER> ) : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <UNTAB> modstubs = [ <NUMBER> ] * ( dmax + <NUMBER> ) <NEWLINE> <NEWLINE> while n > <NUMBER> : <NEWLINE> <NEWLINE> <TAB> while num_degs [ dmax ] == <NUMBER> : <NEWLINE> <TAB> dmax -= <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if dmax > n - <NUMBER> : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> num_degs [ dmax ] , n = num_degs [ dmax ] - <NUMBER> , n - <NUMBER> <NEWLINE> <NEWLINE> mslen = <NUMBER> <NEWLINE> k = dmax <NEWLINE> for i in range ( dmax ) : <NEWLINE> <TAB> while num_degs [ k ] == <NUMBER> : <NEWLINE> <TAB> k -= <NUMBER> <NEWLINE> <UNTAB> num_degs [ k ] , n = num_degs [ k ] - <NUMBER> , n - <NUMBER> <NEWLINE> if k > <NUMBER> : <NEWLINE> <TAB> modstubs [ mslen ] = k - <NUMBER> <NEWLINE> mslen += <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for i in range ( mslen ) : <NEWLINE> <TAB> stub = modstubs [ i ] <NEWLINE> num_degs [ stub ] , n = num_degs [ stub ] + <NUMBER> , n + <NUMBER> <NEWLINE> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _distribute ( info ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( info [ <NUMBER> ] , info [ <NUMBER> ] ) : <NEWLINE> <TAB> for arg in info [ <NUMBER> ] . args : <NEWLINE> <TAB> if isinstance ( arg , info [ <NUMBER> ] ) : <NEWLINE> <TAB> conj = arg <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return info [ <NUMBER> ] <NEWLINE> <UNTAB> rest = info [ <NUMBER> ] ( * [ a for a in info [ <NUMBER> ] . args if a is not conj ] ) <NEWLINE> return info [ <NUMBER> ] ( * list ( map ( _distribute , <NEWLINE> [ ( info [ <NUMBER> ] ( c , rest ) , info [ <NUMBER> ] , info [ <NUMBER> ] ) for c in conj . args ] ) ) ) <NEWLINE> <UNTAB> elif isinstance ( info [ <NUMBER> ] , info [ <NUMBER> ] ) : <NEWLINE> <TAB> return info [ <NUMBER> ] ( * list ( map ( _distribute , <NEWLINE> [ ( x , info [ <NUMBER> ] , info [ <NUMBER> ] ) for x in info [ <NUMBER> ] . args ] ) ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return info [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _encode_comment ( self , s = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if s : <NEWLINE> <TAB> return <STRING> % ( _TK_COMMENT , s ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return <STRING> % _TK_COMMENT <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def savefig ( self , fname , * , frameon = None , transparent = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> kwargs . setdefault ( <STRING> , rcParams [ <STRING> ] ) <NEWLINE> if frameon is None : <NEWLINE> <TAB> frameon = rcParams [ <STRING> ] <NEWLINE> <UNTAB> if transparent is None : <NEWLINE> <TAB> transparent = rcParams [ <STRING> ] <NEWLINE> <NEWLINE> <UNTAB> if transparent : <NEWLINE> <TAB> kwargs . setdefault ( <STRING> , <STRING> ) <NEWLINE> kwargs . setdefault ( <STRING> , <STRING> ) <NEWLINE> original_axes_colors = [ ] <NEWLINE> for ax in self . axes : <NEWLINE> <TAB> patch = ax . patch <NEWLINE> original_axes_colors . append ( ( patch . get_facecolor ( ) , <NEWLINE> patch . get_edgecolor ( ) ) ) <NEWLINE> patch . set_facecolor ( <STRING> ) <NEWLINE> patch . set_edgecolor ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> kwargs . setdefault ( <STRING> , rcParams [ <STRING> ] ) <NEWLINE> kwargs . setdefault ( <STRING> , rcParams [ <STRING> ] ) <NEWLINE> <NEWLINE> <UNTAB> if frameon : <NEWLINE> <TAB> original_frameon = self . get_frameon ( ) <NEWLINE> self . set_frameon ( frameon ) <NEWLINE> <NEWLINE> <UNTAB> self . canvas . print_figure ( fname , ** kwargs ) <NEWLINE> <NEWLINE> if frameon : <NEWLINE> <TAB> self . set_frameon ( original_frameon ) <NEWLINE> <NEWLINE> <UNTAB> if transparent : <NEWLINE> <TAB> for ax , cc in zip ( self . axes , original_axes_colors ) : <NEWLINE> <TAB> ax . patch . set_facecolor ( cc [ <NUMBER> ] ) <NEWLINE> ax . patch . set_edgecolor ( cc [ <NUMBER> ] ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_merge_keys ( self ) : <NEWLINE> <TAB> <NEWLINE> left_keys = [ ] <NEWLINE> right_keys = [ ] <NEWLINE> join_names = [ ] <NEWLINE> right_drop = [ ] <NEWLINE> left_drop = [ ] <NEWLINE> <NEWLINE> left , right = self . left , self . right <NEWLINE> stacklevel = <NUMBER> <NEWLINE> <NEWLINE> is_lkey = lambda x : is_array_like ( x ) and len ( x ) == len ( left ) <NEWLINE> is_rkey = lambda x : is_array_like ( x ) and len ( x ) == len ( right ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if _any ( self . left_on ) and _any ( self . right_on ) : <NEWLINE> <TAB> for lk , rk in zip ( self . left_on , self . right_on ) : <NEWLINE> <TAB> if is_lkey ( lk ) : <NEWLINE> <TAB> left_keys . append ( lk ) <NEWLINE> if is_rkey ( rk ) : <NEWLINE> <TAB> right_keys . append ( rk ) <NEWLINE> join_names . append ( None ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if rk is not None : <NEWLINE> <TAB> right_keys . append ( <NEWLINE> right . _get_label_or_level_values ( <NEWLINE> rk , stacklevel = stacklevel ) ) <NEWLINE> join_names . append ( rk ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> right_keys . append ( right . index ) <NEWLINE> join_names . append ( right . index . name ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if not is_rkey ( rk ) : <NEWLINE> <TAB> if rk is not None : <NEWLINE> <TAB> right_keys . append ( <NEWLINE> right . _get_label_or_level_values ( <NEWLINE> rk , stacklevel = stacklevel ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> right_keys . append ( right . index ) <NEWLINE> <UNTAB> if lk is not None and lk == rk : <NEWLINE> <NEWLINE> <TAB> if len ( left ) > <NUMBER> : <NEWLINE> <TAB> right_drop . append ( rk ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> left_drop . append ( lk ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> right_keys . append ( rk ) <NEWLINE> <UNTAB> if lk is not None : <NEWLINE> <TAB> left_keys . append ( left . _get_label_or_level_values ( <NEWLINE> lk , stacklevel = stacklevel ) ) <NEWLINE> join_names . append ( lk ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> left_keys . append ( left . index ) <NEWLINE> join_names . append ( left . index . name ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> elif _any ( self . left_on ) : <NEWLINE> <TAB> for k in self . left_on : <NEWLINE> <TAB> if is_lkey ( k ) : <NEWLINE> <TAB> left_keys . append ( k ) <NEWLINE> join_names . append ( None ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> left_keys . append ( left . _get_label_or_level_values ( <NEWLINE> k , stacklevel = stacklevel ) ) <NEWLINE> join_names . append ( k ) <NEWLINE> <UNTAB> <UNTAB> if isinstance ( self . right . index , MultiIndex ) : <NEWLINE> <TAB> right_keys = [ lev . _values . take ( lab ) <NEWLINE> for lev , lab in zip ( self . right . index . levels , <NEWLINE> self . right . index . labels ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> right_keys = [ self . right . index . values ] <NEWLINE> <UNTAB> <UNTAB> elif _any ( self . right_on ) : <NEWLINE> <TAB> for k in self . right_on : <NEWLINE> <TAB> if is_rkey ( k ) : <NEWLINE> <TAB> right_keys . append ( k ) <NEWLINE> join_names . append ( None ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> right_keys . append ( right . _get_label_or_level_values ( <NEWLINE> k , stacklevel = stacklevel ) ) <NEWLINE> join_names . append ( k ) <NEWLINE> <UNTAB> <UNTAB> if isinstance ( self . left . index , MultiIndex ) : <NEWLINE> <TAB> left_keys = [ lev . _values . take ( lab ) <NEWLINE> for lev , lab in zip ( self . left . index . levels , <NEWLINE> self . left . index . labels ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> left_keys = [ self . left . index . values ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if left_drop : <NEWLINE> <TAB> self . left = self . left . _drop_labels_or_levels ( left_drop ) <NEWLINE> <NEWLINE> <UNTAB> if right_drop : <NEWLINE> <TAB> self . right = self . right . _drop_labels_or_levels ( right_drop ) <NEWLINE> <NEWLINE> <UNTAB> return left_keys , right_keys , join_names <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def predict ( self , X ) : <NEWLINE> <TAB> <NEWLINE> y = super ( BaseSVC , self ) . predict ( X ) <NEWLINE> return self . classes_ . take ( np . asarray ( y , dtype = np . intp ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _make_random_matrix ( self , n_components , n_features ) : <NEWLINE> <TAB> <NEWLINE> random_state = check_random_state ( self . random_state ) <NEWLINE> return gaussian_random_matrix ( n_components , <NEWLINE> n_features , <NEWLINE> random_state = random_state ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def read_array_header_2_0 ( fp ) : <NEWLINE> <TAB> <NEWLINE> return _read_array_header ( fp , version = ( <NUMBER> , <NUMBER> ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def istask ( x ) : <NEWLINE> <TAB> <NEWLINE> return type ( x ) is tuple and x and callable ( x [ <NUMBER> ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def insert ( x , tck , m = <NUMBER> , per = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> t , c , k = tck <NEWLINE> try : <NEWLINE> <TAB> c [ <NUMBER> ] [ <NUMBER> ] <NEWLINE> parametric = True <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> parametric = False <NEWLINE> <UNTAB> if parametric : <NEWLINE> <TAB> cc = [ ] <NEWLINE> for c_vals in c : <NEWLINE> <TAB> tt , cc_val , kk = insert ( x , [ t , c_vals , k ] , m ) <NEWLINE> cc . append ( cc_val ) <NEWLINE> <UNTAB> return ( tt , cc , kk ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> tt , cc , ier = _fitpack . _insert ( per , t , c , k , x , m ) <NEWLINE> if ier == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if ier : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> return ( tt , cc , k ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ docstring . dedent_interpd <NEWLINE> def semilogx ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> d = { k : kwargs . pop ( k ) for k in [ <STRING> , <STRING> , <STRING> ] <NEWLINE> if k in kwargs } <NEWLINE> <NEWLINE> self . set_xscale ( <STRING> , ** d ) <NEWLINE> l = self . plot ( * args , ** kwargs ) <NEWLINE> return l <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def col_op ( self , j , f ) : <NEWLINE> <TAB> <NEWLINE> self . _mat [ j : : self . cols ] = [ f ( * t ) for t in list ( zip ( self . _mat [ j : : self . cols ] , list ( range ( self . rows ) ) ) ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def fateman_poly_F_3 ( n ) : <NEWLINE> <TAB> <NEWLINE> Y = [ Symbol ( <STRING> + str ( i ) ) for i in range ( n + <NUMBER> ) ] <NEWLINE> <NEWLINE> y_0 = Y [ <NUMBER> ] <NEWLINE> <NEWLINE> u = Add ( * [ y ** ( n + <NUMBER> ) for y in Y [ <NUMBER> : ] ] ) <NEWLINE> <NEWLINE> H = Poly ( ( y_0 ** ( n + <NUMBER> ) + u + <NUMBER> ) ** <NUMBER> , * Y ) <NEWLINE> <NEWLINE> F = Poly ( ( y_0 ** ( n + <NUMBER> ) - u - <NUMBER> ) ** <NUMBER> , * Y ) <NEWLINE> G = Poly ( ( y_0 ** ( n + <NUMBER> ) + u + <NUMBER> ) ** <NUMBER> , * Y ) <NEWLINE> <NEWLINE> return H * F , H * G , H <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _roll_axes ( x , rolls , axes = None ) : <NEWLINE> <TAB> <NEWLINE> if axes is None : <NEWLINE> <TAB> axes = np . arange ( len ( rolls ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for r , a in zip ( rolls , axes ) : <NEWLINE> <TAB> x = np . roll ( x , r , a ) <NEWLINE> <UNTAB> return x <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __eq__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return equal ( self , other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_strip ( f ) : <NEWLINE> <TAB> <NEWLINE> if not f or f [ <NUMBER> ] : <NEWLINE> <TAB> return f <NEWLINE> <NEWLINE> <UNTAB> i = <NUMBER> <NEWLINE> <NEWLINE> for cf in f : <NEWLINE> <TAB> if cf : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> i += <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return f [ i : ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def streaming_curve_points ( labels = None , <NEWLINE> predictions = None , <NEWLINE> weights = None , <NEWLINE> num_thresholds = <NUMBER> , <NEWLINE> metrics_collections = None , <NEWLINE> updates_collections = None , <NEWLINE> curve = <STRING> , <NEWLINE> name = None ) : <NEWLINE> <TAB> <NEWLINE> with variable_scope . variable_scope ( name , <STRING> , <NEWLINE> ( labels , predictions , weights ) ) : <NEWLINE> <TAB> if curve != <STRING> and curve != <STRING> : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( curve ) ) <NEWLINE> <UNTAB> kepsilon = _EPSILON <NEWLINE> thresholds = [ <NEWLINE> ( i + <NUMBER> ) * <NUMBER> / ( num_thresholds - <NUMBER> ) for i in range ( num_thresholds - <NUMBER> ) <NEWLINE> ] <NEWLINE> thresholds = [ <NUMBER> - kepsilon ] + thresholds + [ <NUMBER> + kepsilon ] <NEWLINE> <NEWLINE> values , update_ops = _streaming_confusion_matrix_at_thresholds ( <NEWLINE> labels = labels , <NEWLINE> predictions = predictions , <NEWLINE> thresholds = thresholds , <NEWLINE> weights = weights ) <NEWLINE> <NEWLINE> <NEWLINE> epsilon = <NUMBER> <NEWLINE> <NEWLINE> def compute_points ( tp , fn , tn , fp ) : <NEWLINE> <TAB> <NEWLINE> rec = math_ops . div ( tp + epsilon , tp + fn + epsilon ) <NEWLINE> if curve == <STRING> : <NEWLINE> <TAB> fp_rate = math_ops . div ( fp , fp + tn + epsilon ) <NEWLINE> return fp_rate , rec <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> prec = math_ops . div ( tp + epsilon , tp + fp + epsilon ) <NEWLINE> return rec , prec <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> xs , ys = compute_points ( values [ <STRING> ] , values [ <STRING> ] , values [ <STRING> ] , <NEWLINE> values [ <STRING> ] ) <NEWLINE> points = array_ops . stack ( [ xs , ys ] , axis = <NUMBER> ) <NEWLINE> update_op = control_flow_ops . group ( * update_ops . values ( ) ) <NEWLINE> <NEWLINE> if metrics_collections : <NEWLINE> <TAB> ops . add_to_collections ( metrics_collections , points ) <NEWLINE> <NEWLINE> <UNTAB> if updates_collections : <NEWLINE> <TAB> ops . add_to_collections ( updates_collections , update_op ) <NEWLINE> <NEWLINE> <UNTAB> return points , update_op <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def enable ( self , event = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def ndependencies ( dependencies , dependents ) : <NEWLINE> <TAB> <NEWLINE> result = dict ( ) <NEWLINE> num_needed = { k : len ( v ) for k , v in dependencies . items ( ) } <NEWLINE> current = { k for k , v in num_needed . items ( ) if v == <NUMBER> } <NEWLINE> while current : <NEWLINE> <TAB> key = current . pop ( ) <NEWLINE> result [ key ] = <NUMBER> + sum ( result [ child ] for child in dependencies [ key ] ) <NEWLINE> for parent in dependents [ key ] : <NEWLINE> <TAB> num_needed [ parent ] -= <NUMBER> <NEWLINE> if num_needed [ parent ] == <NUMBER> : <NEWLINE> <TAB> current . add ( parent ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def on_detach ( self , fgraph ) : <NEWLINE> <TAB> <NEWLINE> del fgraph . checkpoint <NEWLINE> del fgraph . revert <NEWLINE> del self . history [ fgraph ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_dashpad ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _dashpad <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ cbook . deprecated ( <STRING> ) <NEWLINE> def get_sparse_matrix ( M , N , frac = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> data = np . zeros ( ( M , N ) ) * <NUMBER> <NEWLINE> for i in range ( int ( M * N * frac ) ) : <NEWLINE> <TAB> x = np . random . randint ( <NUMBER> , M - <NUMBER> ) <NEWLINE> y = np . random . randint ( <NUMBER> , N - <NUMBER> ) <NEWLINE> data [ x , y ] = np . random . rand ( ) <NEWLINE> <UNTAB> return data <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> def extended_barabasi_albert_graph ( n , m , p , q , seed = None ) : <NEWLINE> <TAB> <NEWLINE> if m < <NUMBER> or m >= n : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise nx . NetworkXError ( msg % ( m , n ) ) <NEWLINE> <UNTAB> if p + q >= <NUMBER> : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise nx . NetworkXError ( msg % ( p , q ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> G = empty_graph ( m ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> attachment_preference = [ ] <NEWLINE> attachment_preference . extend ( range ( m ) ) <NEWLINE> <NEWLINE> <NEWLINE> new_node = m <NEWLINE> while new_node < n : <NEWLINE> <TAB> a_probability = seed . random ( ) <NEWLINE> <NEWLINE> <NEWLINE> clique_degree = len ( G ) - <NUMBER> <NEWLINE> clique_size = ( len ( G ) * clique_degree ) / <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> if a_probability < p and G . size ( ) <= clique_size - m : <NEWLINE> <NEWLINE> <TAB> elligible_nodes = [ nd for nd , deg in G . degree ( ) <NEWLINE> if deg < clique_degree ] <NEWLINE> for i in range ( m ) : <NEWLINE> <NEWLINE> <TAB> src_node = seed . choice ( elligible_nodes ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> prohibited_nodes = list ( G [ src_node ] ) <NEWLINE> prohibited_nodes . append ( src_node ) <NEWLINE> <NEWLINE> dest_node = seed . choice ( [ nd for nd in attachment_preference <NEWLINE> if nd not in prohibited_nodes ] ) <NEWLINE> <NEWLINE> G . add_edge ( src_node , dest_node ) <NEWLINE> <NEWLINE> <NEWLINE> attachment_preference . append ( src_node ) <NEWLINE> attachment_preference . append ( dest_node ) <NEWLINE> <NEWLINE> <NEWLINE> if G . degree ( src_node ) == clique_degree : <NEWLINE> <TAB> elligible_nodes . remove ( src_node ) <NEWLINE> <UNTAB> if G . degree ( dest_node ) == clique_degree and dest_node in elligible_nodes : <NEWLINE> <TAB> elligible_nodes . remove ( dest_node ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif p <= a_probability < ( p + q ) and m <= G . size ( ) < clique_size : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> elligible_nodes = [ nd for nd , deg in G . degree ( ) <NEWLINE> if <NUMBER> < deg < clique_degree ] <NEWLINE> for i in range ( m ) : <NEWLINE> <NEWLINE> <TAB> node = seed . choice ( elligible_nodes ) <NEWLINE> <NEWLINE> <NEWLINE> neighbor_nodes = list ( G [ node ] ) <NEWLINE> <NEWLINE> <NEWLINE> src_node = seed . choice ( neighbor_nodes ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> neighbor_nodes . append ( node ) <NEWLINE> dest_node = seed . choice ( [ nd for nd in attachment_preference <NEWLINE> if nd not in neighbor_nodes ] ) <NEWLINE> <NEWLINE> G . remove_edge ( node , src_node ) <NEWLINE> G . add_edge ( node , dest_node ) <NEWLINE> <NEWLINE> <NEWLINE> attachment_preference . remove ( src_node ) <NEWLINE> attachment_preference . append ( dest_node ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if G . degree ( src_node ) == <NUMBER> and src_node in elligible_nodes : <NEWLINE> <TAB> elligible_nodes . remove ( src_node ) <NEWLINE> <UNTAB> if dest_node in elligible_nodes : <NEWLINE> <TAB> if G . degree ( dest_node ) == clique_degree : <NEWLINE> <TAB> elligible_nodes . remove ( dest_node ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if G . degree ( dest_node ) == <NUMBER> : <NEWLINE> <TAB> elligible_nodes . append ( dest_node ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> targets = _random_subset ( attachment_preference , m , seed ) <NEWLINE> G . add_edges_from ( zip ( [ new_node ] * m , targets ) ) <NEWLINE> <NEWLINE> <NEWLINE> attachment_preference . extend ( targets ) <NEWLINE> <NEWLINE> attachment_preference . extend ( [ new_node ] * ( m + <NUMBER> ) ) <NEWLINE> new_node += <NUMBER> <NEWLINE> <UNTAB> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def fast_xs ( self , loc ) : <NEWLINE> <TAB> <NEWLINE> return self . _block . values [ loc ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def group_delay ( system , w = <NUMBER> , whole = False ) : <NEWLINE> <TAB> <NEWLINE> if w is None : <NEWLINE> <TAB> w = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( w , int ) : <NEWLINE> <TAB> if whole : <NEWLINE> <TAB> w = np . linspace ( <NUMBER> , <NUMBER> * pi , w , endpoint = False ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> w = np . linspace ( <NUMBER> , pi , w , endpoint = False ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> w = np . atleast_1d ( w ) <NEWLINE> b , a = map ( np . atleast_1d , system ) <NEWLINE> c = np . convolve ( b , a [ : : - <NUMBER> ] ) <NEWLINE> cr = c * np . arange ( c . size ) <NEWLINE> z = np . exp ( - <NUMBER> * w ) <NEWLINE> num = np . polyval ( cr [ : : - <NUMBER> ] , z ) <NEWLINE> den = np . polyval ( c [ : : - <NUMBER> ] , z ) <NEWLINE> singular = np . absolute ( den ) < <NUMBER> * EPSILON <NEWLINE> if np . any ( singular ) : <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> . <NEWLINE> format ( <STRING> . join ( <STRING> . format ( ws ) for ws in w [ singular ] ) ) <NEWLINE> ) <NEWLINE> <NEWLINE> <UNTAB> gd = np . zeros_like ( w ) <NEWLINE> gd [ ~ singular ] = np . real ( num [ ~ singular ] / den [ ~ singular ] ) - a . size + <NUMBER> <NEWLINE> return w , gd <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def of_type ( self , element ) : <NEWLINE> <TAB> <NEWLINE> return isinstance ( element , self . tp ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def normal_ ( tensor , mean = <NUMBER> , std = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> with torch . no_grad ( ) : <NEWLINE> <TAB> return tensor . normal_ ( mean , std ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _get_format_datetime64_from_values ( values , date_format ) : <NEWLINE> <TAB> <NEWLINE> is_dates_only = _is_dates_only ( values ) <NEWLINE> if is_dates_only : <NEWLINE> <TAB> return date_format or <STRING> <NEWLINE> <UNTAB> return date_format <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get ( self , key ) : <NEWLINE> <TAB> <NEWLINE> if key in self . _columns_to_tensors : <NEWLINE> <TAB> return self . _columns_to_tensors [ key ] <NEWLINE> <UNTAB> if isinstance ( key , str ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> . format ( key ) ) <NEWLINE> <UNTAB> if not isinstance ( key , _FeatureColumn ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> . format ( key ) ) <NEWLINE> <NEWLINE> <UNTAB> key . insert_transformed_feature ( self . _columns_to_tensors ) <NEWLINE> return self . _columns_to_tensors [ key ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def wait ( object_list , timeout = None ) : <NEWLINE> <TAB> <NEWLINE> with _WaitSelector ( ) as selector : <NEWLINE> <TAB> for obj in object_list : <NEWLINE> <TAB> selector . register ( obj , selectors . EVENT_READ ) <NEWLINE> <NEWLINE> <UNTAB> if timeout is not None : <NEWLINE> <TAB> deadline = time . time ( ) + timeout <NEWLINE> <NEWLINE> <UNTAB> while True : <NEWLINE> <TAB> ready = selector . select ( timeout ) <NEWLINE> if ready : <NEWLINE> <TAB> return [ key . fileobj for ( key , events ) in ready ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if timeout is not None : <NEWLINE> <TAB> timeout = deadline - time . time ( ) <NEWLINE> if timeout < <NUMBER> : <NEWLINE> <TAB> return ready <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _iteritems ( d ) : <NEWLINE> <TAB> <NEWLINE> return d . iteritems ( ) if hasattr ( d , <STRING> ) else d . items ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def create_grad ( node , namer , tangent = False ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( node , ( gast . Subscript , gast . Name , gast . Str ) ) : <NEWLINE> <TAB> raise TypeError <NEWLINE> <NEWLINE> <UNTAB> if anno . hasanno ( node , <STRING> ) : <NEWLINE> <TAB> return create_grad ( anno . getanno ( node , <STRING> ) , namer , tangent ) <NEWLINE> <NEWLINE> <UNTAB> def _name_grad ( node ) : <NEWLINE> <TAB> if not isinstance ( node , gast . Name ) : <NEWLINE> <TAB> raise TypeError <NEWLINE> <UNTAB> varname = node . id <NEWLINE> name = namer . grad ( varname , tangent ) <NEWLINE> grad_node = gast . Name ( <NEWLINE> id = name , ctx = None , annotation = None ) <NEWLINE> anno . setanno ( grad_node , <STRING> , node ) <NEWLINE> return grad_node <NEWLINE> <UNTAB> if isinstance ( node , gast . Subscript ) : <NEWLINE> <TAB> grad_node = create_grad ( node . value , namer , tangent = tangent ) <NEWLINE> grad_node . ctx = gast . Load ( ) <NEWLINE> return gast . Subscript ( value = grad_node , slice = node . slice , ctx = None ) <NEWLINE> <UNTAB> elif isinstance ( node , gast . Str ) : <NEWLINE> <TAB> grad_node = create_grad ( <NEWLINE> gast . Name ( id = node . s , ctx = None , annotation = None ) , namer , tangent = tangent ) <NEWLINE> return gast . Str ( grad_node . id ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _name_grad ( node ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def end_pan ( self ) : <NEWLINE> <TAB> <NEWLINE> del self . _pan_start <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def number_of_cliques ( G , nodes = None , cliques = None ) : <NEWLINE> <TAB> <NEWLINE> if cliques is None : <NEWLINE> <TAB> cliques = list ( find_cliques ( G ) ) <NEWLINE> <NEWLINE> <UNTAB> if nodes is None : <NEWLINE> <TAB> nodes = list ( G . nodes ( ) ) <NEWLINE> <NEWLINE> <UNTAB> if not isinstance ( nodes , list ) : <NEWLINE> <TAB> v = nodes <NEWLINE> <NEWLINE> numcliq = len ( [ <NUMBER> for c in cliques if v in c ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> numcliq = { } <NEWLINE> for v in nodes : <NEWLINE> <TAB> numcliq [ v ] = len ( [ <NUMBER> for c in cliques if v in c ] ) <NEWLINE> <UNTAB> <UNTAB> return numcliq <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def relative_luminance ( color ) : <NEWLINE> <TAB> <NEWLINE> rgb = mpl . colors . colorConverter . to_rgba_array ( color ) [ : , : <NUMBER> ] <NEWLINE> rgb = np . where ( rgb <= <NUMBER> , rgb / <NUMBER> , ( ( rgb + <NUMBER> ) / <NUMBER> ) ** <NUMBER> ) <NEWLINE> lum = rgb . dot ( [ <NUMBER> , <NUMBER> , <NUMBER> ] ) <NEWLINE> try : <NEWLINE> <TAB> return lum . item ( ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> return lum <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def literal_processor ( self , dialect ) : <NEWLINE> <TAB> <NEWLINE> if self . _has_literal_processor : <NEWLINE> <TAB> process_param = self . process_literal_param <NEWLINE> <UNTAB> elif self . _has_bind_processor : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> process_param = self . process_bind_param <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> process_param = None <NEWLINE> <NEWLINE> <UNTAB> if process_param : <NEWLINE> <TAB> impl_processor = self . impl . literal_processor ( dialect ) <NEWLINE> if impl_processor : <NEWLINE> <TAB> def process ( value ) : <NEWLINE> <TAB> return impl_processor ( process_param ( value , dialect ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> def process ( value ) : <NEWLINE> <TAB> return process_param ( value , dialect ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return process <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . impl . literal_processor ( dialect ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def rowspace ( self , simplify = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> reduced , pivots = self . echelon_form ( simplify = simplify , with_pivots = True ) <NEWLINE> <NEWLINE> return [ reduced . row ( i ) for i in range ( len ( pivots ) ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def getmaskarray ( arr ) : <NEWLINE> <TAB> <NEWLINE> mask = getmask ( arr ) <NEWLINE> if mask is nomask : <NEWLINE> <TAB> mask = make_mask_none ( np . shape ( arr ) , getattr ( arr , <STRING> , None ) ) <NEWLINE> <UNTAB> return mask <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def bucket_by_sequence_length ( element_length_func , <NEWLINE> bucket_boundaries , <NEWLINE> bucket_batch_sizes , <NEWLINE> padded_shapes = None , <NEWLINE> padding_values = None , <NEWLINE> pad_to_bucket_boundary = False , <NEWLINE> no_padding = False ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( <STRING> ) : <NEWLINE> <TAB> if len ( bucket_batch_sizes ) != ( len ( bucket_boundaries ) + <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> batch_sizes = constant_op . constant ( bucket_batch_sizes , dtype = dtypes . int64 ) <NEWLINE> <NEWLINE> def element_to_bucket_id ( * args ) : <NEWLINE> <TAB> <NEWLINE> seq_length = element_length_func ( * args ) <NEWLINE> <NEWLINE> boundaries = list ( bucket_boundaries ) <NEWLINE> buckets_min = [ np . iinfo ( np . int32 ) . min ] + boundaries <NEWLINE> buckets_max = boundaries + [ np . iinfo ( np . int32 ) . max ] <NEWLINE> conditions_c = math_ops . logical_and ( <NEWLINE> math_ops . less_equal ( buckets_min , seq_length ) , <NEWLINE> math_ops . less ( seq_length , buckets_max ) ) <NEWLINE> bucket_id = math_ops . reduce_min ( array_ops . where ( conditions_c ) ) <NEWLINE> <NEWLINE> return bucket_id <NEWLINE> <NEWLINE> <UNTAB> def window_size_fn ( bucket_id ) : <NEWLINE> <NEWLINE> <TAB> window_size = batch_sizes [ bucket_id ] <NEWLINE> return window_size <NEWLINE> <NEWLINE> <UNTAB> def make_padded_shapes ( shapes , none_filler = None ) : <NEWLINE> <TAB> padded = [ ] <NEWLINE> for shape in nest . flatten ( shapes ) : <NEWLINE> <TAB> shape = tensor_shape . TensorShape ( shape ) <NEWLINE> shape = [ <NEWLINE> none_filler if tensor_shape . dimension_value ( d ) is None else d <NEWLINE> for d in shape <NEWLINE> ] <NEWLINE> padded . append ( shape ) <NEWLINE> <UNTAB> return nest . pack_sequence_as ( shapes , padded ) <NEWLINE> <NEWLINE> <UNTAB> def batching_fn ( bucket_id , grouped_dataset ) : <NEWLINE> <TAB> <NEWLINE> batch_size = window_size_fn ( bucket_id ) <NEWLINE> if no_padding : <NEWLINE> <TAB> return grouped_dataset . batch ( batch_size ) <NEWLINE> <UNTAB> none_filler = None <NEWLINE> if pad_to_bucket_boundary : <NEWLINE> <TAB> err_msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> check = check_ops . assert_less ( <NEWLINE> bucket_id , <NEWLINE> constant_op . constant ( len ( bucket_batch_sizes ) - <NUMBER> , <NEWLINE> dtype = dtypes . int64 ) , <NEWLINE> message = err_msg ) <NEWLINE> with ops . control_dependencies ( [ check ] ) : <NEWLINE> <TAB> boundaries = constant_op . constant ( bucket_boundaries , <NEWLINE> dtype = dtypes . int64 ) <NEWLINE> bucket_boundary = boundaries [ bucket_id ] <NEWLINE> none_filler = bucket_boundary - <NUMBER> <NEWLINE> <UNTAB> <UNTAB> shapes = make_padded_shapes ( <NEWLINE> padded_shapes or grouped_dataset . output_shapes , <NEWLINE> none_filler = none_filler ) <NEWLINE> return grouped_dataset . padded_batch ( batch_size , shapes , padding_values ) <NEWLINE> <NEWLINE> <UNTAB> def _apply_fn ( dataset ) : <NEWLINE> <TAB> return dataset . apply ( <NEWLINE> group_by_window ( element_to_bucket_id , batching_fn , <NEWLINE> window_size_func = window_size_fn ) ) <NEWLINE> <NEWLINE> <UNTAB> return _apply_fn <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _eval_diag ( cls , rows , cols , diag_dict ) : <NEWLINE> <TAB> <NEWLINE> def entry ( i , j ) : <NEWLINE> <TAB> return diag_dict [ ( i , j ) ] <NEWLINE> <UNTAB> return cls . _new ( rows , cols , entry ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _displayof ( self , displayof ) : <NEWLINE> <TAB> <NEWLINE> if displayof : <NEWLINE> <TAB> return ( <STRING> , displayof ) <NEWLINE> <UNTAB> if displayof is None : <NEWLINE> <TAB> return ( <STRING> , self . _w ) <NEWLINE> <UNTAB> return ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def notlike ( self , other , escape = None ) : <NEWLINE> <TAB> <NEWLINE> return self . operate ( notlike_op , other , escape = escape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def grid_location ( self , x , y ) : <NEWLINE> <TAB> <NEWLINE> return self . _getints ( <NEWLINE> self . tk . call ( <NEWLINE> <STRING> , <STRING> , self . _w , x , y ) ) or None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def to_source ( node , indentation = <STRING> * <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( node , gast . AST ) : <NEWLINE> <TAB> node = gast . gast_to_ast ( node ) <NEWLINE> <UNTAB> generator = SourceWithCommentGenerator ( indentation , False , <NEWLINE> astor . string_repr . pretty_string ) <NEWLINE> generator . visit ( node ) <NEWLINE> generator . result . append ( <STRING> ) <NEWLINE> return astor . source_repr . pretty_source ( generator . result ) . lstrip ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , num_steps = None , last_step = None ) : <NEWLINE> <TAB> <NEWLINE> if num_steps is None and last_step is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if num_steps is not None and last_step is not None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> self . _num_steps = num_steps <NEWLINE> self . _last_step = last_step <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def cluster_spec ( self ) : <NEWLINE> <TAB> <NEWLINE> hostlist = self . _resolve_hostnames ( ) <NEWLINE> <NEWLINE> task_list = [ ] <NEWLINE> self . _gpu_allocation = [ ] <NEWLINE> self . _cluster_allocation = { } <NEWLINE> <NEWLINE> for host in hostlist : <NEWLINE> <TAB> for port_offset , gpu_offset in zip ( <NEWLINE> range ( self . _tasks_per_node ) , <NEWLINE> range ( <NUMBER> , self . _gpus_per_node , self . _gpus_per_task ) ) : <NEWLINE> <NEWLINE> <TAB> host_addr = <STRING> % ( host , self . _port_base + port_offset ) <NEWLINE> task_list . append ( host_addr ) <NEWLINE> gpu_id_list = [ ] <NEWLINE> <NEWLINE> for gpu_id in range ( gpu_offset , gpu_offset + self . _gpus_per_task ) : <NEWLINE> <TAB> gpu_id_list . append ( str ( gpu_id ) ) <NEWLINE> <NEWLINE> <UNTAB> self . _gpu_allocation . append ( <STRING> . join ( gpu_id_list ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> cluster_rank_offset_start = <NUMBER> <NEWLINE> cluster_rank_offset_end = <NUMBER> <NEWLINE> <NEWLINE> for job_name , num_tasks in self . _jobs . items ( ) : <NEWLINE> <TAB> cluster_rank_offset_end = cluster_rank_offset_start + num_tasks <NEWLINE> <NEWLINE> self . _cluster_allocation [ job_name ] = task_list [ cluster_rank_offset_start : cluster_rank_offset_end ] <NEWLINE> <NEWLINE> if self . _rank >= cluster_rank_offset_start and self . _rank < cluster_rank_offset_end : <NEWLINE> <NEWLINE> <TAB> self . _job_name = job_name <NEWLINE> self . _task_index = self . _rank - cluster_rank_offset_start <NEWLINE> <NEWLINE> <UNTAB> cluster_rank_offset_start = cluster_rank_offset_end <NEWLINE> <NEWLINE> <UNTAB> if self . _auto_set_gpu is True : <NEWLINE> <TAB> os . environ [ <STRING> ] = self . _gpu_allocation [ self . _rank ] <NEWLINE> <NEWLINE> <UNTAB> return ClusterSpec ( self . _cluster_allocation ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def memory_usage ( self , deep = False ) : <NEWLINE> <TAB> <NEWLINE> return self . nbytes <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def multigammaln ( a , d ) : <NEWLINE> <TAB> <NEWLINE> a = np . asarray ( a ) <NEWLINE> if not np . isscalar ( d ) or ( np . floor ( d ) != d ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if np . any ( a <= <NUMBER> * ( d - <NUMBER> ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> % ( a , <NUMBER> * ( d - <NUMBER> ) ) ) <NEWLINE> <NEWLINE> <UNTAB> res = ( d * ( d - <NUMBER> ) * <NUMBER> ) * np . log ( np . pi ) <NEWLINE> res += np . sum ( loggam ( [ ( a - ( j - <NUMBER> ) / <NUMBER> ) for j in range ( <NUMBER> , d + <NUMBER> ) ] ) , axis = <NUMBER> ) <NEWLINE> return res <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __mod__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return self . operate ( mod , other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit ( self , X , y = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> self . _reset ( ) <NEWLINE> return self . partial_fit ( X , y ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ Appender ( _index_shared_docs [ <STRING> ] ) <NEWLINE> def _convert_list_indexer ( self , keyarr , kind = None ) : <NEWLINE> <TAB> <NEWLINE> locs = self . get_indexer_for ( keyarr ) <NEWLINE> <NEWLINE> <NEWLINE> if ( locs == - <NUMBER> ) . any ( ) : <NEWLINE> <TAB> raise KeyError <NEWLINE> <NEWLINE> <UNTAB> return locs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def diag_indices ( n , ndim = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> idx = arange ( n ) <NEWLINE> return ( idx , ) * ndim <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def conj ( input , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , input ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return conj_eager_fallback ( <NEWLINE> input , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_tool_keymap ( self , name ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> keys = [ k for k , i in self . _keys . items ( ) if i == name ] <NEWLINE> return keys <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def argmax ( self , axis = None , out = None ) : <NEWLINE> <TAB> <NEWLINE> return self . _arg_min_or_max ( axis , out , np . argmax , np . greater ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def corners ( self ) : <NEWLINE> <TAB> <NEWLINE> l , b , r , t = self . get_points ( ) . flatten ( ) <NEWLINE> return np . array ( [ [ l , b ] , [ l , t ] , [ r , b ] , [ r , t ] ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _arg ( self , nbytes , signed = False ) : <NEWLINE> <TAB> <NEWLINE> str = self . file . read ( nbytes ) <NEWLINE> value = str [ <NUMBER> ] <NEWLINE> if signed and value >= <NUMBER> : <NEWLINE> <TAB> value = value - <NUMBER> <NEWLINE> <UNTAB> for i in range ( <NUMBER> , nbytes ) : <NEWLINE> <TAB> value = <NUMBER> * value + str [ i ] <NEWLINE> <UNTAB> return value <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pack_sequence ( sequences ) : <NEWLINE> <TAB> <NEWLINE> return pack_padded_sequence ( pad_sequence ( sequences ) , [ v . size ( <NUMBER> ) for v in sequences ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , indices , values , dense_shape ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( None , <STRING> , <NEWLINE> [ indices , values , dense_shape ] ) : <NEWLINE> <TAB> indices = ops . convert_to_tensor ( <NEWLINE> indices , name = <STRING> , dtype = dtypes . int64 ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> values = ops . internal_convert_to_tensor ( <NEWLINE> values , name = <STRING> , as_ref = True ) <NEWLINE> dense_shape = ops . convert_to_tensor ( <NEWLINE> dense_shape , name = <STRING> , dtype = dtypes . int64 ) <NEWLINE> <UNTAB> self . _indices = indices <NEWLINE> self . _values = values <NEWLINE> self . _dense_shape = dense_shape <NEWLINE> <NEWLINE> indices_shape = indices . get_shape ( ) . with_rank ( <NUMBER> ) <NEWLINE> values_shape = values . get_shape ( ) . with_rank ( <NUMBER> ) <NEWLINE> dense_shape_shape = dense_shape . get_shape ( ) . with_rank ( <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> indices_shape . dims [ <NUMBER> ] . merge_with ( values_shape . dims [ <NUMBER> ] ) <NEWLINE> <NEWLINE> <NEWLINE> indices_shape . dims [ <NUMBER> ] . merge_with ( dense_shape_shape . dims [ <NUMBER> ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _assert_safe_casting ( cls , data , subarr ) : <NEWLINE> <TAB> <NEWLINE> if not issubclass ( data . dtype . type , np . signedinteger ) : <NEWLINE> <TAB> if not np . array_equal ( data , subarr ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def exquo ( self , a , b ) : <NEWLINE> <TAB> <NEWLINE> return GMPYRational ( a ) / GMPYRational ( b ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def validate ( self , fgraph ) : <NEWLINE> <TAB> <NEWLINE> if self . destroyers : <NEWLINE> <TAB> if self . algo == <STRING> : <NEWLINE> <TAB> if self . fail_validate : <NEWLINE> <TAB> app_err_pairs = self . fail_validate <NEWLINE> self . fail_validate = OrderedDict ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for app in app_err_pairs : <NEWLINE> <TAB> if app in fgraph . apply_nodes : <NEWLINE> <TAB> self . fast_destroy ( app , <STRING> ) <NEWLINE> <UNTAB> <UNTAB> if self . fail_validate : <NEWLINE> <TAB> self . fail_validate = app_err_pairs <NEWLINE> raise app_err_pairs [ app ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> ords = self . orderings ( fgraph , ordered = False ) <NEWLINE> if _contains_cycle ( fgraph , ords ) : <NEWLINE> <TAB> raise InconsistencyError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> return True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def decode ( self , s , encode_nominal = False , return_type = DENSE ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return self . _decode ( s , encode_nominal = encode_nominal , <NEWLINE> matrix_type = return_type ) <NEWLINE> <UNTAB> except ArffException as e : <NEWLINE> <TAB> e . line = self . _current_line <NEWLINE> raise e <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def push_current ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _nav_stack . push ( <NEWLINE> WeakKeyDictionary ( <NEWLINE> { ax : ( ax . _get_view ( ) , <NEWLINE> <NEWLINE> ( ax . get_position ( True ) . frozen ( ) , <NEWLINE> ax . get_position ( ) . frozen ( ) ) ) <NEWLINE> for ax in self . canvas . figure . axes } ) ) <NEWLINE> self . set_history_buttons ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ nodes_or_number ( [ <NUMBER> , <NUMBER> ] ) <NEWLINE> def grid_2d_graph ( m , n , periodic = False , create_using = None ) : <NEWLINE> <TAB> <NEWLINE> G = empty_graph ( <NUMBER> , create_using ) <NEWLINE> row_name , rows = m <NEWLINE> col_name , cols = n <NEWLINE> G . add_nodes_from ( ( i , j ) for i in rows for j in cols ) <NEWLINE> G . add_edges_from ( ( ( i , j ) , ( pi , j ) ) <NEWLINE> for pi , i in pairwise ( rows ) for j in cols ) <NEWLINE> G . add_edges_from ( ( ( i , j ) , ( i , pj ) ) <NEWLINE> for i in rows for pj , j in pairwise ( cols ) ) <NEWLINE> if periodic is True : <NEWLINE> <TAB> if len ( rows ) > <NUMBER> : <NEWLINE> <TAB> first = rows [ <NUMBER> ] <NEWLINE> last = rows [ - <NUMBER> ] <NEWLINE> G . add_edges_from ( ( ( first , j ) , ( last , j ) ) for j in cols ) <NEWLINE> <UNTAB> if len ( cols ) > <NUMBER> : <NEWLINE> <TAB> first = cols [ <NUMBER> ] <NEWLINE> last = cols [ - <NUMBER> ] <NEWLINE> G . add_edges_from ( ( ( i , first ) , ( i , last ) ) for i in rows ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if G . is_directed ( ) : <NEWLINE> <TAB> G . add_edges_from ( ( v , u ) for u , v in G . edges ( ) ) <NEWLINE> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _reset ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . mode not in [ <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> logging . warning ( <STRING> <NEWLINE> <STRING> , self . mode ) <NEWLINE> self . mode = <STRING> <NEWLINE> <UNTAB> if ( self . mode == <STRING> or <NEWLINE> ( self . mode == <STRING> and <STRING> not in self . monitor ) ) : <NEWLINE> <TAB> self . monitor_op = lambda a , b : np . less ( a , b - self . min_delta ) <NEWLINE> self . best = np . Inf <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . monitor_op = lambda a , b : np . greater ( a , b + self . min_delta ) <NEWLINE> self . best = - np . Inf <NEWLINE> <UNTAB> self . cooldown_counter = <NUMBER> <NEWLINE> self . wait = <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def lcim ( numbers ) : <NEWLINE> <TAB> <NEWLINE> result = None <NEWLINE> if all ( num . is_irrational for num in numbers ) : <NEWLINE> <TAB> factorized_nums = list ( map ( lambda num : num . factor ( ) , numbers ) ) <NEWLINE> factors_num = list ( <NEWLINE> map ( lambda num : num . as_coeff_Mul ( ) , <NEWLINE> factorized_nums ) ) <NEWLINE> term = factors_num [ <NUMBER> ] [ <NUMBER> ] <NEWLINE> if all ( factor == term for coeff , factor in factors_num ) : <NEWLINE> <TAB> common_term = term <NEWLINE> coeffs = [ coeff for coeff , factor in factors_num ] <NEWLINE> result = lcm_list ( coeffs ) * common_term <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif all ( num . is_rational for num in numbers ) : <NEWLINE> <TAB> result = lcm_list ( numbers ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _check_density ( density , n_features ) : <NEWLINE> <TAB> <NEWLINE> if density == <STRING> : <NEWLINE> <TAB> density = <NUMBER> / np . sqrt ( n_features ) <NEWLINE> <NEWLINE> <UNTAB> elif density <= <NUMBER> or density > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> % density ) <NEWLINE> <UNTAB> return density <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __ge__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return self . operate ( ge , other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def estimator_model_fn ( target_model_fn = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def decorated ( function ) : <NEWLINE> <TAB> return tf_decorator . make_decorator ( function , _ModelFnWrapper ( function ) ) <NEWLINE> <NEWLINE> <UNTAB> return decorated ( target_model_fn ) if target_model_fn else decorated <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def nodes ( G ) : <NEWLINE> <TAB> <NEWLINE> return G . nodes ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def draw_letter_value_plot ( self , ax , kws ) : <NEWLINE> <TAB> <NEWLINE> vert = self . orient == <STRING> <NEWLINE> <NEWLINE> for i , group_data in enumerate ( self . plot_data ) : <NEWLINE> <NEWLINE> <TAB> if self . plot_hues is None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if group_data . size == <NUMBER> : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> box_data = remove_na ( group_data ) <NEWLINE> <NEWLINE> <NEWLINE> if box_data . size == <NUMBER> : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> color = self . colors [ i ] <NEWLINE> <NEWLINE> self . _lvplot ( box_data , <NEWLINE> positions = [ i ] , <NEWLINE> color = color , <NEWLINE> vert = vert , <NEWLINE> widths = self . width , <NEWLINE> k_depth = self . k_depth , <NEWLINE> ax = ax , <NEWLINE> scale = self . scale , <NEWLINE> outlier_prop = self . outlier_prop , <NEWLINE> ** kws ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> offsets = self . hue_offsets <NEWLINE> for j , hue_level in enumerate ( self . hue_names ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if not i : <NEWLINE> <TAB> self . add_legend_data ( ax , self . colors [ j ] , hue_level ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if group_data . size == <NUMBER> : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> hue_mask = self . plot_hues [ i ] == hue_level <NEWLINE> box_data = remove_na ( group_data [ hue_mask ] ) <NEWLINE> <NEWLINE> <NEWLINE> if box_data . size == <NUMBER> : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> color = self . colors [ j ] <NEWLINE> center = i + offsets [ j ] <NEWLINE> self . _lvplot ( box_data , <NEWLINE> positions = [ center ] , <NEWLINE> color = color , <NEWLINE> vert = vert , <NEWLINE> widths = self . nested_width , <NEWLINE> k_depth = self . k_depth , <NEWLINE> ax = ax , <NEWLINE> scale = self . scale , <NEWLINE> outlier_prop = self . outlier_prop , <NEWLINE> ** kws ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_bool_data ( self , copy = False ) : <NEWLINE> <TAB> <NEWLINE> self . _consolidate_inplace ( ) <NEWLINE> return self . combine ( [ b for b in self . blocks if b . is_bool ] , copy ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> def weighted_choice ( mapping , seed = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> rnd = seed . random ( ) * sum ( mapping . values ( ) ) <NEWLINE> for k , w in mapping . items ( ) : <NEWLINE> <TAB> rnd -= w <NEWLINE> if rnd < <NUMBER> : <NEWLINE> <TAB> return k <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def transformed ( self , transform ) : <NEWLINE> <TAB> <NEWLINE> pts = self . get_points ( ) <NEWLINE> ll , ul , lr = transform . transform ( np . array ( [ pts [ <NUMBER> ] , <NEWLINE> [ pts [ <NUMBER> , <NUMBER> ] , pts [ <NUMBER> , <NUMBER> ] ] , [ pts [ <NUMBER> , <NUMBER> ] , pts [ <NUMBER> , <NUMBER> ] ] ] ) ) <NEWLINE> return Bbox ( [ ll , [ lr [ <NUMBER> ] , ul [ <NUMBER> ] ] ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _has ( self , pattern ) : <NEWLINE> <TAB> <NEWLINE> from sympy . core . function import UndefinedFunction , Function <NEWLINE> if isinstance ( pattern , UndefinedFunction ) : <NEWLINE> <TAB> return any ( f . func == pattern or f == pattern <NEWLINE> for f in self . atoms ( Function , UndefinedFunction ) ) <NEWLINE> <NEWLINE> <UNTAB> pattern = sympify ( pattern ) <NEWLINE> if isinstance ( pattern , BasicMeta ) : <NEWLINE> <TAB> return any ( isinstance ( arg , pattern ) <NEWLINE> for arg in preorder_traversal ( self ) ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> match = pattern . _has_matcher ( ) <NEWLINE> return any ( match ( arg ) for arg in preorder_traversal ( self ) ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> return any ( arg == pattern for arg in preorder_traversal ( self ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def monomial_count ( V , N ) : <NEWLINE> <TAB> <NEWLINE> from sympy import factorial <NEWLINE> return factorial ( V + N ) / factorial ( V ) / factorial ( N ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_gradients ( self , loss , params ) : <NEWLINE> <TAB> <NEWLINE> grads = K . gradients ( loss , params ) <NEWLINE> if None in grads : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if hasattr ( self , <STRING> ) : <NEWLINE> <TAB> grads = [ clip_ops . clip_by_norm ( g , self . clipnorm ) for g in grads ] <NEWLINE> <UNTAB> if hasattr ( self , <STRING> ) : <NEWLINE> <TAB> grads = [ <NEWLINE> clip_ops . clip_by_value ( g , - self . clipvalue , self . clipvalue ) <NEWLINE> for g in grads <NEWLINE> ] <NEWLINE> <UNTAB> return grads <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_notna_col_dtype ( self , col ) : <NEWLINE> <TAB> <NEWLINE> col_for_inference = col <NEWLINE> if col . dtype == <STRING> : <NEWLINE> <TAB> notnadata = col [ ~ isna ( col ) ] <NEWLINE> if len ( notnadata ) : <NEWLINE> <TAB> col_for_inference = notnadata <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return lib . infer_dtype ( col_for_inference ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_dashlength ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _dashlength <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _setup_residual_graph ( G , weight ) : <NEWLINE> <TAB> <NEWLINE> residual_graph = G . copy ( ) <NEWLINE> <NEWLINE> <NEWLINE> for u , v in G . edges ( ) : <NEWLINE> <TAB> if not weight : <NEWLINE> <TAB> residual_graph [ u ] [ v ] [ <STRING> ] = ( id ( u ) , id ( v ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> residual_graph [ u ] [ v ] [ <STRING> ] = ( G [ u ] [ v ] [ weight ] , id ( u ) , id ( v ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return residual_graph <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_ctypes ( obj ) : <NEWLINE> <TAB> <NEWLINE> ai = obj . __array_interface__ <NEWLINE> if ai [ <STRING> ] : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if ai [ <STRING> ] != <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> addr , readonly = ai [ <STRING> ] <NEWLINE> if readonly : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> tp = _typecodes [ ai [ <STRING> ] ] <NEWLINE> for dim in ai [ <STRING> ] [ : : - <NUMBER> ] : <NEWLINE> <TAB> tp = tp * dim <NEWLINE> <UNTAB> result = tp . from_address ( addr ) <NEWLINE> result . __keep = ai <NEWLINE> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def qmf ( hk ) : <NEWLINE> <TAB> <NEWLINE> N = len ( hk ) - <NUMBER> <NEWLINE> asgn = [ { <NUMBER> : <NUMBER> , <NUMBER> : - <NUMBER> } [ k % <NUMBER> ] for k in range ( N + <NUMBER> ) ] <NEWLINE> return hk [ : : - <NUMBER> ] * np . array ( asgn ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _fix_real_abs_gt_1 ( x ) : <NEWLINE> <TAB> <NEWLINE> x = asarray ( x ) <NEWLINE> if any ( isreal ( x ) & ( abs ( x ) > <NUMBER> ) ) : <NEWLINE> <TAB> x = _tocomplex ( x ) <NEWLINE> <UNTAB> return x <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def concat_examples ( batch , device = None , padding = None ) : <NEWLINE> <TAB> <NEWLINE> if len ( batch ) == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> first_elem = batch [ <NUMBER> ] <NEWLINE> <NEWLINE> if isinstance ( first_elem , tuple ) : <NEWLINE> <TAB> result = [ ] <NEWLINE> if not isinstance ( padding , tuple ) : <NEWLINE> <TAB> padding = [ padding ] * len ( first_elem ) <NEWLINE> <NEWLINE> <UNTAB> for i in six . moves . range ( len ( first_elem ) ) : <NEWLINE> <TAB> result . append ( to_device ( device , _concat_arrays ( <NEWLINE> [ example [ i ] for example in batch ] , padding [ i ] ) ) ) <NEWLINE> <NEWLINE> <UNTAB> return tuple ( result ) <NEWLINE> <NEWLINE> <UNTAB> elif isinstance ( first_elem , dict ) : <NEWLINE> <TAB> result = { } <NEWLINE> if not isinstance ( padding , dict ) : <NEWLINE> <TAB> padding = { key : padding for key in first_elem } <NEWLINE> <NEWLINE> <UNTAB> for key in first_elem : <NEWLINE> <TAB> result [ key ] = to_device ( device , _concat_arrays ( <NEWLINE> [ example [ key ] for example in batch ] , padding [ key ] ) ) <NEWLINE> <NEWLINE> <UNTAB> return result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return to_device ( device , _concat_arrays ( batch , padding ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _convert_for_op ( self , value ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if is_bool ( value ) or is_bool_dtype ( value ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> raise TypeError <NEWLINE> <NEWLINE> <UNTAB> return value <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def limit_seq ( expr , n = None , trials = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if n is None : <NEWLINE> <TAB> free = expr . free_symbols <NEWLINE> if len ( free ) == <NUMBER> : <NEWLINE> <TAB> n = free . pop ( ) <NEWLINE> <UNTAB> elif not free : <NEWLINE> <TAB> return expr <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % ( expr ) ) <NEWLINE> <UNTAB> <UNTAB> elif n not in expr . free_symbols : <NEWLINE> <TAB> return expr <NEWLINE> <NEWLINE> <UNTAB> n_ = Dummy ( <STRING> , integer = True , positive = True ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> powers = ( p . as_base_exp ( ) for p in expr . atoms ( Pow ) ) <NEWLINE> if any ( b . is_negative and e . has ( n ) for b , e in powers ) : <NEWLINE> <TAB> L1 = _limit_seq ( expr . xreplace ( { n : <NUMBER> * n_ } ) , n_ , trials ) <NEWLINE> if L1 is not None : <NEWLINE> <TAB> L2 = _limit_seq ( expr . xreplace ( { n : <NUMBER> * n_ + <NUMBER> } ) , n_ , trials ) <NEWLINE> if L1 == L2 : <NEWLINE> <TAB> return L1 <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return _limit_seq ( expr . xreplace ( { n : n_ } ) , n_ , trials ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def inverse_transform ( self , y ) : <NEWLINE> <TAB> <NEWLINE> check_is_fitted ( self , <STRING> ) <NEWLINE> y = column_or_1d ( y , warn = True ) <NEWLINE> <NEWLINE> if _num_samples ( y ) == <NUMBER> : <NEWLINE> <TAB> return np . array ( [ ] ) <NEWLINE> <NEWLINE> <UNTAB> diff = np . setdiff1d ( y , np . arange ( len ( self . classes_ ) ) ) <NEWLINE> if len ( diff ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % str ( diff ) ) <NEWLINE> <UNTAB> y = np . asarray ( y ) <NEWLINE> return self . classes_ [ y ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_offsets ( self , xy ) : <NEWLINE> <TAB> <NEWLINE> self . x = xy [ : , <NUMBER> ] <NEWLINE> self . y = xy [ : , <NUMBER> ] <NEWLINE> x , y , u , v = delete_masked_points ( self . x . ravel ( ) , self . y . ravel ( ) , <NEWLINE> self . u , self . v ) <NEWLINE> _check_consistent_shapes ( x , y , u , v ) <NEWLINE> xy = np . column_stack ( ( x , y ) ) <NEWLINE> mcollections . PolyCollection . set_offsets ( self , xy ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def is_dtype ( cls , dtype ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( dtype , compat . string_types ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if dtype . startswith ( <STRING> ) or dtype . startswith ( <STRING> ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> if cls . _parse_dtype_strict ( dtype ) is not None : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> except ValueError : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> return super ( PeriodDtype , cls ) . is_dtype ( dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def stripped_op_list_for_graph ( graph_def ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> used_ops = ops_used_by_graph_def ( graph_def ) <NEWLINE> <NEWLINE> <NEWLINE> registered_ops = op_def_registry . get_registered_ops ( ) <NEWLINE> <NEWLINE> <NEWLINE> op_whitelist = ( <STRING> , <STRING> , <STRING> , <STRING> ) <NEWLINE> for op in used_ops : <NEWLINE> <TAB> if op not in registered_ops and op not in op_whitelist : <NEWLINE> <TAB> raise ValueError ( <STRING> % op ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return op_def_pb2 . OpList ( op = [ registered_ops [ op ] for op in sorted ( used_ops ) <NEWLINE> if op in registered_ops ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def mvsdist ( data ) : <NEWLINE> <TAB> <NEWLINE> x = ravel ( data ) <NEWLINE> n = len ( x ) <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> xbar = x . mean ( ) <NEWLINE> C = x . var ( ) <NEWLINE> if n > <NUMBER> : <NEWLINE> <TAB> mdist = distributions . norm ( loc = xbar , scale = math . sqrt ( C / n ) ) <NEWLINE> sdist = distributions . norm ( loc = math . sqrt ( C ) , scale = math . sqrt ( C / ( <NUMBER> * n ) ) ) <NEWLINE> vdist = distributions . norm ( loc = C , scale = math . sqrt ( <NUMBER> / n ) * C ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nm1 = n - <NUMBER> <NEWLINE> fac = n * C / <NUMBER> <NEWLINE> val = nm1 / <NUMBER> <NEWLINE> mdist = distributions . t ( nm1 , loc = xbar , scale = math . sqrt ( C / nm1 ) ) <NEWLINE> sdist = distributions . gengamma ( val , - <NUMBER> , scale = math . sqrt ( fac ) ) <NEWLINE> vdist = distributions . invgamma ( val , scale = fac ) <NEWLINE> <UNTAB> return mdist , vdist , sdist <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def tk_setPalette ( self , * args , ** kw ) : <NEWLINE> <TAB> <NEWLINE> self . tk . call ( ( <STRING> , ) <NEWLINE> + _flatten ( args ) + _flatten ( list ( kw . items ( ) ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def variable_labels ( self ) : <NEWLINE> <TAB> <NEWLINE> return dict ( zip ( self . varlist , self . _variable_labels ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _check_1d ( x ) : <NEWLINE> <TAB> <NEWLINE> if not hasattr ( x , <STRING> ) or len ( x . shape ) < <NUMBER> : <NEWLINE> <TAB> return np . atleast_1d ( x ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> x [ : , None ] <NEWLINE> return x <NEWLINE> <UNTAB> except ( IndexError , TypeError ) : <NEWLINE> <TAB> return np . atleast_1d ( x ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def local_add_mul_fusion ( node ) : <NEWLINE> <TAB> <NEWLINE> if ( not isinstance ( node . op , Elemwise ) or <NEWLINE> not isinstance ( node . op . scalar_op , ( scalar . Add , scalar . Mul ) ) ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> s_op = node . op . scalar_op . __class__ <NEWLINE> new_inp = [ ] <NEWLINE> fused = False <NEWLINE> nb_inputs = len ( node . inputs ) <NEWLINE> max_inputs = float ( <STRING> ) <NEWLINE> if hasattr ( node . op , <STRING> ) : <NEWLINE> <TAB> max_inputs = node . op . max_inputs ( node ) <NEWLINE> <UNTAB> for inp in node . inputs : <NEWLINE> <TAB> if ( inp . owner and <NEWLINE> isinstance ( inp . owner . op , Elemwise ) and <NEWLINE> isinstance ( inp . owner . op . scalar_op , s_op ) and <NEWLINE> <NEWLINE> len ( inp . clients ) == <NUMBER> and <NEWLINE> ( nb_inputs + len ( inp . owner . inputs ) - <NUMBER> ) <= max_inputs ) : <NEWLINE> <TAB> new_inp . extend ( inp . owner . inputs ) <NEWLINE> fused = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> new_inp . append ( inp ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if fused : <NEWLINE> <TAB> output = node . op ( * new_inp ) <NEWLINE> copy_stack_trace ( node . outputs [ <NUMBER> ] , output ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if output . owner : <NEWLINE> <TAB> output2 = local_add_mul_fusion ( output . owner ) <NEWLINE> if output2 : <NEWLINE> <TAB> return output2 <NEWLINE> <UNTAB> <UNTAB> return [ output ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _scale_loss ( loss_value , scale_loss_by_num_replicas ) : <NEWLINE> <TAB> <NEWLINE> if scale_loss_by_num_replicas is None : <NEWLINE> <TAB> scale_loss_by_num_replicas = ( <NEWLINE> distribute_lib . get_loss_reduction ( ) == variable_scope <NEWLINE> . VariableAggregation . MEAN ) <NEWLINE> <UNTAB> if scale_loss_by_num_replicas : <NEWLINE> <TAB> num_replicas = distribute_ctx . get_distribution_strategy ( ) . num_replicas_in_sync <NEWLINE> if num_replicas > <NUMBER> : <NEWLINE> <TAB> loss_value *= <NUMBER> / num_replicas <NEWLINE> <UNTAB> <UNTAB> return loss_value <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_rgb ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _rgb <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _multi_svd_norm ( x , row_axis , col_axis , op ) : <NEWLINE> <TAB> <NEWLINE> y = moveaxis ( x , ( row_axis , col_axis ) , ( - <NUMBER> , - <NUMBER> ) ) <NEWLINE> result = op ( svd ( y , compute_uv = <NUMBER> ) , axis = - <NUMBER> ) <NEWLINE> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def sincos_to_sum ( expr ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not expr . has ( cos , sin ) : <NEWLINE> <TAB> return expr <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return TR8 ( expand_mul ( TRpower ( expr ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_valid_values ( self , attr ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> name = <STRING> % attr <NEWLINE> if not hasattr ( self . o , name ) : <NEWLINE> <TAB> raise AttributeError ( <STRING> % ( self . o , name ) ) <NEWLINE> <UNTAB> func = getattr ( self . o , name ) <NEWLINE> <NEWLINE> docstring = func . __doc__ <NEWLINE> if docstring is None : <NEWLINE> <TAB> return <STRING> <NEWLINE> <NEWLINE> <UNTAB> if docstring . startswith ( <STRING> ) : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> match = self . _get_valid_values_regex . search ( docstring ) <NEWLINE> if match is not None : <NEWLINE> <TAB> return re . sub ( <STRING> , <STRING> , match . group ( <NUMBER> ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> param_name = func . __code__ . co_varnames [ <NUMBER> ] <NEWLINE> match = re . search ( <STRING> . format ( param_name ) , docstring ) <NEWLINE> if match : <NEWLINE> <TAB> return match . group ( <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> return <STRING> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _slow_pivot ( index , columns , values ) : <NEWLINE> <TAB> <NEWLINE> tree = { } <NEWLINE> for i , ( idx , col ) in enumerate ( zip ( index , columns ) ) : <NEWLINE> <TAB> if col not in tree : <NEWLINE> <TAB> tree [ col ] = { } <NEWLINE> <UNTAB> branch = tree [ col ] <NEWLINE> branch [ idx ] = values [ i ] <NEWLINE> <NEWLINE> <UNTAB> return DataFrame ( tree ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _mareconstruct ( subtype , baseclass , baseshape , basetype , ) : <NEWLINE> <TAB> <NEWLINE> _data = ndarray . __new__ ( baseclass , baseshape , basetype ) <NEWLINE> _mask = ndarray . __new__ ( ndarray , baseshape , make_mask_descr ( basetype ) ) <NEWLINE> return subtype . __new__ ( subtype , _data , mask = _mask , dtype = basetype , ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def abs_rel_err ( a , b ) : <NEWLINE> <TAB> <NEWLINE> abs_err = abs ( a - b ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> rel_err = abs_err / np . maximum ( abs ( a ) + abs ( b ) , [ <NUMBER> ] ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> abs_err = np . asarray ( abs_err ) <NEWLINE> rel_err = np . asarray ( rel_err ) <NEWLINE> return ( abs_err , rel_err ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def keys ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _info_axis <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def tensorproduct ( * args ) : <NEWLINE> <TAB> <NEWLINE> if len ( args ) == <NUMBER> : <NEWLINE> <TAB> return S . One <NEWLINE> <UNTAB> if len ( args ) == <NUMBER> : <NEWLINE> <TAB> return _arrayfy ( args [ <NUMBER> ] ) <NEWLINE> <UNTAB> if len ( args ) > <NUMBER> : <NEWLINE> <TAB> return tensorproduct ( tensorproduct ( args [ <NUMBER> ] , args [ <NUMBER> ] ) , * args [ <NUMBER> : ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> a , b = map ( _arrayfy , args ) <NEWLINE> <NEWLINE> if not isinstance ( a , NDimArray ) or not isinstance ( b , NDimArray ) : <NEWLINE> <TAB> return a * b <NEWLINE> <NEWLINE> <UNTAB> al = list ( a ) <NEWLINE> bl = list ( b ) <NEWLINE> <NEWLINE> product_list = [ i * j for i in al for j in bl ] <NEWLINE> return ImmutableDenseNDimArray ( product_list , a . shape + b . shape ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _assert_safe_casting ( cls , data , subarr ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def ppf ( self , q , * args , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> args , loc , _ = self . _parse_args ( * args , ** kwds ) <NEWLINE> q , loc = map ( asarray , ( q , loc ) ) <NEWLINE> args = tuple ( map ( asarray , args ) ) <NEWLINE> cond0 = self . _argcheck ( * args ) & ( loc == loc ) <NEWLINE> cond1 = ( q > <NUMBER> ) & ( q < <NUMBER> ) <NEWLINE> cond2 = ( q == <NUMBER> ) & cond0 <NEWLINE> cond = cond0 & cond1 <NEWLINE> output = valarray ( shape ( cond ) , value = self . badvalue , typecode = <STRING> ) <NEWLINE> <NEWLINE> place ( output , ( q == <NUMBER> ) * ( cond == cond ) , self . a - <NUMBER> ) <NEWLINE> place ( output , cond2 , self . b ) <NEWLINE> if np . any ( cond ) : <NEWLINE> <TAB> goodargs = argsreduce ( cond , * ( ( q , ) + args + ( loc , ) ) ) <NEWLINE> loc , goodargs = goodargs [ - <NUMBER> ] , goodargs [ : - <NUMBER> ] <NEWLINE> place ( output , cond , self . _ppf ( * goodargs ) + loc ) <NEWLINE> <NEWLINE> <UNTAB> if output . ndim == <NUMBER> : <NEWLINE> <TAB> return output [ ( ) ] <NEWLINE> <UNTAB> return output <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def import_nose ( ) : <NEWLINE> <TAB> <NEWLINE> nose_is_good = True <NEWLINE> minimum_nose_version = ( <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> try : <NEWLINE> <TAB> import nose <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> nose_is_good = False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if nose . __versioninfo__ < minimum_nose_version : <NEWLINE> <TAB> nose_is_good = False <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not nose_is_good : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> % <NEWLINE> minimum_nose_version ) <NEWLINE> raise ImportError ( msg ) <NEWLINE> <NEWLINE> <UNTAB> return nose <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def clear_collection ( self , name ) : <NEWLINE> <TAB> <NEWLINE> self . _check_not_finalized ( ) <NEWLINE> with self . _lock : <NEWLINE> <TAB> if name in self . _collections : <NEWLINE> <TAB> del self . _collections [ name ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def face ( gray = False ) : <NEWLINE> <TAB> <NEWLINE> import bz2 <NEWLINE> import os <NEWLINE> with open ( os . path . join ( os . path . dirname ( __file__ ) , <STRING> ) , <STRING> ) as f : <NEWLINE> <TAB> rawdata = f . read ( ) <NEWLINE> <UNTAB> data = bz2 . decompress ( rawdata ) <NEWLINE> face = frombuffer ( data , dtype = <STRING> ) <NEWLINE> face . shape = ( <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> if gray is True : <NEWLINE> <TAB> face = ( <NUMBER> * face [ : , : , <NUMBER> ] + <NUMBER> * face [ : , : , <NUMBER> ] + <NUMBER> * face [ : , : , <NUMBER> ] ) . astype ( <STRING> ) <NEWLINE> <UNTAB> return face <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def binarize ( X , threshold = <NUMBER> , copy = True ) : <NEWLINE> <TAB> <NEWLINE> X = check_array ( X , accept_sparse = [ <STRING> , <STRING> ] , copy = copy ) <NEWLINE> if sparse . issparse ( X ) : <NEWLINE> <TAB> if threshold < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> cond = X . data > threshold <NEWLINE> not_cond = np . logical_not ( cond ) <NEWLINE> X . data [ cond ] = <NUMBER> <NEWLINE> X . data [ not_cond ] = <NUMBER> <NEWLINE> X . eliminate_zeros ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cond = X > threshold <NEWLINE> not_cond = np . logical_not ( cond ) <NEWLINE> X [ cond ] = <NUMBER> <NEWLINE> X [ not_cond ] = <NUMBER> <NEWLINE> <UNTAB> return X <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def sparse_cross_hashed ( inputs , num_buckets = <NUMBER> , hash_key = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> return _sparse_cross_internal ( <NEWLINE> inputs = inputs , <NEWLINE> hashed_output = True , <NEWLINE> num_buckets = num_buckets , <NEWLINE> hash_key = hash_key , <NEWLINE> name = name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def make_surface ( array ) : <NEWLINE> <TAB> <NEWLINE> return numpysf . make_surface ( array ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _set_self ( self , other , copy = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if copy : <NEWLINE> <TAB> other = other . copy ( ) <NEWLINE> <NEWLINE> <UNTAB> self . data = other . data <NEWLINE> self . indices = other . indices <NEWLINE> self . indptr = other . indptr <NEWLINE> self . _shape = check_shape ( other . shape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( None , <STRING> ) <NEWLINE> def extend_export_strategy ( base_export_strategy , <NEWLINE> post_export_fn , <NEWLINE> post_export_name = None ) : <NEWLINE> <TAB> <NEWLINE> def export_fn ( estimator , export_dir_base , checkpoint_path = None ) : <NEWLINE> <TAB> <NEWLINE> tmp_base_export_folder = <STRING> + str ( int ( time . time ( ) ) ) <NEWLINE> tmp_base_export_dir = os . path . join ( export_dir_base , tmp_base_export_folder ) <NEWLINE> if gfile . Exists ( tmp_base_export_dir ) : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> gfile . MakeDirs ( tmp_base_export_dir ) <NEWLINE> tmp_base_export = base_export_strategy . export ( <NEWLINE> estimator , tmp_base_export_dir , checkpoint_path ) <NEWLINE> <NEWLINE> tmp_post_export_folder = <STRING> + str ( int ( time . time ( ) ) ) <NEWLINE> tmp_post_export_dir = os . path . join ( export_dir_base , tmp_post_export_folder ) <NEWLINE> if gfile . Exists ( tmp_post_export_dir ) : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> gfile . MakeDirs ( tmp_post_export_dir ) <NEWLINE> tmp_post_export = post_export_fn ( tmp_base_export , tmp_post_export_dir ) <NEWLINE> <NEWLINE> if not tmp_post_export . startswith ( tmp_post_export_dir ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> . format ( tmp_post_export_dir ) ) <NEWLINE> <UNTAB> post_export_relpath = os . path . relpath ( tmp_post_export , tmp_post_export_dir ) <NEWLINE> post_export = os . path . join ( export_dir_base , post_export_relpath ) <NEWLINE> if gfile . Exists ( post_export ) : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> gfile . Rename ( tmp_post_export , post_export ) <NEWLINE> <NEWLINE> gfile . DeleteRecursively ( tmp_base_export_dir ) <NEWLINE> gfile . DeleteRecursively ( tmp_post_export_dir ) <NEWLINE> return post_export <NEWLINE> <NEWLINE> <UNTAB> name = post_export_name if post_export_name else base_export_strategy . name <NEWLINE> return export_strategy . ExportStrategy ( name , export_fn ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def drop_duplicates ( self , keep = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return super ( Index , self ) . drop_duplicates ( keep = keep ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def view ( self ) : <NEWLINE> <TAB> <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def on_key_press ( self , event ) : <NEWLINE> <TAB> <NEWLINE> if self . active : <NEWLINE> <TAB> key = event . key or <STRING> <NEWLINE> key = key . replace ( <STRING> , <STRING> ) <NEWLINE> if key == self . state_modifier_keys [ <STRING> ] : <NEWLINE> <TAB> for artist in self . artists : <NEWLINE> <TAB> artist . set_visible ( False ) <NEWLINE> <UNTAB> self . update ( ) <NEWLINE> return <NEWLINE> <UNTAB> for ( state , modifier ) in self . state_modifier_keys . items ( ) : <NEWLINE> <TAB> if modifier in key : <NEWLINE> <TAB> self . state . add ( state ) <NEWLINE> <UNTAB> <UNTAB> self . _on_key_press ( event ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def feature_usage_counts_eager_fallback ( tree_handle , params , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> params = _execute . make_str ( params , <STRING> ) <NEWLINE> tree_handle = _ops . convert_to_tensor ( tree_handle , _dtypes . resource ) <NEWLINE> _inputs_flat = [ tree_handle ] <NEWLINE> _attrs = ( <STRING> , params ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _update_label_position ( self , renderer ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> , <STRING> ) <NEWLINE> def is_strongly_regular ( G ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> return is_distance_regular ( G ) and diameter ( G ) == <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def deltaE_cie76 ( lab1 , lab2 ) : <NEWLINE> <TAB> <NEWLINE> lab1 = np . asarray ( lab1 ) <NEWLINE> lab2 = np . asarray ( lab2 ) <NEWLINE> L1 , a1 , b1 = np . rollaxis ( lab1 , - <NUMBER> ) [ : <NUMBER> ] <NEWLINE> L2 , a2 , b2 = np . rollaxis ( lab2 , - <NUMBER> ) [ : <NUMBER> ] <NEWLINE> return np . sqrt ( ( L2 - L1 ) ** <NUMBER> + ( a2 - a1 ) ** <NUMBER> + ( b2 - b1 ) ** <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _align_method_FRAME ( left , right , axis ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def to_series ( right ) : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> if axis is not None and left . _get_axis_name ( axis ) == <STRING> : <NEWLINE> <TAB> if len ( left . index ) != len ( right ) : <NEWLINE> <TAB> raise ValueError ( msg . format ( req_len = len ( left . index ) , <NEWLINE> given_len = len ( right ) ) ) <NEWLINE> <UNTAB> right = left . _constructor_sliced ( right , index = left . index ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if len ( left . columns ) != len ( right ) : <NEWLINE> <TAB> raise ValueError ( msg . format ( req_len = len ( left . columns ) , <NEWLINE> given_len = len ( right ) ) ) <NEWLINE> <UNTAB> right = left . _constructor_sliced ( right , index = left . columns ) <NEWLINE> <UNTAB> return right <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( right , np . ndarray ) : <NEWLINE> <NEWLINE> <TAB> if right . ndim == <NUMBER> : <NEWLINE> <TAB> right = to_series ( right ) <NEWLINE> <NEWLINE> <UNTAB> elif right . ndim == <NUMBER> : <NEWLINE> <TAB> if left . shape != right . shape : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> . format ( req_shape = left . shape , <NEWLINE> given_shape = right . shape ) ) <NEWLINE> <NEWLINE> <UNTAB> right = left . _constructor ( right , index = left . index , <NEWLINE> columns = left . columns ) <NEWLINE> <UNTAB> elif right . ndim > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( dim = right . shape ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif ( is_list_like ( right ) and <NEWLINE> not isinstance ( right , ( ABCSeries , ABCDataFrame ) ) ) : <NEWLINE> <NEWLINE> <TAB> right = to_series ( right ) <NEWLINE> <NEWLINE> <UNTAB> return right <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_adjustable ( self , adjustable , share = False ) : <NEWLINE> <TAB> <NEWLINE> if adjustable == <STRING> : <NEWLINE> <TAB> cbook . warn_deprecated ( <NEWLINE> <STRING> , <STRING> , obj_type = <STRING> ) <NEWLINE> <UNTAB> if adjustable not in ( <STRING> , <STRING> , <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if share : <NEWLINE> <TAB> axes = set ( self . _shared_x_axes . get_siblings ( self ) <NEWLINE> + self . _shared_y_axes . get_siblings ( self ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> axes = [ self ] <NEWLINE> <UNTAB> for ax in axes : <NEWLINE> <TAB> ax . _adjustable = adjustable <NEWLINE> <UNTAB> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_id ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . id <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def nsimplify ( self , constants = [ ] , tolerance = None , full = False ) : <NEWLINE> <TAB> <NEWLINE> from sympy . simplify import nsimplify <NEWLINE> return nsimplify ( self , constants , tolerance , full ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gf_to_int_poly ( f , p , symmetric = True ) : <NEWLINE> <TAB> <NEWLINE> if symmetric : <NEWLINE> <TAB> return [ gf_int ( c , p ) for c in f ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return f <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sign ( x ) : <NEWLINE> <TAB> <NEWLINE> return tf . sign ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def in_train_phase ( x , alt , training = None ) : <NEWLINE> <TAB> <NEWLINE> if training is None : <NEWLINE> <TAB> training = learning_phase ( ) <NEWLINE> uses_learning_phase = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> uses_learning_phase = False <NEWLINE> <NEWLINE> <UNTAB> if training is <NUMBER> or training is True : <NEWLINE> <TAB> if callable ( x ) : <NEWLINE> <TAB> return x ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return x <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif training is <NUMBER> or training is False : <NEWLINE> <TAB> if callable ( alt ) : <NEWLINE> <TAB> return alt ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return alt <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> x = switch ( training , x , alt ) <NEWLINE> if uses_learning_phase : <NEWLINE> <TAB> x . _uses_learning_phase = True <NEWLINE> <UNTAB> return x <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def tvar ( a , limits = None , inclusive = ( True , True ) , axis = <NUMBER> , ddof = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> a = a . astype ( float ) . ravel ( ) <NEWLINE> if limits is None : <NEWLINE> <TAB> n = ( ~ a . mask ) . sum ( ) <NEWLINE> return np . ma . var ( a ) * n / ( n - <NUMBER> ) <NEWLINE> <UNTAB> am = _mask_to_limits ( a , limits = limits , inclusive = inclusive ) <NEWLINE> <NEWLINE> return np . ma . var ( am , axis = axis , ddof = ddof ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def inverse ( self , argindex = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return erf <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _permute_complexity_right ( self , iszerofunc ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def complexity ( i ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return sum ( <NUMBER> if iszerofunc ( e ) is None else <NUMBER> for e in self [ : , i ] ) <NEWLINE> <UNTAB> complex = [ ( complexity ( i ) , i ) for i in range ( self . cols ) ] <NEWLINE> perm = [ j for ( i , j ) in sorted ( complex ) ] <NEWLINE> <NEWLINE> return ( self . permute ( perm , orientation = <STRING> ) , perm ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def selection ( self , ref ) : <NEWLINE> <TAB> <NEWLINE> from . import selections <NEWLINE> with phil : <NEWLINE> <TAB> sid = h5r . get_region ( ref , self . id ) <NEWLINE> return selections . guess_shape ( sid ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def flat_transforms_to_matrices ( transforms ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( <STRING> ) : <NEWLINE> <TAB> transforms = ops . convert_to_tensor ( transforms , name = <STRING> ) <NEWLINE> if transforms . shape . ndims not in ( <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> % transforms ) <NEWLINE> <NEWLINE> <UNTAB> transforms = array_ops . reshape ( transforms , constant_op . constant ( [ - <NUMBER> , <NUMBER> ] ) ) <NEWLINE> num_transforms = array_ops . shape ( transforms ) [ <NUMBER> ] <NEWLINE> <NEWLINE> return array_ops . reshape ( <NEWLINE> array_ops . concat ( <NEWLINE> [ transforms , array_ops . ones ( [ num_transforms , <NUMBER> ] ) ] , axis = <NUMBER> ) , <NEWLINE> constant_op . constant ( [ - <NUMBER> , <NUMBER> , <NUMBER> ] ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def max_pool3d_grad ( orig_input , orig_output , grad , ksize , strides , padding , data_format = <STRING> , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if not isinstance ( ksize , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ksize ) <NEWLINE> <UNTAB> ksize = [ _execute . make_int ( _i , <STRING> ) for _i in ksize ] <NEWLINE> if not isinstance ( strides , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % strides ) <NEWLINE> <UNTAB> strides = [ _execute . make_int ( _i , <STRING> ) for _i in strides ] <NEWLINE> padding = _execute . make_str ( padding , <STRING> ) <NEWLINE> if data_format is None : <NEWLINE> <TAB> data_format = <STRING> <NEWLINE> <UNTAB> data_format = _execute . make_str ( data_format , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , orig_input = orig_input , orig_output = orig_output , <NEWLINE> grad = grad , ksize = ksize , strides = strides , padding = padding , <NEWLINE> data_format = data_format , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) , <NEWLINE> <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , orig_input , <NEWLINE> orig_output , grad , <STRING> , ksize , <STRING> , strides , <STRING> , <NEWLINE> padding , <STRING> , data_format ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return max_pool3d_grad_eager_fallback ( <NEWLINE> orig_input , orig_output , grad , ksize = ksize , strides = strides , <NEWLINE> padding = padding , data_format = data_format , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def arbitrary_point ( self , u = None , v = None ) : <NEWLINE> <TAB> <NEWLINE> circle = v is None <NEWLINE> if circle : <NEWLINE> <TAB> u = _symbol ( u or <STRING> , real = True ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> u = _symbol ( u or <STRING> , real = True ) <NEWLINE> v = _symbol ( v or <STRING> , real = True ) <NEWLINE> <UNTAB> x , y , z = self . normal_vector <NEWLINE> a , b , c = self . p1 . args <NEWLINE> <NEWLINE> if x . is_zero and y . is_zero : <NEWLINE> <TAB> x1 , y1 , z1 = S . One , S . Zero , S . Zero <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x1 , y1 , z1 = - y , x , S . Zero <NEWLINE> <NEWLINE> <UNTAB> x2 , y2 , z2 = tuple ( Matrix ( ( x , y , z ) ) . cross ( Matrix ( ( x1 , y1 , z1 ) ) ) ) <NEWLINE> if circle : <NEWLINE> <TAB> x1 , y1 , z1 = ( w / sqrt ( x1 ** <NUMBER> + y1 ** <NUMBER> + z1 ** <NUMBER> ) for w in ( x1 , y1 , z1 ) ) <NEWLINE> x2 , y2 , z2 = ( w / sqrt ( x2 ** <NUMBER> + y2 ** <NUMBER> + z2 ** <NUMBER> ) for w in ( x2 , y2 , z2 ) ) <NEWLINE> p = Point3D ( a + x1 * cos ( u ) + x2 * sin ( u ) , b + y1 * cos ( u ) + y2 * sin ( u ) , c + z1 * cos ( u ) + z2 * sin ( u ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> p = Point3D ( a + x1 * u + x2 * v , b + y1 * u + y2 * v , c + z1 * u + z2 * v ) <NEWLINE> <UNTAB> return p <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def deepfirst ( seq ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( seq , ( list , tuple ) ) : <NEWLINE> <TAB> return seq <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return deepfirst ( seq [ <NUMBER> ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def param_static_shapes ( cls , sample_shape ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( sample_shape , tensor_shape . TensorShape ) : <NEWLINE> <TAB> if not sample_shape . is_fully_defined ( ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> sample_shape = sample_shape . as_list ( ) <NEWLINE> <NEWLINE> <UNTAB> params = cls . param_shapes ( sample_shape ) <NEWLINE> <NEWLINE> static_params = { } <NEWLINE> for name , shape in params . items ( ) : <NEWLINE> <TAB> static_shape = tensor_util . constant_value ( shape ) <NEWLINE> if static_shape is None : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> static_params [ name ] = tensor_shape . TensorShape ( static_shape ) <NEWLINE> <NEWLINE> <UNTAB> return static_params <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def run ( verbosity = <NUMBER> , doctest = False , numpy = True ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> import nose <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> raise ImportError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> sys . stderr . write ( <STRING> ) <NEWLINE> nx_install_dir = path . join ( path . dirname ( __file__ ) , path . pardir ) <NEWLINE> <NEWLINE> if getcwd ( ) == path . abspath ( path . join ( nx_install_dir , path . pardir ) ) : <NEWLINE> <TAB> raise RuntimeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> argv = [ <STRING> , <STRING> % verbosity , <NEWLINE> <STRING> , nx_install_dir , <NEWLINE> <STRING> ] <NEWLINE> if doctest : <NEWLINE> <TAB> argv . extend ( [ <STRING> , <STRING> ] ) <NEWLINE> <UNTAB> if not numpy : <NEWLINE> <TAB> argv . extend ( [ <STRING> ] ) <NEWLINE> <NEWLINE> <UNTAB> nose . run ( argv = argv ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def erfinv ( x ) : <NEWLINE> <TAB> <NEWLINE> return ErfInv ( ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def total_time ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _total_time <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _gaussian_kernel1d ( sigma , order , radius ) : <NEWLINE> <TAB> <NEWLINE> if order < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> p = numpy . polynomial . Polynomial ( [ <NUMBER> , <NUMBER> , - <NUMBER> / ( sigma * sigma ) ] ) <NEWLINE> x = numpy . arange ( - radius , radius + <NUMBER> ) <NEWLINE> phi_x = numpy . exp ( p ( x ) , dtype = numpy . double ) <NEWLINE> phi_x /= phi_x . sum ( ) <NEWLINE> if order > <NUMBER> : <NEWLINE> <TAB> q = numpy . polynomial . Polynomial ( [ <NUMBER> ] ) <NEWLINE> p_deriv = p . deriv ( ) <NEWLINE> for _ in range ( order ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> q = q . deriv ( ) + q * p_deriv <NEWLINE> <UNTAB> phi_x *= q ( x ) <NEWLINE> <UNTAB> return phi_x <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def exquo ( f , g , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> options . allowed_flags ( args , [ <STRING> , <STRING> ] ) <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> ( F , G ) , opt = parallel_poly_from_expr ( ( f , g ) , * gens , ** args ) <NEWLINE> <UNTAB> except PolificationFailed as exc : <NEWLINE> <TAB> raise ComputationFailed ( <STRING> , <NUMBER> , exc ) <NEWLINE> <NEWLINE> <UNTAB> q = F . exquo ( G , auto = opt . auto ) <NEWLINE> <NEWLINE> if not opt . polys : <NEWLINE> <TAB> return q . as_expr ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return q <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_test_value ( v ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( v , graph . Variable ) : <NEWLINE> <TAB> v_var = theano . tensor . as_tensor_variable ( v ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> v_var = v <NEWLINE> <UNTAB> return PureOp . _get_test_value ( v_var ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def pink ( ) : <NEWLINE> <TAB> <NEWLINE> set_cmap ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _sanity_check ( fh ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> pos = fh . tell ( ) <NEWLINE> try : <NEWLINE> <TAB> line = next ( fh ) <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> fh . seek ( pos , <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if not line . startswith ( <STRING> ) : <NEWLINE> <TAB> raise RuntimeError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def infeed_enqueue ( input , shape = [ ] , device_ordinal = - <NUMBER> , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if shape is None : <NEWLINE> <TAB> shape = [ ] <NEWLINE> <UNTAB> shape = _execute . make_shape ( shape , <STRING> ) <NEWLINE> if device_ordinal is None : <NEWLINE> <TAB> device_ordinal = - <NUMBER> <NEWLINE> <UNTAB> device_ordinal = _execute . make_int ( device_ordinal , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , shape = shape , <NEWLINE> device_ordinal = device_ordinal , name = name ) <NEWLINE> return _op <NEWLINE> _result = None <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , input , <STRING> , <NEWLINE> shape , <STRING> , device_ordinal ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return infeed_enqueue_eager_fallback ( <NEWLINE> input , shape = shape , device_ordinal = device_ordinal , name = name , <NEWLINE> ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pde_separate_add ( eq , fun , sep ) : <NEWLINE> <TAB> <NEWLINE> return pde_separate ( eq , fun , sep , strategy = <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def gff_list ( f ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( f . rep , <STRING> ) : <NEWLINE> <TAB> result = f . rep . gff_list ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise OperationNotSupported ( f , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return [ ( f . per ( g ) , k ) for g , k in result ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def create_dataset ( self , name , shape = None , dtype = None , data = None , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> with phil : <NEWLINE> <TAB> dsid = dataset . make_new_dset ( self , shape , dtype , data , ** kwds ) <NEWLINE> dset = dataset . Dataset ( dsid ) <NEWLINE> if name is not None : <NEWLINE> <TAB> self [ name ] = dset <NEWLINE> <UNTAB> return dset <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def initialize ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . core_1 = { } <NEWLINE> self . core_2 = { } <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . inout_1 = { } <NEWLINE> self . inout_2 = { } <NEWLINE> <NEWLINE> <NEWLINE> self . state = GMState ( self ) <NEWLINE> <NEWLINE> <NEWLINE> self . mapping = self . core_1 . copy ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __setstate__ ( self , state ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( state , dict ) : <NEWLINE> <TAB> super ( TimedeltaIndex , self ) . __setstate__ ( state ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise Exception ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self ) : <NEWLINE> <TAB> <NEWLINE> if not len ( self . _elements ) : <NEWLINE> <TAB> return self . _default <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . _elements [ self . _pos ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def minimize_quadratic_1d ( a , b , lb , ub , c = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> t = [ lb , ub ] <NEWLINE> if a != <NUMBER> : <NEWLINE> <TAB> extremum = - <NUMBER> * b / a <NEWLINE> if lb < extremum < ub : <NEWLINE> <TAB> t . append ( extremum ) <NEWLINE> <UNTAB> <UNTAB> t = np . asarray ( t ) <NEWLINE> y = a * t ** <NUMBER> + b * t + c <NEWLINE> min_index = np . argmin ( y ) <NEWLINE> return t [ min_index ] , y [ min_index ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def sqf ( f , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> return _generic_factor ( f , gens , args , method = <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , step_callable , session = None ) : <NEWLINE> <TAB> <NEWLINE> if context . executing_eagerly ( ) : <NEWLINE> <TAB> if session is not None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> self . _run_step = step_callable <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if session is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> session . run ( step_callable . _iterator . initializer ) <NEWLINE> self . _run_step = session . make_callable ( step_callable ( ) ) <NEWLINE> session . run ( variables . global_variables_initializer ( ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def applymap ( self , func ) : <NEWLINE> <TAB> <NEWLINE> return self . apply ( lambda x : lmap ( func , x ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> super ( Checkpoint , self ) . __init__ ( ) <NEWLINE> for k , v in sorted ( kwargs . items ( ) , key = lambda item : item [ <NUMBER> ] ) : <NEWLINE> <TAB> if not isinstance ( v , base . CheckpointableBase ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> % ( v , ) ) <NEWLINE> <UNTAB> setattr ( self , k , v ) <NEWLINE> <UNTAB> self . _save_counter = None <NEWLINE> self . _save_assign_op = None <NEWLINE> self . _saver = CheckpointableSaver ( weakref . ref ( self ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def forward ( data , impulse_response = None , filter_params = { } , <NEWLINE> predefined_filter = None ) : <NEWLINE> <TAB> <NEWLINE> assert_nD ( data , <NUMBER> , <STRING> ) <NEWLINE> if predefined_filter is None : <NEWLINE> <TAB> predefined_filter = LPIFilter2D ( impulse_response , ** filter_params ) <NEWLINE> <UNTAB> return predefined_filter ( data ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def uniqify_once ( func ) : <NEWLINE> <TAB> <NEWLINE> @ six . wraps ( func ) <NEWLINE> def unique_once ( self , * args , ** kwargs ) : <NEWLINE> <TAB> return self . unique_once ( func ( self , * args , ** kwargs ) ) <NEWLINE> <UNTAB> return unique_once <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def gf_Qbasis ( Q , p , K ) : <NEWLINE> <TAB> <NEWLINE> Q , n = [ list ( q ) for q in Q ] , len ( Q ) <NEWLINE> <NEWLINE> for k in range ( <NUMBER> , n ) : <NEWLINE> <TAB> Q [ k ] [ k ] = ( Q [ k ] [ k ] - K . one ) % p <NEWLINE> <NEWLINE> <UNTAB> for k in range ( <NUMBER> , n ) : <NEWLINE> <TAB> for i in range ( k , n ) : <NEWLINE> <TAB> if Q [ k ] [ i ] : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> inv = K . invert ( Q [ k ] [ i ] , p ) <NEWLINE> <NEWLINE> for j in range ( <NUMBER> , n ) : <NEWLINE> <TAB> Q [ j ] [ i ] = ( Q [ j ] [ i ] * inv ) % p <NEWLINE> <NEWLINE> <UNTAB> for j in range ( <NUMBER> , n ) : <NEWLINE> <TAB> t = Q [ j ] [ k ] <NEWLINE> Q [ j ] [ k ] = Q [ j ] [ i ] <NEWLINE> Q [ j ] [ i ] = t <NEWLINE> <NEWLINE> <UNTAB> for i in range ( <NUMBER> , n ) : <NEWLINE> <TAB> if i != k : <NEWLINE> <TAB> q = Q [ k ] [ i ] <NEWLINE> <NEWLINE> for j in range ( <NUMBER> , n ) : <NEWLINE> <TAB> Q [ j ] [ i ] = ( Q [ j ] [ i ] - Q [ j ] [ k ] * q ) % p <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> for i in range ( <NUMBER> , n ) : <NEWLINE> <TAB> for j in range ( <NUMBER> , n ) : <NEWLINE> <TAB> if i == j : <NEWLINE> <TAB> Q [ i ] [ j ] = ( K . one - Q [ i ] [ j ] ) % p <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> Q [ i ] [ j ] = ( - Q [ i ] [ j ] ) % p <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> basis = [ ] <NEWLINE> <NEWLINE> for q in Q : <NEWLINE> <TAB> if any ( q ) : <NEWLINE> <TAB> basis . append ( q ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return basis <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def aggregate ( self , vals , grouper , units = None ) : <NEWLINE> <TAB> <NEWLINE> func = self . estimator <NEWLINE> ci = self . ci <NEWLINE> n_boot = self . n_boot <NEWLINE> <NEWLINE> <NEWLINE> null_ci = pd . Series ( index = [ <STRING> , <STRING> ] , dtype = np . float ) <NEWLINE> <NEWLINE> <NEWLINE> def bootstrapped_cis ( vals ) : <NEWLINE> <NEWLINE> <TAB> if len ( vals ) == <NUMBER> : <NEWLINE> <TAB> return null_ci <NEWLINE> <NEWLINE> <UNTAB> boots = bootstrap ( vals , func = func , n_boot = n_boot ) <NEWLINE> cis = utils . ci ( boots , ci ) <NEWLINE> return pd . Series ( cis , [ <STRING> , <STRING> ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> grouped = vals . groupby ( grouper , sort = self . sort ) <NEWLINE> est = grouped . agg ( func ) <NEWLINE> <NEWLINE> <NEWLINE> if ci is None : <NEWLINE> <TAB> return est . index , est , None <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if ci == <STRING> : <NEWLINE> <TAB> sd = grouped . std ( ) <NEWLINE> cis = pd . DataFrame ( np . c_ [ est - sd , est + sd ] , <NEWLINE> index = est . index , <NEWLINE> columns = [ <STRING> , <STRING> ] ) . stack ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cis = grouped . apply ( bootstrapped_cis ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if cis . notnull ( ) . any ( ) : <NEWLINE> <TAB> cis = cis . unstack ( ) . reindex ( est . index ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cis = None <NEWLINE> <NEWLINE> <UNTAB> return est . index , est , cis <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _assign ( cls , keys , value , d , old = None , path = [ ] ) : <NEWLINE> <TAB> <NEWLINE> if len ( keys ) == <NUMBER> : <NEWLINE> <TAB> if old is not None : <NEWLINE> <TAB> path_key = tuple ( path + [ keys [ <NUMBER> ] ] ) <NEWLINE> if keys [ <NUMBER> ] in d : <NEWLINE> <TAB> old [ path_key ] = d [ keys [ <NUMBER> ] ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> old [ path_key ] = <STRING> <NEWLINE> <UNTAB> <UNTAB> d [ keys [ <NUMBER> ] ] = value <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> key = keys [ <NUMBER> ] <NEWLINE> if key not in d : <NEWLINE> <TAB> d [ key ] = { } <NEWLINE> if old is not None : <NEWLINE> <TAB> old [ tuple ( path + [ key ] ) ] = <STRING> <NEWLINE> <UNTAB> old = None <NEWLINE> <UNTAB> cls . _assign ( keys [ <NUMBER> : ] , value , d [ key ] , path = path + [ key ] , old = old ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def memory_usage ( self , deep = False ) : <NEWLINE> <TAB> <NEWLINE> return self . _codes . nbytes + self . dtype . categories . memory_usage ( <NEWLINE> deep = deep ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _invertx ( p , x ) : <NEWLINE> <TAB> <NEWLINE> p1 = poly_from_expr ( p , x ) [ <NUMBER> ] <NEWLINE> <NEWLINE> n = degree ( p1 ) <NEWLINE> a = [ c * x ** ( n - i ) for ( i , ) , c in p1 . terms ( ) ] <NEWLINE> return Add ( * a ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def sum ( x , axis = None , keepdims = False ) : <NEWLINE> <TAB> <NEWLINE> return math_ops . reduce_sum ( x , axis , keepdims ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def non_slot_devices ( self , var_list ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def min ( self , axis = None , out = None , fill_value = None , keepdims = np . _NoValue ) : <NEWLINE> <TAB> <NEWLINE> kwargs = { } if keepdims is np . _NoValue else { <STRING> : keepdims } <NEWLINE> <NEWLINE> _mask = self . _mask <NEWLINE> newmask = _check_mask_axis ( _mask , axis , ** kwargs ) <NEWLINE> if fill_value is None : <NEWLINE> <TAB> fill_value = minimum_fill_value ( self ) <NEWLINE> <NEWLINE> <UNTAB> if out is None : <NEWLINE> <TAB> result = self . filled ( fill_value ) . min ( <NEWLINE> axis = axis , out = out , ** kwargs ) . view ( type ( self ) ) <NEWLINE> if result . ndim : <NEWLINE> <NEWLINE> <TAB> result . __setmask__ ( newmask ) <NEWLINE> <NEWLINE> if newmask . ndim : <NEWLINE> <TAB> np . copyto ( result , result . fill_value , where = newmask ) <NEWLINE> <UNTAB> <UNTAB> elif newmask : <NEWLINE> <TAB> result = masked <NEWLINE> <UNTAB> return result <NEWLINE> <NEWLINE> <UNTAB> result = self . filled ( fill_value ) . min ( axis = axis , out = out , ** kwargs ) <NEWLINE> if isinstance ( out , MaskedArray ) : <NEWLINE> <TAB> outmask = getmask ( out ) <NEWLINE> if ( outmask is nomask ) : <NEWLINE> <TAB> outmask = out . _mask = make_mask_none ( out . shape ) <NEWLINE> <UNTAB> outmask . flat = newmask <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if out . dtype . kind in <STRING> : <NEWLINE> <TAB> errmsg = <STRING> <STRING> <NEWLINE> raise MaskError ( errmsg ) <NEWLINE> <UNTAB> np . copyto ( out , np . nan , where = newmask ) <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def polar ( a , side = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if side not in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> a = np . asarray ( a ) <NEWLINE> if a . ndim != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> w , s , vh = svd ( a , full_matrices = False ) <NEWLINE> u = w . dot ( vh ) <NEWLINE> if side == <STRING> : <NEWLINE> <NEWLINE> <TAB> p = ( vh . T . conj ( ) * s ) . dot ( vh ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> p = ( w * s ) . dot ( w . T . conj ( ) ) <NEWLINE> <UNTAB> return u , p <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_xaxis ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . xaxis <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def combine_first ( self , other ) : <NEWLINE> <TAB> <NEWLINE> new_index = self . index . union ( other . index ) <NEWLINE> this = self . reindex ( new_index , copy = False ) <NEWLINE> other = other . reindex ( new_index , copy = False ) <NEWLINE> <NEWLINE> name = ops . get_op_result_name ( self , other ) <NEWLINE> rs_vals = com . _where_compat ( isna ( this ) , other . _values , this . _values ) <NEWLINE> return self . _constructor ( rs_vals , index = new_index ) . __finalize__ ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def cross ( a , b , axisa = - <NUMBER> , axisb = - <NUMBER> , axisc = - <NUMBER> , axis = None ) : <NEWLINE> <TAB> <NEWLINE> if axis is not None : <NEWLINE> <TAB> axisa , axisb , axisc = ( axis , ) * <NUMBER> <NEWLINE> <UNTAB> a = asarray ( a ) <NEWLINE> b = asarray ( b ) <NEWLINE> <NEWLINE> axisa = normalize_axis_index ( axisa , a . ndim , msg_prefix = <STRING> ) <NEWLINE> axisb = normalize_axis_index ( axisb , b . ndim , msg_prefix = <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> a = moveaxis ( a , axisa , - <NUMBER> ) <NEWLINE> b = moveaxis ( b , axisb , - <NUMBER> ) <NEWLINE> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> if a . shape [ - <NUMBER> ] not in ( <NUMBER> , <NUMBER> ) or b . shape [ - <NUMBER> ] not in ( <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( msg ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> shape = broadcast ( a [ ... , <NUMBER> ] , b [ ... , <NUMBER> ] ) . shape <NEWLINE> if a . shape [ - <NUMBER> ] == <NUMBER> or b . shape [ - <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> shape += ( <NUMBER> , ) <NEWLINE> <NEWLINE> axisc = normalize_axis_index ( axisc , len ( shape ) , msg_prefix = <STRING> ) <NEWLINE> <UNTAB> dtype = promote_types ( a . dtype , b . dtype ) <NEWLINE> cp = empty ( shape , dtype ) <NEWLINE> <NEWLINE> <NEWLINE> a0 = a [ ... , <NUMBER> ] <NEWLINE> a1 = a [ ... , <NUMBER> ] <NEWLINE> if a . shape [ - <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> a2 = a [ ... , <NUMBER> ] <NEWLINE> <UNTAB> b0 = b [ ... , <NUMBER> ] <NEWLINE> b1 = b [ ... , <NUMBER> ] <NEWLINE> if b . shape [ - <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> b2 = b [ ... , <NUMBER> ] <NEWLINE> <UNTAB> if cp . ndim != <NUMBER> and cp . shape [ - <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> cp0 = cp [ ... , <NUMBER> ] <NEWLINE> cp1 = cp [ ... , <NUMBER> ] <NEWLINE> cp2 = cp [ ... , <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> if a . shape [ - <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> if b . shape [ - <NUMBER> ] == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> multiply ( a0 , b1 , out = cp ) <NEWLINE> cp -= a1 * b0 <NEWLINE> return cp <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> assert b . shape [ - <NUMBER> ] == <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> multiply ( a1 , b2 , out = cp0 ) <NEWLINE> multiply ( a0 , b2 , out = cp1 ) <NEWLINE> negative ( cp1 , out = cp1 ) <NEWLINE> multiply ( a0 , b1 , out = cp2 ) <NEWLINE> cp2 -= a1 * b0 <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> assert a . shape [ - <NUMBER> ] == <NUMBER> <NEWLINE> if b . shape [ - <NUMBER> ] == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> multiply ( a1 , b2 , out = cp0 ) <NEWLINE> tmp = array ( a2 * b1 ) <NEWLINE> cp0 -= tmp <NEWLINE> multiply ( a2 , b0 , out = cp1 ) <NEWLINE> multiply ( a0 , b2 , out = tmp ) <NEWLINE> cp1 -= tmp <NEWLINE> multiply ( a0 , b1 , out = cp2 ) <NEWLINE> multiply ( a1 , b0 , out = tmp ) <NEWLINE> cp2 -= tmp <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> assert b . shape [ - <NUMBER> ] == <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> multiply ( a2 , b1 , out = cp0 ) <NEWLINE> negative ( cp0 , out = cp0 ) <NEWLINE> multiply ( a2 , b0 , out = cp1 ) <NEWLINE> multiply ( a0 , b1 , out = cp2 ) <NEWLINE> cp2 -= a1 * b0 <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return moveaxis ( cp , - <NUMBER> , axisc ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_yaxis ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . yaxis <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , distribution_strategy , replica_id = None , tower_id = None ) : <NEWLINE> <TAB> <NEWLINE> if tower_id is not None : <NEWLINE> <TAB> replica_id = tower_id <NEWLINE> <UNTAB> assert replica_id is not None <NEWLINE> self . _distribution_strategy = distribution_strategy <NEWLINE> self . _thread_context = distribution_strategy_context . _InReplicaThreadMode ( <NEWLINE> self ) <NEWLINE> self . _replica_id = replica_id <NEWLINE> <NEWLINE> self . _tower_id = replica_id <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def find ( self , obj , name = None , module = None , globs = None , extraglobs = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if name is None : <NEWLINE> <TAB> name = getattr ( obj , <STRING> , None ) <NEWLINE> if name is None : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % <NEWLINE> ( type ( obj ) , ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if module is False : <NEWLINE> <TAB> module = None <NEWLINE> <UNTAB> elif module is None : <NEWLINE> <TAB> module = inspect . getmodule ( obj ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> file = inspect . getsourcefile ( obj ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> source_lines = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if not file : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> file = inspect . getfile ( obj ) <NEWLINE> if not file [ <NUMBER> ] + file [ - <NUMBER> : ] == <STRING> : file = None <NEWLINE> <UNTAB> if file is None : <NEWLINE> <TAB> source_lines = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if module is not None : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> source_lines = linecache . getlines ( file , module . __dict__ ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> source_lines = linecache . getlines ( file ) <NEWLINE> <UNTAB> if not source_lines : <NEWLINE> <TAB> source_lines = None <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if globs is None : <NEWLINE> <TAB> if module is None : <NEWLINE> <TAB> globs = { } <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> globs = module . __dict__ . copy ( ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> globs = globs . copy ( ) <NEWLINE> <UNTAB> if extraglobs is not None : <NEWLINE> <TAB> globs . update ( extraglobs ) <NEWLINE> <UNTAB> if <STRING> not in globs : <NEWLINE> <TAB> globs [ <STRING> ] = <STRING> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> tests = [ ] <NEWLINE> self . _find ( tests , obj , name , module , source_lines , globs , { } ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> tests . sort ( ) <NEWLINE> return tests <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _rewrite ( self ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def check_inline ( self ) : <NEWLINE> <TAB> <NEWLINE> return check_inline ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _find_permutation ( a , b ) : <NEWLINE> <TAB> <NEWLINE> t = np . argsort ( a ) <NEWLINE> u = np . argsort ( b ) <NEWLINE> u_ = _inverse_permutation ( u ) <NEWLINE> return t [ u_ ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def open_ftp ( self , url ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( url , str ) : <NEWLINE> <TAB> raise URLError ( <STRING> ) <NEWLINE> <UNTAB> import mimetypes <NEWLINE> host , path = splithost ( url ) <NEWLINE> if not host : raise URLError ( <STRING> ) <NEWLINE> host , port = splitport ( host ) <NEWLINE> user , host = splituser ( host ) <NEWLINE> if user : user , passwd = splitpasswd ( user ) <NEWLINE> else : passwd = None <NEWLINE> host = unquote ( host ) <NEWLINE> user = unquote ( user or <STRING> ) <NEWLINE> passwd = unquote ( passwd or <STRING> ) <NEWLINE> host = socket . gethostbyname ( host ) <NEWLINE> if not port : <NEWLINE> <TAB> import ftplib <NEWLINE> port = ftplib . FTP_PORT <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> port = int ( port ) <NEWLINE> <UNTAB> path , attrs = splitattr ( path ) <NEWLINE> path = unquote ( path ) <NEWLINE> dirs = path . split ( <STRING> ) <NEWLINE> dirs , file = dirs [ : - <NUMBER> ] , dirs [ - <NUMBER> ] <NEWLINE> if dirs and not dirs [ <NUMBER> ] : dirs = dirs [ <NUMBER> : ] <NEWLINE> if dirs and not dirs [ <NUMBER> ] : dirs [ <NUMBER> ] = <STRING> <NEWLINE> key = user , host , port , <STRING> . join ( dirs ) <NEWLINE> <NEWLINE> if len ( self . ftpcache ) > MAXFTPCACHE : <NEWLINE> <NEWLINE> <TAB> for k in list ( self . ftpcache ) : <NEWLINE> <TAB> if k != key : <NEWLINE> <TAB> v = self . ftpcache [ k ] <NEWLINE> del self . ftpcache [ k ] <NEWLINE> v . close ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> try : <NEWLINE> <TAB> if key not in self . ftpcache : <NEWLINE> <TAB> self . ftpcache [ key ] = ftpwrapper ( user , passwd , host , port , dirs ) <NEWLINE> <UNTAB> if not file : type = <STRING> <NEWLINE> else : type = <STRING> <NEWLINE> for attr in attrs : <NEWLINE> <TAB> attr , value = splitvalue ( attr ) <NEWLINE> if attr . lower ( ) == <STRING> and value in ( <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ) : <NEWLINE> <TAB> type = value . upper ( ) <NEWLINE> <UNTAB> <UNTAB> ( fp , retrlen ) = self . ftpcache [ key ] . retrfile ( file , type ) <NEWLINE> mtype = mimetypes . guess_type ( <STRING> + url ) [ <NUMBER> ] <NEWLINE> headers = <STRING> <NEWLINE> if mtype : <NEWLINE> <TAB> headers += <STRING> % mtype <NEWLINE> <UNTAB> if retrlen is not None and retrlen >= <NUMBER> : <NEWLINE> <TAB> headers += <STRING> % retrlen <NEWLINE> <UNTAB> headers = email . message_from_string ( headers ) <NEWLINE> return addinfourl ( fp , headers , <STRING> + url ) <NEWLINE> <UNTAB> except ftperrors ( ) as exp : <NEWLINE> <TAB> raise URLError ( <STRING> % exp ) . with_traceback ( sys . exc_info ( ) [ <NUMBER> ] ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __setstate__ ( self , state ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( state , dict ) : <NEWLINE> <TAB> super ( PeriodIndex , self ) . __setstate__ ( state ) <NEWLINE> <NEWLINE> <UNTAB> elif isinstance ( state , tuple ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if len ( state ) == <NUMBER> : <NEWLINE> <TAB> nd_state , own_state = state <NEWLINE> data = np . empty ( nd_state [ <NUMBER> ] , dtype = nd_state [ <NUMBER> ] ) <NEWLINE> np . ndarray . __setstate__ ( data , nd_state ) <NEWLINE> <NEWLINE> <NEWLINE> self . _freq = Period . _maybe_convert_freq ( own_state [ <NUMBER> ] ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> data = np . empty ( state ) <NEWLINE> np . ndarray . __setstate__ ( self , state ) <NEWLINE> <NEWLINE> <UNTAB> self . _data = data <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise Exception ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dumps ( obj , protocol = None ) : <NEWLINE> <TAB> <NEWLINE> file = StringIO ( ) <NEWLINE> try : <NEWLINE> <TAB> cp = CloudPickler ( file , protocol = protocol ) <NEWLINE> cp . dump ( obj ) <NEWLINE> return file . getvalue ( ) <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> file . close ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def py_vq ( obs , code_book , check_finite = True ) : <NEWLINE> <TAB> <NEWLINE> obs = _asarray_validated ( obs , check_finite = check_finite ) <NEWLINE> code_book = _asarray_validated ( code_book , check_finite = check_finite ) <NEWLINE> <NEWLINE> if obs . ndim != code_book . ndim : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if obs . ndim == <NUMBER> : <NEWLINE> <TAB> obs = obs [ : , np . newaxis ] <NEWLINE> code_book = code_book [ : , np . newaxis ] <NEWLINE> <NEWLINE> <UNTAB> dist = cdist ( obs , code_book ) <NEWLINE> code = dist . argmin ( axis = <NUMBER> ) <NEWLINE> min_dist = dist [ np . arange ( len ( code ) ) , code ] <NEWLINE> return code , min_dist <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def make_constant ( args ) : <NEWLINE> <TAB> <NEWLINE> def conv ( a ) : <NEWLINE> <TAB> if a is None : <NEWLINE> <TAB> return a <NEWLINE> <UNTAB> elif isinstance ( a , slice ) : <NEWLINE> <TAB> return slice ( conv ( a . start ) , <NEWLINE> conv ( a . stop ) , <NEWLINE> conv ( a . step ) ) <NEWLINE> <UNTAB> elif isinstance ( a , ( integer_types , np . integer ) ) : <NEWLINE> <TAB> return scal . ScalarConstant ( scal . int64 , a ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return a <NEWLINE> <UNTAB> <UNTAB> return tuple ( map ( conv , args ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def urlunparse ( components ) : <NEWLINE> <TAB> <NEWLINE> scheme , netloc , url , params , query , fragment , _coerce_result = ( <NEWLINE> _coerce_args ( * components ) ) <NEWLINE> if params : <NEWLINE> <TAB> url = <STRING> % ( url , params ) <NEWLINE> <UNTAB> return _coerce_result ( urlunsplit ( ( scheme , netloc , url , query , fragment ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_unique_index ( self , dropna = False ) : <NEWLINE> <TAB> <NEWLINE> res = super ( PeriodIndex , self ) . _get_unique_index ( dropna = dropna ) <NEWLINE> if dropna : <NEWLINE> <TAB> res = res . dropna ( ) <NEWLINE> <UNTAB> return res <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def safecall ( f , name , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> lwork = kwargs . get ( <STRING> , None ) <NEWLINE> if lwork in ( None , - <NUMBER> ) : <NEWLINE> <TAB> kwargs [ <STRING> ] = - <NUMBER> <NEWLINE> ret = f ( * args , ** kwargs ) <NEWLINE> kwargs [ <STRING> ] = ret [ - <NUMBER> ] [ <NUMBER> ] . real . astype ( numpy . int ) <NEWLINE> <UNTAB> ret = f ( * args , ** kwargs ) <NEWLINE> if ret [ - <NUMBER> ] < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> % ( - ret [ - <NUMBER> ] , name ) ) <NEWLINE> <UNTAB> return ret [ : - <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def scatter_kwargs ( inputs , kwargs , target_gpus , dim = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> inputs = scatter ( inputs , target_gpus , dim ) if inputs else [ ] <NEWLINE> kwargs = scatter ( kwargs , target_gpus , dim ) if kwargs else [ ] <NEWLINE> if len ( inputs ) < len ( kwargs ) : <NEWLINE> <TAB> inputs . extend ( [ ( ) for _ in range ( len ( kwargs ) - len ( inputs ) ) ] ) <NEWLINE> <UNTAB> elif len ( kwargs ) < len ( inputs ) : <NEWLINE> <TAB> kwargs . extend ( [ { } for _ in range ( len ( inputs ) - len ( kwargs ) ) ] ) <NEWLINE> <UNTAB> inputs = tuple ( inputs ) <NEWLINE> kwargs = tuple ( kwargs ) <NEWLINE> return inputs , kwargs <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , maxsize = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . _init ( maxsize ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . mutex = threading . RLock ( ) <NEWLINE> <NEWLINE> <NEWLINE> self . not_empty = threading . Condition ( self . mutex ) <NEWLINE> <NEWLINE> <NEWLINE> self . not_full = threading . Condition ( self . mutex ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def lcm ( self , a , b ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( v1 = [ <STRING> ] ) <NEWLINE> @ tf_should_use . should_use_result <NEWLINE> def is_variable_initialized ( variable ) : <NEWLINE> <TAB> <NEWLINE> return state_ops . is_variable_initialized ( variable ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def lbp_sub ( f , g ) : <NEWLINE> <TAB> <NEWLINE> if sig_cmp ( Sign ( f ) , Sign ( g ) , Polyn ( f ) . ring . order ) < <NUMBER> : <NEWLINE> <TAB> max_poly = g <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> max_poly = f <NEWLINE> <NEWLINE> <UNTAB> ret = Polyn ( f ) - Polyn ( g ) <NEWLINE> <NEWLINE> return lbp ( Sign ( max_poly ) , ret , Num ( max_poly ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def grad_not_implemented ( op , x_pos , x , comment = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return ( NullType ( ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> ) % ( x_pos , x , op , comment ) ) ) ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def parallel_poly_from_expr ( exprs , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> opt = options . build_options ( gens , args ) <NEWLINE> return _parallel_poly_from_expr ( exprs , opt ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _batch_inverse ( bmat ) : <NEWLINE> <TAB> <NEWLINE> n = bmat . size ( - <NUMBER> ) <NEWLINE> flat_bmat = bmat . reshape ( - <NUMBER> , n , n ) <NEWLINE> flat_inv_bmat = torch . stack ( [ m . inverse ( ) for m in flat_bmat ] , <NUMBER> ) <NEWLINE> return flat_inv_bmat . view ( bmat . shape ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def iterable ( y ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> iter ( y ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_attrs ( self ) : <NEWLINE> <TAB> <NEWLINE> self . non_index_axes = [ ] <NEWLINE> self . nan_rep = None <NEWLINE> self . levels = [ ] <NEWLINE> <NEWLINE> self . index_axes = [ a . infer ( self ) <NEWLINE> for a in self . indexables if a . is_an_indexable ] <NEWLINE> self . values_axes = [ a . infer ( self ) <NEWLINE> for a in self . indexables if not a . is_an_indexable ] <NEWLINE> self . data_columns = [ a . name for a in self . values_axes ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def traverse_tree_v4_eager_fallback ( tree_handle , input_data , sparse_input_indices , sparse_input_values , sparse_input_shape , input_spec , params , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> input_spec = _execute . make_str ( input_spec , <STRING> ) <NEWLINE> params = _execute . make_str ( params , <STRING> ) <NEWLINE> tree_handle = _ops . convert_to_tensor ( tree_handle , _dtypes . resource ) <NEWLINE> input_data = _ops . convert_to_tensor ( input_data , _dtypes . float32 ) <NEWLINE> sparse_input_indices = _ops . convert_to_tensor ( sparse_input_indices , _dtypes . int64 ) <NEWLINE> sparse_input_values = _ops . convert_to_tensor ( sparse_input_values , _dtypes . float32 ) <NEWLINE> sparse_input_shape = _ops . convert_to_tensor ( sparse_input_shape , _dtypes . int64 ) <NEWLINE> _inputs_flat = [ tree_handle , input_data , sparse_input_indices , sparse_input_values , sparse_input_shape ] <NEWLINE> _attrs = ( <STRING> , input_spec , <STRING> , params ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def accept ( self , fgraph , no_recycling = None , profile = None ) : <NEWLINE> <TAB> <NEWLINE> if no_recycling is None : <NEWLINE> <TAB> no_recycling = [ ] <NEWLINE> <UNTAB> if self . fgraph is not None and self . fgraph is not fgraph : <NEWLINE> <TAB> return type ( self ) ( self . checker , self . schedule ) . accept ( <NEWLINE> fgraph , no_recycling , profile ) <NEWLINE> <UNTAB> self . fgraph = fgraph <NEWLINE> self . no_recycling = no_recycling <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def score ( self , X , y = None ) : <NEWLINE> <TAB> <NEWLINE> self . _check_is_fitted ( <STRING> ) <NEWLINE> if self . scorer_ is None : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> % self . best_estimator_ ) <NEWLINE> <UNTAB> score = self . scorer_ [ self . refit ] if self . multimetric_ else self . scorer_ <NEWLINE> return score ( self . best_estimator_ , X , y ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _rec_perform ( self , node , x , y , inverse , out , curdim ) : <NEWLINE> <TAB> <NEWLINE> if len ( x . shape ) == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> if inverse : <NEWLINE> <TAB> out [ y ] = x [ : ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> out [ : ] = x [ y ] <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> xs0 = x . shape [ <NUMBER> ] <NEWLINE> ys0 = y . shape [ <NUMBER> ] <NEWLINE> if xs0 == ys0 : <NEWLINE> <TAB> for i in xrange ( xs0 ) : <NEWLINE> <TAB> self . _rec_perform ( node , x [ i ] , y [ i ] , inverse , out [ i ] , <NEWLINE> curdim + <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> elif ys0 == <NUMBER> and node . inputs [ <NUMBER> ] . type . broadcastable [ curdim ] : <NEWLINE> <NEWLINE> <TAB> for i in xrange ( xs0 ) : <NEWLINE> <TAB> self . _rec_perform ( node , x [ i ] , y [ <NUMBER> ] , inverse , out [ i ] , <NEWLINE> curdim + <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> elif xs0 == <NUMBER> and node . inputs [ <NUMBER> ] . type . broadcastable [ curdim ] : <NEWLINE> <NEWLINE> <TAB> for i in xrange ( ys0 ) : <NEWLINE> <TAB> self . _rec_perform ( node , x [ <NUMBER> ] , y [ i ] , inverse , out [ i ] , <NEWLINE> curdim + <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( xs0 , ys0 ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _perform_selection ( self , points , op ) : <NEWLINE> <TAB> <NEWLINE> points = np . asarray ( points , order = <STRING> , dtype = <STRING> ) <NEWLINE> if len ( points . shape ) == <NUMBER> : <NEWLINE> <TAB> points . shape = ( <NUMBER> , points . shape [ <NUMBER> ] ) <NEWLINE> <NEWLINE> <UNTAB> if self . _id . get_select_type ( ) != h5s . SEL_POINTS : <NEWLINE> <TAB> op = h5s . SELECT_SET <NEWLINE> <NEWLINE> <UNTAB> if len ( points ) == <NUMBER> : <NEWLINE> <TAB> self . _id . select_none ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _id . select_elements ( points , op ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , o ) : <NEWLINE> <TAB> <NEWLINE> if not self . available ( o ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> self . _owner = o <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _determine_call_convention ( self , call_argspec ) : <NEWLINE> <TAB> <NEWLINE> if call_argspec . varargs : <NEWLINE> <TAB> may_take_single_argument = False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> all_args = tf_inspect . getcallargs ( self . call , None ) <NEWLINE> self_args = set ( ) <NEWLINE> for arg_name , obj in all_args . items ( ) : <NEWLINE> <TAB> if obj is self : <NEWLINE> <TAB> self_args . add ( arg_name ) <NEWLINE> <UNTAB> <UNTAB> may_take_single_argument = True <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> may_take_single_argument = False <NEWLINE> <UNTAB> <UNTAB> if may_take_single_argument : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> all_positional_args = len ( call_argspec . args ) <NEWLINE> if call_argspec . defaults is not None : <NEWLINE> <TAB> all_positional_args -= len ( call_argspec . defaults ) <NEWLINE> <UNTAB> non_self_positional_args = all_positional_args <NEWLINE> for positional_arg_name in call_argspec . args [ : all_positional_args ] : <NEWLINE> <TAB> if positional_arg_name in self_args : <NEWLINE> <TAB> non_self_positional_args -= <NUMBER> <NEWLINE> <UNTAB> <UNTAB> if non_self_positional_args == <NUMBER> : <NEWLINE> <TAB> if <STRING> in call_argspec . args [ all_positional_args : ] : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> return base_layer . CallConvention . SINGLE_POSITIONAL_ARGUMENT <NEWLINE> <UNTAB> <UNTAB> if <STRING> in call_argspec . args : <NEWLINE> <TAB> return base_layer . CallConvention . EXPLICIT_INPUTS_ARGUMENT <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return base_layer . CallConvention . POSITIONAL_ARGUMENTS_ARE_INPUTS <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_projection_class ( self , name ) : <NEWLINE> <TAB> <NEWLINE> return self . _all_projection_types [ name ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def assertRaises ( self , expected_exception , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> context = _AssertRaisesContext ( expected_exception , self ) <NEWLINE> try : <NEWLINE> <TAB> return context . handle ( <STRING> , args , kwargs ) <NEWLINE> <UNTAB> finally : <NEWLINE> <NEWLINE> <TAB> context = None <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def havel_hakimi_graph ( aseq , bseq , create_using = None ) : <NEWLINE> <TAB> <NEWLINE> G = nx . empty_graph ( <NUMBER> , create_using , default = nx . MultiGraph ) <NEWLINE> if G . is_directed ( ) : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> naseq = len ( aseq ) <NEWLINE> nbseq = len ( bseq ) <NEWLINE> <NEWLINE> suma = sum ( aseq ) <NEWLINE> sumb = sum ( bseq ) <NEWLINE> <NEWLINE> if not suma == sumb : <NEWLINE> <TAB> raise nx . NetworkXError ( <NEWLINE> <STRING> <NEWLINE> % ( suma , sumb ) ) <NEWLINE> <NEWLINE> <UNTAB> G = _add_nodes_with_bipartite_label ( G , naseq , nbseq ) <NEWLINE> <NEWLINE> if len ( aseq ) == <NUMBER> or max ( aseq ) == <NUMBER> : <NEWLINE> <TAB> return G <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> astubs = [ [ aseq [ v ] , v ] for v in range ( <NUMBER> , naseq ) ] <NEWLINE> bstubs = [ [ bseq [ v - naseq ] , v ] for v in range ( naseq , naseq + nbseq ) ] <NEWLINE> astubs . sort ( ) <NEWLINE> while astubs : <NEWLINE> <TAB> ( degree , u ) = astubs . pop ( ) <NEWLINE> if degree == <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <UNTAB> bstubs . sort ( ) <NEWLINE> for target in bstubs [ - degree : ] : <NEWLINE> <TAB> v = target [ <NUMBER> ] <NEWLINE> G . add_edge ( u , v ) <NEWLINE> target [ <NUMBER> ] -= <NUMBER> <NEWLINE> if target [ <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> bstubs . remove ( target ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> G . name = <STRING> <NEWLINE> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _assert_can_do_op ( self , value ) : <NEWLINE> <TAB> <NEWLINE> if not is_scalar ( value ) : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise TypeError ( msg . format ( type ( value ) . __name__ ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_out_variables ( self , out_vars ) : <NEWLINE> <TAB> <NEWLINE> self . out_vars = out_vars <NEWLINE> <NEWLINE> for var_ind , var in enumerate ( out_vars ) : <NEWLINE> <TAB> if var is not None : <NEWLINE> <TAB> key = id ( var . data ) <NEWLINE> if key in self . array_id_to_unique_index : <NEWLINE> <TAB> unique_list_index = self . array_id_to_unique_index [ key ] <NEWLINE> self . out_var_hooks . append ( ( var_ind , unique_list_index ) ) <NEWLINE> self . unique_ind_to_out_var_ind [ unique_list_index ] = var_ind <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise RuntimeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_PolynomialRing ( K1 , a , K0 ) : <NEWLINE> <TAB> <NEWLINE> if a . is_ground : <NEWLINE> <TAB> return K1 . convert ( a . LC , K0 . dom ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_slice_axis ( self , slice_obj , axis = None ) : <NEWLINE> <TAB> <NEWLINE> if axis is None : <NEWLINE> <TAB> axis = self . axis or <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> obj = self . obj <NEWLINE> if not need_slice ( slice_obj ) : <NEWLINE> <TAB> return obj . copy ( deep = False ) <NEWLINE> <NEWLINE> <UNTAB> labels = obj . _get_axis ( axis ) <NEWLINE> indexer = labels . slice_indexer ( slice_obj . start , slice_obj . stop , <NEWLINE> slice_obj . step , kind = self . name ) <NEWLINE> <NEWLINE> if isinstance ( indexer , slice ) : <NEWLINE> <TAB> return self . _slice ( indexer , axis = axis , kind = <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . obj . _take ( indexer , axis = axis ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def integer_repr ( x ) : <NEWLINE> <TAB> <NEWLINE> import numpy as np <NEWLINE> if x . dtype == np . float32 : <NEWLINE> <TAB> return _integer_repr ( x , np . int32 , np . int32 ( - <NUMBER> ** <NUMBER> ) ) <NEWLINE> <UNTAB> elif x . dtype == np . float64 : <NEWLINE> <TAB> return _integer_repr ( x , np . int64 , np . int64 ( - <NUMBER> ** <NUMBER> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % x . dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _chk_truncate ( self ) : <NEWLINE> <TAB> <NEWLINE> from pandas . core . reshape . concat import concat <NEWLINE> <NEWLINE> <NEWLINE> self . tr_size_col = - <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> max_cols = self . max_cols <NEWLINE> max_rows = self . max_rows <NEWLINE> <NEWLINE> if max_cols == <NUMBER> or max_rows == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> ( w , h ) = get_terminal_size ( ) <NEWLINE> self . w = w <NEWLINE> self . h = h <NEWLINE> if self . max_rows == <NUMBER> : <NEWLINE> <TAB> dot_row = <NUMBER> <NEWLINE> prompt_row = <NUMBER> <NEWLINE> if self . show_dimensions : <NEWLINE> <TAB> show_dimension_rows = <NUMBER> <NEWLINE> <UNTAB> n_add_rows = ( self . header + dot_row + show_dimension_rows + <NEWLINE> prompt_row ) <NEWLINE> <NEWLINE> max_rows_adj = self . h - n_add_rows <NEWLINE> self . max_rows_adj = max_rows_adj <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if max_cols == <NUMBER> and len ( self . frame . columns ) > w : <NEWLINE> <TAB> max_cols = w <NEWLINE> <UNTAB> if max_rows == <NUMBER> and len ( self . frame ) > h : <NEWLINE> <TAB> max_rows = h <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not hasattr ( self , <STRING> ) : <NEWLINE> <TAB> self . max_rows_adj = max_rows <NEWLINE> <UNTAB> if not hasattr ( self , <STRING> ) : <NEWLINE> <TAB> self . max_cols_adj = max_cols <NEWLINE> <NEWLINE> <UNTAB> max_cols_adj = self . max_cols_adj <NEWLINE> max_rows_adj = self . max_rows_adj <NEWLINE> <NEWLINE> truncate_h = max_cols_adj and ( len ( self . columns ) > max_cols_adj ) <NEWLINE> truncate_v = max_rows_adj and ( len ( self . frame ) > max_rows_adj ) <NEWLINE> <NEWLINE> frame = self . frame <NEWLINE> if truncate_h : <NEWLINE> <TAB> if max_cols_adj == <NUMBER> : <NEWLINE> <TAB> col_num = len ( frame . columns ) <NEWLINE> <UNTAB> elif max_cols_adj == <NUMBER> : <NEWLINE> <TAB> frame = frame . iloc [ : , : max_cols ] <NEWLINE> col_num = max_cols <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> col_num = ( max_cols_adj // <NUMBER> ) <NEWLINE> frame = concat ( ( frame . iloc [ : , : col_num ] , <NEWLINE> frame . iloc [ : , - col_num : ] ) , axis = <NUMBER> ) <NEWLINE> <UNTAB> self . tr_col_num = col_num <NEWLINE> <UNTAB> if truncate_v : <NEWLINE> <TAB> if max_rows_adj == <NUMBER> : <NEWLINE> <TAB> row_num = len ( frame ) <NEWLINE> <UNTAB> if max_rows_adj == <NUMBER> : <NEWLINE> <TAB> row_num = max_rows <NEWLINE> frame = frame . iloc [ : max_rows , : ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> row_num = max_rows_adj // <NUMBER> <NEWLINE> frame = concat ( ( frame . iloc [ : row_num , : ] , <NEWLINE> frame . iloc [ - row_num : , : ] ) ) <NEWLINE> <UNTAB> self . tr_row_num = row_num <NEWLINE> <NEWLINE> <UNTAB> self . tr_frame = frame <NEWLINE> self . truncate_h = truncate_h <NEWLINE> self . truncate_v = truncate_v <NEWLINE> self . is_truncated = self . truncate_h or self . truncate_v <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def assertNear ( self , f1 , f2 , err , msg = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . assertTrue ( <NEWLINE> f1 == f2 or math . fabs ( f1 - f2 ) <= err , <NEWLINE> <STRING> % ( f1 , f2 , err , <STRING> % msg <NEWLINE> if msg is not None else <STRING> ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def circle_ratios ( self , rescale = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if rescale : <NEWLINE> <TAB> ( kx , ky ) = self . scale_factors <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ( kx , ky ) = ( <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> pts = np . vstack ( [ self . _triangulation . x * kx , <NEWLINE> self . _triangulation . y * ky ] ) . T <NEWLINE> tri_pts = pts [ self . _triangulation . triangles ] <NEWLINE> <NEWLINE> a = tri_pts [ : , <NUMBER> , : ] - tri_pts [ : , <NUMBER> , : ] <NEWLINE> b = tri_pts [ : , <NUMBER> , : ] - tri_pts [ : , <NUMBER> , : ] <NEWLINE> c = tri_pts [ : , <NUMBER> , : ] - tri_pts [ : , <NUMBER> , : ] <NEWLINE> a = np . sqrt ( a [ : , <NUMBER> ] ** <NUMBER> + a [ : , <NUMBER> ] ** <NUMBER> ) <NEWLINE> b = np . sqrt ( b [ : , <NUMBER> ] ** <NUMBER> + b [ : , <NUMBER> ] ** <NUMBER> ) <NEWLINE> c = np . sqrt ( c [ : , <NUMBER> ] ** <NUMBER> + c [ : , <NUMBER> ] ** <NUMBER> ) <NEWLINE> <NEWLINE> s = ( a + b + c ) * <NUMBER> <NEWLINE> prod = s * ( a + b - s ) * ( a + c - s ) * ( b + c - s ) <NEWLINE> <NEWLINE> bool_flat = ( prod == <NUMBER> ) <NEWLINE> if np . any ( bool_flat ) : <NEWLINE> <NEWLINE> <TAB> ntri = tri_pts . shape [ <NUMBER> ] <NEWLINE> circum_radius = np . empty ( ntri , dtype = np . float64 ) <NEWLINE> circum_radius [ bool_flat ] = np . inf <NEWLINE> abc = a * b * c <NEWLINE> circum_radius [ ~ bool_flat ] = abc [ ~ bool_flat ] / ( <NEWLINE> <NUMBER> * np . sqrt ( prod [ ~ bool_flat ] ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> circum_radius = ( a * b * c ) / ( <NUMBER> * np . sqrt ( prod ) ) <NEWLINE> <UNTAB> in_radius = ( a * b * c ) / ( <NUMBER> * circum_radius * s ) <NEWLINE> circle_ratio = in_radius / circum_radius <NEWLINE> mask = self . _triangulation . mask <NEWLINE> if mask is None : <NEWLINE> <TAB> return circle_ratio <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return np . ma . array ( circle_ratio , mask = mask ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( <STRING> , <STRING> ) <NEWLINE> def get_regularization_losses ( scope = None ) : <NEWLINE> <TAB> <NEWLINE> return ops . get_collection ( ops . GraphKeys . REGULARIZATION_LOSSES , scope ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def eval_dir ( self , name = None ) : <NEWLINE> <TAB> <NEWLINE> return os . path . join ( self . _model_dir , <STRING> if not name else <NEWLINE> <STRING> + name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ tf_should_use . should_use_result <NEWLINE> def write ( self , index , value , name = None ) : <NEWLINE> <TAB> <NEWLINE> return self . _implementation . write ( index , value , name = name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _is_empty_array ( self , shape ) : <NEWLINE> <TAB> <NEWLINE> return any ( x == <NUMBER> for x in shape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def convert_from_missing_indexer_tuple ( indexer , axes ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def get_indexer ( _i , _idx ) : <NEWLINE> <TAB> return ( axes [ _i ] . get_loc ( _idx [ <STRING> ] ) if isinstance ( _idx , dict ) else <NEWLINE> _idx ) <NEWLINE> <NEWLINE> <UNTAB> return tuple ( get_indexer ( _i , _idx ) for _i , _idx in enumerate ( indexer ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def imagej_metadata ( data , bytecounts , byteorder ) : <NEWLINE> <TAB> <NEWLINE> _str = str if sys . version_info [ <NUMBER> ] < <NUMBER> else lambda x : str ( x , <STRING> ) <NEWLINE> <NEWLINE> def read_string ( data , byteorder ) : <NEWLINE> <TAB> return _str ( stripnull ( data [ <NUMBER> if byteorder == <STRING> else <NUMBER> : : <NUMBER> ] ) ) <NEWLINE> <NEWLINE> <UNTAB> def read_double ( data , byteorder ) : <NEWLINE> <TAB> return struct . unpack ( byteorder + ( <STRING> * ( len ( data ) // <NUMBER> ) ) , data ) <NEWLINE> <NEWLINE> <UNTAB> def read_bytes ( data , byteorder ) : <NEWLINE> <NEWLINE> <TAB> return numpy . fromstring ( data , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> metadata_types = { <NEWLINE> <STRING> : ( <STRING> , read_string ) , <NEWLINE> <STRING> : ( <STRING> , read_string ) , <NEWLINE> <STRING> : ( <STRING> , read_double ) , <NEWLINE> <STRING> : ( <STRING> , read_bytes ) , <NEWLINE> <STRING> : ( <STRING> , read_bytes ) , <NEWLINE> <STRING> : ( <STRING> , read_bytes ) } <NEWLINE> metadata_types . update ( <NEWLINE> dict ( ( k [ : : - <NUMBER> ] , v ) for k , v in metadata_types . items ( ) ) ) <NEWLINE> <NEWLINE> if not bytecounts : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if not data [ : <NUMBER> ] in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> header_size = bytecounts [ <NUMBER> ] <NEWLINE> if header_size < <NUMBER> or header_size > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> ntypes = ( header_size - <NUMBER> ) // <NUMBER> <NEWLINE> header = struct . unpack ( byteorder + <STRING> * ntypes , data [ <NUMBER> : <NUMBER> + ntypes * <NUMBER> ] ) <NEWLINE> pos = <NUMBER> + ntypes * <NUMBER> <NEWLINE> counter = <NUMBER> <NEWLINE> result = { } <NEWLINE> for mtype , count in zip ( header [ : : <NUMBER> ] , header [ <NUMBER> : : <NUMBER> ] ) : <NEWLINE> <TAB> values = [ ] <NEWLINE> name , func = metadata_types . get ( mtype , ( _str ( mtype ) , read_bytes ) ) <NEWLINE> for _ in range ( count ) : <NEWLINE> <TAB> counter += <NUMBER> <NEWLINE> pos1 = pos + bytecounts [ counter ] <NEWLINE> values . append ( func ( data [ pos : pos1 ] , byteorder ) ) <NEWLINE> pos = pos1 <NEWLINE> <UNTAB> result [ name . strip ( ) ] = values [ <NUMBER> ] if count == <NUMBER> else values <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _get_frame_result_type ( result , objs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if result . blocks and all ( b . is_sparse for b in result . blocks ) : <NEWLINE> <TAB> from pandas . core . sparse . api import SparseDataFrame <NEWLINE> return SparseDataFrame <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return next ( obj for obj in objs if not isinstance ( obj , <NEWLINE> ABCSparseDataFrame ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _hash_scalar ( val , encoding = <STRING> , hash_key = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isna ( val ) : <NEWLINE> <NEWLINE> <TAB> return np . array ( [ np . iinfo ( np . uint64 ) . max ] , dtype = <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if getattr ( val , <STRING> , None ) is not None : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if not isinstance ( val , tslib . Timestamp ) : <NEWLINE> <TAB> val = tslib . Timestamp ( val ) <NEWLINE> <UNTAB> val = val . tz_convert ( None ) <NEWLINE> <NEWLINE> <UNTAB> dtype , val = infer_dtype_from_scalar ( val ) <NEWLINE> vals = np . array ( [ val ] , dtype = dtype ) <NEWLINE> <NEWLINE> return hash_array ( vals , hash_key = hash_key , encoding = encoding , <NEWLINE> categorize = False ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def pprint_setters ( self , prop = None , leadingspace = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if leadingspace : <NEWLINE> <TAB> pad = <STRING> * leadingspace <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pad = <STRING> <NEWLINE> <UNTAB> if prop is not None : <NEWLINE> <TAB> accepts = self . get_valid_values ( prop ) <NEWLINE> return <STRING> % ( pad , prop , accepts ) <NEWLINE> <NEWLINE> <UNTAB> attrs = self . _get_setters_and_targets ( ) <NEWLINE> attrs . sort ( ) <NEWLINE> lines = [ ] <NEWLINE> <NEWLINE> for prop , path in attrs : <NEWLINE> <TAB> accepts = self . get_valid_values ( prop ) <NEWLINE> name = self . aliased_name ( prop ) <NEWLINE> <NEWLINE> lines . append ( <STRING> % ( pad , name , accepts ) ) <NEWLINE> <UNTAB> return lines <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def clear_stop ( self ) : <NEWLINE> <TAB> <NEWLINE> with self . _lock : <NEWLINE> <TAB> self . _joined = False <NEWLINE> self . _exc_info_to_raise = None <NEWLINE> if self . _stop_event . is_set ( ) : <NEWLINE> <TAB> self . _stop_event . clear ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_legend_data ( self , ax ) : <NEWLINE> <TAB> <NEWLINE> if self . hue_names is not None : <NEWLINE> <TAB> for rgb , label in zip ( self . colors , self . hue_names ) : <NEWLINE> <TAB> ax . scatter ( [ ] , [ ] , <NEWLINE> color = mpl . colors . rgb2hex ( rgb ) , <NEWLINE> label = label , <NEWLINE> s = <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def entropy ( self ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def generate_adjlist ( G , delimiter = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> directed = G . is_directed ( ) <NEWLINE> seen = set ( ) <NEWLINE> for s , nbrs in G . adjacency ( ) : <NEWLINE> <TAB> line = make_str ( s ) + delimiter <NEWLINE> for t , data in nbrs . items ( ) : <NEWLINE> <TAB> if not directed and t in seen : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> if G . is_multigraph ( ) : <NEWLINE> <TAB> for d in data . values ( ) : <NEWLINE> <TAB> line += make_str ( t ) + delimiter <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> line += make_str ( t ) + delimiter <NEWLINE> <UNTAB> <UNTAB> if not directed : <NEWLINE> <TAB> seen . add ( s ) <NEWLINE> <UNTAB> yield line [ : - len ( delimiter ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def arbitrary_element ( iterable ) : <NEWLINE> <TAB> <NEWLINE> if is_iterator ( iterable ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return next ( iter ( iterable ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dup_trunc ( f , p , K ) : <NEWLINE> <TAB> <NEWLINE> if K . is_ZZ : <NEWLINE> <TAB> g = [ ] <NEWLINE> <NEWLINE> for c in f : <NEWLINE> <TAB> c = c % p <NEWLINE> <NEWLINE> if c > p // <NUMBER> : <NEWLINE> <TAB> g . append ( c - p ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> g . append ( c ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> g = [ c % p for c in f ] <NEWLINE> <NEWLINE> <UNTAB> return dup_strip ( g ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def nlargest ( self , n = <NUMBER> , keep = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return algorithms . SelectNSeries ( self , n = n , keep = keep ) . nlargest ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def squeeze ( x , axis = None ) : <NEWLINE> <TAB> <NEWLINE> y , = Squeeze ( axis ) . apply ( ( x , ) ) <NEWLINE> return y <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def fdiff ( self , argindex = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if argindex == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> k = <NUMBER> <NEWLINE> if len ( self . args ) > <NUMBER> : <NEWLINE> <TAB> k = self . args [ <NUMBER> ] <NEWLINE> <UNTAB> return self . func ( self . args [ <NUMBER> ] , k + <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ArgumentIndexError ( self , argindex ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def full ( shape , fill_value , dtype = None , order = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if dtype is None : <NEWLINE> <TAB> dtype = array ( fill_value ) . dtype <NEWLINE> <UNTAB> a = empty ( shape , dtype , order ) <NEWLINE> multiarray . copyto ( a , fill_value , casting = <STRING> ) <NEWLINE> return a <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _ensure_index_from_sequences ( sequences , names = None ) : <NEWLINE> <TAB> <NEWLINE> from . multi import MultiIndex <NEWLINE> <NEWLINE> if len ( sequences ) == <NUMBER> : <NEWLINE> <TAB> if names is not None : <NEWLINE> <TAB> names = names [ <NUMBER> ] <NEWLINE> <UNTAB> return Index ( sequences [ <NUMBER> ] , name = names ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return MultiIndex . from_arrays ( sequences , names = names ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _no_dependency ( self , value ) : <NEWLINE> <TAB> <NEWLINE> return value <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rs_atanh ( p , x , prec ) : <NEWLINE> <TAB> <NEWLINE> if rs_is_puiseux ( p , x ) : <NEWLINE> <TAB> return rs_puiseux ( rs_atanh , p , x , prec ) <NEWLINE> <UNTAB> R = p . ring <NEWLINE> const = <NUMBER> <NEWLINE> if _has_constant_term ( p , x ) : <NEWLINE> <TAB> zm = R . zero_monom <NEWLINE> c = p [ zm ] <NEWLINE> if R . domain is EX : <NEWLINE> <TAB> c_expr = c . as_expr ( ) <NEWLINE> const = atanh ( c_expr ) <NEWLINE> <UNTAB> elif isinstance ( c , PolyElement ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> c_expr = c . as_expr ( ) <NEWLINE> const = R ( atanh ( c_expr ) ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> raise DomainError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> const = R ( atanh ( c ) ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> raise DomainError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> dp = rs_diff ( p , x ) <NEWLINE> p1 = - rs_square ( p , x , prec ) + <NUMBER> <NEWLINE> p1 = rs_series_inversion ( p1 , x , prec - <NUMBER> ) <NEWLINE> p1 = rs_mul ( dp , p1 , x , prec - <NUMBER> ) <NEWLINE> return rs_integrate ( p1 , x ) + const <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def next_sample ( uid ) : <NEWLINE> <TAB> <NEWLINE> return six . next ( _SHARED_SEQUENCES [ uid ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def register_key_flag_for_module ( self , module_name , flag ) : <NEWLINE> <TAB> <NEWLINE> key_flags_by_module = self . key_flags_by_module_dict ( ) <NEWLINE> <NEWLINE> key_flags = key_flags_by_module . setdefault ( module_name , [ ] ) <NEWLINE> <NEWLINE> if flag not in key_flags : <NEWLINE> <TAB> key_flags . append ( flag ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_n_splits ( self , X = None , y = None , groups = None ) : <NEWLINE> <TAB> <NEWLINE> if groups is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> groups = check_array ( groups , ensure_2d = False , dtype = None ) <NEWLINE> return len ( np . unique ( groups ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , n , p , seed = None ) : <NEWLINE> <TAB> <NEWLINE> return multinomial_frozen ( n , p , seed ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> def transitive_reduction ( G ) : <NEWLINE> <TAB> <NEWLINE> if not is_directed_acyclic_graph ( G ) : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise nx . NetworkXError ( msg ) <NEWLINE> <UNTAB> TR = nx . DiGraph ( ) <NEWLINE> TR . add_nodes_from ( G . nodes ( ) ) <NEWLINE> descendants = { } <NEWLINE> <NEWLINE> check_count = dict ( G . in_degree ) <NEWLINE> for u in G : <NEWLINE> <TAB> u_nbrs = set ( G [ u ] ) <NEWLINE> for v in G [ u ] : <NEWLINE> <TAB> if v in u_nbrs : <NEWLINE> <TAB> if v not in descendants : <NEWLINE> <TAB> descendants [ v ] = { y for x , y in nx . dfs_edges ( G , v ) } <NEWLINE> <UNTAB> u_nbrs -= descendants [ v ] <NEWLINE> <UNTAB> check_count [ v ] -= <NUMBER> <NEWLINE> if check_count [ v ] == <NUMBER> : <NEWLINE> <TAB> del descendants [ v ] <NEWLINE> <UNTAB> <UNTAB> TR . add_edges_from ( ( u , v ) for v in u_nbrs ) <NEWLINE> <UNTAB> return TR <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def betavariate ( self , alpha , beta ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> y = self . gammavariate ( alpha , <NUMBER> ) <NEWLINE> if y == <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return y / ( y + self . gammavariate ( beta , <NUMBER> ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def bspline ( x , n ) : <NEWLINE> <TAB> <NEWLINE> ax = - abs ( asarray ( x ) ) <NEWLINE> <NEWLINE> funclist , condfuncs = _bspline_piecefunctions ( n ) <NEWLINE> condlist = [ func ( ax ) for func in condfuncs ] <NEWLINE> return piecewise ( ax , condlist , funclist ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ contextlib . contextmanager <NEWLINE> def _name_scope ( self , name = None , values = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( self . name ) : <NEWLINE> <TAB> with ops . name_scope ( name , values = ( <NEWLINE> ( [ ] if values is None else values ) + self . _graph_parents ) ) as scope : <NEWLINE> <TAB> yield scope <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def check_restrict ( self ) : <NEWLINE> <TAB> <NEWLINE> return check_restrict ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def poly2herme ( pol ) : <NEWLINE> <TAB> <NEWLINE> [ pol ] = pu . as_series ( [ pol ] ) <NEWLINE> deg = len ( pol ) - <NUMBER> <NEWLINE> res = <NUMBER> <NEWLINE> for i in range ( deg , - <NUMBER> , - <NUMBER> ) : <NEWLINE> <TAB> res = hermeadd ( hermemulx ( res ) , pol [ i ] ) <NEWLINE> <UNTAB> return res <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _parse_input_dimensions ( args , input_core_dims ) : <NEWLINE> <TAB> <NEWLINE> broadcast_args = [ ] <NEWLINE> dim_sizes = { } <NEWLINE> for arg , core_dims in zip ( args , input_core_dims ) : <NEWLINE> <TAB> _update_dim_sizes ( dim_sizes , arg , core_dims ) <NEWLINE> ndim = arg . ndim - len ( core_dims ) <NEWLINE> dummy_array = np . lib . stride_tricks . as_strided ( <NUMBER> , arg . shape [ : ndim ] ) <NEWLINE> broadcast_args . append ( dummy_array ) <NEWLINE> <UNTAB> broadcast_shape = np . lib . stride_tricks . _broadcast_shape ( * broadcast_args ) <NEWLINE> return broadcast_shape , dim_sizes <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def duplicated ( self , keep = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return super ( Series , self ) . duplicated ( keep = keep ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def extend_with_decoupled_weight_decay ( base_optimizer ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> class OptimizerWithDecoupledWeightDecay ( DecoupledWeightDecayExtension , <NEWLINE> base_optimizer ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def __init__ ( self , weight_decay , * args , ** kwargs ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> super ( OptimizerWithDecoupledWeightDecay , self ) . __init__ ( <NEWLINE> weight_decay , * args , ** kwargs ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return OptimizerWithDecoupledWeightDecay <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def typed ( ruletypes ) : <NEWLINE> <TAB> <NEWLINE> return switch ( type , ruletypes ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_axobserver ( self , func ) : <NEWLINE> <TAB> <NEWLINE> self . _axobservers . append ( func ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def make_function ( self , unpack_single = True , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> thunk , inputs , outputs = self . make_thunk ( ** kwargs ) <NEWLINE> <NEWLINE> def execute ( * args ) : <NEWLINE> <TAB> def e_arity ( takes , got ) : <NEWLINE> <TAB> return <STRING> % ( <NEWLINE> takes , [ <STRING> , <STRING> ] [ takes > <NUMBER> ] , got ) <NEWLINE> <UNTAB> if ( len ( args ) != len ( inputs ) ) : <NEWLINE> <TAB> raise TypeError ( e_arity ( len ( inputs ) , len ( args ) ) ) <NEWLINE> <UNTAB> for arg , variable in izip ( args , inputs ) : <NEWLINE> <TAB> variable . data = arg <NEWLINE> <UNTAB> thunk ( ) <NEWLINE> if unpack_single : <NEWLINE> <TAB> return utils . to_return_values ( [ variable . data <NEWLINE> for variable in outputs ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return [ variable . data for variable in outputs ] <NEWLINE> <UNTAB> <UNTAB> execute . thunk = thunk <NEWLINE> execute . inputs = inputs <NEWLINE> execute . outputs = outputs <NEWLINE> <NEWLINE> return execute <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def on_epoch_end ( self ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def reshape ( a , new_shape , order = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> return a . reshape ( new_shape , order = order ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> _tmp = narray ( a , copy = False ) . reshape ( new_shape , order = order ) <NEWLINE> return _tmp . view ( MaskedArray ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def getrowview ( self , i ) : <NEWLINE> <TAB> <NEWLINE> new = lil_matrix ( ( <NUMBER> , self . shape [ <NUMBER> ] ) , dtype = self . dtype ) <NEWLINE> new . rows [ <NUMBER> ] = self . rows [ i ] <NEWLINE> new . data [ <NUMBER> ] = self . data [ i ] <NEWLINE> return new <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def draw_spring ( G , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> draw ( G , spring_layout ( G ) , ** kwargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rogerstanimoto ( u , v , w = None ) : <NEWLINE> <TAB> <NEWLINE> u = _validate_vector ( u ) <NEWLINE> v = _validate_vector ( v ) <NEWLINE> if w is not None : <NEWLINE> <TAB> w = _validate_weights ( w ) <NEWLINE> <UNTAB> ( nff , nft , ntf , ntt ) = _nbool_correspond_all ( u , v , w = w ) <NEWLINE> return float ( <NUMBER> * ( ntf + nft ) ) / float ( ntt + nff + ( <NUMBER> * ( ntf + nft ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _expr_small ( cls , x ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _convert_to_style ( cls , style_dict , num_format_str = None ) : <NEWLINE> <TAB> <NEWLINE> import xlwt <NEWLINE> <NEWLINE> if style_dict : <NEWLINE> <TAB> xlwt_stylestr = cls . _style_to_xlwt ( style_dict ) <NEWLINE> style = xlwt . easyxf ( xlwt_stylestr , field_sep = <STRING> , line_sep = <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> style = xlwt . XFStyle ( ) <NEWLINE> <UNTAB> if num_format_str is not None : <NEWLINE> <TAB> style . num_format_str = num_format_str <NEWLINE> <NEWLINE> <UNTAB> return style <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def close ( fig = None ) : <NEWLINE> <TAB> <NEWLINE> if fig is None : <NEWLINE> <TAB> figManager = _pylab_helpers . Gcf . get_active ( ) <NEWLINE> if figManager is None : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> _pylab_helpers . Gcf . destroy ( figManager . num ) <NEWLINE> <UNTAB> <UNTAB> elif fig == <STRING> : <NEWLINE> <TAB> _pylab_helpers . Gcf . destroy_all ( ) <NEWLINE> <UNTAB> elif isinstance ( fig , int ) : <NEWLINE> <TAB> _pylab_helpers . Gcf . destroy ( fig ) <NEWLINE> <UNTAB> elif hasattr ( fig , <STRING> ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> _pylab_helpers . Gcf . destroy ( fig . int ) <NEWLINE> <UNTAB> elif isinstance ( fig , str ) : <NEWLINE> <TAB> allLabels = get_figlabels ( ) <NEWLINE> if fig in allLabels : <NEWLINE> <TAB> num = get_fignums ( ) [ allLabels . index ( fig ) ] <NEWLINE> _pylab_helpers . Gcf . destroy ( num ) <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( fig , Figure ) : <NEWLINE> <TAB> _pylab_helpers . Gcf . destroy_fig ( fig ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _reload ( self , columns ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for col in columns : <NEWLINE> <TAB> col . primary_key = True <NEWLINE> <NEWLINE> <UNTAB> self . columns . extend ( columns ) <NEWLINE> <NEWLINE> PrimaryKeyConstraint . _autoincrement_column . _reset ( self ) <NEWLINE> self . _set_parent_with_dispatch ( self . table ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , tpu_cluster_resolver = None , using_single_core = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if tpu_cluster_resolver is None : <NEWLINE> <TAB> tpu_cluster_resolver = tpu_cluster_resolver_lib . TPUClusterResolver ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> metadata = get_tpu_system_metadata ( tpu_cluster_resolver ) <NEWLINE> self . _tpu_metadata = metadata <NEWLINE> self . _tpu_cluster_resolver = tpu_cluster_resolver <NEWLINE> self . _num_cores = <NUMBER> if using_single_core else metadata . num_cores <NEWLINE> <NEWLINE> <NEWLINE> worker_re = re . compile ( <STRING> ) <NEWLINE> for device in metadata . devices : <NEWLINE> <TAB> if <STRING> in device . name : <NEWLINE> <TAB> self . _worker_name = worker_re . search ( device . name ) . group ( <NUMBER> ) <NEWLINE> return <NEWLINE> <UNTAB> <UNTAB> raise Exception ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def conflicting ( self , b , planarity_state ) : <NEWLINE> <TAB> <NEWLINE> return ( not self . empty ( ) and <NEWLINE> planarity_state . lowpt [ self . high ] > planarity_state . lowpt [ b ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def pop ( self ) : <NEWLINE> <TAB> <NEWLINE> if not self . layers : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> self . _layers . pop ( ) <NEWLINE> self . built = False <NEWLINE> if not self . layers : <NEWLINE> <TAB> self . outputs = None <NEWLINE> self . inputs = None <NEWLINE> <UNTAB> elif self . outputs : <NEWLINE> <TAB> self . layers [ - <NUMBER> ] . _outbound_nodes = [ ] <NEWLINE> self . outputs = [ self . layers [ - <NUMBER> ] . output ] <NEWLINE> self . build ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def isspace ( self ) : <NEWLINE> <TAB> <NEWLINE> return isspace ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_data ( self ) : <NEWLINE> <TAB> <NEWLINE> return ndarray . view ( self , self . _baseclass ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def http_error ( self , url , fp , errcode , errmsg , headers , data = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> name = <STRING> % errcode <NEWLINE> if hasattr ( self , name ) : <NEWLINE> <TAB> method = getattr ( self , name ) <NEWLINE> if data is None : <NEWLINE> <TAB> result = method ( url , fp , errcode , errmsg , headers ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result = method ( url , fp , errcode , errmsg , headers , data ) <NEWLINE> <UNTAB> if result : return result <NEWLINE> <UNTAB> return self . http_error_default ( url , fp , errcode , errmsg , headers ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_subresultants ( f , g , u , K ) : <NEWLINE> <TAB> <NEWLINE> return dmp_inner_subresultants ( f , g , u , K ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_level_values ( self , level , unique = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> values = self . levels [ level ] <NEWLINE> labels = self . labels [ level ] <NEWLINE> if unique : <NEWLINE> <TAB> labels = algos . unique ( labels ) <NEWLINE> <UNTAB> filled = algos . take_1d ( values . _values , labels , <NEWLINE> fill_value = values . _na_value ) <NEWLINE> values = values . _shallow_copy ( filled ) <NEWLINE> return values <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_solid_joinstyle ( self , s ) : <NEWLINE> <TAB> <NEWLINE> s = s . lower ( ) <NEWLINE> if s not in self . validJoin : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( s , ) <NEWLINE> + <STRING> % ( self . validJoin , ) ) <NEWLINE> <NEWLINE> <UNTAB> if self . _solidjoinstyle != s : <NEWLINE> <TAB> self . stale = True <NEWLINE> <UNTAB> self . _solidjoinstyle = s <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def load ( self , obj ) : <NEWLINE> <TAB> <NEWLINE> obj . serialize ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _setdefaults ( self , defaults , * kwargs ) : <NEWLINE> <TAB> <NEWLINE> for k in defaults : <NEWLINE> <TAB> if all ( kw . get ( k , None ) is None for kw in kwargs ) : <NEWLINE> <TAB> for kw in kwargs : <NEWLINE> <TAB> kw [ k ] = defaults [ k ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ _graph_action_deprecation <NEWLINE> def run_feeds_iter ( output_dict , feed_dicts , restore_checkpoint_path = None ) : <NEWLINE> <TAB> <NEWLINE> if not output_dict : <NEWLINE> <TAB> raise ValueError ( <STRING> % output_dict ) <NEWLINE> <UNTAB> if not feed_dicts : <NEWLINE> <TAB> raise ValueError ( <STRING> % feed_dicts ) <NEWLINE> <NEWLINE> <UNTAB> graph = contrib_ops . get_graph_from_inputs ( output_dict . values ( ) ) <NEWLINE> with graph . as_default ( ) as g : <NEWLINE> <TAB> with tf_session . Session ( <STRING> ) as session : <NEWLINE> <TAB> session . run ( <NEWLINE> resources . initialize_resources ( resources . shared_resources ( ) + <NEWLINE> resources . local_resources ( ) ) ) <NEWLINE> if restore_checkpoint_path : <NEWLINE> <TAB> _restore_from_checkpoint ( session , g , restore_checkpoint_path ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> session . run ( variables . global_variables_initializer ( ) ) <NEWLINE> <UNTAB> session . run ( variables . local_variables_initializer ( ) ) <NEWLINE> session . run ( lookup_ops . tables_initializer ( ) ) <NEWLINE> coord = coordinator . Coordinator ( ) <NEWLINE> threads = None <NEWLINE> try : <NEWLINE> <TAB> threads = queue_runner . start_queue_runners ( session , coord = coord ) <NEWLINE> for f in feed_dicts : <NEWLINE> <TAB> yield session . run ( output_dict , f ) <NEWLINE> <UNTAB> <UNTAB> finally : <NEWLINE> <TAB> coord . request_stop ( ) <NEWLINE> if threads : <NEWLINE> <TAB> coord . join ( threads , stop_grace_period_secs = <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _onenormest_core ( A , AT , t , itmax ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> A_linear_operator = aslinearoperator ( A ) <NEWLINE> AT_linear_operator = aslinearoperator ( AT ) <NEWLINE> if itmax < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if t < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> n = A . shape [ <NUMBER> ] <NEWLINE> if t >= n : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> nmults = <NUMBER> <NEWLINE> nresamples = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> X = np . ones ( ( n , t ) , dtype = float ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if t > <NUMBER> : <NEWLINE> <TAB> for i in range ( <NUMBER> , t ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> resample_column ( i , X ) <NEWLINE> <UNTAB> for i in range ( t ) : <NEWLINE> <TAB> while column_needs_resampling ( i , X ) : <NEWLINE> <TAB> resample_column ( i , X ) <NEWLINE> nresamples += <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> X /= float ( n ) <NEWLINE> <NEWLINE> ind_hist = np . zeros ( <NUMBER> , dtype = np . intp ) <NEWLINE> est_old = <NUMBER> <NEWLINE> S = np . zeros ( ( n , t ) , dtype = float ) <NEWLINE> k = <NUMBER> <NEWLINE> ind = None <NEWLINE> while True : <NEWLINE> <TAB> Y = np . asarray ( A_linear_operator . matmat ( X ) ) <NEWLINE> nmults += <NUMBER> <NEWLINE> mags = _sum_abs_axis0 ( Y ) <NEWLINE> est = np . max ( mags ) <NEWLINE> best_j = np . argmax ( mags ) <NEWLINE> if est > est_old or k == <NUMBER> : <NEWLINE> <TAB> if k >= <NUMBER> : <NEWLINE> <TAB> ind_best = ind [ best_j ] <NEWLINE> <UNTAB> w = Y [ : , best_j ] <NEWLINE> <NEWLINE> <UNTAB> if k >= <NUMBER> and est <= est_old : <NEWLINE> <TAB> est = est_old <NEWLINE> break <NEWLINE> <UNTAB> est_old = est <NEWLINE> S_old = S <NEWLINE> if k > itmax : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> S = sign_round_up ( Y ) <NEWLINE> del Y <NEWLINE> <NEWLINE> if every_col_of_X_is_parallel_to_a_col_of_Y ( S , S_old ) : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> if t > <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> for i in range ( t ) : <NEWLINE> <TAB> while column_needs_resampling ( i , S , S_old ) : <NEWLINE> <TAB> resample_column ( i , S ) <NEWLINE> nresamples += <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> del S_old <NEWLINE> <NEWLINE> Z = np . asarray ( AT_linear_operator . matmat ( S ) ) <NEWLINE> nmults += <NUMBER> <NEWLINE> h = _max_abs_axis1 ( Z ) <NEWLINE> del Z <NEWLINE> <NEWLINE> if k >= <NUMBER> and max ( h ) == h [ ind_best ] : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> ind = np . argsort ( h ) [ : : - <NUMBER> ] [ : t + len ( ind_hist ) ] . copy ( ) <NEWLINE> del h <NEWLINE> if t > <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if np . in1d ( ind [ : t ] , ind_hist ) . all ( ) : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> seen = np . in1d ( ind , ind_hist ) <NEWLINE> ind = np . concatenate ( ( ind [ ~ seen ] , ind [ seen ] ) ) <NEWLINE> <UNTAB> for j in range ( t ) : <NEWLINE> <TAB> X [ : , j ] = elementary_vector ( n , ind [ j ] ) <NEWLINE> <NEWLINE> <UNTAB> new_ind = ind [ : t ] [ ~ np . in1d ( ind [ : t ] , ind_hist ) ] <NEWLINE> ind_hist = np . concatenate ( ( ind_hist , new_ind ) ) <NEWLINE> k += <NUMBER> <NEWLINE> <UNTAB> v = elementary_vector ( n , ind_best ) <NEWLINE> return est , v , w , nmults , nresamples <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _linear_2eq_order2_type11 ( x , y , t , r , eq ) : <NEWLINE> <TAB> <NEWLINE> C1 , C2 , C3 , C4 = get_numbered_constants ( eq , num = <NUMBER> ) <NEWLINE> u , v = symbols ( <STRING> , cls = Function ) <NEWLINE> f = - r [ <STRING> ] ; g = - r [ <STRING> ] <NEWLINE> h = - r [ <STRING> ] ; p = - r [ <STRING> ] <NEWLINE> [ msol1 , msol2 ] = dsolve ( [ Eq ( diff ( u ( t ) , t ) , t * f * u ( t ) + t * g * v ( t ) ) , Eq ( diff ( v ( t ) , t ) , t * h * u ( t ) + t * p * v ( t ) ) ] ) <NEWLINE> sol1 = C3 * t + t * Integral ( msol1 . rhs / t ** <NUMBER> , t ) <NEWLINE> sol2 = C4 * t + t * Integral ( msol2 . rhs / t ** <NUMBER> , t ) <NEWLINE> return [ Eq ( x ( t ) , sol1 ) , Eq ( y ( t ) , sol2 ) ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def infeed_dequeue ( dtype , shape , name = None ) : <NEWLINE> <TAB> <NEWLINE> if dtype not in _SUPPORTED_INFEED_DTYPES : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( dtype , list ( _SUPPORTED_INFEED_DTYPES ) ) ) <NEWLINE> <NEWLINE> <UNTAB> return gen_tpu_ops . infeed_dequeue ( dtype , shape , name = name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def pop_label ( self , index = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> self . labelCValues . pop ( index ) <NEWLINE> t = self . labelTexts . pop ( index ) <NEWLINE> t . remove ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def consider_constant ( x ) : <NEWLINE> <TAB> <NEWLINE> warnings . warn ( ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) , stacklevel = <NUMBER> ) <NEWLINE> <NEWLINE> return consider_constant_ ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def transform ( self , X ) : <NEWLINE> <TAB> <NEWLINE> X = check_array ( X , dtype = None , accept_sparse = <STRING> ) <NEWLINE> mask = self . get_support ( ) <NEWLINE> if not mask . any ( ) : <NEWLINE> <TAB> warn ( <STRING> <NEWLINE> <STRING> , <NEWLINE> UserWarning ) <NEWLINE> return np . empty ( <NUMBER> ) . reshape ( ( X . shape [ <NUMBER> ] , <NUMBER> ) ) <NEWLINE> <UNTAB> if len ( mask ) != X . shape [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return X [ : , safe_mask ( X , mask ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _align_nums ( nums ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> nums = asarray ( nums ) <NEWLINE> <NEWLINE> if not np . issubdtype ( nums . dtype , np . number ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return nums <NEWLINE> <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> nums = [ np . atleast_1d ( num ) for num in nums ] <NEWLINE> max_width = max ( num . size for num in nums ) <NEWLINE> <NEWLINE> <NEWLINE> aligned_nums = np . zeros ( ( len ( nums ) , max_width ) ) <NEWLINE> <NEWLINE> <NEWLINE> for index , num in enumerate ( nums ) : <NEWLINE> <TAB> aligned_nums [ index , - num . size : ] = num <NEWLINE> <NEWLINE> <UNTAB> return aligned_nums <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def check_restrict ( cmd ) : <NEWLINE> <TAB> <NEWLINE> cmd . _check_compiler ( ) <NEWLINE> body = <NEWLINE> <NEWLINE> for kw in [ <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> st = cmd . try_compile ( body % { <STRING> : kw } , None , None ) <NEWLINE> if st : <NEWLINE> <TAB> return kw <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return <STRING> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( v1 = [ <STRING> ] ) <NEWLINE> def scatter_sub ( ref , indices , updates , use_locking = False , name = None ) : <NEWLINE> <TAB> <NEWLINE> if ref . dtype . _is_ref_dtype : <NEWLINE> <TAB> return gen_state_ops . scatter_sub ( ref , indices , updates , <NEWLINE> use_locking = use_locking , name = name ) <NEWLINE> <UNTAB> return ref . _lazy_read ( gen_resource_variable_ops . resource_scatter_sub ( <NEWLINE> ref . handle , indices , ops . convert_to_tensor ( updates , ref . dtype ) , <NEWLINE> name = name ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def c_extract ( self , name , sub , check_input = True ) : <NEWLINE> <TAB> <NEWLINE> raise MethodNotDefined ( <STRING> , type ( self ) , <NEWLINE> self . __class__ . __name__ ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _apply_missing_value ( data , missing_value ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if missing_value is None : <NEWLINE> <TAB> newdata = data <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> missing_value_isnan = np . isnan ( missing_value ) <NEWLINE> <UNTAB> except ( TypeError , NotImplementedError ) : <NEWLINE> <NEWLINE> <TAB> missing_value_isnan = False <NEWLINE> <NEWLINE> <UNTAB> if missing_value_isnan : <NEWLINE> <TAB> mymask = np . isnan ( data ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> mymask = ( data == missing_value ) <NEWLINE> <NEWLINE> <UNTAB> newdata = np . ma . masked_where ( mymask , data ) <NEWLINE> <NEWLINE> <UNTAB> return newdata <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , incoming_graph_data = None , ** attr ) : <NEWLINE> <TAB> <NEWLINE> self . edge_key_dict_factory = self . edge_key_dict_factory <NEWLINE> DiGraph . __init__ ( self , incoming_graph_data , ** attr ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def truncated_tetrahedron_graph ( create_using = None ) : <NEWLINE> <TAB> <NEWLINE> G = path_graph ( <NUMBER> , create_using ) <NEWLINE> <NEWLINE> G . add_edges_from ( [ ( <NUMBER> , <NUMBER> ) , ( <NUMBER> , <NUMBER> ) , ( <NUMBER> , <NUMBER> ) , ( <NUMBER> , <NUMBER> ) , ( <NUMBER> , <NUMBER> ) , ( <NUMBER> , <NUMBER> ) , ( <NUMBER> , <NUMBER> ) ] ) <NEWLINE> G . name = <STRING> <NEWLINE> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def droplevel ( self , level = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> levels = level <NEWLINE> if not isinstance ( levels , ( tuple , list ) ) : <NEWLINE> <TAB> levels = [ level ] <NEWLINE> <NEWLINE> <UNTAB> new_levels = list ( self . levels ) <NEWLINE> new_labels = list ( self . labels ) <NEWLINE> new_names = list ( self . names ) <NEWLINE> <NEWLINE> levnums = sorted ( self . _get_level_number ( lev ) for lev in levels ) [ : : - <NUMBER> ] <NEWLINE> <NEWLINE> for i in levnums : <NEWLINE> <TAB> new_levels . pop ( i ) <NEWLINE> new_labels . pop ( i ) <NEWLINE> new_names . pop ( i ) <NEWLINE> <NEWLINE> <UNTAB> if len ( new_levels ) == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> mask = new_labels [ <NUMBER> ] == - <NUMBER> <NEWLINE> result = new_levels [ <NUMBER> ] . take ( new_labels [ <NUMBER> ] ) <NEWLINE> if mask . any ( ) : <NEWLINE> <TAB> result = result . putmask ( mask , np . nan ) <NEWLINE> <NEWLINE> <UNTAB> result . name = new_names [ <NUMBER> ] <NEWLINE> return result <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return MultiIndex ( levels = new_levels , labels = new_labels , <NEWLINE> names = new_names , verify_integrity = False ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_ambiguous ( self , dt ) : <NEWLINE> <TAB> <NEWLINE> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _get_temp_dir ( pool_folder_name , temp_folder = None ) : <NEWLINE> <TAB> <NEWLINE> use_shared_mem = False <NEWLINE> if temp_folder is None : <NEWLINE> <TAB> temp_folder = os . environ . get ( <STRING> , None ) <NEWLINE> <UNTAB> if temp_folder is None : <NEWLINE> <TAB> if os . path . exists ( SYSTEM_SHARED_MEM_FS ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> shm_stats = os . statvfs ( SYSTEM_SHARED_MEM_FS ) <NEWLINE> available_nbytes = shm_stats . f_bsize * shm_stats . f_bavail <NEWLINE> if available_nbytes > SYSTEM_SHARED_MEM_FS_MIN_SIZE : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> temp_folder = SYSTEM_SHARED_MEM_FS <NEWLINE> pool_folder = os . path . join ( temp_folder , pool_folder_name ) <NEWLINE> if not os . path . exists ( pool_folder ) : <NEWLINE> <TAB> os . makedirs ( pool_folder ) <NEWLINE> <UNTAB> use_shared_mem = True <NEWLINE> <UNTAB> <UNTAB> except ( IOError , OSError ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> temp_folder = None <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if temp_folder is None : <NEWLINE> <NEWLINE> <TAB> temp_folder = tempfile . gettempdir ( ) <NEWLINE> <UNTAB> temp_folder = os . path . abspath ( os . path . expanduser ( temp_folder ) ) <NEWLINE> pool_folder = os . path . join ( temp_folder , pool_folder_name ) <NEWLINE> return pool_folder , use_shared_mem <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def c_no_compile_args ( self ) : <NEWLINE> <TAB> <NEWLINE> raise utils . MethodNotDefined ( <NEWLINE> <STRING> , <NEWLINE> type ( self ) , <NEWLINE> self . __class__ . __name__ ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _generate_graph6_bytes ( G , nodes , header ) : <NEWLINE> <TAB> <NEWLINE> n = len ( G ) <NEWLINE> if n >= <NUMBER> ** <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if header : <NEWLINE> <TAB> yield <STRING> <NEWLINE> <UNTAB> for d in n_to_data ( n ) : <NEWLINE> <TAB> yield str . encode ( chr ( d + <NUMBER> ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> bits = ( nodes [ j ] in G [ nodes [ i ] ] for j in range ( <NUMBER> , n ) for i in range ( j ) ) <NEWLINE> chunk = list ( islice ( bits , <NUMBER> ) ) <NEWLINE> while chunk : <NEWLINE> <TAB> d = sum ( b << <NUMBER> - i for i , b in enumerate ( chunk ) ) <NEWLINE> yield str . encode ( chr ( d + <NUMBER> ) ) <NEWLINE> chunk = list ( islice ( bits , <NUMBER> ) ) <NEWLINE> <UNTAB> yield <STRING> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _select_options ( pat ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if pat in _registered_options : <NEWLINE> <TAB> return [ pat ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> keys = sorted ( _registered_options . keys ( ) ) <NEWLINE> if pat == <STRING> : <NEWLINE> <TAB> return keys <NEWLINE> <NEWLINE> <UNTAB> return [ k for k in keys if re . search ( pat , k , re . I ) ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def collect_callbacks ( self , name , * args ) : <NEWLINE> <TAB> <NEWLINE> d = { } <NEWLINE> for feature in self . _features : <NEWLINE> <TAB> try : <NEWLINE> <TAB> fn = getattr ( feature , name ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> d [ feature ] = fn ( * args ) <NEWLINE> <UNTAB> return d <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def top_kv2_eager_fallback ( input , k , sorted = True , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> if sorted is None : <NEWLINE> <TAB> sorted = True <NEWLINE> <UNTAB> sorted = _execute . make_bool ( sorted , <STRING> ) <NEWLINE> _attr_T , ( input , ) = _execute . args_to_matching_eager ( [ input ] , _ctx ) <NEWLINE> k = _ops . convert_to_tensor ( k , _dtypes . int32 ) <NEWLINE> _inputs_flat = [ input , k ] <NEWLINE> _attrs = ( <STRING> , sorted , <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result = _TopKV2Output . _make ( _result ) <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def frt2 ( a ) : <NEWLINE> <TAB> <NEWLINE> if a . ndim != <NUMBER> or a . shape [ <NUMBER> ] != a . shape [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> ai = a . copy ( ) <NEWLINE> n = ai . shape [ <NUMBER> ] <NEWLINE> f = np . empty ( ( n + <NUMBER> , n ) , np . uint32 ) <NEWLINE> f [ <NUMBER> ] = ai . sum ( axis = <NUMBER> ) <NEWLINE> for m in range ( <NUMBER> , n ) : <NEWLINE> <NEWLINE> <TAB> for row in range ( <NUMBER> , n ) : <NEWLINE> <TAB> ai [ row ] = roll ( ai [ row ] , - row ) <NEWLINE> <UNTAB> f [ m ] = ai . sum ( axis = <NUMBER> ) <NEWLINE> <UNTAB> f [ n ] = ai . sum ( axis = <NUMBER> ) <NEWLINE> return f <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def difference ( self , other ) : <NEWLINE> <TAB> <NEWLINE> self . _assert_can_do_setop ( other ) <NEWLINE> <NEWLINE> if self . equals ( other ) : <NEWLINE> <TAB> return self . _shallow_copy ( [ ] ) <NEWLINE> <NEWLINE> <UNTAB> other , result_name = self . _convert_can_do_setop ( other ) <NEWLINE> <NEWLINE> this = self . _get_unique_index ( ) <NEWLINE> <NEWLINE> indexer = this . get_indexer ( other ) <NEWLINE> indexer = indexer . take ( ( indexer != - <NUMBER> ) . nonzero ( ) [ <NUMBER> ] ) <NEWLINE> <NEWLINE> label_diff = np . setdiff1d ( np . arange ( this . size ) , indexer , <NEWLINE> assume_unique = True ) <NEWLINE> the_diff = this . values . take ( label_diff ) <NEWLINE> try : <NEWLINE> <TAB> the_diff = sorting . safe_sort ( the_diff ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> return this . _shallow_copy ( the_diff , name = result_name , freq = None ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def constant ( value , dtype = None , shape = None , name = <STRING> , verify_shape = False ) : <NEWLINE> <TAB> <NEWLINE> ctx = context . context ( ) <NEWLINE> if ctx . executing_eagerly ( ) : <NEWLINE> <TAB> t = convert_to_eager_tensor ( value , ctx , dtype ) <NEWLINE> if shape is None : <NEWLINE> <TAB> return t <NEWLINE> <UNTAB> shape = tensor_shape . as_shape ( shape ) <NEWLINE> if shape == t . shape : <NEWLINE> <TAB> return t <NEWLINE> <UNTAB> if verify_shape : <NEWLINE> <TAB> raise TypeError ( <STRING> % ( tuple ( shape ) , <NEWLINE> tuple ( t . shape ) ) ) <NEWLINE> <UNTAB> num_t = t . shape . num_elements ( ) <NEWLINE> <NEWLINE> if num_t == shape . num_elements ( ) : <NEWLINE> <TAB> return _eager_reshape ( t , shape . as_list ( ) , ctx ) <NEWLINE> <UNTAB> if num_t == <NUMBER> : <NEWLINE> <TAB> if t . dtype == dtypes . bool : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> with ops . device ( <STRING> ) : <NEWLINE> <TAB> x = _eager_fill ( shape . as_list ( ) , t . cpu ( ) , ctx ) <NEWLINE> <UNTAB> return _eager_identity ( x , ctx ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _eager_fill ( shape . as_list ( ) , t , ctx ) <NEWLINE> <UNTAB> <UNTAB> raise TypeError ( <STRING> <NEWLINE> <STRING> % <NEWLINE> ( num_t , shape , shape . num_elements ( ) ) ) <NEWLINE> <UNTAB> g = ops . get_default_graph ( ) <NEWLINE> tensor_value = attr_value_pb2 . AttrValue ( ) <NEWLINE> tensor_value . tensor . CopyFrom ( <NEWLINE> tensor_util . make_tensor_proto ( <NEWLINE> value , dtype = dtype , shape = shape , verify_shape = verify_shape ) ) <NEWLINE> dtype_value = attr_value_pb2 . AttrValue ( type = tensor_value . tensor . dtype ) <NEWLINE> const_tensor = g . create_op ( <NEWLINE> <STRING> , [ ] , [ dtype_value . type ] , <NEWLINE> attrs = { <STRING> : tensor_value , <NEWLINE> <STRING> : dtype_value } , <NEWLINE> name = name ) . outputs [ <NUMBER> ] <NEWLINE> return const_tensor <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def compare ( self , other , ** kw ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return isinstance ( other , BindParameter ) and self . type . _compare_type_affinity ( other . type ) and self . value == other . value and self . callable == other . callable <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def safe_as_int ( val , atol = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> mod = np . asarray ( val ) % <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> if mod . ndim == <NUMBER> : <NEWLINE> <TAB> if mod > <NUMBER> : <NEWLINE> <TAB> mod = <NUMBER> - mod <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> mod [ mod > <NUMBER> ] = <NUMBER> - mod [ mod > <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> np . testing . assert_allclose ( mod , <NUMBER> , atol = atol ) <NEWLINE> <UNTAB> except AssertionError : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( val ) ) <NEWLINE> <NEWLINE> <UNTAB> return np . round ( val ) . astype ( np . int64 ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_integrator ( self , name , ** integrator_params ) : <NEWLINE> <TAB> <NEWLINE> integrator = find_integrator ( name ) <NEWLINE> if integrator is None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> % name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _integrator = integrator ( ** integrator_params ) <NEWLINE> if not len ( self . _y ) : <NEWLINE> <TAB> self . t = <NUMBER> <NEWLINE> self . _y = array ( [ <NUMBER> ] , self . _integrator . scalar ) <NEWLINE> <UNTAB> self . _integrator . reset ( len ( self . _y ) , self . jac is not None ) <NEWLINE> <UNTAB> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_isolate_complex_roots_sqf ( f , K , eps = None , inf = None , sup = None , blackbox = False ) : <NEWLINE> <TAB> <NEWLINE> if not K . is_ZZ and not K . is_QQ : <NEWLINE> <TAB> raise DomainError ( <STRING> % K ) <NEWLINE> <NEWLINE> <UNTAB> if dup_degree ( f ) <= <NUMBER> : <NEWLINE> <TAB> return [ ] <NEWLINE> <NEWLINE> <UNTAB> if K . is_ZZ : <NEWLINE> <TAB> R , F = K , K . get_field ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> R , F = K . get_ring ( ) , K <NEWLINE> <NEWLINE> <UNTAB> f = dup_convert ( f , K , F ) <NEWLINE> <NEWLINE> n , lc = dup_degree ( f ) , abs ( dup_LC ( f , F ) ) <NEWLINE> B = <NUMBER> * max ( [ F . quo ( abs ( c ) , lc ) for c in f ] ) <NEWLINE> <NEWLINE> ( u , v ) , ( s , t ) = ( - B , F . zero ) , ( B , B ) <NEWLINE> <NEWLINE> if inf is not None : <NEWLINE> <TAB> u = inf <NEWLINE> <NEWLINE> <UNTAB> if sup is not None : <NEWLINE> <TAB> s = sup <NEWLINE> <NEWLINE> <UNTAB> if v < <NUMBER> or t <= v or s <= u : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> f1 , f2 = dup_real_imag ( f , F ) <NEWLINE> <NEWLINE> f1L1 = dmp_eval_in ( f1 , v , <NUMBER> , <NUMBER> , F ) <NEWLINE> f2L1 = dmp_eval_in ( f2 , v , <NUMBER> , <NUMBER> , F ) <NEWLINE> <NEWLINE> f1L2 = dmp_eval_in ( f1 , s , <NUMBER> , <NUMBER> , F ) <NEWLINE> f2L2 = dmp_eval_in ( f2 , s , <NUMBER> , <NUMBER> , F ) <NEWLINE> <NEWLINE> f1L3 = dmp_eval_in ( f1 , t , <NUMBER> , <NUMBER> , F ) <NEWLINE> f2L3 = dmp_eval_in ( f2 , t , <NUMBER> , <NUMBER> , F ) <NEWLINE> <NEWLINE> f1L4 = dmp_eval_in ( f1 , u , <NUMBER> , <NUMBER> , F ) <NEWLINE> f2L4 = dmp_eval_in ( f2 , u , <NUMBER> , <NUMBER> , F ) <NEWLINE> <NEWLINE> S_L1 = [ f1L1 , f2L1 ] <NEWLINE> S_L2 = [ f1L2 , f2L2 ] <NEWLINE> S_L3 = [ f1L3 , f2L3 ] <NEWLINE> S_L4 = [ f1L4 , f2L4 ] <NEWLINE> <NEWLINE> I_L1 = dup_isolate_real_roots_list ( S_L1 , F , inf = u , sup = s , fast = True , strict = True , basis = True ) <NEWLINE> I_L2 = dup_isolate_real_roots_list ( S_L2 , F , inf = v , sup = t , fast = True , strict = True , basis = True ) <NEWLINE> I_L3 = dup_isolate_real_roots_list ( S_L3 , F , inf = u , sup = s , fast = True , strict = True , basis = True ) <NEWLINE> I_L4 = dup_isolate_real_roots_list ( S_L4 , F , inf = v , sup = t , fast = True , strict = True , basis = True ) <NEWLINE> <NEWLINE> I_L3 = _reverse_intervals ( I_L3 ) <NEWLINE> I_L4 = _reverse_intervals ( I_L4 ) <NEWLINE> <NEWLINE> Q_L1 = _intervals_to_quadrants ( I_L1 , f1L1 , f2L1 , u , s , F ) <NEWLINE> Q_L2 = _intervals_to_quadrants ( I_L2 , f1L2 , f2L2 , v , t , F ) <NEWLINE> Q_L3 = _intervals_to_quadrants ( I_L3 , f1L3 , f2L3 , s , u , F ) <NEWLINE> Q_L4 = _intervals_to_quadrants ( I_L4 , f1L4 , f2L4 , t , v , F ) <NEWLINE> <NEWLINE> T = _traverse_quadrants ( Q_L1 , Q_L2 , Q_L3 , Q_L4 ) <NEWLINE> N = _winding_number ( T , F ) <NEWLINE> <NEWLINE> if not N : <NEWLINE> <TAB> return [ ] <NEWLINE> <NEWLINE> <UNTAB> I = ( I_L1 , I_L2 , I_L3 , I_L4 ) <NEWLINE> Q = ( Q_L1 , Q_L2 , Q_L3 , Q_L4 ) <NEWLINE> <NEWLINE> F1 = ( f1L1 , f1L2 , f1L3 , f1L4 ) <NEWLINE> F2 = ( f2L1 , f2L2 , f2L3 , f2L4 ) <NEWLINE> <NEWLINE> rectangles , roots = [ ( N , ( u , v ) , ( s , t ) , I , Q , F1 , F2 ) ] , [ ] <NEWLINE> <NEWLINE> while rectangles : <NEWLINE> <TAB> N , ( u , v ) , ( s , t ) , I , Q , F1 , F2 = _depth_first_select ( rectangles ) <NEWLINE> <NEWLINE> if s - u > t - v : <NEWLINE> <TAB> D_L , D_R = _vertical_bisection ( N , ( u , v ) , ( s , t ) , I , Q , F1 , F2 , f1 , f2 , F ) <NEWLINE> <NEWLINE> N_L , a , b , I_L , Q_L , F1_L , F2_L = D_L <NEWLINE> N_R , c , d , I_R , Q_R , F1_R , F2_R = D_R <NEWLINE> <NEWLINE> if N_L >= <NUMBER> : <NEWLINE> <TAB> if N_L == <NUMBER> and _rectangle_small_p ( a , b , eps ) : <NEWLINE> <TAB> roots . append ( ComplexInterval ( a , b , I_L , Q_L , F1_L , F2_L , f1 , f2 , F ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rectangles . append ( D_L ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if N_R >= <NUMBER> : <NEWLINE> <TAB> if N_R == <NUMBER> and _rectangle_small_p ( c , d , eps ) : <NEWLINE> <TAB> roots . append ( ComplexInterval ( c , d , I_R , Q_R , F1_R , F2_R , f1 , f2 , F ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rectangles . append ( D_R ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> D_B , D_U = _horizontal_bisection ( N , ( u , v ) , ( s , t ) , I , Q , F1 , F2 , f1 , f2 , F ) <NEWLINE> <NEWLINE> N_B , a , b , I_B , Q_B , F1_B , F2_B = D_B <NEWLINE> N_U , c , d , I_U , Q_U , F1_U , F2_U = D_U <NEWLINE> <NEWLINE> if N_B >= <NUMBER> : <NEWLINE> <TAB> if N_B == <NUMBER> and _rectangle_small_p ( a , b , eps ) : <NEWLINE> <TAB> roots . append ( ComplexInterval ( <NEWLINE> a , b , I_B , Q_B , F1_B , F2_B , f1 , f2 , F ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rectangles . append ( D_B ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if N_U >= <NUMBER> : <NEWLINE> <TAB> if N_U == <NUMBER> and _rectangle_small_p ( c , d , eps ) : <NEWLINE> <TAB> roots . append ( ComplexInterval ( <NEWLINE> c , d , I_U , Q_U , F1_U , F2_U , f1 , f2 , F ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rectangles . append ( D_U ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> _roots , roots = sorted ( roots , key = lambda r : ( r . ax , r . ay ) ) , [ ] <NEWLINE> <NEWLINE> for root in _roots : <NEWLINE> <TAB> roots . extend ( [ root . conjugate ( ) , root ] ) <NEWLINE> <NEWLINE> <UNTAB> if blackbox : <NEWLINE> <TAB> return roots <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return [ r . as_tuple ( ) for r in roots ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def parse ( timestr , parserinfo = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if parserinfo : <NEWLINE> <TAB> return parser ( parserinfo ) . parse ( timestr , ** kwargs ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return DEFAULTPARSER . parse ( timestr , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def expm_frechet ( A , E , method = None , compute_expm = True , check_finite = True ) : <NEWLINE> <TAB> <NEWLINE> if check_finite : <NEWLINE> <TAB> A = np . asarray_chkfinite ( A ) <NEWLINE> E = np . asarray_chkfinite ( E ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> A = np . asarray ( A ) <NEWLINE> E = np . asarray ( E ) <NEWLINE> <UNTAB> if A . ndim != <NUMBER> or A . shape [ <NUMBER> ] != A . shape [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if E . ndim != <NUMBER> or E . shape [ <NUMBER> ] != E . shape [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if A . shape != E . shape : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if method is None : <NEWLINE> <TAB> method = <STRING> <NEWLINE> <UNTAB> if method == <STRING> : <NEWLINE> <TAB> expm_A , expm_frechet_AE = expm_frechet_algo_64 ( A , E ) <NEWLINE> <UNTAB> elif method == <STRING> : <NEWLINE> <TAB> expm_A , expm_frechet_AE = expm_frechet_block_enlarge ( A , E ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % method ) <NEWLINE> <UNTAB> if compute_expm : <NEWLINE> <TAB> return expm_A , expm_frechet_AE <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return expm_frechet_AE <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def ode_linear_coefficients ( eq , func , order , match ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return ode_1st_homogeneous_coeff_best ( eq , func , order , match ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _repr_fits_vertical_ ( self ) : <NEWLINE> <TAB> <NEWLINE> max_rows = get_option ( <STRING> ) <NEWLINE> return len ( self ) <= max_rows <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rrelu ( x , l = <NUMBER> / <NUMBER> , u = <NUMBER> / <NUMBER> , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> r = None <NEWLINE> return_r = False <NEWLINE> if kwargs : <NEWLINE> <TAB> r , return_r = argument . parse_kwargs ( <NEWLINE> kwargs , ( <STRING> , r ) , ( <STRING> , r ) , <NEWLINE> train = <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> func = RReLU ( l , u , r ) <NEWLINE> out = func . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> r = func . r <NEWLINE> <NEWLINE> if return_r : <NEWLINE> <TAB> return out , r <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def with_rank_at_most ( self , rank ) : <NEWLINE> <TAB> <NEWLINE> if self . rank is not None and self . rank > rank : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( self , rank ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _series_inversion1 ( p , x , prec ) : <NEWLINE> <TAB> <NEWLINE> if rs_is_puiseux ( p , x ) : <NEWLINE> <TAB> return rs_puiseux ( _series_inversion1 , p , x , prec ) <NEWLINE> <UNTAB> R = p . ring <NEWLINE> zm = R . zero_monom <NEWLINE> c = p [ zm ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if prec == int ( prec ) : <NEWLINE> <TAB> prec = int ( prec ) <NEWLINE> <NEWLINE> <UNTAB> if zm not in p : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if _has_constant_term ( p - c , x ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> one = R ( <NUMBER> ) <NEWLINE> if R . domain is EX : <NEWLINE> <TAB> one = <NUMBER> <NEWLINE> <UNTAB> if c != one : <NEWLINE> <NEWLINE> <TAB> p1 = R ( <NUMBER> ) / c <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> p1 = R ( <NUMBER> ) <NEWLINE> <UNTAB> for precx in _giant_steps ( prec ) : <NEWLINE> <TAB> t = <NUMBER> - rs_mul ( p1 , p , x , precx ) <NEWLINE> p1 = p1 + rs_mul ( p1 , t , x , precx ) <NEWLINE> <UNTAB> return p1 <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_layer ( self , name = None , index = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if index is not None : <NEWLINE> <TAB> if len ( self . layers ) <= index : <NEWLINE> <TAB> raise ValueError ( <STRING> + str ( index ) + <NEWLINE> <STRING> + str ( len ( self . layers ) ) + <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . layers [ index ] <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if not name : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> for layer in self . layers : <NEWLINE> <TAB> if layer . name == name : <NEWLINE> <TAB> return layer <NEWLINE> <UNTAB> <UNTAB> raise ValueError ( <STRING> + name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def after_parent_attach ( self , target , parent ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def cwt ( data , wavelet , widths ) : <NEWLINE> <TAB> <NEWLINE> output = np . zeros ( [ len ( widths ) , len ( data ) ] ) <NEWLINE> for ind , width in enumerate ( widths ) : <NEWLINE> <TAB> wavelet_data = wavelet ( min ( <NUMBER> * width , len ( data ) ) , width ) <NEWLINE> output [ ind , : ] = convolve ( data , wavelet_data , <NEWLINE> mode = <STRING> ) <NEWLINE> <UNTAB> return output <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def batch_det ( a ) : <NEWLINE> <TAB> <NEWLINE> return BatchDet ( ) . apply ( ( a , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def ilcm ( * args ) : <NEWLINE> <TAB> <NEWLINE> if len ( args ) < <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> % len ( args ) ) <NEWLINE> <UNTAB> if <NUMBER> in args : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> a = args [ <NUMBER> ] <NEWLINE> for b in args [ <NUMBER> : ] : <NEWLINE> <TAB> a = a // igcd ( a , b ) * b <NEWLINE> <UNTAB> return a <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _interpolate_single_key ( self , return_key , tri_index , x , y ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> + <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def col_del ( self , i ) : <NEWLINE> <TAB> <NEWLINE> if i < - self . cols or i >= self . cols : <NEWLINE> <TAB> raise IndexError ( <STRING> <NEWLINE> % ( i , self . cols , self . cols ) ) <NEWLINE> <UNTAB> for j in range ( self . rows - <NUMBER> , - <NUMBER> , - <NUMBER> ) : <NEWLINE> <TAB> del self . _mat [ i + j * self . cols ] <NEWLINE> <UNTAB> self . cols -= <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _set_parent ( self , column ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> super ( TypeDecorator , self ) . _set_parent ( column ) <NEWLINE> <NEWLINE> if isinstance ( self . impl , SchemaEventTarget ) : <NEWLINE> <TAB> self . impl . _set_parent ( column ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def expr_from_dict ( rep , * gens ) : <NEWLINE> <TAB> <NEWLINE> result = [ ] <NEWLINE> <NEWLINE> for monom , coeff in rep . items ( ) : <NEWLINE> <TAB> term = [ coeff ] <NEWLINE> for g , m in zip ( gens , monom ) : <NEWLINE> <TAB> if m : <NEWLINE> <TAB> term . append ( Pow ( g , m ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> result . append ( Mul ( * term ) ) <NEWLINE> <NEWLINE> <UNTAB> return Add ( * result ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def draw_violins ( self , ax ) : <NEWLINE> <TAB> <NEWLINE> fill_func = ax . fill_betweenx if self . orient == <STRING> else ax . fill_between <NEWLINE> for i , group_data in enumerate ( self . plot_data ) : <NEWLINE> <NEWLINE> <TAB> kws = dict ( edgecolor = self . gray , linewidth = self . linewidth ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if self . plot_hues is None : <NEWLINE> <NEWLINE> <TAB> support , density = self . support [ i ] , self . density [ i ] <NEWLINE> <NEWLINE> <NEWLINE> if support . size == <NUMBER> : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif support . size == <NUMBER> : <NEWLINE> <TAB> val = np . asscalar ( support ) <NEWLINE> d = np . asscalar ( density ) <NEWLINE> self . draw_single_observation ( ax , i , val , d ) <NEWLINE> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> grid = np . ones ( self . gridsize ) * i <NEWLINE> fill_func ( support , <NEWLINE> grid - density * self . dwidth , <NEWLINE> grid + density * self . dwidth , <NEWLINE> facecolor = self . colors [ i ] , <NEWLINE> ** kws ) <NEWLINE> <NEWLINE> <NEWLINE> if self . inner is None : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> violin_data = remove_na ( group_data ) <NEWLINE> <NEWLINE> <NEWLINE> if self . inner . startswith ( <STRING> ) : <NEWLINE> <TAB> self . draw_box_lines ( ax , violin_data , support , density , i ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif self . inner . startswith ( <STRING> ) : <NEWLINE> <TAB> self . draw_quartiles ( ax , violin_data , support , density , i ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif self . inner . startswith ( <STRING> ) : <NEWLINE> <TAB> self . draw_stick_lines ( ax , violin_data , support , density , i ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif self . inner . startswith ( <STRING> ) : <NEWLINE> <TAB> self . draw_points ( ax , violin_data , i ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> offsets = self . hue_offsets <NEWLINE> for j , hue_level in enumerate ( self . hue_names ) : <NEWLINE> <NEWLINE> <TAB> support , density = self . support [ i ] [ j ] , self . density [ i ] [ j ] <NEWLINE> kws [ <STRING> ] = self . colors [ j ] <NEWLINE> <NEWLINE> <NEWLINE> if not i : <NEWLINE> <TAB> self . add_legend_data ( ax , self . colors [ j ] , hue_level ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if support . size == <NUMBER> : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif support . size == <NUMBER> : <NEWLINE> <TAB> val = np . asscalar ( support ) <NEWLINE> d = np . asscalar ( density ) <NEWLINE> if self . split : <NEWLINE> <TAB> d = d / <NUMBER> <NEWLINE> <UNTAB> at_group = i + offsets [ j ] <NEWLINE> self . draw_single_observation ( ax , at_group , val , d ) <NEWLINE> continue <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . split : <NEWLINE> <NEWLINE> <TAB> grid = np . ones ( self . gridsize ) * i <NEWLINE> if j : <NEWLINE> <TAB> fill_func ( support , <NEWLINE> grid , <NEWLINE> grid + density * self . dwidth , <NEWLINE> ** kws ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> fill_func ( support , <NEWLINE> grid - density * self . dwidth , <NEWLINE> grid , <NEWLINE> ** kws ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . inner is None : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> hue_mask = self . plot_hues [ i ] == hue_level <NEWLINE> violin_data = remove_na ( group_data [ hue_mask ] ) <NEWLINE> <NEWLINE> <NEWLINE> if self . inner . startswith ( <STRING> ) : <NEWLINE> <TAB> self . draw_quartiles ( ax , violin_data , <NEWLINE> support , density , i , <NEWLINE> [ <STRING> , <STRING> ] [ j ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif self . inner . startswith ( <STRING> ) : <NEWLINE> <TAB> self . draw_stick_lines ( ax , violin_data , <NEWLINE> support , density , i , <NEWLINE> [ <STRING> , <STRING> ] [ j ] ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if not j : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> violin_data = remove_na ( group_data ) <NEWLINE> <NEWLINE> <NEWLINE> if self . inner . startswith ( <STRING> ) : <NEWLINE> <TAB> self . draw_box_lines ( ax , violin_data , <NEWLINE> support , density , i ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif self . inner . startswith ( <STRING> ) : <NEWLINE> <TAB> self . draw_points ( ax , violin_data , i ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> grid = np . ones ( self . gridsize ) * ( i + offsets [ j ] ) <NEWLINE> fill_func ( support , <NEWLINE> grid - density * self . dwidth , <NEWLINE> grid + density * self . dwidth , <NEWLINE> ** kws ) <NEWLINE> <NEWLINE> <NEWLINE> if self . inner is None : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> hue_mask = self . plot_hues [ i ] == hue_level <NEWLINE> violin_data = remove_na ( group_data [ hue_mask ] ) <NEWLINE> <NEWLINE> <NEWLINE> if self . inner . startswith ( <STRING> ) : <NEWLINE> <TAB> self . draw_box_lines ( ax , violin_data , <NEWLINE> support , density , <NEWLINE> i + offsets [ j ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif self . inner . startswith ( <STRING> ) : <NEWLINE> <TAB> self . draw_quartiles ( ax , violin_data , <NEWLINE> support , density , <NEWLINE> i + offsets [ j ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif self . inner . startswith ( <STRING> ) : <NEWLINE> <TAB> self . draw_stick_lines ( ax , violin_data , <NEWLINE> support , density , <NEWLINE> i + offsets [ j ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif self . inner . startswith ( <STRING> ) : <NEWLINE> <TAB> self . draw_points ( ax , violin_data , i + offsets [ j ] ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_subset ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( other , Set ) : <NEWLINE> <TAB> return self . intersect ( other ) == self <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % other ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sequence ( seq , limits = None ) : <NEWLINE> <TAB> <NEWLINE> seq = sympify ( seq ) <NEWLINE> <NEWLINE> if is_sequence ( seq , Tuple ) : <NEWLINE> <TAB> return SeqPer ( seq , limits ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return SeqFormula ( seq , limits ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def repeat ( n , body , inputs = None , infeed_queue = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> def _convert_to_list ( xs ) : <NEWLINE> <TAB> if not isinstance ( xs , ( list , tuple ) ) : <NEWLINE> <TAB> return [ xs ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return list ( xs ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def cond ( i , * args ) : <NEWLINE> <TAB> del args <NEWLINE> return i < n <NEWLINE> <NEWLINE> <UNTAB> def body_wrapper ( i , * args ) : <NEWLINE> <TAB> return [ i + <NUMBER> ] + _convert_to_list ( body ( * args ) ) <NEWLINE> <NEWLINE> <UNTAB> inputs = [ <NUMBER> ] if inputs is None else [ <NUMBER> ] + _convert_to_list ( inputs ) <NEWLINE> outputs = while_loop ( <NEWLINE> cond , body_wrapper , inputs = inputs , infeed_queue = infeed_queue , name = name ) <NEWLINE> outputs = _convert_to_list ( outputs ) <NEWLINE> if len ( outputs ) == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> return outputs [ <NUMBER> ] . op <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return outputs [ <NUMBER> : ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def shift ( self , n ) : <NEWLINE> <TAB> <NEWLINE> values = self . _ndarray_values + n * self . freq . n <NEWLINE> if self . hasnans : <NEWLINE> <TAB> values [ self . _isnan ] = tslib . iNaT <NEWLINE> <UNTAB> return self . _shallow_copy ( values = values ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def nroots ( f , n = <NUMBER> , maxsteps = <NUMBER> , cleanup = True ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> F = Poly ( f , greedy = False ) <NEWLINE> <UNTAB> except GeneratorsNeeded : <NEWLINE> <TAB> raise PolynomialError ( <NEWLINE> <STRING> % f ) <NEWLINE> <NEWLINE> <UNTAB> return F . nroots ( n = n , maxsteps = maxsteps , cleanup = cleanup ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def can_fetch ( self , useragent , url ) : <NEWLINE> <TAB> <NEWLINE> if self . disallow_all : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> if self . allow_all : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if not self . last_checked : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> parsed_url = urllib . parse . urlparse ( urllib . parse . unquote ( url ) ) <NEWLINE> url = urllib . parse . urlunparse ( ( <STRING> , <STRING> , parsed_url . path , <NEWLINE> parsed_url . params , parsed_url . query , parsed_url . fragment ) ) <NEWLINE> url = urllib . parse . quote ( url ) <NEWLINE> if not url : <NEWLINE> <TAB> url = <STRING> <NEWLINE> <UNTAB> for entry in self . entries : <NEWLINE> <TAB> if entry . applies_to ( useragent ) : <NEWLINE> <TAB> return entry . allowance ( url ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if self . default_entry : <NEWLINE> <TAB> return self . default_entry . allowance ( url ) <NEWLINE> <NEWLINE> <UNTAB> return True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def plot_interval ( self , parameter = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> t = _symbol ( parameter , real = True ) <NEWLINE> return [ t , - S . Pi , S . Pi ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def square ( x ) : <NEWLINE> <TAB> <NEWLINE> return Square ( ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _make_random_matrix ( self , n_components , n_features ) : <NEWLINE> <TAB> <NEWLINE> random_state = check_random_state ( self . random_state ) <NEWLINE> self . density_ = _check_density ( self . density , n_features ) <NEWLINE> return sparse_random_matrix ( n_components , <NEWLINE> n_features , <NEWLINE> density = self . density_ , <NEWLINE> random_state = random_state ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_proto ( self , export_scope = None ) : <NEWLINE> <TAB> <NEWLINE> if ( export_scope is None or <NEWLINE> self . queue . name . startswith ( export_scope ) ) : <NEWLINE> <TAB> queue_runner_def = queue_runner_pb2 . QueueRunnerDef ( ) <NEWLINE> queue_runner_def . queue_name = ops . strip_name_scope ( <NEWLINE> self . queue . name , export_scope ) <NEWLINE> for enqueue_op in self . enqueue_ops : <NEWLINE> <TAB> queue_runner_def . enqueue_op_name . append ( <NEWLINE> ops . strip_name_scope ( enqueue_op . name , export_scope ) ) <NEWLINE> <UNTAB> queue_runner_def . close_op_name = ops . strip_name_scope ( <NEWLINE> self . close_op . name , export_scope ) <NEWLINE> queue_runner_def . cancel_op_name = ops . strip_name_scope ( <NEWLINE> self . cancel_op . name , export_scope ) <NEWLINE> queue_runner_def . queue_closed_exception_types . extend ( [ <NEWLINE> errors . error_code_from_exception_type ( cls ) <NEWLINE> for cls in self . _queue_closed_exception_types ] ) <NEWLINE> return queue_runner_def <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> def gnc_graph ( n , create_using = None , seed = None ) : <NEWLINE> <TAB> <NEWLINE> G = empty_graph ( <NUMBER> , create_using , default = nx . DiGraph ) <NEWLINE> if not G . is_directed ( ) : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if n == <NUMBER> : <NEWLINE> <TAB> return G <NEWLINE> <NEWLINE> <UNTAB> for source in range ( <NUMBER> , n ) : <NEWLINE> <TAB> target = seed . randrange ( <NUMBER> , source ) <NEWLINE> for succ in G . successors ( target ) : <NEWLINE> <TAB> G . add_edge ( source , succ ) <NEWLINE> <UNTAB> G . add_edge ( source , target ) <NEWLINE> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def dispatch ( self , cls ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> lk = self . _lookup <NEWLINE> try : <NEWLINE> <TAB> impl = lk [ cls ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return impl <NEWLINE> <NEWLINE> <UNTAB> toplevel , _ , _ = cls . __module__ . partition ( <STRING> ) <NEWLINE> try : <NEWLINE> <TAB> register = self . _lazy . pop ( toplevel ) <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> register ( ) <NEWLINE> return self . dispatch ( cls ) <NEWLINE> <NEWLINE> <UNTAB> for cls2 in inspect . getmro ( cls ) [ <NUMBER> : ] : <NEWLINE> <TAB> if cls2 in lk : <NEWLINE> <TAB> lk [ cls ] = lk [ cls2 ] <NEWLINE> return lk [ cls2 ] <NEWLINE> <UNTAB> <UNTAB> raise TypeError ( <STRING> . format ( cls ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _char_wb_ngrams ( self , text_document ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> text_document = self . _white_spaces . sub ( <STRING> , text_document ) <NEWLINE> <NEWLINE> min_n , max_n = self . ngram_range <NEWLINE> ngrams = [ ] <NEWLINE> <NEWLINE> <NEWLINE> ngrams_append = ngrams . append <NEWLINE> <NEWLINE> for w in text_document . split ( ) : <NEWLINE> <TAB> w = <STRING> + w + <STRING> <NEWLINE> w_len = len ( w ) <NEWLINE> for n in xrange ( min_n , max_n + <NUMBER> ) : <NEWLINE> <TAB> offset = <NUMBER> <NEWLINE> ngrams_append ( w [ offset : offset + n ] ) <NEWLINE> while offset + n < w_len : <NEWLINE> <TAB> offset += <NUMBER> <NEWLINE> ngrams_append ( w [ offset : offset + n ] ) <NEWLINE> <UNTAB> if offset == <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return ngrams <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def tick_left ( self ) : <NEWLINE> <TAB> <NEWLINE> label = True <NEWLINE> if <STRING> in self . _major_tick_kw : <NEWLINE> <TAB> label = ( self . _major_tick_kw [ <STRING> ] <NEWLINE> or self . _major_tick_kw [ <STRING> ] ) <NEWLINE> <UNTAB> self . set_ticks_position ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> self . set_tick_params ( which = <STRING> , labelleft = label ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _auto_draw_if_interactive ( fig , val ) : <NEWLINE> <TAB> <NEWLINE> if val and matplotlib . is_interactive ( ) and not fig . canvas . is_saving ( ) : <NEWLINE> <TAB> fig . canvas . draw_idle ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def share_memory_ ( self ) : <NEWLINE> <TAB> <NEWLINE> from torch . multiprocessing import get_sharing_strategy <NEWLINE> if self . is_cuda : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> elif get_sharing_strategy ( ) == <STRING> : <NEWLINE> <TAB> self . _share_filename_ ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _share_fd_ ( ) <NEWLINE> <UNTAB> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def quote ( src_string , return_expr = False ) : <NEWLINE> <TAB> <NEWLINE> node = parse_string ( src_string ) <NEWLINE> body = node . body <NEWLINE> if len ( body ) == <NUMBER> : <NEWLINE> <TAB> if isinstance ( body [ <NUMBER> ] , gast . Expr ) and not return_expr : <NEWLINE> <TAB> out = body [ <NUMBER> ] . value <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> out = body [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> out = node <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def hits_numpy ( G , normalized = True ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> import numpy as np <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> raise ImportError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if len ( G ) == <NUMBER> : <NEWLINE> <TAB> return { } , { } <NEWLINE> <UNTAB> H = nx . hub_matrix ( G , list ( G ) ) <NEWLINE> e , ev = np . linalg . eig ( H ) <NEWLINE> m = e . argsort ( ) [ - <NUMBER> ] <NEWLINE> h = np . array ( ev [ : , m ] ) . flatten ( ) <NEWLINE> A = nx . authority_matrix ( G , list ( G ) ) <NEWLINE> e , ev = np . linalg . eig ( A ) <NEWLINE> m = e . argsort ( ) [ - <NUMBER> ] <NEWLINE> a = np . array ( ev [ : , m ] ) . flatten ( ) <NEWLINE> if normalized : <NEWLINE> <TAB> h = h / h . sum ( ) <NEWLINE> a = a / a . sum ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> h = h / h . max ( ) <NEWLINE> a = a / a . max ( ) <NEWLINE> <UNTAB> hubs = dict ( zip ( G , map ( float , h ) ) ) <NEWLINE> authorities = dict ( zip ( G , map ( float , a ) ) ) <NEWLINE> return hubs , authorities <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def kaiser_atten ( numtaps , width ) : <NEWLINE> <TAB> <NEWLINE> a = <NUMBER> * ( numtaps - <NUMBER> ) * np . pi * width + <NUMBER> <NEWLINE> return a <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _fix_unknown_dimension ( self , input_shape , output_shape ) : <NEWLINE> <TAB> <NEWLINE> output_shape = list ( output_shape ) <NEWLINE> msg = <STRING> <NEWLINE> <NEWLINE> known , unknown = <NUMBER> , None <NEWLINE> for index , dim in enumerate ( output_shape ) : <NEWLINE> <TAB> if dim < <NUMBER> : <NEWLINE> <TAB> if unknown is None : <NEWLINE> <TAB> unknown = index <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> known *= dim <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> original = np . prod ( input_shape , dtype = int ) <NEWLINE> if unknown is not None : <NEWLINE> <TAB> if known == <NUMBER> or original % known != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( msg ) <NEWLINE> <UNTAB> output_shape [ unknown ] = original // known <NEWLINE> <UNTAB> elif original != known : <NEWLINE> <TAB> raise ValueError ( msg ) <NEWLINE> <UNTAB> return output_shape <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , factors = None ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( factors , ( SYMPY_INTS , float ) ) : <NEWLINE> <TAB> factors = S ( factors ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( factors , Factors ) : <NEWLINE> <TAB> factors = factors . factors . copy ( ) <NEWLINE> <UNTAB> elif factors is None or factors is S . One : <NEWLINE> <TAB> factors = { } <NEWLINE> <UNTAB> elif factors is S . Zero or factors == <NUMBER> : <NEWLINE> <TAB> factors = { S . Zero : S . One } <NEWLINE> <UNTAB> elif isinstance ( factors , Number ) : <NEWLINE> <TAB> n = factors <NEWLINE> factors = { } <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> factors [ S . NegativeOne ] = S . One <NEWLINE> n = - n <NEWLINE> <UNTAB> if n is not S . One : <NEWLINE> <TAB> if n . is_Float or n . is_Integer or n is S . Infinity : <NEWLINE> <TAB> factors [ n ] = S . One <NEWLINE> <UNTAB> elif n . is_Rational : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if n . p != <NUMBER> : <NEWLINE> <TAB> factors [ Integer ( n . p ) ] = S . One <NEWLINE> <UNTAB> factors [ Integer ( n . q ) ] = S . NegativeOne <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % n ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif isinstance ( factors , Basic ) and not factors . args : <NEWLINE> <TAB> factors = { factors : S . One } <NEWLINE> <UNTAB> elif isinstance ( factors , Expr ) : <NEWLINE> <TAB> c , nc = factors . args_cnc ( ) <NEWLINE> i = c . count ( I ) <NEWLINE> for _ in range ( i ) : <NEWLINE> <TAB> c . remove ( I ) <NEWLINE> <UNTAB> factors = dict ( Mul . _from_args ( c ) . as_powers_dict ( ) ) <NEWLINE> if i : <NEWLINE> <TAB> factors [ I ] = S . One * i <NEWLINE> <UNTAB> if nc : <NEWLINE> <TAB> factors [ Mul ( * nc , evaluate = False ) ] = S . One <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> factors = factors . copy ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> handle = [ ] <NEWLINE> for k in factors : <NEWLINE> <TAB> if k is I or k in ( - <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> handle . append ( k ) <NEWLINE> <UNTAB> <UNTAB> if handle : <NEWLINE> <TAB> i1 = S . One <NEWLINE> for k in handle : <NEWLINE> <TAB> if not _isnumber ( factors [ k ] ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> i1 *= k ** factors . pop ( k ) <NEWLINE> <UNTAB> if i1 is not S . One : <NEWLINE> <TAB> for a in i1 . args if i1 . is_Mul else [ i1 ] : <NEWLINE> <TAB> if a is S . NegativeOne : <NEWLINE> <TAB> factors [ a ] = S . One <NEWLINE> <UNTAB> elif a is I : <NEWLINE> <TAB> factors [ I ] = S . One <NEWLINE> <UNTAB> elif a . is_Pow : <NEWLINE> <TAB> if S . NegativeOne not in factors : <NEWLINE> <TAB> factors [ S . NegativeOne ] = S . Zero <NEWLINE> <UNTAB> factors [ S . NegativeOne ] += a . exp <NEWLINE> <UNTAB> elif a == <NUMBER> : <NEWLINE> <TAB> factors [ a ] = S . One <NEWLINE> <UNTAB> elif a == - <NUMBER> : <NEWLINE> <TAB> factors [ - a ] = S . One <NEWLINE> factors [ S . NegativeOne ] = S . One <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % a ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> self . factors = factors <NEWLINE> try : <NEWLINE> <TAB> self . gens = frozenset ( factors . keys ( ) ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def fixed_size_partitioner ( num_shards , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> def _partitioner ( shape , ** unused_args ) : <NEWLINE> <TAB> partitions_list = [ <NUMBER> ] * len ( shape ) <NEWLINE> partitions_list [ axis ] = min ( num_shards , shape . dims [ axis ] . value ) <NEWLINE> return partitions_list <NEWLINE> <UNTAB> return _partitioner <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dtype_to_descr ( dtype ) : <NEWLINE> <TAB> <NEWLINE> if dtype . names is not None : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return dtype . descr <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return dtype . str <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _calc_uniform_order_statistic_medians ( n ) : <NEWLINE> <TAB> <NEWLINE> v = np . zeros ( n , dtype = np . float64 ) <NEWLINE> v [ - <NUMBER> ] = <NUMBER> ** ( <NUMBER> / n ) <NEWLINE> v [ <NUMBER> ] = <NUMBER> - v [ - <NUMBER> ] <NEWLINE> i = np . arange ( <NUMBER> , n ) <NEWLINE> v [ <NUMBER> : - <NUMBER> ] = ( i - <NUMBER> ) / ( n + <NUMBER> ) <NEWLINE> return v <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _get_label_info ( G , label_name ) : <NEWLINE> <TAB> <NEWLINE> import numpy as np <NEWLINE> <NEWLINE> labels = [ ] <NEWLINE> label_to_id = { } <NEWLINE> lid = <NUMBER> <NEWLINE> for i , n in enumerate ( G . nodes ( data = True ) ) : <NEWLINE> <TAB> if label_name in n [ <NUMBER> ] : <NEWLINE> <TAB> label = n [ <NUMBER> ] [ label_name ] <NEWLINE> if label not in label_to_id : <NEWLINE> <TAB> label_to_id [ label ] = lid <NEWLINE> lid += <NUMBER> <NEWLINE> <UNTAB> labels . append ( [ i , label_to_id [ label ] ] ) <NEWLINE> <UNTAB> <UNTAB> labels = np . array ( labels ) <NEWLINE> label_dict = np . array ( [ label for label , _ in sorted ( <NEWLINE> label_to_id . items ( ) , key = lambda x : x [ <NUMBER> ] ) ] ) <NEWLINE> return ( labels , label_dict ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def str_encode ( arr , encoding , errors = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if encoding in _cpython_optimized_encoders : <NEWLINE> <NEWLINE> <TAB> f = lambda x : x . encode ( encoding , errors ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> encoder = codecs . getencoder ( encoding ) <NEWLINE> f = lambda x : encoder ( x , errors ) [ <NUMBER> ] <NEWLINE> <UNTAB> return _na_map ( f , arr ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rs_mul ( p1 , p2 , x , prec ) : <NEWLINE> <TAB> <NEWLINE> R = p1 . ring <NEWLINE> p = R . zero <NEWLINE> if R . __class__ != p2 . ring . __class__ or R != p2 . ring : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> iv = R . gens . index ( x ) <NEWLINE> if not isinstance ( p2 , PolyElement ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if R == p2 . ring : <NEWLINE> <TAB> get = p . get <NEWLINE> items2 = list ( p2 . items ( ) ) <NEWLINE> items2 . sort ( key = lambda e : e [ <NUMBER> ] [ iv ] ) <NEWLINE> if R . ngens == <NUMBER> : <NEWLINE> <TAB> for exp1 , v1 in p1 . items ( ) : <NEWLINE> <TAB> for exp2 , v2 in items2 : <NEWLINE> <TAB> exp = exp1 [ <NUMBER> ] + exp2 [ <NUMBER> ] <NEWLINE> if exp < prec : <NEWLINE> <TAB> exp = ( exp , ) <NEWLINE> p [ exp ] = get ( exp , <NUMBER> ) + v1 * v2 <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> monomial_mul = R . monomial_mul <NEWLINE> for exp1 , v1 in p1 . items ( ) : <NEWLINE> <TAB> for exp2 , v2 in items2 : <NEWLINE> <TAB> if exp1 [ iv ] + exp2 [ iv ] < prec : <NEWLINE> <TAB> exp = monomial_mul ( exp1 , exp2 ) <NEWLINE> p [ exp ] = get ( exp , <NUMBER> ) + v1 * v2 <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> p . strip_zero ( ) <NEWLINE> return p <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rfftfreq ( n , d = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( n , integer_types ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> val = <NUMBER> / ( n * d ) <NEWLINE> N = n // <NUMBER> + <NUMBER> <NEWLINE> results = arange ( <NUMBER> , N , dtype = int ) <NEWLINE> return results * val <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> def partial_duplication_graph ( N , n , p , q , seed = None ) : <NEWLINE> <TAB> <NEWLINE> if p < <NUMBER> or p > <NUMBER> or q < <NUMBER> or q > <NUMBER> : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise NetworkXError ( msg ) <NEWLINE> <UNTAB> if n > N : <NEWLINE> <TAB> raise NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> G = nx . complete_graph ( n ) <NEWLINE> for new_node in range ( n , N ) : <NEWLINE> <NEWLINE> <TAB> G . add_node ( new_node ) <NEWLINE> <NEWLINE> <NEWLINE> src_node = seed . randint ( <NUMBER> , new_node ) <NEWLINE> <NEWLINE> <NEWLINE> if seed . random ( ) < q : <NEWLINE> <TAB> G . add_edge ( new_node , src_node ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for neighbor_node in list ( nx . all_neighbors ( G , src_node ) ) : <NEWLINE> <NEWLINE> <TAB> if seed . random ( ) < p : <NEWLINE> <TAB> G . add_edge ( new_node , neighbor_node ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def uniform_ ( tensor , a = <NUMBER> , b = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> with torch . no_grad ( ) : <NEWLINE> <TAB> return tensor . uniform_ ( a , b ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def onenormest ( A , t = <NUMBER> , itmax = <NUMBER> , compute_v = False , compute_w = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> A = aslinearoperator ( A ) <NEWLINE> if A . shape [ <NUMBER> ] != A . shape [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> n = A . shape [ <NUMBER> ] <NEWLINE> if t >= n : <NEWLINE> <TAB> A_explicit = np . asarray ( aslinearoperator ( A ) . matmat ( np . identity ( n ) ) ) <NEWLINE> if A_explicit . shape != ( n , n ) : <NEWLINE> <TAB> raise Exception ( <STRING> , <NEWLINE> <STRING> + str ( A_explicit . shape ) ) <NEWLINE> <UNTAB> col_abs_sums = abs ( A_explicit ) . sum ( axis = <NUMBER> ) <NEWLINE> if col_abs_sums . shape != ( n , ) : <NEWLINE> <TAB> raise Exception ( <STRING> , <NEWLINE> <STRING> + str ( col_abs_sums . shape ) ) <NEWLINE> <UNTAB> argmax_j = np . argmax ( col_abs_sums ) <NEWLINE> v = elementary_vector ( n , argmax_j ) <NEWLINE> w = A_explicit [ : , argmax_j ] <NEWLINE> est = col_abs_sums [ argmax_j ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> est , v , w , nmults , nresamples = _onenormest_core ( A , A . H , t , itmax ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if compute_v or compute_w : <NEWLINE> <TAB> result = ( est , ) <NEWLINE> if compute_v : <NEWLINE> <TAB> result += ( v , ) <NEWLINE> <UNTAB> if compute_w : <NEWLINE> <TAB> result += ( w , ) <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return est <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , serialized = None , mesh_shape = None , device_coordinates = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . _serialized = serialized <NEWLINE> <NEWLINE> if serialized : <NEWLINE> <TAB> self . _parse_topology ( serialized ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _mesh_shape = np . asarray ( mesh_shape , dtype = np . int32 ) <NEWLINE> self . _device_coordinates = np . asarray ( device_coordinates , np . int32 ) <NEWLINE> if len ( self . _mesh_shape ) != <NUMBER> or any ( self . _mesh_shape < <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( self . _mesh_shape ) ) <NEWLINE> <NEWLINE> <UNTAB> if ( len ( self . _device_coordinates . shape ) != <NUMBER> or <NEWLINE> self . _device_coordinates . shape [ <NUMBER> ] != len ( self . _mesh_shape ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . _topology_tasks , self . _topology_devices = self . _invert_topology ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_figure ( self , fig ) : <NEWLINE> <TAB> <NEWLINE> martist . Artist . set_figure ( self , fig ) <NEWLINE> <NEWLINE> self . bbox = mtransforms . TransformedBbox ( self . _position , <NEWLINE> fig . transFigure ) <NEWLINE> <NEWLINE> self . dataLim = mtransforms . Bbox . null ( ) <NEWLINE> self . viewLim = mtransforms . Bbox . unit ( ) <NEWLINE> self . transScale = mtransforms . TransformWrapper ( <NEWLINE> mtransforms . IdentityTransform ( ) ) <NEWLINE> <NEWLINE> self . _set_lim_and_transforms ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def asinh_eager_fallback ( x , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , ( x , ) = _execute . args_to_matching_eager ( [ x ] , _ctx ) <NEWLINE> _inputs_flat = [ x ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def concat_same_type ( self , to_concat , placement = None ) : <NEWLINE> <TAB> <NEWLINE> values = self . _holder . _concat_same_type ( <NEWLINE> [ blk . values for blk in to_concat ] ) <NEWLINE> placement = placement or slice ( <NUMBER> , len ( values ) , <NUMBER> ) <NEWLINE> return self . make_block_same_class ( values , ndim = self . ndim , <NEWLINE> placement = placement ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _update_dim_sizes ( dim_sizes , arg , core_dims ) : <NEWLINE> <TAB> <NEWLINE> if not core_dims : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> num_core_dims = len ( core_dims ) <NEWLINE> if arg . ndim < num_core_dims : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> % ( arg . ndim , core_dims ) ) <NEWLINE> <NEWLINE> <UNTAB> core_shape = arg . shape [ - num_core_dims : ] <NEWLINE> for dim , size in zip ( core_dims , core_shape ) : <NEWLINE> <TAB> if dim in dim_sizes : <NEWLINE> <TAB> if size != dim_sizes [ dim ] : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> % ( dim , size , dim_sizes [ dim ] ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> dim_sizes [ dim ] = size <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _minpoly_add ( x , dom , * a ) : <NEWLINE> <TAB> <NEWLINE> mp = _minpoly_op_algebraic_element ( Add , a [ <NUMBER> ] , a [ <NUMBER> ] , x , dom ) <NEWLINE> p = a [ <NUMBER> ] + a [ <NUMBER> ] <NEWLINE> for px in a [ <NUMBER> : ] : <NEWLINE> <TAB> mp = _minpoly_op_algebraic_element ( Add , p , px , x , dom , mp1 = mp ) <NEWLINE> p = p + px <NEWLINE> <UNTAB> return mp <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def log_to_stderr ( self , level = None ) : <NEWLINE> <TAB> <NEWLINE> from . util import log_to_stderr <NEWLINE> return log_to_stderr ( level ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _codes_for_groupby ( self , sort , observed ) : <NEWLINE> <TAB> <NEWLINE> return self . values . _codes_for_groupby ( sort , observed ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _process_args ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( args [ <NUMBER> ] , TriContourSet ) : <NEWLINE> <TAB> C = args [ <NUMBER> ] . cppContourGenerator <NEWLINE> if self . levels is None : <NEWLINE> <TAB> self . levels = args [ <NUMBER> ] . levels <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> tri , z = self . _contour_args ( args , kwargs ) <NEWLINE> C = _tri . TriContourGenerator ( tri . get_cpp_triangulation ( ) , z ) <NEWLINE> self . _mins = [ tri . x . min ( ) , tri . y . min ( ) ] <NEWLINE> self . _maxs = [ tri . x . max ( ) , tri . y . max ( ) ] <NEWLINE> <NEWLINE> <UNTAB> self . cppContourGenerator = C <NEWLINE> return kwargs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_underline_thickness ( self , font , fontsize , dpi ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def fractional_avg_pool_eager_fallback ( value , pooling_ratio , pseudo_random = False , overlapping = False , deterministic = False , seed = <NUMBER> , seed2 = <NUMBER> , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> if not isinstance ( pooling_ratio , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % pooling_ratio ) <NEWLINE> <UNTAB> pooling_ratio = [ _execute . make_float ( _f , <STRING> ) for _f in pooling_ratio ] <NEWLINE> if pseudo_random is None : <NEWLINE> <TAB> pseudo_random = False <NEWLINE> <UNTAB> pseudo_random = _execute . make_bool ( pseudo_random , <STRING> ) <NEWLINE> if overlapping is None : <NEWLINE> <TAB> overlapping = False <NEWLINE> <UNTAB> overlapping = _execute . make_bool ( overlapping , <STRING> ) <NEWLINE> if deterministic is None : <NEWLINE> <TAB> deterministic = False <NEWLINE> <UNTAB> deterministic = _execute . make_bool ( deterministic , <STRING> ) <NEWLINE> if seed is None : <NEWLINE> <TAB> seed = <NUMBER> <NEWLINE> <UNTAB> seed = _execute . make_int ( seed , <STRING> ) <NEWLINE> if seed2 is None : <NEWLINE> <TAB> seed2 = <NUMBER> <NEWLINE> <UNTAB> seed2 = _execute . make_int ( seed2 , <STRING> ) <NEWLINE> _attr_T , ( value , ) = _execute . args_to_matching_eager ( [ value ] , _ctx ) <NEWLINE> _inputs_flat = [ value ] <NEWLINE> _attrs = ( <STRING> , pooling_ratio , <STRING> , pseudo_random , <NEWLINE> <STRING> , overlapping , <STRING> , deterministic , <STRING> , seed , <NEWLINE> <STRING> , seed2 , <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result = _FractionalAvgPoolOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def tanh ( x ) : <NEWLINE> <TAB> <NEWLINE> return Tanh ( ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def commit ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not self . _parent . is_active : <NEWLINE> <TAB> raise exc . InvalidRequestError ( <STRING> ) <NEWLINE> <UNTAB> self . _do_commit ( ) <NEWLINE> self . is_active = False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def old_frac_field ( self , * symbols , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> from sympy . polys . domains . old_fractionfield import FractionField <NEWLINE> return FractionField ( self , * symbols , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _dmp_ff_trivial_gcd ( f , g , u , K ) : <NEWLINE> <TAB> <NEWLINE> zero_f = dmp_zero_p ( f , u ) <NEWLINE> zero_g = dmp_zero_p ( g , u ) <NEWLINE> <NEWLINE> if zero_f and zero_g : <NEWLINE> <TAB> return tuple ( dmp_zeros ( <NUMBER> , u , K ) ) <NEWLINE> <UNTAB> elif zero_f : <NEWLINE> <TAB> return ( dmp_ground_monic ( g , u , K ) , <NEWLINE> dmp_zero ( u ) , <NEWLINE> dmp_ground ( dmp_ground_LC ( g , u , K ) , u ) ) <NEWLINE> <UNTAB> elif zero_g : <NEWLINE> <TAB> return ( dmp_ground_monic ( f , u , K ) , <NEWLINE> dmp_ground ( dmp_ground_LC ( f , u , K ) , u ) , <NEWLINE> dmp_zero ( u ) ) <NEWLINE> <UNTAB> elif query ( <STRING> ) : <NEWLINE> <TAB> return _dmp_simplify_gcd ( f , g , u , K ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _real_roots ( cls , poly ) : <NEWLINE> <TAB> <NEWLINE> factors = _pure_factors ( poly ) <NEWLINE> <NEWLINE> reals = cls . _get_reals ( factors ) <NEWLINE> reals_count = cls . _count_roots ( reals ) <NEWLINE> <NEWLINE> roots = [ ] <NEWLINE> <NEWLINE> for index in range ( <NUMBER> , reals_count ) : <NEWLINE> <TAB> roots . append ( cls . _reals_index ( reals , index ) ) <NEWLINE> <NEWLINE> <UNTAB> return roots <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def diag_indices_from ( arr ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not arr . ndim >= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if not alltrue ( diff ( arr . shape ) == <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return diag_indices ( arr . shape [ <NUMBER> ] , arr . ndim ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def draw_cursor ( self , event ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_irreducible_p ( f , K ) : <NEWLINE> <TAB> <NEWLINE> return dmp_irreducible_p ( f , <NUMBER> , K ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def log_likelihood_op ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _log_likelihood_op <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_pathlib_path ( obj ) : <NEWLINE> <TAB> <NEWLINE> return Path is not None and isinstance ( obj , Path ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def square ( x ) : <NEWLINE> <TAB> <NEWLINE> return math_ops . square ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def cancel ( f , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> from sympy . core . exprtools import factor_terms <NEWLINE> from sympy . functions . elementary . piecewise import Piecewise <NEWLINE> options . allowed_flags ( args , [ <STRING> ] ) <NEWLINE> <NEWLINE> f = sympify ( f ) <NEWLINE> <NEWLINE> if not isinstance ( f , ( tuple , Tuple ) ) : <NEWLINE> <TAB> if f . is_Number or isinstance ( f , Relational ) or not isinstance ( f , Expr ) : <NEWLINE> <TAB> return f <NEWLINE> <UNTAB> f = factor_terms ( f , radical = True ) <NEWLINE> p , q = f . as_numer_denom ( ) <NEWLINE> <NEWLINE> <UNTAB> elif len ( f ) == <NUMBER> : <NEWLINE> <TAB> p , q = f <NEWLINE> <UNTAB> elif isinstance ( f , Tuple ) : <NEWLINE> <TAB> return factor_terms ( f ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % f ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> ( F , G ) , opt = parallel_poly_from_expr ( ( p , q ) , * gens , ** args ) <NEWLINE> <UNTAB> except PolificationFailed : <NEWLINE> <TAB> if not isinstance ( f , ( tuple , Tuple ) ) : <NEWLINE> <TAB> return f <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return S . One , p , q <NEWLINE> <UNTAB> <UNTAB> except PolynomialError as msg : <NEWLINE> <TAB> if f . is_commutative and not f . has ( Piecewise ) : <NEWLINE> <TAB> raise PolynomialError ( msg ) <NEWLINE> <NEWLINE> <UNTAB> if f . is_Add or f . is_Mul : <NEWLINE> <TAB> c , nc = sift ( f . args , lambda x : <NEWLINE> x . is_commutative is True and not x . has ( Piecewise ) , <NEWLINE> binary = True ) <NEWLINE> nc = [ cancel ( i ) for i in nc ] <NEWLINE> return f . func ( cancel ( f . func . _from_args ( c ) ) , * nc ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> reps = [ ] <NEWLINE> pot = preorder_traversal ( f ) <NEWLINE> next ( pot ) <NEWLINE> for e in pot : <NEWLINE> <NEWLINE> <TAB> if isinstance ( e , ( tuple , Tuple , BooleanAtom ) ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> reps . append ( ( e , cancel ( e ) ) ) <NEWLINE> pot . skip ( ) <NEWLINE> <UNTAB> except NotImplementedError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> return f . xreplace ( dict ( reps ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> c , P , Q = F . cancel ( G ) <NEWLINE> <NEWLINE> if not isinstance ( f , ( tuple , Tuple ) ) : <NEWLINE> <TAB> return c * ( P . as_expr ( ) / Q . as_expr ( ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if not opt . polys : <NEWLINE> <TAB> return c , P . as_expr ( ) , Q . as_expr ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return c , P , Q <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _model_ready_for_local_init ( self , sess ) : <NEWLINE> <TAB> <NEWLINE> return _ready ( self . _ready_for_local_init_op , sess , <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def primitive ( f ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( f . rep , <STRING> ) : <NEWLINE> <TAB> cont , result = f . rep . primitive ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise OperationNotSupported ( f , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return f . rep . dom . to_sympy ( cont ) , f . per ( result ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_xaxis_text1_transform ( self , pad_points ) : <NEWLINE> <TAB> <NEWLINE> labels_align = matplotlib . rcParams [ <STRING> ] <NEWLINE> <NEWLINE> return ( self . get_xaxis_transform ( which = <STRING> ) + <NEWLINE> mtransforms . ScaledTranslation ( <NUMBER> , - <NUMBER> * pad_points / <NUMBER> , <NEWLINE> self . figure . dpi_scale_trans ) , <NEWLINE> <STRING> , labels_align ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def ifib ( n , _cache = { } ) : <NEWLINE> <TAB> <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> return ( - <NUMBER> ) ** ( - n + <NUMBER> ) * ifib ( - n ) <NEWLINE> <UNTAB> if n in _cache : <NEWLINE> <TAB> return _cache [ n ] <NEWLINE> <UNTAB> m = n <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> a , b , p , q = MPZ_ONE , MPZ_ZERO , MPZ_ZERO , MPZ_ONE <NEWLINE> while n : <NEWLINE> <TAB> if n & <NUMBER> : <NEWLINE> <TAB> aq = a * q <NEWLINE> a , b = b * q + aq + a * p , b * p + aq <NEWLINE> n -= <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> qq = q * q <NEWLINE> p , q = p * p + qq , qq + <NUMBER> * p * q <NEWLINE> n >>= <NUMBER> <NEWLINE> <UNTAB> <UNTAB> if m < <NUMBER> : <NEWLINE> <TAB> _cache [ m ] = b <NEWLINE> <UNTAB> return b <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def set_floatx ( floatx ) : <NEWLINE> <TAB> <NEWLINE> global _FLOATX <NEWLINE> if floatx not in { <STRING> , <STRING> , <STRING> } : <NEWLINE> <TAB> raise ValueError ( <STRING> + str ( floatx ) ) <NEWLINE> <UNTAB> _FLOATX = str ( floatx ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def tf2sos ( b , a , pairing = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return zpk2sos ( * tf2zpk ( b , a ) , pairing = pairing ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_initialized ( self , name = None ) : <NEWLINE> <TAB> <NEWLINE> return gen_resource_variable_ops . var_is_initialized_op ( self . handle , name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def chebys ( n , monic = False ) : <NEWLINE> <TAB> <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if n == <NUMBER> : <NEWLINE> <TAB> n1 = n + <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> n1 = n <NEWLINE> <UNTAB> x , w , mu0 = roots_chebys ( n1 , mu = True ) <NEWLINE> if n == <NUMBER> : <NEWLINE> <TAB> x , w = [ ] , [ ] <NEWLINE> <UNTAB> hn = pi <NEWLINE> kn = <NUMBER> <NEWLINE> p = orthopoly1d ( x , w , hn , kn , <NEWLINE> wfunc = lambda x : sqrt ( <NUMBER> - x * x / <NUMBER> ) , <NEWLINE> limits = ( - <NUMBER> , <NUMBER> ) , monic = monic ) <NEWLINE> if not monic : <NEWLINE> <TAB> factor = ( n + <NUMBER> ) / p ( <NUMBER> ) <NEWLINE> p . _scale ( factor ) <NEWLINE> p . __dict__ [ <STRING> ] = lambda x : eval_chebys ( n , x ) <NEWLINE> <UNTAB> return p <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def simple_values_from_events ( events , tags ) : <NEWLINE> <TAB> <NEWLINE> step_by_tag = { } <NEWLINE> value_by_tag = { } <NEWLINE> for e in events : <NEWLINE> <TAB> if e . HasField ( <STRING> ) : <NEWLINE> <TAB> for v in e . summary . value : <NEWLINE> <TAB> tag = v . tag <NEWLINE> if tag in tags : <NEWLINE> <TAB> if not v . HasField ( <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> % tag ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if tag not in step_by_tag or e . step > step_by_tag [ tag ] : <NEWLINE> <TAB> step_by_tag [ tag ] = e . step <NEWLINE> value_by_tag [ tag ] = v . simple_value <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> return value_by_tag <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def morlet ( M , w = <NUMBER> , s = <NUMBER> , complete = True ) : <NEWLINE> <TAB> <NEWLINE> x = linspace ( - s * <NUMBER> * pi , s * <NUMBER> * pi , M ) <NEWLINE> output = exp ( <NUMBER> * w * x ) <NEWLINE> <NEWLINE> if complete : <NEWLINE> <TAB> output -= exp ( - <NUMBER> * ( w ** <NUMBER> ) ) <NEWLINE> <NEWLINE> <UNTAB> output *= exp ( - <NUMBER> * ( x ** <NUMBER> ) ) * pi ** ( - <NUMBER> ) <NEWLINE> <NEWLINE> return output <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def visit_Assign ( self , node , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if len ( node . targets ) != <NUMBER> : <NEWLINE> <TAB> raise SyntaxError ( <STRING> ) <NEWLINE> <UNTAB> if not isinstance ( node . targets [ <NUMBER> ] , ast . Name ) : <NEWLINE> <TAB> raise SyntaxError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if self . env . target is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> assigner = self . visit ( node . targets [ <NUMBER> ] , ** kwargs ) <NEWLINE> <UNTAB> except UndefinedVariableError : <NEWLINE> <TAB> assigner = node . targets [ <NUMBER> ] . id <NEWLINE> <NEWLINE> <UNTAB> self . assigner = getattr ( assigner , <STRING> , assigner ) <NEWLINE> if self . assigner is None : <NEWLINE> <TAB> raise SyntaxError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return self . visit ( node . value , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def restore_state ( self , state , name = None ) : <NEWLINE> <TAB> <NEWLINE> if self . _reader_ref . dtype == dtypes . resource : <NEWLINE> <TAB> return gen_io_ops . reader_restore_state_v2 ( <NEWLINE> self . _reader_ref , state , name = name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return gen_io_ops . reader_restore_state ( self . _reader_ref , state , name = name ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def load_model ( filepath , custom_objects = None , compile = True ) : <NEWLINE> <TAB> <NEWLINE> if h5py is None : <NEWLINE> <TAB> raise ImportError ( <STRING> ) <NEWLINE> <UNTAB> model = None <NEWLINE> opened_new_file = not isinstance ( filepath , h5py . Group ) <NEWLINE> f = h5dict ( filepath , <STRING> ) <NEWLINE> try : <NEWLINE> <TAB> model = _deserialize_model ( f , custom_objects , compile ) <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> if opened_new_file : <NEWLINE> <TAB> f . close ( ) <NEWLINE> <UNTAB> <UNTAB> return model <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def east_asian_len ( data , encoding = None , ambiguous_width = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( data , text_type ) : <NEWLINE> <TAB> return sum ( _EAW_MAP . get ( east_asian_width ( c ) , ambiguous_width ) for c in data ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return len ( data ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def format_schema ( self , name , quote = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return self . quote ( name , quote ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def greater_equal_eager_fallback ( x , y , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ x , y ] , _ctx ) <NEWLINE> ( x , y ) = _inputs_T <NEWLINE> _inputs_flat = [ x , y ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __getstate__ ( self ) : <NEWLINE> <TAB> <NEWLINE> state = self . __dict__ . copy ( ) <NEWLINE> state [ <STRING> ] = None <NEWLINE> return state <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def hermeval2d ( x , y , c ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> x , y = np . array ( ( x , y ) , copy = <NUMBER> ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> c = hermeval ( x , c ) <NEWLINE> c = hermeval ( y , c , tensor = False ) <NEWLINE> return c <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def coerce_compared_value ( self , op , value ) : <NEWLINE> <TAB> <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __getitem__ ( self , name ) : <NEWLINE> <TAB> <NEWLINE> return getattr ( self , name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def load_base_library ( ) : <NEWLINE> <TAB> <NEWLINE> library = read_style_directory ( BASE_LIBRARY_PATH ) <NEWLINE> return library <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _str_extract_noexpand ( arr , pat , flags = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> from pandas import DataFrame , Index <NEWLINE> <NEWLINE> regex = re . compile ( pat , flags = flags ) <NEWLINE> groups_or_na = _groups_or_na_fun ( regex ) <NEWLINE> <NEWLINE> if regex . groups == <NUMBER> : <NEWLINE> <TAB> result = np . array ( [ groups_or_na ( val ) [ <NUMBER> ] for val in arr ] , dtype = object ) <NEWLINE> name = _get_single_group_name ( regex ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if isinstance ( arr , Index ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> name = None <NEWLINE> names = dict ( zip ( regex . groupindex . values ( ) , regex . groupindex . keys ( ) ) ) <NEWLINE> columns = [ names . get ( <NUMBER> + i , i ) for i in range ( regex . groups ) ] <NEWLINE> if arr . empty : <NEWLINE> <TAB> result = DataFrame ( columns = columns , dtype = object ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result = DataFrame ( <NEWLINE> [ groups_or_na ( val ) for val in arr ] , <NEWLINE> columns = columns , <NEWLINE> index = arr . index , <NEWLINE> dtype = object ) <NEWLINE> <UNTAB> <UNTAB> return result , name <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _rmatvec ( self , x ) : <NEWLINE> <TAB> <NEWLINE> if type ( self ) . _adjoint == LinearOperator . _adjoint : <NEWLINE> <NEWLINE> <TAB> raise NotImplementedError <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . H . matvec ( x ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dump ( obj , fp ) : <NEWLINE> <TAB> <NEWLINE> encoder = ArffEncoder ( ) <NEWLINE> generator = encoder . iter_encode ( obj ) <NEWLINE> <NEWLINE> last_row = next ( generator ) <NEWLINE> for row in generator : <NEWLINE> <TAB> fp . write ( last_row + <STRING> ) <NEWLINE> last_row = row <NEWLINE> <UNTAB> fp . write ( last_row ) <NEWLINE> <NEWLINE> return fp <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_stretch ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _stretch <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_text_path_transform ( self , x , y , s , prop , angle , ismath ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> text2path = self . _text2path <NEWLINE> fontsize = self . points_to_pixels ( prop . get_size_in_points ( ) ) <NEWLINE> <NEWLINE> if ismath == <STRING> : <NEWLINE> <TAB> verts , codes = text2path . get_text_path ( prop , s , ismath = False , <NEWLINE> usetex = True ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> verts , codes = text2path . get_text_path ( prop , s , ismath = ismath , <NEWLINE> usetex = False ) <NEWLINE> <NEWLINE> <UNTAB> path = Path ( verts , codes ) <NEWLINE> angle = np . deg2rad ( angle ) <NEWLINE> if self . flipy ( ) : <NEWLINE> <TAB> transform = Affine2D ( ) . scale ( fontsize / text2path . FONT_SCALE , <NEWLINE> fontsize / text2path . FONT_SCALE ) <NEWLINE> transform = transform . rotate ( angle ) . translate ( x , self . height - y ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> transform = Affine2D ( ) . scale ( fontsize / text2path . FONT_SCALE , <NEWLINE> fontsize / text2path . FONT_SCALE ) <NEWLINE> transform = transform . rotate ( angle ) . translate ( x , y ) <NEWLINE> <NEWLINE> <UNTAB> return path , transform <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def mark_flags_as_required ( flag_names , flag_values = _flagvalues . FLAGS ) : <NEWLINE> <TAB> <NEWLINE> for flag_name in flag_names : <NEWLINE> <TAB> mark_flag_as_required ( flag_name , flag_values ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def kl_divergence ( self , other , name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> with self . _name_scope ( name ) : <NEWLINE> <TAB> return self . _kl_divergence ( other ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def optimize_slices ( dsk ) : <NEWLINE> <TAB> <NEWLINE> fancy_ind_types = ( list , np . ndarray ) <NEWLINE> dsk = dsk . copy ( ) <NEWLINE> for k , v in dsk . items ( ) : <NEWLINE> <TAB> if type ( v ) is tuple and v [ <NUMBER> ] in GETTERS and len ( v ) in ( <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> if len ( v ) == <NUMBER> : <NEWLINE> <TAB> get , a , a_index = v <NEWLINE> <NEWLINE> a_asarray = get is not getitem <NEWLINE> a_lock = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> get , a , a_index , a_asarray , a_lock = v <NEWLINE> <UNTAB> while type ( a ) is tuple and a [ <NUMBER> ] in GETTERS and len ( a ) in ( <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> if len ( a ) == <NUMBER> : <NEWLINE> <TAB> f2 , b , b_index = a <NEWLINE> b_asarray = f2 is not getitem <NEWLINE> b_lock = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> f2 , b , b_index , b_asarray , b_lock = a <NEWLINE> <NEWLINE> <UNTAB> if a_lock and a_lock is not b_lock : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> if ( type ( a_index ) is tuple ) != ( type ( b_index ) is tuple ) : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> if type ( a_index ) is tuple : <NEWLINE> <TAB> indices = b_index + a_index <NEWLINE> if ( len ( a_index ) != len ( b_index ) and <NEWLINE> any ( i is None for i in indices ) ) : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> if ( f2 is getter_nofancy and <NEWLINE> any ( isinstance ( i , fancy_ind_types ) for i in indices ) ) : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> elif ( f2 is getter_nofancy and <NEWLINE> ( type ( a_index ) in fancy_ind_types or <NEWLINE> type ( b_index ) in fancy_ind_types ) ) : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> c_index = fuse_slice ( b_index , a_index ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> get = getter if f2 is getter_inline else f2 <NEWLINE> <UNTAB> except NotImplementedError : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> a , a_index , a_lock = b , c_index , b_lock <NEWLINE> a_asarray |= b_asarray <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if ( get not in GETNOREMOVE and <NEWLINE> ( ( type ( a_index ) is slice and not a_index . start and <NEWLINE> a_index . stop is None and a_index . step is None ) or <NEWLINE> ( type ( a_index ) is tuple and <NEWLINE> all ( type ( s ) is slice and not s . start and s . stop is None and <NEWLINE> s . step is None for s in a_index ) ) ) ) : <NEWLINE> <TAB> dsk [ k ] = a <NEWLINE> <UNTAB> elif get is getitem or ( a_asarray and not a_lock ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> dsk [ k ] = ( get , a , a_index ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dsk [ k ] = ( get , a , a_index , a_asarray , a_lock ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return dsk <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def are_coplanar ( cls , * points ) : <NEWLINE> <TAB> <NEWLINE> if len ( points ) <= <NUMBER> : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <UNTAB> points = cls . _normalize_dimension ( * [ Point ( i ) for i in points ] ) <NEWLINE> <NEWLINE> if points [ <NUMBER> ] . ambient_dimension == <NUMBER> : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> points = list ( uniq ( points ) ) <NEWLINE> return Point . affine_rank ( * points ) <= <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _contains_cycle ( fgraph , orderings ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> outputs = fgraph . outputs <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> assert isinstance ( outputs , ( tuple , list , deque ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> parent_counts = { } <NEWLINE> <NEWLINE> node_to_children = { } <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> visitable = deque ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for var in fgraph . variables : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> owner = var . owner <NEWLINE> <NEWLINE> <NEWLINE> if owner : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> node_to_children . setdefault ( owner , [ ] ) . append ( var ) <NEWLINE> parent_counts [ var ] = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> visitable . append ( var ) <NEWLINE> parent_counts [ var ] = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for a_n in fgraph . apply_nodes : <NEWLINE> <TAB> parents = list ( a_n . inputs ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> parents . extend ( orderings . get ( a_n , [ ] ) ) <NEWLINE> <NEWLINE> if parents : <NEWLINE> <TAB> for parent in parents : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> node_to_children . setdefault ( parent , [ ] ) . append ( a_n ) <NEWLINE> <UNTAB> parent_counts [ a_n ] = len ( parents ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> visitable . append ( a_n ) <NEWLINE> parent_counts [ a_n ] = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> visited = <NUMBER> <NEWLINE> while visitable : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> node = visitable . popleft ( ) <NEWLINE> visited += <NUMBER> <NEWLINE> for client in node_to_children . get ( node , [ ] ) : <NEWLINE> <TAB> parent_counts [ client ] -= <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> if not parent_counts [ client ] : <NEWLINE> <TAB> visitable . append ( client ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return visited != len ( parent_counts ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _validate_index_level ( self , level ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( level , int ) : <NEWLINE> <TAB> if level < <NUMBER> and level != - <NUMBER> : <NEWLINE> <TAB> raise IndexError ( <STRING> <NEWLINE> <STRING> % ( level , ) ) <NEWLINE> <UNTAB> elif level > <NUMBER> : <NEWLINE> <TAB> raise IndexError ( <STRING> <NEWLINE> <STRING> % <NEWLINE> ( level + <NUMBER> ) ) <NEWLINE> <UNTAB> <UNTAB> elif level != self . name : <NEWLINE> <TAB> raise KeyError ( <STRING> % <NEWLINE> ( level , self . name ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_ref_xy ( self , renderer ) : <NEWLINE> <TAB> <NEWLINE> def is_offset ( s ) : <NEWLINE> <TAB> return isinstance ( s , str ) and s . split ( ) [ <NUMBER> ] == <STRING> <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( self . xycoords , tuple ) : <NEWLINE> <TAB> s1 , s2 = self . xycoords <NEWLINE> if is_offset ( s1 ) or is_offset ( s2 ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> x , y = self . xy <NEWLINE> x1 , y1 = self . _get_xy ( renderer , x , y , s1 ) <NEWLINE> x2 , y2 = self . _get_xy ( renderer , x , y , s2 ) <NEWLINE> return x1 , y2 <NEWLINE> <UNTAB> elif is_offset ( self . xycoords ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x , y = self . xy <NEWLINE> return self . _get_xy ( renderer , x , y , self . xycoords ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def newfunc ( * args , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> warnings . warn ( depdoc , DeprecationWarning , stacklevel = <NUMBER> ) <NEWLINE> return func ( * args , ** kwds ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _apply_sparse_duplicate_indices ( self , grad , var , state ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> summed_values , unique_indices = optimizer_v1 . _deduplicate_indexed_slices ( <NEWLINE> values = grad . values , indices = grad . indices ) <NEWLINE> <NEWLINE> gradient_no_duplicate_indices = ops . IndexedSlices ( <NEWLINE> indices = unique_indices , <NEWLINE> values = summed_values , <NEWLINE> dense_shape = grad . dense_shape ) <NEWLINE> return self . _apply_sparse ( gradient_no_duplicate_indices , var , state ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def ishashable ( x ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> hash ( x ) <NEWLINE> return True <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_submatrix ( self , row_slice , col_slice ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def process_slice ( sl , num ) : <NEWLINE> <TAB> if isinstance ( sl , slice ) : <NEWLINE> <TAB> i0 , i1 , stride = sl . indices ( num ) <NEWLINE> if stride != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> elif isintlike ( sl ) : <NEWLINE> <TAB> if sl < <NUMBER> : <NEWLINE> <TAB> sl += num <NEWLINE> <UNTAB> i0 , i1 = sl , sl + <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if not ( <NUMBER> <= i0 <= num ) or not ( <NUMBER> <= i1 <= num ) or not ( i0 <= i1 ) : <NEWLINE> <TAB> raise IndexError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ( i0 , num , i1 , num , i0 , i1 ) ) <NEWLINE> <UNTAB> return i0 , i1 <NEWLINE> <NEWLINE> <UNTAB> M , N = self . shape <NEWLINE> i0 , i1 = process_slice ( row_slice , M ) <NEWLINE> j0 , j1 = process_slice ( col_slice , N ) <NEWLINE> <NEWLINE> indptr , indices , data = get_csr_submatrix ( <NEWLINE> M , N , self . indptr , self . indices , self . data , i0 , i1 , j0 , j1 ) <NEWLINE> <NEWLINE> shape = ( i1 - i0 , j1 - j0 ) <NEWLINE> return self . __class__ ( ( data , indices , indptr ) , shape = shape , <NEWLINE> dtype = self . dtype , copy = False ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def row_op ( self , i , f ) : <NEWLINE> <TAB> <NEWLINE> i0 = i * self . cols <NEWLINE> ri = self . _mat [ i0 : i0 + self . cols ] <NEWLINE> self . _mat [ i0 : i0 + self . cols ] = [ f ( x , j ) for x , j in zip ( ri , list ( range ( self . cols ) ) ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def within_group_type ( self , within_group ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def interval_contains_open ( interval , val ) : <NEWLINE> <TAB> <NEWLINE> a , b = interval <NEWLINE> return a < val < b or a > val > b <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def create_memmap_backed_data ( data , mmap_mode = <STRING> , return_folder = False ) : <NEWLINE> <TAB> <NEWLINE> temp_folder = tempfile . mkdtemp ( prefix = <STRING> ) <NEWLINE> atexit . register ( functools . partial ( _delete_folder , temp_folder , warn = True ) ) <NEWLINE> filename = op . join ( temp_folder , <STRING> ) <NEWLINE> joblib . dump ( data , filename ) <NEWLINE> memmap_backed_data = joblib . load ( filename , mmap_mode = mmap_mode ) <NEWLINE> result = ( memmap_backed_data if not return_folder <NEWLINE> else ( memmap_backed_data , temp_folder ) ) <NEWLINE> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def stride_repeat ( x , n , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if axis not in [ <NUMBER> , <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> x = np . asarray ( x ) <NEWLINE> if x . ndim != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if n == <NUMBER> : <NEWLINE> <TAB> if axis == <NUMBER> : <NEWLINE> <TAB> return np . atleast_2d ( x ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return np . atleast_2d ( x ) . T <NEWLINE> <UNTAB> <UNTAB> if n < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> n = int ( n ) <NEWLINE> <NEWLINE> if axis == <NUMBER> : <NEWLINE> <TAB> shape = ( n , x . size ) <NEWLINE> strides = ( <NUMBER> , x . strides [ <NUMBER> ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> shape = ( x . size , n ) <NEWLINE> strides = ( x . strides [ <NUMBER> ] , <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> return np . lib . stride_tricks . as_strided ( x , shape = shape , strides = strides ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def insert_transformed_feature ( self , columns_to_tensors ) : <NEWLINE> <TAB> <NEWLINE> if self . sparse_id_column not in columns_to_tensors : <NEWLINE> <TAB> self . sparse_id_column . insert_transformed_feature ( columns_to_tensors ) <NEWLINE> <NEWLINE> <UNTAB> weight_tensor = columns_to_tensors [ self . weight_column_name ] <NEWLINE> columns_to_tensors [ self ] = self . _do_transform ( <NEWLINE> columns_to_tensors [ self . sparse_id_column ] , weight_tensor ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def makeCategoricalIndex ( k = <NUMBER> , n = <NUMBER> , name = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> x = rands_array ( nchars = <NUMBER> , size = n ) <NEWLINE> return CategoricalIndex ( np . random . choice ( x , k ) , name = name , ** kwargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _eval_derivative ( self , x ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if isinstance ( x , Symbol ) and x not in self . free_symbols : <NEWLINE> <TAB> return S . Zero <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> f , limits = self . function , list ( self . limits ) <NEWLINE> <NEWLINE> limit = limits . pop ( - <NUMBER> ) <NEWLINE> <NEWLINE> if limits : <NEWLINE> <TAB> f = self . func ( f , * limits ) <NEWLINE> <NEWLINE> <UNTAB> if len ( limit ) == <NUMBER> : <NEWLINE> <TAB> _ , a , b = limit <NEWLINE> if x in a . free_symbols or x in b . free_symbols : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> df = Derivative ( f , x , evaluate = True ) <NEWLINE> rv = self . func ( df , limit ) <NEWLINE> return rv <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_d2Sidksij2 ( self , alpha , ecc ) : <NEWLINE> <TAB> <NEWLINE> subtri = np . argmin ( alpha , axis = <NUMBER> ) [ : , <NUMBER> ] <NEWLINE> ksi = _roll_vectorized ( alpha , - subtri , axis = <NUMBER> ) <NEWLINE> E = _roll_vectorized ( ecc , - subtri , axis = <NUMBER> ) <NEWLINE> x = ksi [ : , <NUMBER> , <NUMBER> ] <NEWLINE> y = ksi [ : , <NUMBER> , <NUMBER> ] <NEWLINE> z = ksi [ : , <NUMBER> , <NUMBER> ] <NEWLINE> d2V = _to_matrix_vectorized ( [ <NEWLINE> [ <NUMBER> * x , <NUMBER> * x , <NUMBER> * x ] , <NEWLINE> [ <NUMBER> * y , <NUMBER> , <NUMBER> ] , <NEWLINE> [ <NUMBER> , <NUMBER> * z , <NUMBER> ] , <NEWLINE> [ <NUMBER> * z , <NUMBER> * z - <NUMBER> * x , <NUMBER> * z - <NUMBER> * x ] , <NEWLINE> [ <NUMBER> * y - <NUMBER> * x , <NUMBER> * y , <NUMBER> * y - <NUMBER> * x ] , <NEWLINE> [ <NUMBER> * x - <NUMBER> * y , <NUMBER> , - <NUMBER> * y ] , <NEWLINE> [ <NUMBER> * z , <NUMBER> , <NUMBER> * y ] , <NEWLINE> [ <NUMBER> , <NUMBER> * y , <NUMBER> * z ] , <NEWLINE> [ <NUMBER> , <NUMBER> * x - <NUMBER> * z , - <NUMBER> * z ] , <NEWLINE> [ - <NUMBER> * z , - <NUMBER> * y , x - y - z ] ] ) <NEWLINE> <NEWLINE> d2V = _prod_vectorized ( d2V , _extract_submatrices ( <NEWLINE> self . rotate_d2V , subtri , block_size = <NUMBER> , axis = <NUMBER> ) ) <NEWLINE> prod = _prod_vectorized ( self . M , d2V ) <NEWLINE> prod += _scalar_vectorized ( E [ : , <NUMBER> , <NUMBER> ] , <NEWLINE> _prod_vectorized ( self . M0 , d2V ) ) <NEWLINE> prod += _scalar_vectorized ( E [ : , <NUMBER> , <NUMBER> ] , <NEWLINE> _prod_vectorized ( self . M1 , d2V ) ) <NEWLINE> prod += _scalar_vectorized ( E [ : , <NUMBER> , <NUMBER> ] , <NEWLINE> _prod_vectorized ( self . M2 , d2V ) ) <NEWLINE> d2sdksi2 = _roll_vectorized ( prod , <NUMBER> * subtri , axis = <NUMBER> ) <NEWLINE> return d2sdksi2 <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _parse ( self ) : <NEWLINE> <TAB> <NEWLINE> if not self . pattern : <NEWLINE> <TAB> raise self . ParseError ( <STRING> ) <NEWLINE> <UNTAB> pattern = re . compile ( self . pattern , re . IGNORECASE | re . VERBOSE ) <NEWLINE> matches = pattern . findall ( self . files [ <NUMBER> ] ) <NEWLINE> if not matches : <NEWLINE> <TAB> raise self . ParseError ( <STRING> ) <NEWLINE> <UNTAB> matches = matches [ - <NUMBER> ] <NEWLINE> if len ( matches ) % <NUMBER> : <NEWLINE> <TAB> raise self . ParseError ( <STRING> ) <NEWLINE> <UNTAB> axes = <STRING> . join ( m for m in matches [ : : <NUMBER> ] if m ) <NEWLINE> if not axes : <NEWLINE> <TAB> raise self . ParseError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> indices = [ ] <NEWLINE> for fname in self . files : <NEWLINE> <TAB> matches = pattern . findall ( fname ) [ - <NUMBER> ] <NEWLINE> if axes != <STRING> . join ( m for m in matches [ : : <NUMBER> ] if m ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> indices . append ( [ int ( m ) for m in matches [ <NUMBER> : : <NUMBER> ] if m ] ) <NEWLINE> <UNTAB> shape = tuple ( numpy . max ( indices , axis = <NUMBER> ) ) <NEWLINE> start_index = tuple ( numpy . min ( indices , axis = <NUMBER> ) ) <NEWLINE> shape = tuple ( i - j + <NUMBER> for i , j in zip ( shape , start_index ) ) <NEWLINE> if product ( shape ) != len ( self . files ) : <NEWLINE> <TAB> warnings . warn ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> self . axes = axes . upper ( ) <NEWLINE> self . shape = shape <NEWLINE> self . _indices = indices <NEWLINE> self . _start_index = start_index <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_verts ( self ) : <NEWLINE> <TAB> <NEWLINE> trans = self . get_transform ( ) <NEWLINE> path = self . get_path ( ) <NEWLINE> polygons = path . to_polygons ( trans ) <NEWLINE> if len ( polygons ) : <NEWLINE> <TAB> return polygons [ <NUMBER> ] <NEWLINE> <UNTAB> return [ ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pack_padded_sequence ( input , lengths , batch_first = False ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( lengths , list ) : <NEWLINE> <TAB> lengths = torch . LongTensor ( lengths ) <NEWLINE> <NEWLINE> <UNTAB> data , batch_sizes = PackPadded . apply ( input , lengths , batch_first ) <NEWLINE> <NEWLINE> return PackedSequence ( data , batch_sizes ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def copy ( array , out = None , out_device = None , stream = None ) : <NEWLINE> <TAB> <NEWLINE> check_cuda_available ( ) <NEWLINE> assert stream is None <NEWLINE> <NEWLINE> if out is None : <NEWLINE> <TAB> if out_device is None : <NEWLINE> <TAB> out_device = array <NEWLINE> <UNTAB> with _get_device ( out_device ) : <NEWLINE> <TAB> out = cupy . empty_like ( array ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> with get_device_from_array ( array ) : <NEWLINE> <TAB> cupy . copyto ( out , array ) <NEWLINE> <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_fontweight ( self , weight ) : <NEWLINE> <TAB> <NEWLINE> self . _fontproperties . set_weight ( weight ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_patchB ( self , patchB ) : <NEWLINE> <TAB> <NEWLINE> self . patchB = patchB <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def winfo_manager ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . tk . call ( <STRING> , <STRING> , self . _w ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def spherical_yn ( n , z , derivative = False ) : <NEWLINE> <TAB> <NEWLINE> if derivative : <NEWLINE> <TAB> return _spherical_yn_d ( n , z ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _spherical_yn ( n , z ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , length = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> kwargs . setdefault ( <STRING> , True ) <NEWLINE> kwargs . setdefault ( <STRING> , True ) <NEWLINE> super ( UnicodeText , self ) . __init__ ( length = length , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def SOPform ( variables , minterms , dontcares = None ) : <NEWLINE> <TAB> <NEWLINE> variables = [ sympify ( v ) for v in variables ] <NEWLINE> if minterms == [ ] : <NEWLINE> <TAB> return false <NEWLINE> <NEWLINE> <UNTAB> minterms = [ list ( i ) for i in minterms ] <NEWLINE> dontcares = [ list ( i ) for i in ( dontcares or [ ] ) ] <NEWLINE> for d in dontcares : <NEWLINE> <TAB> if d in minterms : <NEWLINE> <TAB> raise ValueError ( <STRING> % d ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> old = None <NEWLINE> new = minterms + dontcares <NEWLINE> while new != old : <NEWLINE> <TAB> old = new <NEWLINE> new = _simplified_pairs ( old ) <NEWLINE> <UNTAB> essential = _rem_redundancy ( new , minterms ) <NEWLINE> return Or ( * [ _convert_to_varsSOP ( x , variables ) for x in essential ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _distributed_apply ( self , distribution , grads_and_vars , global_step , name ) : <NEWLINE> <TAB> <NEWLINE> reduced_grads = distribution . batch_reduce ( <NEWLINE> variable_scope . VariableAggregation . SUM , grads_and_vars ) <NEWLINE> var_list = [ v for _ , v in grads_and_vars ] <NEWLINE> grads_and_vars = zip ( reduced_grads , var_list ) <NEWLINE> <NEWLINE> unwrapped_var_list = [ x for v in var_list for x in distribution . unwrap ( v ) ] <NEWLINE> eager_execution = context . executing_eagerly ( ) <NEWLINE> if eager_execution : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> for v in unwrapped_var_list : <NEWLINE> <TAB> if isinstance ( v , ops . Tensor ) : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> , v ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> with ops . name_scope ( name , self . _name ) as name : <NEWLINE> <TAB> per_graph_state = self . _get_or_create_state ( var_list = unwrapped_var_list ) <NEWLINE> <NEWLINE> non_slot_devices = distribution . non_slot_devices ( var_list ) <NEWLINE> state = per_graph_state . _copy_with_dynamic_hyper ( <NEWLINE> self . _hyper , distribution , non_slot_devices ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> with ops . init_scope ( ) : <NEWLINE> <TAB> self . _create_vars ( var_list , state ) <NEWLINE> <NEWLINE> <UNTAB> with ops . name_scope ( name ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> self . _prepare ( state ) <NEWLINE> <NEWLINE> def update ( v , g ) : <NEWLINE> <TAB> <NEWLINE> assert v is not None <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> g = ops . convert_to_tensor_or_indexed_slices ( g ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> % g ) <NEWLINE> <UNTAB> if not isinstance ( g , ( ops . Tensor , ops . IndexedSlices ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> % g ) <NEWLINE> <UNTAB> processor = _get_processor ( v ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> scope_name = <STRING> if eager_execution else v . op . name <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> device_policy = context . context ( ) . device_policy ( <NEWLINE> context . DEVICE_PLACEMENT_SILENT ) <NEWLINE> with ops . name_scope ( <STRING> + scope_name ) , device_policy : <NEWLINE> <TAB> return processor . update_op ( self , g , state ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> update_ops = [ ] <NEWLINE> for grad , var in grads_and_vars : <NEWLINE> <TAB> update_ops . extend ( distribution . update ( var , update , grad , grouped = False ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> def finish ( ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> with context . context ( ) . device_policy ( context . DEVICE_PLACEMENT_SILENT ) : <NEWLINE> <TAB> return self . _finish ( state ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> update_ops = control_flow_ops . group ( update_ops ) <NEWLINE> with ops . control_dependencies ( [ update_ops ] ) : <NEWLINE> <TAB> finish_updates = distribution . update_non_slot ( <NEWLINE> non_slot_devices , finish , grouped = False ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if finish_updates == [ None ] : <NEWLINE> <TAB> finish_updates = [ update_ops ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if global_step is None : <NEWLINE> <TAB> apply_updates = distribution . group ( finish_updates , name = name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> with ops . control_dependencies ( finish_updates ) : <NEWLINE> <NEWLINE> <TAB> def update_global_step ( global_step , name ) : <NEWLINE> <TAB> return global_step . assign_add ( <NUMBER> , read_value = False , name = name ) <NEWLINE> <NEWLINE> <UNTAB> apply_updates = distribution . update ( global_step , update_global_step , <NEWLINE> name ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not eager_execution : <NEWLINE> <TAB> if isinstance ( apply_updates , ops . Tensor ) : <NEWLINE> <TAB> apply_updates = apply_updates . op <NEWLINE> <UNTAB> train_op = ops . get_collection_ref ( ops . GraphKeys . TRAIN_OP ) <NEWLINE> if apply_updates not in train_op : <NEWLINE> <TAB> train_op . append ( apply_updates ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return apply_updates <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def flatnonzero ( a ) : <NEWLINE> <TAB> <NEWLINE> return a . ravel ( ) . nonzero ( ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( None , <STRING> ) <NEWLINE> def extract_pandas_matrix ( data ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( data , pd . DataFrame ) : <NEWLINE> <TAB> return data <NEWLINE> <NEWLINE> <UNTAB> return data . as_matrix ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _handle_weight_regularization ( self , name , variable , regularizer ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def _loss_for_variable ( v ) : <NEWLINE> <TAB> <NEWLINE> with ops . colocate_with ( v ) : <NEWLINE> <TAB> with ops . name_scope ( name + <STRING> ) : <NEWLINE> <TAB> regularization = regularizer ( v ) <NEWLINE> <UNTAB> <UNTAB> return regularization <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( variable , tf_variables . PartitionedVariable ) : <NEWLINE> <TAB> for v in variable : <NEWLINE> <TAB> self . add_loss ( functools . partial ( _loss_for_variable , v ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> self . add_loss ( functools . partial ( _loss_for_variable , variable ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , t , fmt , tz = None ) : <NEWLINE> <TAB> <NEWLINE> if tz is None : <NEWLINE> <TAB> tz = _get_rc_timezone ( ) <NEWLINE> <UNTAB> self . t = t <NEWLINE> self . fmt = fmt <NEWLINE> self . tz = tz <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _cached_literal_processor ( self , dialect ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return dialect . _type_memos [ self ] [ <STRING> ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> d = self . _dialect_info ( dialect ) <NEWLINE> d [ <STRING> ] = lp = d [ <STRING> ] . literal_processor ( dialect ) <NEWLINE> return lp <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_scalar_event ( self , name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> with self . _name_scope ( name ) : <NEWLINE> <TAB> return ops . convert_to_tensor ( <NEWLINE> self . _is_scalar_helper ( self . event_shape , self . event_shape_tensor ) , <NEWLINE> name = <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def extend ( self , values ) : <NEWLINE> <TAB> <NEWLINE> for value in values : <NEWLINE> <TAB> self . _storage . append ( self . _track_value ( <NEWLINE> value , name = self . _name_element ( len ( self . _storage ) ) ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def findall ( self , path , namespaces = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if path [ : <NUMBER> ] == <STRING> : <NEWLINE> <TAB> path = <STRING> + path <NEWLINE> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % path , <NEWLINE> FutureWarning , stacklevel = <NUMBER> <NEWLINE> ) <NEWLINE> <UNTAB> return self . _root . findall ( path , namespaces ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def ground_to_ring ( f ) : <NEWLINE> <TAB> <NEWLINE> return f . set_domain ( f . dom . get_ring ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def elu ( x , alpha = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> res = tf . nn . elu ( x ) <NEWLINE> if alpha == <NUMBER> : <NEWLINE> <TAB> return res <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return tf . where ( x > <NUMBER> , res , alpha * res ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_yscale ( self , value , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> g = self . get_shared_y_axes ( ) <NEWLINE> for ax in g . get_siblings ( self ) : <NEWLINE> <TAB> ax . yaxis . _set_scale ( value , ** kwargs ) <NEWLINE> ax . _update_transScale ( ) <NEWLINE> ax . stale = True <NEWLINE> <UNTAB> self . autoscale_view ( scalex = False ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_internal ( self , sprite , layer = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not hasattr ( sprite , <STRING> ) : <NEWLINE> <TAB> raise AttributeError ( ) <NEWLINE> <UNTAB> if not hasattr ( sprite , <STRING> ) : <NEWLINE> <TAB> raise AttributeError ( ) <NEWLINE> <UNTAB> if not hasattr ( sprite , <STRING> ) : <NEWLINE> <TAB> raise AttributeError ( ) <NEWLINE> <NEWLINE> <UNTAB> if not isinstance ( sprite , DirtySprite ) : <NEWLINE> <TAB> raise TypeError ( ) <NEWLINE> <NEWLINE> <UNTAB> if sprite . dirty == <NUMBER> : <NEWLINE> <TAB> sprite . dirty = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> LayeredUpdates . add_internal ( self , sprite , layer ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def max_norm ( f ) : <NEWLINE> <TAB> <NEWLINE> return dmp_max_norm ( f . rep , f . lev , f . dom ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_palette ( self , data , hue , hue_order , palette ) : <NEWLINE> <TAB> <NEWLINE> if hue is None : <NEWLINE> <TAB> palette = color_palette ( n_colors = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> hue_names = utils . categorical_order ( data [ hue ] , hue_order ) <NEWLINE> n_colors = len ( hue_names ) <NEWLINE> <NEWLINE> <NEWLINE> if palette is None : <NEWLINE> <TAB> current_palette = utils . get_color_cycle ( ) <NEWLINE> if n_colors > len ( current_palette ) : <NEWLINE> <TAB> colors = color_palette ( <STRING> , n_colors ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> colors = color_palette ( n_colors = n_colors ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( palette , dict ) : <NEWLINE> <TAB> color_names = [ palette [ h ] for h in hue_names ] <NEWLINE> colors = color_palette ( color_names , n_colors ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> colors = color_palette ( palette , n_colors ) <NEWLINE> <NEWLINE> <UNTAB> palette = color_palette ( colors , n_colors ) <NEWLINE> <NEWLINE> <UNTAB> return palette <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def switch ( key , ruledict ) : <NEWLINE> <TAB> <NEWLINE> def switch_rl ( expr ) : <NEWLINE> <TAB> rl = ruledict . get ( key ( expr ) , identity ) <NEWLINE> return rl ( expr ) <NEWLINE> <UNTAB> return switch_rl <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def parse ( self , argument ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( argument , list ) : <NEWLINE> <TAB> return argument <NEWLINE> <UNTAB> elif not argument : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return [ s . strip ( ) for s in argument . split ( self . _token ) ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def build ( self , input_shape ) : <NEWLINE> <TAB> <NEWLINE> input_size = tensor_shape . dimension_value ( input_shape [ <NUMBER> ] ) <NEWLINE> if input_size is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> self . _gate_kernel = self . add_variable ( <NEWLINE> <STRING> , [ input_size + self . _cell_size , self . _cell_size * <NUMBER> ] ) <NEWLINE> self . _gate_bias = self . add_variable ( <NEWLINE> <STRING> , [ self . _cell_size * <NUMBER> ] , <NEWLINE> initializer = init_ops . constant_initializer ( <NUMBER> ) ) <NEWLINE> self . _candidate_kernel = self . add_variable ( <NEWLINE> <STRING> , [ input_size + self . _cell_size , self . _cell_size ] ) <NEWLINE> self . _candidate_bias = self . add_variable ( <NEWLINE> <STRING> , [ self . _cell_size ] , <NEWLINE> initializer = init_ops . constant_initializer ( <NUMBER> ) ) <NEWLINE> <NEWLINE> self . built = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def condition ( cond , brule ) : <NEWLINE> <TAB> <NEWLINE> def conditioned_brl ( expr ) : <NEWLINE> <TAB> if cond ( expr ) : <NEWLINE> <TAB> for x in brule ( expr ) : yield x <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> return conditioned_brl <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __new__ ( cls , name , bases , dct ) : <NEWLINE> <TAB> props = dct . get ( <STRING> , None ) <NEWLINE> if props is not None : <NEWLINE> <TAB> if not isinstance ( props , tuple ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if not all ( isinstance ( p , string_types ) for p in props ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> def _props ( self ) : <NEWLINE> <TAB> <NEWLINE> return tuple ( getattr ( self , a ) for a in props ) <NEWLINE> <UNTAB> dct [ <STRING> ] = _props <NEWLINE> <NEWLINE> def _props_dict ( self ) : <NEWLINE> <TAB> <NEWLINE> return dict ( [ ( a , getattr ( self , a ) ) <NEWLINE> for a in props ] ) <NEWLINE> <UNTAB> dct [ <STRING> ] = _props_dict <NEWLINE> <NEWLINE> if <STRING> not in dct : <NEWLINE> <TAB> def __hash__ ( self ) : <NEWLINE> <TAB> return hash ( ( type ( self ) , <NEWLINE> tuple ( getattr ( self , a ) for a in props ) ) ) <NEWLINE> <UNTAB> dct [ <STRING> ] = __hash__ <NEWLINE> <NEWLINE> <UNTAB> if <STRING> not in dct : <NEWLINE> <TAB> def __eq__ ( self , other ) : <NEWLINE> <TAB> return ( type ( self ) == type ( other ) and <NEWLINE> tuple ( getattr ( self , a ) for a in props ) == <NEWLINE> tuple ( getattr ( other , a ) for a in props ) ) <NEWLINE> <UNTAB> dct [ <STRING> ] = __eq__ <NEWLINE> <NEWLINE> <UNTAB> if <STRING> not in dct : <NEWLINE> <TAB> if len ( props ) == <NUMBER> : <NEWLINE> <TAB> def __str__ ( self ) : <NEWLINE> <TAB> return <STRING> % ( self . __class__ . __name__ , ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> def __str__ ( self ) : <NEWLINE> <TAB> return <STRING> % ( <NEWLINE> self . __class__ . __name__ , <NEWLINE> <STRING> . join ( <STRING> % ( p , getattr ( self , p ) ) <NEWLINE> for p in props ) ) <NEWLINE> <UNTAB> <UNTAB> dct [ <STRING> ] = __str__ <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return type . __new__ ( cls , name , bases , dct ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def value ( self ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pairwise_distance ( x1 , x2 , p = <NUMBER> , eps = <NUMBER> , keepdim = False ) : <NEWLINE> <TAB> <NEWLINE> return torch . pairwise_distance ( x1 , x2 , p , eps , keepdim ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def step_begin ( self , step ) : <NEWLINE> <TAB> <NEWLINE> if ( step < <NUMBER> ) or ( ( self . _max_steps is not None ) and <NEWLINE> ( step > self . _max_steps ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> % step ) <NEWLINE> <UNTAB> self . _current_step = step <NEWLINE> return [ ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ cacheit <NEWLINE> def term ( self , pt ) : <NEWLINE> <TAB> <NEWLINE> if pt < self . start or pt > self . stop : <NEWLINE> <TAB> raise IndexError ( <STRING> % ( pt , self . interval ) ) <NEWLINE> <UNTAB> return self . _eval_term ( pt ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def expect ( * bool_exprs ) : <NEWLINE> <TAB> <NEWLINE> if in_light_mode ( ) : <NEWLINE> <TAB> if not all ( bool_exprs ) : <NEWLINE> <TAB> raise InvalidType ( <STRING> , <STRING> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for expr in bool_exprs : <NEWLINE> <TAB> assert isinstance ( expr , Testable ) <NEWLINE> expr . expect ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _median_nancheck ( data , result , axis , out ) : <NEWLINE> <TAB> <NEWLINE> if data . size == <NUMBER> : <NEWLINE> <TAB> return result <NEWLINE> <UNTAB> data = np . moveaxis ( data , axis , - <NUMBER> ) <NEWLINE> n = np . isnan ( data [ ... , - <NUMBER> ] ) <NEWLINE> <NEWLINE> if np . ma . isMaskedArray ( n ) : <NEWLINE> <TAB> n = n . filled ( False ) <NEWLINE> <UNTAB> if result . ndim == <NUMBER> : <NEWLINE> <TAB> if n == True : <NEWLINE> <TAB> warnings . warn ( <STRING> , <NEWLINE> RuntimeWarning , stacklevel = <NUMBER> ) <NEWLINE> if out is not None : <NEWLINE> <TAB> out [ ... ] = data . dtype . type ( np . nan ) <NEWLINE> result = out <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result = data . dtype . type ( np . nan ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif np . count_nonzero ( n . ravel ( ) ) > <NUMBER> : <NEWLINE> <TAB> warnings . warn ( <STRING> + <NEWLINE> <STRING> % np . count_nonzero ( n . ravel ( ) ) , <NEWLINE> RuntimeWarning , stacklevel = <NUMBER> ) <NEWLINE> result [ n ] = np . nan <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def quadts ( ctx , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> kwargs [ <STRING> ] = <STRING> <NEWLINE> return ctx . quad ( * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def set_default_handler_map ( cls , handler_map ) : <NEWLINE> <TAB> <NEWLINE> cls . _default_handler_map = handler_map <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecation . deprecated ( None , <STRING> ) <NEWLINE> def scan ( initial_state , scan_func ) : <NEWLINE> <TAB> <NEWLINE> return scan_ops . scan ( initial_state , scan_func ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def to_undirected ( graph ) : <NEWLINE> <TAB> <NEWLINE> return graph . to_undirected ( as_view = True ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def gf_sub_mul ( f , g , h , p , K ) : <NEWLINE> <TAB> <NEWLINE> return gf_sub ( f , gf_mul ( g , h , p , K ) , p , K ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def has_edge ( self , u , v ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return v in self . _adj [ u ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def read_array ( fp , allow_pickle = True , pickle_kwargs = None ) : <NEWLINE> <TAB> <NEWLINE> version = read_magic ( fp ) <NEWLINE> _check_version ( version ) <NEWLINE> shape , fortran_order , dtype = _read_array_header ( fp , version ) <NEWLINE> if len ( shape ) == <NUMBER> : <NEWLINE> <TAB> count = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> count = numpy . multiply . reduce ( shape , dtype = numpy . int64 ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if dtype . hasobject : <NEWLINE> <NEWLINE> <TAB> if not allow_pickle : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if pickle_kwargs is None : <NEWLINE> <TAB> pickle_kwargs = { } <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> array = pickle . load ( fp , ** pickle_kwargs ) <NEWLINE> <UNTAB> except UnicodeError as err : <NEWLINE> <TAB> if sys . version_info [ <NUMBER> ] >= <NUMBER> : <NEWLINE> <NEWLINE> <TAB> raise UnicodeError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % ( err , ) ) <NEWLINE> <UNTAB> raise <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if isfileobj ( fp ) : <NEWLINE> <NEWLINE> <TAB> array = numpy . fromfile ( fp , dtype = dtype , count = count ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> array = numpy . ndarray ( count , dtype = dtype ) <NEWLINE> <NEWLINE> if dtype . itemsize > <NUMBER> : <NEWLINE> <NEWLINE> <TAB> max_read_count = BUFFER_SIZE // min ( BUFFER_SIZE , dtype . itemsize ) <NEWLINE> <NEWLINE> for i in range ( <NUMBER> , count , max_read_count ) : <NEWLINE> <TAB> read_count = min ( max_read_count , count - i ) <NEWLINE> read_size = int ( read_count * dtype . itemsize ) <NEWLINE> data = _read_bytes ( fp , read_size , <STRING> ) <NEWLINE> array [ i : i + read_count ] = numpy . frombuffer ( data , dtype = dtype , <NEWLINE> count = read_count ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if fortran_order : <NEWLINE> <TAB> array . shape = shape [ : : - <NUMBER> ] <NEWLINE> array = array . transpose ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> array . shape = shape <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return array <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _eval_subs ( self , old , new ) : <NEWLINE> <TAB> <NEWLINE> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> def k_edge_components ( G , k ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if k < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if G . is_directed ( ) : <NEWLINE> <TAB> if k == <NUMBER> : <NEWLINE> <TAB> return nx . strongly_connected_components ( G ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> aux_graph = EdgeComponentAuxGraph . construct ( G ) <NEWLINE> return aux_graph . k_edge_components ( k ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if k == <NUMBER> : <NEWLINE> <TAB> return nx . connected_components ( G ) <NEWLINE> <UNTAB> elif k == <NUMBER> : <NEWLINE> <TAB> return bridge_components ( G ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> aux_graph = EdgeComponentAuxGraph . construct ( G ) <NEWLINE> return aux_graph . k_edge_components ( k ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def generate_fontconfig_pattern ( d ) : <NEWLINE> <TAB> <NEWLINE> props = [ ] <NEWLINE> families = <STRING> <NEWLINE> size = <STRING> <NEWLINE> for key in <STRING> . split ( ) : <NEWLINE> <TAB> val = getattr ( d , <STRING> + key ) ( ) <NEWLINE> if val is not None and val != [ ] : <NEWLINE> <TAB> if type ( val ) == list : <NEWLINE> <TAB> val = [ value_escape ( <STRING> , str ( x ) ) for x in val <NEWLINE> if x is not None ] <NEWLINE> if val != [ ] : <NEWLINE> <TAB> val = <STRING> . join ( val ) <NEWLINE> <UNTAB> <UNTAB> props . append ( <STRING> % ( key , val ) ) <NEWLINE> <UNTAB> <UNTAB> return <STRING> . join ( props ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , fmt ) : <NEWLINE> <TAB> <NEWLINE> self . fmt = fmt <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_alpha ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _alpha <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> @ cacheit <NEWLINE> def taylor_term ( n , x , * previous_terms ) : <NEWLINE> <TAB> <NEWLINE> from sympy import bernoulli <NEWLINE> if n == <NUMBER> : <NEWLINE> <TAB> return <NUMBER> / sympify ( x ) <NEWLINE> <UNTAB> elif n < <NUMBER> or n % <NUMBER> == <NUMBER> : <NEWLINE> <TAB> return S . Zero <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x = sympify ( x ) <NEWLINE> <NEWLINE> B = bernoulli ( n + <NUMBER> ) <NEWLINE> F = factorial ( n + <NUMBER> ) <NEWLINE> <NEWLINE> return <NUMBER> * ( <NUMBER> - <NUMBER> ** n ) * B / F * x ** n <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _prepend_max ( arr , pad_amt , num , axis = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if pad_amt == <NUMBER> : <NEWLINE> <TAB> return arr <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if num == <NUMBER> : <NEWLINE> <TAB> return _prepend_edge ( arr , pad_amt , axis ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if num is not None : <NEWLINE> <TAB> if num >= arr . shape [ axis ] : <NEWLINE> <TAB> num = None <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> max_slice = tuple ( slice ( None ) if i != axis else slice ( num ) <NEWLINE> for ( i , x ) in enumerate ( arr . shape ) ) <NEWLINE> <NEWLINE> <NEWLINE> pad_singleton = tuple ( x if i != axis else <NUMBER> <NEWLINE> for ( i , x ) in enumerate ( arr . shape ) ) <NEWLINE> <NEWLINE> <NEWLINE> max_chunk = arr [ max_slice ] . max ( axis = axis ) . reshape ( pad_singleton ) <NEWLINE> <NEWLINE> <NEWLINE> return np . concatenate ( ( max_chunk . repeat ( pad_amt , axis = axis ) , arr ) , <NEWLINE> axis = axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _simplified_pairs ( terms ) : <NEWLINE> <TAB> <NEWLINE> simplified_terms = [ ] <NEWLINE> todo = list ( range ( len ( terms ) ) ) <NEWLINE> for i , ti in enumerate ( terms [ : - <NUMBER> ] ) : <NEWLINE> <TAB> for j_i , tj in enumerate ( terms [ ( i + <NUMBER> ) : ] ) : <NEWLINE> <TAB> index = _check_pair ( ti , tj ) <NEWLINE> if index != - <NUMBER> : <NEWLINE> <TAB> todo [ i ] = todo [ j_i + i + <NUMBER> ] = None <NEWLINE> newterm = ti [ : ] <NEWLINE> newterm [ index ] = <NUMBER> <NEWLINE> if newterm not in simplified_terms : <NEWLINE> <TAB> simplified_terms . append ( newterm ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> simplified_terms . extend ( <NEWLINE> [ terms [ i ] for i in [ _ for _ in todo if _ is not None ] ] ) <NEWLINE> return simplified_terms <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _call_nearest ( self , x_new ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> x_new_indices = searchsorted ( self . x_bds , x_new , side = <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> x_new_indices = x_new_indices . clip ( <NUMBER> , len ( self . x ) - <NUMBER> ) . astype ( intp ) <NEWLINE> <NEWLINE> <NEWLINE> y_new = self . _y [ x_new_indices ] <NEWLINE> <NEWLINE> return y_new <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def hits_scipy ( G , max_iter = <NUMBER> , tol = <NUMBER> , normalized = True ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> import scipy . sparse <NEWLINE> import numpy as np <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> raise ImportError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if len ( G ) == <NUMBER> : <NEWLINE> <TAB> return { } , { } <NEWLINE> <UNTAB> M = nx . to_scipy_sparse_matrix ( G , nodelist = list ( G ) ) <NEWLINE> ( n , m ) = M . shape <NEWLINE> A = M . T * M <NEWLINE> x = scipy . ones ( ( n , <NUMBER> ) ) / n <NEWLINE> <NEWLINE> i = <NUMBER> <NEWLINE> while True : <NEWLINE> <TAB> xlast = x <NEWLINE> x = A * x <NEWLINE> x = x / x . max ( ) <NEWLINE> <NEWLINE> err = scipy . absolute ( x - xlast ) . sum ( ) <NEWLINE> if err < tol : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> if i > max_iter : <NEWLINE> <TAB> raise nx . PowerIterationFailedConvergence ( max_iter ) <NEWLINE> <UNTAB> i += <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> a = np . asarray ( x ) . flatten ( ) <NEWLINE> <NEWLINE> h = np . asarray ( M * a ) . flatten ( ) <NEWLINE> if normalized : <NEWLINE> <TAB> h = h / h . sum ( ) <NEWLINE> a = a / a . sum ( ) <NEWLINE> <UNTAB> hubs = dict ( zip ( G , map ( float , h ) ) ) <NEWLINE> authorities = dict ( zip ( G , map ( float , a ) ) ) <NEWLINE> return hubs , authorities <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def py_random_state ( random_state_index ) : <NEWLINE> <TAB> <NEWLINE> @ decorator <NEWLINE> def _random_state ( func , * args , ** kwargs ) : <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> random_state_arg = args [ random_state_index ] <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <UNTAB> except IndexError : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> random_state = create_py_random_state ( random_state_arg ) <NEWLINE> <NEWLINE> <NEWLINE> new_args = list ( args ) <NEWLINE> new_args [ random_state_index ] = random_state <NEWLINE> return func ( * new_args , ** kwargs ) <NEWLINE> <UNTAB> return _random_state <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def jarque_bera ( x ) : <NEWLINE> <TAB> <NEWLINE> x = np . asarray ( x ) <NEWLINE> n = float ( x . size ) <NEWLINE> if n == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> mu = x . mean ( ) <NEWLINE> diffx = x - mu <NEWLINE> skewness = ( <NUMBER> / n * np . sum ( diffx ** <NUMBER> ) ) / ( <NUMBER> / n * np . sum ( diffx ** <NUMBER> ) ) ** ( <NUMBER> / <NUMBER> ) <NEWLINE> kurtosis = ( <NUMBER> / n * np . sum ( diffx ** <NUMBER> ) ) / ( <NUMBER> / n * np . sum ( diffx ** <NUMBER> ) ) ** <NUMBER> <NEWLINE> jb_value = n / <NUMBER> * ( skewness ** <NUMBER> + ( kurtosis - <NUMBER> ) ** <NUMBER> / <NUMBER> ) <NEWLINE> p = <NUMBER> - distributions . chi2 . cdf ( jb_value , <NUMBER> ) <NEWLINE> <NEWLINE> return jb_value , p <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _maybe_cache_changed ( self , item , value ) : <NEWLINE> <TAB> <NEWLINE> self . _data . set ( item , value , check = False ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def refine_MatMul ( expr , assumptions ) : <NEWLINE> <TAB> <NEWLINE> newargs = [ ] <NEWLINE> exprargs = [ ] <NEWLINE> <NEWLINE> for args in expr . args : <NEWLINE> <TAB> if args . is_Matrix : <NEWLINE> <TAB> exprargs . append ( args ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> newargs . append ( args ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> last = exprargs [ <NUMBER> ] <NEWLINE> for arg in exprargs [ <NUMBER> : ] : <NEWLINE> <TAB> if arg == last . T and ask ( Q . orthogonal ( arg ) , assumptions ) : <NEWLINE> <TAB> last = Identity ( arg . shape [ <NUMBER> ] ) <NEWLINE> <UNTAB> elif arg == last . conjugate ( ) and ask ( Q . unitary ( arg ) , assumptions ) : <NEWLINE> <TAB> last = Identity ( arg . shape [ <NUMBER> ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> newargs . append ( last ) <NEWLINE> last = arg <NEWLINE> <UNTAB> <UNTAB> newargs . append ( last ) <NEWLINE> <NEWLINE> return MatMul ( * newargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def request_stop ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _stop_requested = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _replace_forward_references ( t , context ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( t , str ) : <NEWLINE> <TAB> return context [ t ] <NEWLINE> <UNTAB> elif isinstance ( t , Type ) : <NEWLINE> <TAB> return type ( t ) ( * [ _replace_forward_references ( t , context ) for t in t . _types ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return t <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self ) : <NEWLINE> <TAB> <NEWLINE> super ( PairingHeap , self ) . __init__ ( ) <NEWLINE> self . _root = None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def logical_not ( x , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , x = x , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = None <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , x ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return logical_not_eager_fallback ( <NEWLINE> x , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def autoscale_None ( self , A ) : <NEWLINE> <TAB> <NEWLINE> A = np . asanyarray ( A ) <NEWLINE> if self . vmin is None and A . size : <NEWLINE> <TAB> self . vmin = A . min ( ) <NEWLINE> <UNTAB> if self . vmax is None and A . size : <NEWLINE> <TAB> self . vmax = A . max ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def deprecate_kwarg ( old_arg_name , new_arg_name , mapping = None , stacklevel = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if mapping is not None and not hasattr ( mapping , <STRING> ) and not callable ( mapping ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> def _deprecate_kwarg ( func ) : <NEWLINE> <TAB> @ wraps ( func ) <NEWLINE> def wrapper ( * args , ** kwargs ) : <NEWLINE> <TAB> old_arg_value = kwargs . pop ( old_arg_name , None ) <NEWLINE> <NEWLINE> if new_arg_name is None and old_arg_value is not None : <NEWLINE> <TAB> msg = ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> ) . format ( old_name = old_arg_name ) <NEWLINE> warnings . warn ( msg , FutureWarning , stacklevel = stacklevel ) <NEWLINE> kwargs [ old_arg_name ] = old_arg_value <NEWLINE> return func ( * args , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> if old_arg_value is not None : <NEWLINE> <TAB> if mapping is not None : <NEWLINE> <TAB> if hasattr ( mapping , <STRING> ) : <NEWLINE> <TAB> new_arg_value = mapping . get ( old_arg_value , <NEWLINE> old_arg_value ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> new_arg_value = mapping ( old_arg_value ) <NEWLINE> <UNTAB> msg = ( <STRING> <NEWLINE> <STRING> <NEWLINE> ) . format ( old_name = old_arg_name , <NEWLINE> old_val = old_arg_value , <NEWLINE> new_name = new_arg_name , <NEWLINE> new_val = new_arg_value ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> new_arg_value = old_arg_value <NEWLINE> msg = ( <STRING> <NEWLINE> <STRING> <NEWLINE> ) . format ( old_name = old_arg_name , <NEWLINE> new_name = new_arg_name ) <NEWLINE> <NEWLINE> <UNTAB> warnings . warn ( msg , FutureWarning , stacklevel = stacklevel ) <NEWLINE> if kwargs . get ( new_arg_name , None ) is not None : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) . format ( old_name = old_arg_name , <NEWLINE> new_name = new_arg_name ) <NEWLINE> raise TypeError ( msg ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> kwargs [ new_arg_name ] = new_arg_value <NEWLINE> <UNTAB> <UNTAB> return func ( * args , ** kwargs ) <NEWLINE> <UNTAB> return wrapper <NEWLINE> <UNTAB> return _deprecate_kwarg <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def maximum ( x1 , x2 ) : <NEWLINE> <TAB> <NEWLINE> return Maximum ( ) . apply ( ( x1 , x2 ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dup_clear_denoms ( f , K0 , K1 = None , convert = False ) : <NEWLINE> <TAB> <NEWLINE> if K1 is None : <NEWLINE> <TAB> if K0 . has_assoc_Ring : <NEWLINE> <TAB> K1 = K0 . get_ring ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> K1 = K0 <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> common = K1 . one <NEWLINE> <NEWLINE> for c in f : <NEWLINE> <TAB> common = K1 . lcm ( common , K0 . denom ( c ) ) <NEWLINE> <NEWLINE> <UNTAB> if not K1 . is_one ( common ) : <NEWLINE> <TAB> f = dup_mul_ground ( f , common , K0 ) <NEWLINE> <NEWLINE> <UNTAB> if not convert : <NEWLINE> <TAB> return common , f <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return common , dup_convert ( f , K0 , K1 ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sosfiltfilt ( sos , x , axis = - <NUMBER> , padtype = <STRING> , padlen = None ) : <NEWLINE> <TAB> <NEWLINE> sos , n_sections = _validate_sos ( sos ) <NEWLINE> <NEWLINE> <NEWLINE> ntaps = <NUMBER> * n_sections + <NUMBER> <NEWLINE> ntaps -= min ( ( sos [ : , <NUMBER> ] == <NUMBER> ) . sum ( ) , ( sos [ : , <NUMBER> ] == <NUMBER> ) . sum ( ) ) <NEWLINE> edge , ext = _validate_pad ( padtype , padlen , x , axis , <NEWLINE> ntaps = ntaps ) <NEWLINE> <NEWLINE> <NEWLINE> zi = sosfilt_zi ( sos ) <NEWLINE> zi_shape = [ <NUMBER> ] * x . ndim <NEWLINE> zi_shape [ axis ] = <NUMBER> <NEWLINE> zi . shape = [ n_sections ] + zi_shape <NEWLINE> x_0 = axis_slice ( ext , stop = <NUMBER> , axis = axis ) <NEWLINE> ( y , zf ) = sosfilt ( sos , ext , axis = axis , zi = zi * x_0 ) <NEWLINE> y_0 = axis_slice ( y , start = - <NUMBER> , axis = axis ) <NEWLINE> ( y , zf ) = sosfilt ( sos , axis_reverse ( y , axis = axis ) , axis = axis , zi = zi * y_0 ) <NEWLINE> y = axis_reverse ( y , axis = axis ) <NEWLINE> if edge > <NUMBER> : <NEWLINE> <TAB> y = axis_slice ( y , start = edge , stop = - edge , axis = axis ) <NEWLINE> <UNTAB> return y <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _transform_new ( self , X ) : <NEWLINE> <TAB> <NEWLINE> X_temp = check_array ( X , dtype = None ) <NEWLINE> if not hasattr ( X , <STRING> ) and np . issubdtype ( X_temp . dtype , np . str_ ) : <NEWLINE> <TAB> X = check_array ( X , dtype = np . object ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> X = X_temp <NEWLINE> <NEWLINE> <UNTAB> n_samples , n_features = X . shape <NEWLINE> <NEWLINE> X_int , X_mask = self . _transform ( X , handle_unknown = self . handle_unknown ) <NEWLINE> <NEWLINE> mask = X_mask . ravel ( ) <NEWLINE> n_values = [ cats . shape [ <NUMBER> ] for cats in self . categories_ ] <NEWLINE> n_values = np . array ( [ <NUMBER> ] + n_values ) <NEWLINE> feature_indices = np . cumsum ( n_values ) <NEWLINE> <NEWLINE> indices = ( X_int + feature_indices [ : - <NUMBER> ] ) . ravel ( ) [ mask ] <NEWLINE> indptr = X_mask . sum ( axis = <NUMBER> ) . cumsum ( ) <NEWLINE> indptr = np . insert ( indptr , <NUMBER> , <NUMBER> ) <NEWLINE> data = np . ones ( n_samples * n_features ) [ mask ] <NEWLINE> <NEWLINE> out = sparse . csr_matrix ( ( data , indices , indptr ) , <NEWLINE> shape = ( n_samples , feature_indices [ - <NUMBER> ] ) , <NEWLINE> dtype = self . dtype ) <NEWLINE> if not self . sparse : <NEWLINE> <TAB> return out . toarray ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return out <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_list_of_ints ( intlist ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( intlist , list ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> for i in intlist : <NEWLINE> <TAB> if not isinstance ( i , int ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def clone_with_new_inputs ( self , inputs , strict = True ) : <NEWLINE> <TAB> <NEWLINE> assert isinstance ( inputs , ( list , tuple ) ) <NEWLINE> remake_node = False <NEWLINE> new_inputs = inputs [ : ] <NEWLINE> for i , ( curr , new ) in enumerate ( zip ( self . inputs , new_inputs ) ) : <NEWLINE> <TAB> if not curr . type == new . type : <NEWLINE> <TAB> if strict : <NEWLINE> <NEWLINE> <TAB> new_inputs [ i ] = curr . type . filter_variable ( new ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> remake_node = True <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if remake_node : <NEWLINE> <TAB> new_node = self . op . make_node ( * new_inputs ) <NEWLINE> new_node . tag = copy ( self . tag ) . __update__ ( new_node . tag ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> new_node = self . clone ( ) <NEWLINE> new_node . inputs = new_inputs <NEWLINE> <UNTAB> return new_node <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _handle_Integral ( expr , func , order , hint ) : <NEWLINE> <TAB> <NEWLINE> global y <NEWLINE> x = func . args [ <NUMBER> ] <NEWLINE> f = func . func <NEWLINE> if hint == <STRING> : <NEWLINE> <TAB> sol = ( expr . doit ( ) ) . subs ( y , f ( x ) ) <NEWLINE> del y <NEWLINE> <UNTAB> elif hint == <STRING> : <NEWLINE> <TAB> sol = Eq ( Subs ( expr . lhs , y , f ( x ) ) , expr . rhs ) <NEWLINE> del y <NEWLINE> <UNTAB> elif hint == <STRING> : <NEWLINE> <TAB> sol = expr <NEWLINE> <UNTAB> elif not hint . endswith ( <STRING> ) : <NEWLINE> <TAB> sol = expr . doit ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> sol = expr <NEWLINE> <UNTAB> return sol <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def set_union ( a , b , validate_indices = True ) : <NEWLINE> <TAB> <NEWLINE> a , b , _ = _convert_to_tensors_or_sparse_tensors ( a , b ) <NEWLINE> return _set_operation ( a , b , <STRING> , validate_indices ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def separatevars ( expr , symbols = [ ] , dict = False , force = False ) : <NEWLINE> <TAB> <NEWLINE> expr = sympify ( expr ) <NEWLINE> if dict : <NEWLINE> <TAB> return _separatevars_dict ( _separatevars ( expr , force ) , symbols ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _separatevars ( expr , force ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def imread_collection_wrapper ( imread ) : <NEWLINE> <TAB> def imread_collection ( load_pattern , conserve_memory = True ) : <NEWLINE> <TAB> <NEWLINE> return ImageCollection ( load_pattern , conserve_memory = conserve_memory , <NEWLINE> load_func = imread ) <NEWLINE> <UNTAB> return imread_collection <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def semantic_feasibility ( self , G1_node , G2_node ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> feasible = _semantic_feasibility ( self , G1_node , G2_node ) <NEWLINE> if not feasible : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . G1_adj = self . G1 . pred <NEWLINE> self . G2_adj = self . G2 . pred <NEWLINE> feasible = _semantic_feasibility ( self , G1_node , G2_node ) <NEWLINE> self . G1_adj = self . G1 . adj <NEWLINE> self . G2_adj = self . G2 . adj <NEWLINE> <NEWLINE> return feasible <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def add_n ( inputs , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if not isinstance ( inputs , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % inputs ) <NEWLINE> <UNTAB> _attr_N = len ( inputs ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , inputs = inputs , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , inputs ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return add_n_eager_fallback ( <NEWLINE> inputs , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def seuclidean ( u , v , V ) : <NEWLINE> <TAB> <NEWLINE> u = _validate_vector ( u ) <NEWLINE> v = _validate_vector ( v ) <NEWLINE> V = _validate_vector ( V , dtype = np . float64 ) <NEWLINE> if V . shape [ <NUMBER> ] != u . shape [ <NUMBER> ] or u . shape [ <NUMBER> ] != v . shape [ <NUMBER> ] : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> return euclidean ( u , v , w = <NUMBER> / V ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def draw_to_density ( self , ax , center , val , support , density , split , ** kws ) : <NEWLINE> <TAB> <NEWLINE> idx = np . argmin ( np . abs ( support - val ) ) <NEWLINE> width = self . dwidth * density [ idx ] * <NUMBER> <NEWLINE> <NEWLINE> kws [ <STRING> ] = self . gray <NEWLINE> <NEWLINE> if self . orient == <STRING> : <NEWLINE> <TAB> if split == <STRING> : <NEWLINE> <TAB> ax . plot ( [ center - width , center ] , [ val , val ] , ** kws ) <NEWLINE> <UNTAB> elif split == <STRING> : <NEWLINE> <TAB> ax . plot ( [ center , center + width ] , [ val , val ] , ** kws ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ax . plot ( [ center - width , center + width ] , [ val , val ] , ** kws ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if split == <STRING> : <NEWLINE> <TAB> ax . plot ( [ val , val ] , [ center - width , center ] , ** kws ) <NEWLINE> <UNTAB> elif split == <STRING> : <NEWLINE> <TAB> ax . plot ( [ val , val ] , [ center , center + width ] , ** kws ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ax . plot ( [ val , val ] , [ center - width , center + width ] , ** kws ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_cacher ( self ) : <NEWLINE> <TAB> <NEWLINE> cacher = getattr ( self , <STRING> , None ) <NEWLINE> if cacher is not None : <NEWLINE> <TAB> cacher = cacher [ <NUMBER> ] ( ) <NEWLINE> <UNTAB> return cacher <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def lin_space ( start , stop , num , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , start = start , stop = stop , num = num , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , start , stop , num ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return lin_space_eager_fallback ( <NEWLINE> start , stop , num , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_edge ( self , G , edge_element , graphml_keys ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> ports = edge_element . find ( <STRING> % self . NS_GRAPHML ) <NEWLINE> if ports is not None : <NEWLINE> <TAB> warnings . warn ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> directed = edge_element . get ( <STRING> ) <NEWLINE> if G . is_directed ( ) and directed == <STRING> : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise nx . NetworkXError ( msg ) <NEWLINE> <UNTAB> if ( not G . is_directed ( ) ) and directed == <STRING> : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise nx . NetworkXError ( msg ) <NEWLINE> <NEWLINE> <UNTAB> source = self . node_type ( edge_element . get ( <STRING> ) ) <NEWLINE> target = self . node_type ( edge_element . get ( <STRING> ) ) <NEWLINE> data = self . decode_data_elements ( graphml_keys , edge_element ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> edge_id = edge_element . get ( <STRING> ) <NEWLINE> if edge_id : <NEWLINE> <NEWLINE> <TAB> self . edge_ids [ source , target ] = edge_id <NEWLINE> try : <NEWLINE> <TAB> edge_id = self . edge_key_type ( edge_id ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> edge_id = data . get ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if G . has_edge ( source , target ) : <NEWLINE> <NEWLINE> <TAB> self . multigraph = True <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> G . add_edges_from ( [ ( source , target , edge_id , data ) ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _maybe_cache ( arg , format , cache , tz , convert_listlike ) : <NEWLINE> <TAB> <NEWLINE> from pandas import Series <NEWLINE> cache_array = Series ( ) <NEWLINE> if cache : <NEWLINE> <NEWLINE> <TAB> from pandas import Index <NEWLINE> if not Index ( arg ) . is_unique : <NEWLINE> <TAB> unique_dates = algorithms . unique ( arg ) <NEWLINE> cache_dates = convert_listlike ( unique_dates , True , format , tz = tz ) <NEWLINE> cache_array = Series ( cache_dates , index = unique_dates ) <NEWLINE> <UNTAB> <UNTAB> return cache_array <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def sum ( x , axis = None , keepdims = False ) : <NEWLINE> <TAB> <NEWLINE> return tf . reduce_sum ( x , axis , keepdims ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , urlname ) : <NEWLINE> <TAB> <NEWLINE> dataset_name = urlname . split ( <STRING> ) [ - <NUMBER> ] <NEWLINE> if dataset_name in self . mock_datasets : <NEWLINE> <TAB> resource_name = <STRING> + dataset_name <NEWLINE> from io import BytesIO <NEWLINE> matfile = BytesIO ( ) <NEWLINE> <NEWLINE> dataset = self . mock_datasets [ dataset_name ] <NEWLINE> ordering = None <NEWLINE> if isinstance ( dataset , tuple ) : <NEWLINE> <TAB> dataset , ordering = dataset <NEWLINE> <UNTAB> fake_mldata ( dataset , resource_name , matfile , ordering ) <NEWLINE> <NEWLINE> matfile . seek ( <NUMBER> ) <NEWLINE> return matfile <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise HTTPError ( urlname , <NUMBER> , dataset_name + <STRING> , <NEWLINE> [ ] , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def read_block ( f , offset , length , delimiter = None ) : <NEWLINE> <TAB> <NEWLINE> if offset != f . tell ( ) : <NEWLINE> <TAB> f . seek ( offset ) <NEWLINE> <NEWLINE> <UNTAB> if not offset and length is None and f . tell ( ) == <NUMBER> : <NEWLINE> <TAB> return f . read ( ) <NEWLINE> <NEWLINE> <UNTAB> if delimiter : <NEWLINE> <TAB> seek_delimiter ( f , delimiter , <NUMBER> ** <NUMBER> ) <NEWLINE> start = f . tell ( ) <NEWLINE> length -= start - offset <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> f . seek ( start + length ) <NEWLINE> seek_delimiter ( f , delimiter , <NUMBER> ** <NUMBER> ) <NEWLINE> <UNTAB> except ( OSError , ValueError ) : <NEWLINE> <TAB> f . seek ( <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> end = f . tell ( ) <NEWLINE> <NEWLINE> offset = start <NEWLINE> length = end - start <NEWLINE> <NEWLINE> f . seek ( offset ) <NEWLINE> <NEWLINE> <UNTAB> return f . read ( length ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def try_rpc ( address , method , request , protocol = <STRING> , fail_fast = True , timeout_in_ms = <NUMBER> , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if protocol is None : <NEWLINE> <TAB> protocol = <STRING> <NEWLINE> <UNTAB> protocol = _execute . make_str ( protocol , <STRING> ) <NEWLINE> if fail_fast is None : <NEWLINE> <TAB> fail_fast = True <NEWLINE> <UNTAB> fail_fast = _execute . make_bool ( fail_fast , <STRING> ) <NEWLINE> if timeout_in_ms is None : <NEWLINE> <TAB> timeout_in_ms = <NUMBER> <NEWLINE> <UNTAB> timeout_in_ms = _execute . make_int ( timeout_in_ms , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , address = address , method = method , request = request , <NEWLINE> protocol = protocol , fail_fast = fail_fast , timeout_in_ms = timeout_in_ms , <NEWLINE> name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result = _TryRpcOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , address , method , request , <STRING> , <NEWLINE> protocol , <STRING> , fail_fast , <STRING> , timeout_in_ms ) <NEWLINE> _result = _TryRpcOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return try_rpc_eager_fallback ( <NEWLINE> address , method , request , protocol = protocol , fail_fast = fail_fast , <NEWLINE> timeout_in_ms = timeout_in_ms , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def stacklists ( arg ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( arg , ( tuple , list ) ) : <NEWLINE> <TAB> return stack ( list ( map ( stacklists , arg ) ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return arg <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def output_index ( self , t ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> subgraph_id = self . _output_ts . index ( t ) <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( <NEWLINE> t . name , self . name ) ) <NEWLINE> <UNTAB> return subgraph_id <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _to_corr ( self , m ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not ( m . flags . c_contiguous and m . dtype == np . float64 and m . shape [ <NUMBER> ] == m . shape [ <NUMBER> ] ) : <NEWLINE> <TAB> raise ValueError ( ) <NEWLINE> <NEWLINE> <UNTAB> d = m . shape [ <NUMBER> ] <NEWLINE> for i in range ( d - <NUMBER> ) : <NEWLINE> <TAB> if m [ i , i ] == <NUMBER> : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> elif m [ i , i ] > <NUMBER> : <NEWLINE> <TAB> for j in range ( i + <NUMBER> , d ) : <NEWLINE> <TAB> if m [ j , j ] < <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for j in range ( i + <NUMBER> , d ) : <NEWLINE> <TAB> if m [ j , j ] > <NUMBER> : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> c , s = self . _givens_to_1 ( m [ i , i ] , m [ j , j ] , m [ i , j ] ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> mv = m . ravel ( ) <NEWLINE> drot ( mv , mv , c , - s , n = d , <NEWLINE> offx = i * d , incx = <NUMBER> , offy = j * d , incy = <NUMBER> , <NEWLINE> overwrite_x = True , overwrite_y = True ) <NEWLINE> drot ( mv , mv , c , - s , n = d , <NEWLINE> offx = i , incx = d , offy = j , incy = d , <NEWLINE> overwrite_x = True , overwrite_y = True ) <NEWLINE> <NEWLINE> <UNTAB> return m <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def iteritems ( self ) : <NEWLINE> <TAB> <NEWLINE> return zip ( iter ( self . index ) , iter ( self ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def cholesky ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> from sympy . core . numbers import nan , oo <NEWLINE> if not self . is_symmetric ( ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> M = self . as_mutable ( ) . _cholesky_sparse ( ) <NEWLINE> if M . has ( nan ) or M . has ( oo ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> return self . _new ( M ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_half_edge_first ( self , start_node , end_node ) : <NEWLINE> <TAB> <NEWLINE> if start_node in self and <STRING> in self . nodes [ start_node ] : <NEWLINE> <TAB> reference = self . nodes [ start_node ] [ <STRING> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> reference = None <NEWLINE> <UNTAB> self . add_half_edge_ccw ( start_node , end_node , reference ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def distribute_or_over_and ( expr ) : <NEWLINE> <TAB> <NEWLINE> return _distribute ( ( expr , Or , And ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( <STRING> , <STRING> <NEWLINE> <STRING> ) <NEWLINE> def mean_squared_error_regressor ( tensor_in , labels , weights , biases , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , <NEWLINE> [ tensor_in , labels ] ) : <NEWLINE> <TAB> predictions = nn . xw_plus_b ( tensor_in , weights , biases ) <NEWLINE> if len ( labels . get_shape ( ) ) == <NUMBER> and len ( predictions . get_shape ( ) ) == <NUMBER> : <NEWLINE> <TAB> predictions = array_ops_ . squeeze ( predictions , axis = [ <NUMBER> ] ) <NEWLINE> <UNTAB> return predictions , losses . mean_squared_error ( labels , predictions ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def raise_requested_exception ( self ) : <NEWLINE> <TAB> <NEWLINE> with self . _lock : <NEWLINE> <TAB> if self . _exc_info_to_raise : <NEWLINE> <TAB> six . reraise ( * self . _exc_info_to_raise ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def masked_object ( x , value , copy = True , shrink = True ) : <NEWLINE> <TAB> <NEWLINE> if isMaskedArray ( x ) : <NEWLINE> <TAB> condition = umath . equal ( x . _data , value ) <NEWLINE> mask = x . _mask <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> condition = umath . equal ( np . asarray ( x ) , value ) <NEWLINE> mask = nomask <NEWLINE> <UNTAB> mask = mask_or ( mask , make_mask ( condition , shrink = shrink ) ) <NEWLINE> return masked_array ( x , mask = mask , copy = copy , fill_value = value ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def unreduce ( array , shape , axis , keepdims ) : <NEWLINE> <TAB> <NEWLINE> unreducer = unreducers [ type ( array ) ] <NEWLINE> return unreducer ( array , shape , axis , keepdims ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _adjoint ( self ) : <NEWLINE> <TAB> <NEWLINE> shape = ( self . shape [ <NUMBER> ] , self . shape [ <NUMBER> ] ) <NEWLINE> return _CustomLinearOperator ( shape , matvec = self . rmatvec , <NEWLINE> rmatvec = self . matvec , <NEWLINE> dtype = self . dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def convert ( self , values , nan_rep , encoding , errors ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . values = Int64Index ( np . arange ( self . table . nrows ) ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _compute_mi_cd ( c , d , n_neighbors ) : <NEWLINE> <TAB> <NEWLINE> n_samples = c . shape [ <NUMBER> ] <NEWLINE> c = c . reshape ( ( - <NUMBER> , <NUMBER> ) ) <NEWLINE> <NEWLINE> radius = np . empty ( n_samples ) <NEWLINE> label_counts = np . empty ( n_samples ) <NEWLINE> k_all = np . empty ( n_samples ) <NEWLINE> nn = NearestNeighbors ( ) <NEWLINE> for label in np . unique ( d ) : <NEWLINE> <TAB> mask = d == label <NEWLINE> count = np . sum ( mask ) <NEWLINE> if count > <NUMBER> : <NEWLINE> <TAB> k = min ( n_neighbors , count - <NUMBER> ) <NEWLINE> nn . set_params ( n_neighbors = k ) <NEWLINE> nn . fit ( c [ mask ] ) <NEWLINE> r = nn . kneighbors ( ) [ <NUMBER> ] <NEWLINE> radius [ mask ] = np . nextafter ( r [ : , - <NUMBER> ] , <NUMBER> ) <NEWLINE> k_all [ mask ] = k <NEWLINE> <UNTAB> label_counts [ mask ] = count <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> mask = label_counts > <NUMBER> <NEWLINE> n_samples = np . sum ( mask ) <NEWLINE> label_counts = label_counts [ mask ] <NEWLINE> k_all = k_all [ mask ] <NEWLINE> c = c [ mask ] <NEWLINE> radius = radius [ mask ] <NEWLINE> <NEWLINE> nn . set_params ( algorithm = <STRING> ) <NEWLINE> nn . fit ( c ) <NEWLINE> ind = nn . radius_neighbors ( radius = radius , return_distance = False ) <NEWLINE> m_all = np . array ( [ i . size for i in ind ] ) <NEWLINE> <NEWLINE> mi = ( digamma ( n_samples ) + np . mean ( digamma ( k_all ) ) - <NEWLINE> np . mean ( digamma ( label_counts ) ) - <NEWLINE> np . mean ( digamma ( m_all + <NUMBER> ) ) ) <NEWLINE> <NEWLINE> return max ( <NUMBER> , mi ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def gather_tree ( step_ids , parent_ids , max_sequence_lengths , end_token , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , step_ids = step_ids , parent_ids = parent_ids , <NEWLINE> max_sequence_lengths = max_sequence_lengths , end_token = end_token , <NEWLINE> name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , step_ids , parent_ids , <NEWLINE> max_sequence_lengths , end_token ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return gather_tree_eager_fallback ( <NEWLINE> step_ids , parent_ids , max_sequence_lengths , end_token , name = name , <NEWLINE> ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def viridis ( ) : <NEWLINE> <TAB> <NEWLINE> set_cmap ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rs_cos ( p , x , prec ) : <NEWLINE> <TAB> <NEWLINE> if rs_is_puiseux ( p , x ) : <NEWLINE> <TAB> return rs_puiseux ( rs_cos , p , x , prec ) <NEWLINE> <UNTAB> R = p . ring <NEWLINE> c = _get_constant_term ( p , x ) <NEWLINE> if c : <NEWLINE> <TAB> if R . domain is EX : <NEWLINE> <TAB> c_expr = c . as_expr ( ) <NEWLINE> t1 , t2 = sin ( c_expr ) , cos ( c_expr ) <NEWLINE> <UNTAB> elif isinstance ( c , PolyElement ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> c_expr = c . as_expr ( ) <NEWLINE> t1 , t2 = R ( sin ( c_expr ) ) , R ( cos ( c_expr ) ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> R = R . add_gens ( [ sin ( c_expr ) , cos ( c_expr ) ] ) <NEWLINE> p = p . set_ring ( R ) <NEWLINE> x = x . set_ring ( R ) <NEWLINE> c = c . set_ring ( R ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> t1 , t2 = R ( sin ( c ) ) , R ( cos ( c ) ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> raise DomainError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> p1 = p - c <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> p_cos = rs_cos ( p1 , x , prec ) <NEWLINE> p_sin = rs_sin ( p1 , x , prec ) <NEWLINE> R = R . compose ( p_cos . ring ) . compose ( p_sin . ring ) <NEWLINE> p_cos . set_ring ( R ) <NEWLINE> p_sin . set_ring ( R ) <NEWLINE> t1 , t2 = R ( sin ( c_expr ) ) , R ( cos ( c_expr ) ) <NEWLINE> return p_cos * t2 - p_sin * t1 <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if len ( p ) > <NUMBER> and R . ngens == <NUMBER> : <NEWLINE> <TAB> t = rs_tan ( p / <NUMBER> , x , prec ) <NEWLINE> t2 = rs_square ( t , x , prec ) <NEWLINE> p1 = rs_series_inversion ( <NUMBER> + t2 , x , prec ) <NEWLINE> return rs_mul ( p1 , <NUMBER> - t2 , x , prec ) <NEWLINE> <UNTAB> one = R ( <NUMBER> ) <NEWLINE> n = <NUMBER> <NEWLINE> c = [ ] <NEWLINE> for k in range ( <NUMBER> , prec + <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> c . append ( one / n ) <NEWLINE> c . append ( <NUMBER> ) <NEWLINE> n *= - k * ( k - <NUMBER> ) <NEWLINE> <UNTAB> return rs_series_from_list ( p , c , x , prec ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def expand_trig ( expr , deep = True ) : <NEWLINE> <TAB> <NEWLINE> return sympify ( expr ) . expand ( deep = deep , trig = True , basic = False , <NEWLINE> log = False , mul = False , power_exp = False , power_base = False , multinomial = False ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def quo ( f , g ) : <NEWLINE> <TAB> <NEWLINE> lev , dom , per , F , G = f . unify ( g ) <NEWLINE> return per ( dmp_quo ( F , G , lev , dom ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_offset ( self , xy ) : <NEWLINE> <TAB> <NEWLINE> self . _offset = xy <NEWLINE> <NEWLINE> self . offset_transform . clear ( ) <NEWLINE> self . offset_transform . translate ( xy [ <NUMBER> ] , xy [ <NUMBER> ] ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def visit_Call_35 ( self , node , side = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( node . func , ast . Attribute ) : <NEWLINE> <TAB> res = self . visit_Attribute ( node . func ) <NEWLINE> <UNTAB> elif not isinstance ( node . func , ast . Name ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> res = self . visit ( node . func ) <NEWLINE> <UNTAB> except UndefinedVariableError : <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> res = FuncNode ( node . func . id ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <NEWLINE> <TAB> raise <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if res is None : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> . format ( func = node . func . id ) ) <NEWLINE> <UNTAB> if hasattr ( res , <STRING> ) : <NEWLINE> <TAB> res = res . value <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( res , FuncNode ) : <NEWLINE> <NEWLINE> <TAB> new_args = [ self . visit ( arg ) for arg in node . args ] <NEWLINE> <NEWLINE> if node . keywords : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> . format ( name = res . name ) ) <NEWLINE> <NEWLINE> <UNTAB> return res ( * new_args , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> new_args = [ self . visit ( arg ) . value for arg in node . args ] <NEWLINE> <NEWLINE> for key in node . keywords : <NEWLINE> <TAB> if not isinstance ( key , ast . keyword ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( func = node . func . id ) ) <NEWLINE> <NEWLINE> <UNTAB> if key . arg : <NEWLINE> <NEWLINE> <TAB> kwargs . append ( ast . keyword ( <NEWLINE> keyword . arg , self . visit ( keyword . value ) ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return self . const_type ( res ( * new_args , ** kwargs ) , self . env ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def clear ( self , name = None ) : <NEWLINE> <TAB> <NEWLINE> if name is None : <NEWLINE> <TAB> name = <STRING> % self . _name <NEWLINE> <NEWLINE> <UNTAB> return gen_data_flow_ops . stage_clear ( <NEWLINE> name = name , <NEWLINE> shared_name = self . _name , <NEWLINE> dtypes = self . _dtypes , <NEWLINE> capacity = self . _capacity , <NEWLINE> memory_limit = self . _memory_limit ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def complete_multipartite_graph ( * subset_sizes ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> G = Graph ( ) <NEWLINE> <NEWLINE> if len ( subset_sizes ) == <NUMBER> : <NEWLINE> <TAB> return G <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> extents = pairwise ( accumulate ( ( <NUMBER> , ) + subset_sizes ) ) <NEWLINE> subsets = [ range ( start , end ) for start , end in extents ] <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> subsets = subset_sizes <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> for ( i , subset ) in enumerate ( subsets ) : <NEWLINE> <TAB> G . add_nodes_from ( subset , subset = i ) <NEWLINE> <UNTAB> <UNTAB> except TypeError : <NEWLINE> <TAB> raise NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for subset1 , subset2 in itertools . combinations ( subsets , <NUMBER> ) : <NEWLINE> <TAB> G . add_edges_from ( itertools . product ( subset1 , subset2 ) ) <NEWLINE> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _load_coverage ( F , header_length = <NUMBER> , dtype = np . int16 ) : <NEWLINE> <TAB> <NEWLINE> header = [ F . readline ( ) for i in range ( header_length ) ] <NEWLINE> make_tuple = lambda t : ( t . split ( ) [ <NUMBER> ] , float ( t . split ( ) [ <NUMBER> ] ) ) <NEWLINE> header = dict ( [ make_tuple ( line ) for line in header ] ) <NEWLINE> <NEWLINE> M = np . loadtxt ( F , dtype = dtype ) <NEWLINE> nodata = int ( header [ <STRING> ] ) <NEWLINE> if nodata != - <NUMBER> : <NEWLINE> <TAB> M [ nodata ] = - <NUMBER> <NEWLINE> <UNTAB> return M <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_fontfamily ( self , fontname ) : <NEWLINE> <TAB> <NEWLINE> self . _fontproperties . set_family ( fontname ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def winter ( ) : <NEWLINE> <TAB> <NEWLINE> set_cmap ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def sobel_h ( image , mask = None ) : <NEWLINE> <TAB> <NEWLINE> assert_nD ( image , <NUMBER> ) <NEWLINE> image = img_as_float ( image ) <NEWLINE> result = convolve ( image , HSOBEL_WEIGHTS ) <NEWLINE> return _mask_filter_result ( result , mask ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _get_fiedler_func ( method ) : <NEWLINE> <TAB> <NEWLINE> if method == <STRING> : <NEWLINE> <TAB> method = <STRING> <NEWLINE> <UNTAB> if method in ( <STRING> , <STRING> , <STRING> ) : <NEWLINE> <TAB> def find_fiedler ( L , x , normalized , tol , seed ) : <NEWLINE> <TAB> q = <NUMBER> if method == <STRING> else min ( <NUMBER> , L . shape [ <NUMBER> ] - <NUMBER> ) <NEWLINE> X = asmatrix ( seed . normal ( size = ( q , L . shape [ <NUMBER> ] ) ) ) . T <NEWLINE> sigma , X = _tracemin_fiedler ( L , X , normalized , tol , method ) <NEWLINE> return sigma [ <NUMBER> ] , X [ : , <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> elif method == <STRING> or method == <STRING> : <NEWLINE> <TAB> def find_fiedler ( L , x , normalized , tol , seed ) : <NEWLINE> <TAB> L = csc_matrix ( L , dtype = float ) <NEWLINE> n = L . shape [ <NUMBER> ] <NEWLINE> if normalized : <NEWLINE> <TAB> D = spdiags ( <NUMBER> / sqrt ( L . diagonal ( ) ) , [ <NUMBER> ] , n , n , format = <STRING> ) <NEWLINE> L = D * L * D <NEWLINE> <UNTAB> if method == <STRING> or n < <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> sigma , X = eigsh ( L , <NUMBER> , which = <STRING> , tol = tol , <NEWLINE> return_eigenvectors = True ) <NEWLINE> return sigma [ <NUMBER> ] , X [ : , <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> X = asarray ( asmatrix ( x ) . T ) <NEWLINE> M = spdiags ( <NUMBER> / L . diagonal ( ) , [ <NUMBER> ] , n , n ) <NEWLINE> Y = ones ( n ) <NEWLINE> if normalized : <NEWLINE> <TAB> Y /= D . diagonal ( ) <NEWLINE> <UNTAB> sigma , X = lobpcg ( L , X , M = M , Y = asmatrix ( Y ) . T , tol = tol , <NEWLINE> maxiter = n , largest = False ) <NEWLINE> return sigma [ <NUMBER> ] , X [ : , <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> % method ) <NEWLINE> <NEWLINE> <UNTAB> return find_fiedler <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def masked_greater ( x , value , copy = True ) : <NEWLINE> <TAB> <NEWLINE> return masked_where ( greater ( x , value ) , x , copy = copy ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ cbook . deprecated ( <STRING> , alternative = <STRING> ) <NEWLINE> def norm_flat ( a , p = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if p == <STRING> : <NEWLINE> <TAB> return np . max ( np . abs ( a ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return np . sum ( np . abs ( a ) ** p ) ** ( <NUMBER> / p ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def draw_box_lines ( self , ax , data , support , density , center ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> q25 , q50 , q75 = np . percentile ( data , [ <NUMBER> , <NUMBER> , <NUMBER> ] ) <NEWLINE> whisker_lim = <NUMBER> * iqr ( data ) <NEWLINE> h1 = np . min ( data [ data >= ( q25 - whisker_lim ) ] ) <NEWLINE> h2 = np . max ( data [ data <= ( q75 + whisker_lim ) ] ) <NEWLINE> <NEWLINE> <NEWLINE> if self . orient == <STRING> : <NEWLINE> <TAB> ax . plot ( [ center , center ] , [ h1 , h2 ] , <NEWLINE> linewidth = self . linewidth , <NEWLINE> color = self . gray ) <NEWLINE> ax . plot ( [ center , center ] , [ q25 , q75 ] , <NEWLINE> linewidth = self . linewidth * <NUMBER> , <NEWLINE> color = self . gray ) <NEWLINE> ax . scatter ( center , q50 , <NEWLINE> zorder = <NUMBER> , <NEWLINE> color = <STRING> , <NEWLINE> edgecolor = self . gray , <NEWLINE> s = np . square ( self . linewidth * <NUMBER> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ax . plot ( [ h1 , h2 ] , [ center , center ] , <NEWLINE> linewidth = self . linewidth , <NEWLINE> color = self . gray ) <NEWLINE> ax . plot ( [ q25 , q75 ] , [ center , center ] , <NEWLINE> linewidth = self . linewidth * <NUMBER> , <NEWLINE> color = self . gray ) <NEWLINE> ax . scatter ( q50 , center , <NEWLINE> zorder = <NUMBER> , <NEWLINE> color = <STRING> , <NEWLINE> edgecolor = self . gray , <NEWLINE> s = np . square ( self . linewidth * <NUMBER> ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _best1 ( self , samples ) : <NEWLINE> <TAB> <NEWLINE> r0 , r1 = samples [ : <NUMBER> ] <NEWLINE> return ( self . population [ <NUMBER> ] + self . scale * <NEWLINE> ( self . population [ r0 ] - self . population [ r1 ] ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def bernfrac ( n ) : <NEWLINE> <TAB> <NEWLINE> n = int ( n ) <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> return [ ( <NUMBER> , <NUMBER> ) , ( - <NUMBER> , <NUMBER> ) , ( <NUMBER> , <NUMBER> ) ] [ n ] <NEWLINE> <UNTAB> if n & <NUMBER> : <NEWLINE> <TAB> return ( <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> q = <NUMBER> <NEWLINE> for k in list_primes ( n + <NUMBER> ) : <NEWLINE> <TAB> if not ( n % ( k - <NUMBER> ) ) : <NEWLINE> <TAB> q *= k <NEWLINE> <UNTAB> <UNTAB> prec = bernoulli_size ( n ) + int ( math . log ( q , <NUMBER> ) ) + <NUMBER> <NEWLINE> b = mpf_bernoulli ( n , prec ) <NEWLINE> p = mpf_mul ( b , from_int ( q ) ) <NEWLINE> pint = to_int ( p , round_nearest ) <NEWLINE> return ( pint , q ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _between_impl ( expr , op , cleft , cright , ** kw ) : <NEWLINE> <TAB> <NEWLINE> return BinaryExpression ( <NEWLINE> expr , <NEWLINE> ClauseList ( <NEWLINE> _check_literal ( expr , operators . and_ , cleft ) , <NEWLINE> _check_literal ( expr , operators . and_ , cright ) , <NEWLINE> operator = operators . and_ , <NEWLINE> group = False , group_contents = False ) , <NEWLINE> op , <NEWLINE> negate = operators . notbetween_op <NEWLINE> if op is operators . between_op <NEWLINE> else operators . between_op , <NEWLINE> modifiers = kw ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def mean ( input , axis , keep_dims = False , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if keep_dims is None : <NEWLINE> <TAB> keep_dims = False <NEWLINE> <UNTAB> keep_dims = _execute . make_bool ( keep_dims , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , reduction_indices = axis , keep_dims = keep_dims , <NEWLINE> name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) , <NEWLINE> <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , input , axis , <STRING> , keep_dims ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return mean_eager_fallback ( <NEWLINE> input , axis , keep_dims = keep_dims , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _solve_discrete_lyapunov_direct ( a , q ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> lhs = kron ( a , a . conj ( ) ) <NEWLINE> lhs = np . eye ( lhs . shape [ <NUMBER> ] ) - lhs <NEWLINE> x = solve ( lhs , q . flatten ( ) ) <NEWLINE> <NEWLINE> return np . reshape ( x , q . shape ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def unconstrained_one_edge_augmentation ( G ) : <NEWLINE> <TAB> <NEWLINE> ccs1 = list ( nx . connected_components ( G ) ) <NEWLINE> C = collapse ( G , ccs1 ) <NEWLINE> <NEWLINE> meta_nodes = list ( C . nodes ( ) ) <NEWLINE> <NEWLINE> meta_aug = list ( zip ( meta_nodes , meta_nodes [ <NUMBER> : ] ) ) <NEWLINE> <NEWLINE> inverse = defaultdict ( list ) <NEWLINE> for k , v in C . graph [ <STRING> ] . items ( ) : <NEWLINE> <TAB> inverse [ v ] . append ( k ) <NEWLINE> <UNTAB> for mu , mv in meta_aug : <NEWLINE> <TAB> yield ( inverse [ mu ] [ <NUMBER> ] , inverse [ mv ] [ <NUMBER> ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _z_to_zinv ( num , den ) : <NEWLINE> <TAB> <NEWLINE> diff = len ( num ) - len ( den ) <NEWLINE> if diff > <NUMBER> : <NEWLINE> <TAB> den = np . hstack ( ( np . zeros ( diff ) , den ) ) <NEWLINE> <UNTAB> elif diff < <NUMBER> : <NEWLINE> <TAB> num = np . hstack ( ( np . zeros ( - diff ) , num ) ) <NEWLINE> <UNTAB> return num , den <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def butter ( N , Wn , btype = <STRING> , analog = False , output = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return iirfilter ( N , Wn , btype = btype , analog = analog , <NEWLINE> output = output , ftype = <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def axisinfo ( unit , axis ) : <NEWLINE> <TAB> <NEWLINE> tz = unit <NEWLINE> <NEWLINE> majloc = AutoDateLocator ( tz = tz ) <NEWLINE> majfmt = AutoDateFormatter ( majloc , tz = tz ) <NEWLINE> datemin = datetime . date ( <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> datemax = datetime . date ( <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> <NEWLINE> return units . AxisInfo ( majloc = majloc , majfmt = majfmt , label = <STRING> , <NEWLINE> default_limits = ( datemin , datemax ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def base ( self , base ) : <NEWLINE> <TAB> <NEWLINE> self . _base = base <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dsplit ( ary , indices_or_sections ) : <NEWLINE> <TAB> <NEWLINE> if _nx . ndim ( ary ) < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return split ( ary , indices_or_sections , <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def irfft ( a , n = None , axis = - <NUMBER> , norm = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> a = array ( a , copy = True , dtype = complex ) <NEWLINE> if n is None : <NEWLINE> <TAB> n = ( a . shape [ axis ] - <NUMBER> ) * <NUMBER> <NEWLINE> <UNTAB> unitary = _unitary ( norm ) <NEWLINE> output = _raw_fft ( a , n , axis , fftpack . rffti , fftpack . rfftb , <NEWLINE> _real_fft_cache ) <NEWLINE> return output * ( <NUMBER> / ( sqrt ( n ) if unitary else n ) ) <NEWLINE> <UNTAB> <END> <EoC>
