<BoC> def data_parallel ( module , inputs , device_ids = None , output_device = None , dim = <NUMBER> , module_kwargs = None ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( inputs , tuple ) : <NEWLINE> <TAB> inputs = ( inputs , ) <NEWLINE> <NEWLINE> <UNTAB> if device_ids is None : <NEWLINE> <TAB> device_ids = list ( range ( torch . cuda . device_count ( ) ) ) <NEWLINE> <NEWLINE> <UNTAB> if output_device is None : <NEWLINE> <TAB> output_device = device_ids [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> inputs , module_kwargs = scatter_kwargs ( inputs , module_kwargs , device_ids , dim ) <NEWLINE> if len ( device_ids ) == <NUMBER> : <NEWLINE> <TAB> return module ( * inputs [ <NUMBER> ] , ** module_kwargs [ <NUMBER> ] ) <NEWLINE> <UNTAB> used_device_ids = device_ids [ : len ( inputs ) ] <NEWLINE> replicas = replicate ( module , used_device_ids ) <NEWLINE> outputs = parallel_apply ( replicas , inputs , module_kwargs , used_device_ids ) <NEWLINE> return gather ( outputs , output_device , dim ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dup_lcm ( f , g , K ) : <NEWLINE> <TAB> <NEWLINE> if K . is_Field : <NEWLINE> <TAB> return dup_ff_lcm ( f , g , K ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return dup_rr_lcm ( f , g , K ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def find_stacks ( node , strict = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> fso = FindStackOps ( ) <NEWLINE> fso . visit ( node ) <NEWLINE> <NEWLINE> AnnotateStacks ( fso . push_pop_pairs , strict ) . visit ( node ) <NEWLINE> return node <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _logistic_loss_and_grad ( w , X , y , alpha , sample_weight = None ) : <NEWLINE> <TAB> <NEWLINE> n_samples , n_features = X . shape <NEWLINE> grad = np . empty_like ( w ) <NEWLINE> <NEWLINE> w , c , yz = _intercept_dot ( w , X , y ) <NEWLINE> <NEWLINE> if sample_weight is None : <NEWLINE> <TAB> sample_weight = np . ones ( n_samples ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> out = - np . sum ( sample_weight * log_logistic ( yz ) ) + <NUMBER> * alpha * np . dot ( w , w ) <NEWLINE> <NEWLINE> z = expit ( yz ) <NEWLINE> z0 = sample_weight * ( z - <NUMBER> ) * y <NEWLINE> <NEWLINE> grad [ : n_features ] = safe_sparse_dot ( X . T , z0 ) + alpha * w <NEWLINE> <NEWLINE> <NEWLINE> if grad . shape [ <NUMBER> ] > n_features : <NEWLINE> <TAB> grad [ - <NUMBER> ] = z0 . sum ( ) <NEWLINE> <UNTAB> return out , grad <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _parse_cubehelix_args ( argstr ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if argstr . startswith ( <STRING> ) : <NEWLINE> <TAB> argstr = argstr [ <NUMBER> : ] <NEWLINE> <NEWLINE> <UNTAB> if argstr . endswith ( <STRING> ) : <NEWLINE> <TAB> reverse = True <NEWLINE> argstr = argstr [ : - <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> reverse = False <NEWLINE> <NEWLINE> <UNTAB> if not argstr : <NEWLINE> <TAB> return [ ] , { <STRING> : reverse } <NEWLINE> <NEWLINE> <UNTAB> all_args = argstr . split ( <STRING> ) <NEWLINE> <NEWLINE> args = [ float ( a . strip ( <STRING> ) ) for a in all_args if <STRING> not in a ] <NEWLINE> <NEWLINE> kwargs = [ a . split ( <STRING> ) for a in all_args if <STRING> in a ] <NEWLINE> kwargs = { k . strip ( <STRING> ) : float ( v . strip ( <STRING> ) ) for k , v in kwargs } <NEWLINE> <NEWLINE> kwarg_map = dict ( <NEWLINE> s = <STRING> , r = <STRING> , g = <STRING> , <NEWLINE> h = <STRING> , l = <STRING> , d = <STRING> , <NEWLINE> ) <NEWLINE> <NEWLINE> kwargs = { kwarg_map . get ( k , k ) : v for k , v in kwargs . items ( ) } <NEWLINE> <NEWLINE> if reverse : <NEWLINE> <TAB> kwargs [ <STRING> ] = True <NEWLINE> <NEWLINE> <UNTAB> return args , kwargs <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _ensure_like_indices ( time , panels ) : <NEWLINE> <TAB> <NEWLINE> n_time = len ( time ) <NEWLINE> n_panel = len ( panels ) <NEWLINE> u_panels = np . unique ( panels ) <NEWLINE> u_time = np . unique ( time ) <NEWLINE> if len ( u_time ) == n_time : <NEWLINE> <TAB> time = np . tile ( u_time , len ( u_panels ) ) <NEWLINE> <UNTAB> if len ( u_panels ) == n_panel : <NEWLINE> <TAB> panels = np . repeat ( u_panels , len ( u_time ) ) <NEWLINE> <UNTAB> return time , panels <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def copy ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . npartitions == <NUMBER> : <NEWLINE> <TAB> return self . map_blocks ( M . copy ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return Array ( self . dask , self . name , self . chunks , self . dtype ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def createFontList ( fontfiles , fontext = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> fontlist = [ ] <NEWLINE> <NEWLINE> seen = set ( ) <NEWLINE> for fpath in fontfiles : <NEWLINE> <TAB> _log . debug ( <STRING> , fpath ) <NEWLINE> fname = os . path . split ( fpath ) [ <NUMBER> ] <NEWLINE> if fname in seen : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> seen . add ( fname ) <NEWLINE> <UNTAB> if fontext == <STRING> : <NEWLINE> <TAB> try : <NEWLINE> <TAB> with open ( fpath , <STRING> ) as fh : <NEWLINE> <TAB> font = afm . AFM ( fh ) <NEWLINE> <UNTAB> <UNTAB> except EnvironmentError : <NEWLINE> <TAB> _log . info ( <STRING> , fpath ) <NEWLINE> continue <NEWLINE> <UNTAB> except RuntimeError : <NEWLINE> <TAB> _log . info ( <STRING> , fpath ) <NEWLINE> continue <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> prop = afmFontProperty ( fpath , font ) <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> font = ft2font . FT2Font ( fpath ) <NEWLINE> <UNTAB> except RuntimeError : <NEWLINE> <TAB> _log . info ( <STRING> , fpath ) <NEWLINE> continue <NEWLINE> <UNTAB> except UnicodeError : <NEWLINE> <TAB> _log . info ( <STRING> ) <NEWLINE> continue <NEWLINE> <UNTAB> except OSError : <NEWLINE> <TAB> _log . info ( <STRING> , fpath ) <NEWLINE> continue <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> prop = ttfFontProperty ( font ) <NEWLINE> <UNTAB> except ( KeyError , RuntimeError , ValueError , NotImplementedError ) : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> fontlist . append ( prop ) <NEWLINE> <UNTAB> return fontlist <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def prefixes ( seq ) : <NEWLINE> <TAB> <NEWLINE> n = len ( seq ) <NEWLINE> <NEWLINE> for i in range ( n ) : <NEWLINE> <TAB> yield seq [ : i + <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _newnames ( datatype , order ) : <NEWLINE> <TAB> <NEWLINE> oldnames = datatype . names <NEWLINE> nameslist = list ( oldnames ) <NEWLINE> if isinstance ( order , str ) : <NEWLINE> <TAB> order = [ order ] <NEWLINE> <UNTAB> seen = set ( ) <NEWLINE> if isinstance ( order , ( list , tuple ) ) : <NEWLINE> <TAB> for name in order : <NEWLINE> <TAB> try : <NEWLINE> <TAB> nameslist . remove ( name ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> if name in seen : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( name , ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( name , ) ) <NEWLINE> <UNTAB> <UNTAB> seen . add ( name ) <NEWLINE> <UNTAB> return tuple ( list ( order ) + nameslist ) <NEWLINE> <UNTAB> raise ValueError ( <STRING> % ( order , ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_isolation_level ( self , dbapi_conn , level ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_factor_list ( f , K0 ) : <NEWLINE> <TAB> <NEWLINE> j , f = dup_terms_gcd ( f , K0 ) <NEWLINE> cont , f = dup_primitive ( f , K0 ) <NEWLINE> <NEWLINE> if K0 . is_FiniteField : <NEWLINE> <TAB> coeff , factors = dup_gf_factor ( f , K0 ) <NEWLINE> <UNTAB> elif K0 . is_Algebraic : <NEWLINE> <TAB> coeff , factors = dup_ext_factor ( f , K0 ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if not K0 . is_Exact : <NEWLINE> <TAB> K0_inexact , K0 = K0 , K0 . get_exact ( ) <NEWLINE> f = dup_convert ( f , K0_inexact , K0 ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> K0_inexact = None <NEWLINE> <NEWLINE> <UNTAB> if K0 . is_Field : <NEWLINE> <TAB> K = K0 . get_ring ( ) <NEWLINE> <NEWLINE> denom , f = dup_clear_denoms ( f , K0 , K ) <NEWLINE> f = dup_convert ( f , K0 , K ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> K = K0 <NEWLINE> <NEWLINE> <UNTAB> if K . is_ZZ : <NEWLINE> <TAB> coeff , factors = dup_zz_factor ( f , K ) <NEWLINE> <UNTAB> elif K . is_Poly : <NEWLINE> <TAB> f , u = dmp_inject ( f , <NUMBER> , K ) <NEWLINE> <NEWLINE> coeff , factors = dmp_factor_list ( f , u , K . dom ) <NEWLINE> <NEWLINE> for i , ( f , k ) in enumerate ( factors ) : <NEWLINE> <TAB> factors [ i ] = ( dmp_eject ( f , u , K ) , k ) <NEWLINE> <NEWLINE> <UNTAB> coeff = K . convert ( coeff , K . dom ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise DomainError ( <STRING> % K0 ) <NEWLINE> <NEWLINE> <UNTAB> if K0 . is_Field : <NEWLINE> <TAB> for i , ( f , k ) in enumerate ( factors ) : <NEWLINE> <TAB> factors [ i ] = ( dup_convert ( f , K , K0 ) , k ) <NEWLINE> <NEWLINE> <UNTAB> coeff = K0 . convert ( coeff , K ) <NEWLINE> coeff = K0 . quo ( coeff , denom ) <NEWLINE> <NEWLINE> if K0_inexact : <NEWLINE> <TAB> for i , ( f , k ) in enumerate ( factors ) : <NEWLINE> <TAB> max_norm = dup_max_norm ( f , K0 ) <NEWLINE> f = dup_quo_ground ( f , max_norm , K0 ) <NEWLINE> f = dup_convert ( f , K0 , K0_inexact ) <NEWLINE> factors [ i ] = ( f , k ) <NEWLINE> coeff = K0 . mul ( coeff , K0 . pow ( max_norm , k ) ) <NEWLINE> <NEWLINE> <UNTAB> coeff = K0_inexact . convert ( coeff , K0 ) <NEWLINE> K0 = K0_inexact <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if j : <NEWLINE> <TAB> factors . insert ( <NUMBER> , ( [ K0 . one , K0 . zero ] , j ) ) <NEWLINE> <NEWLINE> <UNTAB> return coeff * cont , _sort_factors ( factors ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def concat ( xs , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> y , = Concat ( axis ) . apply ( xs ) <NEWLINE> return y <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def shrink_mask ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _mask = _shrink_mask ( self . _mask ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def tmean ( a , limits = None , inclusive = ( True , True ) , axis = None ) : <NEWLINE> <TAB> <NEWLINE> return trima ( a , limits = limits , inclusive = inclusive ) . mean ( axis = axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def load_sample_images ( ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> from . . externals . _pilutil import imread <NEWLINE> <NEWLINE> module_path = join ( dirname ( __file__ ) , <STRING> ) <NEWLINE> with open ( join ( module_path , <STRING> ) ) as f : <NEWLINE> <TAB> descr = f . read ( ) <NEWLINE> <UNTAB> filenames = [ join ( module_path , filename ) <NEWLINE> for filename in os . listdir ( module_path ) <NEWLINE> if filename . endswith ( <STRING> ) ] <NEWLINE> <NEWLINE> images = [ imread ( filename ) for filename in filenames ] <NEWLINE> <NEWLINE> return Bunch ( images = images , <NEWLINE> filenames = filenames , <NEWLINE> DESCR = descr ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def allclose ( a , b , rtol = <NUMBER> , atol = <NUMBER> , equal_nan = False ) : <NEWLINE> <TAB> <NEWLINE> res = all ( isclose ( a , b , rtol = rtol , atol = atol , equal_nan = equal_nan ) ) <NEWLINE> return bool ( res ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def sigmoid_cross_entropy ( x , t , normalize = True , reduce = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return SigmoidCrossEntropy ( normalize , reduce ) . apply ( ( x , t ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def createDimension ( self , name , length ) : <NEWLINE> <TAB> <NEWLINE> if length is None and self . _dims : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> self . dimensions [ name ] = length <NEWLINE> self . _dims . append ( name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _fix_shape ( x , n , axis ) : <NEWLINE> <TAB> <NEWLINE> s = list ( x . shape ) <NEWLINE> if s [ axis ] > n : <NEWLINE> <TAB> index = [ slice ( None ) ] * len ( s ) <NEWLINE> index [ axis ] = slice ( <NUMBER> , n ) <NEWLINE> x = x [ index ] <NEWLINE> return x , False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> index = [ slice ( None ) ] * len ( s ) <NEWLINE> index [ axis ] = slice ( <NUMBER> , s [ axis ] ) <NEWLINE> s [ axis ] = n <NEWLINE> z = zeros ( s , x . dtype . char ) <NEWLINE> z [ index ] = x <NEWLINE> return z , True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def solve_continuous_lyapunov ( a , q ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> a = np . atleast_2d ( _asarray_validated ( a , check_finite = True ) ) <NEWLINE> q = np . atleast_2d ( _asarray_validated ( q , check_finite = True ) ) <NEWLINE> <NEWLINE> r_or_c = float <NEWLINE> <NEWLINE> for ind , _ in enumerate ( ( a , q ) ) : <NEWLINE> <TAB> if np . iscomplexobj ( _ ) : <NEWLINE> <TAB> r_or_c = complex <NEWLINE> <NEWLINE> <UNTAB> if not np . equal ( * _ . shape ) : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( <STRING> [ ind ] ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if a . shape != q . shape : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> r , u = schur ( a , output = <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> f = u . conj ( ) . T . dot ( q . dot ( u ) ) <NEWLINE> <NEWLINE> <NEWLINE> trsyl = get_lapack_funcs ( <STRING> , ( r , f ) ) <NEWLINE> <NEWLINE> dtype_string = <STRING> if r_or_c == float else <STRING> <NEWLINE> y , scale , info = trsyl ( r , r , f , tranb = dtype_string ) <NEWLINE> <NEWLINE> if info < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( - info ) ) <NEWLINE> <UNTAB> elif info == <NUMBER> : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> , <NEWLINE> RuntimeWarning ) <NEWLINE> <UNTAB> y *= scale <NEWLINE> <NEWLINE> return u . dot ( y ) . dot ( u . conj ( ) . T ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_num_denum ( self , input ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if input . owner is None or input . owner . op not in [ <NEWLINE> self . main , self . inverse , self . reciprocal ] : <NEWLINE> <TAB> if input . owner and isinstance ( input . owner . op , T . DimShuffle ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> dsn = input . owner <NEWLINE> dsop = dsn . op <NEWLINE> <NEWLINE> <NEWLINE> dsi0 = dsn . inputs [ <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> compatible_order = ( ( <STRING> , ) * <NEWLINE> ( input . type . ndim - dsi0 . type . ndim ) + <NEWLINE> tuple ( range ( dsi0 . type . ndim ) ) ) <NEWLINE> if dsop . new_order == compatible_order : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return self . get_num_denum ( input . owner . inputs [ <NUMBER> ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return [ input ] , [ ] <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return [ input ] , [ ] <NEWLINE> <UNTAB> <UNTAB> num = [ ] <NEWLINE> denum = [ ] <NEWLINE> parent = input . owner <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> pairs = [ self . get_num_denum ( input2 ) for input2 in parent . inputs ] <NEWLINE> <NEWLINE> if parent . op == self . main : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> num = reduce ( list . __iadd__ , map ( operator . itemgetter ( <NUMBER> ) , pairs ) ) <NEWLINE> denum = reduce ( list . __iadd__ , map ( operator . itemgetter ( <NUMBER> ) , pairs ) ) <NEWLINE> <UNTAB> elif parent . op == self . inverse : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> num = pairs [ <NUMBER> ] [ <NUMBER> ] + pairs [ <NUMBER> ] [ <NUMBER> ] <NEWLINE> denum = pairs [ <NUMBER> ] [ <NUMBER> ] + pairs [ <NUMBER> ] [ <NUMBER> ] <NEWLINE> <UNTAB> elif parent . op == self . reciprocal : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> num = pairs [ <NUMBER> ] [ <NUMBER> ] <NEWLINE> denum = pairs [ <NUMBER> ] [ <NUMBER> ] <NEWLINE> <UNTAB> return num , denum <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def clear ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> del self . registry [ self . scopefunc ( ) ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def checkpoint_exists ( checkpoint_prefix ) : <NEWLINE> <TAB> <NEWLINE> pathname = _prefix_to_checkpoint_path ( checkpoint_prefix , <NEWLINE> saver_pb2 . SaverDef . V2 ) <NEWLINE> if file_io . get_matching_files ( pathname ) : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> elif file_io . get_matching_files ( checkpoint_prefix ) : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def list_variables ( self ) : <NEWLINE> <TAB> <NEWLINE> self . mat_stream . seek ( <NUMBER> ) <NEWLINE> <NEWLINE> self . initialize_read ( ) <NEWLINE> self . read_file_header ( ) <NEWLINE> vars = [ ] <NEWLINE> while not self . end_of_stream ( ) : <NEWLINE> <TAB> hdr , next_position = self . read_var_header ( ) <NEWLINE> name = asstr ( hdr . name ) <NEWLINE> if name == <STRING> : <NEWLINE> <NEWLINE> <TAB> name = <STRING> <NEWLINE> <NEWLINE> <UNTAB> shape = self . _matrix_reader . shape_from_header ( hdr ) <NEWLINE> if hdr . is_logical : <NEWLINE> <TAB> info = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> info = mclass_info . get ( hdr . mclass , <STRING> ) <NEWLINE> <UNTAB> vars . append ( ( name , shape , info ) ) <NEWLINE> <NEWLINE> self . mat_stream . seek ( next_position ) <NEWLINE> <UNTAB> return vars <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def invoke ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _ensure_safe ( ) <NEWLINE> self . _interpreter . Invoke ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_configuration_from_input_tensors ( self , input_tensors ) : <NEWLINE> <TAB> <NEWLINE> if len ( input_tensors ) != self . number_of_tuple_elements : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> , ( <NEWLINE> str ( input_tensors ) , self . number_of_tuple_elements ) ) <NEWLINE> <UNTAB> self . set_tuple_shapes ( [ t . shape for t in input_tensors ] ) <NEWLINE> self . set_tuple_types ( [ t . dtype for t in input_tensors ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def load_checkpoint ( ckpt_dir_or_file ) : <NEWLINE> <TAB> <NEWLINE> filename = _get_checkpoint_filename ( ckpt_dir_or_file ) <NEWLINE> if filename is None : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % ckpt_dir_or_file ) <NEWLINE> <UNTAB> return pywrap_tensorflow . NewCheckpointReader ( filename ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def request_stop ( self , ex = None ) : <NEWLINE> <TAB> <NEWLINE> self . _coord . request_stop ( ex = ex ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def backend ( ) : <NEWLINE> <TAB> <NEWLINE> return <STRING> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def roberts_neg_diag ( image , mask = None ) : <NEWLINE> <TAB> <NEWLINE> assert_nD ( image , <NUMBER> ) <NEWLINE> image = img_as_float ( image ) <NEWLINE> result = convolve ( image , ROBERTS_ND_WEIGHTS ) <NEWLINE> return _mask_filter_result ( result , mask ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def array ( symbol , dim , intent = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( dim , Attribute ) : <NEWLINE> <TAB> if str ( dim . name ) != <STRING> : <NEWLINE> <TAB> raise ValueError ( <STRING> % str ( dim ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> dim = dimension ( * dim ) <NEWLINE> <NEWLINE> <UNTAB> attrs = list ( kwargs . pop ( <STRING> , [ ] ) ) + [ dim ] <NEWLINE> if intent is not None : <NEWLINE> <TAB> if intent not in ( intent_in , intent_out , intent_inout ) : <NEWLINE> <TAB> intent = { <STRING> : intent_in , <STRING> : intent_out , <STRING> : intent_inout } [ intent ] <NEWLINE> <UNTAB> attrs . append ( intent ) <NEWLINE> <UNTAB> value = kwargs . pop ( <STRING> , None ) <NEWLINE> type_ = kwargs . pop ( <STRING> , None ) <NEWLINE> if type_ is None : <NEWLINE> <TAB> return Variable . deduced ( symbol , value = value , attrs = attrs ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return Variable ( symbol , type_ , value = value , attrs = attrs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def read_ints ( self , dtype = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return self . read_record ( dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ docstring . dedent_interpd <NEWLINE> def axvline ( self , x = <NUMBER> , ymin = <NUMBER> , ymax = <NUMBER> , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if <STRING> in kwargs : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> + <STRING> ) <NEWLINE> <UNTAB> xmin , xmax = self . get_xbound ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . _process_unit_info ( xdata = x , kwargs = kwargs ) <NEWLINE> xx = self . convert_xunits ( x ) <NEWLINE> scalex = ( xx < xmin ) or ( xx > xmax ) <NEWLINE> <NEWLINE> trans = self . get_xaxis_transform ( which = <STRING> ) <NEWLINE> l = mlines . Line2D ( [ x , x ] , [ ymin , ymax ] , transform = trans , ** kwargs ) <NEWLINE> self . add_line ( l ) <NEWLINE> self . autoscale_view ( scalex = scalex , scaley = False ) <NEWLINE> return l <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _symbolic_factor ( expr , opt , method ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( expr , Expr ) and not expr . is_Relational : <NEWLINE> <TAB> if hasattr ( expr , <STRING> ) : <NEWLINE> <TAB> return expr . _eval_factor ( ) <NEWLINE> <UNTAB> coeff , factors = _symbolic_factor_list ( together ( expr ) , opt , method ) <NEWLINE> return _keep_coeff ( coeff , _factors_product ( factors ) ) <NEWLINE> <UNTAB> elif hasattr ( expr , <STRING> ) : <NEWLINE> <TAB> return expr . func ( * [ _symbolic_factor ( arg , opt , method ) for arg in expr . args ] ) <NEWLINE> <UNTAB> elif hasattr ( expr , <STRING> ) : <NEWLINE> <TAB> return expr . __class__ ( [ _symbolic_factor ( arg , opt , method ) for arg in expr ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return expr <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def register_persistent ( self , name ) : <NEWLINE> <TAB> <NEWLINE> if not hasattr ( self , name ) : <NEWLINE> <TAB> raise AttributeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % name ) <NEWLINE> <UNTAB> self . _persistent . add ( name ) <NEWLINE> self . _params . discard ( name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def isdecimal ( self ) : <NEWLINE> <TAB> <NEWLINE> return isdecimal ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def extract_multiplicatively ( self , c ) : <NEWLINE> <TAB> <NEWLINE> from . function import _coeff_isneg <NEWLINE> <NEWLINE> c = sympify ( c ) <NEWLINE> if self is S . NaN : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> if c is S . One : <NEWLINE> <TAB> return self <NEWLINE> <UNTAB> elif c == self : <NEWLINE> <TAB> return S . One <NEWLINE> <NEWLINE> <UNTAB> if c . is_Add : <NEWLINE> <TAB> cc , pc = c . primitive ( ) <NEWLINE> if cc is not S . One : <NEWLINE> <TAB> c = Mul ( cc , pc , evaluate = False ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if c . is_Mul : <NEWLINE> <TAB> a , b = c . as_two_terms ( ) <NEWLINE> x = self . extract_multiplicatively ( a ) <NEWLINE> if x is not None : <NEWLINE> <TAB> return x . extract_multiplicatively ( b ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> quotient = self / c <NEWLINE> if self . is_Number : <NEWLINE> <TAB> if self is S . Infinity : <NEWLINE> <TAB> if c . is_positive : <NEWLINE> <TAB> return S . Infinity <NEWLINE> <UNTAB> <UNTAB> elif self is S . NegativeInfinity : <NEWLINE> <TAB> if c . is_negative : <NEWLINE> <TAB> return S . Infinity <NEWLINE> <UNTAB> elif c . is_positive : <NEWLINE> <TAB> return S . NegativeInfinity <NEWLINE> <UNTAB> <UNTAB> elif self is S . ComplexInfinity : <NEWLINE> <TAB> if not c . is_zero : <NEWLINE> <TAB> return S . ComplexInfinity <NEWLINE> <UNTAB> <UNTAB> elif self . is_Integer : <NEWLINE> <TAB> if not quotient . is_Integer : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> elif self . is_positive and quotient . is_negative : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return quotient <NEWLINE> <UNTAB> <UNTAB> elif self . is_Rational : <NEWLINE> <TAB> if not quotient . is_Rational : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> elif self . is_positive and quotient . is_negative : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return quotient <NEWLINE> <UNTAB> <UNTAB> elif self . is_Float : <NEWLINE> <TAB> if not quotient . is_Float : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> elif self . is_positive and quotient . is_negative : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return quotient <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif self . is_NumberSymbol or self . is_Symbol or self is S . ImaginaryUnit : <NEWLINE> <TAB> if quotient . is_Mul and len ( quotient . args ) == <NUMBER> : <NEWLINE> <TAB> if quotient . args [ <NUMBER> ] . is_Integer and quotient . args [ <NUMBER> ] . is_positive and quotient . args [ <NUMBER> ] == self : <NEWLINE> <TAB> return quotient <NEWLINE> <UNTAB> <UNTAB> elif quotient . is_Integer and c . is_Number : <NEWLINE> <TAB> return quotient <NEWLINE> <UNTAB> <UNTAB> elif self . is_Add : <NEWLINE> <TAB> cs , ps = self . primitive ( ) <NEWLINE> <NEWLINE> if c . is_Number and c is not S . NegativeOne : <NEWLINE> <NEWLINE> <TAB> if cs is not S . One : <NEWLINE> <TAB> if c . is_negative : <NEWLINE> <TAB> xc = - ( cs . extract_multiplicatively ( - c ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> xc = cs . extract_multiplicatively ( c ) <NEWLINE> <UNTAB> if xc is not None : <NEWLINE> <TAB> return xc * ps <NEWLINE> <UNTAB> <UNTAB> return <NEWLINE> <UNTAB> if c == ps : <NEWLINE> <TAB> return cs <NEWLINE> <NEWLINE> <UNTAB> newargs = [ ] <NEWLINE> for arg in ps . args : <NEWLINE> <TAB> newarg = arg . extract_multiplicatively ( c ) <NEWLINE> if newarg is None : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> newargs . append ( newarg ) <NEWLINE> <NEWLINE> <UNTAB> if cs is not S . One : <NEWLINE> <TAB> return Add . _from_args ( [ cs * t for t in newargs ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return Add . _from_args ( newargs ) <NEWLINE> <UNTAB> <UNTAB> elif self . is_Mul : <NEWLINE> <TAB> args = list ( self . args ) <NEWLINE> for i , arg in enumerate ( args ) : <NEWLINE> <TAB> newarg = arg . extract_multiplicatively ( c ) <NEWLINE> if newarg is not None : <NEWLINE> <TAB> args [ i ] = newarg <NEWLINE> return Mul ( * args ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif self . is_Pow : <NEWLINE> <TAB> if c . is_Pow and c . base == self . base : <NEWLINE> <TAB> new_exp = self . exp . extract_additively ( c . exp ) <NEWLINE> if new_exp is not None : <NEWLINE> <TAB> return self . base ** ( new_exp ) <NEWLINE> <UNTAB> <UNTAB> elif c == self . base : <NEWLINE> <TAB> new_exp = self . exp . extract_additively ( <NUMBER> ) <NEWLINE> if new_exp is not None : <NEWLINE> <TAB> return self . base ** ( new_exp ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ _graph_action_deprecation <NEWLINE> def run_n ( output_dict , feed_dict = None , restore_checkpoint_path = None , n = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return run_feeds ( <NEWLINE> output_dict = output_dict , <NEWLINE> feed_dicts = itertools . repeat ( feed_dict , n ) , <NEWLINE> restore_checkpoint_path = restore_checkpoint_path ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def report_memory ( i = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> from subprocess import Popen , PIPE <NEWLINE> pid = os . getpid ( ) <NEWLINE> if sys . platform == <STRING> : <NEWLINE> <TAB> try : <NEWLINE> <TAB> a2 = Popen ( [ <STRING> , <STRING> , <STRING> % pid , <STRING> , <STRING> ] , <NEWLINE> stdout = PIPE ) . stdout . readlines ( ) <NEWLINE> <UNTAB> except OSError : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> mem = int ( a2 [ - <NUMBER> ] . strip ( ) ) <NEWLINE> <UNTAB> elif sys . platform == <STRING> : <NEWLINE> <TAB> try : <NEWLINE> <TAB> a2 = Popen ( [ <STRING> , <STRING> , <STRING> % pid , <STRING> , <STRING> ] , <NEWLINE> stdout = PIPE ) . stdout . readlines ( ) <NEWLINE> <UNTAB> except OSError : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> mem = int ( a2 [ <NUMBER> ] . split ( ) [ <NUMBER> ] ) <NEWLINE> <UNTAB> elif sys . platform == <STRING> : <NEWLINE> <TAB> try : <NEWLINE> <TAB> a2 = Popen ( [ <STRING> , <STRING> , <STRING> % pid , <STRING> , <STRING> ] , <NEWLINE> stdout = PIPE ) . stdout . readlines ( ) <NEWLINE> <UNTAB> except OSError : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> mem = int ( a2 [ <NUMBER> ] . split ( ) [ <NUMBER> ] ) <NEWLINE> <UNTAB> elif sys . platform == <STRING> : <NEWLINE> <TAB> try : <NEWLINE> <TAB> a2 = Popen ( [ <STRING> , <STRING> , <STRING> , <STRING> % pid ] , <NEWLINE> stdout = PIPE ) . stdout . read ( ) <NEWLINE> <UNTAB> except OSError : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> mem = int ( a2 . strip ( ) . split ( ) [ - <NUMBER> ] . replace ( <STRING> , <STRING> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> % sys . platform ) <NEWLINE> <UNTAB> return mem <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def diag ( v , k = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> output = np . diag ( v , k ) . view ( MaskedArray ) <NEWLINE> if getmask ( v ) is not nomask : <NEWLINE> <TAB> output . _mask = np . diag ( v . _mask , k ) <NEWLINE> <UNTAB> return output <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_yaxis_transform ( self , which = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if which == <STRING> : <NEWLINE> <TAB> return self . _yaxis_transform <NEWLINE> <UNTAB> elif which == <STRING> : <NEWLINE> <NEWLINE> <TAB> return self . spines [ <STRING> ] . get_spine_transform ( ) <NEWLINE> <UNTAB> elif which == <STRING> : <NEWLINE> <NEWLINE> <TAB> return self . spines [ <STRING> ] . get_spine_transform ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_variable_value ( self , name ) : <NEWLINE> <TAB> <NEWLINE> return load_variable ( self . model_dir , name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def random_crop ( value , size , seed = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> with ops . name_scope ( name , <STRING> , [ value , size ] ) as name : <NEWLINE> <TAB> value = ops . convert_to_tensor ( value , name = <STRING> ) <NEWLINE> size = ops . convert_to_tensor ( size , dtype = dtypes . int32 , name = <STRING> ) <NEWLINE> shape = array_ops . shape ( value ) <NEWLINE> check = control_flow_ops . Assert ( <NEWLINE> math_ops . reduce_all ( shape >= size ) , <NEWLINE> [ <STRING> , shape , size ] , <NEWLINE> summarize = <NUMBER> ) <NEWLINE> shape = control_flow_ops . with_dependencies ( [ check ] , shape ) <NEWLINE> limit = shape - size + <NUMBER> <NEWLINE> offset = random_uniform ( <NEWLINE> array_ops . shape ( shape ) , <NEWLINE> dtype = size . dtype , <NEWLINE> maxval = size . dtype . max , <NEWLINE> seed = seed ) % limit <NEWLINE> return array_ops . slice ( value , offset , size , name = name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ contextlib . contextmanager <NEWLINE> def using_config ( name , value , config = config ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( config . _local , name ) : <NEWLINE> <TAB> old_value = getattr ( config , name ) <NEWLINE> setattr ( config , name , value ) <NEWLINE> try : <NEWLINE> <TAB> yield <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> setattr ( config , name , old_value ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> setattr ( config , name , value ) <NEWLINE> try : <NEWLINE> <TAB> yield <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> delattr ( config , name ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def copydata ( self , var ) : <NEWLINE> <TAB> <NEWLINE> src = var . array <NEWLINE> dst = self . array <NEWLINE> if src is None : <NEWLINE> <TAB> if dst is None : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> var . initialize ( self . shape ) <NEWLINE> src = var . array <NEWLINE> <UNTAB> elif dst is None : <NEWLINE> <TAB> self . initialize ( src . shape ) <NEWLINE> dst = self . array <NEWLINE> <UNTAB> backend . copyto ( dst , src ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def remap_default ( self , remove_input_map = True , remove_output_map = True ) : <NEWLINE> <TAB> <NEWLINE> res = self . copy ( ) <NEWLINE> res . _remap_default ( remove_input_map , remove_output_map ) <NEWLINE> return res <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def gcd ( f , g = None , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( f , <STRING> ) : <NEWLINE> <TAB> if g is not None : <NEWLINE> <TAB> gens = ( g , ) + gens <NEWLINE> <NEWLINE> <UNTAB> return gcd_list ( f , * gens , ** args ) <NEWLINE> <UNTAB> elif g is None : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> options . allowed_flags ( args , [ <STRING> ] ) <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> ( F , G ) , opt = parallel_poly_from_expr ( ( f , g ) , * gens , ** args ) <NEWLINE> <NEWLINE> <NEWLINE> a , b = map ( sympify , ( f , g ) ) <NEWLINE> if a . is_algebraic and a . is_irrational and b . is_algebraic and b . is_irrational : <NEWLINE> <TAB> frc = ( a / b ) . ratsimp ( ) <NEWLINE> if frc . is_rational : <NEWLINE> <TAB> return a / frc . as_numer_denom ( ) [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> except PolificationFailed as exc : <NEWLINE> <TAB> domain , ( a , b ) = construct_domain ( exc . exprs ) <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> return domain . to_sympy ( domain . gcd ( a , b ) ) <NEWLINE> <UNTAB> except NotImplementedError : <NEWLINE> <TAB> raise ComputationFailed ( <STRING> , <NUMBER> , exc ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> result = F . gcd ( G ) <NEWLINE> <NEWLINE> if not opt . polys : <NEWLINE> <TAB> return result . as_expr ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def delete ( arr , obj , axis = None ) : <NEWLINE> <TAB> <NEWLINE> wrap = None <NEWLINE> if type ( arr ) is not ndarray : <NEWLINE> <TAB> try : <NEWLINE> <TAB> wrap = arr . __array_wrap__ <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> arr = asarray ( arr ) <NEWLINE> ndim = arr . ndim <NEWLINE> arrorder = <STRING> if arr . flags . fnc else <STRING> <NEWLINE> if axis is None : <NEWLINE> <TAB> if ndim != <NUMBER> : <NEWLINE> <TAB> arr = arr . ravel ( ) <NEWLINE> <UNTAB> ndim = arr . ndim <NEWLINE> axis = - <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> if ndim == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> , DeprecationWarning , stacklevel = <NUMBER> ) <NEWLINE> if wrap : <NEWLINE> <TAB> return wrap ( arr ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return arr . copy ( order = arrorder ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> axis = normalize_axis_index ( axis , ndim ) <NEWLINE> <NEWLINE> slobj = [ slice ( None ) ] * ndim <NEWLINE> N = arr . shape [ axis ] <NEWLINE> newshape = list ( arr . shape ) <NEWLINE> <NEWLINE> if isinstance ( obj , slice ) : <NEWLINE> <TAB> start , stop , step = obj . indices ( N ) <NEWLINE> xr = range ( start , stop , step ) <NEWLINE> numtodel = len ( xr ) <NEWLINE> <NEWLINE> if numtodel <= <NUMBER> : <NEWLINE> <TAB> if wrap : <NEWLINE> <TAB> return wrap ( arr . copy ( order = arrorder ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return arr . copy ( order = arrorder ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if step < <NUMBER> : <NEWLINE> <TAB> step = - step <NEWLINE> start = xr [ - <NUMBER> ] <NEWLINE> stop = xr [ <NUMBER> ] + <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> newshape [ axis ] -= numtodel <NEWLINE> new = empty ( newshape , arr . dtype , arrorder ) <NEWLINE> <NEWLINE> if start == <NUMBER> : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> slobj [ axis ] = slice ( None , start ) <NEWLINE> new [ slobj ] = arr [ slobj ] <NEWLINE> <NEWLINE> <UNTAB> if stop == N : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> slobj [ axis ] = slice ( stop - numtodel , None ) <NEWLINE> slobj2 = [ slice ( None ) ] * ndim <NEWLINE> slobj2 [ axis ] = slice ( stop , None ) <NEWLINE> new [ slobj ] = arr [ slobj2 ] <NEWLINE> <NEWLINE> <UNTAB> if step == <NUMBER> : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> keep = ones ( stop - start , dtype = bool ) <NEWLINE> keep [ : stop - start : step ] = False <NEWLINE> slobj [ axis ] = slice ( start , stop - numtodel ) <NEWLINE> slobj2 = [ slice ( None ) ] * ndim <NEWLINE> slobj2 [ axis ] = slice ( start , stop ) <NEWLINE> arr = arr [ slobj2 ] <NEWLINE> slobj2 [ axis ] = keep <NEWLINE> new [ slobj ] = arr [ slobj2 ] <NEWLINE> <UNTAB> if wrap : <NEWLINE> <TAB> return wrap ( new ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return new <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> _obj = obj <NEWLINE> obj = np . asarray ( obj ) <NEWLINE> <NEWLINE> <NEWLINE> if obj . dtype == bool : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> , FutureWarning , stacklevel = <NUMBER> ) <NEWLINE> obj = obj . astype ( intp ) <NEWLINE> <UNTAB> if isinstance ( _obj , ( int , long , integer ) ) : <NEWLINE> <NEWLINE> <TAB> obj = obj . item ( ) <NEWLINE> if ( obj < - N or obj >= N ) : <NEWLINE> <TAB> raise IndexError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ( obj , axis , N ) ) <NEWLINE> <UNTAB> if ( obj < <NUMBER> ) : <NEWLINE> <TAB> obj += N <NEWLINE> <UNTAB> newshape [ axis ] -= <NUMBER> <NEWLINE> new = empty ( newshape , arr . dtype , arrorder ) <NEWLINE> slobj [ axis ] = slice ( None , obj ) <NEWLINE> new [ slobj ] = arr [ slobj ] <NEWLINE> slobj [ axis ] = slice ( obj , None ) <NEWLINE> slobj2 = [ slice ( None ) ] * ndim <NEWLINE> slobj2 [ axis ] = slice ( obj + <NUMBER> , None ) <NEWLINE> new [ slobj ] = arr [ slobj2 ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if obj . size == <NUMBER> and not isinstance ( _obj , np . ndarray ) : <NEWLINE> <TAB> obj = obj . astype ( intp ) <NEWLINE> <UNTAB> if not np . can_cast ( obj , intp , <STRING> ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> , DeprecationWarning , stacklevel = <NUMBER> ) <NEWLINE> obj = obj . astype ( intp ) <NEWLINE> <UNTAB> keep = ones ( N , dtype = bool ) <NEWLINE> <NEWLINE> <NEWLINE> inside_bounds = ( obj < N ) & ( obj >= - N ) <NEWLINE> if not inside_bounds . all ( ) : <NEWLINE> <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> , <NEWLINE> DeprecationWarning , stacklevel = <NUMBER> ) <NEWLINE> obj = obj [ inside_bounds ] <NEWLINE> <UNTAB> positive_indices = obj >= <NUMBER> <NEWLINE> if not positive_indices . all ( ) : <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> , FutureWarning , stacklevel = <NUMBER> ) <NEWLINE> obj = obj [ positive_indices ] <NEWLINE> <NEWLINE> <UNTAB> keep [ obj , ] = False <NEWLINE> slobj [ axis ] = keep <NEWLINE> new = arr [ slobj ] <NEWLINE> <NEWLINE> <UNTAB> if wrap : <NEWLINE> <TAB> return wrap ( new ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return new <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def pexquo ( f , g , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> options . allowed_flags ( args , [ <STRING> ] ) <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> ( F , G ) , opt = parallel_poly_from_expr ( ( f , g ) , * gens , ** args ) <NEWLINE> <UNTAB> except PolificationFailed as exc : <NEWLINE> <TAB> raise ComputationFailed ( <STRING> , <NUMBER> , exc ) <NEWLINE> <NEWLINE> <UNTAB> q = F . pexquo ( G ) <NEWLINE> <NEWLINE> if not opt . polys : <NEWLINE> <TAB> return q . as_expr ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return q <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def make_callable ( self , fetches , feed_list = None , accept_options = False ) : <NEWLINE> <TAB> <NEWLINE> if feed_list is not None : <NEWLINE> <TAB> if not isinstance ( feed_list , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> def _generic_run ( * feed_args , ** kwargs ) : <NEWLINE> <TAB> feed_dict = { <NEWLINE> feed : feed_val <NEWLINE> for feed , feed_val in zip ( feed_list , feed_args ) <NEWLINE> } <NEWLINE> return self . run ( fetches , feed_dict = feed_dict , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> return _generic_run <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . _extend_graph ( ) <NEWLINE> <NEWLINE> <NEWLINE> fetch_handler = _FetchHandler ( self . _graph , fetches , { } ) <NEWLINE> <NEWLINE> fetch_list = [ t . _as_tf_output ( ) for t in fetch_handler . fetches ( ) ] <NEWLINE> target_list = [ op . _c_op for op in fetch_handler . targets ( ) ] <NEWLINE> <NEWLINE> <NEWLINE> def _callable_template_with_options_and_metadata ( fetch_list , <NEWLINE> target_list , <NEWLINE> fetch_handler , <NEWLINE> options = None , <NEWLINE> run_metadata = None ) : <NEWLINE> <TAB> <NEWLINE> options_ptr = tf_session . TF_NewBufferFromString ( <NEWLINE> compat . as_bytes ( options . SerializeToString ( ) ) ) if options else None <NEWLINE> run_metadata_ptr = tf_session . TF_NewBuffer ( ) if run_metadata else None <NEWLINE> try : <NEWLINE> <TAB> results = self . _call_tf_sessionrun ( <NEWLINE> options_ptr , { } , fetch_list , target_list , run_metadata_ptr ) <NEWLINE> if fetch_handler : <NEWLINE> <TAB> results = fetch_handler . build_results ( self , results ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> results = results [ <NUMBER> ] if results else None <NEWLINE> <UNTAB> if run_metadata : <NEWLINE> <TAB> proto_data = tf_session . TF_GetBuffer ( run_metadata_ptr ) <NEWLINE> run_metadata . ParseFromString ( compat . as_bytes ( proto_data ) ) <NEWLINE> <UNTAB> <UNTAB> finally : <NEWLINE> <TAB> if run_metadata_ptr : <NEWLINE> <TAB> tf_session . TF_DeleteBuffer ( run_metadata_ptr ) <NEWLINE> <UNTAB> if options : <NEWLINE> <TAB> tf_session . TF_DeleteBuffer ( options_ptr ) <NEWLINE> <UNTAB> <UNTAB> return results <NEWLINE> <NEWLINE> <UNTAB> if accept_options : <NEWLINE> <TAB> return functools . partial ( _callable_template_with_options_and_metadata , <NEWLINE> fetch_list , target_list , fetch_handler ) <NEWLINE> <UNTAB> elif isinstance ( fetches , ops . Operation ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> assert not fetch_list <NEWLINE> assert len ( target_list ) == <NUMBER> <NEWLINE> <NEWLINE> def _single_operation_run ( ) : <NEWLINE> <TAB> self . _call_tf_sessionrun ( None , { } , [ ] , target_list , None ) <NEWLINE> <NEWLINE> <UNTAB> return _single_operation_run <NEWLINE> <UNTAB> elif isinstance ( fetches , ops . Tensor ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> assert len ( fetch_list ) == <NUMBER> <NEWLINE> assert not target_list <NEWLINE> <NEWLINE> def _single_tensor_run ( ) : <NEWLINE> <TAB> results = self . _call_tf_sessionrun ( None , { } , fetch_list , [ ] , None ) <NEWLINE> return results [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> return _single_tensor_run <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> def _fetch_handler_run ( ) : <NEWLINE> <TAB> results = self . _call_tf_sessionrun ( <NEWLINE> None , { } , fetch_list , target_list , None ) <NEWLINE> return fetch_handler . build_results ( self , results ) <NEWLINE> <NEWLINE> <UNTAB> return _fetch_handler_run <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _polyder ( p , m ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if m == <NUMBER> : <NEWLINE> <TAB> result = p <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> n = len ( p ) <NEWLINE> if n <= m : <NEWLINE> <TAB> result = np . zeros_like ( p [ : <NUMBER> , ... ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dp = p [ : - m ] . copy ( ) <NEWLINE> for k in range ( m ) : <NEWLINE> <TAB> rng = np . arange ( n - k - <NUMBER> , m - k - <NUMBER> , - <NUMBER> ) <NEWLINE> dp *= rng . reshape ( ( n - m , ) + ( <NUMBER> , ) * ( p . ndim - <NUMBER> ) ) <NEWLINE> <UNTAB> result = dp <NEWLINE> <UNTAB> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _yeo_johnson_optimize ( self , x ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def _neg_log_likelihood ( lmbda ) : <NEWLINE> <TAB> <NEWLINE> x_trans = self . _yeo_johnson_transform ( x , lmbda ) <NEWLINE> n_samples = x . shape [ <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> est_mean = x_trans . sum ( ) / n_samples <NEWLINE> est_var = np . power ( x_trans - est_mean , <NUMBER> ) . sum ( ) / n_samples <NEWLINE> <NEWLINE> loglike = - n_samples / <NUMBER> * np . log ( est_var ) <NEWLINE> loglike += ( lmbda - <NUMBER> ) * ( np . sign ( x ) * np . log ( np . abs ( x ) + <NUMBER> ) ) . sum ( ) <NEWLINE> <NEWLINE> return - loglike <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> x = x [ ~ np . isnan ( x ) ] <NEWLINE> <NEWLINE> return optimize . brent ( _neg_log_likelihood , brack = ( - <NUMBER> , <NUMBER> ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def cheb1ap ( N , rp ) : <NEWLINE> <TAB> <NEWLINE> if abs ( int ( N ) ) != N : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> elif N == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return numpy . array ( [ ] ) , numpy . array ( [ ] ) , <NUMBER> ** ( - rp / <NUMBER> ) <NEWLINE> <UNTAB> z = numpy . array ( [ ] ) <NEWLINE> <NEWLINE> <NEWLINE> eps = numpy . sqrt ( <NUMBER> ** ( <NUMBER> * rp ) - <NUMBER> ) <NEWLINE> mu = <NUMBER> / N * arcsinh ( <NUMBER> / eps ) <NEWLINE> <NEWLINE> <NEWLINE> m = numpy . arange ( - N + <NUMBER> , N , <NUMBER> ) <NEWLINE> theta = pi * m / ( <NUMBER> * N ) <NEWLINE> p = - sinh ( mu + <NUMBER> * theta ) <NEWLINE> <NEWLINE> k = numpy . prod ( - p , axis = <NUMBER> ) . real <NEWLINE> if N % <NUMBER> == <NUMBER> : <NEWLINE> <TAB> k = k / sqrt ( ( <NUMBER> + eps * eps ) ) <NEWLINE> <NEWLINE> <UNTAB> return z , p , k <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __gt__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return greater ( self , other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def eigh ( a , UPLO = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> UPLO = UPLO . upper ( ) <NEWLINE> if UPLO not in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> a , wrap = _makearray ( a ) <NEWLINE> _assertRankAtLeast2 ( a ) <NEWLINE> _assertNdSquareness ( a ) <NEWLINE> t , result_t = _commonType ( a ) <NEWLINE> <NEWLINE> extobj = get_linalg_error_extobj ( <NEWLINE> _raise_linalgerror_eigenvalues_nonconvergence ) <NEWLINE> if UPLO == <STRING> : <NEWLINE> <TAB> gufunc = _umath_linalg . eigh_lo <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> gufunc = _umath_linalg . eigh_up <NEWLINE> <NEWLINE> <UNTAB> signature = <STRING> if isComplexType ( t ) else <STRING> <NEWLINE> w , vt = gufunc ( a , signature = signature , extobj = extobj ) <NEWLINE> w = w . astype ( _realType ( result_t ) , copy = False ) <NEWLINE> vt = vt . astype ( result_t , copy = False ) <NEWLINE> return w , wrap ( vt ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def prem ( f , g ) : <NEWLINE> <TAB> <NEWLINE> _ , per , F , G = f . _unify ( g ) <NEWLINE> <NEWLINE> if hasattr ( f . rep , <STRING> ) : <NEWLINE> <TAB> result = F . prem ( G ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise OperationNotSupported ( f , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return per ( result ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def array2d ( surface ) : <NEWLINE> <TAB> <NEWLINE> return numpysf . array2d ( surface ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_executables ( self , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for key in kwargs : <NEWLINE> <TAB> if key not in self . executables : <NEWLINE> <TAB> raise ValueError ( <STRING> % <NEWLINE> ( key , self . __class__ . __name__ ) ) <NEWLINE> <UNTAB> self . set_executable ( key , kwargs [ key ] ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _evaluate_compare ( self , other , op ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if not isinstance ( other , type ( self ) ) : <NEWLINE> <TAB> if not is_list_like ( other ) : <NEWLINE> <NEWLINE> <TAB> other = [ other ] <NEWLINE> <UNTAB> elif is_scalar ( lib . item_from_zerodim ( other ) ) : <NEWLINE> <NEWLINE> <TAB> other = [ other . item ( ) ] <NEWLINE> <UNTAB> other = type ( self ) ( other ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> result = op ( self . asi8 , other . asi8 ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> mask = ( self . _isnan ) | ( other . _isnan ) <NEWLINE> if is_bool_dtype ( result ) : <NEWLINE> <TAB> result [ mask ] = False <NEWLINE> return result <NEWLINE> <NEWLINE> <UNTAB> result [ mask ] = iNaT <NEWLINE> try : <NEWLINE> <TAB> return Index ( result ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> return result <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def elu ( x , alpha = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return ELU ( alpha = alpha ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rocket ( ) : <NEWLINE> <TAB> <NEWLINE> return load ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_string_dtype ( arr_or_dtype ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if arr_or_dtype is None : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> dtype = _get_dtype ( arr_or_dtype ) <NEWLINE> return dtype . kind in ( <STRING> , <STRING> , <STRING> ) and not is_period_dtype ( dtype ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def make_session_run_hook ( self , is_chief , num_tokens = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return _SyncReplicasOptimizerHook ( self , is_chief , num_tokens ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_rng_state ( device = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> _lazy_init ( ) <NEWLINE> with device_ctx_manager ( device ) : <NEWLINE> <TAB> return _C . _cuda_getRNGState ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def canon ( * rules , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return exhaust ( top_down ( exhaust ( do_one ( * rules ) ) , ** kwargs ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def null ( ) : <NEWLINE> <TAB> <NEWLINE> return Bbox ( np . array ( [ [ np . inf , np . inf ] , [ - np . inf , - np . inf ] ] , float ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def get_active ( cls ) : <NEWLINE> <TAB> <NEWLINE> if len ( cls . _activeQue ) == <NUMBER> : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return cls . _activeQue [ - <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _is_function ( self , name ) : <NEWLINE> <TAB> <NEWLINE> return compat . as_str ( name ) in self . _functions <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def back ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _pos > <NUMBER> : <NEWLINE> <TAB> self . _pos -= <NUMBER> <NEWLINE> <UNTAB> return self ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def connect ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return self . _branch ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def applyfunc ( self , f ) : <NEWLINE> <TAB> <NEWLINE> return type ( self ) ( map ( f , self ) , self . shape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def from_int ( n , prec = <NUMBER> , rnd = round_fast ) : <NEWLINE> <TAB> <NEWLINE> if not prec : <NEWLINE> <TAB> if n in int_cache : <NEWLINE> <TAB> return int_cache [ n ] <NEWLINE> <UNTAB> <UNTAB> return from_man_exp ( n , <NUMBER> , prec , rnd ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def set_fill_value ( a , fill_value ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( a , MaskedArray ) : <NEWLINE> <TAB> a . set_fill_value ( fill_value ) <NEWLINE> <UNTAB> return <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def mode ( self , df , scale ) : <NEWLINE> <TAB> <NEWLINE> dim , df , scale = self . _process_parameters ( df , scale ) <NEWLINE> out = self . _mode ( dim , df , scale ) <NEWLINE> return _squeeze_output ( out ) if out is not None else out <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit_loc_scale ( self , data , * args ) : <NEWLINE> <TAB> <NEWLINE> mu , mu2 = self . stats ( * args , ** { <STRING> : <STRING> } ) <NEWLINE> tmp = asarray ( data ) <NEWLINE> muhat = tmp . mean ( ) <NEWLINE> mu2hat = tmp . var ( ) <NEWLINE> Shat = sqrt ( mu2hat / mu2 ) <NEWLINE> Lhat = muhat - Shat * mu <NEWLINE> if not np . isfinite ( Lhat ) : <NEWLINE> <TAB> Lhat = <NUMBER> <NEWLINE> <UNTAB> if not ( np . isfinite ( Shat ) and ( <NUMBER> < Shat ) ) : <NEWLINE> <TAB> Shat = <NUMBER> <NEWLINE> <UNTAB> return Lhat , Shat <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def placeholder_with_default ( input , shape , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> shape = _execute . make_shape ( shape , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , shape = shape , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , input , <NEWLINE> <STRING> , shape ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return placeholder_with_default_eager_fallback ( <NEWLINE> input , shape = shape , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pointbiserialr ( x , y ) : <NEWLINE> <TAB> <NEWLINE> x = ma . fix_invalid ( x , copy = True ) . astype ( bool ) <NEWLINE> y = ma . fix_invalid ( y , copy = True ) . astype ( float ) <NEWLINE> <NEWLINE> m = ma . mask_or ( ma . getmask ( x ) , ma . getmask ( y ) ) <NEWLINE> if m is not nomask : <NEWLINE> <TAB> unmask = np . logical_not ( m ) <NEWLINE> x = x [ unmask ] <NEWLINE> y = y [ unmask ] <NEWLINE> <NEWLINE> <UNTAB> n = len ( x ) <NEWLINE> <NEWLINE> phat = x . sum ( ) / float ( n ) <NEWLINE> y0 = y [ ~ x ] <NEWLINE> y1 = y [ x ] <NEWLINE> y0m = y0 . mean ( ) <NEWLINE> y1m = y1 . mean ( ) <NEWLINE> <NEWLINE> rpb = ( y1m - y0m ) * np . sqrt ( phat * ( <NUMBER> - phat ) ) / y . std ( ) <NEWLINE> <NEWLINE> df = n - <NUMBER> <NEWLINE> t = rpb * ma . sqrt ( df / ( <NUMBER> - rpb ** <NUMBER> ) ) <NEWLINE> prob = _betai ( <NUMBER> * df , <NUMBER> , df / ( df + t * t ) ) <NEWLINE> <NEWLINE> return PointbiserialrResult ( rpb , prob ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_pk_constraint ( self , connection , table_name , schema = None , ** kw ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_profiles ( self , cmd ) : <NEWLINE> <TAB> <NEWLINE> if cmd not in self . _views : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( cmd ) ) <NEWLINE> <UNTAB> return self . _views [ cmd ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _parser_dispatch ( flavor ) : <NEWLINE> <TAB> <NEWLINE> valid_parsers = list ( _valid_parsers . keys ( ) ) <NEWLINE> if flavor not in valid_parsers : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> . format ( invalid = flavor , valid = valid_parsers ) ) <NEWLINE> <NEWLINE> <UNTAB> if flavor in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> if not _HAS_HTML5LIB : <NEWLINE> <TAB> raise ImportError ( <STRING> ) <NEWLINE> <UNTAB> if not _HAS_BS4 : <NEWLINE> <TAB> raise ImportError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> import bs4 <NEWLINE> if LooseVersion ( bs4 . __version__ ) <= LooseVersion ( <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if not _HAS_LXML : <NEWLINE> <TAB> raise ImportError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> return _valid_parsers [ flavor ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def alpha_dropout ( x , keep_prob , noise_shape = None , seed = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ x ] ) as name : <NEWLINE> <TAB> x = ops . convert_to_tensor ( x , name = <STRING> ) <NEWLINE> if isinstance ( keep_prob , numbers . Real ) and not <NUMBER> < keep_prob <= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % keep_prob ) <NEWLINE> <UNTAB> keep_prob = ops . convert_to_tensor ( keep_prob , <NEWLINE> dtype = x . dtype , <NEWLINE> name = <STRING> ) <NEWLINE> keep_prob . get_shape ( ) . assert_is_compatible_with ( tensor_shape . scalar ( ) ) <NEWLINE> <NEWLINE> <NEWLINE> if tensor_util . constant_value ( keep_prob ) == <NUMBER> : <NEWLINE> <TAB> return x <NEWLINE> <NEWLINE> <UNTAB> alpha = - <NUMBER> <NEWLINE> <NEWLINE> noise_shape = noise_shape if noise_shape is not None else array_ops . shape ( x ) <NEWLINE> random_tensor = random_ops . random_uniform ( noise_shape , <NEWLINE> seed = seed , <NEWLINE> dtype = x . dtype ) <NEWLINE> kept_idx = gen_math_ops . greater_equal ( random_tensor , <NUMBER> - keep_prob ) <NEWLINE> kept_idx = math_ops . cast ( kept_idx , x . dtype ) <NEWLINE> <NEWLINE> x = x * kept_idx + alpha * ( <NUMBER> - kept_idx ) <NEWLINE> <NEWLINE> <NEWLINE> a = ( keep_prob + keep_prob * ( <NUMBER> - keep_prob ) * alpha ** <NUMBER> ) ** - <NUMBER> <NEWLINE> b = - a * alpha * ( <NUMBER> - keep_prob ) <NEWLINE> <NEWLINE> <NEWLINE> return a * x + b <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def chebyu ( n , monic = False ) : <NEWLINE> <TAB> <NEWLINE> base = jacobi ( n , <NUMBER> , <NUMBER> , monic = monic ) <NEWLINE> if monic : <NEWLINE> <TAB> return base <NEWLINE> <UNTAB> factor = sqrt ( pi ) / <NUMBER> * _gam ( n + <NUMBER> ) / _gam ( n + <NUMBER> ) <NEWLINE> base . _scale ( factor ) <NEWLINE> return base <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def col_del ( self , col ) : <NEWLINE> <TAB> <NEWLINE> if col < <NUMBER> : <NEWLINE> <TAB> col += self . cols <NEWLINE> <UNTAB> if not <NUMBER> <= col < self . cols : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( col ) ) <NEWLINE> <UNTAB> return self . _eval_col_del ( col ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def detach ( self , dbapi_connection , connection_record ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_active ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _active <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def argmax ( a , axis = None , out = None ) : <NEWLINE> <TAB> <NEWLINE> return _wrapfunc ( a , <STRING> , axis = axis , out = out ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def polyint ( p , m = <NUMBER> , k = None ) : <NEWLINE> <TAB> <NEWLINE> m = int ( m ) <NEWLINE> if m < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if k is None : <NEWLINE> <TAB> k = NX . zeros ( m , float ) <NEWLINE> <UNTAB> k = atleast_1d ( k ) <NEWLINE> if len ( k ) == <NUMBER> and m > <NUMBER> : <NEWLINE> <TAB> k = k [ <NUMBER> ] * NX . ones ( m , float ) <NEWLINE> <UNTAB> if len ( k ) < m : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> truepoly = isinstance ( p , poly1d ) <NEWLINE> p = NX . asarray ( p ) <NEWLINE> if m == <NUMBER> : <NEWLINE> <TAB> if truepoly : <NEWLINE> <TAB> return poly1d ( p ) <NEWLINE> <UNTAB> return p <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> y = NX . concatenate ( ( p . __truediv__ ( NX . arange ( len ( p ) , <NUMBER> , - <NUMBER> ) ) , [ k [ <NUMBER> ] ] ) ) <NEWLINE> val = polyint ( y , m - <NUMBER> , k = k [ <NUMBER> : ] ) <NEWLINE> if truepoly : <NEWLINE> <TAB> return poly1d ( val ) <NEWLINE> <UNTAB> return val <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def convert ( image , dtype , force_copy = False , uniform = False ) : <NEWLINE> <TAB> <NEWLINE> image = np . asarray ( image ) <NEWLINE> dtypeobj_in = image . dtype <NEWLINE> dtypeobj_out = np . dtype ( dtype ) <NEWLINE> dtype_in = dtypeobj_in . type <NEWLINE> dtype_out = dtypeobj_out . type <NEWLINE> kind_in = dtypeobj_in . kind <NEWLINE> kind_out = dtypeobj_out . kind <NEWLINE> itemsize_in = dtypeobj_in . itemsize <NEWLINE> itemsize_out = dtypeobj_out . itemsize <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> type_out = dtype if isinstance ( dtype , type ) else dtypeobj_out <NEWLINE> <NEWLINE> if np . issubdtype ( dtypeobj_in , type_out ) : <NEWLINE> <TAB> if force_copy : <NEWLINE> <TAB> image = image . copy ( ) <NEWLINE> <UNTAB> return image <NEWLINE> <NEWLINE> <UNTAB> if not ( dtype_in in _supported_types and dtype_out in _supported_types ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> . format ( dtypeobj_in , dtypeobj_out ) ) <NEWLINE> <NEWLINE> <UNTAB> def sign_loss ( ) : <NEWLINE> <TAB> warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> . format ( dtypeobj_in , dtypeobj_out ) ) <NEWLINE> <NEWLINE> <UNTAB> def prec_loss ( ) : <NEWLINE> <TAB> warn ( <STRING> <NEWLINE> . format ( dtypeobj_in , dtypeobj_out ) ) <NEWLINE> <NEWLINE> <UNTAB> def _dtype_itemsize ( itemsize , * dtypes ) : <NEWLINE> <NEWLINE> <TAB> return next ( dt for dt in dtypes if np . dtype ( dt ) . itemsize >= itemsize ) <NEWLINE> <NEWLINE> <UNTAB> def _dtype_bits ( kind , bits , itemsize = <NUMBER> ) : <NEWLINE> <NEWLINE> <TAB> def compare ( x , y , kind = <STRING> ) : <NEWLINE> <TAB> if kind == <STRING> : <NEWLINE> <TAB> return x <= y <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return x < y <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> s = next ( i for i in ( itemsize , ) + ( <NUMBER> , <NUMBER> , <NUMBER> ) if compare ( bits , i * <NUMBER> , <NEWLINE> kind = kind ) ) <NEWLINE> return np . dtype ( kind + str ( s ) ) <NEWLINE> <NEWLINE> <UNTAB> def _scale ( a , n , m , copy = True ) : <NEWLINE> <TAB> <NEWLINE> kind = a . dtype . kind <NEWLINE> if n > m and a . max ( ) < <NUMBER> ** m : <NEWLINE> <TAB> mnew = int ( np . ceil ( m / <NUMBER> ) * <NUMBER> ) <NEWLINE> if mnew > m : <NEWLINE> <TAB> dtype = <STRING> . format ( mnew ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dtype = <STRING> . format ( mnew ) <NEWLINE> <UNTAB> n = int ( np . ceil ( n / <NUMBER> ) * <NUMBER> ) <NEWLINE> warn ( <STRING> <NEWLINE> <STRING> . format ( a . dtype , dtype , a . max ( ) , dtype ) ) <NEWLINE> return a . astype ( _dtype_bits ( kind , m ) ) <NEWLINE> <UNTAB> elif n == m : <NEWLINE> <TAB> return a . copy ( ) if copy else a <NEWLINE> <UNTAB> elif n > m : <NEWLINE> <NEWLINE> <TAB> prec_loss ( ) <NEWLINE> if copy : <NEWLINE> <TAB> b = np . empty ( a . shape , _dtype_bits ( kind , m ) ) <NEWLINE> np . floor_divide ( a , <NUMBER> ** ( n - m ) , out = b , dtype = a . dtype , <NEWLINE> casting = <STRING> ) <NEWLINE> return b <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> a //= <NUMBER> ** ( n - m ) <NEWLINE> return a <NEWLINE> <UNTAB> <UNTAB> elif m % n == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> if copy : <NEWLINE> <TAB> b = np . empty ( a . shape , _dtype_bits ( kind , m ) ) <NEWLINE> np . multiply ( a , ( <NUMBER> ** m - <NUMBER> ) // ( <NUMBER> ** n - <NUMBER> ) , out = b , dtype = b . dtype ) <NEWLINE> return b <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> a = a . astype ( _dtype_bits ( kind , m , a . dtype . itemsize ) , copy = False ) <NEWLINE> a *= ( <NUMBER> ** m - <NUMBER> ) // ( <NUMBER> ** n - <NUMBER> ) <NEWLINE> return a <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> prec_loss ( ) <NEWLINE> o = ( m // n + <NUMBER> ) * n <NEWLINE> if copy : <NEWLINE> <TAB> b = np . empty ( a . shape , _dtype_bits ( kind , o ) ) <NEWLINE> np . multiply ( a , ( <NUMBER> ** o - <NUMBER> ) // ( <NUMBER> ** n - <NUMBER> ) , out = b , dtype = b . dtype ) <NEWLINE> b //= <NUMBER> ** ( o - m ) <NEWLINE> return b <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> a = a . astype ( _dtype_bits ( kind , o , a . dtype . itemsize ) , copy = False ) <NEWLINE> a *= ( <NUMBER> ** o - <NUMBER> ) // ( <NUMBER> ** n - <NUMBER> ) <NEWLINE> a //= <NUMBER> ** ( o - m ) <NEWLINE> return a <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if kind_in in <STRING> : <NEWLINE> <TAB> imin_in = np . iinfo ( dtype_in ) . min <NEWLINE> imax_in = np . iinfo ( dtype_in ) . max <NEWLINE> <UNTAB> if kind_out in <STRING> : <NEWLINE> <TAB> imin_out = np . iinfo ( dtype_out ) . min <NEWLINE> imax_out = np . iinfo ( dtype_out ) . max <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if kind_out == <STRING> : <NEWLINE> <TAB> if kind_in in <STRING> : <NEWLINE> <TAB> sign_loss ( ) <NEWLINE> <UNTAB> prec_loss ( ) <NEWLINE> return image > dtype_in ( dtype_range [ dtype_in ] [ <NUMBER> ] / <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if kind_in == <STRING> : <NEWLINE> <TAB> result = image . astype ( dtype_out ) <NEWLINE> if kind_out != <STRING> : <NEWLINE> <TAB> result *= dtype_out ( dtype_range [ dtype_out ] [ <NUMBER> ] ) <NEWLINE> <UNTAB> return result <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if kind_in == <STRING> : <NEWLINE> <TAB> if kind_out == <STRING> : <NEWLINE> <NEWLINE> <TAB> if itemsize_in > itemsize_out : <NEWLINE> <TAB> prec_loss ( ) <NEWLINE> <UNTAB> return image . astype ( dtype_out ) <NEWLINE> <NEWLINE> <UNTAB> if np . min ( image ) < - <NUMBER> or np . max ( image ) > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> prec_loss ( ) <NEWLINE> <NEWLINE> computation_type = _dtype_itemsize ( itemsize_out , dtype_in , <NEWLINE> np . float32 , np . float64 ) <NEWLINE> <NEWLINE> if not uniform : <NEWLINE> <TAB> if kind_out == <STRING> : <NEWLINE> <TAB> image_out = np . multiply ( image , imax_out , <NEWLINE> dtype = computation_type ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> image_out = np . multiply ( image , ( imax_out - imin_out ) / <NUMBER> , <NEWLINE> dtype = computation_type ) <NEWLINE> image_out -= <NUMBER> / <NUMBER> <NEWLINE> <UNTAB> np . rint ( image_out , out = image_out ) <NEWLINE> np . clip ( image_out , imin_out , imax_out , out = image_out ) <NEWLINE> <UNTAB> elif kind_out == <STRING> : <NEWLINE> <TAB> image_out = np . multiply ( image , imax_out + <NUMBER> , <NEWLINE> dtype = computation_type ) <NEWLINE> np . clip ( image_out , <NUMBER> , imax_out , out = image_out ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> image_out = np . multiply ( image , ( imax_out - imin_out + <NUMBER> ) / <NUMBER> , <NEWLINE> dtype = computation_type ) <NEWLINE> np . floor ( image_out , out = image_out ) <NEWLINE> np . clip ( image_out , imin_out , imax_out , out = image_out ) <NEWLINE> <UNTAB> return image_out . astype ( dtype_out ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if kind_out == <STRING> : <NEWLINE> <TAB> if itemsize_in >= itemsize_out : <NEWLINE> <TAB> prec_loss ( ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> computation_type = _dtype_itemsize ( itemsize_in , dtype_out , <NEWLINE> np . float32 , np . float64 ) <NEWLINE> <NEWLINE> if kind_in == <STRING> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> image = np . multiply ( image , <NUMBER> / imax_in , <NEWLINE> dtype = computation_type ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> image = np . add ( image , <NUMBER> , dtype = computation_type ) <NEWLINE> image *= <NUMBER> / ( imax_in - imin_in ) <NEWLINE> <NEWLINE> <UNTAB> return np . asarray ( image , dtype_out ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if kind_in == <STRING> : <NEWLINE> <TAB> if kind_out == <STRING> : <NEWLINE> <NEWLINE> <TAB> image = _scale ( image , <NUMBER> * itemsize_in , <NUMBER> * itemsize_out - <NUMBER> ) <NEWLINE> return image . view ( dtype_out ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> return _scale ( image , <NUMBER> * itemsize_in , <NUMBER> * itemsize_out ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if kind_out == <STRING> : <NEWLINE> <TAB> sign_loss ( ) <NEWLINE> image = _scale ( image , <NUMBER> * itemsize_in - <NUMBER> , <NUMBER> * itemsize_out ) <NEWLINE> result = np . empty ( image . shape , dtype_out ) <NEWLINE> np . maximum ( image , <NUMBER> , out = result , dtype = image . dtype , casting = <STRING> ) <NEWLINE> return result <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if itemsize_in > itemsize_out : <NEWLINE> <TAB> return _scale ( image , <NUMBER> * itemsize_in - <NUMBER> , <NUMBER> * itemsize_out - <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> image = image . astype ( _dtype_bits ( <STRING> , itemsize_out * <NUMBER> ) ) <NEWLINE> image -= imin_in <NEWLINE> image = _scale ( image , <NUMBER> * itemsize_in , <NUMBER> * itemsize_out , copy = False ) <NEWLINE> image += imin_out <NEWLINE> return image . astype ( dtype_out ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def train_on_batch ( self , x , y = None , sample_weight = None , class_weight = None ) : <NEWLINE> <TAB> <NEWLINE> if self . _distribution_strategy : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> x , y , sample_weights = self . _standardize_user_data ( <NEWLINE> x , y , sample_weight = sample_weight , class_weight = class_weight ) <NEWLINE> <NEWLINE> if context . executing_eagerly ( ) : <NEWLINE> <TAB> outputs = training_eager . train_on_batch ( <NEWLINE> self , x , y , sample_weights = sample_weights ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if self . uses_learning_phase and not isinstance ( K . learning_phase ( ) , int ) : <NEWLINE> <TAB> ins = x + y + sample_weights + [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ins = x + y + sample_weights <NEWLINE> <NEWLINE> <UNTAB> self . _make_train_function ( ) <NEWLINE> outputs = self . train_function ( ins ) <NEWLINE> <NEWLINE> <UNTAB> if len ( outputs ) == <NUMBER> : <NEWLINE> <TAB> return outputs [ <NUMBER> ] <NEWLINE> <UNTAB> return outputs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def on_batch_end ( self , batch , logs = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> logs = logs or { } <NEWLINE> self . _samples_seen += logs . get ( <STRING> , <NUMBER> ) <NEWLINE> samples_seen_since = self . _samples_seen - self . _samples_seen_at_last_write <NEWLINE> if self . update_freq != <STRING> and samples_seen_since >= self . update_freq : <NEWLINE> <TAB> batch_logs = { ( <STRING> + k ) : v <NEWLINE> for k , v in logs . items ( ) <NEWLINE> if k not in [ <STRING> , <STRING> , <STRING> ] } <NEWLINE> self . _write_custom_summaries ( self . _total_batches_seen , batch_logs ) <NEWLINE> self . _samples_seen_at_last_write = self . _samples_seen <NEWLINE> <UNTAB> self . _total_batches_seen += <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ Substitution ( name = <STRING> ) <NEWLINE> @ Appender ( _doc_template ) <NEWLINE> @ Appender ( _pairwise_template ) <NEWLINE> def corr ( self , other = None , pairwise = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if other is None : <NEWLINE> <TAB> other = self . _selected_obj <NEWLINE> <NEWLINE> pairwise = True if pairwise is None else pairwise <NEWLINE> <UNTAB> other = self . _shallow_copy ( other ) <NEWLINE> <NEWLINE> def _get_corr ( X , Y ) : <NEWLINE> <TAB> X = self . _shallow_copy ( X ) <NEWLINE> Y = self . _shallow_copy ( Y ) <NEWLINE> <NEWLINE> def _cov ( x , y ) : <NEWLINE> <TAB> return _window . ewmcov ( x , y , self . com , int ( self . adjust ) , <NEWLINE> int ( self . ignore_na ) , <NEWLINE> int ( self . min_periods ) , <NEWLINE> <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> x_values = X . _prep_values ( ) <NEWLINE> y_values = Y . _prep_values ( ) <NEWLINE> with np . errstate ( all = <STRING> ) : <NEWLINE> <TAB> cov = _cov ( x_values , y_values ) <NEWLINE> x_var = _cov ( x_values , x_values ) <NEWLINE> y_var = _cov ( y_values , y_values ) <NEWLINE> corr = cov / _zsqrt ( x_var * y_var ) <NEWLINE> <UNTAB> return X . _wrap_result ( corr ) <NEWLINE> <NEWLINE> <UNTAB> return _flex_binary_moment ( self . _selected_obj , other . _selected_obj , <NEWLINE> _get_corr , pairwise = bool ( pairwise ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def deserialize ( config , custom_objects = None ) : <NEWLINE> <TAB> <NEWLINE> from . . import models <NEWLINE> globs = globals ( ) <NEWLINE> globs [ <STRING> ] = models . Model <NEWLINE> globs [ <STRING> ] = models . Sequential <NEWLINE> return deserialize_keras_object ( config , <NEWLINE> module_objects = globs , <NEWLINE> custom_objects = custom_objects , <NEWLINE> printable_module_name = <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _eval_berkowitz_toeplitz_matrix ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if self . rows == <NUMBER> and self . cols == <NUMBER> : <NEWLINE> <TAB> return self . _new ( <NUMBER> , <NUMBER> , [ S . One ] ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> a , R = self [ <NUMBER> , <NUMBER> ] , self [ <NUMBER> , <NUMBER> : ] <NEWLINE> C , A = self [ <NUMBER> : , <NUMBER> ] , self [ <NUMBER> : , <NUMBER> : ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> diags = [ C ] <NEWLINE> for i in range ( self . rows - <NUMBER> ) : <NEWLINE> <TAB> diags . append ( A * diags [ i ] ) <NEWLINE> <UNTAB> diags = [ ( - R * d ) [ <NUMBER> , <NUMBER> ] for d in diags ] <NEWLINE> diags = [ S . One , - a ] + diags <NEWLINE> <NEWLINE> def entry ( i , j ) : <NEWLINE> <TAB> if j > i : <NEWLINE> <TAB> return S . Zero <NEWLINE> <UNTAB> return diags [ i - j ] <NEWLINE> <NEWLINE> <UNTAB> toeplitz = self . _new ( self . cols + <NUMBER> , self . rows , entry ) <NEWLINE> return ( A , toeplitz ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def term_div ( a , b , domain ) : <NEWLINE> <TAB> <NEWLINE> a_lm , a_lc = a <NEWLINE> b_lm , b_lc = b <NEWLINE> <NEWLINE> monom = monomial_div ( a_lm , b_lm ) <NEWLINE> <NEWLINE> if domain . is_Field : <NEWLINE> <TAB> if monom is not None : <NEWLINE> <TAB> return monom , domain . quo ( a_lc , b_lc ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if not ( monom is None or a_lc % b_lc ) : <NEWLINE> <TAB> return monom , domain . quo ( a_lc , b_lc ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def remove_option ( self , section , option ) : <NEWLINE> <TAB> <NEWLINE> if not section or section == self . default_section : <NEWLINE> <TAB> sectdict = self . _defaults <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> sectdict = self . _sections [ section ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> raise NoSectionError ( section ) from None <NEWLINE> <UNTAB> <UNTAB> option = self . optionxform ( option ) <NEWLINE> existed = option in sectdict <NEWLINE> if existed : <NEWLINE> <TAB> del sectdict [ option ] <NEWLINE> <UNTAB> return existed <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def kei_zeros ( nt ) : <NEWLINE> <TAB> <NEWLINE> if not isscalar ( nt ) or ( floor ( nt ) != nt ) or ( nt <= <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return specfun . klvnzo ( nt , <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def integrate ( self , x = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> from sympy . integrals import integrate <NEWLINE> <NEWLINE> if x is None : <NEWLINE> <TAB> x = self . x <NEWLINE> <UNTAB> elif iterable ( x ) : <NEWLINE> <TAB> return integrate ( self . function , x ) <NEWLINE> <NEWLINE> <UNTAB> f = integrate ( self . function , x ) <NEWLINE> ind = integrate ( self . ind , x ) <NEWLINE> ind += ( f - ind ) . limit ( x , <NUMBER> ) <NEWLINE> <NEWLINE> pow_xk = self . _get_pow_x ( self . xk . formula ) <NEWLINE> ak = self . ak <NEWLINE> k = ak . variables [ <NUMBER> ] <NEWLINE> if ak . formula . has ( x ) : <NEWLINE> <TAB> form = [ ] <NEWLINE> for e , c in ak . formula . args : <NEWLINE> <TAB> temp = S . Zero <NEWLINE> for t in Add . make_args ( e ) : <NEWLINE> <TAB> pow_x = self . _get_pow_x ( t ) <NEWLINE> temp += t / ( pow_xk + pow_x + <NUMBER> ) <NEWLINE> <UNTAB> form . append ( ( temp , c ) ) <NEWLINE> <UNTAB> form = Piecewise ( * form ) <NEWLINE> ak = sequence ( form . subs ( k , k - <NUMBER> ) , ( k , ak . start + <NUMBER> , ak . stop ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ak = sequence ( ( ak . formula / ( pow_xk + <NUMBER> ) ) . subs ( k , k - <NUMBER> ) , <NEWLINE> ( k , ak . start + <NUMBER> , ak . stop ) ) <NEWLINE> <NEWLINE> <UNTAB> return self . func ( f , self . x , self . x0 , self . dir , ( ak , self . xk , ind ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def jordan_cell ( eigenval , n ) : <NEWLINE> <TAB> <NEWLINE> from . dense import Matrix <NEWLINE> <NEWLINE> return Matrix . jordan_block ( size = n , eigenvalue = eigenval ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _convert_params ( sql , params ) : <NEWLINE> <TAB> <NEWLINE> args = [ sql ] <NEWLINE> if params is not None : <NEWLINE> <TAB> if hasattr ( params , <STRING> ) : <NEWLINE> <TAB> args += [ params ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> args += [ list ( params ) ] <NEWLINE> <UNTAB> <UNTAB> return args <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def spatial_pyramid_pooling_2d ( x , pyramid_height , pooling = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> bottom_c , bottom_h , bottom_w = x . shape [ <NUMBER> : ] <NEWLINE> ys = [ ] <NEWLINE> <NEWLINE> <NEWLINE> for pyramid_level in six . moves . range ( pyramid_height ) : <NEWLINE> <TAB> num_bins = int ( <NUMBER> ** pyramid_level ) <NEWLINE> <NEWLINE> ksize_h = int ( math . ceil ( bottom_h / ( float ( num_bins ) ) ) ) <NEWLINE> remainder_h = ksize_h * num_bins - bottom_h <NEWLINE> pad_h = remainder_h // <NUMBER> <NEWLINE> <NEWLINE> ksize_w = int ( math . ceil ( bottom_w / ( float ( num_bins ) ) ) ) <NEWLINE> remainder_w = ksize_w * num_bins - bottom_w <NEWLINE> pad_w = remainder_w // <NUMBER> <NEWLINE> <NEWLINE> ksize = ( ksize_h , ksize_w ) <NEWLINE> pad = ( pad_h , pad_w ) <NEWLINE> <NEWLINE> if pooling != <STRING> : <NEWLINE> <TAB> raise ValueError ( <STRING> , pooling ) <NEWLINE> <NEWLINE> <UNTAB> y_var = chainer . functions . max_pooling_2d ( <NEWLINE> x , ksize = ksize , stride = None , pad = pad , cover_all = True ) <NEWLINE> n , c , h , w = y_var . shape <NEWLINE> ys . append ( y_var . reshape ( ( n , c * h * w , <NUMBER> , <NUMBER> ) ) ) <NEWLINE> <NEWLINE> <UNTAB> return chainer . functions . concat ( ys ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def sparse_mat_mul_eager_fallback ( a , b , transpose_a = False , transpose_b = False , a_is_sparse = False , b_is_sparse = False , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> if transpose_a is None : <NEWLINE> <TAB> transpose_a = False <NEWLINE> <UNTAB> transpose_a = _execute . make_bool ( transpose_a , <STRING> ) <NEWLINE> if transpose_b is None : <NEWLINE> <TAB> transpose_b = False <NEWLINE> <UNTAB> transpose_b = _execute . make_bool ( transpose_b , <STRING> ) <NEWLINE> if a_is_sparse is None : <NEWLINE> <TAB> a_is_sparse = False <NEWLINE> <UNTAB> a_is_sparse = _execute . make_bool ( a_is_sparse , <STRING> ) <NEWLINE> if b_is_sparse is None : <NEWLINE> <TAB> b_is_sparse = False <NEWLINE> <UNTAB> b_is_sparse = _execute . make_bool ( b_is_sparse , <STRING> ) <NEWLINE> _attr_Ta , ( a , ) = _execute . args_to_matching_eager ( [ a ] , _ctx , _dtypes . float32 ) <NEWLINE> _attr_Tb , ( b , ) = _execute . args_to_matching_eager ( [ b ] , _ctx , _dtypes . float32 ) <NEWLINE> _inputs_flat = [ a , b ] <NEWLINE> _attrs = ( <STRING> , transpose_a , <STRING> , transpose_b , <NEWLINE> <STRING> , a_is_sparse , <STRING> , b_is_sparse , <STRING> , _attr_Ta , <NEWLINE> <STRING> , _attr_Tb ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __iter__ ( self ) : <NEWLINE> <TAB> <NEWLINE> for item in ( self [ i ] for i in range ( len ( self ) ) ) : <NEWLINE> <TAB> yield item <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def exponential_decay_noise ( xp , shape , dtype , hook , opt ) : <NEWLINE> <TAB> <NEWLINE> std = numpy . sqrt ( hook . eta / numpy . power ( <NUMBER> + opt . t , <NUMBER> ) ) <NEWLINE> return xp . random . normal ( <NUMBER> , std , shape ) . astype ( dtype ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _richcmp ( self , other , op ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( other , numbers . Rational ) : <NEWLINE> <TAB> return op ( self . _numerator * other . denominator , <NEWLINE> self . _denominator * other . numerator ) <NEWLINE> <UNTAB> if isinstance ( other , float ) : <NEWLINE> <TAB> if math . isnan ( other ) or math . isinf ( other ) : <NEWLINE> <TAB> return op ( <NUMBER> , other ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return op ( self , self . from_float ( other ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return NotImplemented <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def log2 ( x ) : <NEWLINE> <TAB> <NEWLINE> x = _fix_real_lt_zero ( x ) <NEWLINE> return nx . log2 ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> @ not_implemented_for ( <STRING> ) <NEWLINE> @ not_implemented_for ( <STRING> ) <NEWLINE> def spanner ( G , stretch , weight = None , seed = None ) : <NEWLINE> <TAB> <NEWLINE> if stretch < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> k = ( stretch + <NUMBER> ) // <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> H = nx . empty_graph ( ) <NEWLINE> H . add_nodes_from ( G . nodes ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> residual_graph = _setup_residual_graph ( G , weight ) <NEWLINE> <NEWLINE> <NEWLINE> clustering = { v : v for v in G . nodes } <NEWLINE> sample_prob = math . pow ( G . number_of_nodes ( ) , - <NUMBER> / k ) <NEWLINE> size_limit = <NUMBER> * math . pow ( G . number_of_nodes ( ) , <NUMBER> + <NUMBER> / k ) <NEWLINE> <NEWLINE> i = <NUMBER> <NEWLINE> while i < k - <NUMBER> : <NEWLINE> <NEWLINE> <TAB> sampled_centers = set ( ) <NEWLINE> for center in set ( clustering . values ( ) ) : <NEWLINE> <TAB> if seed . random ( ) < sample_prob : <NEWLINE> <TAB> sampled_centers . add ( center ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> edges_to_add = set ( ) <NEWLINE> edges_to_remove = set ( ) <NEWLINE> new_clustering = { } <NEWLINE> for v in residual_graph . nodes : <NEWLINE> <TAB> if clustering [ v ] in sampled_centers : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> lightest_edge_neighbor , lightest_edge_weight = _lightest_edge_dicts ( residual_graph , clustering , v ) <NEWLINE> neighboring_sampled_centers = set ( lightest_edge_weight . keys ( ) ) & sampled_centers <NEWLINE> <NEWLINE> <NEWLINE> if not neighboring_sampled_centers : <NEWLINE> <NEWLINE> <TAB> for neighbor in lightest_edge_neighbor . values ( ) : <NEWLINE> <TAB> edges_to_add . add ( ( v , neighbor ) ) <NEWLINE> <NEWLINE> <UNTAB> for neighbor in residual_graph . adj [ v ] : <NEWLINE> <TAB> edges_to_remove . add ( ( v , neighbor ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> closest_center = min ( neighboring_sampled_centers , <NEWLINE> key = lightest_edge_weight . get ) <NEWLINE> closest_center_weight = lightest_edge_weight [ closest_center ] <NEWLINE> closest_center_neighbor = lightest_edge_neighbor [ closest_center ] <NEWLINE> <NEWLINE> edges_to_add . add ( ( v , closest_center_neighbor ) ) <NEWLINE> new_clustering [ v ] = closest_center <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for center , edge_weight in lightest_edge_weight . items ( ) : <NEWLINE> <TAB> if edge_weight < closest_center_weight : <NEWLINE> <TAB> neighbor = lightest_edge_neighbor [ center ] <NEWLINE> edges_to_add . add ( ( v , neighbor ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for neighbor in residual_graph . adj [ v ] : <NEWLINE> <TAB> neighbor_cluster = clustering [ neighbor ] <NEWLINE> neighbor_weight = lightest_edge_weight [ neighbor_cluster ] <NEWLINE> if neighbor_cluster == closest_center or neighbor_weight < closest_center_weight : <NEWLINE> <TAB> edges_to_remove . add ( ( v , neighbor ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> if len ( edges_to_add ) > size_limit : <NEWLINE> <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> i = i + <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> for u , v in edges_to_add : <NEWLINE> <TAB> _add_edge_to_spanner ( H , residual_graph , u , v , weight ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> residual_graph . remove_edges_from ( edges_to_remove ) <NEWLINE> <NEWLINE> <NEWLINE> for node , center in clustering . items ( ) : <NEWLINE> <TAB> if center in sampled_centers : <NEWLINE> <TAB> new_clustering [ node ] = center <NEWLINE> <UNTAB> <UNTAB> clustering = new_clustering <NEWLINE> <NEWLINE> <NEWLINE> for u in residual_graph . nodes : <NEWLINE> <TAB> for v in list ( residual_graph . adj [ u ] ) : <NEWLINE> <TAB> if clustering [ u ] == clustering [ v ] : <NEWLINE> <TAB> residual_graph . remove_edge ( u , v ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> for v in list ( residual_graph . nodes ) : <NEWLINE> <TAB> if v not in clustering : <NEWLINE> <TAB> residual_graph . remove_node ( v ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> for v in residual_graph . nodes : <NEWLINE> <TAB> lightest_edge_neighbor , _ = _lightest_edge_dicts ( residual_graph , clustering , v ) <NEWLINE> for neighbor in lightest_edge_neighbor . values ( ) : <NEWLINE> <TAB> _add_edge_to_spanner ( H , residual_graph , v , neighbor , weight ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return H <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _create_xml_dom_element ( self , doc , module_name , is_key = False ) : <NEWLINE> <TAB> <NEWLINE> element = doc . createElement ( <STRING> ) <NEWLINE> if is_key : <NEWLINE> <TAB> element . appendChild ( _helpers . create_xml_dom_element ( doc , <STRING> , <STRING> ) ) <NEWLINE> <UNTAB> element . appendChild ( _helpers . create_xml_dom_element ( <NEWLINE> doc , <STRING> , module_name ) ) <NEWLINE> <NEWLINE> element . appendChild ( _helpers . create_xml_dom_element ( doc , <STRING> , self . name ) ) <NEWLINE> if self . short_name : <NEWLINE> <TAB> element . appendChild ( _helpers . create_xml_dom_element ( <NEWLINE> doc , <STRING> , self . short_name ) ) <NEWLINE> <UNTAB> if self . help : <NEWLINE> <TAB> element . appendChild ( _helpers . create_xml_dom_element ( <NEWLINE> doc , <STRING> , self . help ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . serializer and not isinstance ( self . default , str ) : <NEWLINE> <TAB> if self . default is not None : <NEWLINE> <TAB> default_serialized = self . serializer . serialize ( self . default ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> default_serialized = <STRING> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> default_serialized = self . default <NEWLINE> <UNTAB> element . appendChild ( _helpers . create_xml_dom_element ( <NEWLINE> doc , <STRING> , default_serialized ) ) <NEWLINE> element . appendChild ( _helpers . create_xml_dom_element ( <NEWLINE> doc , <STRING> , self . value ) ) <NEWLINE> element . appendChild ( _helpers . create_xml_dom_element ( <NEWLINE> doc , <STRING> , self . flag_type ( ) ) ) <NEWLINE> <NEWLINE> for e in self . _extra_xml_dom_elements ( doc ) : <NEWLINE> <TAB> element . appendChild ( e ) <NEWLINE> <UNTAB> return element <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def validate_col ( self , itemsize = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if _ensure_decoded ( self . kind ) == u ( <STRING> ) : <NEWLINE> <TAB> c = self . col <NEWLINE> if c is not None : <NEWLINE> <TAB> if itemsize is None : <NEWLINE> <TAB> itemsize = self . itemsize <NEWLINE> <UNTAB> if c . itemsize < itemsize : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % ( itemsize , self . cname , c . itemsize ) ) <NEWLINE> <UNTAB> return c . itemsize <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_QQ_gmpy ( K1 , a , K0 ) : <NEWLINE> <TAB> <NEWLINE> return K1 ( K1 . dom . convert ( a , K0 ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __eq__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def edges_from_line ( geom , attrs , simplify = True , geom_attrs = True ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> from osgeo import ogr <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> raise ImportError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if geom . GetGeometryType ( ) == ogr . wkbLineString : <NEWLINE> <TAB> if simplify : <NEWLINE> <TAB> edge_attrs = attrs . copy ( ) <NEWLINE> last = geom . GetPointCount ( ) - <NUMBER> <NEWLINE> if geom_attrs : <NEWLINE> <TAB> edge_attrs [ <STRING> ] = geom . ExportToWkb ( ) <NEWLINE> edge_attrs [ <STRING> ] = geom . ExportToWkt ( ) <NEWLINE> edge_attrs [ <STRING> ] = geom . ExportToJson ( ) <NEWLINE> <UNTAB> yield ( geom . GetPoint_2D ( <NUMBER> ) , geom . GetPoint_2D ( last ) , edge_attrs ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for i in range ( <NUMBER> , geom . GetPointCount ( ) - <NUMBER> ) : <NEWLINE> <TAB> pt1 = geom . GetPoint_2D ( i ) <NEWLINE> pt2 = geom . GetPoint_2D ( i + <NUMBER> ) <NEWLINE> edge_attrs = attrs . copy ( ) <NEWLINE> if geom_attrs : <NEWLINE> <TAB> segment = ogr . Geometry ( ogr . wkbLineString ) <NEWLINE> segment . AddPoint_2D ( pt1 [ <NUMBER> ] , pt1 [ <NUMBER> ] ) <NEWLINE> segment . AddPoint_2D ( pt2 [ <NUMBER> ] , pt2 [ <NUMBER> ] ) <NEWLINE> edge_attrs [ <STRING> ] = segment . ExportToWkb ( ) <NEWLINE> edge_attrs [ <STRING> ] = segment . ExportToWkt ( ) <NEWLINE> edge_attrs [ <STRING> ] = segment . ExportToJson ( ) <NEWLINE> del segment <NEWLINE> <UNTAB> yield ( pt1 , pt2 , edge_attrs ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif geom . GetGeometryType ( ) == ogr . wkbMultiLineString : <NEWLINE> <TAB> for i in range ( geom . GetGeometryCount ( ) ) : <NEWLINE> <TAB> geom_i = geom . GetGeometryRef ( i ) <NEWLINE> for edge in edges_from_line ( geom_i , attrs , simplify , geom_attrs ) : <NEWLINE> <TAB> yield edge <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _clean_axis ( self , ax ) : <NEWLINE> <TAB> <NEWLINE> ax . set_xlabel ( <STRING> ) <NEWLINE> ax . set_ylabel ( <STRING> ) <NEWLINE> ax . legend_ = None <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def row_op ( self , i , f ) : <NEWLINE> <TAB> <NEWLINE> for j in range ( self . cols ) : <NEWLINE> <TAB> v = self . _smat . get ( ( i , j ) , S . Zero ) <NEWLINE> fv = f ( v , j ) <NEWLINE> if fv : <NEWLINE> <TAB> self . _smat [ ( i , j ) ] = fv <NEWLINE> <UNTAB> elif v : <NEWLINE> <TAB> self . _smat . pop ( ( i , j ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def assert_summary ( expected_tags , expected_simple_values , summary_proto ) : <NEWLINE> <TAB> <NEWLINE> actual_tags = set ( ) <NEWLINE> for value in summary_proto . value : <NEWLINE> <TAB> actual_tags . add ( value . tag ) <NEWLINE> if value . tag in expected_simple_values : <NEWLINE> <TAB> expected = expected_simple_values [ value . tag ] <NEWLINE> actual = value . simple_value <NEWLINE> np . testing . assert_almost_equal ( <NEWLINE> actual , expected , decimal = <NUMBER> , err_msg = value . tag ) <NEWLINE> <UNTAB> <UNTAB> expected_tags = set ( expected_tags ) <NEWLINE> if expected_tags != actual_tags : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( expected_tags , actual_tags ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_window_extent ( self , renderer ) : <NEWLINE> <TAB> <NEWLINE> w , h , xd , yd = self . get_extent ( renderer ) <NEWLINE> ox , oy = self . get_offset ( ) <NEWLINE> <NEWLINE> return mtransforms . Bbox . from_bounds ( ox - xd , oy - yd , w , h ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecation . deprecated_endpoints ( <STRING> ) <NEWLINE> def conj ( x , name = None ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( x , ops . Tensor ) : <NEWLINE> <TAB> dt = x . dtype <NEWLINE> if dt . is_floating or dt . is_integer : <NEWLINE> <TAB> return x <NEWLINE> <UNTAB> <UNTAB> with ops . name_scope ( name , <STRING> , [ x ] ) as name : <NEWLINE> <TAB> x = ops . convert_to_tensor ( x , name = <STRING> ) <NEWLINE> if x . dtype . is_complex or x . dtype == dtypes . variant : <NEWLINE> <TAB> return gen_math_ops . conj ( x , name = name ) <NEWLINE> <UNTAB> elif x . dtype . is_floating or x . dtype . is_integer : <NEWLINE> <TAB> return x <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> % x . dtype ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_annotation_clip ( self , b ) : <NEWLINE> <TAB> <NEWLINE> self . _annotation_clip = b <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def compress_rowcols ( x , axis = None ) : <NEWLINE> <TAB> <NEWLINE> if asarray ( x ) . ndim != <NUMBER> : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> return compress_nd ( x , axis = axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def mean_variance_axis ( X , axis ) : <NEWLINE> <TAB> <NEWLINE> _raise_error_wrong_axis ( axis ) <NEWLINE> <NEWLINE> if isinstance ( X , sp . csr_matrix ) : <NEWLINE> <TAB> if axis == <NUMBER> : <NEWLINE> <TAB> return _csr_mean_var_axis0 ( X ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _csc_mean_var_axis0 ( X . T ) <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( X , sp . csc_matrix ) : <NEWLINE> <TAB> if axis == <NUMBER> : <NEWLINE> <TAB> return _csc_mean_var_axis0 ( X ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _csr_mean_var_axis0 ( X . T ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> _raise_typeerror ( X ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def if_delegate_has_method ( delegate ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( delegate , list ) : <NEWLINE> <TAB> delegate = tuple ( delegate ) <NEWLINE> <UNTAB> if not isinstance ( delegate , tuple ) : <NEWLINE> <TAB> delegate = ( delegate , ) <NEWLINE> <NEWLINE> <UNTAB> return lambda fn : _IffHasAttrDescriptor ( fn , delegate , <NEWLINE> attribute_name = fn . __name__ ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def ones_like ( tensor , dtype = None , name = None , optimize = True ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ tensor ] ) as name : <NEWLINE> <TAB> tensor = ops . convert_to_tensor ( tensor , name = <STRING> ) <NEWLINE> ones_shape = shape_internal ( tensor , optimize = optimize ) <NEWLINE> if dtype is None : <NEWLINE> <TAB> dtype = tensor . dtype <NEWLINE> <UNTAB> ret = ones ( ones_shape , dtype = dtype , name = name ) <NEWLINE> if not context . executing_eagerly ( ) : <NEWLINE> <TAB> ret . set_shape ( tensor . get_shape ( ) ) <NEWLINE> <UNTAB> return ret <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __getattribute__ ( self , name ) : <NEWLINE> <TAB> <NEWLINE> value = super ( NumpyState , self ) . __getattribute__ ( name ) <NEWLINE> if isinstance ( value , _NumpyWrapper ) : <NEWLINE> <TAB> return value . array <NEWLINE> <UNTAB> return value <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def read_var_header ( self ) : <NEWLINE> <TAB> <NEWLINE> hdr = self . _matrix_reader . read_header ( ) <NEWLINE> n = reduce ( lambda x , y : x * y , hdr . dims , <NUMBER> ) <NEWLINE> remaining_bytes = hdr . dtype . itemsize * n <NEWLINE> if hdr . is_complex and not hdr . mclass == mxSPARSE_CLASS : <NEWLINE> <TAB> remaining_bytes *= <NUMBER> <NEWLINE> <UNTAB> next_position = self . mat_stream . tell ( ) + remaining_bytes <NEWLINE> return hdr , next_position <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def normal ( self , size = None , avg = <NUMBER> , std = <NUMBER> , ndim = None , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> return self . gen ( normal , size , avg , std , ndim = ndim , dtype = dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def mpi_tag_key ( a ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( a . op , ( MPISend , MPIRecv , MPIRecvWait , MPISendWait ) ) : <NEWLINE> <TAB> return a . op . tag <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ memoize ( ) <NEWLINE> def elementwise ( in_params , out_params , operation , name , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> check_cuda_available ( ) <NEWLINE> return cupy . ElementwiseKernel ( <NEWLINE> in_params , out_params , operation , name , ** kwargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def create_index ( self , columns = None , optlevel = None , kind = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not self . infer_axes ( ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> if columns is False : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if columns is None or columns is True : <NEWLINE> <TAB> columns = [ a . cname for a in self . axes if a . is_data_indexable ] <NEWLINE> <UNTAB> if not isinstance ( columns , ( tuple , list ) ) : <NEWLINE> <TAB> columns = [ columns ] <NEWLINE> <NEWLINE> <UNTAB> kw = dict ( ) <NEWLINE> if optlevel is not None : <NEWLINE> <TAB> kw [ <STRING> ] = optlevel <NEWLINE> <UNTAB> if kind is not None : <NEWLINE> <TAB> kw [ <STRING> ] = kind <NEWLINE> <NEWLINE> <UNTAB> table = self . table <NEWLINE> for c in columns : <NEWLINE> <TAB> v = getattr ( table . cols , c , None ) <NEWLINE> if v is not None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if v . is_indexed : <NEWLINE> <TAB> index = v . index <NEWLINE> cur_optlevel = index . optlevel <NEWLINE> cur_kind = index . kind <NEWLINE> <NEWLINE> if kind is not None and cur_kind != kind : <NEWLINE> <TAB> v . remove_index ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> kw [ <STRING> ] = cur_kind <NEWLINE> <NEWLINE> <UNTAB> if optlevel is not None and cur_optlevel != optlevel : <NEWLINE> <TAB> v . remove_index ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> kw [ <STRING> ] = cur_optlevel <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not v . is_indexed : <NEWLINE> <TAB> if v . type . startswith ( <STRING> ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> v . create_index ( ** kw ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def parse_style ( self , data , markers , dashes , order ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if self . _empty_data ( data ) : <NEWLINE> <NEWLINE> <TAB> levels = [ None ] <NEWLINE> dashes = { } <NEWLINE> markers = { } <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> if order is None : <NEWLINE> <TAB> levels = categorical_order ( data ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> levels = order <NEWLINE> <NEWLINE> <UNTAB> markers = self . style_to_attributes ( <NEWLINE> levels , markers , self . default_markers , <STRING> <NEWLINE> ) <NEWLINE> <NEWLINE> dashes = self . style_to_attributes ( <NEWLINE> levels , dashes , self . default_dashes , <STRING> <NEWLINE> ) <NEWLINE> <NEWLINE> <UNTAB> paths = { } <NEWLINE> filled_markers = [ ] <NEWLINE> for k , m in markers . items ( ) : <NEWLINE> <TAB> if not isinstance ( m , mpl . markers . MarkerStyle ) : <NEWLINE> <TAB> m = mpl . markers . MarkerStyle ( m ) <NEWLINE> <UNTAB> paths [ k ] = m . get_path ( ) . transformed ( m . get_transform ( ) ) <NEWLINE> filled_markers . append ( m . is_filled ( ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if any ( filled_markers ) and not all ( filled_markers ) : <NEWLINE> <TAB> err = <STRING> <NEWLINE> raise ValueError ( err ) <NEWLINE> <NEWLINE> <UNTAB> self . style_levels = levels <NEWLINE> self . dashes = dashes <NEWLINE> self . markers = markers <NEWLINE> self . paths = paths <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def IsSequence ( o ) : <NEWLINE> <TAB> <NEWLINE> return _pywrap_tensorflow_internal . IsSequence ( o ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def select_column ( self , key , column , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return self . get_storer ( key ) . read_column ( column = column , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def min ( self ) : <NEWLINE> <TAB> <NEWLINE> return nanops . nanmin ( self . values ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_isolate ( G , n ) : <NEWLINE> <TAB> <NEWLINE> return G . degree ( n ) == <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit ( self , X , y = None ) : <NEWLINE> <TAB> <NEWLINE> X = check_array ( X , accept_sparse = <STRING> ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_view ( self ) : <NEWLINE> <TAB> <NEWLINE> xmin , xmax = self . get_xlim ( ) <NEWLINE> ymin , ymax = self . get_ylim ( ) <NEWLINE> return ( xmin , xmax , ymin , ymax ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dumps ( obj ) : <NEWLINE> <TAB> <NEWLINE> encoder = ArffEncoder ( ) <NEWLINE> return encoder . encode ( obj ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def concat_same_type ( self , to_concat , placement = None ) : <NEWLINE> <TAB> <NEWLINE> values = self . _concatenator ( [ blk . values for blk in to_concat ] , <NEWLINE> axis = self . ndim - <NUMBER> ) <NEWLINE> <NEWLINE> return make_block ( <NEWLINE> values , placement = placement or slice ( <NUMBER> , len ( values ) , <NUMBER> ) , <NEWLINE> ndim = self . ndim ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _apply_index_days ( self , i , roll ) : <NEWLINE> <TAB> <NEWLINE> nanos = ( roll % <NUMBER> ) * Timedelta ( days = self . day_of_month - <NUMBER> ) . value <NEWLINE> return i + nanos . astype ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , scores = None , classes = None ) : <NEWLINE> <TAB> <NEWLINE> if ( scores is not None <NEWLINE> and not ( isinstance ( scores , ops . Tensor ) <NEWLINE> and scores . dtype . is_floating ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( scores ) ) <NEWLINE> <UNTAB> if ( classes is not None <NEWLINE> and not ( isinstance ( classes , ops . Tensor ) <NEWLINE> and dtypes . as_dtype ( classes . dtype ) == dtypes . string ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( classes ) ) <NEWLINE> <UNTAB> if scores is None and classes is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> self . _scores = scores <NEWLINE> self . _classes = classes <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def experimental ( func ) : <NEWLINE> <TAB> <NEWLINE> decorator_utils . validate_callable ( func , <STRING> ) <NEWLINE> @ functools . wraps ( func ) <NEWLINE> def new_func ( * args , ** kwargs ) : <NEWLINE> <TAB> logging . warning ( <NEWLINE> <STRING> <NEWLINE> <STRING> , <NEWLINE> decorator_utils . get_qualified_name ( func ) , func . __module__ ) <NEWLINE> return func ( * args , ** kwargs ) <NEWLINE> <UNTAB> new_func . __doc__ = _add_experimental_function_notice_to_docstring ( <NEWLINE> func . __doc__ ) <NEWLINE> return new_func <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def broadcast ( tensor , devices ) : <NEWLINE> <TAB> <NEWLINE> return torch . _C . _broadcast ( tensor , devices ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def single ( y ) : <NEWLINE> <TAB> <NEWLINE> return linkage ( y , method = <STRING> , metric = <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def str_pad ( arr , width , side = <STRING> , fillchar = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not isinstance ( fillchar , compat . string_types ) : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise TypeError ( msg . format ( type ( fillchar ) . __name__ ) ) <NEWLINE> <NEWLINE> <UNTAB> if len ( fillchar ) != <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if not is_integer ( width ) : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise TypeError ( msg . format ( type ( width ) . __name__ ) ) <NEWLINE> <NEWLINE> <UNTAB> if side == <STRING> : <NEWLINE> <TAB> f = lambda x : x . rjust ( width , fillchar ) <NEWLINE> <UNTAB> elif side == <STRING> : <NEWLINE> <TAB> f = lambda x : x . ljust ( width , fillchar ) <NEWLINE> <UNTAB> elif side == <STRING> : <NEWLINE> <TAB> f = lambda x : x . center ( width , fillchar ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return _na_map ( f , arr ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def initialize ( self , name = None ) : <NEWLINE> <TAB> <NEWLINE> return self . _helper . initialize ( ) + ( self . _initial_state , ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_text_heights ( self , renderer ) : <NEWLINE> <TAB> <NEWLINE> bbox , bbox2 = self . get_ticklabel_extents ( renderer ) <NEWLINE> <NEWLINE> padPixels = self . majorTicks [ <NUMBER> ] . get_pad_pixels ( ) <NEWLINE> <NEWLINE> above = <NUMBER> <NEWLINE> if bbox2 . height : <NEWLINE> <TAB> above += bbox2 . height + padPixels <NEWLINE> <UNTAB> below = <NUMBER> <NEWLINE> if bbox . height : <NEWLINE> <TAB> below += bbox . height + padPixels <NEWLINE> <NEWLINE> <UNTAB> if self . get_label_position ( ) == <STRING> : <NEWLINE> <TAB> above += self . label . get_window_extent ( renderer ) . height + padPixels <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> below += self . label . get_window_extent ( renderer ) . height + padPixels <NEWLINE> <UNTAB> return above , below <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def conv3d_backprop_input_v2 ( input_sizes , filter , out_backprop , strides , padding , data_format = <STRING> , dilations = [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if not isinstance ( strides , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % strides ) <NEWLINE> <UNTAB> strides = [ _execute . make_int ( _i , <STRING> ) for _i in strides ] <NEWLINE> padding = _execute . make_str ( padding , <STRING> ) <NEWLINE> if data_format is None : <NEWLINE> <TAB> data_format = <STRING> <NEWLINE> <UNTAB> data_format = _execute . make_str ( data_format , <STRING> ) <NEWLINE> if dilations is None : <NEWLINE> <TAB> dilations = [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] <NEWLINE> <UNTAB> if not isinstance ( dilations , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % dilations ) <NEWLINE> <UNTAB> dilations = [ _execute . make_int ( _i , <STRING> ) for _i in dilations ] <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input_sizes = input_sizes , filter = filter , <NEWLINE> out_backprop = out_backprop , strides = strides , padding = padding , <NEWLINE> data_format = data_format , dilations = dilations , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) , <NEWLINE> <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , <NEWLINE> input_sizes , filter , out_backprop , <STRING> , strides , <STRING> , <NEWLINE> padding , <STRING> , data_format , <STRING> , dilations ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return conv3d_backprop_input_v2_eager_fallback ( <NEWLINE> input_sizes , filter , out_backprop , strides = strides , padding = padding , <NEWLINE> data_format = data_format , dilations = dilations , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def XML ( text , parser = None ) : <NEWLINE> <TAB> <NEWLINE> if not parser : <NEWLINE> <TAB> parser = XMLParser ( target = TreeBuilder ( ) ) <NEWLINE> <UNTAB> parser . feed ( text ) <NEWLINE> return parser . close ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def get_revision ( ) : <NEWLINE> <TAB> <NEWLINE> vcs , revision , tag = None , None , None <NEWLINE> <NEWLINE> gitdir = os . path . join ( basedir , <STRING> , <STRING> ) <NEWLINE> <NEWLINE> if os . path . isdir ( gitdir ) : <NEWLINE> <TAB> vcs = <STRING> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> vcs_info = ( vcs , ( revision , tag ) ) <NEWLINE> <NEWLINE> return revision , vcs_info <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def truncate_div_eager_fallback ( x , y , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ x , y ] , _ctx ) <NEWLINE> ( x , y ) = _inputs_T <NEWLINE> _inputs_flat = [ x , y ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _OpaqueParamsToCanonical ( self ) : <NEWLINE> <TAB> <NEWLINE> with ops . device ( <STRING> ) : <NEWLINE> <TAB> weights , biases = gen_cudnn_rnn_ops . cudnn_rnn_params_to_canonical ( <NEWLINE> num_layers = self . _num_layers , <NEWLINE> num_units = self . _num_units , <NEWLINE> input_size = self . _input_size , <NEWLINE> params = self . _variables , <NEWLINE> num_params = self . _num_params , <NEWLINE> rnn_mode = self . _rnn_mode , <NEWLINE> input_mode = self . _input_mode , <NEWLINE> direction = self . _direction ) <NEWLINE> return ( weights , biases ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_value ( self , series , key ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if _is_convertible_to_td ( key ) : <NEWLINE> <TAB> key = Timedelta ( key ) <NEWLINE> return self . get_value_maybe_box ( series , key ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> return com . _maybe_box ( self , Index . get_value ( self , series , key ) , <NEWLINE> series , key ) <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> try : <NEWLINE> <TAB> loc = self . _get_string_slice ( key ) <NEWLINE> return series [ loc ] <NEWLINE> <UNTAB> except ( TypeError , ValueError , KeyError ) : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> return self . get_value_maybe_box ( series , key ) <NEWLINE> <UNTAB> except ( TypeError , ValueError , KeyError ) : <NEWLINE> <TAB> raise KeyError ( key ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def homogeneity_completeness_v_measure ( labels_true , labels_pred ) : <NEWLINE> <TAB> <NEWLINE> labels_true , labels_pred = check_clusterings ( labels_true , labels_pred ) <NEWLINE> <NEWLINE> if len ( labels_true ) == <NUMBER> : <NEWLINE> <TAB> return <NUMBER> , <NUMBER> , <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> entropy_C = entropy ( labels_true ) <NEWLINE> entropy_K = entropy ( labels_pred ) <NEWLINE> <NEWLINE> contingency = contingency_matrix ( labels_true , labels_pred , sparse = True ) <NEWLINE> MI = mutual_info_score ( None , None , contingency = contingency ) <NEWLINE> <NEWLINE> homogeneity = MI / ( entropy_C ) if entropy_C else <NUMBER> <NEWLINE> completeness = MI / ( entropy_K ) if entropy_K else <NUMBER> <NEWLINE> <NEWLINE> if homogeneity + completeness == <NUMBER> : <NEWLINE> <TAB> v_measure_score = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> v_measure_score = ( <NUMBER> * homogeneity * completeness / <NEWLINE> ( homogeneity + completeness ) ) <NEWLINE> <NEWLINE> <UNTAB> return homogeneity , completeness , v_measure_score <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def mean_log_det ( self , name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> with self . _name_scope ( name ) : <NEWLINE> <TAB> return ( self . _multi_digamma ( <NUMBER> * self . df , self . dimension ) + <NEWLINE> self . dimension * math . log ( <NUMBER> ) + <NEWLINE> <NUMBER> * self . scale_operator . log_abs_determinant ( ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _default_compare_fn ( curr_best_eval_result , cand_eval_result ) : <NEWLINE> <TAB> <NEWLINE> default_key = metric_key . MetricKey . LOSS <NEWLINE> if not curr_best_eval_result or default_key not in curr_best_eval_result : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if not cand_eval_result or default_key not in cand_eval_result : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return curr_best_eval_result [ default_key ] > cand_eval_result [ default_key ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _to_ordinalf ( dt ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> tzi = getattr ( dt , <STRING> , None ) <NEWLINE> if tzi is not None : <NEWLINE> <TAB> dt = dt . astimezone ( UTC ) <NEWLINE> tzi = UTC <NEWLINE> <NEWLINE> <UNTAB> base = float ( dt . toordinal ( ) ) <NEWLINE> <NEWLINE> <NEWLINE> cdate = getattr ( dt , <STRING> , lambda : None ) ( ) <NEWLINE> if cdate is not None : <NEWLINE> <NEWLINE> <TAB> midnight_time = datetime . time ( <NUMBER> , tzinfo = tzi ) <NEWLINE> <NEWLINE> rdt = datetime . datetime . combine ( cdate , midnight_time ) <NEWLINE> <NEWLINE> <NEWLINE> base += ( dt - rdt ) . total_seconds ( ) / SEC_PER_DAY <NEWLINE> <NEWLINE> <UNTAB> return base <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def srepr ( expr , ** settings ) : <NEWLINE> <TAB> <NEWLINE> return ReprPrinter ( settings ) . doprint ( expr ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def match_font ( name , bold = <NUMBER> , italic = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if not Sysfonts : <NEWLINE> <TAB> initsysfonts ( ) <NEWLINE> <NEWLINE> <UNTAB> fontname = None <NEWLINE> allnames = name <NEWLINE> for name in allnames . split ( <STRING> ) : <NEWLINE> <TAB> name = _simplename ( name ) <NEWLINE> styles = Sysfonts . get ( name ) <NEWLINE> if not styles : <NEWLINE> <TAB> styles = Sysalias . get ( name ) <NEWLINE> <UNTAB> if styles : <NEWLINE> <TAB> while not fontname : <NEWLINE> <TAB> fontname = styles . get ( ( bold , italic ) ) <NEWLINE> if italic : <NEWLINE> <TAB> italic = <NUMBER> <NEWLINE> <UNTAB> elif bold : <NEWLINE> <TAB> bold = <NUMBER> <NEWLINE> <UNTAB> elif not fontname : <NEWLINE> <TAB> fontname = list ( styles . values ( ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if fontname : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> return fontname <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , * maps ) : <NEWLINE> <TAB> <NEWLINE> self . maps = list ( maps ) or [ { } ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( None , <STRING> ) <NEWLINE> def seq2seq_inputs ( x , y , input_length , output_length , sentinel = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ x , y ] ) : <NEWLINE> <TAB> in_x = array_ops . unstack ( x , axis = <NUMBER> ) <NEWLINE> y = array_ops . unstack ( y , axis = <NUMBER> ) <NEWLINE> if not sentinel : <NEWLINE> <NEWLINE> <TAB> sentinel_shape = array_ops . stack ( <NEWLINE> [ array_ops . shape ( x ) [ <NUMBER> ] , y [ <NUMBER> ] . get_shape ( ) [ <NUMBER> ] ] ) <NEWLINE> sentinel = array_ops . zeros ( sentinel_shape ) <NEWLINE> sentinel . set_shape ( y [ <NUMBER> ] . get_shape ( ) ) <NEWLINE> <UNTAB> in_y = [ sentinel ] + y <NEWLINE> out_y = y + [ sentinel ] <NEWLINE> return in_x , in_y , out_y <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_dir ( self ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return S_ISDIR ( self . stat ( ) . st_mode ) <NEWLINE> <UNTAB> except OSError as e : <NEWLINE> <TAB> if e . errno not in ( ENOENT , ENOTDIR ) : <NEWLINE> <TAB> raise <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _get_kind_name ( param_type , is_list ) : <NEWLINE> <TAB> <NEWLINE> if issubclass ( param_type , bool ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> typename = <STRING> <NEWLINE> <UNTAB> elif issubclass ( param_type , six . integer_types ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> typename = <STRING> <NEWLINE> <UNTAB> elif issubclass ( param_type , ( six . string_types , six . binary_type ) ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> typename = <STRING> <NEWLINE> <UNTAB> elif issubclass ( param_type , float ) : <NEWLINE> <TAB> typename = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> % str ( param_type ) ) <NEWLINE> <NEWLINE> <UNTAB> suffix = <STRING> if is_list else <STRING> <NEWLINE> return <STRING> . join ( [ typename , suffix ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _reroute_sgv ( sgv0 , sgv1 , mode ) : <NEWLINE> <TAB> <NEWLINE> _reroute_sgv_outputs ( sgv0 , sgv1 , mode ) <NEWLINE> _reroute_sgv_inputs ( sgv0 , sgv1 , mode ) <NEWLINE> return sgv0 , sgv1 <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def outside_compilation ( computation , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> args = [ ] if args is None else args <NEWLINE> graph = ops . get_default_graph ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> initial_context = graph . _get_control_flow_context ( ) <NEWLINE> context = initial_context <NEWLINE> while context : <NEWLINE> <TAB> if isinstance ( context , TPUReplicateContext ) : <NEWLINE> <TAB> context . _EnterOutsideCompilationScope ( ) <NEWLINE> <UNTAB> context = context . outer_context <NEWLINE> <NEWLINE> <UNTAB> retval = computation ( * args , ** kwargs ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> final_context = graph . _get_control_flow_context ( ) <NEWLINE> if initial_context is not final_context : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> context = initial_context <NEWLINE> while context : <NEWLINE> <TAB> if isinstance ( context , TPUReplicateContext ) : <NEWLINE> <TAB> context . _ExitOutsideCompilationScope ( ) <NEWLINE> <UNTAB> context = context . outer_context <NEWLINE> <NEWLINE> <UNTAB> return retval <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def modularity_spectrum ( G ) : <NEWLINE> <TAB> <NEWLINE> from scipy . linalg import eigvals <NEWLINE> if G . is_directed ( ) : <NEWLINE> <TAB> return eigvals ( nx . directed_modularity_matrix ( G ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return eigvals ( nx . modularity_matrix ( G ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def convert ( recursive = False , verbose = converter . Verbosity . VERBOSE ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def decorator ( f ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> @ functools . wraps ( f ) <NEWLINE> def wrapper ( * args , ** kwargs ) : <NEWLINE> <TAB> return converted_call ( <NEWLINE> f , None , <NEWLINE> converter . ConversionOptions ( <NEWLINE> recursive = recursive , <NEWLINE> verbose = verbose , <NEWLINE> force_conversion = True , <NEWLINE> optional_features = converter . Feature . ALL , <NEWLINE> ) , * args , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> wrapper = tf_decorator . make_decorator ( f , wrapper ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> setattr ( wrapper , <STRING> , True ) <NEWLINE> return wrapper <NEWLINE> <NEWLINE> <UNTAB> return decorator <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_categories ( self , new_categories , inplace = False ) : <NEWLINE> <TAB> <NEWLINE> inplace = validate_bool_kwarg ( inplace , <STRING> ) <NEWLINE> if not is_list_like ( new_categories ) : <NEWLINE> <TAB> new_categories = [ new_categories ] <NEWLINE> <UNTAB> already_included = set ( new_categories ) & set ( self . dtype . categories ) <NEWLINE> if len ( already_included ) != <NUMBER> : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> raise ValueError ( msg . format ( already_included = already_included ) ) <NEWLINE> <UNTAB> new_categories = list ( self . dtype . categories ) + list ( new_categories ) <NEWLINE> new_dtype = CategoricalDtype ( new_categories , self . ordered ) <NEWLINE> <NEWLINE> cat = self if inplace else self . copy ( ) <NEWLINE> cat . _dtype = new_dtype <NEWLINE> cat . _codes = coerce_indexer_dtype ( cat . _codes , new_dtype . categories ) <NEWLINE> if not inplace : <NEWLINE> <TAB> return cat <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def expand_power_exp ( expr , deep = True ) : <NEWLINE> <TAB> <NEWLINE> return sympify ( expr ) . expand ( deep = deep , complex = False , basic = False , <NEWLINE> log = False , mul = False , power_exp = True , power_base = False , multinomial = False ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def modified ( self ) : <NEWLINE> <TAB> <NEWLINE> import time <NEWLINE> self . last_checked = time . time ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def POSform ( variables , minterms , dontcares = None ) : <NEWLINE> <TAB> <NEWLINE> variables = [ sympify ( v ) for v in variables ] <NEWLINE> if minterms == [ ] : <NEWLINE> <TAB> return false <NEWLINE> <NEWLINE> <UNTAB> minterms = [ list ( i ) for i in minterms ] <NEWLINE> dontcares = [ list ( i ) for i in ( dontcares or [ ] ) ] <NEWLINE> for d in dontcares : <NEWLINE> <TAB> if d in minterms : <NEWLINE> <TAB> raise ValueError ( <STRING> % d ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> maxterms = [ ] <NEWLINE> for t in product ( [ <NUMBER> , <NUMBER> ] , repeat = len ( variables ) ) : <NEWLINE> <TAB> t = list ( t ) <NEWLINE> if ( t not in minterms ) and ( t not in dontcares ) : <NEWLINE> <TAB> maxterms . append ( t ) <NEWLINE> <UNTAB> <UNTAB> old = None <NEWLINE> new = maxterms + dontcares <NEWLINE> while new != old : <NEWLINE> <TAB> old = new <NEWLINE> new = _simplified_pairs ( old ) <NEWLINE> <UNTAB> essential = _rem_redundancy ( new , maxterms ) <NEWLINE> return And ( * [ _convert_to_varsPOS ( x , variables ) for x in essential ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _inner_refine ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . mobius is None : <NEWLINE> <TAB> return self <NEWLINE> <NEWLINE> <UNTAB> f , mobius = dup_inner_refine_real_root ( <NEWLINE> self . f , self . mobius , self . dom , steps = <NUMBER> , mobius = True ) <NEWLINE> <NEWLINE> return RealInterval ( mobius + ( self . neg , ) , f , self . dom ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _gen_roots_and_weights ( n , mu0 , an_func , bn_func , f , df , symmetrize , mu ) : <NEWLINE> <TAB> <NEWLINE> k = np . arange ( n , dtype = <STRING> ) <NEWLINE> c = np . zeros ( ( <NUMBER> , n ) ) <NEWLINE> c [ <NUMBER> , <NUMBER> : ] = bn_func ( k [ <NUMBER> : ] ) <NEWLINE> c [ <NUMBER> , : ] = an_func ( k ) <NEWLINE> x = linalg . eigvals_banded ( c , overwrite_a_band = True ) <NEWLINE> <NEWLINE> <NEWLINE> y = f ( n , x ) <NEWLINE> dy = df ( n , x ) <NEWLINE> x -= y / dy <NEWLINE> <NEWLINE> fm = f ( n - <NUMBER> , x ) <NEWLINE> fm /= np . abs ( fm ) . max ( ) <NEWLINE> dy /= np . abs ( dy ) . max ( ) <NEWLINE> w = <NUMBER> / ( fm * dy ) <NEWLINE> <NEWLINE> if symmetrize : <NEWLINE> <TAB> w = ( w + w [ : : - <NUMBER> ] ) / <NUMBER> <NEWLINE> x = ( x - x [ : : - <NUMBER> ] ) / <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> w *= mu0 / w . sum ( ) <NEWLINE> <NEWLINE> if mu : <NEWLINE> <TAB> return x , w , mu0 <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return x , w <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def use_arraytype ( arraytype ) : <NEWLINE> <TAB> <NEWLINE> arraytype = arraytype . lower ( ) <NEWLINE> if arraytype != <STRING> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def setup_module ( module ) : <NEWLINE> <TAB> <NEWLINE> from nose import SkipTest <NEWLINE> try : <NEWLINE> <TAB> import numpy <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> raise SkipTest ( <STRING> ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> import scipy <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> raise SkipTest ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sort_complex ( a ) : <NEWLINE> <TAB> <NEWLINE> b = array ( a , copy = True ) <NEWLINE> b . sort ( ) <NEWLINE> if not issubclass ( b . dtype . type , _nx . complexfloating ) : <NEWLINE> <TAB> if b . dtype . char in <STRING> : <NEWLINE> <TAB> return b . astype ( <STRING> ) <NEWLINE> <UNTAB> elif b . dtype . char == <STRING> : <NEWLINE> <TAB> return b . astype ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return b . astype ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return b <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def check_feature_columns ( feature_columns ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( feature_columns , dict ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> seen_keys = set ( ) <NEWLINE> for f in feature_columns : <NEWLINE> <TAB> key = f . key <NEWLINE> if key in seen_keys : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( <NEWLINE> f . name ) ) <NEWLINE> <UNTAB> seen_keys . add ( key ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _check_retval_ ( self ) : <NEWLINE> <TAB> <NEWLINE> return array ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _text_getter ( self , obj ) : <NEWLINE> <TAB> <NEWLINE> raise com . AbstractMethodError ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def collect_metrics ( metrics , output_names ) : <NEWLINE> <TAB> <NEWLINE> if not metrics : <NEWLINE> <TAB> return [ [ ] for _ in output_names ] <NEWLINE> <UNTAB> if isinstance ( metrics , list ) : <NEWLINE> <NEWLINE> <TAB> return [ copy . copy ( metrics ) for _ in output_names ] <NEWLINE> <UNTAB> elif isinstance ( metrics , dict ) : <NEWLINE> <TAB> nested_metrics = [ ] <NEWLINE> for name in output_names : <NEWLINE> <TAB> output_metrics = metrics . get ( name , [ ] ) <NEWLINE> output_metrics = to_list ( output_metrics ) <NEWLINE> nested_metrics . append ( output_metrics ) <NEWLINE> <UNTAB> return nested_metrics <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> + <NEWLINE> str ( metrics ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , num_tasks , load_fn ) : <NEWLINE> <TAB> <NEWLINE> self . _num_tasks = num_tasks <NEWLINE> self . _load_fn = load_fn <NEWLINE> self . _ps_loads = np . zeros ( num_tasks ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def push_state ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _state_stack . append ( self . get_state ( ) . copy ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def minsolve_linear_system ( system , * symbols , ** flags ) : <NEWLINE> <TAB> <NEWLINE> quick = flags . get ( <STRING> , False ) <NEWLINE> <NEWLINE> s0 = solve_linear_system ( system , * symbols , ** flags ) <NEWLINE> if not s0 or all ( v == <NUMBER> for v in s0 . values ( ) ) : <NEWLINE> <TAB> return s0 <NEWLINE> <UNTAB> if quick : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> s = solve_linear_system ( system , * symbols ) <NEWLINE> def update ( determined , solution ) : <NEWLINE> <TAB> delete = [ ] <NEWLINE> for k , v in solution . items ( ) : <NEWLINE> <TAB> solution [ k ] = v . subs ( determined ) <NEWLINE> if not solution [ k ] . free_symbols : <NEWLINE> <TAB> delete . append ( k ) <NEWLINE> determined [ k ] = solution [ k ] <NEWLINE> <UNTAB> <UNTAB> for k in delete : <NEWLINE> <TAB> del solution [ k ] <NEWLINE> <UNTAB> <UNTAB> determined = { } <NEWLINE> update ( determined , s ) <NEWLINE> while s : <NEWLINE> <NEWLINE> <TAB> k = max ( ( k for k in s . values ( ) ) , <NEWLINE> key = lambda x : ( len ( x . free_symbols ) , default_sort_key ( x ) ) ) <NEWLINE> x = max ( k . free_symbols , key = default_sort_key ) <NEWLINE> if len ( k . free_symbols ) != <NUMBER> : <NEWLINE> <TAB> determined [ x ] = S ( <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> val = solve ( k ) [ <NUMBER> ] <NEWLINE> if val == <NUMBER> and all ( v . subs ( x , val ) == <NUMBER> for v in s . values ( ) ) : <NEWLINE> <TAB> determined [ x ] = S ( <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> determined [ x ] = val <NEWLINE> <UNTAB> <UNTAB> update ( determined , s ) <NEWLINE> <UNTAB> return determined <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> from itertools import combinations <NEWLINE> from sympy . utilities . misc import debug <NEWLINE> N = len ( symbols ) <NEWLINE> bestsol = minsolve_linear_system ( system , * symbols , quick = True ) <NEWLINE> n0 = len ( [ x for x in bestsol . values ( ) if x != <NUMBER> ] ) <NEWLINE> for n in range ( n0 - <NUMBER> , <NUMBER> , - <NUMBER> ) : <NEWLINE> <TAB> debug ( <STRING> % n ) <NEWLINE> thissol = None <NEWLINE> for nonzeros in combinations ( list ( range ( N ) ) , n ) : <NEWLINE> <TAB> subm = Matrix ( [ system . col ( i ) . T for i in nonzeros ] + [ system . col ( - <NUMBER> ) . T ] ) . T <NEWLINE> s = solve_linear_system ( subm , * [ symbols [ i ] for i in nonzeros ] ) <NEWLINE> if s and not all ( v == <NUMBER> for v in s . values ( ) ) : <NEWLINE> <TAB> subs = [ ( symbols [ v ] , S ( <NUMBER> ) ) for v in nonzeros ] <NEWLINE> for k , v in s . items ( ) : <NEWLINE> <TAB> s [ k ] = v . subs ( subs ) <NEWLINE> <UNTAB> for sym in symbols : <NEWLINE> <TAB> if sym not in s : <NEWLINE> <TAB> if symbols . index ( sym ) in nonzeros : <NEWLINE> <TAB> s [ sym ] = S ( <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> s [ sym ] = S ( <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> thissol = s <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> if thissol is None : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> bestsol = thissol <NEWLINE> <UNTAB> return bestsol <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def matdims ( arr , oned_as = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> shape = arr . shape <NEWLINE> if shape == ( ) : <NEWLINE> <TAB> return ( <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> if reduce ( operator . mul , shape ) == <NUMBER> : <NEWLINE> <TAB> return ( <NUMBER> , ) * np . max ( [ arr . ndim , <NUMBER> ] ) <NEWLINE> <UNTAB> if len ( shape ) == <NUMBER> : <NEWLINE> <TAB> if oned_as == <STRING> : <NEWLINE> <TAB> return shape + ( <NUMBER> , ) <NEWLINE> <UNTAB> elif oned_as == <STRING> : <NEWLINE> <TAB> return ( <NUMBER> , ) + shape <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> % oned_as ) <NEWLINE> <UNTAB> <UNTAB> return shape <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _compute_dof ( self , kind , dz = None ) : <NEWLINE> <TAB> <NEWLINE> if kind == <STRING> : <NEWLINE> <TAB> if dz is None : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> TE = _DOF_estimator_user ( self , dz = dz ) <NEWLINE> <UNTAB> elif kind == <STRING> : <NEWLINE> <TAB> TE = _DOF_estimator_geom ( self ) <NEWLINE> <UNTAB> elif kind == <STRING> : <NEWLINE> <TAB> TE = _DOF_estimator_min_E ( self ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( kind ) ) <NEWLINE> <UNTAB> return TE . compute_dof_from_df ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def predecessor ( G , source , target = None , cutoff = None , return_seen = None ) : <NEWLINE> <TAB> <NEWLINE> if source not in G : <NEWLINE> <TAB> raise nx . NodeNotFound ( <STRING> . format ( source ) ) <NEWLINE> <NEWLINE> <UNTAB> level = <NUMBER> <NEWLINE> nextlevel = [ source ] <NEWLINE> seen = { source : level } <NEWLINE> pred = { source : [ ] } <NEWLINE> while nextlevel : <NEWLINE> <TAB> level = level + <NUMBER> <NEWLINE> thislevel = nextlevel <NEWLINE> nextlevel = [ ] <NEWLINE> for v in thislevel : <NEWLINE> <TAB> for w in G [ v ] : <NEWLINE> <TAB> if w not in seen : <NEWLINE> <TAB> pred [ w ] = [ v ] <NEWLINE> seen [ w ] = level <NEWLINE> nextlevel . append ( w ) <NEWLINE> <UNTAB> elif ( seen [ w ] == level ) : <NEWLINE> <TAB> pred [ w ] . append ( v ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if ( cutoff and cutoff <= level ) : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if target is not None : <NEWLINE> <TAB> if return_seen : <NEWLINE> <TAB> if target not in pred : <NEWLINE> <TAB> return ( [ ] , - <NUMBER> ) <NEWLINE> <UNTAB> return ( pred [ target ] , seen [ target ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if target not in pred : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> return pred [ target ] <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if return_seen : <NEWLINE> <TAB> return ( pred , seen ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return pred <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def regress_out ( self , a , b ) : <NEWLINE> <TAB> <NEWLINE> a_mean = a . mean ( ) <NEWLINE> a = a - a_mean <NEWLINE> b = b - b . mean ( ) <NEWLINE> b = np . c_ [ b ] <NEWLINE> a_prime = a - b . dot ( np . linalg . pinv ( b ) . dot ( a ) ) <NEWLINE> return ( a_prime + a_mean ) . reshape ( a . shape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _populate_grad_dict ( var_to_app_to_idx , <NEWLINE> grad_dict , wrt , cost_name = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> term_dict = OrderedDict ( ) <NEWLINE> <NEWLINE> def access_term_cache ( node ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if node not in term_dict : <NEWLINE> <NEWLINE> <TAB> inputs = node . inputs <NEWLINE> <NEWLINE> output_grads = [ access_grad_cache ( var ) for var in node . outputs ] <NEWLINE> <NEWLINE> <NEWLINE> outputs_connected = [ not isinstance ( g . type , DisconnectedType ) <NEWLINE> for g in output_grads ] <NEWLINE> <NEWLINE> connection_pattern = _node_to_pattern ( node ) <NEWLINE> <NEWLINE> <NEWLINE> inputs_connected = [ <NEWLINE> ( True in [ input_to_output and output_to_cost for <NEWLINE> input_to_output , output_to_cost in <NEWLINE> zip ( input_to_outputs , outputs_connected ) ] ) for <NEWLINE> input_to_outputs in connection_pattern <NEWLINE> ] <NEWLINE> <NEWLINE> <NEWLINE> output_is_int = [ hasattr ( output . type , <STRING> ) and <NEWLINE> output . type . dtype in theano . tensor . discrete_dtypes <NEWLINE> for output in node . outputs ] <NEWLINE> <NEWLINE> <NEWLINE> ograd_is_nan = [ isinstance ( output . type , NullType ) <NEWLINE> for output in output_grads ] <NEWLINE> <NEWLINE> <NEWLINE> only_connected_to_nan = [ <NEWLINE> ( True not in <NEWLINE> [ in_to_out and out_to_cost and not out_nan <NEWLINE> for in_to_out , out_to_cost , out_nan in <NEWLINE> zip ( in_to_outs , outputs_connected , ograd_is_nan ) ] ) <NEWLINE> for in_to_outs in connection_pattern ] <NEWLINE> <NEWLINE> if True not in inputs_connected : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> input_grads = [ disconnected_type ( ) for ipt in inputs ] <NEWLINE> <UNTAB> elif False not in only_connected_to_nan : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> input_grads = [ ] <NEWLINE> for connected in inputs_connected : <NEWLINE> <TAB> if connected : <NEWLINE> <TAB> input_grads . append ( null_type ( ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> input_grads . append ( disconnected_type ( ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> dinputs = [ node . inputs [ x [ <NUMBER> ] ] for x in <NEWLINE> itervalues ( node . op . destroy_map ) ] <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> dinputs = [ ] <NEWLINE> <NEWLINE> <UNTAB> def try_to_copy_if_needed ( var ) : <NEWLINE> <TAB> if var in dinputs and hasattr ( var , <STRING> ) : <NEWLINE> <TAB> return var . copy ( ) <NEWLINE> <UNTAB> return var <NEWLINE> <NEWLINE> <UNTAB> inputs = [ try_to_copy_if_needed ( ipt ) for ipt in inputs ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> new_output_grads = [ ] <NEWLINE> for o , og in zip ( node . outputs , output_grads ) : <NEWLINE> <TAB> o_dt = getattr ( o . type , <STRING> , None ) <NEWLINE> og_dt = getattr ( og . type , <STRING> , None ) <NEWLINE> if ( o_dt not in theano . tensor . discrete_dtypes and <NEWLINE> og_dt and o_dt != og_dt ) : <NEWLINE> <TAB> new_output_grads . append ( og . astype ( o_dt ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> new_output_grads . append ( og ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for o , ng in zip ( node . outputs , new_output_grads ) : <NEWLINE> <TAB> o_dt = getattr ( o . type , <STRING> , None ) <NEWLINE> ng_dt = getattr ( ng . type , <STRING> , None ) <NEWLINE> if ( ng_dt is not None and <NEWLINE> o_dt not in theano . tensor . discrete_dtypes ) : <NEWLINE> <TAB> assert ng_dt == o_dt <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for ng in new_output_grads : <NEWLINE> <TAB> assert ( getattr ( ng . type , <STRING> , None ) <NEWLINE> not in theano . tensor . discrete_dtypes ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for idx , packed in enumerate ( izip ( node . outputs , <NEWLINE> new_output_grads ) ) : <NEWLINE> <TAB> orig_output , new_output_grad = packed <NEWLINE> if not hasattr ( orig_output , <STRING> ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> if isinstance ( new_output_grad . type , DisconnectedType ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> for orig_output_v , new_output_grad_v in get_debug_values ( <NEWLINE> * packed ) : <NEWLINE> <TAB> o_shape = orig_output_v . shape <NEWLINE> g_shape = new_output_grad_v . shape <NEWLINE> if o_shape != g_shape : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> + <NEWLINE> str ( o_shape ) + <STRING> + <NEWLINE> str ( g_shape ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> input_grads = node . op . L_op ( inputs , node . outputs , <NEWLINE> new_output_grads ) <NEWLINE> <NEWLINE> if input_grads is None : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> % str ( node . op ) ) <NEWLINE> <NEWLINE> <UNTAB> if len ( input_grads ) != len ( inputs ) : <NEWLINE> <TAB> raise ValueError ( ( <STRING> + <NEWLINE> <STRING> ) % str ( node . op ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> input_grads = list ( input_grads ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for inp_idx in range ( len ( input_grads ) ) : <NEWLINE> <TAB> for out_idx in range ( len ( ograd_is_nan ) ) : <NEWLINE> <TAB> if ( ograd_is_nan [ out_idx ] and <NEWLINE> connection_pattern [ inp_idx ] [ out_idx ] and <NEWLINE> not isinstance ( input_grads [ inp_idx ] . type , <NEWLINE> DisconnectedType ) ) : <NEWLINE> <TAB> input_grads [ inp_idx ] = output_grads [ out_idx ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> only_connected_to_int = [ <NEWLINE> ( True not in <NEWLINE> [ in_to_out and out_to_cost and not out_int <NEWLINE> for in_to_out , out_to_cost , out_int in <NEWLINE> zip ( in_to_outs , outputs_connected , output_is_int ) ] ) <NEWLINE> for in_to_outs in connection_pattern ] <NEWLINE> <NEWLINE> for i , term in enumerate ( input_grads ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if term is None : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> raise TypeError ( <NEWLINE> ( <STRING> + <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) % node . op ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if hasattr ( term , <STRING> ) : <NEWLINE> <TAB> orig_ipt = inputs [ i ] <NEWLINE> for orig_ipt_v , term_v in get_debug_values ( orig_ipt , term ) : <NEWLINE> <TAB> i_shape = orig_ipt_v . shape <NEWLINE> t_shape = term_v . shape <NEWLINE> if i_shape != t_shape : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % ( node . op , t_shape , i , i_shape ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if not isinstance ( term . type , <NEWLINE> ( NullType , DisconnectedType ) ) : <NEWLINE> <TAB> if term . type . dtype not in theano . tensor . float_dtypes : <NEWLINE> <TAB> raise TypeError ( str ( node . op ) + <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % ( <NEWLINE> i , term . type . dtype ) ) <NEWLINE> <NEWLINE> <UNTAB> if only_connected_to_nan [ i ] : <NEWLINE> <TAB> assert isinstance ( term . type , NullType ) <NEWLINE> <NEWLINE> <UNTAB> if only_connected_to_int [ i ] : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> is_zero = _is_zero ( term ) <NEWLINE> assert is_zero in [ <STRING> , <STRING> , <STRING> ] <NEWLINE> if is_zero == <STRING> : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> msg %= ( node . op , term , type ( term ) , i ) <NEWLINE> <NEWLINE> <UNTAB> elif is_zero == <STRING> : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> msg %= ( node . op , term , type ( term ) , i , <NEWLINE> theano . get_scalar_constant_value ( term ) ) <NEWLINE> <NEWLINE> raise ValueError ( msg ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> for i , ( ipt , ig , connected ) in enumerate ( <NEWLINE> zip ( inputs , input_grads , inputs_connected ) <NEWLINE> ) : <NEWLINE> <TAB> actually_connected = not isinstance ( ig . type , DisconnectedType ) <NEWLINE> <NEWLINE> if actually_connected and not connected : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> msg %= ( str ( node . op ) , str ( ig ) , str ( ig . type ) , i ) <NEWLINE> raise TypeError ( msg ) <NEWLINE> <NEWLINE> <UNTAB> elif connected and not actually_connected : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> msg %= ( str ( node . op ) , i ) <NEWLINE> if hasattr ( node . op , <STRING> ) : <NEWLINE> <TAB> msg += ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> raise TypeError ( msg ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> msg += ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> warnings . warn ( msg ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> term_dict [ node ] = input_grads <NEWLINE> <NEWLINE> <UNTAB> return term_dict [ node ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> def access_grad_cache ( var ) : <NEWLINE> <TAB> if var not in grad_dict : <NEWLINE> <NEWLINE> <TAB> if var in var_to_app_to_idx : <NEWLINE> <TAB> null_terms = [ ] <NEWLINE> terms = [ ] <NEWLINE> node_to_idx = var_to_app_to_idx [ var ] <NEWLINE> for node in node_to_idx : <NEWLINE> <TAB> for idx in node_to_idx [ node ] : <NEWLINE> <NEWLINE> <TAB> term = access_term_cache ( node ) [ idx ] <NEWLINE> <NEWLINE> if not isinstance ( term , gof . Variable ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ( str ( node . op ) , <NEWLINE> type ( term ) ) ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( term . type , NullType ) : <NEWLINE> <TAB> null_terms . append ( term ) <NEWLINE> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( term . type , DisconnectedType ) : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> if hasattr ( var , <STRING> ) and term . ndim != var . ndim : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> ( <STRING> <NEWLINE> <STRING> ) % ( <NEWLINE> str ( node . op ) , term . ndim , var . ndim ) ) <NEWLINE> <NEWLINE> <UNTAB> terms . append ( term ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if len ( null_terms ) > <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> grad_dict [ var ] = null_terms [ <NUMBER> ] <NEWLINE> <UNTAB> elif len ( terms ) > <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> grad_dict [ var ] = reduce ( lambda x , y : x + y , terms ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> grad_dict [ var ] = disconnected_type ( ) <NEWLINE> <NEWLINE> <UNTAB> if cost_name is not None and var . name is not None : <NEWLINE> <TAB> grad_dict [ var ] . name = <STRING> % ( cost_name , var . name ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> grad_dict [ var ] = disconnected_type ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return grad_dict [ var ] <NEWLINE> <NEWLINE> <UNTAB> rval = [ access_grad_cache ( elem ) for elem in wrt ] <NEWLINE> <NEWLINE> return rval <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def unformat_identifiers ( self , identifiers ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> r = self . _r_identifiers <NEWLINE> return [ self . _unescape_identifier ( i ) <NEWLINE> for i in [ a or b for a , b in r . findall ( identifiers ) ] ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def expand_dims ( x , axis = - <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return tf . expand_dims ( x , axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def transform ( self , X ) : <NEWLINE> <TAB> <NEWLINE> check_is_fitted ( self , <STRING> , <STRING> ) <NEWLINE> X = check_array ( X , accept_sparse = ( <STRING> , <STRING> ) , copy = self . copy , <NEWLINE> estimator = self , dtype = FLOAT_DTYPES , <NEWLINE> force_all_finite = <STRING> ) <NEWLINE> <NEWLINE> if sparse . issparse ( X ) : <NEWLINE> <TAB> if self . with_scaling : <NEWLINE> <TAB> inplace_column_scale ( X , <NUMBER> / self . scale_ ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if self . with_centering : <NEWLINE> <TAB> X -= self . center_ <NEWLINE> <UNTAB> if self . with_scaling : <NEWLINE> <TAB> X /= self . scale_ <NEWLINE> <UNTAB> <UNTAB> return X <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _distinct_impl ( expr , op , ** kw ) : <NEWLINE> <TAB> <NEWLINE> return UnaryExpression ( expr , operator = operators . distinct_op , <NEWLINE> type_ = expr . type ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def check_docstring_parameters ( func , doc = None , ignore = None , class_name = None ) : <NEWLINE> <TAB> <NEWLINE> from numpydoc import docscrape <NEWLINE> incorrect = [ ] <NEWLINE> ignore = [ ] if ignore is None else ignore <NEWLINE> <NEWLINE> func_name = _get_func_name ( func , class_name = class_name ) <NEWLINE> if ( not func_name . startswith ( <STRING> ) or <NEWLINE> func_name . startswith ( <STRING> ) ) : <NEWLINE> <TAB> return incorrect <NEWLINE> <NEWLINE> <UNTAB> if inspect . isdatadescriptor ( func ) : <NEWLINE> <TAB> return incorrect <NEWLINE> <NEWLINE> <UNTAB> if func_name . split ( <STRING> ) [ - <NUMBER> ] in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> return incorrect <NEWLINE> <NEWLINE> <UNTAB> if func_name . split ( <STRING> ) [ <NUMBER> ] == <STRING> : <NEWLINE> <TAB> return incorrect <NEWLINE> <UNTAB> args = list ( filter ( lambda x : x not in ignore , _get_args ( func ) ) ) <NEWLINE> <NEWLINE> if len ( args ) > <NUMBER> and args [ <NUMBER> ] == <STRING> : <NEWLINE> <TAB> args . remove ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if doc is None : <NEWLINE> <TAB> with warnings . catch_warnings ( record = True ) as w : <NEWLINE> <TAB> try : <NEWLINE> <TAB> doc = docscrape . FunctionDoc ( func ) <NEWLINE> <UNTAB> except Exception as exp : <NEWLINE> <TAB> incorrect += [ func_name + <STRING> + str ( exp ) ] <NEWLINE> return incorrect <NEWLINE> <UNTAB> <UNTAB> if len ( w ) : <NEWLINE> <TAB> raise RuntimeError ( <STRING> % ( func_name , w [ <NUMBER> ] ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> param_names = [ ] <NEWLINE> for name , type_definition , param_doc in doc [ <STRING> ] : <NEWLINE> <TAB> if not type_definition . strip ( ) : <NEWLINE> <TAB> if <STRING> in name and name [ : name . index ( <STRING> ) ] [ - <NUMBER> : ] . strip ( ) : <NEWLINE> <TAB> incorrect += [ func_name + <NEWLINE> <STRING> <NEWLINE> <STRING> % name ] <NEWLINE> <UNTAB> elif name . rstrip ( ) . endswith ( <STRING> ) : <NEWLINE> <TAB> incorrect += [ func_name + <NEWLINE> <STRING> <NEWLINE> <STRING> % ( name . lstrip ( ) ) ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if <STRING> not in name : <NEWLINE> <TAB> param_names . append ( name . split ( <STRING> ) [ <NUMBER> ] . strip ( <STRING> ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> param_names = list ( filter ( lambda x : x not in ignore , param_names ) ) <NEWLINE> <NEWLINE> if len ( param_names ) != len ( args ) : <NEWLINE> <TAB> bad = str ( sorted ( list ( set ( param_names ) ^ set ( args ) ) ) ) <NEWLINE> incorrect += [ func_name + <STRING> + bad ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for n1 , n2 in zip ( param_names , args ) : <NEWLINE> <TAB> if n1 != n2 : <NEWLINE> <TAB> incorrect += [ func_name + <STRING> + n1 + <STRING> + n2 ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return incorrect <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _define_maximization_operation ( self , num_batches ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> with ops . control_dependencies ( self . _w ) : <NEWLINE> <TAB> points_in_k = array_ops . squeeze ( <NEWLINE> math_ops . add_n ( self . _points_in_k ) , axis = [ <NUMBER> ] ) <NEWLINE> <NEWLINE> if <STRING> in self . _params : <NEWLINE> <TAB> final_points_in_k = points_in_k / num_batches <NEWLINE> num_examples = math_ops . to_float ( math_ops . reduce_sum ( final_points_in_k ) ) <NEWLINE> self . _alpha_op = self . _alpha . assign ( final_points_in_k / <NEWLINE> ( num_examples + MEPS ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _alpha_op = control_flow_ops . no_op ( ) <NEWLINE> <UNTAB> self . _train_ops = [ self . _alpha_op ] <NEWLINE> <NEWLINE> <NEWLINE> points_in_k_expanded = array_ops . reshape ( points_in_k , <NEWLINE> [ self . _num_classes , <NUMBER> , <NUMBER> ] ) <NEWLINE> if <STRING> in self . _params : <NEWLINE> <TAB> self . _means_op = self . _means . assign ( <NEWLINE> math_ops . div ( <NEWLINE> math_ops . add_n ( self . _w_mul_x ) , points_in_k_expanded + MEPS ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _means_op = control_flow_ops . no_op ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> with ops . control_dependencies ( [ self . _means_op ] ) : <NEWLINE> <TAB> b = math_ops . add_n ( self . _w_mul_x2 ) / ( points_in_k_expanded + MEPS ) <NEWLINE> new_covs = [ ] <NEWLINE> for k in range ( self . _num_classes ) : <NEWLINE> <TAB> mean = self . _means . value ( ) [ k , : , : ] <NEWLINE> square_mean = math_ops . matmul ( mean , mean , transpose_a = True ) <NEWLINE> new_cov = b [ k , : , : ] - square_mean + self . _min_var <NEWLINE> if self . _covariance_type == FULL_COVARIANCE : <NEWLINE> <TAB> new_covs . append ( array_ops . expand_dims ( new_cov , <NUMBER> ) ) <NEWLINE> <UNTAB> elif self . _covariance_type == DIAG_COVARIANCE : <NEWLINE> <TAB> new_covs . append ( <NEWLINE> array_ops . expand_dims ( array_ops . diag_part ( new_cov ) , <NUMBER> ) ) <NEWLINE> <UNTAB> <UNTAB> new_covs = array_ops . concat ( new_covs , <NUMBER> ) <NEWLINE> if <STRING> in self . _params : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> with ops . control_dependencies ( [ self . _means_op , new_covs ] ) : <NEWLINE> <TAB> self . _train_ops . append ( <NEWLINE> state_ops . assign ( <NEWLINE> self . _covs , new_covs , validate_shape = False ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __array_wrap__ ( self , result , context = None ) : <NEWLINE> <TAB> <NEWLINE> return self . _constructor ( result , index = self . index , <NEWLINE> copy = False ) . __finalize__ ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _copy_fields ( ary ) : <NEWLINE> <TAB> <NEWLINE> dt = ary . dtype <NEWLINE> copy_dtype = { <STRING> : dt . names , <NEWLINE> <STRING> : [ dt . fields [ name ] [ <NUMBER> ] for name in dt . names ] } <NEWLINE> return array ( ary , dtype = copy_dtype , copy = True ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __new__ ( cls , subtype = None ) : <NEWLINE> <TAB> <NEWLINE> from pandas . core . dtypes . common import ( <NEWLINE> is_categorical_dtype , is_string_dtype , pandas_dtype ) <NEWLINE> <NEWLINE> if isinstance ( subtype , IntervalDtype ) : <NEWLINE> <TAB> return subtype <NEWLINE> <UNTAB> elif subtype is None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> u = object . __new__ ( cls ) <NEWLINE> u . subtype = None <NEWLINE> return u <NEWLINE> <UNTAB> elif ( isinstance ( subtype , compat . string_types ) and <NEWLINE> subtype . lower ( ) == <STRING> ) : <NEWLINE> <TAB> subtype = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if isinstance ( subtype , compat . string_types ) : <NEWLINE> <TAB> m = cls . _match . search ( subtype ) <NEWLINE> if m is not None : <NEWLINE> <TAB> subtype = m . group ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> try : <NEWLINE> <TAB> subtype = pandas_dtype ( subtype ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if is_categorical_dtype ( subtype ) or is_string_dtype ( subtype ) : <NEWLINE> <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> raise TypeError ( msg ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> return cls . _cache [ str ( subtype ) ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> u = object . __new__ ( cls ) <NEWLINE> u . subtype = subtype <NEWLINE> cls . _cache [ str ( subtype ) ] = u <NEWLINE> return u <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _replace_single ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return self if kwargs [ <STRING> ] else self . copy ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _is_memory_usage_qualified ( self ) : <NEWLINE> <TAB> <NEWLINE> def f ( l ) : <NEWLINE> <TAB> return <STRING> in l or <STRING> in l or <STRING> in l <NEWLINE> <UNTAB> return any ( f ( l ) for l in self . _inferred_type_levels ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , persistent = False , watch_accessed_variables = True ) : <NEWLINE> <TAB> <NEWLINE> self . _tape = None <NEWLINE> self . _persistent = persistent <NEWLINE> self . _watch_accessed_variables = watch_accessed_variables <NEWLINE> self . _recording = False <NEWLINE> self . _created_eagerly = context . executing_eagerly ( ) <NEWLINE> if self . _created_eagerly : <NEWLINE> <TAB> context . context ( ) . start_step ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_tightbbox ( self , renderer ) : <NEWLINE> <TAB> <NEWLINE> if not self . get_visible ( ) : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> ticks_to_draw = self . _update_ticks ( renderer ) <NEWLINE> <NEWLINE> self . _update_label_position ( renderer ) <NEWLINE> <NEWLINE> <NEWLINE> ticklabelBoxes , ticklabelBoxes2 = self . _get_tick_bboxes ( <NEWLINE> ticks_to_draw , renderer ) <NEWLINE> <NEWLINE> self . _update_offset_text_position ( ticklabelBoxes , ticklabelBoxes2 ) <NEWLINE> self . offsetText . set_text ( self . major . formatter . get_offset ( ) ) <NEWLINE> <NEWLINE> bb = [ ] <NEWLINE> <NEWLINE> for a in [ self . label , self . offsetText ] : <NEWLINE> <TAB> bbox = a . get_window_extent ( renderer ) <NEWLINE> if ( np . isfinite ( bbox . width ) and np . isfinite ( bbox . height ) and <NEWLINE> a . get_visible ( ) ) : <NEWLINE> <TAB> bb . append ( bbox ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> bb . extend ( ticklabelBoxes ) <NEWLINE> bb . extend ( ticklabelBoxes2 ) <NEWLINE> <NEWLINE> bb = [ b for b in bb if b . width != <NUMBER> or b . height != <NUMBER> ] <NEWLINE> if bb : <NEWLINE> <TAB> _bbox = mtransforms . Bbox . union ( bb ) <NEWLINE> return _bbox <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def compare_and_bitpack ( input , threshold , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , threshold = threshold , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , input , <NEWLINE> threshold ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return compare_and_bitpack_eager_fallback ( <NEWLINE> input , threshold , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , a , b , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> ( da , db ) = ( getdata ( a ) , getdata ( b ) ) <NEWLINE> <NEWLINE> with np . errstate ( ) : <NEWLINE> <TAB> np . seterr ( divide = <STRING> , invalid = <STRING> ) <NEWLINE> result = self . f ( da , db , * args , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> ( ma , mb ) = ( getmask ( a ) , getmask ( b ) ) <NEWLINE> if ma is nomask : <NEWLINE> <TAB> if mb is nomask : <NEWLINE> <TAB> m = nomask <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> m = umath . logical_or ( getmaskarray ( a ) , mb ) <NEWLINE> <UNTAB> <UNTAB> elif mb is nomask : <NEWLINE> <TAB> m = umath . logical_or ( ma , getmaskarray ( b ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> m = umath . logical_or ( ma , mb ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if not result . ndim : <NEWLINE> <TAB> if m : <NEWLINE> <TAB> return masked <NEWLINE> <UNTAB> return result <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if m is not nomask and m . any ( ) : <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> np . copyto ( result , da , casting = <STRING> , where = m ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> masked_result = result . view ( get_masked_subclass ( a , b ) ) <NEWLINE> masked_result . _mask = m <NEWLINE> if isinstance ( a , MaskedArray ) : <NEWLINE> <TAB> masked_result . _update_from ( a ) <NEWLINE> <UNTAB> elif isinstance ( b , MaskedArray ) : <NEWLINE> <TAB> masked_result . _update_from ( b ) <NEWLINE> <UNTAB> return masked_result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _node_value ( G , node_attr ) : <NEWLINE> <TAB> <NEWLINE> if node_attr is None : <NEWLINE> <TAB> def value ( u ) : return u <NEWLINE> <UNTAB> elif not hasattr ( node_attr , <STRING> ) : <NEWLINE> <NEWLINE> <TAB> def value ( u ) : return G . nodes [ u ] [ node_attr ] <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> value = node_attr <NEWLINE> <NEWLINE> <UNTAB> return value <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> def to_prufer_sequence ( T ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> n = len ( T ) <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise nx . NetworkXPointlessConcept ( msg ) <NEWLINE> <UNTAB> if not nx . is_tree ( T ) : <NEWLINE> <TAB> raise nx . NotATree ( <STRING> ) <NEWLINE> <UNTAB> if set ( T ) != set ( range ( n ) ) : <NEWLINE> <TAB> raise KeyError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> degree = dict ( T . degree ( ) ) <NEWLINE> <NEWLINE> def parents ( u ) : <NEWLINE> <TAB> return next ( v for v in T [ u ] if degree [ v ] > <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> index = u = min ( k for k in range ( n ) if degree [ k ] == <NUMBER> ) <NEWLINE> result = [ ] <NEWLINE> for i in range ( n - <NUMBER> ) : <NEWLINE> <TAB> v = parents ( u ) <NEWLINE> result . append ( v ) <NEWLINE> degree [ v ] -= <NUMBER> <NEWLINE> if v < index and degree [ v ] == <NUMBER> : <NEWLINE> <TAB> u = v <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> index = u = min ( k for k in range ( index + <NUMBER> , n ) if degree [ k ] == <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _to_unmasked_float_array ( x ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( x , <STRING> ) : <NEWLINE> <TAB> return np . ma . asarray ( x , float ) . filled ( np . nan ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return np . asarray ( x , float ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def score ( self , x , y , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> y = np . searchsorted ( self . classes_ , y ) <NEWLINE> kwargs = self . filter_sk_params ( Sequential . evaluate , kwargs ) <NEWLINE> <NEWLINE> loss_name = self . model . loss <NEWLINE> if hasattr ( loss_name , <STRING> ) : <NEWLINE> <TAB> loss_name = loss_name . __name__ <NEWLINE> <UNTAB> if loss_name == <STRING> and len ( y . shape ) != <NUMBER> : <NEWLINE> <TAB> y = to_categorical ( y ) <NEWLINE> <NEWLINE> <UNTAB> outputs = self . model . evaluate ( x , y , ** kwargs ) <NEWLINE> if not isinstance ( outputs , list ) : <NEWLINE> <TAB> outputs = [ outputs ] <NEWLINE> <UNTAB> for name , output in zip ( self . model . metrics_names , outputs ) : <NEWLINE> <TAB> if name == <STRING> : <NEWLINE> <TAB> return output <NEWLINE> <UNTAB> <UNTAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def instance_logger ( instance , echoflag = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if instance . logging_name : <NEWLINE> <TAB> name = <STRING> % ( instance . __class__ . __module__ , <NEWLINE> instance . __class__ . __name__ , <NEWLINE> instance . logging_name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> name = <STRING> % ( instance . __class__ . __module__ , <NEWLINE> instance . __class__ . __name__ ) <NEWLINE> <NEWLINE> <UNTAB> instance . _echo = echoflag <NEWLINE> <NEWLINE> if echoflag in ( False , None ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> logger = logging . getLogger ( name ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> logger = InstanceLogger ( echoflag , name ) <NEWLINE> <NEWLINE> <UNTAB> instance . logger = logger <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ vectorize ( <NUMBER> ) <NEWLINE> def odesimp ( eq , func , order , constants , hint ) : <NEWLINE> <TAB> <NEWLINE> x = func . args [ <NUMBER> ] <NEWLINE> f = func . func <NEWLINE> C1 = get_numbered_constants ( eq , num = <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> eq = _handle_Integral ( eq , func , order , hint ) <NEWLINE> if hint . startswith ( <STRING> ) : <NEWLINE> <TAB> eq = simplify ( eq ) <NEWLINE> <UNTAB> if not isinstance ( eq , Equality ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> eq = constantsimp ( eq , constants ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if eq . rhs == func and not eq . lhs . has ( func ) : <NEWLINE> <TAB> eq = [ Eq ( eq . rhs , eq . lhs ) ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if eq . lhs == func and not eq . rhs . has ( func ) : <NEWLINE> <NEWLINE> <TAB> eq = [ eq ] <NEWLINE> <NEWLINE> <NEWLINE> if hint . startswith ( <STRING> ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> global collectterms <NEWLINE> try : <NEWLINE> <TAB> collectterms . sort ( key = default_sort_key ) <NEWLINE> collectterms . reverse ( ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> assert len ( eq ) == <NUMBER> and eq [ <NUMBER> ] . lhs == f ( x ) <NEWLINE> sol = eq [ <NUMBER> ] . rhs <NEWLINE> sol = expand_mul ( sol ) <NEWLINE> for i , reroot , imroot in collectterms : <NEWLINE> <TAB> sol = collect ( sol , x ** i * exp ( reroot * x ) * sin ( abs ( imroot ) * x ) ) <NEWLINE> sol = collect ( sol , x ** i * exp ( reroot * x ) * cos ( imroot * x ) ) <NEWLINE> <UNTAB> for i , reroot , imroot in collectterms : <NEWLINE> <TAB> sol = collect ( sol , x ** i * exp ( reroot * x ) ) <NEWLINE> <UNTAB> del collectterms <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> sol = powsimp ( sol ) <NEWLINE> <NEWLINE> eq [ <NUMBER> ] = Eq ( f ( x ) , sol ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> floats = any ( i . is_Float for i in eq . atoms ( Number ) ) <NEWLINE> eqsol = solve ( eq , func , force = True , rational = False if floats else None ) <NEWLINE> if not eqsol : <NEWLINE> <TAB> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> except ( NotImplementedError , PolynomialError ) : <NEWLINE> <TAB> eq = [ eq ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> def _expand ( expr ) : <NEWLINE> <TAB> numer , denom = expr . as_numer_denom ( ) <NEWLINE> <NEWLINE> if denom . is_Add : <NEWLINE> <TAB> return expr <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return powsimp ( expr . expand ( ) , combine = <STRING> , deep = True ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> eq = [ Eq ( f ( x ) , _expand ( t ) ) for t in eqsol ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if hint . startswith ( <STRING> ) : <NEWLINE> <TAB> for j , eqi in enumerate ( eq ) : <NEWLINE> <TAB> newi = logcombine ( eqi , force = True ) <NEWLINE> if isinstance ( newi . lhs , log ) and newi . rhs == <NUMBER> : <NEWLINE> <TAB> newi = Eq ( newi . lhs . args [ <NUMBER> ] / C1 , C1 ) <NEWLINE> <UNTAB> eq [ j ] = newi <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> for i , eqi in enumerate ( eq ) : <NEWLINE> <TAB> eq [ i ] = constantsimp ( eqi , constants ) <NEWLINE> eq [ i ] = constant_renumber ( eq [ i ] , <STRING> , <NUMBER> , <NUMBER> * order ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if len ( eq ) == <NUMBER> : <NEWLINE> <TAB> eq = eq [ <NUMBER> ] <NEWLINE> <UNTAB> return eq <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _updated_ctor_param ( self ) : <NEWLINE> <TAB> <NEWLINE> dct = self . _ctor_param . copy ( ) <NEWLINE> dct [ <STRING> ] = self . a <NEWLINE> dct [ <STRING> ] = self . b <NEWLINE> dct [ <STRING> ] = self . badvalue <NEWLINE> dct [ <STRING> ] = self . moment_tol <NEWLINE> dct [ <STRING> ] = self . inc <NEWLINE> dct [ <STRING> ] = self . name <NEWLINE> dct [ <STRING> ] = self . shapes <NEWLINE> dct [ <STRING> ] = self . extradoc <NEWLINE> return dct <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_sprites_from_layer ( self , layer ) : <NEWLINE> <TAB> <NEWLINE> sprites = [ ] <NEWLINE> sprites_append = sprites . append <NEWLINE> sprite_layers = self . _spritelayers <NEWLINE> for spr in self . _spritelist : <NEWLINE> <TAB> if sprite_layers [ spr ] == layer : <NEWLINE> <TAB> sprites_append ( spr ) <NEWLINE> <UNTAB> elif sprite_layers [ spr ] > layer : <NEWLINE> <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> return sprites <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def getfullargspec ( func ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return inspect . getfullargspec ( func ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> arg_spec = inspect . getargspec ( func ) <NEWLINE> return full_argspec_type ( args = arg_spec . args , <NEWLINE> varargs = arg_spec . varargs , <NEWLINE> varkw = arg_spec . keywords , <NEWLINE> defaults = arg_spec . defaults , <NEWLINE> kwonlyargs = [ ] , <NEWLINE> kwonlydefaults = None , <NEWLINE> annotations = { } ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_scalar_nan ( x ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> return bool ( isinstance ( x , ( numbers . Real , np . floating ) ) and np . isnan ( x ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_unordered ( self , inplace = False ) : <NEWLINE> <TAB> <NEWLINE> inplace = validate_bool_kwarg ( inplace , <STRING> ) <NEWLINE> return self . set_ordered ( False , inplace = inplace ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> def duplication_divergence_graph ( n , p , seed = None ) : <NEWLINE> <TAB> <NEWLINE> if p > <NUMBER> or p < <NUMBER> : <NEWLINE> <TAB> msg = <STRING> . format ( p ) <NEWLINE> raise nx . NetworkXError ( msg ) <NEWLINE> <UNTAB> if n < <NUMBER> : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise nx . NetworkXError ( msg ) <NEWLINE> <NEWLINE> <UNTAB> G = nx . Graph ( ) <NEWLINE> <NEWLINE> <NEWLINE> G . add_edge ( <NUMBER> , <NUMBER> ) <NEWLINE> i = <NUMBER> <NEWLINE> while i < n : <NEWLINE> <NEWLINE> <TAB> random_node = seed . choice ( list ( G ) ) <NEWLINE> <NEWLINE> G . add_node ( i ) <NEWLINE> <NEWLINE> flag = False <NEWLINE> for nbr in G . neighbors ( random_node ) : <NEWLINE> <TAB> if seed . random ( ) < p : <NEWLINE> <NEWLINE> <TAB> G . add_edge ( i , nbr ) <NEWLINE> flag = True <NEWLINE> <UNTAB> <UNTAB> if not flag : <NEWLINE> <NEWLINE> <TAB> G . remove_node ( i ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> i += <NUMBER> <NEWLINE> <UNTAB> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_constant ( self , * wrt , ** flags ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> simplify = flags . get ( <STRING> , True ) <NEWLINE> <NEWLINE> if self . is_number : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> free = self . free_symbols <NEWLINE> if not free : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> wrt = set ( wrt ) <NEWLINE> if wrt and not wrt & free : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> wrt = wrt or free <NEWLINE> <NEWLINE> <NEWLINE> expr = self <NEWLINE> if simplify : <NEWLINE> <TAB> expr = expr . simplify ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if expr . is_zero : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> failing_number = None <NEWLINE> if wrt == free : <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> a = expr . subs ( list ( zip ( free , [ <NUMBER> ] * len ( free ) ) ) , <NEWLINE> simultaneous = True ) <NEWLINE> if a is S . NaN : <NEWLINE> <NEWLINE> <TAB> a = expr . _random ( None , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> except ZeroDivisionError : <NEWLINE> <TAB> a = None <NEWLINE> <UNTAB> if a is not None and a is not S . NaN : <NEWLINE> <TAB> try : <NEWLINE> <TAB> b = expr . subs ( list ( zip ( free , [ <NUMBER> ] * len ( free ) ) ) , <NEWLINE> simultaneous = True ) <NEWLINE> if b is S . NaN : <NEWLINE> <NEWLINE> <TAB> b = expr . _random ( None , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> except ZeroDivisionError : <NEWLINE> <TAB> b = None <NEWLINE> <UNTAB> if b is not None and b is not S . NaN and b . equals ( a ) is False : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> b = expr . _random ( None , - <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) <NEWLINE> if b is not None and b is not S . NaN and b . equals ( a ) is False : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> b = expr . _random ( ) <NEWLINE> if b is not None and b is not S . NaN : <NEWLINE> <TAB> if b . equals ( a ) is False : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> failing_number = a if a . is_number else b <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> for w in wrt : <NEWLINE> <TAB> deriv = expr . diff ( w ) <NEWLINE> if simplify : <NEWLINE> <TAB> deriv = deriv . simplify ( ) <NEWLINE> <UNTAB> if deriv != <NUMBER> : <NEWLINE> <TAB> if not ( pure_complex ( deriv , or_real = True ) ) : <NEWLINE> <TAB> if flags . get ( <STRING> , False ) : <NEWLINE> <TAB> return failing_number <NEWLINE> <UNTAB> elif deriv . free_symbols : <NEWLINE> <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> return False <NEWLINE> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_s3_url ( url ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return parse_url ( url ) . scheme in [ <STRING> , <STRING> , <STRING> ] <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def conv2d ( input , filter , strides , padding , use_cudnn_on_gpu = True , data_format = <STRING> , dilations = [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if not isinstance ( strides , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % strides ) <NEWLINE> <UNTAB> strides = [ _execute . make_int ( _i , <STRING> ) for _i in strides ] <NEWLINE> padding = _execute . make_str ( padding , <STRING> ) <NEWLINE> if use_cudnn_on_gpu is None : <NEWLINE> <TAB> use_cudnn_on_gpu = True <NEWLINE> <UNTAB> use_cudnn_on_gpu = _execute . make_bool ( use_cudnn_on_gpu , <STRING> ) <NEWLINE> if data_format is None : <NEWLINE> <TAB> data_format = <STRING> <NEWLINE> <UNTAB> data_format = _execute . make_str ( data_format , <STRING> ) <NEWLINE> if dilations is None : <NEWLINE> <TAB> dilations = [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] <NEWLINE> <UNTAB> if not isinstance ( dilations , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % dilations ) <NEWLINE> <UNTAB> dilations = [ _execute . make_int ( _i , <STRING> ) for _i in dilations ] <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , filter = filter , strides = strides , <NEWLINE> padding = padding , use_cudnn_on_gpu = use_cudnn_on_gpu , <NEWLINE> data_format = data_format , dilations = dilations , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) , <NEWLINE> <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , input , filter , <STRING> , strides , <NEWLINE> <STRING> , use_cudnn_on_gpu , <STRING> , padding , <NEWLINE> <STRING> , data_format , <STRING> , dilations ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return conv2d_eager_fallback ( <NEWLINE> input , filter , strides = strides , use_cudnn_on_gpu = use_cudnn_on_gpu , <NEWLINE> padding = padding , data_format = data_format , dilations = dilations , <NEWLINE> name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def ignore ( self , event ) : <NEWLINE> <TAB> <NEWLINE> if not self . active or not self . ax . get_visible ( ) : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if not self . canvas . widgetlock . available ( self ) : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <UNTAB> if not hasattr ( event , <STRING> ) : <NEWLINE> <TAB> event . button = None <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . validButtons is not None : <NEWLINE> <TAB> if event . button not in self . validButtons : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if self . eventpress is None : <NEWLINE> <TAB> return event . inaxes != self . ax <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if event . button == self . eventpress . button : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return ( event . inaxes != self . ax or <NEWLINE> event . button != self . eventpress . button ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_url ( filename ) : <NEWLINE> <TAB> <NEWLINE> return ( isinstance ( filename , six . string_types ) and <NEWLINE> URL_REGEX . match ( filename ) is not None ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def decode ( a , encoding = None , errors = None ) : <NEWLINE> <TAB> <NEWLINE> return _to_string_or_unicode_array ( <NEWLINE> _vec_string ( a , object_ , <STRING> , _clean_args ( encoding , errors ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_str ( self ) : <NEWLINE> <TAB> <NEWLINE> return ( ( str ( self . value ) . split ( <STRING> , <NUMBER> ) [ <NUMBER> ] ) if ( self . _type != <NUMBER> ) <NEWLINE> else <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def c_code_template ( dtype ) : <NEWLINE> <TAB> init_decl = <NEWLINE> <NEWLINE> begin_row_loop = <NEWLINE> <NEWLINE> inside_row_loop = <NEWLINE> end_row_loop = <NEWLINE> return ( init_decl , begin_row_loop , inside_row_loop , end_row_loop ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def on_attach ( self , fgraph ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> already_there = False <NEWLINE> if self . fgraph is fgraph : <NEWLINE> <TAB> already_there = True <NEWLINE> <UNTAB> if self . fgraph is not None : <NEWLINE> <TAB> raise Exception ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> for attr in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> if hasattr ( fgraph , attr ) : <NEWLINE> <TAB> already_there = True <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if already_there : <NEWLINE> <NEWLINE> <TAB> raise toolbox . AlreadyThere ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . unpickle ( fgraph ) <NEWLINE> fgraph . destroy_handler = self <NEWLINE> <NEWLINE> self . fgraph = fgraph <NEWLINE> self . destroyers = OrderedSet ( ) <NEWLINE> self . view_i = { } <NEWLINE> self . view_o = { } <NEWLINE> <NEWLINE> self . clients = OrderedDict ( ) <NEWLINE> self . stale_droot = True <NEWLINE> <NEWLINE> self . debug_all_apps = set ( ) <NEWLINE> if self . do_imports_on_attach : <NEWLINE> <TAB> toolbox . Bookkeeper . on_attach ( self , fgraph ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def rvs ( self , df , scale , size = <NUMBER> , random_state = None ) : <NEWLINE> <TAB> <NEWLINE> n , shape = self . _process_size ( size ) <NEWLINE> dim , df , scale = self . _process_parameters ( df , scale ) <NEWLINE> <NEWLINE> <NEWLINE> eye = np . eye ( dim ) <NEWLINE> L , lower = scipy . linalg . cho_factor ( scale , lower = True ) <NEWLINE> inv_scale = scipy . linalg . cho_solve ( ( L , lower ) , eye ) <NEWLINE> <NEWLINE> C = scipy . linalg . cholesky ( inv_scale , lower = True ) <NEWLINE> <NEWLINE> out = self . _rvs ( n , shape , dim , df , C , random_state ) <NEWLINE> <NEWLINE> return _squeeze_output ( out ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_exact ( self ) : <NEWLINE> <TAB> <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def provide_inputs ( self , node , inputs ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _get_default_annual_spacing ( nyears ) : <NEWLINE> <TAB> <NEWLINE> if nyears < <NUMBER> : <NEWLINE> <TAB> ( min_spacing , maj_spacing ) = ( <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> elif nyears < <NUMBER> : <NEWLINE> <TAB> ( min_spacing , maj_spacing ) = ( <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> elif nyears < <NUMBER> : <NEWLINE> <TAB> ( min_spacing , maj_spacing ) = ( <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> elif nyears < <NUMBER> : <NEWLINE> <TAB> ( min_spacing , maj_spacing ) = ( <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> elif nyears < <NUMBER> : <NEWLINE> <TAB> ( min_spacing , maj_spacing ) = ( <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> elif nyears < <NUMBER> : <NEWLINE> <TAB> ( min_spacing , maj_spacing ) = ( <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> factor = nyears // <NUMBER> + <NUMBER> <NEWLINE> ( min_spacing , maj_spacing ) = ( factor * <NUMBER> , factor * <NUMBER> ) <NEWLINE> <UNTAB> return ( min_spacing , maj_spacing ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def loads ( strg ) : <NEWLINE> <TAB> <NEWLINE> return pickle . loads ( strg ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def spatial_2d_padding ( x , padding = ( ( <NUMBER> , <NUMBER> ) , ( <NUMBER> , <NUMBER> ) ) , data_format = None ) : <NEWLINE> <TAB> <NEWLINE> assert len ( padding ) == <NUMBER> <NEWLINE> assert len ( padding [ <NUMBER> ] ) == <NUMBER> <NEWLINE> assert len ( padding [ <NUMBER> ] ) == <NUMBER> <NEWLINE> if data_format is None : <NEWLINE> <TAB> data_format = image_data_format ( ) <NEWLINE> <UNTAB> if data_format not in { <STRING> , <STRING> } : <NEWLINE> <TAB> raise ValueError ( <STRING> + str ( data_format ) ) <NEWLINE> <NEWLINE> <UNTAB> if data_format == <STRING> : <NEWLINE> <TAB> pattern = [ [ <NUMBER> , <NUMBER> ] , [ <NUMBER> , <NUMBER> ] , list ( padding [ <NUMBER> ] ) , list ( padding [ <NUMBER> ] ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pattern = [ [ <NUMBER> , <NUMBER> ] , list ( padding [ <NUMBER> ] ) , list ( padding [ <NUMBER> ] ) , [ <NUMBER> , <NUMBER> ] ] <NEWLINE> <UNTAB> return array_ops . pad ( x , pattern ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def __RandomState_ctor ( ) : <NEWLINE> <TAB> <NEWLINE> return RandomState ( seed = <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def distribute ( A , B ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def distribute_rl ( expr ) : <NEWLINE> <TAB> for i , arg in enumerate ( expr . args ) : <NEWLINE> <TAB> if isinstance ( arg , B ) : <NEWLINE> <TAB> first , b , tail = expr . args [ : i ] , expr . args [ i ] , expr . args [ i + <NUMBER> : ] <NEWLINE> return B ( * [ A ( * ( first + ( arg , ) + tail ) ) for arg in b . args ] ) <NEWLINE> <UNTAB> <UNTAB> return expr <NEWLINE> <UNTAB> return distribute_rl <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def distance_matrix ( x , y , p = <NUMBER> , threshold = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> x = np . asarray ( x ) <NEWLINE> m , k = x . shape <NEWLINE> y = np . asarray ( y ) <NEWLINE> n , kk = y . shape <NEWLINE> <NEWLINE> if k != kk : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( k , kk ) ) <NEWLINE> <NEWLINE> <UNTAB> if m * n * k <= threshold : <NEWLINE> <TAB> return minkowski_distance ( x [ : , np . newaxis , : ] , y [ np . newaxis , : , : ] , p ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result = np . empty ( ( m , n ) , dtype = float ) <NEWLINE> if m < n : <NEWLINE> <TAB> for i in range ( m ) : <NEWLINE> <TAB> result [ i , : ] = minkowski_distance ( x [ i ] , y , p ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for j in range ( n ) : <NEWLINE> <TAB> result [ : , j ] = minkowski_distance ( x , y [ j ] , p ) <NEWLINE> <UNTAB> <UNTAB> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def hessenberg ( a , calc_q = False , overwrite_a = False , check_finite = True ) : <NEWLINE> <TAB> <NEWLINE> a1 = _asarray_validated ( a , check_finite = check_finite ) <NEWLINE> if len ( a1 . shape ) != <NUMBER> or ( a1 . shape [ <NUMBER> ] != a1 . shape [ <NUMBER> ] ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> overwrite_a = overwrite_a or ( _datacopied ( a1 , a ) ) <NEWLINE> <NEWLINE> <NEWLINE> if a1 . shape [ <NUMBER> ] <= <NUMBER> : <NEWLINE> <TAB> if calc_q : <NEWLINE> <TAB> return a1 , numpy . eye ( a1 . shape [ <NUMBER> ] ) <NEWLINE> <UNTAB> return a1 <NEWLINE> <NEWLINE> <UNTAB> gehrd , gebal , gehrd_lwork = get_lapack_funcs ( ( <STRING> , <STRING> , <NEWLINE> <STRING> ) , ( a1 , ) ) <NEWLINE> ba , lo , hi , pivscale , info = gebal ( a1 , permute = <NUMBER> , overwrite_a = overwrite_a ) <NEWLINE> _check_info ( info , <STRING> , positive = False ) <NEWLINE> n = len ( a1 ) <NEWLINE> <NEWLINE> lwork = _compute_lwork ( gehrd_lwork , ba . shape [ <NUMBER> ] , lo = lo , hi = hi ) <NEWLINE> <NEWLINE> hq , tau , info = gehrd ( ba , lo = lo , hi = hi , lwork = lwork , overwrite_a = <NUMBER> ) <NEWLINE> _check_info ( info , <STRING> , positive = False ) <NEWLINE> h = numpy . triu ( hq , - <NUMBER> ) <NEWLINE> if not calc_q : <NEWLINE> <TAB> return h <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> orghr , orghr_lwork = get_lapack_funcs ( ( <STRING> , <STRING> ) , ( a1 , ) ) <NEWLINE> lwork = _compute_lwork ( orghr_lwork , n , lo = lo , hi = hi ) <NEWLINE> <NEWLINE> q , info = orghr ( a = hq , tau = tau , lo = lo , hi = hi , lwork = lwork , overwrite_a = <NUMBER> ) <NEWLINE> _check_info ( info , <STRING> , positive = False ) <NEWLINE> return h , q <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def betainc ( a , b , x , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , a = a , b = b , x = x , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , a , b , x ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return betainc_eager_fallback ( <NEWLINE> a , b , x , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _rank ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . shape . ndims <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_requirements ( self , fgraph ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _validate_targets ( self , y ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> self . class_weight_ = np . empty ( <NUMBER> ) <NEWLINE> return column_or_1d ( y , warn = True ) . astype ( np . float64 ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def prevprime ( n ) : <NEWLINE> <TAB> <NEWLINE> from sympy . functions . elementary . integers import ceiling <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> n = as_int ( ceiling ( n ) ) <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if n < <NUMBER> : <NEWLINE> <TAB> return { <NUMBER> : <NUMBER> , <NUMBER> : <NUMBER> , <NUMBER> : <NUMBER> , <NUMBER> : <NUMBER> , <NUMBER> : <NUMBER> } [ n ] <NEWLINE> <UNTAB> if n <= sieve . _list [ - <NUMBER> ] : <NEWLINE> <TAB> l , u = sieve . search ( n ) <NEWLINE> if l == u : <NEWLINE> <TAB> return sieve [ l - <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return sieve [ l ] <NEWLINE> <UNTAB> <UNTAB> nn = <NUMBER> * ( n // <NUMBER> ) <NEWLINE> if n - nn <= <NUMBER> : <NEWLINE> <TAB> n = nn - <NUMBER> <NEWLINE> if isprime ( n ) : <NEWLINE> <TAB> return n <NEWLINE> <UNTAB> n -= <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> n = nn + <NUMBER> <NEWLINE> <UNTAB> while <NUMBER> : <NEWLINE> <TAB> if isprime ( n ) : <NEWLINE> <TAB> return n <NEWLINE> <UNTAB> n -= <NUMBER> <NEWLINE> if isprime ( n ) : <NEWLINE> <TAB> return n <NEWLINE> <UNTAB> n -= <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def kneighbors ( self , X = None , n_neighbors = None , return_distance = True ) : <NEWLINE> <TAB> <NEWLINE> check_is_fitted ( self , <STRING> ) <NEWLINE> <NEWLINE> if n_neighbors is None : <NEWLINE> <TAB> n_neighbors = self . n_neighbors <NEWLINE> <UNTAB> elif n_neighbors <= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % <NEWLINE> n_neighbors <NEWLINE> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if not np . issubdtype ( type ( n_neighbors ) , np . integer ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % <NEWLINE> type ( n_neighbors ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if X is not None : <NEWLINE> <TAB> query_is_train = False <NEWLINE> X = check_array ( X , accept_sparse = <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> query_is_train = True <NEWLINE> X = self . _fit_X <NEWLINE> <NEWLINE> <NEWLINE> n_neighbors += <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> train_size = self . _fit_X . shape [ <NUMBER> ] <NEWLINE> if n_neighbors > train_size : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % <NEWLINE> ( train_size , n_neighbors ) <NEWLINE> ) <NEWLINE> <UNTAB> n_samples , _ = X . shape <NEWLINE> sample_range = np . arange ( n_samples ) [ : , None ] <NEWLINE> <NEWLINE> n_jobs = effective_n_jobs ( self . n_jobs ) <NEWLINE> if self . _fit_method == <STRING> : <NEWLINE> <NEWLINE> <TAB> reduce_func = partial ( self . _kneighbors_reduce_func , <NEWLINE> n_neighbors = n_neighbors , <NEWLINE> return_distance = return_distance ) <NEWLINE> <NEWLINE> <NEWLINE> kwds = ( { <STRING> : True } if self . effective_metric_ == <STRING> <NEWLINE> else self . effective_metric_params_ ) <NEWLINE> <NEWLINE> result = pairwise_distances_chunked ( <NEWLINE> X , self . _fit_X , reduce_func = reduce_func , <NEWLINE> metric = self . effective_metric_ , n_jobs = n_jobs , <NEWLINE> ** kwds ) <NEWLINE> <NEWLINE> <UNTAB> elif self . _fit_method in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> if issparse ( X ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % self . _fit_method ) <NEWLINE> <UNTAB> if LooseVersion ( joblib_version ) < LooseVersion ( <STRING> ) : <NEWLINE> <NEWLINE> <TAB> delayed_query = delayed ( self . _tree . query , <NEWLINE> check_pickle = False ) <NEWLINE> parallel_kwargs = { <STRING> : <STRING> } <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> delayed_query = delayed ( self . _tree . query ) <NEWLINE> parallel_kwargs = { <STRING> : <STRING> } <NEWLINE> <UNTAB> result = Parallel ( n_jobs , ** parallel_kwargs ) ( <NEWLINE> delayed_query ( <NEWLINE> X [ s ] , n_neighbors , return_distance ) <NEWLINE> for s in gen_even_slices ( X . shape [ <NUMBER> ] , n_jobs ) <NEWLINE> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if return_distance : <NEWLINE> <TAB> dist , neigh_ind = zip ( * result ) <NEWLINE> result = np . vstack ( dist ) , np . vstack ( neigh_ind ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result = np . vstack ( result ) <NEWLINE> <NEWLINE> <UNTAB> if not query_is_train : <NEWLINE> <TAB> return result <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if return_distance : <NEWLINE> <TAB> dist , neigh_ind = result <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> neigh_ind = result <NEWLINE> <NEWLINE> <UNTAB> sample_mask = neigh_ind != sample_range <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> dup_gr_nbrs = np . all ( sample_mask , axis = <NUMBER> ) <NEWLINE> sample_mask [ : , <NUMBER> ] [ dup_gr_nbrs ] = False <NEWLINE> <NEWLINE> neigh_ind = np . reshape ( <NEWLINE> neigh_ind [ sample_mask ] , ( n_samples , n_neighbors - <NUMBER> ) ) <NEWLINE> <NEWLINE> if return_distance : <NEWLINE> <TAB> dist = np . reshape ( <NEWLINE> dist [ sample_mask ] , ( n_samples , n_neighbors - <NUMBER> ) ) <NEWLINE> return dist , neigh_ind <NEWLINE> <UNTAB> return neigh_ind <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set ( self , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> props = OrderedDict ( <NEWLINE> sorted ( kwargs . items ( ) , reverse = True , <NEWLINE> key = lambda x : ( self . _prop_order . get ( x [ <NUMBER> ] , <NUMBER> ) , x [ <NUMBER> ] ) ) ) <NEWLINE> <NEWLINE> return self . update ( props ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def f_oneway ( * args ) : <NEWLINE> <TAB> <NEWLINE> n_classes = len ( args ) <NEWLINE> args = [ as_float_array ( a ) for a in args ] <NEWLINE> n_samples_per_class = np . array ( [ a . shape [ <NUMBER> ] for a in args ] ) <NEWLINE> n_samples = np . sum ( n_samples_per_class ) <NEWLINE> ss_alldata = sum ( safe_sqr ( a ) . sum ( axis = <NUMBER> ) for a in args ) <NEWLINE> sums_args = [ np . asarray ( a . sum ( axis = <NUMBER> ) ) for a in args ] <NEWLINE> square_of_sums_alldata = sum ( sums_args ) ** <NUMBER> <NEWLINE> square_of_sums_args = [ s ** <NUMBER> for s in sums_args ] <NEWLINE> sstot = ss_alldata - square_of_sums_alldata / float ( n_samples ) <NEWLINE> ssbn = <NUMBER> <NEWLINE> for k , _ in enumerate ( args ) : <NEWLINE> <TAB> ssbn += square_of_sums_args [ k ] / n_samples_per_class [ k ] <NEWLINE> <UNTAB> ssbn -= square_of_sums_alldata / float ( n_samples ) <NEWLINE> sswn = sstot - ssbn <NEWLINE> dfbn = n_classes - <NUMBER> <NEWLINE> dfwn = n_samples - n_classes <NEWLINE> msb = ssbn / float ( dfbn ) <NEWLINE> msw = sswn / float ( dfwn ) <NEWLINE> constant_features_idx = np . where ( msw == <NUMBER> ) [ <NUMBER> ] <NEWLINE> if ( np . nonzero ( msb ) [ <NUMBER> ] . size != msb . size and constant_features_idx . size ) : <NEWLINE> <TAB> warnings . warn ( <STRING> % constant_features_idx , <NEWLINE> UserWarning ) <NEWLINE> <UNTAB> f = msb / msw <NEWLINE> <NEWLINE> f = np . asarray ( f ) . ravel ( ) <NEWLINE> prob = special . fdtrc ( dfbn , dfwn , f ) <NEWLINE> return f , prob <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def row_del ( self , row ) : <NEWLINE> <TAB> <NEWLINE> if row < <NUMBER> : <NEWLINE> <TAB> row += self . rows <NEWLINE> <UNTAB> if not <NUMBER> <= row < self . rows : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( row ) ) <NEWLINE> <NEWLINE> <UNTAB> return self . _eval_row_del ( row ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _build_option_description ( k ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> o = _get_registered_option ( k ) <NEWLINE> d = _get_deprecated_option ( k ) <NEWLINE> <NEWLINE> s = u ( <STRING> ) . format ( k = k ) <NEWLINE> <NEWLINE> if o . doc : <NEWLINE> <TAB> s += <STRING> . join ( o . doc . strip ( ) . split ( <STRING> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> s += <STRING> <NEWLINE> <NEWLINE> <UNTAB> if o : <NEWLINE> <TAB> s += ( u ( <STRING> ) <NEWLINE> . format ( default = o . defval , current = _get_option ( k , True ) ) ) <NEWLINE> <NEWLINE> <UNTAB> if d : <NEWLINE> <TAB> s += u ( <STRING> ) <NEWLINE> s += ( u ( <STRING> ) <NEWLINE> . format ( rkey = d . rkey if d . rkey else <STRING> ) ) <NEWLINE> s += u ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> s += <STRING> <NEWLINE> return s <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def checkedThread ( self , target , args = None , kwargs = None ) : <NEWLINE> <TAB> <NEWLINE> ret = TensorFlowTestCase . _CheckedThread ( self , target , args , kwargs ) <NEWLINE> self . _threads . append ( ret ) <NEWLINE> return ret <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def normalized ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . rows != <NUMBER> and self . cols != <NUMBER> : <NEWLINE> <TAB> raise ShapeError ( <STRING> ) <NEWLINE> <UNTAB> norm = self . norm ( ) <NEWLINE> out = self . applyfunc ( lambda i : i / norm ) <NEWLINE> return out <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _create_sequence_feature_spec_for_parsing ( sequence_feature_columns , <NEWLINE> allow_missing_by_default = False ) : <NEWLINE> <TAB> <NEWLINE> feature_spec = create_feature_spec_for_parsing ( sequence_feature_columns ) <NEWLINE> sequence_feature_spec = { } <NEWLINE> for key , feature in feature_spec . items ( ) : <NEWLINE> <TAB> if isinstance ( feature , parsing_ops . VarLenFeature ) : <NEWLINE> <TAB> sequence_feature = feature <NEWLINE> <UNTAB> elif ( isinstance ( feature , parsing_ops . FixedLenFeature ) or <NEWLINE> isinstance ( feature , parsing_ops . FixedLenSequenceFeature ) ) : <NEWLINE> <TAB> default_is_set = feature . default_value is not None <NEWLINE> if default_is_set : <NEWLINE> <TAB> logging . warning ( <NEWLINE> <STRING> <NEWLINE> <STRING> . <NEWLINE> format ( feature . default_value , key ) ) <NEWLINE> <UNTAB> sequence_feature = parsing_ops . FixedLenSequenceFeature ( <NEWLINE> shape = feature . shape , <NEWLINE> dtype = feature . dtype , <NEWLINE> allow_missing = ( allow_missing_by_default or default_is_set ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> . format ( type ( feature ) . __name__ ) ) <NEWLINE> <UNTAB> sequence_feature_spec [ key ] = sequence_feature <NEWLINE> <UNTAB> return sequence_feature_spec <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _parallel_pairwise ( X , Y , func , n_jobs , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if Y is None : <NEWLINE> <TAB> Y = X <NEWLINE> <NEWLINE> <UNTAB> if effective_n_jobs ( n_jobs ) == <NUMBER> : <NEWLINE> <TAB> return func ( X , Y , ** kwds ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> fd = delayed ( func ) <NEWLINE> ret = Parallel ( n_jobs = n_jobs , verbose = <NUMBER> ) ( <NEWLINE> fd ( X , Y [ s ] , ** kwds ) <NEWLINE> for s in gen_even_slices ( _num_samples ( Y ) , effective_n_jobs ( n_jobs ) ) ) <NEWLINE> <NEWLINE> return np . hstack ( ret ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def power ( x , p ) : <NEWLINE> <TAB> <NEWLINE> x = _fix_real_lt_zero ( x ) <NEWLINE> p = _fix_int_lt_zero ( p ) <NEWLINE> return nx . power ( x , p ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _remap_outputs_to_consumers ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _remap_outputs_make_unique ( ) <NEWLINE> output_ts = list ( self . _output_ts ) <NEWLINE> self . _output_ts = [ ] <NEWLINE> for t in output_ts : <NEWLINE> <TAB> self . _output_ts += [ t ] * len ( t . consumers ( ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def export ( self , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> % self . name , <NEWLINE> [ self . resource_handle ] ) as name : <NEWLINE> <TAB> with ops . colocate_with ( self . resource_handle ) : <NEWLINE> <TAB> exported_keys , exported_values = gen_lookup_ops . lookup_table_export_v2 ( <NEWLINE> self . resource_handle , self . _key_dtype , self . _value_dtype , name = name ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return exported_keys , exported_values <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_group_index_sorter ( group_index , ngroups ) : <NEWLINE> <TAB> <NEWLINE> count = len ( group_index ) <NEWLINE> alpha = <NUMBER> <NEWLINE> beta = <NUMBER> <NEWLINE> do_groupsort = ( count > <NUMBER> and ( ( alpha + beta * ngroups ) < <NEWLINE> ( count * np . log ( count ) ) ) ) <NEWLINE> if do_groupsort : <NEWLINE> <TAB> sorter , _ = algos . groupsort_indexer ( _ensure_int64 ( group_index ) , <NEWLINE> ngroups ) <NEWLINE> return _ensure_platform_int ( sorter ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return group_index . argsort ( kind = <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def scalar ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . select ( ) . execute ( ) . scalar ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def len ( self ) : <NEWLINE> <TAB> <NEWLINE> with phil : <NEWLINE> <TAB> shape = self . shape <NEWLINE> if len ( shape ) == <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> return shape [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def focus_get ( self ) : <NEWLINE> <TAB> <NEWLINE> name = self . tk . call ( <STRING> ) <NEWLINE> if name == <STRING> or not name : return None <NEWLINE> return self . _nametowidget ( name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , name , element , type_ = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( element , Label ) : <NEWLINE> <TAB> self . _resolve_label = element . _label <NEWLINE> <NEWLINE> <UNTAB> while isinstance ( element , Label ) : <NEWLINE> <TAB> element = element . element <NEWLINE> <NEWLINE> <UNTAB> if name : <NEWLINE> <TAB> self . name = name <NEWLINE> self . _resolve_label = self . name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . name = _anonymous_label ( <NEWLINE> <STRING> % ( id ( self ) , getattr ( element , <STRING> , <STRING> ) ) <NEWLINE> ) <NEWLINE> <NEWLINE> <UNTAB> self . key = self . _label = self . _key_label = self . name <NEWLINE> self . _element = element <NEWLINE> self . _type = type_ <NEWLINE> self . _proxies = [ element ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def find_available_plugins ( loaded = False ) : <NEWLINE> <TAB> <NEWLINE> active_plugins = set ( ) <NEWLINE> for plugin_func in plugin_store . values ( ) : <NEWLINE> <TAB> for plugin , func in plugin_func : <NEWLINE> <TAB> active_plugins . add ( plugin ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> d = { } <NEWLINE> for plugin in plugin_provides : <NEWLINE> <TAB> if not loaded or plugin in active_plugins : <NEWLINE> <TAB> d [ plugin ] = [ f for f in plugin_provides [ plugin ] <NEWLINE> if not f . startswith ( <STRING> ) ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return d <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def win32FontDirectory ( ) : <NEWLINE> <TAB> <NEWLINE> import winreg <NEWLINE> try : <NEWLINE> <TAB> with winreg . OpenKey ( winreg . HKEY_CURRENT_USER , MSFolders ) as user : <NEWLINE> <TAB> return winreg . QueryValueEx ( user , <STRING> ) [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> except OSError : <NEWLINE> <TAB> return os . path . join ( os . environ [ <STRING> ] , <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __getitem__ ( self , symbols ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( symbols , <STRING> ) : <NEWLINE> <TAB> return self . poly_ring ( * symbols ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . poly_ring ( symbols ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __unicode__ ( self ) : <NEWLINE> <TAB> <NEWLINE> self . infer_axes ( ) <NEWLINE> dc = <STRING> % <STRING> . join ( <NEWLINE> self . data_columns ) if len ( self . data_columns ) else <STRING> <NEWLINE> <NEWLINE> ver = <STRING> <NEWLINE> if self . is_old_version : <NEWLINE> <TAB> ver = <STRING> % <STRING> . join ( str ( x ) for x in self . version ) <NEWLINE> <NEWLINE> <UNTAB> return <STRING> % ( <NEWLINE> self . pandas_type , ver , self . table_type_short , self . nrows , <NEWLINE> self . ncols , <STRING> . join ( a . name for a in self . index_axes ) , dc <NEWLINE> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def do_connect ( self , dialect , conn_rec , cargs , cparams ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _compute_distances ( self , query , candidates ) : <NEWLINE> <TAB> <NEWLINE> if candidates . shape == ( <NUMBER> , ) : <NEWLINE> <NEWLINE> <TAB> return np . empty ( <NUMBER> , dtype = np . int ) , np . empty ( <NUMBER> , dtype = float ) <NEWLINE> <NEWLINE> <UNTAB> if sparse . issparse ( self . _fit_X ) : <NEWLINE> <TAB> candidate_X = self . _fit_X [ candidates ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> candidate_X = self . _fit_X . take ( candidates , axis = <NUMBER> , mode = <STRING> ) <NEWLINE> <UNTAB> distances = pairwise_distances ( query , candidate_X , <NEWLINE> metric = <STRING> ) [ <NUMBER> ] <NEWLINE> distance_positions = np . argsort ( distances ) <NEWLINE> distances = distances . take ( distance_positions , mode = <STRING> , axis = <NUMBER> ) <NEWLINE> return distance_positions , distances <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sqrt_grad ( y , dy , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , y = y , dy = dy , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , y , dy ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return sqrt_grad_eager_fallback ( <NEWLINE> y , dy , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def leaveWhitespace ( self ) : <NEWLINE> <TAB> <NEWLINE> self . skipWhitespace = False <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __getitem__ ( self , index ) : <NEWLINE> <TAB> <NEWLINE> syindex = self . _check_symbolic_index ( index ) <NEWLINE> if syindex is not None : <NEWLINE> <TAB> return syindex <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( index , tuple ) and any ( [ isinstance ( i , slice ) for i in index ] ) : <NEWLINE> <NEWLINE> <TAB> def slice_expand ( s , dim ) : <NEWLINE> <TAB> if not isinstance ( s , slice ) : <NEWLINE> <TAB> return ( s , ) <NEWLINE> <UNTAB> start , stop , step = s . indices ( dim ) <NEWLINE> return [ start + i * step for i in range ( ( stop - start ) // step ) ] <NEWLINE> <NEWLINE> <UNTAB> sl_factors = [ slice_expand ( i , dim ) for ( i , dim ) in zip ( index , self . shape ) ] <NEWLINE> eindices = itertools . product ( * sl_factors ) <NEWLINE> array = [ self . _array [ self . _parse_index ( i ) ] for i in eindices ] <NEWLINE> nshape = [ len ( el ) for i , el in enumerate ( sl_factors ) if isinstance ( index [ i ] , slice ) ] <NEWLINE> return type ( self ) ( array , nshape ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if isinstance ( index , slice ) : <NEWLINE> <TAB> return self . _array [ index ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> index = self . _parse_index ( index ) <NEWLINE> return self . _array [ index ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_coefficient ( self , expr ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> r = self . extract_multiplicatively ( expr ) <NEWLINE> if r and not r . has ( expr ) : <NEWLINE> <TAB> return r <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def doit ( self , ** hints ) : <NEWLINE> <TAB> <NEWLINE> from sympy . series . limitseq import limit_seq <NEWLINE> from sympy . functions import RisingFactorial <NEWLINE> <NEWLINE> e , z , z0 , dir = self . args <NEWLINE> <NEWLINE> if z0 is S . ComplexInfinity : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if hints . get ( <STRING> , True ) : <NEWLINE> <TAB> e = e . doit ( ** hints ) <NEWLINE> z = z . doit ( ** hints ) <NEWLINE> z0 = z0 . doit ( ** hints ) <NEWLINE> <NEWLINE> <UNTAB> if e == z : <NEWLINE> <TAB> return z0 <NEWLINE> <NEWLINE> <UNTAB> if not e . has ( z ) : <NEWLINE> <TAB> return e <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if z0 . is_positive : <NEWLINE> <TAB> e = e . rewrite ( [ factorial , RisingFactorial ] , gamma ) <NEWLINE> <NEWLINE> <UNTAB> if e . is_Mul : <NEWLINE> <TAB> if abs ( z0 ) is S . Infinity : <NEWLINE> <TAB> e = factor_terms ( e ) <NEWLINE> e = e . rewrite ( fibonacci , GoldenRatio ) <NEWLINE> ok = lambda w : ( z in w . free_symbols and <NEWLINE> any ( a . is_polynomial ( z ) or <NEWLINE> any ( z in m . free_symbols and m . is_polynomial ( z ) <NEWLINE> for m in Mul . make_args ( a ) ) <NEWLINE> for a in Add . make_args ( w ) ) ) <NEWLINE> if all ( ok ( w ) for w in e . as_numer_denom ( ) ) : <NEWLINE> <TAB> u = Dummy ( positive = True ) <NEWLINE> if z0 is S . NegativeInfinity : <NEWLINE> <TAB> inve = e . subs ( z , - <NUMBER> / u ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> inve = e . subs ( z , <NUMBER> / u ) <NEWLINE> <UNTAB> r = limit ( inve . as_leading_term ( u ) , u , S . Zero , <STRING> ) <NEWLINE> if isinstance ( r , Limit ) : <NEWLINE> <TAB> return self <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return r <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> if e . is_Order : <NEWLINE> <TAB> return Order ( limit ( e . expr , z , z0 ) , * e . args [ <NUMBER> : ] ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> r = gruntz ( e , z , z0 , dir ) <NEWLINE> if r is S . NaN : <NEWLINE> <TAB> raise PoleError ( ) <NEWLINE> <UNTAB> <UNTAB> except ( PoleError , ValueError ) : <NEWLINE> <TAB> r = heuristics ( e , z , z0 , dir ) <NEWLINE> if r is None : <NEWLINE> <TAB> return self <NEWLINE> <UNTAB> <UNTAB> except NotImplementedError : <NEWLINE> <NEWLINE> <TAB> if hints . get ( <STRING> , True ) and z0 is S . Infinity : <NEWLINE> <TAB> trials = hints . get ( <STRING> , <NUMBER> ) <NEWLINE> r = limit_seq ( e , z , trials ) <NEWLINE> if r is None : <NEWLINE> <TAB> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise NotImplementedError ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return r <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_values ( self , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> if is_object_dtype ( dtype ) : <NEWLINE> <TAB> return lib . map_infer ( self . values . ravel ( ) , <NEWLINE> self . _box_func ) . reshape ( self . values . shape ) <NEWLINE> <UNTAB> return self . values <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_exp ( var ) : <NEWLINE> <TAB> <NEWLINE> neg = False <NEWLINE> neg_info = is_neg ( var ) <NEWLINE> if neg_info is not None : <NEWLINE> <TAB> neg = True <NEWLINE> var = neg_info <NEWLINE> <UNTAB> if var . owner and var . owner . op == tensor . exp : <NEWLINE> <TAB> return neg , var . owner . inputs [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit ( self , X , y = None ) : <NEWLINE> <TAB> <NEWLINE> X = check_array ( X , accept_sparse = [ <STRING> , <STRING> ] ) <NEWLINE> <NEWLINE> n_samples , n_features = X . shape <NEWLINE> <NEWLINE> if self . n_components == <STRING> : <NEWLINE> <TAB> self . n_components_ = johnson_lindenstrauss_min_dim ( <NEWLINE> n_samples = n_samples , eps = self . eps ) <NEWLINE> <NEWLINE> if self . n_components_ <= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ( <NEWLINE> self . eps , n_samples , self . n_components_ ) ) <NEWLINE> <NEWLINE> <UNTAB> elif self . n_components_ > n_features : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % ( self . eps , n_samples , self . n_components_ , <NEWLINE> n_features ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if self . n_components <= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> % self . n_components ) <NEWLINE> <NEWLINE> <UNTAB> elif self . n_components > n_features : <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> % ( n_features , self . n_components ) , <NEWLINE> DataDimensionalityWarning ) <NEWLINE> <NEWLINE> <UNTAB> self . n_components_ = self . n_components <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . components_ = self . _make_random_matrix ( self . n_components_ , <NEWLINE> n_features ) <NEWLINE> <NEWLINE> <NEWLINE> assert_equal ( <NEWLINE> self . components_ . shape , <NEWLINE> ( self . n_components_ , n_features ) , <NEWLINE> err_msg = ( <STRING> <NEWLINE> <STRING> ) ) <NEWLINE> <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def summer ( ) : <NEWLINE> <TAB> <NEWLINE> set_cmap ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dup_discriminant ( f , K ) : <NEWLINE> <TAB> <NEWLINE> d = dup_degree ( f ) <NEWLINE> <NEWLINE> if d <= <NUMBER> : <NEWLINE> <TAB> return K . zero <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> s = ( - <NUMBER> ) ** ( ( d * ( d - <NUMBER> ) ) // <NUMBER> ) <NEWLINE> c = dup_LC ( f , K ) <NEWLINE> <NEWLINE> r = dup_resultant ( f , dup_diff ( f , <NUMBER> , K ) , K ) <NEWLINE> <NEWLINE> return K . quo ( r , c * K ( s ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def inverse_transform ( self , X ) : <NEWLINE> <TAB> <NEWLINE> check_is_fitted ( self , <STRING> ) <NEWLINE> X = self . _check_input ( X , check_shape = True ) <NEWLINE> <NEWLINE> if self . standardize : <NEWLINE> <TAB> X = self . _scaler . inverse_transform ( X ) <NEWLINE> <NEWLINE> <UNTAB> inv_fun = { <STRING> : self . _box_cox_inverse_tranform , <NEWLINE> <STRING> : self . _yeo_johnson_inverse_transform <NEWLINE> } [ self . method ] <NEWLINE> for i , lmbda in enumerate ( self . lambdas_ ) : <NEWLINE> <TAB> with np . errstate ( invalid = <STRING> ) : <NEWLINE> <TAB> X [ : , i ] = inv_fun ( X [ : , i ] , lmbda ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return X <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get ( self , name = None ) : <NEWLINE> <TAB> <NEWLINE> if name is None : <NEWLINE> <TAB> name = <STRING> % self . _name <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> fn = lambda : gen_data_flow_ops . unstage ( dtypes = self . _dtypes , <NEWLINE> shared_name = self . _name , name = name , <NEWLINE> capacity = self . _capacity , <NEWLINE> memory_limit = self . _memory_limit ) <NEWLINE> <NEWLINE> <NEWLINE> return self . __internal_get ( fn , name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def assertNotIn ( self , member , container , msg = None ) : <NEWLINE> <TAB> <NEWLINE> if member in container : <NEWLINE> <TAB> standardMsg = <STRING> % ( safe_repr ( member ) , <NEWLINE> safe_repr ( container ) ) <NEWLINE> self . fail ( self . _formatMessage ( msg , standardMsg ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _read_bytes ( f , n ) : <NEWLINE> <TAB> <NEWLINE> return f . read ( n ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __winfo_parseitem ( self , t ) : <NEWLINE> <TAB> <NEWLINE> return t [ : <NUMBER> ] + tuple ( map ( self . __winfo_getint , t [ <NUMBER> : ] ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _legacy_fit_transform ( self , X ) : <NEWLINE> <TAB> <NEWLINE> dtype = getattr ( X , <STRING> , None ) <NEWLINE> X = check_array ( X , dtype = np . int ) <NEWLINE> if np . any ( X < <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> n_samples , n_features = X . shape <NEWLINE> if ( isinstance ( self . n_values , six . string_types ) and <NEWLINE> self . n_values == <STRING> ) : <NEWLINE> <TAB> n_values = np . max ( X , axis = <NUMBER> ) + <NUMBER> <NEWLINE> <UNTAB> elif isinstance ( self . n_values , numbers . Integral ) : <NEWLINE> <TAB> if ( np . max ( X , axis = <NUMBER> ) >= self . n_values ) . any ( ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> % self . n_values ) <NEWLINE> <UNTAB> n_values = np . empty ( n_features , dtype = np . int ) <NEWLINE> n_values . fill ( self . n_values ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> n_values = np . asarray ( self . n_values , dtype = int ) <NEWLINE> <UNTAB> except ( ValueError , TypeError ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> <NEWLINE> % type ( X ) ) <NEWLINE> <UNTAB> if n_values . ndim < <NUMBER> or n_values . shape [ <NUMBER> ] != X . shape [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . _n_values_ = n_values <NEWLINE> self . categories_ = [ np . arange ( n_val - <NUMBER> , dtype = dtype ) <NEWLINE> for n_val in n_values ] <NEWLINE> n_values = np . hstack ( [ [ <NUMBER> ] , n_values ] ) <NEWLINE> indices = np . cumsum ( n_values ) <NEWLINE> self . _feature_indices_ = indices <NEWLINE> <NEWLINE> column_indices = ( X + indices [ : - <NUMBER> ] ) . ravel ( ) <NEWLINE> row_indices = np . repeat ( np . arange ( n_samples , dtype = np . int32 ) , <NEWLINE> n_features ) <NEWLINE> data = np . ones ( n_samples * n_features ) <NEWLINE> out = sparse . coo_matrix ( ( data , ( row_indices , column_indices ) ) , <NEWLINE> shape = ( n_samples , indices [ - <NUMBER> ] ) , <NEWLINE> dtype = self . dtype ) . tocsr ( ) <NEWLINE> <NEWLINE> if ( isinstance ( self . n_values , six . string_types ) and <NEWLINE> self . n_values == <STRING> ) : <NEWLINE> <TAB> mask = np . array ( out . sum ( axis = <NUMBER> ) ) . ravel ( ) != <NUMBER> <NEWLINE> active_features = np . where ( mask ) [ <NUMBER> ] <NEWLINE> out = out [ : , active_features ] <NEWLINE> self . _active_features_ = active_features <NEWLINE> <NEWLINE> self . categories_ = [ <NEWLINE> np . unique ( X [ : , i ] ) . astype ( dtype ) if dtype <NEWLINE> else np . unique ( X [ : , i ] ) for i in range ( n_features ) ] <NEWLINE> <NEWLINE> <UNTAB> return out if self . sparse else out . toarray ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def extend ( self , modules ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( modules , Iterable ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> + type ( modules ) . __name__ ) <NEWLINE> <UNTAB> offset = len ( self ) <NEWLINE> for i , module in enumerate ( modules ) : <NEWLINE> <TAB> self . add_module ( str ( offset + i ) , module ) <NEWLINE> <UNTAB> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def scale ( self , x = <NUMBER> , y = <NUMBER> , pt = None ) : <NEWLINE> <TAB> <NEWLINE> c = self . center <NEWLINE> if pt : <NEWLINE> <TAB> pt = Point ( pt , dim = <NUMBER> ) <NEWLINE> return self . translate ( * ( - pt ) . args ) . scale ( x , y ) . translate ( * pt . args ) <NEWLINE> <UNTAB> c = c . scale ( x , y ) <NEWLINE> x , y = [ abs ( i ) for i in ( x , y ) ] <NEWLINE> if x == y : <NEWLINE> <TAB> return self . func ( c , x * self . radius ) <NEWLINE> <UNTAB> h = v = self . radius <NEWLINE> return Ellipse ( c , hradius = h * x , vradius = v * y ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tc . returns ( LabeledTensor ) <NEWLINE> @ tc . accepts ( LabeledTensorLike , <NEWLINE> tc . Optional ( tc . Collection ( string_types ) ) , tc . Optional ( string_types ) ) <NEWLINE> def impose_axis_order ( labeled_tensor , axis_order = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ labeled_tensor ] ) as scope : <NEWLINE> <TAB> labeled_tensor = convert_to_labeled_tensor ( labeled_tensor ) <NEWLINE> <NEWLINE> if axis_order is None : <NEWLINE> <TAB> axis_order = _get_valid_axis_order ( ) <NEWLINE> <NEWLINE> <UNTAB> relevant_axis_order = [ a for a in axis_order if a in labeled_tensor . axes ] <NEWLINE> <NEWLINE> return transpose ( labeled_tensor , relevant_axis_order , name = scope ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def matmul_adjoint_x ( dz , x , y , transpose_a , transpose_b ) : <NEWLINE> <TAB> <NEWLINE> if not transpose_a and not transpose_b : <NEWLINE> <TAB> return tf . matmul ( dz , y , transpose_b = True ) <NEWLINE> <UNTAB> elif not transpose_a and transpose_b : <NEWLINE> <TAB> return tf . matmul ( dz , y ) <NEWLINE> <UNTAB> elif transpose_a and not transpose_b : <NEWLINE> <TAB> return tf . matmul ( y , dz , transpose_b = True ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return tf . matmul ( y , dz , transpose_a = True , transpose_b = True ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _process_quantiles ( self , x , dim ) : <NEWLINE> <TAB> <NEWLINE> x = np . asarray ( x , dtype = float ) <NEWLINE> <NEWLINE> if x . ndim == <NUMBER> : <NEWLINE> <TAB> x = x [ np . newaxis ] <NEWLINE> <UNTAB> elif x . ndim == <NUMBER> : <NEWLINE> <TAB> if dim == <NUMBER> : <NEWLINE> <TAB> x = x [ : , np . newaxis ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x = x [ np . newaxis , : ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return x <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def TR1 ( rv ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def f ( rv ) : <NEWLINE> <TAB> if isinstance ( rv , sec ) : <NEWLINE> <TAB> a = rv . args [ <NUMBER> ] <NEWLINE> return S . One / cos ( a ) <NEWLINE> <UNTAB> elif isinstance ( rv , csc ) : <NEWLINE> <TAB> a = rv . args [ <NUMBER> ] <NEWLINE> return S . One / sin ( a ) <NEWLINE> <UNTAB> return rv <NEWLINE> <NEWLINE> <UNTAB> return bottom_up ( rv , f ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __rsub__ ( p1 , n ) : <NEWLINE> <TAB> <NEWLINE> ring = p1 . ring <NEWLINE> try : <NEWLINE> <TAB> n = ring . domain_new ( n ) <NEWLINE> <UNTAB> except CoercionFailed : <NEWLINE> <TAB> return NotImplemented <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> p = ring . zero <NEWLINE> for expv in p1 : <NEWLINE> <TAB> p [ expv ] = - p1 [ expv ] <NEWLINE> <UNTAB> p += n <NEWLINE> return p <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def generate_gml ( G , stringizer = None ) : <NEWLINE> <TAB> <NEWLINE> valid_keys = re . compile ( <STRING> ) <NEWLINE> <NEWLINE> def stringize ( key , value , ignored_keys , indent , in_list = False ) : <NEWLINE> <TAB> if not isinstance ( key , ( str , unicode ) ) : <NEWLINE> <TAB> raise NetworkXError ( <STRING> % ( key , ) ) <NEWLINE> <UNTAB> if not valid_keys . match ( key ) : <NEWLINE> <TAB> raise NetworkXError ( <STRING> % ( key , ) ) <NEWLINE> <UNTAB> if not isinstance ( key , str ) : <NEWLINE> <TAB> key = str ( key ) <NEWLINE> <UNTAB> if key not in ignored_keys : <NEWLINE> <TAB> if isinstance ( value , ( int , long , bool ) ) : <NEWLINE> <TAB> if key == <STRING> : <NEWLINE> <TAB> yield indent + key + <STRING> + str ( value ) + <STRING> <NEWLINE> <UNTAB> elif value is True : <NEWLINE> <NEWLINE> <TAB> yield indent + key + <STRING> <NEWLINE> <UNTAB> elif value is False : <NEWLINE> <TAB> yield indent + key + <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> yield indent + key + <STRING> + str ( value ) <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( value , float ) : <NEWLINE> <TAB> text = repr ( value ) . upper ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> epos = text . rfind ( <STRING> ) <NEWLINE> if epos != - <NUMBER> and text . find ( <STRING> , <NUMBER> , epos ) == - <NUMBER> : <NEWLINE> <TAB> text = text [ : epos ] + <STRING> + text [ epos : ] <NEWLINE> <UNTAB> if key == <STRING> : <NEWLINE> <TAB> yield indent + key + <STRING> + text + <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> yield indent + key + <STRING> + text <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( value , dict ) : <NEWLINE> <TAB> yield indent + key + <STRING> <NEWLINE> next_indent = indent + <STRING> <NEWLINE> for key , value in value . items ( ) : <NEWLINE> <TAB> for line in stringize ( key , value , ( ) , next_indent ) : <NEWLINE> <TAB> yield line <NEWLINE> <UNTAB> <UNTAB> yield indent + <STRING> <NEWLINE> <UNTAB> elif isinstance ( value , ( list , tuple ) ) and key != <STRING> and value and not in_list : <NEWLINE> <TAB> next_indent = indent + <STRING> <NEWLINE> for val in value : <NEWLINE> <TAB> for line in stringize ( key , val , ( ) , next_indent , True ) : <NEWLINE> <TAB> yield line <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if stringizer : <NEWLINE> <TAB> try : <NEWLINE> <TAB> value = stringizer ( value ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> raise NetworkXError ( <NEWLINE> <STRING> % ( value , ) ) <NEWLINE> <UNTAB> <UNTAB> if not isinstance ( value , ( str , unicode ) ) : <NEWLINE> <TAB> raise NetworkXError ( <STRING> % ( value , ) ) <NEWLINE> <UNTAB> yield indent + key + <STRING> + escape ( value ) + <STRING> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> multigraph = G . is_multigraph ( ) <NEWLINE> yield <STRING> <NEWLINE> <NEWLINE> <NEWLINE> if G . is_directed ( ) : <NEWLINE> <TAB> yield <STRING> <NEWLINE> <UNTAB> if multigraph : <NEWLINE> <TAB> yield <STRING> <NEWLINE> <UNTAB> ignored_keys = { <STRING> , <STRING> , <STRING> , <STRING> } <NEWLINE> for attr , value in G . graph . items ( ) : <NEWLINE> <TAB> for line in stringize ( attr , value , ignored_keys , <STRING> ) : <NEWLINE> <TAB> yield line <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> node_id = dict ( zip ( G , range ( len ( G ) ) ) ) <NEWLINE> ignored_keys = { <STRING> , <STRING> } <NEWLINE> for node , attrs in G . nodes . items ( ) : <NEWLINE> <TAB> yield <STRING> <NEWLINE> yield <STRING> + str ( node_id [ node ] ) <NEWLINE> for line in stringize ( <STRING> , node , ( ) , <STRING> ) : <NEWLINE> <TAB> yield line <NEWLINE> <UNTAB> for attr , value in attrs . items ( ) : <NEWLINE> <TAB> for line in stringize ( attr , value , ignored_keys , <STRING> ) : <NEWLINE> <TAB> yield line <NEWLINE> <UNTAB> <UNTAB> yield <STRING> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> ignored_keys = { <STRING> , <STRING> } <NEWLINE> kwargs = { <STRING> : True } <NEWLINE> if multigraph : <NEWLINE> <TAB> ignored_keys . add ( <STRING> ) <NEWLINE> kwargs [ <STRING> ] = True <NEWLINE> <UNTAB> for e in G . edges ( ** kwargs ) : <NEWLINE> <TAB> yield <STRING> <NEWLINE> yield <STRING> + str ( node_id [ e [ <NUMBER> ] ] ) <NEWLINE> yield <STRING> + str ( node_id [ e [ <NUMBER> ] ] ) <NEWLINE> if multigraph : <NEWLINE> <TAB> for line in stringize ( <STRING> , e [ <NUMBER> ] , ( ) , <STRING> ) : <NEWLINE> <TAB> yield line <NEWLINE> <UNTAB> <UNTAB> for attr , value in e [ - <NUMBER> ] . items ( ) : <NEWLINE> <TAB> for line in stringize ( attr , value , ignored_keys , <STRING> ) : <NEWLINE> <TAB> yield line <NEWLINE> <UNTAB> <UNTAB> yield <STRING> <NEWLINE> <UNTAB> yield <STRING> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _nbytes ( self , deep = False ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> objsize = <NUMBER> <NEWLINE> <NEWLINE> level_nbytes = sum ( i . memory_usage ( deep = deep ) for i in self . levels ) <NEWLINE> label_nbytes = sum ( i . nbytes for i in self . labels ) <NEWLINE> names_nbytes = sum ( getsizeof ( i , objsize ) for i in self . names ) <NEWLINE> result = level_nbytes + label_nbytes + names_nbytes <NEWLINE> <NEWLINE> <NEWLINE> result += self . _engine . sizeof ( deep = deep ) <NEWLINE> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _convert_to_boolean ( self , value ) : <NEWLINE> <TAB> <NEWLINE> if value . lower ( ) not in self . BOOLEAN_STATES : <NEWLINE> <TAB> raise ValueError ( <STRING> % value ) <NEWLINE> <UNTAB> return self . BOOLEAN_STATES [ value . lower ( ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def parse ( self , s , fonts_object , fontsize , dpi ) : <NEWLINE> <TAB> <NEWLINE> self . _state_stack = [ self . State ( fonts_object , <STRING> , <STRING> , fontsize , dpi ) ] <NEWLINE> self . _em_width_cache = { } <NEWLINE> try : <NEWLINE> <TAB> result = self . _expression . parseString ( s ) <NEWLINE> <UNTAB> except ParseBaseException as err : <NEWLINE> <TAB> raise ValueError ( <STRING> . join ( [ <STRING> , <NEWLINE> err . line , <NEWLINE> <STRING> * ( err . column - <NUMBER> ) + <STRING> , <NEWLINE> str ( err ) ] ) ) <NEWLINE> <UNTAB> self . _state_stack = None <NEWLINE> self . _em_width_cache = { } <NEWLINE> self . _expression . resetCache ( ) <NEWLINE> return result [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def invert_xaxis ( self ) : <NEWLINE> <TAB> <NEWLINE> self . set_xlim ( self . get_xlim ( ) [ : : - <NUMBER> ] , auto = None ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _dots_per_unit ( self , units ) : <NEWLINE> <TAB> <NEWLINE> ax = self . ax <NEWLINE> if units in ( <STRING> , <STRING> , <STRING> ) : <NEWLINE> <TAB> if units == <STRING> : <NEWLINE> <TAB> dx0 = ax . viewLim . width <NEWLINE> dx1 = ax . bbox . width <NEWLINE> <UNTAB> elif units == <STRING> : <NEWLINE> <TAB> dx0 = ax . viewLim . height <NEWLINE> dx1 = ax . bbox . height <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dxx0 = ax . viewLim . width <NEWLINE> dxx1 = ax . bbox . width <NEWLINE> dyy0 = ax . viewLim . height <NEWLINE> dyy1 = ax . bbox . height <NEWLINE> dx1 = np . hypot ( dxx1 , dyy1 ) <NEWLINE> dx0 = np . hypot ( dxx0 , dyy0 ) <NEWLINE> <UNTAB> dx = dx1 / dx0 <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if units == <STRING> : <NEWLINE> <TAB> dx = ax . bbox . width <NEWLINE> <UNTAB> elif units == <STRING> : <NEWLINE> <TAB> dx = ax . bbox . height <NEWLINE> <UNTAB> elif units == <STRING> : <NEWLINE> <TAB> dx = <NUMBER> <NEWLINE> <UNTAB> elif units == <STRING> : <NEWLINE> <TAB> dx = ax . figure . dpi <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> return dx <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gf_rem ( f , g , p , K ) : <NEWLINE> <TAB> <NEWLINE> return gf_div ( f , g , p , K ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _simple_new ( cls , values , name = None , freq = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if not is_integer_dtype ( values ) : <NEWLINE> <TAB> values = np . array ( values , copy = False ) <NEWLINE> if len ( values ) > <NUMBER> and is_float_dtype ( values ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> return cls ( values , name = name , freq = freq , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> return cls . _from_ordinals ( values , name , freq , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def indent_code ( self , code ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if isinstance ( code , string_types ) : <NEWLINE> <TAB> code_lines = self . indent_code ( code . splitlines ( True ) ) <NEWLINE> return <STRING> . join ( code_lines ) <NEWLINE> <NEWLINE> <UNTAB> tab = <STRING> <NEWLINE> inc_regex = ( <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ) <NEWLINE> dec_regex = ( <STRING> , <STRING> , <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> code = [ line . lstrip ( <STRING> ) for line in code ] <NEWLINE> <NEWLINE> increase = [ int ( any ( [ search ( re , line ) for re in inc_regex ] ) ) <NEWLINE> for line in code ] <NEWLINE> decrease = [ int ( any ( [ search ( re , line ) for re in dec_regex ] ) ) <NEWLINE> for line in code ] <NEWLINE> <NEWLINE> pretty = [ ] <NEWLINE> level = <NUMBER> <NEWLINE> for n , line in enumerate ( code ) : <NEWLINE> <TAB> if line == <STRING> or line == <STRING> : <NEWLINE> <TAB> pretty . append ( line ) <NEWLINE> continue <NEWLINE> <UNTAB> level -= decrease [ n ] <NEWLINE> pretty . append ( <STRING> % ( tab * level , line ) ) <NEWLINE> level += increase [ n ] <NEWLINE> <UNTAB> return pretty <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def allclose ( a , b , rtol = <NUMBER> , atol = <NUMBER> , equal_nan = False ) : <NEWLINE> <TAB> <NEWLINE> return all ( isclose ( a , b , rtol , atol , equal_nan ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def solve_poly_inequalities ( polys ) : <NEWLINE> <TAB> <NEWLINE> from sympy import Union <NEWLINE> return Union ( * [ solve_poly_inequality ( * p ) for p in polys ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def pdf ( self , x , mean = None , cov = <NUMBER> , allow_singular = False ) : <NEWLINE> <TAB> <NEWLINE> dim , mean , cov = self . _process_parameters ( None , mean , cov ) <NEWLINE> x = self . _process_quantiles ( x , dim ) <NEWLINE> psd = _PSD ( cov , allow_singular = allow_singular ) <NEWLINE> out = np . exp ( self . _logpdf ( x , mean , psd . U , psd . log_pdet , psd . rank ) ) <NEWLINE> return _squeeze_output ( out ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_abs ( f , K ) : <NEWLINE> <TAB> <NEWLINE> return [ K . abs ( coeff ) for coeff in f ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_exact ( self ) : <NEWLINE> <TAB> <NEWLINE> from sympy . polys . domains import QQ <NEWLINE> return QQ <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _convert_listlike_indexer ( self , keyarr , kind = None ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( keyarr , Index ) : <NEWLINE> <TAB> keyarr = self . _convert_index_indexer ( keyarr ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> keyarr = self . _convert_arr_indexer ( keyarr ) <NEWLINE> <NEWLINE> <UNTAB> indexer = self . _convert_list_indexer ( keyarr , kind = kind ) <NEWLINE> return indexer , keyarr <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def denom ( f ) : <NEWLINE> <TAB> <NEWLINE> return f . half_per ( f . den ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _any_pandas_objects ( terms ) : <NEWLINE> <TAB> <NEWLINE> return any ( isinstance ( term . value , pd . core . generic . PandasObject ) <NEWLINE> for term in terms ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_timestamp ( self , freq = None , how = <STRING> , axis = <NUMBER> , copy = True ) : <NEWLINE> <TAB> <NEWLINE> new_data = self . _data <NEWLINE> if copy : <NEWLINE> <TAB> new_data = new_data . copy ( ) <NEWLINE> <NEWLINE> <UNTAB> axis = self . _get_axis_number ( axis ) <NEWLINE> if axis == <NUMBER> : <NEWLINE> <TAB> new_data . set_axis ( <NUMBER> , self . index . to_timestamp ( freq = freq , how = how ) ) <NEWLINE> <UNTAB> elif axis == <NUMBER> : <NEWLINE> <TAB> new_data . set_axis ( <NUMBER> , self . columns . to_timestamp ( freq = freq , how = how ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise AssertionError ( <STRING> . format ( <NEWLINE> ax = axis ) ) <NEWLINE> <NEWLINE> <UNTAB> return self . _constructor ( new_data ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __getattr__ ( self , attr ) : <NEWLINE> <TAB> <NEWLINE> return getattr ( self . mat , attr ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def qsize ( self ) : <NEWLINE> <TAB> <NEWLINE> with self . mutex : <NEWLINE> <TAB> return self . _qsize ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_tool ( self , name , tool , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> tool_cls = self . _get_cls_to_instantiate ( tool ) <NEWLINE> if not tool_cls : <NEWLINE> <TAB> raise ValueError ( <STRING> % str ( tool ) ) <NEWLINE> <NEWLINE> <UNTAB> if name in self . _tools : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> return self . _tools [ name ] <NEWLINE> <NEWLINE> <UNTAB> tool_obj = tool_cls ( self , name , * args , ** kwargs ) <NEWLINE> self . _tools [ name ] = tool_obj <NEWLINE> <NEWLINE> if tool_cls . default_keymap is not None : <NEWLINE> <TAB> self . update_keymap ( name , tool_cls . default_keymap ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( tool_obj , tools . ToolToggleBase ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if tool_obj . radio_group is None : <NEWLINE> <TAB> self . _toggled . setdefault ( None , set ( ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _toggled . setdefault ( tool_obj . radio_group , None ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if tool_obj . toggled : <NEWLINE> <TAB> self . _handle_toggle ( tool_obj , None , None , None ) <NEWLINE> <UNTAB> <UNTAB> tool_obj . set_figure ( self . figure ) <NEWLINE> <NEWLINE> self . _tool_added_event ( tool_obj ) <NEWLINE> return tool_obj <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def plot ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> args = list ( map ( sympify , args ) ) <NEWLINE> free = set ( ) <NEWLINE> for a in args : <NEWLINE> <TAB> if isinstance ( a , Expr ) : <NEWLINE> <TAB> free |= a . free_symbols <NEWLINE> if len ( free ) > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> x = free . pop ( ) if free else Symbol ( <STRING> ) <NEWLINE> kwargs . setdefault ( <STRING> , x . name ) <NEWLINE> kwargs . setdefault ( <STRING> , <STRING> % x . name ) <NEWLINE> show = kwargs . pop ( <STRING> , True ) <NEWLINE> series = [ ] <NEWLINE> plot_expr = check_arguments ( args , <NUMBER> , <NUMBER> ) <NEWLINE> series = [ LineOver1DRangeSeries ( * arg , ** kwargs ) for arg in plot_expr ] <NEWLINE> <NEWLINE> plots = Plot ( * series , ** kwargs ) <NEWLINE> if show : <NEWLINE> <TAB> plots . show ( ) <NEWLINE> <UNTAB> return plots <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def resize_volumes ( x , depth_factor , height_factor , width_factor , data_format ) : <NEWLINE> <TAB> <NEWLINE> if data_format == <STRING> : <NEWLINE> <TAB> output = repeat_elements ( x , depth_factor , axis = <NUMBER> ) <NEWLINE> output = repeat_elements ( output , height_factor , axis = <NUMBER> ) <NEWLINE> output = repeat_elements ( output , width_factor , axis = <NUMBER> ) <NEWLINE> return output <NEWLINE> <UNTAB> elif data_format == <STRING> : <NEWLINE> <TAB> output = repeat_elements ( x , depth_factor , axis = <NUMBER> ) <NEWLINE> output = repeat_elements ( output , height_factor , axis = <NUMBER> ) <NEWLINE> output = repeat_elements ( output , width_factor , axis = <NUMBER> ) <NEWLINE> return output <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> + str ( data_format ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def conjugate ( self ) : <NEWLINE> <TAB> <NEWLINE> return + self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_model_variables ( scope = None , suffix = None ) : <NEWLINE> <TAB> <NEWLINE> return get_variables ( scope , suffix , ops . GraphKeys . MODEL_VARIABLES ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _ixs ( self , i , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> label = self . index [ i ] <NEWLINE> if isinstance ( label , Index ) : <NEWLINE> <TAB> return self . take ( i , axis = axis ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . _get_val_at ( i ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dinitz_impl ( G , s , t , capacity , residual , cutoff ) : <NEWLINE> <TAB> if s not in G : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> % str ( s ) ) <NEWLINE> <UNTAB> if t not in G : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> % str ( t ) ) <NEWLINE> <UNTAB> if s == t : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if residual is None : <NEWLINE> <TAB> R = build_residual_network ( G , capacity ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> R = residual <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for u in R : <NEWLINE> <TAB> for e in R [ u ] . values ( ) : <NEWLINE> <TAB> e [ <STRING> ] = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> INF = R . graph [ <STRING> ] <NEWLINE> <NEWLINE> if cutoff is None : <NEWLINE> <TAB> cutoff = INF <NEWLINE> <NEWLINE> <UNTAB> R_succ = R . succ <NEWLINE> R_pred = R . pred <NEWLINE> <NEWLINE> def breath_first_search ( ) : <NEWLINE> <TAB> parents = { } <NEWLINE> queue = deque ( [ s ] ) <NEWLINE> while queue : <NEWLINE> <TAB> if t in parents : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> u = queue . popleft ( ) <NEWLINE> for v in R_succ [ u ] : <NEWLINE> <TAB> attr = R_succ [ u ] [ v ] <NEWLINE> if v not in parents and attr [ <STRING> ] - attr [ <STRING> ] > <NUMBER> : <NEWLINE> <TAB> parents [ v ] = u <NEWLINE> queue . append ( v ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return parents <NEWLINE> <NEWLINE> <UNTAB> def depth_first_search ( parents ) : <NEWLINE> <TAB> <NEWLINE> path = [ ] <NEWLINE> u = t <NEWLINE> flow = INF <NEWLINE> while u != s : <NEWLINE> <TAB> path . append ( u ) <NEWLINE> v = parents [ u ] <NEWLINE> flow = min ( flow , R_pred [ u ] [ v ] [ <STRING> ] - R_pred [ u ] [ v ] [ <STRING> ] ) <NEWLINE> u = v <NEWLINE> <UNTAB> path . append ( s ) <NEWLINE> <NEWLINE> if flow > <NUMBER> : <NEWLINE> <TAB> for u , v in pairwise ( path ) : <NEWLINE> <TAB> R_pred [ u ] [ v ] [ <STRING> ] += flow <NEWLINE> R_pred [ v ] [ u ] [ <STRING> ] -= flow <NEWLINE> <UNTAB> <UNTAB> return flow <NEWLINE> <NEWLINE> <UNTAB> flow_value = <NUMBER> <NEWLINE> while flow_value < cutoff : <NEWLINE> <TAB> parents = breath_first_search ( ) <NEWLINE> if t not in parents : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> this_flow = depth_first_search ( parents ) <NEWLINE> if this_flow * <NUMBER> > INF : <NEWLINE> <TAB> raise nx . NetworkXUnbounded ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> flow_value += this_flow <NEWLINE> <NEWLINE> <UNTAB> R . graph [ <STRING> ] = flow_value <NEWLINE> return R <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def iteritems ( d , ** kw ) : <NEWLINE> <TAB> <NEWLINE> return iter ( getattr ( d , _iteritems ) ( ** kw ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def text ( self , x , y , s , fontdict = None , withdash = False , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> default = { <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : self . transData , <NEWLINE> <STRING> : False } <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if withdash : <NEWLINE> <TAB> t = mtext . TextWithDash ( <NEWLINE> x = x , y = y , text = s ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> t = mtext . Text ( <NEWLINE> x = x , y = y , text = s ) <NEWLINE> <NEWLINE> <UNTAB> t . update ( default ) <NEWLINE> if fontdict is not None : <NEWLINE> <TAB> t . update ( fontdict ) <NEWLINE> <UNTAB> t . update ( kwargs ) <NEWLINE> <NEWLINE> t . set_clip_path ( self . patch ) <NEWLINE> self . _add_text ( t ) <NEWLINE> return t <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __floordiv__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if self . _delegate_binop ( other ) : <NEWLINE> <TAB> return NotImplemented <NEWLINE> <UNTAB> return floor_divide ( self , other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def winfo_id ( self ) : <NEWLINE> <TAB> <NEWLINE> return int ( self . tk . call ( <STRING> , <STRING> , self . _w ) , <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def russellrao ( u , v , w = None ) : <NEWLINE> <TAB> <NEWLINE> u = _validate_vector ( u ) <NEWLINE> v = _validate_vector ( v ) <NEWLINE> if u . dtype == v . dtype == bool and w is None : <NEWLINE> <TAB> ntt = ( u & v ) . sum ( ) <NEWLINE> n = float ( len ( u ) ) <NEWLINE> <UNTAB> elif w is None : <NEWLINE> <TAB> ntt = ( u * v ) . sum ( ) <NEWLINE> n = float ( len ( u ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> w = _validate_weights ( w ) <NEWLINE> ntt = ( u * v * w ) . sum ( ) <NEWLINE> n = w . sum ( ) <NEWLINE> <UNTAB> return float ( n - ntt ) / n <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def inverse ( self , argindex = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return atanh <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ public <NEWLINE> def chebyshevu_poly ( n , x = None , polys = False ) : <NEWLINE> <TAB> <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % n ) <NEWLINE> <NEWLINE> <UNTAB> poly = DMP ( dup_chebyshevu ( int ( n ) , ZZ ) , ZZ ) <NEWLINE> <NEWLINE> if x is not None : <NEWLINE> <TAB> poly = Poly . new ( poly , x ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> poly = PurePoly . new ( poly , Dummy ( <STRING> ) ) <NEWLINE> <NEWLINE> <UNTAB> return poly if polys else poly . as_expr ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def edmonds_karp_core ( R , s , t , cutoff ) : <NEWLINE> <TAB> <NEWLINE> R_nodes = R . nodes <NEWLINE> R_pred = R . pred <NEWLINE> R_succ = R . succ <NEWLINE> <NEWLINE> inf = R . graph [ <STRING> ] <NEWLINE> <NEWLINE> def augment ( path ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> flow = inf <NEWLINE> it = iter ( path ) <NEWLINE> u = next ( it ) <NEWLINE> for v in it : <NEWLINE> <TAB> attr = R_succ [ u ] [ v ] <NEWLINE> flow = min ( flow , attr [ <STRING> ] - attr [ <STRING> ] ) <NEWLINE> u = v <NEWLINE> <UNTAB> if flow * <NUMBER> > inf : <NEWLINE> <TAB> raise nx . NetworkXUnbounded ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> it = iter ( path ) <NEWLINE> u = next ( it ) <NEWLINE> for v in it : <NEWLINE> <TAB> R_succ [ u ] [ v ] [ <STRING> ] += flow <NEWLINE> R_succ [ v ] [ u ] [ <STRING> ] -= flow <NEWLINE> u = v <NEWLINE> <UNTAB> return flow <NEWLINE> <NEWLINE> <UNTAB> def bidirectional_bfs ( ) : <NEWLINE> <TAB> <NEWLINE> pred = { s : None } <NEWLINE> q_s = [ s ] <NEWLINE> succ = { t : None } <NEWLINE> q_t = [ t ] <NEWLINE> while True : <NEWLINE> <TAB> q = [ ] <NEWLINE> if len ( q_s ) <= len ( q_t ) : <NEWLINE> <TAB> for u in q_s : <NEWLINE> <TAB> for v , attr in R_succ [ u ] . items ( ) : <NEWLINE> <TAB> if v not in pred and attr [ <STRING> ] < attr [ <STRING> ] : <NEWLINE> <TAB> pred [ v ] = u <NEWLINE> if v in succ : <NEWLINE> <TAB> return v , pred , succ <NEWLINE> <UNTAB> q . append ( v ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if not q : <NEWLINE> <TAB> return None , None , None <NEWLINE> <UNTAB> q_s = q <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for u in q_t : <NEWLINE> <TAB> for v , attr in R_pred [ u ] . items ( ) : <NEWLINE> <TAB> if v not in succ and attr [ <STRING> ] < attr [ <STRING> ] : <NEWLINE> <TAB> succ [ v ] = u <NEWLINE> if v in pred : <NEWLINE> <TAB> return v , pred , succ <NEWLINE> <UNTAB> q . append ( v ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if not q : <NEWLINE> <TAB> return None , None , None <NEWLINE> <UNTAB> q_t = q <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> flow_value = <NUMBER> <NEWLINE> while flow_value < cutoff : <NEWLINE> <TAB> v , pred , succ = bidirectional_bfs ( ) <NEWLINE> if pred is None : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> path = [ v ] <NEWLINE> <NEWLINE> u = v <NEWLINE> while u != s : <NEWLINE> <TAB> u = pred [ u ] <NEWLINE> path . append ( u ) <NEWLINE> <UNTAB> path . reverse ( ) <NEWLINE> <NEWLINE> u = v <NEWLINE> while u != t : <NEWLINE> <TAB> u = succ [ u ] <NEWLINE> path . append ( u ) <NEWLINE> <UNTAB> flow_value += augment ( path ) <NEWLINE> <NEWLINE> <UNTAB> return flow_value <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def listterms ( self ) : <NEWLINE> <TAB> <NEWLINE> return list ( self . items ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def broadcast_static_shape ( shape_x , shape_y ) : <NEWLINE> <TAB> <NEWLINE> return common_shapes . broadcast_shape ( shape_x , shape_y ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def ppf ( self , q , * args , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> args , loc , scale = self . _parse_args ( * args , ** kwds ) <NEWLINE> q , loc , scale = map ( asarray , ( q , loc , scale ) ) <NEWLINE> args = tuple ( map ( asarray , args ) ) <NEWLINE> cond0 = self . _argcheck ( * args ) & ( scale > <NUMBER> ) & ( loc == loc ) <NEWLINE> cond1 = ( <NUMBER> < q ) & ( q < <NUMBER> ) <NEWLINE> cond2 = cond0 & ( q == <NUMBER> ) <NEWLINE> cond3 = cond0 & ( q == <NUMBER> ) <NEWLINE> cond = cond0 & cond1 <NEWLINE> output = valarray ( shape ( cond ) , value = self . badvalue ) <NEWLINE> <NEWLINE> lower_bound = self . a * scale + loc <NEWLINE> upper_bound = self . b * scale + loc <NEWLINE> place ( output , cond2 , argsreduce ( cond2 , lower_bound ) [ <NUMBER> ] ) <NEWLINE> place ( output , cond3 , argsreduce ( cond3 , upper_bound ) [ <NUMBER> ] ) <NEWLINE> <NEWLINE> if np . any ( cond ) : <NEWLINE> <TAB> goodargs = argsreduce ( cond , * ( ( q , ) + args + ( scale , loc ) ) ) <NEWLINE> scale , loc , goodargs = goodargs [ - <NUMBER> ] , goodargs [ - <NUMBER> ] , goodargs [ : - <NUMBER> ] <NEWLINE> place ( output , cond , self . _ppf ( * goodargs ) * scale + loc ) <NEWLINE> <UNTAB> if output . ndim == <NUMBER> : <NEWLINE> <TAB> return output [ ( ) ] <NEWLINE> <UNTAB> return output <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_visible ( self , b ) : <NEWLINE> <TAB> <NEWLINE> self . _visible = b <NEWLINE> self . pchanged ( ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def equals ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if self . is_ ( other ) : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <UNTAB> if not isinstance ( other , ABCIndexClass ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> elif not isinstance ( other , type ( self ) ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> other = type ( self ) ( other ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not is_dtype_equal ( self . dtype , other . dtype ) : <NEWLINE> <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif isinstance ( self , ABCPeriodIndex ) : <NEWLINE> <TAB> if not isinstance ( other , ABCPeriodIndex ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> if self . freq != other . freq : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return np . array_equal ( self . asi8 , other . asi8 ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def literal_processor ( self , dialect ) : <NEWLINE> <TAB> <NEWLINE> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_offset ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _offset <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def asjacobian ( J ) : <NEWLINE> <TAB> <NEWLINE> spsolve = scipy . sparse . linalg . spsolve <NEWLINE> if isinstance ( J , Jacobian ) : <NEWLINE> <TAB> return J <NEWLINE> <UNTAB> elif inspect . isclass ( J ) and issubclass ( J , Jacobian ) : <NEWLINE> <TAB> return J ( ) <NEWLINE> <UNTAB> elif isinstance ( J , np . ndarray ) : <NEWLINE> <TAB> if J . ndim > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> J = np . atleast_2d ( np . asarray ( J ) ) <NEWLINE> if J . shape [ <NUMBER> ] != J . shape [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return Jacobian ( matvec = lambda v : dot ( J , v ) , <NEWLINE> rmatvec = lambda v : dot ( J . conj ( ) . T , v ) , <NEWLINE> solve = lambda v : solve ( J , v ) , <NEWLINE> rsolve = lambda v : solve ( J . conj ( ) . T , v ) , <NEWLINE> dtype = J . dtype , shape = J . shape ) <NEWLINE> <UNTAB> elif scipy . sparse . isspmatrix ( J ) : <NEWLINE> <TAB> if J . shape [ <NUMBER> ] != J . shape [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return Jacobian ( matvec = lambda v : J * v , <NEWLINE> rmatvec = lambda v : J . conj ( ) . T * v , <NEWLINE> solve = lambda v : spsolve ( J , v ) , <NEWLINE> rsolve = lambda v : spsolve ( J . conj ( ) . T , v ) , <NEWLINE> dtype = J . dtype , shape = J . shape ) <NEWLINE> <UNTAB> elif hasattr ( J , <STRING> ) and hasattr ( J , <STRING> ) and hasattr ( J , <STRING> ) : <NEWLINE> <TAB> return Jacobian ( matvec = getattr ( J , <STRING> ) , <NEWLINE> rmatvec = getattr ( J , <STRING> ) , <NEWLINE> solve = J . solve , <NEWLINE> rsolve = getattr ( J , <STRING> ) , <NEWLINE> update = getattr ( J , <STRING> ) , <NEWLINE> setup = getattr ( J , <STRING> ) , <NEWLINE> dtype = J . dtype , <NEWLINE> shape = J . shape ) <NEWLINE> <UNTAB> elif callable ( J ) : <NEWLINE> <NEWLINE> <TAB> class Jac ( Jacobian ) : <NEWLINE> <TAB> def update ( self , x , F ) : <NEWLINE> <TAB> self . x = x <NEWLINE> <NEWLINE> <UNTAB> def solve ( self , v , tol = <NUMBER> ) : <NEWLINE> <TAB> m = J ( self . x ) <NEWLINE> if isinstance ( m , np . ndarray ) : <NEWLINE> <TAB> return solve ( m , v ) <NEWLINE> <UNTAB> elif scipy . sparse . isspmatrix ( m ) : <NEWLINE> <TAB> return spsolve ( m , v ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def matvec ( self , v ) : <NEWLINE> <TAB> m = J ( self . x ) <NEWLINE> if isinstance ( m , np . ndarray ) : <NEWLINE> <TAB> return dot ( m , v ) <NEWLINE> <UNTAB> elif scipy . sparse . isspmatrix ( m ) : <NEWLINE> <TAB> return m * v <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def rsolve ( self , v , tol = <NUMBER> ) : <NEWLINE> <TAB> m = J ( self . x ) <NEWLINE> if isinstance ( m , np . ndarray ) : <NEWLINE> <TAB> return solve ( m . conj ( ) . T , v ) <NEWLINE> <UNTAB> elif scipy . sparse . isspmatrix ( m ) : <NEWLINE> <TAB> return spsolve ( m . conj ( ) . T , v ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def rmatvec ( self , v ) : <NEWLINE> <TAB> m = J ( self . x ) <NEWLINE> if isinstance ( m , np . ndarray ) : <NEWLINE> <TAB> return dot ( m . conj ( ) . T , v ) <NEWLINE> <UNTAB> elif scipy . sparse . isspmatrix ( m ) : <NEWLINE> <TAB> return m . conj ( ) . T * v <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return Jac ( ) <NEWLINE> <UNTAB> elif isinstance ( J , str ) : <NEWLINE> <TAB> return dict ( broyden1 = BroydenFirst , <NEWLINE> broyden2 = BroydenSecond , <NEWLINE> anderson = Anderson , <NEWLINE> diagbroyden = DiagBroyden , <NEWLINE> linearmixing = LinearMixing , <NEWLINE> excitingmixing = ExcitingMixing , <NEWLINE> krylov = KrylovJacobian ) [ J ] ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _result_type_many ( * arrays_and_dtypes ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return np . result_type ( * arrays_and_dtypes ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <NEWLINE> <TAB> return reduce ( np . result_type , arrays_and_dtypes ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def simplify_logic ( expr , form = None , deep = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if form not in ( None , <STRING> , <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> expr = sympify ( expr ) <NEWLINE> if deep : <NEWLINE> <TAB> variables = _find_predicates ( expr ) <NEWLINE> from sympy . simplify . simplify import simplify <NEWLINE> s = [ simplify ( v ) for v in variables ] <NEWLINE> expr = expr . xreplace ( dict ( zip ( variables , s ) ) ) <NEWLINE> <UNTAB> if not isinstance ( expr , BooleanFunction ) : <NEWLINE> <TAB> return expr <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> variables = _find_predicates ( expr ) <NEWLINE> truthtable = [ ] <NEWLINE> for t in product ( [ <NUMBER> , <NUMBER> ] , repeat = len ( variables ) ) : <NEWLINE> <TAB> t = list ( t ) <NEWLINE> if expr . xreplace ( dict ( zip ( variables , t ) ) ) == True : <NEWLINE> <TAB> truthtable . append ( t ) <NEWLINE> <UNTAB> <UNTAB> big = len ( truthtable ) >= ( <NUMBER> ** ( len ( variables ) - <NUMBER> ) ) <NEWLINE> if form == <STRING> or form is None and big : <NEWLINE> <TAB> return SOPform ( variables , truthtable ) <NEWLINE> <UNTAB> return POSform ( variables , truthtable ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def atop ( func , out_ind , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> out = kwargs . pop ( <STRING> , None ) <NEWLINE> token = kwargs . pop ( <STRING> , None ) <NEWLINE> dtype = kwargs . pop ( <STRING> , None ) <NEWLINE> adjust_chunks = kwargs . pop ( <STRING> , None ) <NEWLINE> new_axes = kwargs . get ( <STRING> , { } ) <NEWLINE> <NEWLINE> from . core import Array , unify_chunks , normalize_arg <NEWLINE> <NEWLINE> if dtype is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> chunkss , arrays = unify_chunks ( * args ) <NEWLINE> for k , v in new_axes . items ( ) : <NEWLINE> <TAB> chunkss [ k ] = ( v , ) <NEWLINE> <UNTAB> arginds = list ( zip ( arrays , args [ <NUMBER> : : <NUMBER> ] ) ) <NEWLINE> <NEWLINE> for arg , ind in arginds : <NEWLINE> <TAB> if hasattr ( arg , <STRING> ) and hasattr ( ind , <STRING> ) and arg . ndim != len ( ind ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> % ( ind , arg . ndim ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> numblocks = { a . name : a . numblocks for a , ind in arginds if ind is not None } <NEWLINE> argindsstr = list ( toolz . concat ( [ ( normalize_arg ( a ) if ind is None else a . name , ind ) <NEWLINE> for a , ind in arginds ] ) ) <NEWLINE> <NEWLINE> if not out : <NEWLINE> <TAB> out = <STRING> % ( token or utils . funcname ( func ) . strip ( <STRING> ) , <NEWLINE> base . tokenize ( func , out_ind , argindsstr , dtype , ** kwargs ) ) <NEWLINE> <NEWLINE> <UNTAB> kwargs2 = { k : normalize_arg ( v ) for k , v in kwargs . items ( ) } <NEWLINE> dsk = _top ( func , out , out_ind , * argindsstr , numblocks = numblocks , ** kwargs2 ) <NEWLINE> dsks = [ a . dask for a , ind in arginds if ind is not None ] <NEWLINE> <NEWLINE> chunks = [ chunkss [ i ] for i in out_ind ] <NEWLINE> if adjust_chunks : <NEWLINE> <TAB> for i , ind in enumerate ( out_ind ) : <NEWLINE> <TAB> if ind in adjust_chunks : <NEWLINE> <TAB> if callable ( adjust_chunks [ ind ] ) : <NEWLINE> <TAB> chunks [ i ] = tuple ( map ( adjust_chunks [ ind ] , chunks [ i ] ) ) <NEWLINE> <UNTAB> elif isinstance ( adjust_chunks [ ind ] , numbers . Integral ) : <NEWLINE> <TAB> chunks [ i ] = tuple ( adjust_chunks [ ind ] for _ in chunks [ i ] ) <NEWLINE> <UNTAB> elif isinstance ( adjust_chunks [ ind ] , ( tuple , list ) ) : <NEWLINE> <TAB> chunks [ i ] = tuple ( adjust_chunks [ ind ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> chunks = tuple ( chunks ) <NEWLINE> <NEWLINE> return Array ( sharedict . merge ( ( out , dsk ) , * dsks , <NEWLINE> dependencies = { out : { a . name for a , ind in arginds if ind is not None } } ) , <NEWLINE> out , chunks , dtype = dtype ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def on_epoch_begin ( self , epoch , logs = None ) : <NEWLINE> <TAB> <NEWLINE> logs = logs or { } <NEWLINE> for callback in self . callbacks : <NEWLINE> <TAB> callback . on_epoch_begin ( epoch , logs ) <NEWLINE> <UNTAB> self . _delta_t_batch = <NUMBER> <NEWLINE> self . _delta_ts_batch_begin = deque ( [ ] , maxlen = self . queue_length ) <NEWLINE> self . _delta_ts_batch_end = deque ( [ ] , maxlen = self . queue_length ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def mpf_div ( s , t , prec , rnd = round_fast ) : <NEWLINE> <TAB> <NEWLINE> ssign , sman , sexp , sbc = s <NEWLINE> tsign , tman , texp , tbc = t <NEWLINE> if not sman or not tman : <NEWLINE> <TAB> if s == fzero : <NEWLINE> <TAB> if t == fzero : raise ZeroDivisionError <NEWLINE> if t == fnan : return fnan <NEWLINE> return fzero <NEWLINE> <UNTAB> if t == fzero : <NEWLINE> <TAB> raise ZeroDivisionError <NEWLINE> <UNTAB> s_special = ( not sman ) and sexp <NEWLINE> t_special = ( not tman ) and texp <NEWLINE> if s_special and t_special : <NEWLINE> <TAB> return fnan <NEWLINE> <UNTAB> if s == fnan or t == fnan : <NEWLINE> <TAB> return fnan <NEWLINE> <UNTAB> if not t_special : <NEWLINE> <TAB> if t == fzero : <NEWLINE> <TAB> return fnan <NEWLINE> <UNTAB> return { <NUMBER> : finf , - <NUMBER> : fninf } [ mpf_sign ( s ) * mpf_sign ( t ) ] <NEWLINE> <UNTAB> return fzero <NEWLINE> <UNTAB> sign = ssign ^ tsign <NEWLINE> if tman == <NUMBER> : <NEWLINE> <TAB> return normalize1 ( sign , sman , sexp - texp , sbc , prec , rnd ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> extra = prec - sbc + tbc + <NUMBER> <NEWLINE> if extra < <NUMBER> : <NEWLINE> <TAB> extra = <NUMBER> <NEWLINE> <UNTAB> quot , rem = divmod ( sman << extra , tman ) <NEWLINE> if rem : <NEWLINE> <TAB> quot = ( quot << <NUMBER> ) + <NUMBER> <NEWLINE> extra += <NUMBER> <NEWLINE> return normalize1 ( sign , quot , sexp - texp - extra , bitcount ( quot ) , prec , rnd ) <NEWLINE> <UNTAB> return normalize ( sign , quot , sexp - texp - extra , bitcount ( quot ) , prec , rnd ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def fused_batch_norm_grad_eager_fallback ( y_backprop , x , scale , reserve_space_1 , reserve_space_2 , epsilon = <NUMBER> , data_format = <STRING> , is_training = True , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> if epsilon is None : <NEWLINE> <TAB> epsilon = <NUMBER> <NEWLINE> <UNTAB> epsilon = _execute . make_float ( epsilon , <STRING> ) <NEWLINE> if data_format is None : <NEWLINE> <TAB> data_format = <STRING> <NEWLINE> <UNTAB> data_format = _execute . make_str ( data_format , <STRING> ) <NEWLINE> if is_training is None : <NEWLINE> <TAB> is_training = True <NEWLINE> <UNTAB> is_training = _execute . make_bool ( is_training , <STRING> ) <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ y_backprop , x , scale , reserve_space_1 , reserve_space_2 ] , _ctx ) <NEWLINE> ( y_backprop , x , scale , reserve_space_1 , reserve_space_2 ) = _inputs_T <NEWLINE> _inputs_flat = [ y_backprop , x , scale , reserve_space_1 , reserve_space_2 ] <NEWLINE> _attrs = ( <STRING> , _attr_T , <STRING> , epsilon , <STRING> , data_format , <NEWLINE> <STRING> , is_training ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result = _FusedBatchNormGradOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def initial_state ( self , batch_size , dtype ) : <NEWLINE> <TAB> <NEWLINE> return self . initial_alignments ( batch_size , dtype ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _helper_simplify ( eq , hint , match , simplify = True , ics = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> r = match <NEWLINE> if hint . endswith ( <STRING> ) : <NEWLINE> <TAB> solvefunc = globals ( ) [ <STRING> + hint [ : - len ( <STRING> ) ] ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> solvefunc = globals ( ) [ <STRING> + hint ] <NEWLINE> <UNTAB> func = r [ <STRING> ] <NEWLINE> order = r [ <STRING> ] <NEWLINE> match = r [ hint ] <NEWLINE> <NEWLINE> free = eq . free_symbols <NEWLINE> cons = lambda s : s . free_symbols . difference ( free ) <NEWLINE> <NEWLINE> if simplify : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> sols = solvefunc ( eq , func , order , match ) <NEWLINE> if isinstance ( sols , Expr ) : <NEWLINE> <TAB> rv = odesimp ( sols , func , order , cons ( sols ) , hint ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rv = [ odesimp ( s , func , order , cons ( s ) , hint ) for s in sols ] <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> match [ <STRING> ] = False <NEWLINE> rv = _handle_Integral ( solvefunc ( eq , func , order , match ) , <NEWLINE> func , order , hint ) <NEWLINE> <NEWLINE> <UNTAB> if ics and not <STRING> in hint : <NEWLINE> <TAB> if isinstance ( rv , Expr ) : <NEWLINE> <TAB> solved_constants = solve_ics ( [ rv ] , [ r [ <STRING> ] ] , cons ( rv ) , ics ) <NEWLINE> rv = rv . subs ( solved_constants ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rv1 = [ ] <NEWLINE> for s in rv : <NEWLINE> <TAB> solved_constants = solve_ics ( [ s ] , [ r [ <STRING> ] ] , cons ( s ) , ics ) <NEWLINE> rv1 . append ( s . subs ( solved_constants ) ) <NEWLINE> <UNTAB> rv = rv1 <NEWLINE> <UNTAB> <UNTAB> return rv <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_init_op ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _local_vars_update ( variables . trainable_variables ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def fliplr ( a ) : <NEWLINE> <TAB> <NEWLINE> return FlipLR ( ) . apply ( ( a , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def keepdims_wrapper ( a_callable ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> @ wraps ( a_callable ) <NEWLINE> def keepdims_wrapped_callable ( x , axis = None , keepdims = None , * args , ** kwargs ) : <NEWLINE> <TAB> r = a_callable ( x , axis = axis , * args , ** kwargs ) <NEWLINE> <NEWLINE> if not keepdims : <NEWLINE> <TAB> return r <NEWLINE> <NEWLINE> <UNTAB> axes = axis <NEWLINE> <NEWLINE> if axes is None : <NEWLINE> <TAB> axes = range ( x . ndim ) <NEWLINE> <NEWLINE> <UNTAB> if not isinstance ( axes , ( Container , Iterable , Sequence ) ) : <NEWLINE> <TAB> axes = [ axes ] <NEWLINE> <NEWLINE> <UNTAB> r_slice = tuple ( ) <NEWLINE> for each_axis in range ( x . ndim ) : <NEWLINE> <TAB> if each_axis in axes : <NEWLINE> <TAB> r_slice += ( None , ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> r_slice += ( slice ( None ) , ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> r = r [ r_slice ] <NEWLINE> <NEWLINE> return r <NEWLINE> <NEWLINE> <UNTAB> return keepdims_wrapped_callable <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def on_prune ( self , function_graph , node , reason ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __getitem__ ( self , index ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not isinstance ( index , tuple ) : <NEWLINE> <TAB> index = ( index , ) <NEWLINE> <UNTAB> fixed = [ ] <NEWLINE> length , dims = len ( index ) , self . ndim <NEWLINE> for slice_ in index : <NEWLINE> <TAB> if slice_ is Ellipsis : <NEWLINE> <TAB> fixed . extend ( [ slice ( None ) ] * ( dims - length + <NUMBER> ) ) <NEWLINE> length = len ( fixed ) <NEWLINE> <UNTAB> elif isinstance ( slice_ , ( int , long ) ) : <NEWLINE> <TAB> fixed . append ( slice ( slice_ , slice_ + <NUMBER> , <NUMBER> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> fixed . append ( slice_ ) <NEWLINE> <UNTAB> <UNTAB> index = tuple ( fixed ) <NEWLINE> if len ( index ) < dims : <NEWLINE> <TAB> index += ( slice ( None ) , ) * ( dims - len ( index ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> out = self . __class__ ( self . var , self . buf_size ) <NEWLINE> for i , ( start , stop , step , slice_ ) in enumerate ( <NEWLINE> zip ( self . start , self . stop , self . step , index ) ) : <NEWLINE> <TAB> out . start [ i ] = start + ( slice_ . start or <NUMBER> ) <NEWLINE> out . step [ i ] = step * ( slice_ . step or <NUMBER> ) <NEWLINE> out . stop [ i ] = start + ( slice_ . stop or stop - start ) <NEWLINE> out . stop [ i ] = min ( stop , out . stop [ i ] ) <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def traverse_using ( iterator , obj , visitors ) : <NEWLINE> <TAB> <NEWLINE> for target in iterator : <NEWLINE> <TAB> meth = visitors . get ( target . __visit_name__ , None ) <NEWLINE> if meth : <NEWLINE> <TAB> meth ( target ) <NEWLINE> <UNTAB> <UNTAB> return obj <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def scatter_nd_update ( self , indices , updates , name = None ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_shape ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _tensor . get_shape ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _rewrite2 ( f , x ) : <NEWLINE> <TAB> <NEWLINE> fac , po , g = _split_mul ( f , x ) <NEWLINE> if any ( _rewrite_single ( expr , x , False ) is None for expr in _mul_args ( g ) ) : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> l = _mul_as_two_parts ( g ) <NEWLINE> if not l : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> l = list ( ordered ( l , [ <NEWLINE> lambda p : max ( len ( _exponents ( p [ <NUMBER> ] , x ) ) , len ( _exponents ( p [ <NUMBER> ] , x ) ) ) , <NEWLINE> lambda p : max ( len ( _functions ( p [ <NUMBER> ] , x ) ) , len ( _functions ( p [ <NUMBER> ] , x ) ) ) , <NEWLINE> lambda p : max ( len ( _find_splitting_points ( p [ <NUMBER> ] , x ) ) , <NEWLINE> len ( _find_splitting_points ( p [ <NUMBER> ] , x ) ) ) ] ) ) <NEWLINE> <NEWLINE> for recursive in [ False , True ] : <NEWLINE> <TAB> for fac1 , fac2 in l : <NEWLINE> <TAB> g1 = _rewrite_single ( fac1 , x , recursive ) <NEWLINE> g2 = _rewrite_single ( fac2 , x , recursive ) <NEWLINE> if g1 and g2 : <NEWLINE> <TAB> cond = And ( g1 [ <NUMBER> ] , g2 [ <NUMBER> ] ) <NEWLINE> if cond != False : <NEWLINE> <TAB> return fac , po , g1 [ <NUMBER> ] , g2 [ <NUMBER> ] , cond <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_dynamic_module ( self ) : <NEWLINE> <TAB> <NEWLINE> if not hasattr ( self , <STRING> ) : <NEWLINE> <TAB> self . code_gen ( ) <NEWLINE> <NEWLINE> mod = cmodule . DynamicModule ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> code = self . instantiate_code ( <NUMBER> + len ( self . args ) ) <NEWLINE> instantiate = cmodule . ExtFunction ( <STRING> , code , <NEWLINE> method = cmodule . METH_VARARGS ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if PY3 : <NEWLINE> <TAB> static = " " " 
                 s t a t i c   i n t   { s t r u c t _ n a m e } _ e x e c u t o r ( { s t r u c t _ n a m e }   * s e l f )   { { 
                         r e t u r n   s e l f - > r u n ( ) ; 
                 } } 
 
                 s t a t i c   v o i d   { s t r u c t _ n a m e } _ d e s t r u c t o r ( P y O b j e c t   * c a p s u l e )   { { 
                         { s t r u c t _ n a m e }   * s e l f   =   ( { s t r u c t _ n a m e }   * ) P y C a p s u l e _ G e t C o n t e x t ( c a p s u l e ) ; 
                         d e l e t e   s e l f ; 
                 } } 
                 " " " . format ( struct_name = self . struct_name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> static = " " " 
                 s t a t i c   i n t   % ( s t r u c t _ n a m e ) s _ e x e c u t o r ( % ( s t r u c t _ n a m e ) s *   s e l f )   { 
                         r e t u r n   s e l f - > r u n ( ) ; 
                 } 
 
                 s t a t i c   v o i d   % ( s t r u c t _ n a m e ) s _ d e s t r u c t o r ( v o i d *   e x e c u t o r ,   v o i d *   s e l f )   { 
                         d e l e t e   ( ( % ( s t r u c t _ n a m e ) s * ) s e l f ) ; 
                 } 
                 " " " % dict ( struct_name = self . struct_name ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for support_code in self . support_code ( ) + self . c_support_code_apply : <NEWLINE> <TAB> mod . add_support_code ( support_code ) <NEWLINE> <UNTAB> mod . add_support_code ( self . struct_code ) <NEWLINE> mod . add_support_code ( static ) <NEWLINE> mod . add_function ( instantiate ) <NEWLINE> for header in self . headers ( ) : <NEWLINE> <TAB> mod . add_include ( header ) <NEWLINE> <UNTAB> for init_code_block in self . init_code ( ) + self . c_init_code_apply : <NEWLINE> <TAB> mod . add_init_code ( init_code_block ) <NEWLINE> <UNTAB> self . _mod = mod <NEWLINE> <UNTAB> return self . _mod <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def winfo_height ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . tk . getint ( <NEWLINE> self . tk . call ( <STRING> , <STRING> , self . _w ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def restore ( self , save_path ) : <NEWLINE> <TAB> <NEWLINE> if save_path is None : <NEWLINE> <TAB> return InitializationOnlyStatus ( self . _root_checkpointable , ops . uid ( ) ) <NEWLINE> <UNTAB> reader = pywrap_tensorflow . NewCheckpointReader ( save_path ) <NEWLINE> graph_building = not context . executing_eagerly ( ) <NEWLINE> if graph_building : <NEWLINE> <TAB> dtype_map = None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dtype_map = reader . get_variable_to_dtype_map ( ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> object_graph_string = reader . get_tensor ( <NEWLINE> base . OBJECT_GRAPH_PROTO_KEY ) <NEWLINE> <UNTAB> except errors_impl . NotFoundError : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> restore_coordinator = _NameBasedRestoreCoordinator ( <NEWLINE> save_path = save_path , dtype_map = dtype_map ) <NEWLINE> if not graph_building : <NEWLINE> <TAB> for existing_checkpointable in list_objects ( self . _root_checkpointable ) : <NEWLINE> <NEWLINE> <TAB> existing_checkpointable . _maybe_initialize_checkpointable ( ) <NEWLINE> existing_checkpointable . _name_based_restores . add ( restore_coordinator ) <NEWLINE> existing_checkpointable . _name_based_attribute_restore ( <NEWLINE> restore_coordinator ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return NameBasedSaverStatus ( <NEWLINE> restore_coordinator , root_checkpointable = self . _root_checkpointable ) <NEWLINE> <NEWLINE> <UNTAB> if graph_building : <NEWLINE> <TAB> if self . _file_prefix_placeholder is None : <NEWLINE> <TAB> with ops . device ( <STRING> ) : <NEWLINE> <TAB> self . _file_prefix_placeholder = constant_op . constant ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> file_prefix_tensor = self . _file_prefix_placeholder <NEWLINE> file_prefix_feed_dict = { self . _file_prefix_placeholder : save_path } <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> with ops . device ( <STRING> ) : <NEWLINE> <TAB> file_prefix_tensor = constant_op . constant ( save_path ) <NEWLINE> <UNTAB> file_prefix_feed_dict = None <NEWLINE> <UNTAB> object_graph_proto = ( <NEWLINE> checkpointable_object_graph_pb2 . CheckpointableObjectGraph ( ) ) <NEWLINE> object_graph_proto . ParseFromString ( object_graph_string ) <NEWLINE> checkpoint = _CheckpointRestoreCoordinator ( <NEWLINE> object_graph_proto = object_graph_proto , <NEWLINE> save_path = save_path , <NEWLINE> save_path_tensor = file_prefix_tensor , <NEWLINE> restore_op_cache = self . _restore_op_cache , <NEWLINE> saveable_object_cache = self . _saveable_object_cache ) <NEWLINE> base . _CheckpointPosition ( <NEWLINE> checkpoint = checkpoint , proto_id = <NUMBER> ) . restore ( self . _root_checkpointable ) <NEWLINE> load_status = CheckpointLoadStatus ( <NEWLINE> checkpoint , <NEWLINE> root_checkpointable = self . _root_checkpointable , <NEWLINE> feed_dict = file_prefix_feed_dict ) <NEWLINE> return load_status <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _get_running_interactive_framework ( ) : <NEWLINE> <TAB> <NEWLINE> QtWidgets = ( sys . modules . get ( <STRING> ) <NEWLINE> or sys . modules . get ( <STRING> ) ) <NEWLINE> if QtWidgets and QtWidgets . QApplication . instance ( ) : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> QtGui = ( sys . modules . get ( <STRING> ) <NEWLINE> or sys . modules . get ( <STRING> ) ) <NEWLINE> if QtGui and QtGui . QApplication . instance ( ) : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> Gtk = ( sys . modules . get ( <STRING> ) <NEWLINE> or sys . modules . get ( <STRING> ) ) <NEWLINE> if Gtk and Gtk . main_level ( ) : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> wx = sys . modules . get ( <STRING> ) <NEWLINE> if wx and wx . GetApp ( ) : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> tkinter = sys . modules . get ( <STRING> ) <NEWLINE> if tkinter : <NEWLINE> <TAB> for frame in sys . _current_frames ( ) . values ( ) : <NEWLINE> <TAB> while frame : <NEWLINE> <TAB> if frame . f_code == tkinter . mainloop . __code__ : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> frame = frame . f_back <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if <STRING> in sys . modules : <NEWLINE> <TAB> if sys . modules [ <STRING> ] . event_loop_is_running ( ) : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> <UNTAB> if sys . platform . startswith ( <STRING> ) and not os . environ . get ( <STRING> ) : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> return None <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def masked_not_equal ( x , value , copy = True ) : <NEWLINE> <TAB> <NEWLINE> return masked_where ( not_equal ( x , value ) , x , copy = copy ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def boxcox_normmax ( x , brack = ( - <NUMBER> , <NUMBER> ) , method = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def _pearsonr ( x , brack ) : <NEWLINE> <TAB> osm_uniform = _calc_uniform_order_statistic_medians ( len ( x ) ) <NEWLINE> xvals = distributions . norm . ppf ( osm_uniform ) <NEWLINE> <NEWLINE> def _eval_pearsonr ( lmbda , xvals , samps ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> y = boxcox ( samps , lmbda ) <NEWLINE> yvals = np . sort ( y ) <NEWLINE> r , prob = stats . pearsonr ( xvals , yvals ) <NEWLINE> return <NUMBER> - r <NEWLINE> <NEWLINE> <UNTAB> return optimize . brent ( _eval_pearsonr , brack = brack , args = ( xvals , x ) ) <NEWLINE> <NEWLINE> <UNTAB> def _mle ( x , brack ) : <NEWLINE> <TAB> def _eval_mle ( lmb , data ) : <NEWLINE> <NEWLINE> <TAB> return - boxcox_llf ( lmb , data ) <NEWLINE> <NEWLINE> <UNTAB> return optimize . brent ( _eval_mle , brack = brack , args = ( x , ) ) <NEWLINE> <NEWLINE> <UNTAB> def _all ( x , brack ) : <NEWLINE> <TAB> maxlog = np . zeros ( <NUMBER> , dtype = float ) <NEWLINE> maxlog [ <NUMBER> ] = _pearsonr ( x , brack ) <NEWLINE> maxlog [ <NUMBER> ] = _mle ( x , brack ) <NEWLINE> return maxlog <NEWLINE> <NEWLINE> <UNTAB> methods = { <STRING> : _pearsonr , <NEWLINE> <STRING> : _mle , <NEWLINE> <STRING> : _all } <NEWLINE> if method not in methods . keys ( ) : <NEWLINE> <TAB> raise ValueError ( <STRING> % method ) <NEWLINE> <NEWLINE> <UNTAB> optimfunc = methods [ method ] <NEWLINE> return optimfunc ( x , brack ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _lookup_dependency ( self , name ) : <NEWLINE> <TAB> <NEWLINE> unconditional = super ( Optimizer , self ) . _lookup_dependency ( name ) <NEWLINE> if unconditional is not None : <NEWLINE> <TAB> return unconditional <NEWLINE> <UNTAB> graph = None if context . executing_eagerly ( ) else ops . get_default_graph ( ) <NEWLINE> return self . _get_non_slot_variable ( name , graph = graph ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __iter__ ( self ) : <NEWLINE> <TAB> <NEWLINE> return iter ( self . _dict ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def cheb2poly ( c ) : <NEWLINE> <TAB> <NEWLINE> from . polynomial import polyadd , polysub , polymulx <NEWLINE> <NEWLINE> [ c ] = pu . as_series ( [ c ] ) <NEWLINE> n = len ( c ) <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> return c <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> c0 = c [ - <NUMBER> ] <NEWLINE> c1 = c [ - <NUMBER> ] <NEWLINE> <NEWLINE> for i in range ( n - <NUMBER> , <NUMBER> , - <NUMBER> ) : <NEWLINE> <TAB> tmp = c0 <NEWLINE> c0 = polysub ( c [ i - <NUMBER> ] , c1 ) <NEWLINE> c1 = polyadd ( tmp , polymulx ( c1 ) * <NUMBER> ) <NEWLINE> <UNTAB> return polyadd ( c0 , polymulx ( c1 ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def select_read ( fspace , args ) : <NEWLINE> <TAB> <NEWLINE> if fspace . shape == ( ) : <NEWLINE> <TAB> return ScalarReadSelection ( fspace , args ) <NEWLINE> <NEWLINE> <UNTAB> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _update_offset_text_position ( self , bboxes , bboxes2 ) : <NEWLINE> <TAB> <NEWLINE> x , y = self . offsetText . get_position ( ) <NEWLINE> top = self . axes . bbox . ymax <NEWLINE> self . offsetText . set_position ( <NEWLINE> ( x , top + self . OFFSETTEXTPAD * self . figure . dpi / <NUMBER> ) <NEWLINE> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> @ not_implemented_for ( <STRING> ) <NEWLINE> def hamiltonian_path ( G ) : <NEWLINE> <TAB> <NEWLINE> if len ( G ) == <NUMBER> : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> if len ( G ) == <NUMBER> : <NEWLINE> <TAB> return [ arbitrary_element ( G ) ] <NEWLINE> <UNTAB> v = arbitrary_element ( G ) <NEWLINE> hampath = hamiltonian_path ( G . subgraph ( set ( G ) - { v } ) ) <NEWLINE> <NEWLINE> <NEWLINE> index = index_satisfying ( hampath , lambda u : v not in G [ u ] ) <NEWLINE> hampath . insert ( index , v ) <NEWLINE> return hampath <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def backlink ( node ) : <NEWLINE> <TAB> <NEWLINE> seen = set ( ) <NEWLINE> to_see = [ node ] <NEWLINE> while to_see : <NEWLINE> <TAB> node = to_see . pop ( ) <NEWLINE> seen . add ( node ) <NEWLINE> for succ in node . next : <NEWLINE> <TAB> succ . prev . add ( node ) <NEWLINE> if succ not in seen : <NEWLINE> <TAB> to_see . append ( succ ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def bucketize ( input , boundaries , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if not isinstance ( boundaries , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % boundaries ) <NEWLINE> <UNTAB> boundaries = [ _execute . make_float ( _f , <STRING> ) for _f in boundaries ] <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , boundaries = boundaries , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , input , <STRING> , boundaries ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return bucketize_eager_fallback ( <NEWLINE> input , boundaries = boundaries , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _d ( self , name ) : <NEWLINE> <TAB> <NEWLINE> if name is None : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> return name . decode ( <STRING> ) <NEWLINE> <UNTAB> except UnicodeDecodeError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> return name <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_RealField ( K1 , a , K0 ) : <NEWLINE> <TAB> <NEWLINE> p , q = K0 . to_rational ( a ) <NEWLINE> <NEWLINE> if q == <NUMBER> : <NEWLINE> <TAB> return PythonInteger ( p ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( None , <STRING> ) <NEWLINE> def extract_dask_labels ( labels ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( labels , dd . DataFrame ) : <NEWLINE> <TAB> ncol = labels . columns <NEWLINE> <UNTAB> elif isinstance ( labels , dd . Series ) : <NEWLINE> <TAB> ncol = labels . name <NEWLINE> <UNTAB> if isinstance ( labels , allowed_classes ) : <NEWLINE> <TAB> if len ( ncol ) > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return _construct_dask_df_with_divisions ( labels ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return labels <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ _generative <NEWLINE> def with_hint ( self , text , selectable = None , dialect_name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if selectable is None : <NEWLINE> <TAB> selectable = self . table <NEWLINE> <NEWLINE> <UNTAB> self . _hints = self . _hints . union ( <NEWLINE> { ( selectable , dialect_name ) : text } ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_frame_like ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _ensure_position_is_set ( ) <NEWLINE> position = self . _position <NEWLINE> if isinstance ( position , str ) : <NEWLINE> <TAB> if position == <STRING> : <NEWLINE> <TAB> position = ( <STRING> , <NUMBER> ) <NEWLINE> <UNTAB> elif position == <STRING> : <NEWLINE> <TAB> position = ( <STRING> , <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> if len ( position ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> position_type , amount = position <NEWLINE> if position_type == <STRING> and amount == <NUMBER> : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def simplify ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> trans = self . by_key ( ) <NEWLINE> return reduce ( add , ( _cycler ( k , v ) for k , v in six . iteritems ( trans ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_urls ( self , urls ) : <NEWLINE> <TAB> <NEWLINE> self . _urls = urls if urls is not None else [ None ] <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_func_kwargs ( func ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return compat . inspect_getargspec ( func ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def classof ( A , B ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> if A . _class_priority > B . _class_priority : <NEWLINE> <TAB> return A . __class__ <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return B . __class__ <NEWLINE> <UNTAB> <UNTAB> except AttributeError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> import numpy <NEWLINE> if isinstance ( A , numpy . ndarray ) : <NEWLINE> <TAB> return B . __class__ <NEWLINE> <UNTAB> if isinstance ( B , numpy . ndarray ) : <NEWLINE> <TAB> return A . __class__ <NEWLINE> <UNTAB> <UNTAB> except ( AttributeError , ImportError ) : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> raise TypeError ( <STRING> % ( A . __class__ , B . __class__ ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _width_of ( self , char ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> width = self . _tfm . width . get ( char , None ) <NEWLINE> if width is not None : <NEWLINE> <TAB> return _mul2012 ( width , self . _scale ) <NEWLINE> <UNTAB> _log . debug ( <STRING> , char , self . texname ) <NEWLINE> return <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _shallow_copy_with_infer ( self , values = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if values is None : <NEWLINE> <TAB> values = self . values <NEWLINE> <UNTAB> attributes = self . _get_attributes_dict ( ) <NEWLINE> attributes . update ( kwargs ) <NEWLINE> attributes [ <STRING> ] = False <NEWLINE> if not len ( values ) and <STRING> not in kwargs : <NEWLINE> <TAB> attributes [ <STRING> ] = self . dtype <NEWLINE> <UNTAB> if self . _infer_as_myclass : <NEWLINE> <TAB> try : <NEWLINE> <TAB> return self . _constructor ( values , ** attributes ) <NEWLINE> <UNTAB> except ( TypeError , ValueError ) : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> return Index ( values , ** attributes ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def itemsize ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _size <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_position ( self , position ) : <NEWLINE> <TAB> <NEWLINE> if position in ( <STRING> , <STRING> ) : <NEWLINE> <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if len ( position ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if position [ <NUMBER> ] not in [ <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> self . _position = position <NEWLINE> self . _calc_offset_transform ( ) <NEWLINE> <NEWLINE> self . set_transform ( self . get_spine_transform ( ) ) <NEWLINE> <NEWLINE> if self . axis is not None : <NEWLINE> <TAB> self . axis . reset_ticks ( ) <NEWLINE> <UNTAB> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def with_step ( self , step ) : <NEWLINE> <TAB> <NEWLINE> self . _options [ <STRING> ] = step <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def round_trip_localpath ( writer , reader , path = None ) : <NEWLINE> <TAB> <NEWLINE> import pytest <NEWLINE> LocalPath = pytest . importorskip ( <STRING> ) . local <NEWLINE> if path is None : <NEWLINE> <TAB> path = <STRING> <NEWLINE> <UNTAB> with ensure_clean ( path ) as path : <NEWLINE> <TAB> writer ( LocalPath ( path ) ) <NEWLINE> obj = reader ( LocalPath ( path ) ) <NEWLINE> <UNTAB> return obj <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def unsorted_segment_prod ( data , segment_ids , num_segments , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , data = data , segment_ids = segment_ids , <NEWLINE> num_segments = num_segments , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , _op . get_attr ( <STRING> ) , <NEWLINE> <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , data , <NEWLINE> segment_ids , num_segments ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return unsorted_segment_prod_eager_fallback ( <NEWLINE> data , segment_ids , num_segments , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_ufunc_and_otypes ( self , func , args ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not args : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if self . otypes is not None : <NEWLINE> <TAB> otypes = self . otypes <NEWLINE> nout = len ( otypes ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if func is self . pyfunc and self . _ufunc is not None : <NEWLINE> <TAB> ufunc = self . _ufunc <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ufunc = self . _ufunc = frompyfunc ( func , len ( args ) , nout ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> args = [ asarray ( arg ) for arg in args ] <NEWLINE> if builtins . any ( arg . size == <NUMBER> for arg in args ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> inputs = [ arg . flat [ <NUMBER> ] for arg in args ] <NEWLINE> outputs = func ( * inputs ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if self . cache : <NEWLINE> <TAB> _cache = [ outputs ] <NEWLINE> <NEWLINE> def _func ( * vargs ) : <NEWLINE> <TAB> if _cache : <NEWLINE> <TAB> return _cache . pop ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return func ( * vargs ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> _func = func <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( outputs , tuple ) : <NEWLINE> <TAB> nout = len ( outputs ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nout = <NUMBER> <NEWLINE> outputs = ( outputs , ) <NEWLINE> <NEWLINE> <UNTAB> otypes = <STRING> . join ( [ asarray ( outputs [ _k ] ) . dtype . char <NEWLINE> for _k in range ( nout ) ] ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> ufunc = frompyfunc ( _func , len ( args ) , nout ) <NEWLINE> <NEWLINE> <UNTAB> return ufunc , otypes <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def getO ( self ) : <NEWLINE> <TAB> <NEWLINE> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_oinp_iinp_iout_oout_mappings ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> outer_input_indices = [ <NUMBER> ] <NEWLINE> inner_input_indices = [ [ ] ] <NEWLINE> inner_output_indices = [ [ ] ] <NEWLINE> outer_output_indices = [ - <NUMBER> ] <NEWLINE> <NEWLINE> outer_iidx = <NUMBER> <NEWLINE> inner_iidx = <NUMBER> <NEWLINE> inner_oidx = <NUMBER> <NEWLINE> outer_oidx = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> for i in xrange ( self . info [ <STRING> ] ) : <NEWLINE> <TAB> outer_input_indices . append ( outer_iidx ) <NEWLINE> inner_input_indices . append ( [ inner_iidx ] ) <NEWLINE> inner_output_indices . append ( [ ] ) <NEWLINE> outer_output_indices . append ( - <NUMBER> ) <NEWLINE> <NEWLINE> outer_iidx += <NUMBER> <NEWLINE> inner_iidx += <NUMBER> <NEWLINE> inner_oidx += <NUMBER> <NEWLINE> outer_oidx += <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> for i in xrange ( len ( self . info [ <STRING> ] ) ) : <NEWLINE> <TAB> nb_input_taps = len ( self . info [ <STRING> ] [ i ] ) <NEWLINE> <NEWLINE> if i < self . n_mit_mot : <NEWLINE> <TAB> nb_output_taps = len ( self . mit_mot_out_slices [ i ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nb_output_taps = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> outer_input_indices . append ( outer_iidx ) <NEWLINE> inner_input_indices . append ( list ( range ( inner_iidx , <NEWLINE> inner_iidx + nb_input_taps ) ) ) <NEWLINE> inner_output_indices . append ( list ( range ( inner_oidx , <NEWLINE> inner_oidx + nb_output_taps ) ) ) <NEWLINE> outer_output_indices . append ( outer_oidx ) <NEWLINE> <NEWLINE> outer_iidx += <NUMBER> <NEWLINE> inner_iidx += nb_input_taps <NEWLINE> inner_oidx += nb_output_taps <NEWLINE> outer_oidx += <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> outer_iidx += self . info [ <STRING> ] <NEWLINE> <NEWLINE> <NEWLINE> for i in xrange ( self . n_nit_sot ) : <NEWLINE> <TAB> outer_input_indices . append ( outer_iidx ) <NEWLINE> inner_input_indices . append ( [ ] ) <NEWLINE> inner_output_indices . append ( [ inner_oidx ] ) <NEWLINE> outer_output_indices . append ( outer_oidx ) <NEWLINE> <NEWLINE> outer_iidx += <NUMBER> <NEWLINE> inner_iidx += <NUMBER> <NEWLINE> inner_oidx += <NUMBER> <NEWLINE> outer_oidx += <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> outer_iidx -= ( self . info [ <STRING> ] + self . n_nit_sot ) <NEWLINE> <NEWLINE> <NEWLINE> for i in xrange ( self . info [ <STRING> ] ) : <NEWLINE> <TAB> outer_input_indices . append ( outer_iidx ) <NEWLINE> inner_input_indices . append ( [ inner_iidx ] ) <NEWLINE> inner_output_indices . append ( [ inner_oidx ] ) <NEWLINE> outer_output_indices . append ( outer_oidx ) <NEWLINE> <NEWLINE> outer_iidx += <NUMBER> <NEWLINE> inner_iidx += <NUMBER> <NEWLINE> inner_oidx += <NUMBER> <NEWLINE> outer_oidx += <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> outer_iidx += self . n_nit_sot <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for i in xrange ( len ( self . inputs ) - inner_iidx ) : <NEWLINE> <TAB> outer_input_indices . append ( outer_iidx ) <NEWLINE> inner_input_indices . append ( [ inner_iidx ] ) <NEWLINE> inner_output_indices . append ( [ ] ) <NEWLINE> outer_output_indices . append ( - <NUMBER> ) <NEWLINE> <NEWLINE> outer_iidx += <NUMBER> <NEWLINE> inner_iidx += <NUMBER> <NEWLINE> inner_oidx += <NUMBER> <NEWLINE> outer_oidx += <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> mappings = { <STRING> : { } , <NEWLINE> <STRING> : { } , <NEWLINE> <STRING> : { } , <NEWLINE> <STRING> : { } , <NEWLINE> <STRING> : { } , <NEWLINE> <STRING> : { } , <NEWLINE> <STRING> : { } , <NEWLINE> <STRING> : { } , <NEWLINE> <STRING> : { } , <NEWLINE> <STRING> : { } , <NEWLINE> <STRING> : { } , <NEWLINE> <STRING> : { } } <NEWLINE> <NEWLINE> for ( oinp , iinp , iout , oout ) in izip ( outer_input_indices , <NEWLINE> inner_input_indices , <NEWLINE> inner_output_indices , <NEWLINE> outer_output_indices ) : <NEWLINE> <NEWLINE> <TAB> if oout != - <NUMBER> : <NEWLINE> <TAB> mappings [ <STRING> ] [ oout ] = oinp <NEWLINE> mappings [ <STRING> ] [ oout ] = iinp <NEWLINE> mappings [ <STRING> ] [ oout ] = iout <NEWLINE> <NEWLINE> <UNTAB> if oinp != - <NUMBER> : <NEWLINE> <TAB> mappings [ <STRING> ] [ oinp ] = iinp <NEWLINE> mappings [ <STRING> ] [ oinp ] = iout <NEWLINE> mappings [ <STRING> ] [ oinp ] = oout <NEWLINE> <NEWLINE> <UNTAB> for idx in iinp : <NEWLINE> <TAB> mappings [ <STRING> ] [ idx ] = oinp <NEWLINE> mappings [ <STRING> ] [ idx ] = iout <NEWLINE> mappings [ <STRING> ] [ idx ] = oout <NEWLINE> <NEWLINE> <UNTAB> for idx in iout : <NEWLINE> <TAB> mappings [ <STRING> ] [ idx ] = oinp <NEWLINE> mappings [ <STRING> ] [ idx ] = iinp <NEWLINE> mappings [ <STRING> ] [ idx ] = oout <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return mappings <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _apply_style_colors ( self , colors , kwds , col_num , label ) : <NEWLINE> <TAB> <NEWLINE> style = None <NEWLINE> if self . style is not None : <NEWLINE> <TAB> if isinstance ( self . style , list ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> style = self . style [ col_num ] <NEWLINE> <UNTAB> except IndexError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( self . style , dict ) : <NEWLINE> <TAB> style = self . style . get ( label , style ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> style = self . style <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> has_color = <STRING> in kwds or self . colormap is not None <NEWLINE> nocolor_style = style is None or re . match ( <STRING> , style ) is None <NEWLINE> if ( has_color or self . subplots ) and nocolor_style : <NEWLINE> <TAB> kwds [ <STRING> ] = colors [ col_num % len ( colors ) ] <NEWLINE> <UNTAB> return style , kwds <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _create_distinct ( cls , expr ) : <NEWLINE> <TAB> <NEWLINE> expr = _literal_as_binds ( expr ) <NEWLINE> return UnaryExpression ( <NEWLINE> expr , operator = operators . distinct_op , <NEWLINE> type_ = expr . type , wraps_column_expression = False ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ _generative <NEWLINE> def order_by ( self , * clauses ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . append_order_by ( * clauses ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def tanh ( x ) : <NEWLINE> <TAB> <NEWLINE> np = import_module ( <STRING> ) <NEWLINE> if isinstance ( x , ( int , float ) ) : <NEWLINE> <TAB> return interval ( np . tanh ( x ) , np . tanh ( x ) ) <NEWLINE> <UNTAB> elif isinstance ( x , interval ) : <NEWLINE> <TAB> return interval ( np . tanh ( x . start ) , np . tanh ( x . end ) , is_valid = x . is_valid ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def write_array ( fp , array , version = None , allow_pickle = True , pickle_kwargs = None ) : <NEWLINE> <TAB> <NEWLINE> _check_version ( version ) <NEWLINE> used_ver = _write_array_header ( fp , header_data_from_array_1_0 ( array ) , <NEWLINE> version ) <NEWLINE> <NEWLINE> if version != ( <NUMBER> , <NUMBER> ) and used_ver == ( <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> , UserWarning , stacklevel = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> if array . itemsize == <NUMBER> : <NEWLINE> <TAB> buffersize = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> buffersize = max ( <NUMBER> * <NUMBER> ** <NUMBER> // array . itemsize , <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> if array . dtype . hasobject : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if not allow_pickle : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if pickle_kwargs is None : <NEWLINE> <TAB> pickle_kwargs = { } <NEWLINE> <UNTAB> pickle . dump ( array , fp , protocol = <NUMBER> , ** pickle_kwargs ) <NEWLINE> <UNTAB> elif array . flags . f_contiguous and not array . flags . c_contiguous : <NEWLINE> <TAB> if isfileobj ( fp ) : <NEWLINE> <TAB> array . T . tofile ( fp ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for chunk in numpy . nditer ( <NEWLINE> array , flags = [ <STRING> , <STRING> , <STRING> ] , <NEWLINE> buffersize = buffersize , order = <STRING> ) : <NEWLINE> <TAB> fp . write ( chunk . tobytes ( <STRING> ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if isfileobj ( fp ) : <NEWLINE> <TAB> array . tofile ( fp ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for chunk in numpy . nditer ( <NEWLINE> array , flags = [ <STRING> , <STRING> , <STRING> ] , <NEWLINE> buffersize = buffersize , order = <STRING> ) : <NEWLINE> <TAB> fp . write ( chunk . tobytes ( <STRING> ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def slice_locs ( self , start = None , end = None , step = None , kind = None ) : <NEWLINE> <TAB> <NEWLINE> inc = ( step is None or step >= <NUMBER> ) <NEWLINE> <NEWLINE> if not inc : <NEWLINE> <NEWLINE> <TAB> start , end = end , start <NEWLINE> <NEWLINE> <UNTAB> start_slice = None <NEWLINE> if start is not None : <NEWLINE> <TAB> start_slice = self . get_slice_bound ( start , <STRING> , kind ) <NEWLINE> <UNTAB> if start_slice is None : <NEWLINE> <TAB> start_slice = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> end_slice = None <NEWLINE> if end is not None : <NEWLINE> <TAB> end_slice = self . get_slice_bound ( end , <STRING> , kind ) <NEWLINE> <UNTAB> if end_slice is None : <NEWLINE> <TAB> end_slice = len ( self ) <NEWLINE> <NEWLINE> <UNTAB> if not inc : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> end_slice , start_slice = start_slice - <NUMBER> , end_slice - <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if end_slice == - <NUMBER> : <NEWLINE> <TAB> end_slice -= len ( self ) <NEWLINE> <UNTAB> if start_slice == - <NUMBER> : <NEWLINE> <TAB> start_slice -= len ( self ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return start_slice , end_slice <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sqrt ( arg , evaluate = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return Pow ( arg , S . Half , evaluate = evaluate ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __isub__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> m = getmask ( other ) <NEWLINE> if self . _mask is nomask : <NEWLINE> <TAB> if m is not nomask and m . any ( ) : <NEWLINE> <TAB> self . _mask = make_mask_none ( self . shape , self . dtype ) <NEWLINE> self . _mask += m <NEWLINE> <UNTAB> <UNTAB> elif m is not nomask : <NEWLINE> <TAB> self . _mask += m <NEWLINE> <UNTAB> self . _data . __isub__ ( np . where ( self . _mask , self . dtype . type ( <NUMBER> ) , <NEWLINE> getdata ( other ) ) ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_summary ( self , summ , current_global_step ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( summ , bytes ) : <NEWLINE> <TAB> summary_proto = summary_pb2 . Summary ( ) <NEWLINE> summary_proto . ParseFromString ( summ ) <NEWLINE> summ = summary_proto <NEWLINE> <UNTAB> if current_global_step in self . _summaries : <NEWLINE> <TAB> step_summaries = self . _summaries [ current_global_step ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> step_summaries = [ ] <NEWLINE> self . _summaries [ current_global_step ] = step_summaries <NEWLINE> <UNTAB> step_summaries . append ( summ ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def fit ( self , X , y , sample_weight = None ) : <NEWLINE> <TAB> <NEWLINE> X = check_array ( X , accept_sparse = <STRING> ) <NEWLINE> y = check_array ( y , ensure_2d = False ) <NEWLINE> check_consistent_length ( X , y ) <NEWLINE> <NEWLINE> if self . base_estimator is not None : <NEWLINE> <TAB> base_estimator = clone ( self . base_estimator ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> base_estimator = LinearRegression ( ) <NEWLINE> <NEWLINE> <UNTAB> if self . min_samples is None : <NEWLINE> <NEWLINE> <TAB> min_samples = X . shape [ <NUMBER> ] + <NUMBER> <NEWLINE> <UNTAB> elif <NUMBER> < self . min_samples < <NUMBER> : <NEWLINE> <TAB> min_samples = np . ceil ( self . min_samples * X . shape [ <NUMBER> ] ) <NEWLINE> <UNTAB> elif self . min_samples >= <NUMBER> : <NEWLINE> <TAB> if self . min_samples % <NUMBER> != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> min_samples = self . min_samples <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if min_samples > X . shape [ <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % ( X . shape [ <NUMBER> ] ) ) <NEWLINE> <NEWLINE> <UNTAB> if self . stop_probability < <NUMBER> or self . stop_probability > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if self . residual_threshold is None : <NEWLINE> <NEWLINE> <TAB> residual_threshold = np . median ( np . abs ( y - np . median ( y ) ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> residual_threshold = self . residual_threshold <NEWLINE> <NEWLINE> <UNTAB> if self . loss == <STRING> : <NEWLINE> <TAB> if y . ndim == <NUMBER> : <NEWLINE> <TAB> loss_function = lambda y_true , y_pred : np . abs ( y_true - y_pred ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> loss_function = lambda y_true , y_pred : np . sum ( np . abs ( y_true - y_pred ) , axis = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif self . loss == <STRING> : <NEWLINE> <TAB> if y . ndim == <NUMBER> : <NEWLINE> <TAB> loss_function = lambda y_true , y_pred : ( y_true - y_pred ) ** <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> loss_function = lambda y_true , y_pred : np . sum ( ( y_true - y_pred ) ** <NUMBER> , axis = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif callable ( self . loss ) : <NEWLINE> <TAB> loss_function = self . loss <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % self . loss ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> random_state = check_random_state ( self . random_state ) <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> base_estimator . set_params ( random_state = random_state ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> estimator_fit_has_sample_weight = has_fit_parameter ( base_estimator , <NEWLINE> <STRING> ) <NEWLINE> estimator_name = type ( base_estimator ) . __name__ <NEWLINE> if ( sample_weight is not None and not <NEWLINE> estimator_fit_has_sample_weight ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % estimator_name ) <NEWLINE> <UNTAB> if sample_weight is not None : <NEWLINE> <TAB> sample_weight = np . asarray ( sample_weight ) <NEWLINE> <NEWLINE> <UNTAB> n_inliers_best = <NUMBER> <NEWLINE> score_best = - np . inf <NEWLINE> inlier_mask_best = None <NEWLINE> X_inlier_best = None <NEWLINE> y_inlier_best = None <NEWLINE> self . n_skips_no_inliers_ = <NUMBER> <NEWLINE> self . n_skips_invalid_data_ = <NUMBER> <NEWLINE> self . n_skips_invalid_model_ = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> n_samples = X . shape [ <NUMBER> ] <NEWLINE> sample_idxs = np . arange ( n_samples ) <NEWLINE> <NEWLINE> n_samples , _ = X . shape <NEWLINE> <NEWLINE> self . n_trials_ = <NUMBER> <NEWLINE> max_trials = self . max_trials <NEWLINE> while self . n_trials_ < max_trials : <NEWLINE> <TAB> self . n_trials_ += <NUMBER> <NEWLINE> <NEWLINE> if ( self . n_skips_no_inliers_ + self . n_skips_invalid_data_ + <NEWLINE> self . n_skips_invalid_model_ ) > self . max_skips : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> subset_idxs = sample_without_replacement ( n_samples , min_samples , <NEWLINE> random_state = random_state ) <NEWLINE> X_subset = X [ subset_idxs ] <NEWLINE> y_subset = y [ subset_idxs ] <NEWLINE> <NEWLINE> <NEWLINE> if ( self . is_data_valid is not None <NEWLINE> and not self . is_data_valid ( X_subset , y_subset ) ) : <NEWLINE> <TAB> self . n_skips_invalid_data_ += <NUMBER> <NEWLINE> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if sample_weight is None : <NEWLINE> <TAB> base_estimator . fit ( X_subset , y_subset ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> base_estimator . fit ( X_subset , y_subset , <NEWLINE> sample_weight = sample_weight [ subset_idxs ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if ( self . is_model_valid is not None and not <NEWLINE> self . is_model_valid ( base_estimator , X_subset , y_subset ) ) : <NEWLINE> <TAB> self . n_skips_invalid_model_ += <NUMBER> <NEWLINE> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> y_pred = base_estimator . predict ( X ) <NEWLINE> residuals_subset = loss_function ( y , y_pred ) <NEWLINE> <NEWLINE> <NEWLINE> inlier_mask_subset = residuals_subset < residual_threshold <NEWLINE> n_inliers_subset = np . sum ( inlier_mask_subset ) <NEWLINE> <NEWLINE> <NEWLINE> if n_inliers_subset < n_inliers_best : <NEWLINE> <TAB> self . n_skips_no_inliers_ += <NUMBER> <NEWLINE> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> inlier_idxs_subset = sample_idxs [ inlier_mask_subset ] <NEWLINE> X_inlier_subset = X [ inlier_idxs_subset ] <NEWLINE> y_inlier_subset = y [ inlier_idxs_subset ] <NEWLINE> <NEWLINE> <NEWLINE> score_subset = base_estimator . score ( X_inlier_subset , <NEWLINE> y_inlier_subset ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if ( n_inliers_subset == n_inliers_best <NEWLINE> and score_subset < score_best ) : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> n_inliers_best = n_inliers_subset <NEWLINE> score_best = score_subset <NEWLINE> inlier_mask_best = inlier_mask_subset <NEWLINE> X_inlier_best = X_inlier_subset <NEWLINE> y_inlier_best = y_inlier_subset <NEWLINE> <NEWLINE> max_trials = min ( <NEWLINE> max_trials , <NEWLINE> _dynamic_max_trials ( n_inliers_best , n_samples , <NEWLINE> min_samples , self . stop_probability ) ) <NEWLINE> <NEWLINE> <NEWLINE> if n_inliers_best >= self . stop_n_inliers or score_best >= self . stop_score : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if inlier_mask_best is None : <NEWLINE> <TAB> if ( ( self . n_skips_no_inliers_ + self . n_skips_invalid_data_ + <NEWLINE> self . n_skips_invalid_model_ ) > self . max_skips ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if ( self . n_skips_no_inliers_ + self . n_skips_invalid_data_ + <NEWLINE> self . n_skips_invalid_model_ ) > self . max_skips : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> , <NEWLINE> ConvergenceWarning ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> base_estimator . fit ( X_inlier_best , y_inlier_best ) <NEWLINE> <NEWLINE> self . estimator_ = base_estimator <NEWLINE> self . inlier_mask_ = inlier_mask_best <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def lchmod ( self , mode ) : <NEWLINE> <TAB> <NEWLINE> if self . _closed : <NEWLINE> <TAB> self . _raise_closed ( ) <NEWLINE> <UNTAB> self . _accessor . lchmod ( self , mode ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def remove ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . ax . figure . callbacks . disconnect ( self . _cid ) <NEWLINE> self . _cid = None <NEWLINE> <NEWLINE> mcollections . PolyCollection . remove ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def close ( self , cancel_pending_enqueues = False , name = None ) : <NEWLINE> <TAB> <NEWLINE> if name is None : <NEWLINE> <TAB> name = <STRING> % self . _name <NEWLINE> <UNTAB> if self . _queue_ref . dtype == _dtypes . resource : <NEWLINE> <TAB> return gen_data_flow_ops . queue_close_v2 ( <NEWLINE> self . _queue_ref , <NEWLINE> cancel_pending_enqueues = cancel_pending_enqueues , <NEWLINE> name = name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return gen_data_flow_ops . queue_close ( <NEWLINE> self . _queue_ref , <NEWLINE> cancel_pending_enqueues = cancel_pending_enqueues , <NEWLINE> name = name ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _build_import_library_x86 ( ) : <NEWLINE> <TAB> <NEWLINE> out_exists , out_file = _check_for_import_lib ( ) <NEWLINE> if out_exists : <NEWLINE> <TAB> log . debug ( <STRING> , out_file ) <NEWLINE> return <NEWLINE> <NEWLINE> <UNTAB> lib_name = <STRING> % tuple ( sys . version_info [ : <NUMBER> ] ) <NEWLINE> lib_file = os . path . join ( sys . prefix , <STRING> , lib_name ) <NEWLINE> if not os . path . isfile ( lib_file ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if hasattr ( sys , <STRING> ) : <NEWLINE> <TAB> base_lib = os . path . join ( sys . base_prefix , <STRING> , lib_name ) <NEWLINE> <UNTAB> elif hasattr ( sys , <STRING> ) : <NEWLINE> <TAB> base_lib = os . path . join ( sys . real_prefix , <STRING> , lib_name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> base_lib = <STRING> <NEWLINE> <NEWLINE> <UNTAB> if os . path . isfile ( base_lib ) : <NEWLINE> <TAB> lib_file = base_lib <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> log . warn ( <STRING> , lib_file ) <NEWLINE> return <NEWLINE> <UNTAB> <UNTAB> log . info ( <STRING> , out_file ) <NEWLINE> <NEWLINE> from numpy . distutils import lib2def <NEWLINE> <NEWLINE> def_name = <STRING> % tuple ( sys . version_info [ : <NUMBER> ] ) <NEWLINE> def_file = os . path . join ( sys . prefix , <STRING> , def_name ) <NEWLINE> nm_cmd = <STRING> % ( lib2def . DEFAULT_NM , lib_file ) <NEWLINE> nm_output = lib2def . getnm ( nm_cmd ) <NEWLINE> dlist , flist = lib2def . parse_nm ( nm_output ) <NEWLINE> lib2def . output_def ( dlist , flist , lib2def . DEF_HEADER , open ( def_file , <STRING> ) ) <NEWLINE> <NEWLINE> dll_name = find_python_dll ( ) <NEWLINE> args = ( dll_name , def_file , out_file ) <NEWLINE> cmd = <STRING> % args <NEWLINE> status = os . system ( cmd ) <NEWLINE> <NEWLINE> if status : <NEWLINE> <TAB> log . warn ( <STRING> ) <NEWLINE> <UNTAB> return <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def quote_schema ( self , schema , force = None ) : <NEWLINE> <TAB> <NEWLINE> return self . quote ( schema , force ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def broadcast ( self , target_shape ) : <NEWLINE> <TAB> <NEWLINE> if self . shape == ( ) : <NEWLINE> <TAB> if np . product ( target_shape ) != <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> % target_shape ) <NEWLINE> <UNTAB> self . _id . select_all ( ) <NEWLINE> yield self . _id <NEWLINE> return <NEWLINE> <NEWLINE> <UNTAB> start , count , step , scalar = self . _sel <NEWLINE> <NEWLINE> rank = len ( count ) <NEWLINE> target = list ( target_shape ) <NEWLINE> <NEWLINE> tshape = [ ] <NEWLINE> for idx in xrange ( <NUMBER> , rank + <NUMBER> ) : <NEWLINE> <TAB> if len ( target ) == <NUMBER> or scalar [ - idx ] : <NEWLINE> <TAB> tshape . append ( <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> t = target . pop ( ) <NEWLINE> if t == <NUMBER> or count [ - idx ] == t : <NEWLINE> <TAB> tshape . append ( t ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> % ( target_shape , count ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> tshape . reverse ( ) <NEWLINE> tshape = tuple ( tshape ) <NEWLINE> <NEWLINE> chunks = tuple ( x // y for x , y in zip ( count , tshape ) ) <NEWLINE> nchunks = int ( np . product ( chunks ) ) <NEWLINE> <NEWLINE> if nchunks == <NUMBER> : <NEWLINE> <TAB> yield self . _id <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> sid = self . _id . copy ( ) <NEWLINE> sid . select_hyperslab ( ( <NUMBER> , ) * rank , tshape , step ) <NEWLINE> for idx in xrange ( nchunks ) : <NEWLINE> <TAB> offset = tuple ( x * y * z + s for x , y , z , s in zip ( np . unravel_index ( idx , chunks ) , tshape , step , start ) ) <NEWLINE> sid . offset_simple ( offset ) <NEWLINE> yield sid <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _solve_check ( n , info , lamch = None , rcond = None ) : <NEWLINE> <TAB> <NEWLINE> if info < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( - info ) ) <NEWLINE> <UNTAB> elif <NUMBER> < info : <NEWLINE> <TAB> raise LinAlgError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if lamch is None : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> E = lamch ( <STRING> ) <NEWLINE> if rcond < E : <NEWLINE> <TAB> warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( rcond ) , LinAlgWarning , stacklevel = <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_disjoint ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( other , RealInterval ) : <NEWLINE> <TAB> return ( self . b <= other . a or other . b <= self . a ) <NEWLINE> <UNTAB> assert isinstance ( other , ComplexInterval ) <NEWLINE> return ( self . b <= other . ax or other . bx <= self . a <NEWLINE> or other . ay * other . by > <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __ge__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> other = _sympify ( other ) <NEWLINE> if isinstance ( other , AccumBounds ) : <NEWLINE> <TAB> if self . min >= other . max : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> if self . max < other . min : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> elif not ( other . is_real or other is S . Infinity or <NEWLINE> other is S . NegativeInfinity ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> % <NEWLINE> ( type ( other ) , other ) ) <NEWLINE> <UNTAB> elif other . is_comparable : <NEWLINE> <TAB> if self . min >= other : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> if self . max < other : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> return super ( AccumulationBounds , self ) . __ge__ ( other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def dot ( inputs , axes , normalize = False , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return Dot ( axes = axes , normalize = normalize , ** kwargs ) ( inputs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def unify ( f , g ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( g , DMP ) or f . lev != g . lev : <NEWLINE> <TAB> raise UnificationFailed ( <STRING> % ( f , g ) ) <NEWLINE> <NEWLINE> <UNTAB> if f . dom == g . dom and f . ring == g . ring : <NEWLINE> <TAB> return f . lev , f . dom , f . per , f . rep , g . rep <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> lev , dom = f . lev , f . dom . unify ( g . dom ) <NEWLINE> ring = f . ring <NEWLINE> if g . ring is not None : <NEWLINE> <TAB> if ring is not None : <NEWLINE> <TAB> ring = ring . unify ( g . ring ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ring = g . ring <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> F = dmp_convert ( f . rep , lev , f . dom , dom ) <NEWLINE> G = dmp_convert ( g . rep , lev , g . dom , dom ) <NEWLINE> <NEWLINE> def per ( rep , dom = dom , lev = lev , kill = False ) : <NEWLINE> <TAB> if kill : <NEWLINE> <TAB> if not lev : <NEWLINE> <TAB> return rep <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> lev -= <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return DMP ( rep , dom , lev , ring ) <NEWLINE> <NEWLINE> <UNTAB> return lev , dom , per , F , G <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def read ( self ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> f = urllib . request . urlopen ( self . url ) <NEWLINE> <UNTAB> except urllib . error . HTTPError as err : <NEWLINE> <TAB> if err . code in ( <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> self . disallow_all = True <NEWLINE> <UNTAB> elif err . code >= <NUMBER> and err . code < <NUMBER> : <NEWLINE> <TAB> self . allow_all = True <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raw = f . read ( ) <NEWLINE> self . parse ( raw . decode ( <STRING> ) . splitlines ( ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def norm ( x ) : <NEWLINE> <TAB> <NEWLINE> return np . linalg . norm ( x ) / x . size ** <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def to_sparse6_bytes ( G , nodes = None , header = True ) : <NEWLINE> <TAB> <NEWLINE> if nodes is not None : <NEWLINE> <TAB> G = G . subgraph ( nodes ) <NEWLINE> <UNTAB> G = nx . convert_node_labels_to_integers ( G , ordering = <STRING> ) <NEWLINE> return <STRING> . join ( _generate_sparse6_bytes ( G , nodes , header ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def find_corresponding ( targets , dst_graph , dst_scope = <STRING> , src_scope = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> def func ( top ) : <NEWLINE> <TAB> return find_corresponding_elem ( top , dst_graph , dst_scope , src_scope ) <NEWLINE> <UNTAB> return transform_tree ( targets , func ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def all_pairs_node_connectivity ( G , nbunch = None , flow_func = None ) : <NEWLINE> <TAB> <NEWLINE> if nbunch is None : <NEWLINE> <TAB> nbunch = G <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nbunch = set ( nbunch ) <NEWLINE> <NEWLINE> <UNTAB> directed = G . is_directed ( ) <NEWLINE> if directed : <NEWLINE> <TAB> iter_func = itertools . permutations <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> iter_func = itertools . combinations <NEWLINE> <NEWLINE> <UNTAB> all_pairs = { n : { } for n in nbunch } <NEWLINE> <NEWLINE> <NEWLINE> H = build_auxiliary_node_connectivity ( G ) <NEWLINE> mapping = H . graph [ <STRING> ] <NEWLINE> R = build_residual_network ( H , <STRING> ) <NEWLINE> kwargs = dict ( flow_func = flow_func , auxiliary = H , residual = R ) <NEWLINE> <NEWLINE> for u , v in iter_func ( nbunch , <NUMBER> ) : <NEWLINE> <TAB> K = local_node_connectivity ( G , u , v , ** kwargs ) <NEWLINE> all_pairs [ u ] [ v ] = K <NEWLINE> if not directed : <NEWLINE> <TAB> all_pairs [ v ] [ u ] = K <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return all_pairs <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def array_split ( ary , indices_or_sections , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> Ntotal = ary . shape [ axis ] <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> Ntotal = len ( ary ) <NEWLINE> <UNTAB> try : <NEWLINE> <NEWLINE> <TAB> Nsections = len ( indices_or_sections ) + <NUMBER> <NEWLINE> div_points = [ <NUMBER> ] + list ( indices_or_sections ) + [ Ntotal ] <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <NEWLINE> <TAB> Nsections = int ( indices_or_sections ) <NEWLINE> if Nsections <= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> Neach_section , extras = divmod ( Ntotal , Nsections ) <NEWLINE> section_sizes = ( [ <NUMBER> ] + <NEWLINE> extras * [ Neach_section + <NUMBER> ] + <NEWLINE> ( Nsections - extras ) * [ Neach_section ] ) <NEWLINE> div_points = _nx . array ( section_sizes ) . cumsum ( ) <NEWLINE> <NEWLINE> <UNTAB> sub_arys = [ ] <NEWLINE> sary = _nx . swapaxes ( ary , axis , <NUMBER> ) <NEWLINE> for i in range ( Nsections ) : <NEWLINE> <TAB> st = div_points [ i ] <NEWLINE> end = div_points [ i + <NUMBER> ] <NEWLINE> sub_arys . append ( _nx . swapaxes ( sary [ st : end ] , axis , <NUMBER> ) ) <NEWLINE> <NEWLINE> <UNTAB> return sub_arys <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def quantile ( x , q , interpolation_method = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> x = np . asarray ( x ) <NEWLINE> mask = isna ( x ) <NEWLINE> <NEWLINE> x = x [ ~ mask ] <NEWLINE> <NEWLINE> values = np . sort ( x ) <NEWLINE> <NEWLINE> def _interpolate ( a , b , fraction ) : <NEWLINE> <TAB> <NEWLINE> return a + ( b - a ) * fraction <NEWLINE> <NEWLINE> <UNTAB> def _get_score ( at ) : <NEWLINE> <TAB> if len ( values ) == <NUMBER> : <NEWLINE> <TAB> return np . nan <NEWLINE> <NEWLINE> <UNTAB> idx = at * ( len ( values ) - <NUMBER> ) <NEWLINE> if idx % <NUMBER> == <NUMBER> : <NEWLINE> <TAB> score = values [ int ( idx ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if interpolation_method == <STRING> : <NEWLINE> <TAB> score = _interpolate ( values [ int ( idx ) ] , values [ int ( idx ) + <NUMBER> ] , <NEWLINE> idx % <NUMBER> ) <NEWLINE> <UNTAB> elif interpolation_method == <STRING> : <NEWLINE> <TAB> score = values [ np . floor ( idx ) ] <NEWLINE> <UNTAB> elif interpolation_method == <STRING> : <NEWLINE> <TAB> score = values [ np . ceil ( idx ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return score <NEWLINE> <NEWLINE> <UNTAB> if is_scalar ( q ) : <NEWLINE> <TAB> return _get_score ( q ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> q = np . asarray ( q , np . float64 ) <NEWLINE> return algos . arrmap_float64 ( q , _get_score ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def load_library ( libname , loader_path ) : <NEWLINE> <TAB> <NEWLINE> if ctypes . __version__ < <STRING> : <NEWLINE> <TAB> import warnings <NEWLINE> warnings . warn ( <STRING> <STRING> , stacklevel = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> ext = os . path . splitext ( libname ) [ <NUMBER> ] <NEWLINE> if not ext : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> from numpy . distutils . misc_util import get_shared_lib_extension <NEWLINE> so_ext = get_shared_lib_extension ( ) <NEWLINE> libname_ext = [ libname + so_ext ] <NEWLINE> <NEWLINE> <NEWLINE> so_ext2 = get_shared_lib_extension ( is_python_ext = True ) <NEWLINE> if not so_ext2 == so_ext : <NEWLINE> <TAB> libname_ext . insert ( <NUMBER> , libname + so_ext2 ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> libname_ext = [ libname ] <NEWLINE> <NEWLINE> <UNTAB> loader_path = os . path . abspath ( loader_path ) <NEWLINE> if not os . path . isdir ( loader_path ) : <NEWLINE> <TAB> libdir = os . path . dirname ( loader_path ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> libdir = loader_path <NEWLINE> <NEWLINE> <UNTAB> for ln in libname_ext : <NEWLINE> <TAB> libpath = os . path . join ( libdir , ln ) <NEWLINE> if os . path . exists ( libpath ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> return ctypes . cdll [ libpath ] <NEWLINE> <UNTAB> except OSError : <NEWLINE> <NEWLINE> <TAB> raise <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> raise OSError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _prod ( iterable ) : <NEWLINE> <TAB> <NEWLINE> product = <NUMBER> <NEWLINE> for x in iterable : <NEWLINE> <TAB> product *= x <NEWLINE> <UNTAB> return product <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def l1_norm ( f ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( f . rep , <STRING> ) : <NEWLINE> <TAB> result = f . rep . l1_norm ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise OperationNotSupported ( f , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return f . rep . dom . to_sympy ( result ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def hist ( self , by = None , bins = <NUMBER> , ** kwds ) : <NEWLINE> <TAB> <NEWLINE> return self ( kind = <STRING> , by = by , bins = bins , ** kwds ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def tree_size ( tree_handle , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , tree_handle = tree_handle , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = None <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , tree_handle ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return tree_size_eager_fallback ( <NEWLINE> tree_handle , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def degree_sequence_tree ( deg_sequence , create_using = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> degree_sum = sum ( deg_sequence ) <NEWLINE> if degree_sum % <NUMBER> != <NUMBER> : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise nx . NetworkXError ( msg ) <NEWLINE> <UNTAB> if len ( deg_sequence ) - degree_sum // <NUMBER> != <NUMBER> : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> raise nx . NetworkXError ( msg ) <NEWLINE> <UNTAB> G = nx . empty_graph ( <NUMBER> , create_using ) <NEWLINE> if G . is_directed ( ) : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> deg = sorted ( ( s for s in deg_sequence if s > <NUMBER> ) , reverse = True ) <NEWLINE> <NEWLINE> <NEWLINE> n = len ( deg ) + <NUMBER> <NEWLINE> nx . add_path ( G , range ( n ) ) <NEWLINE> last = n <NEWLINE> <NEWLINE> <NEWLINE> for source in range ( <NUMBER> , n - <NUMBER> ) : <NEWLINE> <TAB> nedges = deg . pop ( ) - <NUMBER> <NEWLINE> for target in range ( last , last + nedges ) : <NEWLINE> <TAB> G . add_edge ( source , target ) <NEWLINE> <UNTAB> last += nedges <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if len ( G ) > len ( deg_sequence ) : <NEWLINE> <TAB> G . remove_node ( <NUMBER> ) <NEWLINE> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_linestyle ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _linestyle <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _construct_divmod_result ( left , result , index , name , dtype ) : <NEWLINE> <TAB> <NEWLINE> constructor = left . _constructor <NEWLINE> return ( <NEWLINE> constructor ( result [ <NUMBER> ] , index = index , name = name , dtype = dtype ) , <NEWLINE> constructor ( result [ <NUMBER> ] , index = index , name = name , dtype = dtype ) , <NEWLINE> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def get_projection_names ( ) : <NEWLINE> <TAB> <NEWLINE> return projection_registry . get_projection_names ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def isscalar ( num ) : <NEWLINE> <TAB> <NEWLINE> return ( isinstance ( num , generic ) <NEWLINE> or type ( num ) in ScalarType <NEWLINE> or isinstance ( num , numbers . Number ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def c_code_cache_version ( self ) : <NEWLINE> <TAB> <NEWLINE> return ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _read_int16 ( f ) : <NEWLINE> <TAB> <NEWLINE> return np . int16 ( struct . unpack ( <STRING> , f . read ( <NUMBER> ) [ <NUMBER> : <NUMBER> ] ) [ <NUMBER> ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def python ( expr , ** settings ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> printer = PythonPrinter ( settings ) <NEWLINE> exprp = printer . doprint ( expr ) <NEWLINE> <NEWLINE> result = <STRING> <NEWLINE> <NEWLINE> renamings = { } <NEWLINE> for symbolname in printer . symbols : <NEWLINE> <TAB> newsymbolname = symbolname <NEWLINE> <NEWLINE> if kw . iskeyword ( newsymbolname ) : <NEWLINE> <TAB> while True : <NEWLINE> <TAB> newsymbolname += <STRING> <NEWLINE> if ( newsymbolname not in printer . symbols and <NEWLINE> newsymbolname not in printer . functions ) : <NEWLINE> <TAB> renamings [ sympy . Symbol ( <NEWLINE> symbolname ) ] = sympy . Symbol ( newsymbolname ) <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> <UNTAB> result += newsymbolname + <STRING> + symbolname + <STRING> <NEWLINE> <NEWLINE> <UNTAB> for functionname in printer . functions : <NEWLINE> <TAB> newfunctionname = functionname <NEWLINE> <NEWLINE> if kw . iskeyword ( newfunctionname ) : <NEWLINE> <TAB> while True : <NEWLINE> <TAB> newfunctionname += <STRING> <NEWLINE> if ( newfunctionname not in printer . symbols and <NEWLINE> newfunctionname not in printer . functions ) : <NEWLINE> <TAB> renamings [ sympy . Function ( <NEWLINE> functionname ) ] = sympy . Function ( newfunctionname ) <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> <UNTAB> result += newfunctionname + <STRING> + functionname + <STRING> <NEWLINE> <NEWLINE> <UNTAB> if not len ( renamings ) == <NUMBER> : <NEWLINE> <TAB> exprp = expr . subs ( renamings ) <NEWLINE> <UNTAB> result += <STRING> + printer . _str ( exprp ) <NEWLINE> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _clean_args ( * args ) : <NEWLINE> <TAB> <NEWLINE> newargs = [ ] <NEWLINE> for chk in args : <NEWLINE> <TAB> if chk is None : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> newargs . append ( chk ) <NEWLINE> <UNTAB> return newargs <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_exceptions ( self ) : <NEWLINE> <TAB> <NEWLINE> return [ ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def map ( self , input_tensor ) : <NEWLINE> <TAB> <NEWLINE> input_tensor_shape = input_tensor . get_shape ( ) <NEWLINE> if len ( input_tensor_shape ) != <NUMBER> : <NEWLINE> <TAB> raise dkm . InvalidShapeError ( <NEWLINE> <STRING> % <NEWLINE> len ( input_tensor_shape ) ) <NEWLINE> <NEWLINE> <UNTAB> features_dim = input_tensor_shape [ <NUMBER> ] <NEWLINE> if features_dim != self . _input_dim : <NEWLINE> <TAB> raise dkm . InvalidShapeError ( <NEWLINE> <STRING> % <NEWLINE> ( self . _input_dim , features_dim ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> np . random . seed ( self . _seed ) <NEWLINE> omega_matrix_shape = [ self . _input_dim , self . _output_dim ] <NEWLINE> bias_shape = [ self . _output_dim ] <NEWLINE> <NEWLINE> omega_matrix = constant_op . constant ( <NEWLINE> np . random . normal ( <NEWLINE> scale = <NUMBER> / self . _stddev , size = omega_matrix_shape ) , <NEWLINE> dtype = dtypes . float32 ) <NEWLINE> bias = constant_op . constant ( <NEWLINE> np . random . uniform ( <NEWLINE> low = <NUMBER> , high = <NUMBER> * np . pi , size = bias_shape ) , <NEWLINE> dtype = dtypes . float32 ) <NEWLINE> <NEWLINE> x_omega_plus_bias = math_ops . add ( <NEWLINE> math_ops . matmul ( input_tensor , omega_matrix ) , bias ) <NEWLINE> return math . sqrt ( <NUMBER> / self . _output_dim ) * math_ops . cos ( x_omega_plus_bias ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def entropy ( labels ) : <NEWLINE> <TAB> <NEWLINE> if len ( labels ) == <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> label_idx = np . unique ( labels , return_inverse = True ) [ <NUMBER> ] <NEWLINE> pi = np . bincount ( label_idx ) . astype ( np . float64 ) <NEWLINE> pi = pi [ pi > <NUMBER> ] <NEWLINE> pi_sum = np . sum ( pi ) <NEWLINE> <NEWLINE> <NEWLINE> return - np . sum ( ( pi / pi_sum ) * ( np . log ( pi ) - log ( pi_sum ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def reduce_inequalities ( inequalities , symbols = [ ] ) : <NEWLINE> <TAB> <NEWLINE> if not iterable ( inequalities ) : <NEWLINE> <TAB> inequalities = [ inequalities ] <NEWLINE> <UNTAB> inequalities = [ sympify ( i ) for i in inequalities ] <NEWLINE> <NEWLINE> gens = set ( ) . union ( * [ i . free_symbols for i in inequalities ] ) <NEWLINE> <NEWLINE> if not iterable ( symbols ) : <NEWLINE> <TAB> symbols = [ symbols ] <NEWLINE> <UNTAB> symbols = ( set ( symbols ) or gens ) & gens <NEWLINE> if any ( i . is_real is False for i in symbols ) : <NEWLINE> <TAB> raise TypeError ( filldedent ( ' ' ' 
                         i n e q u a l i t i e s   c a n n o t   c o n t a i n   s y m b o l s   t h a t   a r e   n o t   r e a l . 
                         ' ' ' ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> recast = dict ( [ ( i , Dummy ( i . name , real = True ) ) <NEWLINE> for i in gens if i . is_real is None ] ) <NEWLINE> inequalities = [ i . xreplace ( recast ) for i in inequalities ] <NEWLINE> symbols = { i . xreplace ( recast ) for i in symbols } <NEWLINE> <NEWLINE> <NEWLINE> keep = [ ] <NEWLINE> for i in inequalities : <NEWLINE> <TAB> if isinstance ( i , Relational ) : <NEWLINE> <TAB> i = i . func ( i . lhs . as_expr ( ) - i . rhs . as_expr ( ) , <NUMBER> ) <NEWLINE> <UNTAB> elif i not in ( True , False ) : <NEWLINE> <TAB> i = Eq ( i , <NUMBER> ) <NEWLINE> <UNTAB> if i == True : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> elif i == False : <NEWLINE> <TAB> return S . false <NEWLINE> <UNTAB> if i . lhs . is_number : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> % i ) <NEWLINE> <UNTAB> keep . append ( i ) <NEWLINE> <UNTAB> inequalities = keep <NEWLINE> del keep <NEWLINE> <NEWLINE> <NEWLINE> rv = _reduce_inequalities ( inequalities , symbols ) <NEWLINE> <NEWLINE> <NEWLINE> return rv . xreplace ( { v : k for k , v in recast . items ( ) } ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __eq__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return all ( getattr ( self , a , None ) == getattr ( other , a , None ) <NEWLINE> for a in [ <STRING> , <STRING> , <STRING> , <STRING> ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gf_frobenius_monomial_base ( g , p , K ) : <NEWLINE> <TAB> <NEWLINE> n = gf_degree ( g ) <NEWLINE> if n == <NUMBER> : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> b = [ <NUMBER> ] * n <NEWLINE> b [ <NUMBER> ] = [ <NUMBER> ] <NEWLINE> if p < n : <NEWLINE> <TAB> for i in range ( <NUMBER> , n ) : <NEWLINE> <TAB> mon = gf_lshift ( b [ i - <NUMBER> ] , p , K ) <NEWLINE> b [ i ] = gf_rem ( mon , g , p , K ) <NEWLINE> <UNTAB> <UNTAB> elif n > <NUMBER> : <NEWLINE> <TAB> b [ <NUMBER> ] = gf_pow_mod ( [ K . one , K . zero ] , p , g , p , K ) <NEWLINE> for i in range ( <NUMBER> , n ) : <NEWLINE> <TAB> b [ i ] = gf_mul ( b [ i - <NUMBER> ] , b [ <NUMBER> ] , p , K ) <NEWLINE> b [ i ] = gf_rem ( b [ i ] , g , p , K ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return b <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def pow_xin ( p , i , n ) : <NEWLINE> <TAB> <NEWLINE> R = p . ring <NEWLINE> q = R ( <NUMBER> ) <NEWLINE> for k , v in p . items ( ) : <NEWLINE> <TAB> k1 = list ( k ) <NEWLINE> k1 [ i ] *= n <NEWLINE> q [ tuple ( k1 ) ] = v <NEWLINE> <UNTAB> return q <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _get_backing_memmap ( a ) : <NEWLINE> <TAB> <NEWLINE> b = getattr ( a , <STRING> , None ) <NEWLINE> if b is None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> elif isinstance ( b , mmap ) : <NEWLINE> <NEWLINE> <TAB> return a <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> return _get_backing_memmap ( b ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , trainer = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> reporter = reporter_module . Reporter ( ) <NEWLINE> if self . name is not None : <NEWLINE> <TAB> prefix = self . name + <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> prefix = <STRING> <NEWLINE> <UNTAB> for name , target in six . iteritems ( self . _targets ) : <NEWLINE> <TAB> reporter . add_observer ( prefix + name , target ) <NEWLINE> reporter . add_observers ( prefix + name , <NEWLINE> target . namedlinks ( skipself = True ) ) <NEWLINE> <NEWLINE> <UNTAB> with reporter : <NEWLINE> <TAB> with configuration . using_config ( <STRING> , False ) : <NEWLINE> <TAB> result = self . evaluate ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> reporter_module . report ( result ) <NEWLINE> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _preprocess_conv3d_input ( x , data_format ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if ( dtype ( x ) == <STRING> and <NEWLINE> StrictVersion ( tf . __version__ . split ( <STRING> ) [ <NUMBER> ] ) < StrictVersion ( <STRING> ) ) : <NEWLINE> <TAB> x = tf . cast ( x , <STRING> ) <NEWLINE> <UNTAB> tf_data_format = <STRING> <NEWLINE> if data_format == <STRING> : <NEWLINE> <TAB> if not _has_nchw_support ( ) : <NEWLINE> <TAB> x = tf . transpose ( x , ( <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> tf_data_format = <STRING> <NEWLINE> <UNTAB> <UNTAB> return x , tf_data_format <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def diff ( f , * symbols , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> kwargs . setdefault ( <STRING> , True ) <NEWLINE> try : <NEWLINE> <TAB> return f . _eval_diff ( * symbols , ** kwargs ) <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> return Derivative ( f , * symbols , ** kwargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def size ( self ) : <NEWLINE> <TAB> <NEWLINE> return model_ops . tree_size ( self . variables . tree ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def ycbcr2rgb ( ycbcr ) : <NEWLINE> <TAB> <NEWLINE> arr = ycbcr . copy ( ) <NEWLINE> arr [ ... , <NUMBER> ] -= <NUMBER> <NEWLINE> arr [ ... , <NUMBER> ] -= <NUMBER> <NEWLINE> arr [ ... , <NUMBER> ] -= <NUMBER> <NEWLINE> return _convert ( rgb_from_ycbcr , arr ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def copy_op_to_graph ( org_instance , to_graph , variables , scope = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if scope != <STRING> : <NEWLINE> <TAB> new_name = scope + <STRING> + org_instance . name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> new_name = org_instance . name <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> copied_variables = dict ( ( x . name , x ) for x in variables ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if new_name in copied_variables : <NEWLINE> <TAB> return to_graph . get_tensor_by_name ( copied_variables [ new_name ] . name ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> already_present = to_graph . as_graph_element ( <NEWLINE> new_name , allow_tensor = True , allow_operation = True ) <NEWLINE> return already_present <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> collections = [ ] <NEWLINE> for name , collection in org_instance . graph . _collections . items ( ) : <NEWLINE> <TAB> if org_instance in collection : <NEWLINE> <TAB> if scope == <STRING> : <NEWLINE> <TAB> collections . append ( name ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> collections . append ( scope + <STRING> + name ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if isinstance ( org_instance , ops . Tensor ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> op = org_instance . op <NEWLINE> new_op = copy_op_to_graph ( op , to_graph , variables , scope ) <NEWLINE> output_index = op . outputs . index ( org_instance ) <NEWLINE> new_tensor = new_op . outputs [ output_index ] <NEWLINE> <NEWLINE> for collection in collections : <NEWLINE> <TAB> to_graph . add_to_collection ( collection , new_tensor ) <NEWLINE> <NEWLINE> <UNTAB> return new_tensor <NEWLINE> <NEWLINE> <UNTAB> elif isinstance ( org_instance , ops . Operation ) : <NEWLINE> <NEWLINE> <TAB> op = org_instance <NEWLINE> <NEWLINE> <NEWLINE> if op . _original_op is not None : <NEWLINE> <TAB> new_original_op = copy_op_to_graph ( op . _original_op , to_graph , variables , <NEWLINE> scope ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> new_original_op = None <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> new_control_inputs = [ <NEWLINE> copy_op_to_graph ( x , to_graph , variables , scope ) <NEWLINE> for x in op . control_inputs <NEWLINE> ] <NEWLINE> <NEWLINE> <NEWLINE> new_inputs = [ <NEWLINE> copy_op_to_graph ( x , to_graph , variables , scope ) for x in op . inputs <NEWLINE> ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> new_node_def = deepcopy ( op . node_def ) <NEWLINE> <NEWLINE> new_node_def . name = new_name <NEWLINE> <NEWLINE> <NEWLINE> output_types = op . _output_types [ : ] <NEWLINE> input_types = op . _input_types [ : ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> op_def = deepcopy ( op . op_def ) <NEWLINE> <NEWLINE> <NEWLINE> new_op = ops . Operation ( new_node_def , to_graph , new_inputs , output_types , <NEWLINE> new_control_inputs , input_types , new_original_op , <NEWLINE> op_def ) <NEWLINE> <NEWLINE> to_graph . _record_op_seen_by_control_dependencies ( new_op ) <NEWLINE> <NEWLINE> for device_function in to_graph . _device_functions_outer_to_inner : <NEWLINE> <TAB> new_op . _set_device ( device_function ( new_op ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return new_op <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> + str ( org_instance ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def rename_categories ( self , new_categories , inplace = False ) : <NEWLINE> <TAB> <NEWLINE> inplace = validate_bool_kwarg ( inplace , <STRING> ) <NEWLINE> cat = self if inplace else self . copy ( ) <NEWLINE> <NEWLINE> if isinstance ( new_categories , ABCSeries ) : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> warn ( msg , FutureWarning , stacklevel = <NUMBER> ) <NEWLINE> new_categories = list ( new_categories ) <NEWLINE> <NEWLINE> <UNTAB> if is_dict_like ( new_categories ) : <NEWLINE> <TAB> cat . categories = [ new_categories . get ( item , item ) <NEWLINE> for item in cat . categories ] <NEWLINE> <UNTAB> elif callable ( new_categories ) : <NEWLINE> <TAB> cat . categories = [ new_categories ( item ) for item in cat . categories ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cat . categories = new_categories <NEWLINE> <UNTAB> if not inplace : <NEWLINE> <TAB> return cat <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _rgb_to_rgba ( A ) : <NEWLINE> <TAB> <NEWLINE> rgba = np . zeros ( ( A . shape [ <NUMBER> ] , A . shape [ <NUMBER> ] , <NUMBER> ) , dtype = A . dtype ) <NEWLINE> rgba [ : , : , : <NUMBER> ] = A <NEWLINE> if rgba . dtype == np . uint8 : <NEWLINE> <TAB> rgba [ : , : , <NUMBER> ] = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rgba [ : , : , <NUMBER> ] = <NUMBER> <NEWLINE> <UNTAB> return rgba <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def generate_pajek ( G ) : <NEWLINE> <TAB> <NEWLINE> if G . name == <STRING> : <NEWLINE> <TAB> name = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> name = G . name <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> yield <STRING> % ( G . order ( ) ) <NEWLINE> nodes = list ( G ) <NEWLINE> <NEWLINE> nodenumber = dict ( zip ( nodes , range ( <NUMBER> , len ( nodes ) + <NUMBER> ) ) ) <NEWLINE> for n in nodes : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> na = G . nodes . get ( n , { } ) . copy ( ) <NEWLINE> x = na . pop ( <STRING> , <NUMBER> ) <NEWLINE> y = na . pop ( <STRING> , <NUMBER> ) <NEWLINE> id = int ( na . pop ( <STRING> , nodenumber [ n ] ) ) <NEWLINE> nodenumber [ n ] = id <NEWLINE> shape = na . pop ( <STRING> , <STRING> ) <NEWLINE> s = <STRING> . join ( map ( make_qstr , ( id , n , x , y , shape ) ) ) <NEWLINE> <NEWLINE> for k , v in na . items ( ) : <NEWLINE> <TAB> if is_string_like ( v ) and v . strip ( ) != <STRING> : <NEWLINE> <TAB> s += <STRING> % ( make_qstr ( k ) , make_qstr ( v ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> warnings . warn ( <STRING> % <NEWLINE> ( k , <NEWLINE> <STRING> if is_string_like ( v ) else <NEWLINE> <STRING> ) ) <NEWLINE> <UNTAB> <UNTAB> yield s <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if G . is_directed ( ) : <NEWLINE> <TAB> yield <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> yield <STRING> <NEWLINE> <UNTAB> for u , v , edgedata in G . edges ( data = True ) : <NEWLINE> <TAB> d = edgedata . copy ( ) <NEWLINE> value = d . pop ( <STRING> , <NUMBER> ) <NEWLINE> s = <STRING> . join ( map ( make_qstr , ( nodenumber [ u ] , nodenumber [ v ] , value ) ) ) <NEWLINE> for k , v in d . items ( ) : <NEWLINE> <TAB> if is_string_like ( v ) and v . strip ( ) != <STRING> : <NEWLINE> <TAB> s += <STRING> % ( make_qstr ( k ) , make_qstr ( v ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> warnings . warn ( <STRING> % <NEWLINE> ( k , <NEWLINE> <STRING> if is_string_like ( v ) else <NEWLINE> <STRING> ) ) <NEWLINE> <UNTAB> <UNTAB> yield s <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def make_node ( self , * inputs ) : <NEWLINE> <TAB> <NEWLINE> assert np . all ( isinstance ( i , gof . Variable ) for i in inputs ) <NEWLINE> <NEWLINE> <NEWLINE> n_outer_ins = len ( inputs ) - len ( self . outer_nitsot ( inputs ) ) - <NUMBER> <NEWLINE> n_inner_ins = ( len ( self . inner_seqs ( self . inputs ) ) + <NEWLINE> len ( self . mitmot_taps ( ) ) + <NEWLINE> len ( self . mitsot_taps ( ) ) + <NEWLINE> len ( self . inner_sitsot ( self . inputs ) ) + <NEWLINE> len ( self . inner_shared ( self . inputs ) ) + <NEWLINE> len ( self . inner_non_seqs ( self . inputs ) ) ) <NEWLINE> assert n_outer_ins == n_inner_ins , ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> new_inputs = [ as_tensor_variable ( inputs [ <NUMBER> ] ) ] <NEWLINE> <NEWLINE> err_msg1 = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> ) <NEWLINE> err_msg2 = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> err_msg3 = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> ) <NEWLINE> <NEWLINE> def check_broadcast ( v1 , v2 ) : <NEWLINE> <TAB> <NEWLINE> if ( not hasattr ( v1 , <STRING> ) and <NEWLINE> not hasattr ( v2 , <STRING> ) ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> msg = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> size = min ( len ( v1 . broadcastable ) , len ( v2 . broadcastable ) ) <NEWLINE> for n , ( b1 , b2 ) in enumerate ( zip ( v1 . broadcastable [ - size : ] , <NEWLINE> v2 . broadcastable [ - size : ] ) ) : <NEWLINE> <TAB> if b1 != b2 : <NEWLINE> <TAB> a1 = n + size - len ( v1 . broadcastable ) + <NUMBER> <NEWLINE> a2 = n + size - len ( v2 . broadcastable ) + <NUMBER> <NEWLINE> raise TypeError ( msg % ( v1 . type , v2 . type , a1 , b1 , b2 , a2 ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> def format ( var , as_var ) : <NEWLINE> <TAB> <NEWLINE> if not hasattr ( var , <STRING> ) : <NEWLINE> <TAB> return var <NEWLINE> <UNTAB> rval = var <NEWLINE> if rval . type . dtype != as_var . type . dtype : <NEWLINE> <TAB> rval = rval . astype ( as_var . type . dtype ) <NEWLINE> <UNTAB> if rval . ndim == as_var . ndim : <NEWLINE> <TAB> rval = as_var . type . filter_variable ( rval ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> tmp = as_var . type . clone ( <NEWLINE> broadcastable = ( tuple ( var . broadcastable [ : <NUMBER> ] ) + <NEWLINE> tuple ( as_var . broadcastable ) ) ) <NEWLINE> rval = tmp . filter_variable ( rval ) <NEWLINE> <UNTAB> return rval <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> argoffset = <NUMBER> <NEWLINE> for inner_seq , outer_seq in zip ( self . inner_seqs ( self . inputs ) , <NEWLINE> self . outer_seqs ( inputs ) ) : <NEWLINE> <TAB> check_broadcast ( outer_seq , inner_seq ) <NEWLINE> new_inputs . append ( format ( outer_seq , as_var = inner_seq ) ) <NEWLINE> <NEWLINE> <UNTAB> argoffset += len ( self . outer_seqs ( inputs ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> ipos = <NUMBER> <NEWLINE> opos = <NUMBER> <NEWLINE> inner_mitmot = self . inner_mitmot ( self . inputs ) <NEWLINE> inner_mitmot_outs = self . inner_mitmot_outs ( self . outputs ) <NEWLINE> for idx , ( itaps , otaps , _outer_mitmot ) in enumerate ( <NEWLINE> zip ( self . mitmot_taps ( ) , <NEWLINE> self . mitmot_out_taps ( ) , <NEWLINE> self . outer_mitmot ( inputs ) ) ) : <NEWLINE> <TAB> outer_mitmot = format ( _outer_mitmot , as_var = inner_mitmot [ ipos ] ) <NEWLINE> new_inputs . append ( outer_mitmot ) <NEWLINE> for k in xrange ( len ( itaps ) ) : <NEWLINE> <TAB> if ( inner_mitmot [ ipos + k ] . type . dtype != <NEWLINE> outer_mitmot . type . dtype or <NEWLINE> inner_mitmot [ ipos + k ] . ndim != outer_mitmot . ndim - <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( err_msg1 % ( <STRING> <NEWLINE> <STRING> , <NEWLINE> str ( outer_mitmot ) , <NEWLINE> argoffset + idx , <NEWLINE> outer_mitmot . type . dtype , <NEWLINE> outer_mitmot . type . ndim , <NEWLINE> str ( inner_mitmot [ ipos + k ] ) , <NEWLINE> inner_mitmot [ ipos + <NEWLINE> k ] . type . dtype , <NEWLINE> inner_mitmot [ ipos + k ] . type . ndim ) ) <NEWLINE> <UNTAB> <UNTAB> ipos += len ( itaps ) <NEWLINE> for k in xrange ( len ( otaps ) ) : <NEWLINE> <TAB> if ( inner_mitmot_outs [ opos + k ] . type . dtype != <NEWLINE> outer_mitmot . type . dtype ) : <NEWLINE> <TAB> raise ValueError ( err_msg2 % <NEWLINE> ( str ( outer_mitmot ) , <NEWLINE> argoffset + idx , <NEWLINE> outer_mitmot . type . dtype , <NEWLINE> inner_mitmot_outs [ opos + k ] . type . dtype ) ) <NEWLINE> <UNTAB> if inner_mitmot_outs [ opos + k ] . ndim != outer_mitmot . ndim - <NUMBER> : <NEWLINE> <TAB> raise ValueError ( err_msg3 % <NEWLINE> ( str ( outer_mitmot ) , <NEWLINE> argoffset + idx , <NEWLINE> outer_mitmot . ndim , <NEWLINE> inner_mitmot_outs [ opos + k ] . ndim ) ) <NEWLINE> <UNTAB> <UNTAB> opos += len ( otaps ) <NEWLINE> <UNTAB> argoffset += len ( self . outer_mitmot ( inputs ) ) <NEWLINE> <NEWLINE> ipos = <NUMBER> <NEWLINE> inner_mitsots = self . inner_mitsot ( self . inputs ) <NEWLINE> for idx , ( itaps , _outer_mitsot , inner_mitsot_out ) in enumerate ( <NEWLINE> zip ( self . mitsot_taps ( ) , <NEWLINE> self . outer_mitsot ( inputs ) , <NEWLINE> self . inner_mitsot_outs ( self . outputs ) ) ) : <NEWLINE> <TAB> outer_mitsot = format ( _outer_mitsot , as_var = inner_mitsots [ ipos ] ) <NEWLINE> new_inputs . append ( outer_mitsot ) <NEWLINE> <NEWLINE> for k in xrange ( len ( itaps ) ) : <NEWLINE> <TAB> if ( inner_mitsots [ ipos + k ] . type . dtype != <NEWLINE> outer_mitsot . type . dtype or <NEWLINE> inner_mitsots [ ipos + k ] . ndim != outer_mitsot . ndim - <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( err_msg1 % ( <STRING> <NEWLINE> <STRING> , <NEWLINE> str ( outer_mitsot ) , <NEWLINE> argoffset + idx , <NEWLINE> outer_mitsot . type . dtype , <NEWLINE> outer_mitsot . type . ndim , <NEWLINE> str ( inner_mitsots [ ipos + k ] ) , <NEWLINE> inner_mitsots [ ipos + k ] . type . dtype , <NEWLINE> inner_mitsots [ ipos + k ] . type . ndim ) ) <NEWLINE> <UNTAB> <UNTAB> ipos += len ( itaps ) <NEWLINE> if inner_mitsot_out . type . dtype != outer_mitsot . type . dtype : <NEWLINE> <TAB> raise ValueError ( err_msg2 % <NEWLINE> ( str ( outer_mitsot ) , <NEWLINE> argoffset + idx , <NEWLINE> outer_mitsot . type . dtype , <NEWLINE> inner_mitsot_out . type . dtype ) ) <NEWLINE> <UNTAB> if inner_mitsot_out . ndim != outer_mitsot . ndim - <NUMBER> : <NEWLINE> <TAB> raise ValueError ( err_msg3 % <NEWLINE> ( str ( outer_mitsot ) , <NEWLINE> argoffset + idx , <NEWLINE> outer_mitsot . ndim , <NEWLINE> inner_mitsot_out . ndim ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> argoffset += len ( self . outer_mitsot ( inputs ) ) <NEWLINE> <NEWLINE> for idx , ( inner_sitsot , _outer_sitsot , inner_sitsot_out ) in enumerate ( <NEWLINE> zip ( self . inner_sitsot ( self . inputs ) , <NEWLINE> self . outer_sitsot ( inputs ) , <NEWLINE> self . inner_sitsot_outs ( self . outputs ) ) ) : <NEWLINE> <TAB> outer_sitsot = format ( _outer_sitsot , as_var = inner_sitsot ) <NEWLINE> new_inputs . append ( outer_sitsot ) <NEWLINE> if ( inner_sitsot . ndim != outer_sitsot . ndim - <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( err_msg1 % ( <STRING> <NEWLINE> <STRING> , <NEWLINE> str ( outer_sitsot ) , <NEWLINE> argoffset + idx , <NEWLINE> outer_sitsot . type . dtype , <NEWLINE> outer_sitsot . type . ndim , <NEWLINE> str ( inner_sitsot ) , <NEWLINE> inner_sitsot . type . dtype , <NEWLINE> inner_sitsot . type . ndim ) ) <NEWLINE> <UNTAB> if inner_sitsot_out . type . dtype != outer_sitsot . type . dtype : <NEWLINE> <TAB> raise ValueError ( err_msg2 % <NEWLINE> ( str ( outer_sitsot ) , <NEWLINE> argoffset + idx , <NEWLINE> outer_sitsot . type . dtype , <NEWLINE> inner_sitsot_out . type . dtype ) ) <NEWLINE> <UNTAB> if inner_sitsot_out . ndim != outer_sitsot . ndim - <NUMBER> : <NEWLINE> <TAB> raise ValueError ( err_msg3 % <NEWLINE> ( str ( outer_sitsot ) , <NEWLINE> argoffset + idx , <NEWLINE> outer_sitsot . type . ndim , <NEWLINE> inner_sitsot_out . type . ndim ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> argoffset += len ( self . outer_sitsot ( inputs ) ) <NEWLINE> <NEWLINE> <NEWLINE> for idx , ( inner_shared , inner_shared_out , _outer_shared ) in enumerate ( <NEWLINE> zip ( self . inner_shared ( self . inputs ) , <NEWLINE> self . inner_shared_outs ( self . outputs ) , <NEWLINE> self . outer_shared ( inputs ) ) ) : <NEWLINE> <TAB> outer_shared = format ( _outer_shared , as_var = inner_shared ) <NEWLINE> new_inputs . append ( outer_shared ) <NEWLINE> if ( hasattr ( outer_shared , <STRING> ) and <NEWLINE> outer_shared . dtype != inner_shared_out . dtype ) : <NEWLINE> <TAB> raise ValueError ( err_msg2 % ( str ( outer_shared ) , <NEWLINE> idx + argoffset , <NEWLINE> outer_shared . dtype , <NEWLINE> inner_shared_out . dtype ) ) <NEWLINE> <UNTAB> if ( hasattr ( outer_shared , <STRING> ) and <NEWLINE> outer_shared . ndim != inner_shared_out . ndim ) : <NEWLINE> <TAB> raise ValueError ( err_msg3 % ( str ( outer_shared ) , <NEWLINE> idx + argoffset , <NEWLINE> outer_shared . ndim , <NEWLINE> inner_shared_out . ndim ) ) <NEWLINE> <NEWLINE> <UNTAB> if ( hasattr ( outer_shared , <STRING> ) and <NEWLINE> ( outer_shared . dtype != inner_shared . dtype or <NEWLINE> outer_shared . ndim != inner_shared . ndim ) ) : <NEWLINE> <TAB> raise ValueError ( err_msg1 % ( <STRING> <NEWLINE> <STRING> , <NEWLINE> str ( outer_shared ) , <NEWLINE> argoffset + idx , <NEWLINE> outer_shared . dtype , <NEWLINE> outer_shared . ndim , <NEWLINE> str ( inner_shared ) , <NEWLINE> inner_shared . dtype , <NEWLINE> inner_shared . ndim ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> new_inputs += [ as_tensor_variable ( ons ) <NEWLINE> for ons in self . outer_nitsot ( inputs ) ] <NEWLINE> for inner_nonseq , _outer_nonseq in zip ( self . inner_non_seqs ( self . inputs ) , <NEWLINE> self . outer_non_seqs ( inputs ) ) : <NEWLINE> <TAB> outer_nonseq = format ( _outer_nonseq , as_var = inner_nonseq ) <NEWLINE> new_inputs . append ( outer_nonseq ) <NEWLINE> if inner_nonseq . type != outer_nonseq . type : <NEWLINE> <TAB> raise ValueError ( ( <STRING> <NEWLINE> <STRING> ) % <NEWLINE> ( str ( outer_nonseq ) , str ( inner_nonseq ) ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for outer_nitsot in self . outer_nitsot ( inputs ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if ( str ( outer_nitsot . type . dtype ) not in tensor . integer_dtypes or <NEWLINE> outer_nitsot . ndim != <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> , str ( outer_nitsot ) ) <NEWLINE> <UNTAB> <UNTAB> assert len ( new_inputs ) == len ( inputs ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> def is_cpu_vector ( s ) : <NEWLINE> <TAB> return isinstance ( s . type , tensor . TensorType ) and s . ndim == <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> self . vector_seqs = [ <NEWLINE> is_cpu_vector ( seq ) for seq in new_inputs [ <NUMBER> : <NUMBER> + self . n_seqs ] ] <NEWLINE> self . vector_outs = [ <NEWLINE> is_cpu_vector ( arg ) for arg in new_inputs [ <NEWLINE> <NUMBER> + self . n_seqs : ( <NUMBER> + self . n_seqs + self . n_outs ) ] ] <NEWLINE> self . vector_outs += [ <NEWLINE> isinstance ( t . type , tensor . TensorType ) and t . ndim == <NUMBER> <NEWLINE> for t in self . outer_nitsot_outs ( self . outputs ) ] <NEWLINE> <NEWLINE> apply_node = Apply ( self , <NEWLINE> new_inputs , <NEWLINE> [ t ( ) for t in self . output_types ] ) <NEWLINE> return apply_node <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def write ( self , dataset ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( dataset , dataset_ops . Dataset ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if ( dataset . output_types != dtypes . string or <NEWLINE> dataset . output_shapes != tensor_shape . scalar ( ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( dataset . output_shapes , <NEWLINE> dataset . output_types ) ) <NEWLINE> <UNTAB> return gen_dataset_ops . dataset_to_tf_record ( <NEWLINE> dataset . _as_variant_tensor ( ) , self . _filename , self . _compression_type ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def hermint ( c , m = <NUMBER> , k = [ ] , lbnd = <NUMBER> , scl = <NUMBER> , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> c = np . array ( c , ndmin = <NUMBER> , copy = <NUMBER> ) <NEWLINE> if c . dtype . char in <STRING> : <NEWLINE> <TAB> c = c . astype ( np . double ) <NEWLINE> <UNTAB> if not np . iterable ( k ) : <NEWLINE> <TAB> k = [ k ] <NEWLINE> <UNTAB> cnt , iaxis = [ int ( t ) for t in [ m , axis ] ] <NEWLINE> <NEWLINE> if cnt != m : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if cnt < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if len ( k ) > cnt : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if np . ndim ( lbnd ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if np . ndim ( scl ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if iaxis != axis : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> iaxis = normalize_axis_index ( iaxis , c . ndim ) <NEWLINE> <NEWLINE> if cnt == <NUMBER> : <NEWLINE> <TAB> return c <NEWLINE> <NEWLINE> <UNTAB> c = np . moveaxis ( c , iaxis , <NUMBER> ) <NEWLINE> k = list ( k ) + [ <NUMBER> ] * ( cnt - len ( k ) ) <NEWLINE> for i in range ( cnt ) : <NEWLINE> <TAB> n = len ( c ) <NEWLINE> c *= scl <NEWLINE> if n == <NUMBER> and np . all ( c [ <NUMBER> ] == <NUMBER> ) : <NEWLINE> <TAB> c [ <NUMBER> ] += k [ i ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> tmp = np . empty ( ( n + <NUMBER> , ) + c . shape [ <NUMBER> : ] , dtype = c . dtype ) <NEWLINE> tmp [ <NUMBER> ] = c [ <NUMBER> ] * <NUMBER> <NEWLINE> tmp [ <NUMBER> ] = c [ <NUMBER> ] / <NUMBER> <NEWLINE> for j in range ( <NUMBER> , n ) : <NEWLINE> <TAB> tmp [ j + <NUMBER> ] = c [ j ] / ( <NUMBER> * ( j + <NUMBER> ) ) <NEWLINE> <UNTAB> tmp [ <NUMBER> ] += k [ i ] - hermval ( lbnd , tmp ) <NEWLINE> c = tmp <NEWLINE> <UNTAB> <UNTAB> c = np . moveaxis ( c , <NUMBER> , iaxis ) <NEWLINE> return c <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _RemoveExternalControlEdges ( self , op ) : <NEWLINE> <TAB> <NEWLINE> while_ctxt = self . GetWhileContext ( ) <NEWLINE> <NEWLINE> <NEWLINE> if while_ctxt is None : <NEWLINE> <TAB> internal_control_inputs = op . control_inputs <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> internal_control_inputs = [ ] <NEWLINE> for x in op . control_inputs : <NEWLINE> <TAB> ctxt = util . GetOutputContext ( x ) <NEWLINE> if ctxt is not None and ctxt . GetWhileContext ( ) == while_ctxt : <NEWLINE> <TAB> internal_control_inputs . append ( x ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> external_control_inputs = [ ] <NEWLINE> if len ( internal_control_inputs ) != len ( op . control_inputs ) : <NEWLINE> <TAB> external_control_inputs = list ( <NEWLINE> set ( op . control_inputs ) - set ( internal_control_inputs ) ) <NEWLINE> op . _remove_all_control_inputs ( ) <NEWLINE> op . _add_control_inputs ( internal_control_inputs ) <NEWLINE> <UNTAB> return internal_control_inputs , external_control_inputs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _format_attrs ( self ) : <NEWLINE> <TAB> <NEWLINE> attrs = [ <NEWLINE> ( <STRING> , ibase . default_pprint ( self . _levels , <NEWLINE> max_seq_items = False ) ) , <NEWLINE> ( <STRING> , ibase . default_pprint ( self . _labels , <NEWLINE> max_seq_items = False ) ) ] <NEWLINE> if com . _any_not_none ( * self . names ) : <NEWLINE> <TAB> attrs . append ( ( <STRING> , ibase . default_pprint ( self . names ) ) ) <NEWLINE> <UNTAB> if self . sortorder is not None : <NEWLINE> <TAB> attrs . append ( ( <STRING> , ibase . default_pprint ( self . sortorder ) ) ) <NEWLINE> <UNTAB> return attrs <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def convolve ( a , v , mode = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> a , v = array ( a , copy = False , ndmin = <NUMBER> ) , array ( v , copy = False , ndmin = <NUMBER> ) <NEWLINE> if ( len ( v ) > len ( a ) ) : <NEWLINE> <TAB> a , v = v , a <NEWLINE> <UNTAB> if len ( a ) == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if len ( v ) == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> mode = _mode_from_name ( mode ) <NEWLINE> return multiarray . correlate ( a , v [ : : - <NUMBER> ] , mode ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def randrange ( self , start , stop = None , step = <NUMBER> , _int = int ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> istart = _int ( start ) <NEWLINE> if istart != start : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if stop is None : <NEWLINE> <TAB> if istart > <NUMBER> : <NEWLINE> <TAB> return self . _randbelow ( istart ) <NEWLINE> <UNTAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> istop = _int ( stop ) <NEWLINE> if istop != stop : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> width = istop - istart <NEWLINE> if step == <NUMBER> and width > <NUMBER> : <NEWLINE> <TAB> return istart + self . _randbelow ( width ) <NEWLINE> <UNTAB> if step == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( istart , istop , width ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> istep = _int ( step ) <NEWLINE> if istep != step : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if istep > <NUMBER> : <NEWLINE> <TAB> n = ( width + istep - <NUMBER> ) // istep <NEWLINE> <UNTAB> elif istep < <NUMBER> : <NEWLINE> <TAB> n = ( width + istep + <NUMBER> ) // istep <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if n <= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return istart + istep * self . _randbelow ( n ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def read_var_array ( self , header , process = True ) : <NEWLINE> <TAB> <NEWLINE> return self . _matrix_reader . array_from_header ( header , process ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def reduce ( self , aggregation , per_device_value , destinations ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( per_device_value , value_lib . PerDevice ) : <NEWLINE> <TAB> per_device_value = _make_tensor_into_per_device ( per_device_value ) <NEWLINE> <NEWLINE> <UNTAB> validate_destinations ( destinations ) <NEWLINE> return self . _reduce ( aggregation , per_device_value , destinations ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def mod_eager_fallback ( x , y , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ x , y ] , _ctx ) <NEWLINE> ( x , y ) = _inputs_T <NEWLINE> _inputs_flat = [ x , y ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def translate ( images , translations , interpolation = <STRING> , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> ) : <NEWLINE> <TAB> return transform ( <NEWLINE> images , <NEWLINE> translations_to_projective_transforms ( translations ) , <NEWLINE> interpolation = interpolation ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_trigger ( trigger ) : <NEWLINE> <TAB> <NEWLINE> if callable ( trigger ) : <NEWLINE> <TAB> return trigger <NEWLINE> <UNTAB> elif trigger is None : <NEWLINE> <TAB> return _never_fire_trigger <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return interval_trigger . IntervalTrigger ( * trigger ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sign_eager_fallback ( x , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , ( x , ) = _execute . args_to_matching_eager ( [ x ] , _ctx ) <NEWLINE> _inputs_flat = [ x ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def get_indexer_dict ( label_list , keys ) : <NEWLINE> <TAB> <NEWLINE> shape = list ( map ( len , keys ) ) <NEWLINE> <NEWLINE> group_index = get_group_index ( label_list , shape , sort = True , xnull = True ) <NEWLINE> ngroups = ( ( group_index . size and group_index . max ( ) ) + <NUMBER> ) if is_int64_overflow_possible ( shape ) else np . prod ( shape , dtype = <STRING> ) <NEWLINE> <NEWLINE> sorter = get_group_index_sorter ( group_index , ngroups ) <NEWLINE> <NEWLINE> sorted_labels = [ lab . take ( sorter ) for lab in label_list ] <NEWLINE> group_index = group_index . take ( sorter ) <NEWLINE> <NEWLINE> return lib . indices_fast ( sorter , group_index , keys , sorted_labels ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ abc . abstractmethod <NEWLINE> def as_signature_def ( self , receiver_tensors ) : <NEWLINE> <TAB> <NEWLINE> pass <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_ordered ( self , value , inplace = False ) : <NEWLINE> <TAB> <NEWLINE> inplace = validate_bool_kwarg ( inplace , <STRING> ) <NEWLINE> new_dtype = CategoricalDtype ( self . categories , ordered = value ) <NEWLINE> cat = self if inplace else self . copy ( ) <NEWLINE> cat . _dtype = new_dtype <NEWLINE> if not inplace : <NEWLINE> <TAB> return cat <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def chebline ( off , scl ) : <NEWLINE> <TAB> <NEWLINE> if scl != <NUMBER> : <NEWLINE> <TAB> return np . array ( [ off , scl ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return np . array ( [ off ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _call_model_fn_eval ( self , input_fn , config ) : <NEWLINE> <TAB> <NEWLINE> features , labels , input_hooks = self . _get_features_and_labels_from_input_fn ( <NEWLINE> input_fn , model_fn_lib . ModeKeys . EVAL ) <NEWLINE> <NEWLINE> estimator_spec = self . _call_model_fn ( <NEWLINE> features , labels , model_fn_lib . ModeKeys . EVAL , config ) <NEWLINE> eval_metric_ops = _verify_and_create_loss_metric ( <NEWLINE> estimator_spec . eval_metric_ops , estimator_spec . loss ) <NEWLINE> update_op , eval_dict = _extract_metric_update_ops ( eval_metric_ops ) <NEWLINE> return ( estimator_spec . scaffold , estimator_spec . evaluation_hooks , <NEWLINE> input_hooks , update_op , eval_dict ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def in_top_kv2 ( predictions , targets , k , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , predictions = predictions , targets = targets , k = k , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , predictions , targets , k ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return in_top_kv2_eager_fallback ( <NEWLINE> predictions , targets , k , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def contracted_edge ( G , edge , self_loops = True ) : <NEWLINE> <TAB> <NEWLINE> if not G . has_edge ( * edge ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( edge ) ) <NEWLINE> <UNTAB> return contracted_nodes ( G , * edge , self_loops = self_loops ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def overlap_internal ( x , axes ) : <NEWLINE> <TAB> <NEWLINE> dims = list ( map ( len , x . chunks ) ) <NEWLINE> expand_key2 = partial ( expand_key , dims = dims , axes = axes ) <NEWLINE> <NEWLINE> <NEWLINE> interior_keys = pipe ( x . __dask_keys__ ( ) , flatten , map ( expand_key2 ) , <NEWLINE> map ( flatten ) , concat , list ) <NEWLINE> <NEWLINE> name = <STRING> + tokenize ( x , axes ) <NEWLINE> getitem_name = <STRING> + tokenize ( x , axes ) <NEWLINE> interior_slices = { } <NEWLINE> overlap_blocks = { } <NEWLINE> for k in interior_keys : <NEWLINE> <TAB> frac_slice = fractional_slice ( ( x . name , ) + k , axes ) <NEWLINE> if ( x . name , ) + k != frac_slice : <NEWLINE> <TAB> interior_slices [ ( getitem_name , ) + k ] = frac_slice <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> interior_slices [ ( getitem_name , ) + k ] = ( x . name , ) + k <NEWLINE> overlap_blocks [ ( name , ) + k ] = ( concatenate3 , <NEWLINE> ( concrete , expand_key2 ( ( None , ) + k , name = getitem_name ) ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> chunks = [ ] <NEWLINE> for i , bds in enumerate ( x . chunks ) : <NEWLINE> <TAB> if len ( bds ) == <NUMBER> : <NEWLINE> <TAB> chunks . append ( bds ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> left = [ bds [ <NUMBER> ] + axes . get ( i , <NUMBER> ) ] <NEWLINE> right = [ bds [ - <NUMBER> ] + axes . get ( i , <NUMBER> ) ] <NEWLINE> mid = [ ] <NEWLINE> for bd in bds [ <NUMBER> : - <NUMBER> ] : <NEWLINE> <TAB> mid . append ( bd + axes . get ( i , <NUMBER> ) * <NUMBER> ) <NEWLINE> <UNTAB> chunks . append ( left + mid + right ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> dsk = merge ( interior_slices , overlap_blocks ) <NEWLINE> dsk = sharedict . merge ( x . dask , ( name , dsk ) , dependencies = { name : { x . name } } ) <NEWLINE> <NEWLINE> return Array ( dsk , name , chunks , dtype = x . dtype ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def new_blockdim ( dim_shape , lengths , index ) : <NEWLINE> <TAB> <NEWLINE> if index == slice ( None , None , None ) : <NEWLINE> <TAB> return lengths <NEWLINE> <UNTAB> if isinstance ( index , list ) : <NEWLINE> <TAB> return [ len ( index ) ] <NEWLINE> <UNTAB> assert not isinstance ( index , Integral ) <NEWLINE> pairs = sorted ( _slice_1d ( dim_shape , lengths , index ) . items ( ) , <NEWLINE> key = itemgetter ( <NUMBER> ) ) <NEWLINE> slices = [ slice ( <NUMBER> , lengths [ i ] , <NUMBER> ) if slc == slice ( None , None , None ) else slc <NEWLINE> for i , slc in pairs ] <NEWLINE> if isinstance ( index , slice ) and index . step and index . step < <NUMBER> : <NEWLINE> <TAB> slices = slices [ : : - <NUMBER> ] <NEWLINE> <UNTAB> return [ int ( math . ceil ( ( <NUMBER> * slc . stop - slc . start ) / slc . step ) ) for slc in slices ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def option_clear ( self ) : <NEWLINE> <TAB> <NEWLINE> self . tk . call ( <STRING> , <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_prop_tup ( self , renderer = None ) : <NEWLINE> <TAB> <NEWLINE> props = [ p for p in Text . get_prop_tup ( self , renderer = renderer ) ] <NEWLINE> props . extend ( [ self . _x , self . _y , self . _dashlength , <NEWLINE> self . _dashdirection , self . _dashrotation , self . _dashpad , <NEWLINE> self . _dashpush ] ) <NEWLINE> return tuple ( props ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _finalize_index ( index_or_t , ts ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( index_or_t , six . integer_types ) : <NEWLINE> <TAB> return index_or_t <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return ts . index ( index_or_t ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _construct_axes_dict_from ( self , axes , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> d = { a : ax for a , ax in zip ( self . _AXIS_ORDERS , axes ) } <NEWLINE> d . update ( kwargs ) <NEWLINE> return d <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def registered_drivers ( ) : <NEWLINE> <TAB> <NEWLINE> return frozenset ( _drivers ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def execute ( self , * multiparams , ** params ) : <NEWLINE> <TAB> <NEWLINE> e = self . bind <NEWLINE> if e is None : <NEWLINE> <TAB> label = getattr ( self , <STRING> , self . __class__ . __name__ ) <NEWLINE> msg = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % label ) <NEWLINE> raise exc . UnboundExecutionError ( msg ) <NEWLINE> <UNTAB> return e . _execute_clauseelement ( self , multiparams , params ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def clear_path ( self , path ) : <NEWLINE> <TAB> <NEWLINE> func_path = os . path . join ( self . location , * path ) <NEWLINE> if self . _item_exists ( func_path ) : <NEWLINE> <TAB> self . clear_location ( func_path ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __iter__ ( self ) : <NEWLINE> <TAB> <NEWLINE> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def multiply ( self , b ) : <NEWLINE> <TAB> <NEWLINE> return self * b <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_linestyle ( self , ls ) : <NEWLINE> <TAB> <NEWLINE> if ls is None : <NEWLINE> <TAB> ls = <STRING> <NEWLINE> <UNTAB> self . _linestyle = ls <NEWLINE> <NEWLINE> offset , ls = self . _us_dashes = mlines . _get_dash_pattern ( ls ) <NEWLINE> <NEWLINE> self . _dashoffset , self . _dashes = mlines . _scale_dashes ( <NEWLINE> offset , ls , self . _linewidth ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , <STRING> ) <NEWLINE> def logical_and ( x , y , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , x = x , y = y , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = None <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , x , y ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return logical_and_eager_fallback ( <NEWLINE> x , y , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def neg ( f ) : <NEWLINE> <TAB> <NEWLINE> if hasattr ( f . rep , <STRING> ) : <NEWLINE> <TAB> result = f . rep . neg ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise OperationNotSupported ( f , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return f . per ( result ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def split_dataset ( dataset , split_at , order = None ) : <NEWLINE> <TAB> <NEWLINE> n_examples = len ( dataset ) <NEWLINE> if not isinstance ( split_at , ( six . integer_types , numpy . integer ) ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> . format ( type ( split_at ) ) ) <NEWLINE> <UNTAB> if split_at < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if split_at >= n_examples : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> subset1 = SubDataset ( dataset , <NUMBER> , split_at , order ) <NEWLINE> subset2 = SubDataset ( dataset , split_at , n_examples , order ) <NEWLINE> return subset1 , subset2 <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_dtype_equal ( source , target ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> source = _get_dtype ( source ) <NEWLINE> target = _get_dtype ( target ) <NEWLINE> return source == target <NEWLINE> <UNTAB> except ( TypeError , AttributeError ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _sympifyit ( arg , retval = None ) : <NEWLINE> <TAB> <NEWLINE> def deco ( func ) : <NEWLINE> <TAB> return __sympifyit ( func , arg , retval ) <NEWLINE> <NEWLINE> <UNTAB> return deco <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_bounds ( self , low , high ) : <NEWLINE> <TAB> <NEWLINE> if self . spine_type == <STRING> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> self . _bounds = ( low , high ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def enable_automatic_int_sympification ( shell ) : <NEWLINE> <TAB> <NEWLINE> import ast <NEWLINE> old_run_cell = shell . run_cell <NEWLINE> <NEWLINE> def my_run_cell ( cell , * args , ** kwargs ) : <NEWLINE> <TAB> try : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> ast . parse ( cell ) <NEWLINE> <UNTAB> except SyntaxError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cell = int_to_Integer ( cell ) <NEWLINE> <UNTAB> old_run_cell ( cell , * args , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> shell . run_cell = my_run_cell <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def size ( a , axis = None ) : <NEWLINE> <TAB> <NEWLINE> if axis is None : <NEWLINE> <TAB> try : <NEWLINE> <TAB> return a . size <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> return asarray ( a ) . size <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> return a . shape [ axis ] <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> return asarray ( a ) . shape [ axis ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def block ( arrays ) : <NEWLINE> <TAB> <NEWLINE> bottom_index , arr_ndim = _block_check_depths_match ( arrays ) <NEWLINE> list_ndim = len ( bottom_index ) <NEWLINE> return _block ( arrays , list_ndim , max ( arr_ndim , list_ndim ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def whiten ( obs , check_finite = True ) : <NEWLINE> <TAB> <NEWLINE> obs = _asarray_validated ( obs , check_finite = check_finite ) <NEWLINE> std_dev = obs . std ( axis = <NUMBER> ) <NEWLINE> zero_std_mask = std_dev == <NUMBER> <NEWLINE> if zero_std_mask . any ( ) : <NEWLINE> <TAB> std_dev [ zero_std_mask ] = <NUMBER> <NEWLINE> warnings . warn ( <STRING> <NEWLINE> <STRING> , <NEWLINE> RuntimeWarning ) <NEWLINE> <UNTAB> return obs / std_dev <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , incoming_graph_data = None , ** attr ) : <NEWLINE> <TAB> <NEWLINE> self . edge_key_dict_factory = self . edge_key_dict_factory <NEWLINE> Graph . __init__ ( self , incoming_graph_data , ** attr ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def ExitGradientColocation ( self , op , gradient_uid ) : <NEWLINE> <TAB> <NEWLINE> if self . _outer_context : <NEWLINE> <TAB> self . _outer_context . ExitGradientColocation ( op , gradient_uid ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _best_effort_input_batch_size ( flat_input ) : <NEWLINE> <TAB> <NEWLINE> for input_ in flat_input : <NEWLINE> <TAB> shape = input_ . shape <NEWLINE> if shape . rank is None : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> if shape . rank < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % input_ ) <NEWLINE> <UNTAB> batch_size = shape . dims [ <NUMBER> ] . value <NEWLINE> if batch_size is not None : <NEWLINE> <TAB> return batch_size <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return array_ops . shape ( flat_input [ <NUMBER> ] ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _hash ( self ) : <NEWLINE> <TAB> <NEWLINE> MAX = sys . maxsize <NEWLINE> MASK = <NUMBER> * MAX + <NUMBER> <NEWLINE> n = len ( self ) <NEWLINE> h = <NUMBER> * ( n + <NUMBER> ) <NEWLINE> h &= MASK <NEWLINE> for x in self : <NEWLINE> <TAB> hx = hash ( x ) <NEWLINE> h ^= ( hx ^ ( hx << <NUMBER> ) ^ <NUMBER> ) * <NUMBER> <NEWLINE> h &= MASK <NEWLINE> <UNTAB> h = h * <NUMBER> + <NUMBER> <NEWLINE> h &= MASK <NEWLINE> if h > MAX : <NEWLINE> <TAB> h -= MASK + <NUMBER> <NEWLINE> <UNTAB> if h == - <NUMBER> : <NEWLINE> <TAB> h = <NUMBER> <NEWLINE> <UNTAB> return h <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def isnot_distinct_from ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return self . operate ( isnot_distinct_from , other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def line_aa ( r0 , c0 , r1 , c1 ) : <NEWLINE> <TAB> <NEWLINE> return _line_aa ( r0 , c0 , r1 , c1 ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_best_eval_result ( self , event_files ) : <NEWLINE> <TAB> <NEWLINE> if not event_files : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> best_eval_result = None <NEWLINE> for event_file in gfile . Glob ( os . path . join ( event_files ) ) : <NEWLINE> <TAB> for event in summary_iterator . summary_iterator ( event_file ) : <NEWLINE> <TAB> if event . HasField ( <STRING> ) : <NEWLINE> <TAB> event_eval_result = { } <NEWLINE> for value in event . summary . value : <NEWLINE> <TAB> if value . HasField ( <STRING> ) : <NEWLINE> <TAB> event_eval_result [ value . tag ] = value . simple_value <NEWLINE> <UNTAB> <UNTAB> if event_eval_result : <NEWLINE> <TAB> if best_eval_result is None or self . _compare_fn ( <NEWLINE> best_eval_result , event_eval_result ) : <NEWLINE> <TAB> best_eval_result = event_eval_result <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> return best_eval_result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def deduced ( cls , symbol , value = None , attrs = Tuple ( ) , cast_check = True ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( symbol , Variable ) : <NEWLINE> <TAB> return symbol <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> type_ = Type . from_expr ( symbol ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> type_ = Type . from_expr ( value ) <NEWLINE> <NEWLINE> <UNTAB> if value is not None and cast_check : <NEWLINE> <TAB> value = type_ . cast_check ( value ) <NEWLINE> <UNTAB> return cls ( symbol , type = type_ , value = value , attrs = attrs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gf_expand ( F , p , K ) : <NEWLINE> <TAB> <NEWLINE> if type ( F ) is tuple : <NEWLINE> <TAB> lc , F = F <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> lc = K . one <NEWLINE> <NEWLINE> <UNTAB> g = [ lc ] <NEWLINE> <NEWLINE> for f , k in F : <NEWLINE> <TAB> f = gf_pow ( f , k , p , K ) <NEWLINE> g = gf_mul ( g , f , p , K ) <NEWLINE> <NEWLINE> <UNTAB> return g <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __setattr__ ( self , name , value ) : <NEWLINE> <TAB> <NEWLINE> if getattr ( self , <STRING> , True ) : <NEWLINE> <TAB> value = data_structures . sticky_attribute_assignment ( <NEWLINE> checkpointable = self , value = value , name = name ) <NEWLINE> <UNTAB> super ( Checkpointable , self ) . __setattr__ ( name , value ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _new_DatetimeIndex ( cls , d ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> tz = d . pop ( <STRING> , None ) <NEWLINE> <NEWLINE> result = cls . __new__ ( cls , verify_integrity = False , ** d ) <NEWLINE> if tz is not None : <NEWLINE> <TAB> result = result . tz_localize ( <STRING> ) . tz_convert ( tz ) <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def maybe_convert_string_to_object ( values ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( values , string_types ) : <NEWLINE> <TAB> values = np . array ( [ values ] , dtype = object ) <NEWLINE> <UNTAB> elif ( isinstance ( values , np . ndarray ) and <NEWLINE> issubclass ( values . dtype . type , ( np . string_ , np . unicode_ ) ) ) : <NEWLINE> <TAB> values = values . astype ( object ) <NEWLINE> <UNTAB> return values <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def greater_equal ( x , y ) : <NEWLINE> <TAB> <NEWLINE> return math_ops . greater_equal ( x , y ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ abstractmethod <NEWLINE> def __floordiv__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def host_device ( self , replica = <NUMBER> , logical_core = <NUMBER> , job = None ) : <NEWLINE> <TAB> <NEWLINE> coordinates = self . _coordinates ( replica , logical_core ) <NEWLINE> return self . _topology . cpu_device_name_at_coordinates ( coordinates , job = job ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def denom ( self , a ) : <NEWLINE> <TAB> <NEWLINE> return a . denom <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def meijerint_inversion ( f , x , t ) : <NEWLINE> <TAB> <NEWLINE> from sympy import I , Integral , exp , expand , log , Add , Mul , Heaviside <NEWLINE> f_ = f <NEWLINE> t_ = t <NEWLINE> t = Dummy ( <STRING> , polar = True ) <NEWLINE> f = f . subs ( t_ , t ) <NEWLINE> _debug ( <STRING> , f ) <NEWLINE> if not _is_analytic ( f , x ) : <NEWLINE> <TAB> _debug ( <STRING> ) <NEWLINE> return None <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> shift = S . Zero <NEWLINE> <NEWLINE> if f . is_Mul : <NEWLINE> <TAB> args = list ( f . args ) <NEWLINE> <UNTAB> elif isinstance ( f , exp ) : <NEWLINE> <TAB> args = [ f ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> args = None <NEWLINE> <NEWLINE> <UNTAB> if args : <NEWLINE> <TAB> newargs = [ ] <NEWLINE> exponentials = [ ] <NEWLINE> while args : <NEWLINE> <TAB> arg = args . pop ( ) <NEWLINE> if isinstance ( arg , exp ) : <NEWLINE> <TAB> arg2 = expand ( arg ) <NEWLINE> if arg2 . is_Mul : <NEWLINE> <TAB> args += arg2 . args <NEWLINE> continue <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> a , b = _get_coeff_exp ( arg . args [ <NUMBER> ] , x ) <NEWLINE> <UNTAB> except _CoeffExpValueError : <NEWLINE> <TAB> b = <NUMBER> <NEWLINE> <UNTAB> if b == <NUMBER> : <NEWLINE> <TAB> exponentials . append ( a ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> newargs . append ( arg ) <NEWLINE> <UNTAB> <UNTAB> elif arg . is_Pow : <NEWLINE> <TAB> arg2 = expand ( arg ) <NEWLINE> if arg2 . is_Mul : <NEWLINE> <TAB> args += arg2 . args <NEWLINE> continue <NEWLINE> <UNTAB> if x not in arg . base . free_symbols : <NEWLINE> <TAB> try : <NEWLINE> <TAB> a , b = _get_coeff_exp ( arg . exp , x ) <NEWLINE> <UNTAB> except _CoeffExpValueError : <NEWLINE> <TAB> b = <NUMBER> <NEWLINE> <UNTAB> if b == <NUMBER> : <NEWLINE> <TAB> exponentials . append ( a * log ( arg . base ) ) <NEWLINE> <UNTAB> <UNTAB> newargs . append ( arg ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> newargs . append ( arg ) <NEWLINE> <UNTAB> <UNTAB> shift = Add ( * exponentials ) <NEWLINE> f = Mul ( * newargs ) <NEWLINE> <NEWLINE> <UNTAB> if x not in f . free_symbols : <NEWLINE> <TAB> _debug ( <STRING> , f , shift ) <NEWLINE> from sympy import Eq , im <NEWLINE> cond = Eq ( im ( shift ) , <NUMBER> ) <NEWLINE> if cond == False : <NEWLINE> <TAB> _debug ( <STRING> ) <NEWLINE> return None <NEWLINE> <UNTAB> res = f * DiracDelta ( t + shift ) <NEWLINE> _debug ( <STRING> , res , cond ) <NEWLINE> <NEWLINE> return Piecewise ( ( res . subs ( t , t_ ) , cond ) ) <NEWLINE> <NEWLINE> <UNTAB> gs = _rewrite1 ( f , x ) <NEWLINE> if gs is not None : <NEWLINE> <TAB> fac , po , g , cond = gs <NEWLINE> _debug ( <STRING> , fac , po , g ) <NEWLINE> res = S ( <NUMBER> ) <NEWLINE> for C , s , f in g : <NEWLINE> <TAB> C , f = _rewrite_inversion ( fac * C , po * x ** s , f , x ) <NEWLINE> res += C * _int_inversion ( f , x , t ) <NEWLINE> cond = And ( cond , _check_antecedents_inversion ( f , x ) ) <NEWLINE> if cond == False : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> cond = _my_unpolarify ( cond ) <NEWLINE> if cond == False : <NEWLINE> <TAB> _debug ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> _debug ( <STRING> , res ) <NEWLINE> res = _my_unpolarify ( hyperexpand ( res ) ) <NEWLINE> if not res . has ( Heaviside ) : <NEWLINE> <TAB> res *= Heaviside ( t ) <NEWLINE> <UNTAB> res = res . subs ( t , t + shift ) <NEWLINE> if not isinstance ( cond , bool ) : <NEWLINE> <TAB> cond = cond . subs ( t , t + shift ) <NEWLINE> <UNTAB> from sympy import InverseLaplaceTransform <NEWLINE> return Piecewise ( ( res . subs ( t , t_ ) , cond ) , <NEWLINE> ( InverseLaplaceTransform ( f_ . subs ( t , t_ ) , x , t_ , None ) , True ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def johnson_lindenstrauss_min_dim ( n_samples , eps = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> eps = np . asarray ( eps ) <NEWLINE> n_samples = np . asarray ( n_samples ) <NEWLINE> <NEWLINE> if np . any ( eps <= <NUMBER> ) or np . any ( eps >= <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % eps ) <NEWLINE> <NEWLINE> <UNTAB> if np . any ( n_samples ) <= <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> % n_samples ) <NEWLINE> <NEWLINE> <UNTAB> denominator = ( eps ** <NUMBER> / <NUMBER> ) - ( eps ** <NUMBER> / <NUMBER> ) <NEWLINE> return ( <NUMBER> * np . log ( n_samples ) / denominator ) . astype ( np . int ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , name , default_name = None , values = None ) : <NEWLINE> <TAB> <NEWLINE> self . _name = default_name if name is None else name <NEWLINE> self . _default_name = default_name <NEWLINE> self . _values = values <NEWLINE> self . _ctx = context . context ( ) <NEWLINE> self . _in_eager_mode = self . _ctx . executing_eagerly ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def class_hierarchy ( cls ) : <NEWLINE> <TAB> <NEWLINE> if compat . py2k : <NEWLINE> <TAB> if isinstance ( cls , types . ClassType ) : <NEWLINE> <TAB> return list ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> hier = { cls } <NEWLINE> process = list ( cls . __mro__ ) <NEWLINE> while process : <NEWLINE> <TAB> c = process . pop ( ) <NEWLINE> if compat . py2k : <NEWLINE> <TAB> if isinstance ( c , types . ClassType ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> bases = ( _ for _ in c . __bases__ <NEWLINE> if _ not in hier and not isinstance ( _ , types . ClassType ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> bases = ( _ for _ in c . __bases__ if _ not in hier ) <NEWLINE> <NEWLINE> <UNTAB> for b in bases : <NEWLINE> <TAB> process . append ( b ) <NEWLINE> hier . add ( b ) <NEWLINE> <NEWLINE> <UNTAB> if compat . py3k : <NEWLINE> <TAB> if c . __module__ == <STRING> or not hasattr ( c , <STRING> ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if c . __module__ == <STRING> or not hasattr ( <NEWLINE> c , <STRING> ) : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> for s in [ _ for _ in c . __subclasses__ ( ) if _ not in hier ] : <NEWLINE> <TAB> process . append ( s ) <NEWLINE> hier . add ( s ) <NEWLINE> <UNTAB> <UNTAB> return list ( hier ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_yticklines ( self ) : <NEWLINE> <TAB> <NEWLINE> return cbook . silent_list ( <STRING> , <NEWLINE> self . yaxis . get_ticklines ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _recursive_call ( expr_to_call , on_args ) : <NEWLINE> <TAB> <NEWLINE> from sympy import Symbol <NEWLINE> def the_call_method_is_overridden ( expr ) : <NEWLINE> <TAB> for cls in getmro ( type ( expr ) ) : <NEWLINE> <TAB> if <STRING> in cls . __dict__ : <NEWLINE> <TAB> return cls != Basic <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if callable ( expr_to_call ) and the_call_method_is_overridden ( expr_to_call ) : <NEWLINE> <TAB> if isinstance ( expr_to_call , Symbol ) : <NEWLINE> <TAB> return expr_to_call <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return expr_to_call ( * on_args ) <NEWLINE> <UNTAB> <UNTAB> elif expr_to_call . args : <NEWLINE> <TAB> args = [ Basic . _recursive_call ( <NEWLINE> sub , on_args ) for sub in expr_to_call . args ] <NEWLINE> return type ( expr_to_call ) ( * args ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return expr_to_call <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_config ( self ) : <NEWLINE> <TAB> <NEWLINE> data = self . data <NEWLINE> if type ( self . data ) . __module__ == np . __name__ : <NEWLINE> <TAB> data = self . data . tolist ( ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> json_data = json . dumps ( data ) <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> raise TypeError ( <STRING> , data ) <NEWLINE> <NEWLINE> <UNTAB> targets = self . targets <NEWLINE> if type ( self . targets ) . __module__ == np . __name__ : <NEWLINE> <TAB> targets = self . targets . tolist ( ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> json_targets = json . dumps ( targets ) <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> raise TypeError ( <STRING> , targets ) <NEWLINE> <NEWLINE> <UNTAB> return { <NEWLINE> <STRING> : json_data , <NEWLINE> <STRING> : json_targets , <NEWLINE> <STRING> : self . length , <NEWLINE> <STRING> : self . sampling_rate , <NEWLINE> <STRING> : self . stride , <NEWLINE> <STRING> : self . start_index , <NEWLINE> <STRING> : self . end_index , <NEWLINE> <STRING> : self . shuffle , <NEWLINE> <STRING> : self . reverse , <NEWLINE> <STRING> : self . batch_size <NEWLINE> } <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def join ( self , a , * args ) : <NEWLINE> <TAB> <NEWLINE> mapping = self . _mapping <NEWLINE> set_a = mapping . setdefault ( weakref . ref ( a ) , [ weakref . ref ( a ) ] ) <NEWLINE> <NEWLINE> for arg in args : <NEWLINE> <TAB> set_b = mapping . get ( weakref . ref ( arg ) , [ weakref . ref ( arg ) ] ) <NEWLINE> if set_b is not set_a : <NEWLINE> <TAB> if len ( set_b ) > len ( set_a ) : <NEWLINE> <TAB> set_a , set_b = set_b , set_a <NEWLINE> <UNTAB> set_a . extend ( set_b ) <NEWLINE> for elem in set_b : <NEWLINE> <TAB> mapping [ elem ] = set_a <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> self . clean ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_ylabel ( self , ylabel , fontdict = None , labelpad = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if labelpad is not None : <NEWLINE> <TAB> self . yaxis . labelpad = labelpad <NEWLINE> <UNTAB> return self . yaxis . set_label_text ( ylabel , fontdict , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _munp ( self , n , beta , m ) : <NEWLINE> <TAB> <NEWLINE> N = <NUMBER> / ( m / beta / ( m - <NUMBER> ) * np . exp ( - beta ** <NUMBER> / <NUMBER> ) + _norm_pdf_C * _norm_cdf ( beta ) ) <NEWLINE> <NEWLINE> def n_th_moment ( n , beta , m ) : <NEWLINE> <TAB> <NEWLINE> A = ( m / beta ) ** m * np . exp ( - beta ** <NUMBER> / <NUMBER> ) <NEWLINE> B = m / beta - beta <NEWLINE> rhs = <NUMBER> ** ( ( n - <NUMBER> ) / <NUMBER> ) * sc . gamma ( ( n + <NUMBER> ) / <NUMBER> ) * ( <NUMBER> + ( - <NUMBER> ) ** n * sc . gammainc ( ( n + <NUMBER> ) / <NUMBER> , beta ** <NUMBER> / <NUMBER> ) ) <NEWLINE> lhs = np . zeros ( rhs . shape ) <NEWLINE> for k in range ( n + <NUMBER> ) : <NEWLINE> <TAB> lhs += sc . binom ( n , k ) * B ** ( n - k ) * ( - <NUMBER> ) ** k / ( m - k - <NUMBER> ) * ( m / beta ) ** ( - m + k + <NUMBER> ) <NEWLINE> <UNTAB> return A * lhs + rhs <NEWLINE> <NEWLINE> <UNTAB> return N * _lazywhere ( np . atleast_1d ( n + <NUMBER> < m ) , <NEWLINE> ( n , beta , m ) , <NEWLINE> np . vectorize ( n_th_moment , otypes = [ np . float ] ) , <NEWLINE> np . inf ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def zerograd ( self ) : <NEWLINE> <TAB> <NEWLINE> warnings . warn ( <NEWLINE> <STRING> , <NEWLINE> DeprecationWarning ) <NEWLINE> <NEWLINE> if self . array is None : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> with cuda . get_device_from_array ( self . array ) as dev : <NEWLINE> <TAB> gv = self . _grad_var <NEWLINE> if gv is None : <NEWLINE> <TAB> xp = numpy if dev . id == - <NUMBER> else cuda . cupy <NEWLINE> self . grad = xp . zeros_like ( self . array ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> gv . unchain ( ) <NEWLINE> gv . array . fill ( <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _dst ( x , type , n = None , axis = - <NUMBER> , overwrite_x = False , normalize = None ) : <NEWLINE> <TAB> <NEWLINE> x0 , n , copy_made = __fix_shape ( x , n , axis , <STRING> ) <NEWLINE> if type == <NUMBER> and n < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> overwrite_x = overwrite_x or copy_made <NEWLINE> nm = _get_norm_mode ( normalize ) <NEWLINE> if np . iscomplexobj ( x0 ) : <NEWLINE> <TAB> return ( _raw_dst ( x0 . real , type , n , axis , nm , overwrite_x ) + <NUMBER> * <NEWLINE> _raw_dst ( x0 . imag , type , n , axis , nm , overwrite_x ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return _raw_dst ( x0 , type , n , axis , nm , overwrite_x ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _ensure_has_len ( seq ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> len ( seq ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> return list ( seq ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return seq <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_graph_element ( self , G ) : <NEWLINE> <TAB> <NEWLINE> if G . is_directed ( ) : <NEWLINE> <TAB> default_edge_type = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> default_edge_type = <STRING> <NEWLINE> <NEWLINE> <UNTAB> graphid = G . graph . pop ( <STRING> , None ) <NEWLINE> if graphid is None : <NEWLINE> <TAB> graph_element = self . myElement ( <STRING> , <NEWLINE> edgedefault = default_edge_type ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> graph_element = self . myElement ( <STRING> , <NEWLINE> edgedefault = default_edge_type , <NEWLINE> id = graphid ) <NEWLINE> <UNTAB> default = { } <NEWLINE> data = { k : v for ( k , v ) in G . graph . items ( ) <NEWLINE> if k not in [ <STRING> , <STRING> ] } <NEWLINE> self . add_attributes ( <STRING> , graph_element , data , default ) <NEWLINE> self . add_nodes ( G , graph_element ) <NEWLINE> self . add_edges ( G , graph_element ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for ( xml_obj , data ) in self . attributes . items ( ) : <NEWLINE> <TAB> for ( k , v , scope , default ) in data : <NEWLINE> <TAB> xml_obj . append ( self . add_data ( make_str ( k ) , <NEWLINE> self . attr_type ( k , scope , v ) , <NEWLINE> make_str ( v ) , scope , default ) ) <NEWLINE> <UNTAB> <UNTAB> self . xml . append ( graph_element ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def reshape ( self , rows , cols ) : <NEWLINE> <TAB> <NEWLINE> if self . rows * self . cols != rows * cols : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( rows , cols ) ) <NEWLINE> <UNTAB> return self . _new ( rows , cols , lambda i , j : self [ i * cols + j ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def memodict ( f ) : <NEWLINE> <TAB> <NEWLINE> class memodict ( defaultdict ) : <NEWLINE> <TAB> def __missing__ ( self , key ) : <NEWLINE> <TAB> ret = self [ key ] = f ( key ) <NEWLINE> return ret <NEWLINE> <UNTAB> <UNTAB> return memodict ( ) . __getitem__ <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def measure ( code_str , times = <NUMBER> , label = None ) : <NEWLINE> <TAB> <NEWLINE> frame = sys . _getframe ( <NUMBER> ) <NEWLINE> locs , globs = frame . f_locals , frame . f_globals <NEWLINE> <NEWLINE> code = compile ( code_str , <NEWLINE> <STRING> % label , <NEWLINE> <STRING> ) <NEWLINE> i = <NUMBER> <NEWLINE> elapsed = jiffies ( ) <NEWLINE> while i < times : <NEWLINE> <TAB> i += <NUMBER> <NEWLINE> exec ( code , globs , locs ) <NEWLINE> <UNTAB> elapsed = jiffies ( ) - elapsed <NEWLINE> return <NUMBER> * elapsed <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_inverse_pair ( node_op , prev_op , inv_pair ) : <NEWLINE> <TAB> <NEWLINE> node_is_op0 = isinstance ( node_op , inv_pair [ <NUMBER> ] ) <NEWLINE> node_is_op1 = isinstance ( node_op , inv_pair [ <NUMBER> ] ) <NEWLINE> prev_is_op0 = isinstance ( prev_op , inv_pair [ <NUMBER> ] ) <NEWLINE> prev_is_op1 = isinstance ( prev_op , inv_pair [ <NUMBER> ] ) <NEWLINE> <NEWLINE> return ( node_is_op0 and prev_is_op1 ) or ( node_is_op1 and prev_is_op0 ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def get_bound_method_class ( m ) : <NEWLINE> <TAB> <NEWLINE> return m . im_class if sys . version < <STRING> else m . __self__ . __class__ <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_callback ( self , func , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> self . callbacks . append ( ( func , args , kwargs ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def ynp_zeros ( n , nt ) : <NEWLINE> <TAB> <NEWLINE> return jnyn_zeros ( n , nt ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def peek ( self , index , name = None ) : <NEWLINE> <TAB> <NEWLINE> if name is None : <NEWLINE> <TAB> name = <STRING> % self . _name <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> fn = lambda : gen_data_flow_ops . stage_peek ( index , <NEWLINE> dtypes = self . _dtypes , shared_name = self . _name , <NEWLINE> name = name , capacity = self . _capacity , <NEWLINE> memory_limit = self . _memory_limit ) <NEWLINE> <NEWLINE> <NEWLINE> return self . __internal_get ( fn , name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def diagonal_solve ( self , rhs ) : <NEWLINE> <TAB> <NEWLINE> if not self . is_diagonal : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> if rhs . rows != self . rows : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> return self . _diagonal_solve ( rhs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def from_rational ( p , q , prec , rnd = round_fast ) : <NEWLINE> <TAB> <NEWLINE> return mpf_div ( from_int ( p ) , from_int ( q ) , prec , rnd ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def print_rcode ( expr , ** settings ) : <NEWLINE> <TAB> <NEWLINE> print ( rcode ( expr , ** settings ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def identity ( cls , domain = None , window = None ) : <NEWLINE> <TAB> <NEWLINE> if domain is None : <NEWLINE> <TAB> domain = cls . domain <NEWLINE> <UNTAB> if window is None : <NEWLINE> <TAB> window = cls . window <NEWLINE> <UNTAB> off , scl = pu . mapparms ( window , domain ) <NEWLINE> coef = cls . _line ( off , scl ) <NEWLINE> return cls ( coef , domain , window ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get ( self , op ) : <NEWLINE> <TAB> <NEWLINE> if op in self . _control_outputs : <NEWLINE> <TAB> return self . _control_outputs [ op ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def equals ( self , other , failing_expression = False ) : <NEWLINE> <TAB> <NEWLINE> from sympy . simplify . simplify import nsimplify , simplify <NEWLINE> from sympy . solvers . solveset import solveset <NEWLINE> from sympy . polys . polyerrors import NotAlgebraic <NEWLINE> from sympy . polys . numberfields import minimal_polynomial <NEWLINE> <NEWLINE> other = sympify ( other ) <NEWLINE> if self == other : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> diff = factor_terms ( simplify ( self - other ) , radical = True ) <NEWLINE> <NEWLINE> if not diff : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <UNTAB> if not diff . has ( Add , Mod ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> constant = diff . is_constant ( simplify = False , failing_number = True ) <NEWLINE> <NEWLINE> if constant is False : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> if constant is None and ( diff . free_symbols or not diff . is_number ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> if constant is True : <NEWLINE> <TAB> ndiff = diff . _random ( ) <NEWLINE> if ndiff : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if diff . is_number : <NEWLINE> <TAB> approx = diff . nsimplify ( ) <NEWLINE> if not approx : <NEWLINE> <NEWLINE> <TAB> surds = [ s for s in diff . atoms ( Pow ) if s . args [ <NUMBER> ] . is_Integer ] <NEWLINE> <NEWLINE> surds . sort ( key = lambda x : - x . args [ <NUMBER> ] ) <NEWLINE> for s in surds : <NEWLINE> <TAB> try : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if s . is_Symbol : <NEWLINE> <TAB> sol = list ( solveset ( diff , s ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> sol = [ s ] <NEWLINE> <UNTAB> if sol : <NEWLINE> <TAB> if s in sol : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> if s . is_real : <NEWLINE> <TAB> if any ( nsimplify ( si , [ s ] ) == s and simplify ( si ) == s <NEWLINE> for si in sol ) : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> except NotImplementedError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if True : <NEWLINE> <TAB> try : <NEWLINE> <TAB> mp = minimal_polynomial ( diff ) <NEWLINE> if mp . is_Symbol : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> return False <NEWLINE> <UNTAB> except ( NotAlgebraic , NotImplementedError ) : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> if constant not in ( True , None ) and constant != <NUMBER> : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> if failing_expression : <NEWLINE> <TAB> return diff <NEWLINE> <UNTAB> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def union_many ( self , others ) : <NEWLINE> <TAB> <NEWLINE> this = self <NEWLINE> <NEWLINE> for other in others : <NEWLINE> <TAB> if not isinstance ( this , DatetimeIndex ) : <NEWLINE> <TAB> this = Index . union ( this , other ) <NEWLINE> continue <NEWLINE> <NEWLINE> <UNTAB> if not isinstance ( other , DatetimeIndex ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> other = DatetimeIndex ( other ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> this , other = this . _maybe_utc_convert ( other ) <NEWLINE> <NEWLINE> if this . _can_fast_union ( other ) : <NEWLINE> <TAB> this = this . _fast_union ( other ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> tz = this . tz <NEWLINE> this = Index . union ( this , other ) <NEWLINE> if isinstance ( this , DatetimeIndex ) : <NEWLINE> <TAB> this . _tz = timezones . tz_standardize ( tz ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if this . freq is None : <NEWLINE> <TAB> this . freq = to_offset ( this . inferred_freq ) <NEWLINE> <UNTAB> return this <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def class_key ( cls ) : <NEWLINE> <TAB> <NEWLINE> return <NUMBER> , <NUMBER> , cls . __name__ <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_local_variables ( scope = None , suffix = None ) : <NEWLINE> <TAB> <NEWLINE> return get_variables ( scope , suffix , ops . GraphKeys . LOCAL_VARIABLES ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def start_state_from_dask ( dsk , cache = None , sortkey = None ) : <NEWLINE> <TAB> <NEWLINE> if sortkey is None : <NEWLINE> <TAB> sortkey = order ( dsk ) . get <NEWLINE> <UNTAB> if cache is None : <NEWLINE> <TAB> cache = config . get ( <STRING> , None ) <NEWLINE> <UNTAB> if cache is None : <NEWLINE> <TAB> cache = dict ( ) <NEWLINE> <UNTAB> data_keys = set ( ) <NEWLINE> for k , v in dsk . items ( ) : <NEWLINE> <TAB> if not has_tasks ( dsk , v ) : <NEWLINE> <TAB> cache [ k ] = v <NEWLINE> data_keys . add ( k ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> dsk2 = dsk . copy ( ) <NEWLINE> dsk2 . update ( cache ) <NEWLINE> <NEWLINE> dependencies = { k : get_dependencies ( dsk2 , k ) for k in dsk } <NEWLINE> waiting = { k : v . copy ( ) <NEWLINE> for k , v in dependencies . items ( ) <NEWLINE> if k not in data_keys } <NEWLINE> <NEWLINE> dependents = reverse_dict ( dependencies ) <NEWLINE> for a in cache : <NEWLINE> <TAB> for b in dependents . get ( a , ( ) ) : <NEWLINE> <TAB> waiting [ b ] . remove ( a ) <NEWLINE> <UNTAB> <UNTAB> waiting_data = dict ( ( k , v . copy ( ) ) for k , v in dependents . items ( ) if v ) <NEWLINE> <NEWLINE> ready_set = set ( [ k for k , v in waiting . items ( ) if not v ] ) <NEWLINE> ready = sorted ( ready_set , key = sortkey , reverse = True ) <NEWLINE> waiting = dict ( ( k , v ) for k , v in waiting . items ( ) if v ) <NEWLINE> <NEWLINE> state = { <STRING> : dependencies , <NEWLINE> <STRING> : dependents , <NEWLINE> <STRING> : waiting , <NEWLINE> <STRING> : waiting_data , <NEWLINE> <STRING> : cache , <NEWLINE> <STRING> : ready , <NEWLINE> <STRING> : set ( ) , <NEWLINE> <STRING> : set ( ) , <NEWLINE> <STRING> : set ( ) } <NEWLINE> <NEWLINE> return state <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def almosteq ( p1 , p2 , tolerance = None ) : <NEWLINE> <TAB> <NEWLINE> ring = p1 . ring <NEWLINE> <NEWLINE> if isinstance ( p2 , ring . dtype ) : <NEWLINE> <TAB> if set ( p1 . keys ( ) ) != set ( p2 . keys ( ) ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> almosteq = ring . domain . almosteq <NEWLINE> <NEWLINE> for k in p1 . keys ( ) : <NEWLINE> <TAB> if not almosteq ( p1 [ k ] , p2 [ k ] , tolerance ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> <UNTAB> elif len ( p1 ) > <NUMBER> : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> p2 = ring . domain . convert ( p2 ) <NEWLINE> <UNTAB> except CoercionFailed : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return ring . domain . almosteq ( p1 . const ( ) , p2 , tolerance ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def make_saveable_from_iterator ( iterator ) : <NEWLINE> <TAB> <NEWLINE> return _Saveable ( iterator . _iterator_resource ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def remove ( self , node ) : <NEWLINE> <TAB> <NEWLINE> self . to_remove . add ( node ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def output_difference ( self , example , got , optionflags ) : <NEWLINE> <TAB> <NEWLINE> want = example . want <NEWLINE> <NEWLINE> <NEWLINE> if not ( optionflags & DONT_ACCEPT_BLANKLINE ) : <NEWLINE> <TAB> got = re . sub ( <STRING> , BLANKLINE_MARKER , got ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . _do_a_fancy_diff ( want , got , optionflags ) : <NEWLINE> <NEWLINE> <TAB> want_lines = want . splitlines ( keepends = True ) <NEWLINE> got_lines = got . splitlines ( keepends = True ) <NEWLINE> <NEWLINE> if optionflags & REPORT_UDIFF : <NEWLINE> <TAB> diff = difflib . unified_diff ( want_lines , got_lines , n = <NUMBER> ) <NEWLINE> diff = list ( diff ) [ <NUMBER> : ] <NEWLINE> kind = <STRING> <NEWLINE> <UNTAB> elif optionflags & REPORT_CDIFF : <NEWLINE> <TAB> diff = difflib . context_diff ( want_lines , got_lines , n = <NUMBER> ) <NEWLINE> diff = list ( diff ) [ <NUMBER> : ] <NEWLINE> kind = <STRING> <NEWLINE> <UNTAB> elif optionflags & REPORT_NDIFF : <NEWLINE> <TAB> engine = difflib . Differ ( charjunk = difflib . IS_CHARACTER_JUNK ) <NEWLINE> diff = list ( engine . compare ( want_lines , got_lines ) ) <NEWLINE> kind = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> assert <NUMBER> , <STRING> <NEWLINE> <NEWLINE> <UNTAB> diff = [ line . rstrip ( ) + <STRING> for line in diff ] <NEWLINE> return <STRING> % kind + _indent ( <STRING> . join ( diff ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if want and got : <NEWLINE> <TAB> return <STRING> % ( _indent ( want ) , _indent ( got ) ) <NEWLINE> <UNTAB> elif want : <NEWLINE> <TAB> return <STRING> % _indent ( want ) <NEWLINE> <UNTAB> elif got : <NEWLINE> <TAB> return <STRING> % _indent ( got ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return <STRING> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def abs ( self ) : <NEWLINE> <TAB> <NEWLINE> return np . abs ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def inverse_transform ( self , X , copy = None ) : <NEWLINE> <TAB> <NEWLINE> check_is_fitted ( self , <STRING> ) <NEWLINE> <NEWLINE> copy = copy if copy is not None else self . copy <NEWLINE> if sparse . issparse ( X ) : <NEWLINE> <TAB> if self . with_mean : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if not sparse . isspmatrix_csr ( X ) : <NEWLINE> <TAB> X = X . tocsr ( ) <NEWLINE> copy = False <NEWLINE> <UNTAB> if copy : <NEWLINE> <TAB> X = X . copy ( ) <NEWLINE> <UNTAB> if self . scale_ is not None : <NEWLINE> <TAB> inplace_column_scale ( X , self . scale_ ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> X = np . asarray ( X ) <NEWLINE> if copy : <NEWLINE> <TAB> X = X . copy ( ) <NEWLINE> <UNTAB> if self . with_std : <NEWLINE> <TAB> X *= self . scale_ <NEWLINE> <UNTAB> if self . with_mean : <NEWLINE> <TAB> X += self . mean_ <NEWLINE> <UNTAB> <UNTAB> return X <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def gumbel_softmax ( log_pi , tau = <NUMBER> , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> xp = backend . get_array_module ( log_pi ) <NEWLINE> if log_pi . ndim < <NUMBER> : <NEWLINE> <TAB> return variable . Variable ( xp . ones ( ( ) , log_pi . dtype ) ) <NEWLINE> <UNTAB> dtype = log_pi . dtype <NEWLINE> g = xp . random . gumbel ( size = log_pi . shape ) . astype ( dtype ) <NEWLINE> y = chainer . functions . softmax ( ( log_pi + g ) / tau , axis = axis ) <NEWLINE> <NEWLINE> return y <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _ispow ( e ) : <NEWLINE> <TAB> <NEWLINE> return isinstance ( e , Expr ) and ( e . is_Pow or isinstance ( e , exp ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def extract ( self , rowsList , colsList ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not is_sequence ( rowsList ) or not is_sequence ( colsList ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if rowsList and all ( isinstance ( i , bool ) for i in rowsList ) : <NEWLINE> <TAB> rowsList = [ index for index , item in enumerate ( rowsList ) if item ] <NEWLINE> <UNTAB> if colsList and all ( isinstance ( i , bool ) for i in colsList ) : <NEWLINE> <TAB> colsList = [ index for index , item in enumerate ( colsList ) if item ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> rowsList = [ a2idx ( k , self . rows ) for k in rowsList ] <NEWLINE> colsList = [ a2idx ( k , self . cols ) for k in colsList ] <NEWLINE> <NEWLINE> return self . _eval_extract ( rowsList , colsList ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def assign ( self , value , use_locking = False , name = None , read_value = True ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _gotitem ( self , key , ndim , subset = None ) : <NEWLINE> <TAB> <NEWLINE> raise AbstractMethodError ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def principal_value ( self , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> from sympy . calculus import singularities <NEWLINE> if len ( self . limits ) != <NUMBER> or len ( list ( self . limits [ <NUMBER> ] ) ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> x , a , b = self . limits [ <NUMBER> ] <NEWLINE> if not ( a . is_comparable and b . is_comparable and a <= b ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if a == b : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> r = Dummy ( <STRING> ) <NEWLINE> f = self . function <NEWLINE> singularities_list = [ s for s in singularities ( f , x ) if s . is_comparable and a <= s <= b ] <NEWLINE> for i in singularities_list : <NEWLINE> <TAB> if ( i == b ) or ( i == a ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % ( i ) ) <NEWLINE> <UNTAB> <UNTAB> F = integrate ( f , x , ** kwargs ) <NEWLINE> if F . has ( Integral ) : <NEWLINE> <TAB> return self <NEWLINE> <UNTAB> if a is - oo and b is oo : <NEWLINE> <TAB> I = limit ( F - F . subs ( x , - x ) , x , oo ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> I = limit ( F , x , b , <STRING> ) - limit ( F , x , a , <STRING> ) <NEWLINE> <UNTAB> for s in singularities_list : <NEWLINE> <TAB> I += limit ( ( ( F . subs ( x , s - r ) ) - F . subs ( x , s + r ) ) , r , <NUMBER> , <STRING> ) <NEWLINE> <UNTAB> return I <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def func_dump ( func ) : <NEWLINE> <TAB> <NEWLINE> raw_code = marshal . dumps ( func . __code__ ) <NEWLINE> code = codecs . encode ( raw_code , <STRING> ) . decode ( <STRING> ) <NEWLINE> defaults = func . __defaults__ <NEWLINE> if func . __closure__ : <NEWLINE> <TAB> closure = tuple ( c . cell_contents for c in func . __closure__ ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> closure = None <NEWLINE> <UNTAB> return code , defaults , closure <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def numer ( self , a ) : <NEWLINE> <TAB> <NEWLINE> return a <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _is_separating_set ( G , cut ) : <NEWLINE> <TAB> <NEWLINE> if len ( cut ) == len ( G ) - <NUMBER> : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <UNTAB> H = nx . restricted_view ( G , cut , [ ] ) <NEWLINE> if nx . is_connected ( H ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def min ( self , axis = None , keepdims = False ) : <NEWLINE> <TAB> <NEWLINE> return theano . tensor . basic . min ( self , axis , keepdims = keepdims ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def matrix_power ( M , n ) : <NEWLINE> <TAB> <NEWLINE> result = <NUMBER> <NEWLINE> for i in xrange ( n ) : <NEWLINE> <TAB> result = theano . dot ( result , M ) <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_dashpush ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _dashpush <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def tail_degree ( f , x = None ) : <NEWLINE> <TAB> <NEWLINE> i = f . ring . index ( x ) <NEWLINE> <NEWLINE> if not f : <NEWLINE> <TAB> return - oo <NEWLINE> <UNTAB> elif i < <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return min ( [ monom [ i ] for monom in f . itermonoms ( ) ] ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def prepare ( image , size = ( <NUMBER> , <NUMBER> ) ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not available : <NEWLINE> <TAB> raise ImportError ( <STRING> <NEWLINE> <STRING> + <NEWLINE> str ( _import_error ) ) <NEWLINE> <UNTAB> dtype = chainer . get_dtype ( ) <NEWLINE> if isinstance ( image , numpy . ndarray ) : <NEWLINE> <TAB> if image . ndim == <NUMBER> : <NEWLINE> <TAB> if image . shape [ <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> image = image [ <NUMBER> , : , : ] <NEWLINE> <UNTAB> elif image . shape [ <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> image = image . transpose ( ( <NUMBER> , <NUMBER> , <NUMBER> ) ) <NEWLINE> <UNTAB> <UNTAB> image = Image . fromarray ( image . astype ( numpy . uint8 ) ) <NEWLINE> <UNTAB> image = image . convert ( <STRING> ) <NEWLINE> if size : <NEWLINE> <TAB> image = image . resize ( size ) <NEWLINE> <UNTAB> image = numpy . asarray ( image , dtype = dtype ) <NEWLINE> image = image [ : , : , : : - <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> image -= numpy . array ( <NEWLINE> [ <NUMBER> , <NUMBER> , <NUMBER> ] , dtype = dtype ) <NEWLINE> image = image . transpose ( ( <NUMBER> , <NUMBER> , <NUMBER> ) ) <NEWLINE> return image <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def run_callable ( self , callable_ , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> return callable_ ( self , * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def nth_element ( input , n , reverse = False , name = None ) : <NEWLINE> <TAB> <NEWLINE> return gen_nn_ops . nth_element ( input , n , reverse = reverse , name = name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_variant ( self , variant ) : <NEWLINE> <TAB> <NEWLINE> if variant is None : <NEWLINE> <TAB> variant = rcParams [ <STRING> ] <NEWLINE> <UNTAB> if variant not in ( <STRING> , <STRING> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> self . _variant = variant <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def part_key ( part ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> rval = [ ] <NEWLINE> for ps in part : <NEWLINE> <TAB> rval . append ( ps . u ) <NEWLINE> rval . append ( ps . v ) <NEWLINE> <UNTAB> return tuple ( rval ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def argmax ( self , axis = None , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> nv . validate_argmax ( args , kwargs ) <NEWLINE> <NEWLINE> i8 = self . asi8 <NEWLINE> if self . hasnans : <NEWLINE> <TAB> mask = self . _isnan <NEWLINE> if mask . all ( ) : <NEWLINE> <TAB> return - <NUMBER> <NEWLINE> <UNTAB> i8 = i8 . copy ( ) <NEWLINE> i8 [ mask ] = <NUMBER> <NEWLINE> <UNTAB> return i8 . argmax ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def swapaxes ( x , axis1 , axis2 ) : <NEWLINE> <TAB> <NEWLINE> y , = Swapaxes ( axis1 , axis2 ) . apply ( ( x , ) ) <NEWLINE> return y <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _nsort ( roots , separated = False ) : <NEWLINE> <TAB> <NEWLINE> if not all ( r . is_number for r in roots ) : <NEWLINE> <TAB> raise NotImplementedError <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> key = [ [ i . n ( <NUMBER> ) . as_real_imag ( ) [ <NUMBER> ] for i in r . as_real_imag ( ) ] for r in roots ] <NEWLINE> <NEWLINE> if any ( i . _prec == <NUMBER> for k in key for i in k ) : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> key = [ ( <NUMBER> if i else <NUMBER> , r , i ) for r , i in key ] <NEWLINE> key = sorted ( zip ( key , roots ) ) <NEWLINE> <NEWLINE> if separated : <NEWLINE> <TAB> r = [ ] <NEWLINE> i = [ ] <NEWLINE> for ( im , _ , _ ) , v in key : <NEWLINE> <TAB> if im : <NEWLINE> <TAB> i . append ( v ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> r . append ( v ) <NEWLINE> <UNTAB> <UNTAB> return r , i <NEWLINE> <UNTAB> _ , roots = zip ( * key ) <NEWLINE> return list ( roots ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ nodes_or_number ( <NUMBER> ) <NEWLINE> def wheel_graph ( n , create_using = None ) : <NEWLINE> <TAB> <NEWLINE> n_name , nodes = n <NEWLINE> if n_name == <NUMBER> : <NEWLINE> <TAB> G = empty_graph ( <NUMBER> , create_using ) <NEWLINE> return G <NEWLINE> <UNTAB> G = star_graph ( nodes , create_using ) <NEWLINE> if len ( G ) > <NUMBER> : <NEWLINE> <TAB> G . add_edges_from ( pairwise ( nodes [ <NUMBER> : ] ) ) <NEWLINE> G . add_edge ( nodes [ - <NUMBER> ] , nodes [ <NUMBER> ] ) <NEWLINE> <UNTAB> return G <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def conv1d_input ( input_size , weight , grad_output , stride = <NUMBER> , padding = <NUMBER> , dilation = <NUMBER> , groups = <NUMBER> , bias = None ) : <NEWLINE> <TAB> <NEWLINE> stride = _single ( stride ) <NEWLINE> padding = _single ( padding ) <NEWLINE> dilation = _single ( dilation ) <NEWLINE> kernel_size = [ weight . shape [ <NUMBER> ] ] <NEWLINE> <NEWLINE> if input_size is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> grad_input_padding = _grad_input_padding ( grad_output , input_size , stride , <NEWLINE> padding , kernel_size ) <NEWLINE> <NEWLINE> return torch . conv_transpose1d ( <NEWLINE> grad_output , weight , bias , stride , padding , grad_input_padding , groups , <NEWLINE> dilation ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def move_to_front ( self , sprite ) : <NEWLINE> <TAB> <NEWLINE> self . change_layer ( sprite , self . get_top_layer ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def wrap_func_shape_as_first_arg ( func , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if <STRING> not in kwargs : <NEWLINE> <TAB> shape , args = args [ <NUMBER> ] , args [ <NUMBER> : ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> shape = kwargs . pop ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( shape , np . ndarray ) : <NEWLINE> <TAB> shape = shape . tolist ( ) <NEWLINE> <NEWLINE> <UNTAB> if not isinstance ( shape , ( tuple , list ) ) : <NEWLINE> <TAB> shape = ( shape , ) <NEWLINE> <NEWLINE> <UNTAB> chunks = kwargs . pop ( <STRING> , None ) <NEWLINE> <NEWLINE> dtype = kwargs . pop ( <STRING> , None ) <NEWLINE> if dtype is None : <NEWLINE> <TAB> dtype = func ( shape , * args , ** kwargs ) . dtype <NEWLINE> <UNTAB> dtype = np . dtype ( dtype ) <NEWLINE> <NEWLINE> chunks = normalize_chunks ( chunks , shape , dtype = dtype ) <NEWLINE> name = kwargs . pop ( <STRING> , None ) <NEWLINE> <NEWLINE> name = name or funcname ( func ) + <STRING> + tokenize ( func , shape , chunks , dtype , args , kwargs ) <NEWLINE> <NEWLINE> keys = product ( [ name ] , * [ range ( len ( bd ) ) for bd in chunks ] ) <NEWLINE> shapes = product ( * chunks ) <NEWLINE> func = partial ( func , dtype = dtype , ** kwargs ) <NEWLINE> vals = ( ( func , ) + ( s , ) + args for s in shapes ) <NEWLINE> <NEWLINE> dsk = dict ( zip ( keys , vals ) ) <NEWLINE> return Array ( dsk , name , chunks , dtype = dtype ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def reduce_abs_inequalities ( exprs , gen ) : <NEWLINE> <TAB> <NEWLINE> return And ( * [ reduce_abs_inequality ( expr , rel , gen ) <NEWLINE> for expr , rel in exprs ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def compare_psnr ( im_true , im_test , data_range = None ) : <NEWLINE> <TAB> <NEWLINE> _assert_compatible ( im_true , im_test ) <NEWLINE> <NEWLINE> if data_range is None : <NEWLINE> <TAB> if im_true . dtype != im_test . dtype : <NEWLINE> <TAB> warn ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> dmin , dmax = dtype_range [ im_true . dtype . type ] <NEWLINE> true_min , true_max = np . min ( im_true ) , np . max ( im_true ) <NEWLINE> if true_max > dmax or true_min < dmin : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if true_min >= <NUMBER> : <NEWLINE> <NEWLINE> <TAB> data_range = dmax <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> data_range = dmax - dmin <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> im_true , im_test = _as_floats ( im_true , im_test ) <NEWLINE> <NEWLINE> err = compare_mse ( im_true , im_test ) <NEWLINE> return <NUMBER> * np . log10 ( ( data_range ** <NUMBER> ) / err ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def one2many_rnn_seq2seq ( encoder_inputs , <NEWLINE> decoder_inputs_dict , <NEWLINE> enc_cell , <NEWLINE> dec_cells_dict , <NEWLINE> num_encoder_symbols , <NEWLINE> num_decoder_symbols_dict , <NEWLINE> embedding_size , <NEWLINE> feed_previous = False , <NEWLINE> dtype = None , <NEWLINE> scope = None ) : <NEWLINE> <TAB> <NEWLINE> outputs_dict = { } <NEWLINE> state_dict = { } <NEWLINE> <NEWLINE> if not isinstance ( enc_cell , rnn_cell_impl . RNNCell ) : <NEWLINE> <TAB> raise TypeError ( <STRING> % type ( enc_cell ) ) <NEWLINE> <UNTAB> if set ( dec_cells_dict ) != set ( decoder_inputs_dict ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> for dec_cell in dec_cells_dict . values ( ) : <NEWLINE> <TAB> if not isinstance ( dec_cell , rnn_cell_impl . RNNCell ) : <NEWLINE> <TAB> raise TypeError ( <STRING> % type ( dec_cell ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> with variable_scope . variable_scope ( <NEWLINE> scope or <STRING> , dtype = dtype ) as scope : <NEWLINE> <TAB> dtype = scope . dtype <NEWLINE> <NEWLINE> <NEWLINE> enc_cell = core_rnn_cell . EmbeddingWrapper ( <NEWLINE> enc_cell , <NEWLINE> embedding_classes = num_encoder_symbols , <NEWLINE> embedding_size = embedding_size ) <NEWLINE> _ , encoder_state = rnn . static_rnn ( enc_cell , encoder_inputs , dtype = dtype ) <NEWLINE> <NEWLINE> <NEWLINE> for name , decoder_inputs in decoder_inputs_dict . items ( ) : <NEWLINE> <TAB> num_decoder_symbols = num_decoder_symbols_dict [ name ] <NEWLINE> dec_cell = dec_cells_dict [ name ] <NEWLINE> <NEWLINE> with variable_scope . variable_scope ( <STRING> + str ( <NEWLINE> name ) ) as scope : <NEWLINE> <TAB> dec_cell = core_rnn_cell . OutputProjectionWrapper ( <NEWLINE> dec_cell , num_decoder_symbols ) <NEWLINE> if isinstance ( feed_previous , bool ) : <NEWLINE> <TAB> outputs , state = embedding_rnn_decoder ( <NEWLINE> decoder_inputs , <NEWLINE> encoder_state , <NEWLINE> dec_cell , <NEWLINE> num_decoder_symbols , <NEWLINE> embedding_size , <NEWLINE> feed_previous = feed_previous ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> def filled_embedding_rnn_decoder ( feed_previous ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> reuse = None if feed_previous else True <NEWLINE> vs = variable_scope . get_variable_scope ( ) <NEWLINE> with variable_scope . variable_scope ( vs , reuse = reuse ) : <NEWLINE> <TAB> outputs , state = embedding_rnn_decoder ( <NEWLINE> decoder_inputs , <NEWLINE> encoder_state , <NEWLINE> dec_cell , <NEWLINE> num_decoder_symbols , <NEWLINE> embedding_size , <NEWLINE> feed_previous = feed_previous ) <NEWLINE> <NEWLINE> <UNTAB> state_list = [ state ] <NEWLINE> if nest . is_sequence ( state ) : <NEWLINE> <TAB> state_list = nest . flatten ( state ) <NEWLINE> <UNTAB> return outputs + state_list <NEWLINE> <NEWLINE> <UNTAB> outputs_and_state = control_flow_ops . cond ( <NEWLINE> feed_previous , lambda : filled_embedding_rnn_decoder ( True ) , <NEWLINE> lambda : filled_embedding_rnn_decoder ( False ) ) <NEWLINE> <NEWLINE> outputs_len = len ( decoder_inputs ) <NEWLINE> outputs = outputs_and_state [ : outputs_len ] <NEWLINE> state_list = outputs_and_state [ outputs_len : ] <NEWLINE> state = state_list [ <NUMBER> ] <NEWLINE> if nest . is_sequence ( encoder_state ) : <NEWLINE> <TAB> state = nest . pack_sequence_as ( <NEWLINE> structure = encoder_state , flat_sequence = state_list ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> outputs_dict [ name ] = outputs <NEWLINE> state_dict [ name ] = state <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return outputs_dict , state_dict <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _expand_hint ( expr , hint , deep = True , ** hints ) : <NEWLINE> <TAB> <NEWLINE> hit = False <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if deep and getattr ( expr , <STRING> , ( ) ) and not expr . is_Atom : <NEWLINE> <TAB> sargs = [ ] <NEWLINE> for arg in expr . args : <NEWLINE> <TAB> arg , arghit = Expr . _expand_hint ( arg , hint , ** hints ) <NEWLINE> hit |= arghit <NEWLINE> sargs . append ( arg ) <NEWLINE> <NEWLINE> <UNTAB> if hit : <NEWLINE> <TAB> expr = expr . func ( * sargs ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if hasattr ( expr , hint ) : <NEWLINE> <TAB> newexpr = getattr ( expr , hint ) ( ** hints ) <NEWLINE> if newexpr != expr : <NEWLINE> <TAB> return ( newexpr , True ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return ( expr , hit ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _unpickle_sparse_frame_compat ( self , state ) : <NEWLINE> <TAB> <NEWLINE> series , cols , idx , fv , kind = state <NEWLINE> <NEWLINE> if not isinstance ( cols , Index ) : <NEWLINE> <TAB> from pandas . io . pickle import _unpickle_array <NEWLINE> columns = _unpickle_array ( cols ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> columns = cols <NEWLINE> <NEWLINE> <UNTAB> if not isinstance ( idx , Index ) : <NEWLINE> <TAB> from pandas . io . pickle import _unpickle_array <NEWLINE> index = _unpickle_array ( idx ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> index = idx <NEWLINE> <NEWLINE> <UNTAB> series_dict = DataFrame ( ) <NEWLINE> for col , ( sp_index , sp_values ) in compat . iteritems ( series ) : <NEWLINE> <TAB> series_dict [ col ] = SparseSeries ( sp_values , sparse_index = sp_index , <NEWLINE> fill_value = fv ) <NEWLINE> <NEWLINE> <UNTAB> self . _data = to_manager ( series_dict , columns , index ) <NEWLINE> self . _default_fill_value = fv <NEWLINE> self . _default_kind = kind <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tc . returns ( tc . Optional ( list ) ) <NEWLINE> @ tc . accepts ( list , list ) <NEWLINE> def _find_consistent_ordering ( a , b ) : <NEWLINE> <TAB> <NEWLINE> a_set = set ( a ) <NEWLINE> b_set = set ( b ) <NEWLINE> i = <NUMBER> <NEWLINE> j = <NUMBER> <NEWLINE> ordering = [ ] <NEWLINE> while i < len ( a ) and j < len ( b ) : <NEWLINE> <TAB> if a [ i ] not in b_set : <NEWLINE> <TAB> ordering . append ( a [ i ] ) <NEWLINE> i += <NUMBER> <NEWLINE> <UNTAB> elif b [ j ] not in a_set : <NEWLINE> <TAB> ordering . append ( b [ j ] ) <NEWLINE> j += <NUMBER> <NEWLINE> <UNTAB> elif a [ i ] == b [ j ] : <NEWLINE> <TAB> ordering . append ( a [ i ] ) <NEWLINE> i += <NUMBER> <NEWLINE> j += <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> ordering . extend ( a [ i : ] ) <NEWLINE> ordering . extend ( b [ j : ] ) <NEWLINE> <NEWLINE> return ordering <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_coeff_Add ( self , rational = False ) : <NEWLINE> <TAB> <NEWLINE> coeff , args = self . args [ <NUMBER> ] , self . args [ <NUMBER> : ] <NEWLINE> <NEWLINE> if coeff . is_Number and not rational or coeff . is_Rational : <NEWLINE> <TAB> return coeff , self . _new_rawargs ( * args ) <NEWLINE> <UNTAB> return S . Zero , self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __eq__ ( p1 , p2 ) : <NEWLINE> <TAB> <NEWLINE> if not p2 : <NEWLINE> <TAB> return not p1 <NEWLINE> <UNTAB> elif isinstance ( p2 , PolyElement ) and p2 . ring == p1 . ring : <NEWLINE> <TAB> return dict . __eq__ ( p1 , p2 ) <NEWLINE> <UNTAB> elif len ( p1 ) > <NUMBER> : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return p1 . get ( p1 . ring . zero_monom ) == p2 <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def finalize ( self ) : <NEWLINE> <TAB> <NEWLINE> for iterator in six . itervalues ( self . _iterators ) : <NEWLINE> <TAB> iterator . finalize ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_AlgebraicField ( K1 , a , K0 ) : <NEWLINE> <TAB> <NEWLINE> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def downcast_intp_index ( arr ) : <NEWLINE> <TAB> <NEWLINE> if arr . dtype . itemsize > np . dtype ( np . intp ) . itemsize : <NEWLINE> <TAB> if arr . size == <NUMBER> : <NEWLINE> <TAB> return arr . astype ( np . intp ) <NEWLINE> <UNTAB> maxval = arr . max ( ) <NEWLINE> minval = arr . min ( ) <NEWLINE> if maxval > np . iinfo ( np . intp ) . max or minval < np . iinfo ( np . intp ) . min : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> return arr . astype ( np . intp ) <NEWLINE> <UNTAB> return arr <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <NEWLINE> <STRING> , <NEWLINE> v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecation . deprecated_endpoints ( <STRING> ) <NEWLINE> def assert_integer ( x , message = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> message = message or <STRING> <NEWLINE> with ops . name_scope ( name , <STRING> , [ x ] ) : <NEWLINE> <TAB> x = ops . convert_to_tensor ( x , name = <STRING> ) <NEWLINE> if not x . dtype . is_integer : <NEWLINE> <TAB> if context . executing_eagerly ( ) : <NEWLINE> <TAB> name = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> name = x . name <NEWLINE> <UNTAB> err_msg = ( <NEWLINE> <STRING> <NEWLINE> % ( message , name , x . dtype ) ) <NEWLINE> raise TypeError ( err_msg ) <NEWLINE> <NEWLINE> <UNTAB> return control_flow_ops . no_op ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _from_list ( cls , rep , opt ) : <NEWLINE> <TAB> <NEWLINE> gens = opt . gens <NEWLINE> <NEWLINE> if not gens : <NEWLINE> <TAB> raise GeneratorsNeeded ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> elif len ( gens ) != <NUMBER> : <NEWLINE> <TAB> raise MultivariatePolynomialError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> level = len ( gens ) - <NUMBER> <NEWLINE> domain = opt . domain <NEWLINE> <NEWLINE> if domain is None : <NEWLINE> <TAB> domain , rep = construct_domain ( rep , opt = opt ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rep = list ( map ( domain . convert , rep ) ) <NEWLINE> <NEWLINE> <UNTAB> return cls . new ( DMP . from_list ( rep , level , domain ) , * gens ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def graph_number_of_cliques ( G , cliques = None ) : <NEWLINE> <TAB> <NEWLINE> if cliques is None : <NEWLINE> <TAB> cliques = list ( find_cliques ( G ) ) <NEWLINE> <UNTAB> return len ( cliques ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def skip ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _skip_flag = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def serialize ( self , value ) : <NEWLINE> <TAB> <NEWLINE> return _helpers . str_or_unicode ( value ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def finalize ( self ) : <NEWLINE> <TAB> <NEWLINE> if eager_context . executing_eagerly ( ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _auto_fn ( name ) : <NEWLINE> <TAB> <NEWLINE> if <STRING> in name : <NEWLINE> <TAB> dialect , driver = name . split ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dialect = name <NEWLINE> driver = <STRING> <NEWLINE> <NEWLINE> <UNTAB> if dialect in _translates : <NEWLINE> <TAB> translated = _translates [ dialect ] <NEWLINE> util . warn_deprecated ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ( dialect , translated ) <NEWLINE> ) <NEWLINE> dialect = translated <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> module = __import__ ( <STRING> % ( dialect , ) ) . dialects <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> module = getattr ( module , dialect ) <NEWLINE> if hasattr ( module , driver ) : <NEWLINE> <TAB> module = getattr ( module , driver ) <NEWLINE> return lambda : module . dialect <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_dominating_set ( G , nbunch ) : <NEWLINE> <TAB> <NEWLINE> testset = set ( n for n in nbunch if n in G ) <NEWLINE> nbrs = set ( chain . from_iterable ( G [ n ] for n in testset ) ) <NEWLINE> return len ( set ( G ) - testset - nbrs ) == <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def unshared2d ( self , inp , kern , out_shape , direction = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if self . convdim != <NUMBER> : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> <NEWLINE> % self . convdim ) <NEWLINE> <UNTAB> out = np . zeros ( out_shape , dtype = inp . dtype ) <NEWLINE> <NEWLINE> if direction == <STRING> : <NEWLINE> <TAB> for row in xrange ( out_shape [ <NUMBER> ] ) : <NEWLINE> <TAB> for col in xrange ( out_shape [ <NUMBER> ] ) : <NEWLINE> <TAB> out [ row , col ] = np . sum ( np . multiply ( inp [ row : row + kern . shape [ <NUMBER> ] , <NEWLINE> col : col + kern . shape [ <NUMBER> ] ] , <NEWLINE> kern [ row , col , : : - <NUMBER> , : : - <NUMBER> ] ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif direction == <STRING> : <NEWLINE> <TAB> for row in xrange ( out_shape [ <NUMBER> ] ) : <NEWLINE> <TAB> for col in xrange ( out_shape [ <NUMBER> ] ) : <NEWLINE> <TAB> out [ row , col , ... ] = kern [ row , col ] * inp [ row : row + out_shape [ <NUMBER> ] , col : col + out_shape [ <NUMBER> ] ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif direction == <STRING> : <NEWLINE> <TAB> for row in xrange ( kern . shape [ <NUMBER> ] ) : <NEWLINE> <TAB> for col in xrange ( kern . shape [ <NUMBER> ] ) : <NEWLINE> <TAB> out [ row : row + kern . shape [ <NUMBER> ] , col : col + kern . shape [ <NUMBER> ] ] += inp [ row , col ] * kern [ row , col , : : - <NUMBER> , : : - <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( direction ) ) <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _make_twin_axes ( self , * kl , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if <STRING> in kwargs and <STRING> in kwargs : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> ax2 = self . figure . add_axes ( self . get_position ( True ) , * kl , ** kwargs ) <NEWLINE> self . set_adjustable ( <STRING> ) <NEWLINE> ax2 . set_adjustable ( <STRING> ) <NEWLINE> self . _twinned_axes . join ( self , ax2 ) <NEWLINE> return ax2 <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def groups ( self ) : <NEWLINE> <TAB> <NEWLINE> return list ( self . __g ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def merge ( * dicts , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if len ( dicts ) == <NUMBER> and not isinstance ( dicts [ <NUMBER> ] , dict ) : <NEWLINE> <TAB> dicts = dicts [ <NUMBER> ] <NEWLINE> <UNTAB> factory = _get_factory ( merge , kwargs ) <NEWLINE> <NEWLINE> rv = factory ( ) <NEWLINE> for d in dicts : <NEWLINE> <TAB> rv . update ( d ) <NEWLINE> <UNTAB> return rv <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def traverse ( self , obj ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def replace ( elem ) : <NEWLINE> <TAB> for v in self . _visitor_iterator : <NEWLINE> <TAB> e = v . replace ( elem ) <NEWLINE> if e is not None : <NEWLINE> <TAB> return e <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return replacement_traverse ( obj , self . __traverse_options__ , replace ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def convert_value ( self , v ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def stringify ( value ) : <NEWLINE> <TAB> if self . encoding is not None : <NEWLINE> <TAB> encoder = partial ( pprint_thing_encoded , <NEWLINE> encoding = self . encoding ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> encoder = pprint_thing <NEWLINE> <UNTAB> return encoder ( value ) <NEWLINE> <NEWLINE> <UNTAB> kind = _ensure_decoded ( self . kind ) <NEWLINE> meta = _ensure_decoded ( self . meta ) <NEWLINE> if kind == u ( <STRING> ) or kind == u ( <STRING> ) : <NEWLINE> <TAB> if isinstance ( v , ( int , float ) ) : <NEWLINE> <TAB> v = stringify ( v ) <NEWLINE> <UNTAB> v = _ensure_decoded ( v ) <NEWLINE> v = pd . Timestamp ( v ) <NEWLINE> if v . tz is not None : <NEWLINE> <TAB> v = v . tz_convert ( <STRING> ) <NEWLINE> <UNTAB> return TermValue ( v , v . value , kind ) <NEWLINE> <UNTAB> elif kind == u ( <STRING> ) or kind == u ( <STRING> ) : <NEWLINE> <TAB> v = _coerce_scalar_to_timedelta_type ( v , unit = <STRING> ) . value <NEWLINE> return TermValue ( int ( v ) , v , kind ) <NEWLINE> <UNTAB> elif meta == u ( <STRING> ) : <NEWLINE> <TAB> metadata = com . _values_from_object ( self . metadata ) <NEWLINE> result = metadata . searchsorted ( v , side = <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if not result and v not in metadata : <NEWLINE> <TAB> result = - <NUMBER> <NEWLINE> <UNTAB> return TermValue ( result , result , u ( <STRING> ) ) <NEWLINE> <UNTAB> elif kind == u ( <STRING> ) : <NEWLINE> <TAB> v = int ( float ( v ) ) <NEWLINE> return TermValue ( v , v , kind ) <NEWLINE> <UNTAB> elif kind == u ( <STRING> ) : <NEWLINE> <TAB> v = float ( v ) <NEWLINE> return TermValue ( v , v , kind ) <NEWLINE> <UNTAB> elif kind == u ( <STRING> ) : <NEWLINE> <TAB> if isinstance ( v , string_types ) : <NEWLINE> <TAB> v = not v . strip ( ) . lower ( ) in [ u ( <STRING> ) , u ( <STRING> ) , u ( <STRING> ) , <NEWLINE> u ( <STRING> ) , u ( <STRING> ) , u ( <STRING> ) , <NEWLINE> u ( <STRING> ) , u ( <STRING> ) , u ( <STRING> ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> v = bool ( v ) <NEWLINE> <UNTAB> return TermValue ( v , v , kind ) <NEWLINE> <UNTAB> elif isinstance ( v , string_types ) : <NEWLINE> <NEWLINE> <TAB> return TermValue ( v , stringify ( v ) , u ( <STRING> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> . format ( v = v , typ = type ( v ) , kind = kind ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _align_32 ( f ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> pos = f . tell ( ) <NEWLINE> if pos % <NUMBER> != <NUMBER> : <NEWLINE> <TAB> f . seek ( pos + <NUMBER> - pos % <NUMBER> ) <NEWLINE> <UNTAB> return <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _initial_nodes ( n ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> fit = <NUMBER> * n - <NUMBER> <NEWLINE> turnover = around ( fit ) . astype ( int ) <NEWLINE> <NEWLINE> ia = arange ( <NUMBER> , int ( floor ( n * <NUMBER> ) + <NUMBER> ) ) <NEWLINE> ib = ia [ : : - <NUMBER> ] <NEWLINE> xasq = _initial_nodes_a ( n , ia [ : turnover + <NUMBER> ] ) <NEWLINE> xbsq = _initial_nodes_b ( n , ib [ turnover + <NUMBER> : ] ) <NEWLINE> <NEWLINE> iv = sqrt ( hstack ( [ xasq , xbsq ] ) ) <NEWLINE> <NEWLINE> if n % <NUMBER> == <NUMBER> : <NEWLINE> <TAB> iv = hstack ( [ <NUMBER> , iv ] ) <NEWLINE> <UNTAB> return iv <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def random_saturation ( image , lower , upper , seed = None ) : <NEWLINE> <TAB> <NEWLINE> if upper <= lower : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if lower < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> saturation_factor = random_ops . random_uniform ( [ ] , lower , upper , seed = seed ) <NEWLINE> return adjust_saturation ( image , saturation_factor ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def transform ( self , input_fn ) : <NEWLINE> <TAB> <NEWLINE> for distances in self . _predict_one_key ( input_fn , <NEWLINE> KMeansClustering . ALL_DISTANCES ) : <NEWLINE> <TAB> yield distances <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _box_values ( self , values ) : <NEWLINE> <TAB> <NEWLINE> return lib . map_infer ( values , self . _box_func ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def bessel_i0 ( x , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ x ] ) : <NEWLINE> <TAB> return math_ops . exp ( math_ops . abs ( x ) ) * math_ops . bessel_i0e ( x ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def resampler ( data , warp , name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ data , warp ] ) : <NEWLINE> <TAB> data_tensor = ops . convert_to_tensor ( data , name = <STRING> ) <NEWLINE> warp_tensor = ops . convert_to_tensor ( warp , name = <STRING> ) <NEWLINE> return gen_resampler_ops . resampler ( data_tensor , warp_tensor ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _pad_bytes_new ( name , length ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( name , string_types ) : <NEWLINE> <TAB> name = _bytes ( name , <STRING> ) <NEWLINE> <UNTAB> return name + <STRING> * ( length - len ( name ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _python2_gzipopen ( fn , mode , encoding , newline ) : <NEWLINE> <TAB> <NEWLINE> import gzip <NEWLINE> <NEWLINE> class GzipWrap ( gzip . GzipFile ) : <NEWLINE> <TAB> def read1 ( self , n ) : <NEWLINE> <TAB> return self . read ( n ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> _check_mode ( mode , encoding , newline ) <NEWLINE> <NEWLINE> gz_mode = mode . replace ( <STRING> , <STRING> ) <NEWLINE> <NEWLINE> if isinstance ( fn , ( str , bytes ) ) : <NEWLINE> <TAB> binary_file = GzipWrap ( fn , gz_mode ) <NEWLINE> <UNTAB> elif hasattr ( fn , <STRING> ) or hasattr ( fn , <STRING> ) : <NEWLINE> <TAB> binary_file = GzipWrap ( None , gz_mode , fileobj = fn ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if <STRING> in mode : <NEWLINE> <TAB> return io . TextIOWrapper ( binary_file , encoding , newline = newline ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return binary_file <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def load_data ( path = <STRING> , test_split = <NUMBER> , seed = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> assert <NUMBER> <= test_split < <NUMBER> <NEWLINE> path = get_file ( <NEWLINE> path , <NEWLINE> origin = <STRING> , <NEWLINE> file_hash = <STRING> ) <NEWLINE> with np . load ( path ) as f : <NEWLINE> <TAB> x = f [ <STRING> ] <NEWLINE> y = f [ <STRING> ] <NEWLINE> <NEWLINE> <UNTAB> np . random . seed ( seed ) <NEWLINE> indices = np . arange ( len ( x ) ) <NEWLINE> np . random . shuffle ( indices ) <NEWLINE> x = x [ indices ] <NEWLINE> y = y [ indices ] <NEWLINE> <NEWLINE> x_train = np . array ( x [ : int ( len ( x ) * ( <NUMBER> - test_split ) ) ] ) <NEWLINE> y_train = np . array ( y [ : int ( len ( x ) * ( <NUMBER> - test_split ) ) ] ) <NEWLINE> x_test = np . array ( x [ int ( len ( x ) * ( <NUMBER> - test_split ) ) : ] ) <NEWLINE> y_test = np . array ( y [ int ( len ( x ) * ( <NUMBER> - test_split ) ) : ] ) <NEWLINE> return ( x_train , y_train ) , ( x_test , y_test ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _sparse_fit ( self , X , random_state ) : <NEWLINE> <TAB> <NEWLINE> n_samples , n_features = X . shape <NEWLINE> references = self . references_ * <NUMBER> <NEWLINE> <NEWLINE> if LooseVersion ( np . __version__ ) < <STRING> : <NEWLINE> <TAB> references = references . tolist ( ) <NEWLINE> <NEWLINE> <UNTAB> self . quantiles_ = [ ] <NEWLINE> for feature_idx in range ( n_features ) : <NEWLINE> <TAB> column_nnz_data = X . data [ X . indptr [ feature_idx ] : <NEWLINE> X . indptr [ feature_idx + <NUMBER> ] ] <NEWLINE> if len ( column_nnz_data ) > self . subsample : <NEWLINE> <TAB> column_subsample = ( self . subsample * len ( column_nnz_data ) // <NEWLINE> n_samples ) <NEWLINE> if self . ignore_implicit_zeros : <NEWLINE> <TAB> column_data = np . zeros ( shape = column_subsample , <NEWLINE> dtype = X . dtype ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> column_data = np . zeros ( shape = self . subsample , dtype = X . dtype ) <NEWLINE> <UNTAB> column_data [ : column_subsample ] = random_state . choice ( <NEWLINE> column_nnz_data , size = column_subsample , replace = False ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if self . ignore_implicit_zeros : <NEWLINE> <TAB> column_data = np . zeros ( shape = len ( column_nnz_data ) , <NEWLINE> dtype = X . dtype ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> column_data = np . zeros ( shape = n_samples , dtype = X . dtype ) <NEWLINE> <UNTAB> column_data [ : len ( column_nnz_data ) ] = column_nnz_data <NEWLINE> <NEWLINE> <UNTAB> if not column_data . size : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> self . quantiles_ . append ( [ <NUMBER> ] * len ( references ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . quantiles_ . append ( nanpercentile ( column_data , references ) ) <NEWLINE> <UNTAB> <UNTAB> self . quantiles_ = np . transpose ( self . quantiles_ ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _register_unknown_flag_setter ( self , setter ) : <NEWLINE> <TAB> <NEWLINE> self . __dict__ [ <STRING> ] = setter <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dynamic_decode ( decoder , <NEWLINE> output_time_major = False , <NEWLINE> impute_finished = False , <NEWLINE> maximum_iterations = None , <NEWLINE> parallel_iterations = <NUMBER> , <NEWLINE> swap_memory = False , <NEWLINE> scope = None ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( decoder , Decoder ) : <NEWLINE> <TAB> raise TypeError ( <STRING> % <NEWLINE> type ( decoder ) ) <NEWLINE> <NEWLINE> <UNTAB> with variable_scope . variable_scope ( scope , <STRING> ) as varscope : <NEWLINE> <NEWLINE> <TAB> ctxt = ops . get_default_graph ( ) . _get_control_flow_context ( ) <NEWLINE> is_xla = control_flow_util . GetContainingXLAContext ( ctxt ) is not None <NEWLINE> in_while_loop = ( <NEWLINE> control_flow_util . GetContainingWhileContext ( ctxt ) is not None ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if not context . executing_eagerly ( ) and not in_while_loop : <NEWLINE> <TAB> if varscope . caching_device is None : <NEWLINE> <TAB> varscope . set_caching_device ( lambda op : op . device ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if maximum_iterations is not None : <NEWLINE> <TAB> maximum_iterations = ops . convert_to_tensor ( <NEWLINE> maximum_iterations , dtype = dtypes . int32 , name = <STRING> ) <NEWLINE> if maximum_iterations . get_shape ( ) . ndims != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> initial_finished , initial_inputs , initial_state = decoder . initialize ( ) <NEWLINE> <NEWLINE> zero_outputs = _create_zero_outputs ( decoder . output_size , <NEWLINE> decoder . output_dtype , <NEWLINE> decoder . batch_size ) <NEWLINE> <NEWLINE> if is_xla and maximum_iterations is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if maximum_iterations is not None : <NEWLINE> <TAB> initial_finished = math_ops . logical_or ( <NEWLINE> initial_finished , <NUMBER> >= maximum_iterations ) <NEWLINE> <UNTAB> initial_sequence_lengths = array_ops . zeros_like ( <NEWLINE> initial_finished , dtype = dtypes . int32 ) <NEWLINE> initial_time = constant_op . constant ( <NUMBER> , dtype = dtypes . int32 ) <NEWLINE> <NEWLINE> def _shape ( batch_size , from_shape ) : <NEWLINE> <TAB> if ( not isinstance ( from_shape , tensor_shape . TensorShape ) or <NEWLINE> from_shape . ndims == <NUMBER> ) : <NEWLINE> <TAB> return tensor_shape . TensorShape ( None ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> batch_size = tensor_util . constant_value ( <NEWLINE> ops . convert_to_tensor ( <NEWLINE> batch_size , name = <STRING> ) ) <NEWLINE> return tensor_shape . TensorShape ( [ batch_size ] ) . concatenate ( from_shape ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> dynamic_size = maximum_iterations is None or not is_xla <NEWLINE> <NEWLINE> def _create_ta ( s , d ) : <NEWLINE> <TAB> return tensor_array_ops . TensorArray ( <NEWLINE> dtype = d , <NEWLINE> size = <NUMBER> if dynamic_size else maximum_iterations , <NEWLINE> dynamic_size = dynamic_size , <NEWLINE> element_shape = _shape ( decoder . batch_size , s ) ) <NEWLINE> <NEWLINE> <UNTAB> initial_outputs_ta = nest . map_structure ( _create_ta , decoder . output_size , <NEWLINE> decoder . output_dtype ) <NEWLINE> <NEWLINE> def condition ( unused_time , unused_outputs_ta , unused_state , unused_inputs , <NEWLINE> finished , unused_sequence_lengths ) : <NEWLINE> <TAB> return math_ops . logical_not ( math_ops . reduce_all ( finished ) ) <NEWLINE> <NEWLINE> <UNTAB> def body ( time , outputs_ta , state , inputs , finished , sequence_lengths ) : <NEWLINE> <TAB> <NEWLINE> ( next_outputs , decoder_state , next_inputs , <NEWLINE> decoder_finished ) = decoder . step ( time , inputs , state ) <NEWLINE> if decoder . tracks_own_finished : <NEWLINE> <TAB> next_finished = decoder_finished <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> next_finished = math_ops . logical_or ( decoder_finished , finished ) <NEWLINE> <UNTAB> next_sequence_lengths = array_ops . where ( <NEWLINE> math_ops . logical_not ( finished ) , <NEWLINE> array_ops . fill ( array_ops . shape ( sequence_lengths ) , time + <NUMBER> ) , <NEWLINE> sequence_lengths ) <NEWLINE> <NEWLINE> nest . assert_same_structure ( state , decoder_state ) <NEWLINE> nest . assert_same_structure ( outputs_ta , next_outputs ) <NEWLINE> nest . assert_same_structure ( inputs , next_inputs ) <NEWLINE> <NEWLINE> <NEWLINE> if impute_finished : <NEWLINE> <TAB> emit = nest . map_structure ( <NEWLINE> lambda out , zero : array_ops . where ( finished , zero , out ) , <NEWLINE> next_outputs , <NEWLINE> zero_outputs ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> emit = next_outputs <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> def _maybe_copy_state ( new , cur ) : <NEWLINE> <NEWLINE> <TAB> if isinstance ( cur , tensor_array_ops . TensorArray ) : <NEWLINE> <TAB> pass_through = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> new . set_shape ( cur . shape ) <NEWLINE> pass_through = ( new . shape . ndims == <NUMBER> ) <NEWLINE> <UNTAB> return new if pass_through else array_ops . where ( finished , cur , new ) <NEWLINE> <NEWLINE> <UNTAB> if impute_finished : <NEWLINE> <TAB> next_state = nest . map_structure ( <NEWLINE> _maybe_copy_state , decoder_state , state ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> next_state = decoder_state <NEWLINE> <NEWLINE> <UNTAB> outputs_ta = nest . map_structure ( lambda ta , out : ta . write ( time , out ) , <NEWLINE> outputs_ta , emit ) <NEWLINE> return ( time + <NUMBER> , outputs_ta , next_state , next_inputs , next_finished , <NEWLINE> next_sequence_lengths ) <NEWLINE> <NEWLINE> <UNTAB> res = control_flow_ops . while_loop ( <NEWLINE> condition , <NEWLINE> body , <NEWLINE> loop_vars = ( <NEWLINE> initial_time , <NEWLINE> initial_outputs_ta , <NEWLINE> initial_state , <NEWLINE> initial_inputs , <NEWLINE> initial_finished , <NEWLINE> initial_sequence_lengths , <NEWLINE> ) , <NEWLINE> parallel_iterations = parallel_iterations , <NEWLINE> maximum_iterations = maximum_iterations , <NEWLINE> swap_memory = swap_memory ) <NEWLINE> <NEWLINE> final_outputs_ta = res [ <NUMBER> ] <NEWLINE> final_state = res [ <NUMBER> ] <NEWLINE> final_sequence_lengths = res [ <NUMBER> ] <NEWLINE> <NEWLINE> final_outputs = nest . map_structure ( lambda ta : ta . stack ( ) , final_outputs_ta ) <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> final_outputs , final_state = decoder . finalize ( <NEWLINE> final_outputs , final_state , final_sequence_lengths ) <NEWLINE> <UNTAB> except NotImplementedError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> if not output_time_major : <NEWLINE> <TAB> final_outputs = nest . map_structure ( _transpose_batch_time , final_outputs ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return final_outputs , final_state , final_sequence_lengths <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_display ( self , s ) : <NEWLINE> <TAB> <NEWLINE> self . _display = s <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def moments ( image , order = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return moments_central ( image , ( <NUMBER> , ) * image . ndim , order = order ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def sc_diff ( x , a , b , period = None , _cache = _cache ) : <NEWLINE> <TAB> <NEWLINE> tmp = asarray ( x ) <NEWLINE> if iscomplexobj ( tmp ) : <NEWLINE> <TAB> return sc_diff ( tmp . real , a , b , period ) + <NUMBER> * sc_diff ( tmp . imag , a , b , period ) <NEWLINE> <UNTAB> if period is not None : <NEWLINE> <TAB> a = a * <NUMBER> * pi / period <NEWLINE> b = b * <NUMBER> * pi / period <NEWLINE> <UNTAB> n = len ( x ) <NEWLINE> omega = _cache . get ( ( n , a , b ) ) <NEWLINE> if omega is None : <NEWLINE> <TAB> if len ( _cache ) > <NUMBER> : <NEWLINE> <TAB> while _cache : <NEWLINE> <TAB> _cache . popitem ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def kernel ( k , a = a , b = b ) : <NEWLINE> <TAB> if k : <NEWLINE> <TAB> return sinh ( a * k ) / cosh ( b * k ) <NEWLINE> <UNTAB> return <NUMBER> <NEWLINE> <UNTAB> omega = convolve . init_convolution_kernel ( n , kernel , d = <NUMBER> ) <NEWLINE> _cache [ ( n , a , b ) ] = omega <NEWLINE> <UNTAB> overwrite_x = _datacopied ( tmp , x ) <NEWLINE> return convolve . convolve ( tmp , omega , swap_real_imag = <NUMBER> , overwrite_x = overwrite_x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def cumprod ( x , axis = None ) : <NEWLINE> <TAB> <NEWLINE> return CumOp ( axis = axis , mode = <STRING> ) ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def odeint_fixed ( func , y0 , t , dt = None , method = <STRING> , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ y0 , t , dt ] ) : <NEWLINE> <TAB> t = ops . convert_to_tensor ( t , preferred_dtype = dtypes . float64 , name = <STRING> ) <NEWLINE> y0 = ops . convert_to_tensor ( y0 , name = <STRING> ) <NEWLINE> <NEWLINE> intervals = t [ <NUMBER> : ] - t [ : - <NUMBER> ] <NEWLINE> if dt is None : <NEWLINE> <TAB> dt = intervals <NEWLINE> <UNTAB> dt = ops . convert_to_tensor ( dt , preferred_dtype = dtypes . float64 , name = <STRING> ) <NEWLINE> <NEWLINE> steps_on_intervals = math_ops . ceil ( intervals / dt ) <NEWLINE> dt = intervals / steps_on_intervals <NEWLINE> steps_on_intervals = math_ops . cast ( steps_on_intervals , dtype = dtypes . int32 ) <NEWLINE> <NEWLINE> _check_input_types ( y0 , t , dt ) <NEWLINE> _check_input_sizes ( t , dt ) <NEWLINE> <NEWLINE> with _assert_increasing ( t ) : <NEWLINE> <TAB> with ops . name_scope ( method ) : <NEWLINE> <TAB> if method == <STRING> : <NEWLINE> <TAB> return _MidpointFixedGridIntegrator ( ) . integrate ( func , y0 , t , dt , <NEWLINE> steps_on_intervals ) <NEWLINE> <UNTAB> elif method == <STRING> : <NEWLINE> <TAB> return _RK4FixedGridIntegrator ( ) . integrate ( func , y0 , t , dt , <NEWLINE> steps_on_intervals ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( method ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_sprite ( self , idx ) : <NEWLINE> <TAB> <NEWLINE> return self . _spritelist [ idx ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_common_arg_candidates ( self , argset , min_func_i = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> from collections import defaultdict <NEWLINE> count_map = defaultdict ( lambda : <NUMBER> ) <NEWLINE> <NEWLINE> funcsets = [ self . arg_to_funcset [ arg ] for arg in argset ] <NEWLINE> <NEWLINE> <NEWLINE> largest_funcset = max ( funcsets , key = len ) <NEWLINE> <NEWLINE> for funcset in funcsets : <NEWLINE> <TAB> if largest_funcset is funcset : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> for func_i in funcset : <NEWLINE> <TAB> if func_i >= min_func_i : <NEWLINE> <TAB> count_map [ func_i ] += <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> ( smaller_funcs_container , <NEWLINE> larger_funcs_container ) = sorted ( <NEWLINE> [ largest_funcset , count_map ] , <NEWLINE> key = len ) <NEWLINE> <NEWLINE> for func_i in smaller_funcs_container : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if count_map [ func_i ] < <NUMBER> : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> if func_i in larger_funcs_container : <NEWLINE> <TAB> count_map [ func_i ] += <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return dict ( ( k , v ) for k , v in count_map . items ( ) if v >= <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def task_ordinal_at_coordinates ( self , device_coordinates ) : <NEWLINE> <TAB> <NEWLINE> return self . _topology_tasks [ tuple ( device_coordinates ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def getargvalues ( frame ) : <NEWLINE> <TAB> <NEWLINE> args , varargs , varkw = getargs ( frame . f_code ) <NEWLINE> return args , varargs , varkw , frame . f_locals <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _with_annotations ( self , values ) : <NEWLINE> <TAB> <NEWLINE> return Annotated ( self , values ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def connect ( self ) : <NEWLINE> <TAB> <NEWLINE> self . _cidmotion = self . canvas . mpl_connect ( <STRING> , <NEWLINE> self . onmove ) <NEWLINE> self . _ciddraw = self . canvas . mpl_connect ( <STRING> , self . clear ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( None , <STRING> ) <NEWLINE> def extract_labels ( f , one_hot = False , num_classes = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> print ( <STRING> , f . name ) <NEWLINE> with gzip . GzipFile ( fileobj = f ) as bytestream : <NEWLINE> <TAB> magic = _read32 ( bytestream ) <NEWLINE> if magic != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % <NEWLINE> ( magic , f . name ) ) <NEWLINE> <UNTAB> num_items = _read32 ( bytestream ) <NEWLINE> buf = bytestream . read ( num_items ) <NEWLINE> labels = numpy . frombuffer ( buf , dtype = numpy . uint8 ) <NEWLINE> if one_hot : <NEWLINE> <TAB> return dense_to_one_hot ( labels , num_classes ) <NEWLINE> <UNTAB> return labels <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def make_variable ( self , name = None ) : <NEWLINE> <TAB> <NEWLINE> return self . Variable ( self , name = name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _compiler ( self , dialect , ** kw ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return dialect . ddl_compiler ( dialect , self , ** kw ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_quo ( f , g , u , K ) : <NEWLINE> <TAB> <NEWLINE> return dmp_div ( f , g , u , K ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def append_group_by ( self , * clauses ) : <NEWLINE> <TAB> <NEWLINE> if len ( clauses ) == <NUMBER> and clauses [ <NUMBER> ] is None : <NEWLINE> <TAB> self . _group_by_clause = ClauseList ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if getattr ( self , <STRING> , None ) is not None : <NEWLINE> <TAB> clauses = list ( self . _group_by_clause ) + list ( clauses ) <NEWLINE> <UNTAB> self . _group_by_clause = ClauseList ( <NEWLINE> * clauses , _literal_as_text = _literal_as_label_reference ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def intersection_all ( graphs ) : <NEWLINE> <TAB> <NEWLINE> if not graphs : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> graphs = iter ( graphs ) <NEWLINE> R = next ( graphs ) <NEWLINE> for H in graphs : <NEWLINE> <TAB> R = nx . intersection ( R , H ) <NEWLINE> <UNTAB> return R <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def do_not_doc_inheritable ( obj ) : <NEWLINE> <TAB> <NEWLINE> setattr ( obj , _DO_NOT_DOC_INHERITABLE , None ) <NEWLINE> return obj <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _can_set_locale ( lc ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> with set_locale ( lc ) : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> except locale . Error : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def condition_tensor_from_onehot ( tensor , one_hot_labels , embedding_size = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> _validate_onehot ( one_hot_labels ) <NEWLINE> <NEWLINE> conditioning = _one_hot_to_embedding ( one_hot_labels , embedding_size ) <NEWLINE> return condition_tensor ( tensor , conditioning ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def sort_indices ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if not self . has_sorted_indices : <NEWLINE> <TAB> _sparsetools . csr_sort_indices ( len ( self . indptr ) - <NUMBER> , self . indptr , <NEWLINE> self . indices , self . data ) <NEWLINE> self . has_sorted_indices = True <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def restore ( self ) : <NEWLINE> <TAB> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_numer_denom ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> exp = self . exp <NEWLINE> neg_exp = exp . is_negative <NEWLINE> if not neg_exp and not ( - exp ) . is_negative : <NEWLINE> <TAB> neg_exp = _coeff_isneg ( exp ) <NEWLINE> <UNTAB> if neg_exp : <NEWLINE> <TAB> return S . One , self . func ( - exp ) <NEWLINE> <UNTAB> return self , S . One <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _multi_lgamma ( self , a , p , name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> with self . _name_scope ( name , values = [ a , p ] ) : <NEWLINE> <TAB> seq = self . _multi_gamma_sequence ( a , p ) <NEWLINE> return ( <NUMBER> * p * ( p - <NUMBER> ) * math . log ( math . pi ) + <NEWLINE> math_ops . reduce_sum ( math_ops . lgamma ( seq ) , <NEWLINE> axis = [ - <NUMBER> ] ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def equals ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if self . is_ ( other ) : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <UNTAB> if not isinstance ( other , Index ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> if is_object_dtype ( self ) and not is_object_dtype ( other ) : <NEWLINE> <NEWLINE> <TAB> return other . equals ( self ) <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> return array_equivalent ( com . _values_from_object ( self ) , <NEWLINE> com . _values_from_object ( other ) ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def concatenate ( cls , canonical_constraints , sparse_jacobian ) : <NEWLINE> <TAB> <NEWLINE> def fun ( x ) : <NEWLINE> <TAB> eq_all = [ ] <NEWLINE> ineq_all = [ ] <NEWLINE> for c in canonical_constraints : <NEWLINE> <TAB> eq , ineq = c . fun ( x ) <NEWLINE> eq_all . append ( eq ) <NEWLINE> ineq_all . append ( ineq ) <NEWLINE> <NEWLINE> <UNTAB> return np . hstack ( eq_all ) , np . hstack ( ineq_all ) <NEWLINE> <NEWLINE> <UNTAB> if sparse_jacobian : <NEWLINE> <TAB> vstack = sps . vstack <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> vstack = np . vstack <NEWLINE> <NEWLINE> <UNTAB> def jac ( x ) : <NEWLINE> <TAB> eq_all = [ ] <NEWLINE> ineq_all = [ ] <NEWLINE> for c in canonical_constraints : <NEWLINE> <TAB> eq , ineq = c . jac ( x ) <NEWLINE> eq_all . append ( eq ) <NEWLINE> ineq_all . append ( ineq ) <NEWLINE> <UNTAB> return vstack ( eq_all ) , vstack ( ineq_all ) <NEWLINE> <NEWLINE> <UNTAB> def hess ( x , v_eq , v_ineq ) : <NEWLINE> <TAB> hess_all = [ ] <NEWLINE> index_eq = <NUMBER> <NEWLINE> index_ineq = <NUMBER> <NEWLINE> for c in canonical_constraints : <NEWLINE> <TAB> vc_eq = v_eq [ index_eq : index_eq + c . n_eq ] <NEWLINE> vc_ineq = v_ineq [ index_ineq : index_ineq + c . n_ineq ] <NEWLINE> hess_all . append ( c . hess ( x , vc_eq , vc_ineq ) ) <NEWLINE> index_eq += c . n_eq <NEWLINE> index_ineq += c . n_ineq <NEWLINE> <NEWLINE> <UNTAB> def matvec ( p ) : <NEWLINE> <TAB> result = np . zeros_like ( p ) <NEWLINE> for h in hess_all : <NEWLINE> <TAB> result += h . dot ( p ) <NEWLINE> <UNTAB> return result <NEWLINE> <NEWLINE> <UNTAB> n = x . shape [ <NUMBER> ] <NEWLINE> return sps . linalg . LinearOperator ( ( n , n ) , matvec , dtype = float ) <NEWLINE> <NEWLINE> <UNTAB> n_eq = sum ( c . n_eq for c in canonical_constraints ) <NEWLINE> n_ineq = sum ( c . n_ineq for c in canonical_constraints ) <NEWLINE> keep_feasible = np . array ( np . hstack ( ( <NEWLINE> c . keep_feasible for c in canonical_constraints ) ) , dtype = bool ) <NEWLINE> <NEWLINE> return cls ( n_eq , n_ineq , fun , jac , hess , keep_feasible ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_ylabels ( self , label = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if label is None : <NEWLINE> <TAB> label = self . _y_var <NEWLINE> <UNTAB> for ax in self . _left_axes : <NEWLINE> <TAB> ax . set_ylabel ( label , ** kwargs ) <NEWLINE> <UNTAB> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , op_type ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( op_type , six . string_types ) : <NEWLINE> <TAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> self . _op_type = op_type <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def apply_transform ( self , x , transform_parameters ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> img_row_axis = self . row_axis - <NUMBER> <NEWLINE> img_col_axis = self . col_axis - <NUMBER> <NEWLINE> img_channel_axis = self . channel_axis - <NUMBER> <NEWLINE> <NEWLINE> x = apply_affine_transform ( x , transform_parameters . get ( <STRING> , <NUMBER> ) , <NEWLINE> transform_parameters . get ( <STRING> , <NUMBER> ) , <NEWLINE> transform_parameters . get ( <STRING> , <NUMBER> ) , <NEWLINE> transform_parameters . get ( <STRING> , <NUMBER> ) , <NEWLINE> transform_parameters . get ( <STRING> , <NUMBER> ) , <NEWLINE> transform_parameters . get ( <STRING> , <NUMBER> ) , <NEWLINE> row_axis = img_row_axis , <NEWLINE> col_axis = img_col_axis , <NEWLINE> channel_axis = img_channel_axis , <NEWLINE> fill_mode = self . fill_mode , <NEWLINE> cval = self . cval ) <NEWLINE> <NEWLINE> if transform_parameters . get ( <STRING> ) is not None : <NEWLINE> <TAB> x = apply_channel_shift ( x , <NEWLINE> transform_parameters [ <STRING> ] , <NEWLINE> img_channel_axis ) <NEWLINE> <NEWLINE> <UNTAB> if transform_parameters . get ( <STRING> , False ) : <NEWLINE> <TAB> x = flip_axis ( x , img_col_axis ) <NEWLINE> <NEWLINE> <UNTAB> if transform_parameters . get ( <STRING> , False ) : <NEWLINE> <TAB> x = flip_axis ( x , img_row_axis ) <NEWLINE> <NEWLINE> <UNTAB> if transform_parameters . get ( <STRING> ) is not None : <NEWLINE> <TAB> x = apply_brightness_shift ( x , transform_parameters [ <STRING> ] ) <NEWLINE> <NEWLINE> <UNTAB> return x <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _minor_reduce ( self , ufunc , data = None ) : <NEWLINE> <TAB> <NEWLINE> if data is None : <NEWLINE> <TAB> data = self . data <NEWLINE> <UNTAB> major_index = np . flatnonzero ( np . diff ( self . indptr ) ) <NEWLINE> value = ufunc . reduceat ( data , <NEWLINE> downcast_intp_index ( self . indptr [ major_index ] ) ) <NEWLINE> return major_index , value <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def compose_all ( graphs ) : <NEWLINE> <TAB> <NEWLINE> if not graphs : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> graphs = iter ( graphs ) <NEWLINE> C = next ( graphs ) <NEWLINE> for H in graphs : <NEWLINE> <TAB> C = nx . compose ( C , H ) <NEWLINE> <UNTAB> return C <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def unflatten ( iter , n = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if n < <NUMBER> or len ( iter ) % n : <NEWLINE> <TAB> raise ValueError ( <STRING> % n ) <NEWLINE> <UNTAB> return list ( zip ( * ( iter [ i : : n ] for i in range ( n ) ) ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def set_config ( assume_finite = None , working_memory = None ) : <NEWLINE> <TAB> <NEWLINE> if assume_finite is not None : <NEWLINE> <TAB> _global_config [ <STRING> ] = assume_finite <NEWLINE> <UNTAB> if working_memory is not None : <NEWLINE> <TAB> _global_config [ <STRING> ] = working_memory <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dropout ( x , level , noise_shape = None , seed = None ) : <NEWLINE> <TAB> <NEWLINE> retain_prob = <NUMBER> - level <NEWLINE> if seed is None : <NEWLINE> <TAB> seed = np . random . randint ( <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return tf . nn . dropout ( x * <NUMBER> , retain_prob , noise_shape , seed = seed ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def interpolated ( self , steps ) : <NEWLINE> <TAB> <NEWLINE> if steps == <NUMBER> : <NEWLINE> <TAB> return self <NEWLINE> <NEWLINE> <UNTAB> vertices = simple_linear_interpolation ( self . vertices , steps ) <NEWLINE> codes = self . codes <NEWLINE> if codes is not None : <NEWLINE> <TAB> new_codes = Path . LINETO * np . ones ( ( ( len ( codes ) - <NUMBER> ) * steps + <NUMBER> , ) ) <NEWLINE> new_codes [ <NUMBER> : : steps ] = codes <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> new_codes = None <NEWLINE> <UNTAB> return Path ( vertices , new_codes ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _check_valid_event_ndims ( self , min_event_ndims , event_ndims ) : <NEWLINE> <TAB> <NEWLINE> event_ndims = ops . convert_to_tensor ( event_ndims , name = <STRING> ) <NEWLINE> event_ndims_ = tensor_util . constant_value ( event_ndims ) <NEWLINE> assertions = [ ] <NEWLINE> <NEWLINE> if not event_ndims . dtype . is_integer : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( <NEWLINE> event_ndims . dtype ) ) <NEWLINE> <NEWLINE> <UNTAB> if event_ndims_ is not None : <NEWLINE> <TAB> if event_ndims . shape . ndims != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( <NEWLINE> event_ndims . shape ) ) <NEWLINE> <UNTAB> if min_event_ndims > event_ndims_ : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> . format ( <NEWLINE> event_ndims_ , min_event_ndims ) ) <NEWLINE> <UNTAB> <UNTAB> elif self . validate_args : <NEWLINE> <TAB> assertions += [ <NEWLINE> check_ops . assert_greater_equal ( event_ndims , min_event_ndims ) ] <NEWLINE> <NEWLINE> <UNTAB> if event_ndims . shape . is_fully_defined ( ) : <NEWLINE> <TAB> if event_ndims . shape . ndims != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( <NEWLINE> event_ndims . shape . ndims ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif self . validate_args : <NEWLINE> <TAB> assertions += [ <NEWLINE> check_ops . assert_rank ( event_ndims , <NUMBER> , message = <STRING> ) ] <NEWLINE> <UNTAB> return assertions <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def write_array ( self , data ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> data . tofile ( self . _fh ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <NEWLINE> <TAB> self . _fh . write ( data . tostring ( ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def place_poles ( A , B , poles , method = <STRING> , rtol = <NUMBER> , maxiter = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> update_loop , poles = _valid_inputs ( A , B , poles , method , rtol , maxiter ) <NEWLINE> <NEWLINE> <NEWLINE> cur_rtol = <NUMBER> <NEWLINE> <NEWLINE> nb_iter = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> u , z = s_qr ( B , mode = <STRING> ) <NEWLINE> rankB = np . linalg . matrix_rank ( B ) <NEWLINE> u0 = u [ : , : rankB ] <NEWLINE> u1 = u [ : , rankB : ] <NEWLINE> z = z [ : rankB , : ] <NEWLINE> <NEWLINE> <NEWLINE> if B . shape [ <NUMBER> ] == rankB : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> diag_poles = np . zeros ( A . shape ) <NEWLINE> idx = <NUMBER> <NEWLINE> while idx < poles . shape [ <NUMBER> ] : <NEWLINE> <TAB> p = poles [ idx ] <NEWLINE> diag_poles [ idx , idx ] = np . real ( p ) <NEWLINE> if ~ np . isreal ( p ) : <NEWLINE> <TAB> diag_poles [ idx , idx + <NUMBER> ] = - np . imag ( p ) <NEWLINE> diag_poles [ idx + <NUMBER> , idx + <NUMBER> ] = np . real ( p ) <NEWLINE> diag_poles [ idx + <NUMBER> , idx ] = np . imag ( p ) <NEWLINE> idx += <NUMBER> <NEWLINE> <UNTAB> idx += <NUMBER> <NEWLINE> <UNTAB> gain_matrix = np . linalg . lstsq ( B , diag_poles - A , rcond = - <NUMBER> ) [ <NUMBER> ] <NEWLINE> transfer_matrix = np . eye ( A . shape [ <NUMBER> ] ) <NEWLINE> cur_rtol = np . nan <NEWLINE> nb_iter = np . nan <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> ker_pole = [ ] <NEWLINE> <NEWLINE> <NEWLINE> skip_conjugate = False <NEWLINE> <NEWLINE> <NEWLINE> for j in range ( B . shape [ <NUMBER> ] ) : <NEWLINE> <TAB> if skip_conjugate : <NEWLINE> <TAB> skip_conjugate = False <NEWLINE> continue <NEWLINE> <UNTAB> pole_space_j = np . dot ( u1 . T , A - poles [ j ] * np . eye ( B . shape [ <NUMBER> ] ) ) . T <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> Q , _ = s_qr ( pole_space_j , mode = <STRING> ) <NEWLINE> <NEWLINE> ker_pole_j = Q [ : , pole_space_j . shape [ <NUMBER> ] : ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> transfer_matrix_j = np . sum ( ker_pole_j , axis = <NUMBER> ) [ : , np . newaxis ] <NEWLINE> transfer_matrix_j = ( transfer_matrix_j / <NEWLINE> np . linalg . norm ( transfer_matrix_j ) ) <NEWLINE> if ~ np . isreal ( poles [ j ] ) : <NEWLINE> <TAB> transfer_matrix_j = np . hstack ( [ np . real ( transfer_matrix_j ) , <NEWLINE> np . imag ( transfer_matrix_j ) ] ) <NEWLINE> ker_pole . extend ( [ ker_pole_j , ker_pole_j ] ) <NEWLINE> <NEWLINE> <NEWLINE> skip_conjugate = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ker_pole . append ( ker_pole_j ) <NEWLINE> <NEWLINE> <UNTAB> if j == <NUMBER> : <NEWLINE> <TAB> transfer_matrix = transfer_matrix_j <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> transfer_matrix = np . hstack ( ( transfer_matrix , transfer_matrix_j ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if rankB > <NUMBER> : <NEWLINE> <TAB> stop , cur_rtol , nb_iter = update_loop ( ker_pole , transfer_matrix , <NEWLINE> poles , B , maxiter , rtol ) <NEWLINE> if not stop and rtol > <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> err_msg = ( <NEWLINE> <STRING> <NEWLINE> <STRING> % <NEWLINE> ( rtol , cur_rtol ) <NEWLINE> ) <NEWLINE> warnings . warn ( err_msg ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> transfer_matrix = transfer_matrix . astype ( complex ) <NEWLINE> idx = <NUMBER> <NEWLINE> while idx < poles . shape [ <NUMBER> ] - <NUMBER> : <NEWLINE> <TAB> if ~ np . isreal ( poles [ idx ] ) : <NEWLINE> <TAB> rel = transfer_matrix [ : , idx ] . copy ( ) <NEWLINE> img = transfer_matrix [ : , idx + <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> transfer_matrix [ : , idx ] = rel - <NUMBER> * img <NEWLINE> transfer_matrix [ : , idx + <NUMBER> ] = rel + <NUMBER> * img <NEWLINE> idx += <NUMBER> <NEWLINE> <UNTAB> idx += <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> m = np . linalg . solve ( transfer_matrix . T , np . dot ( np . diag ( poles ) , <NEWLINE> transfer_matrix . T ) ) . T <NEWLINE> gain_matrix = np . linalg . solve ( z , np . dot ( u0 . T , m - A ) ) <NEWLINE> <UNTAB> except np . linalg . LinAlgError : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> gain_matrix = - gain_matrix <NEWLINE> <NEWLINE> gain_matrix = np . real ( gain_matrix ) <NEWLINE> <NEWLINE> full_state_feedback = Bunch ( ) <NEWLINE> full_state_feedback . gain_matrix = gain_matrix <NEWLINE> full_state_feedback . computed_poles = _order_complex_poles ( <NEWLINE> np . linalg . eig ( A - np . dot ( B , gain_matrix ) ) [ <NUMBER> ] <NEWLINE> ) <NEWLINE> full_state_feedback . requested_poles = poles <NEWLINE> full_state_feedback . X = transfer_matrix <NEWLINE> full_state_feedback . rtol = cur_rtol <NEWLINE> full_state_feedback . nb_iter = nb_iter <NEWLINE> <NEWLINE> return full_state_feedback <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def ones_like ( x , dtype = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> return array_ops . ones_like ( x , dtype = dtype , name = name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_creator ( self , creator ) : <NEWLINE> <TAB> <NEWLINE> self . creator = creator <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _call_input_fn ( self , input_fn , mode ) : <NEWLINE> <TAB> <NEWLINE> input_fn_args = function_utils . fn_args ( input_fn ) <NEWLINE> kwargs = { } <NEWLINE> if <STRING> in input_fn_args : <NEWLINE> <TAB> kwargs [ <STRING> ] = mode <NEWLINE> <UNTAB> if <STRING> in input_fn_args : <NEWLINE> <TAB> kwargs [ <STRING> ] = self . params <NEWLINE> <UNTAB> if <STRING> in input_fn_args : <NEWLINE> <TAB> kwargs [ <STRING> ] = self . config <NEWLINE> <UNTAB> with ops . device ( <STRING> ) : <NEWLINE> <TAB> return input_fn ( ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_level_values ( self , level ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . _validate_index_level ( level ) <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def transform_op_if_inside_handler ( info , op , keep_if_possible = True ) : <NEWLINE> <TAB> <NEWLINE> if op in info . sgv . ops : <NEWLINE> <TAB> return info . transformed_ops [ op ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if keep_if_possible and info . graph is info . graph_ : <NEWLINE> <TAB> return op <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def enable ( self , shrink = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> self . _enabled = shrink <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_ground_p ( f , c , u ) : <NEWLINE> <TAB> <NEWLINE> if c is not None and not c : <NEWLINE> <TAB> return dmp_zero_p ( f , u ) <NEWLINE> <NEWLINE> <UNTAB> while u : <NEWLINE> <TAB> if len ( f ) != <NUMBER> : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> f = f [ <NUMBER> ] <NEWLINE> u -= <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> if c is None : <NEWLINE> <TAB> return len ( f ) <= <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return f == [ c ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def typename ( char ) : <NEWLINE> <TAB> <NEWLINE> return _namefromtype [ char ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def from_bernstein_basis ( cls , bp , extrapolate = None ) : <NEWLINE> <TAB> <NEWLINE> dx = np . diff ( bp . x ) <NEWLINE> k = bp . c . shape [ <NUMBER> ] - <NUMBER> <NEWLINE> <NEWLINE> rest = ( None , ) * ( bp . c . ndim - <NUMBER> ) <NEWLINE> <NEWLINE> c = np . zeros_like ( bp . c ) <NEWLINE> for a in range ( k + <NUMBER> ) : <NEWLINE> <TAB> factor = ( - <NUMBER> ) ** a * comb ( k , a ) * bp . c [ a ] <NEWLINE> for s in range ( a , k + <NUMBER> ) : <NEWLINE> <TAB> val = comb ( k - a , s - a ) * ( - <NUMBER> ) ** s <NEWLINE> c [ k - s ] += factor * val / dx [ ( slice ( None ) , ) + rest ] ** s <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if extrapolate is None : <NEWLINE> <TAB> extrapolate = bp . extrapolate <NEWLINE> <NEWLINE> <UNTAB> return cls . construct_fast ( c , bp . x , extrapolate , bp . axis ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_proto ( self , export_scope = None ) : <NEWLINE> <TAB> <NEWLINE> if export_scope is None : <NEWLINE> <TAB> return self . saver_def <NEWLINE> <NEWLINE> <UNTAB> if not ( self . saver_def . filename_tensor_name . startswith ( export_scope ) and <NEWLINE> self . saver_def . save_tensor_name . startswith ( export_scope ) and <NEWLINE> self . saver_def . restore_op_name . startswith ( export_scope ) ) : <NEWLINE> <TAB> return None <NEWLINE> <NEWLINE> <UNTAB> saver_def = saver_pb2 . SaverDef ( ) <NEWLINE> saver_def . CopyFrom ( self . saver_def ) <NEWLINE> saver_def . filename_tensor_name = ops . strip_name_scope ( <NEWLINE> saver_def . filename_tensor_name , export_scope ) <NEWLINE> saver_def . save_tensor_name = ops . strip_name_scope ( <NEWLINE> saver_def . save_tensor_name , export_scope ) <NEWLINE> saver_def . restore_op_name = ops . strip_name_scope ( <NEWLINE> saver_def . restore_op_name , export_scope ) <NEWLINE> return saver_def <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _expr_big_minus ( cls , x , n ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rs_tanh ( p , x , prec ) : <NEWLINE> <TAB> <NEWLINE> if rs_is_puiseux ( p , x ) : <NEWLINE> <TAB> return rs_puiseux ( rs_tanh , p , x , prec ) <NEWLINE> <UNTAB> R = p . ring <NEWLINE> const = <NUMBER> <NEWLINE> if _has_constant_term ( p , x ) : <NEWLINE> <TAB> zm = R . zero_monom <NEWLINE> c = p [ zm ] <NEWLINE> if R . domain is EX : <NEWLINE> <TAB> c_expr = c . as_expr ( ) <NEWLINE> const = tanh ( c_expr ) <NEWLINE> <UNTAB> elif isinstance ( c , PolyElement ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> c_expr = c . as_expr ( ) <NEWLINE> const = R ( tanh ( c_expr ) ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> raise DomainError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> const = R ( tanh ( c ) ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> raise DomainError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> p1 = p - c <NEWLINE> t1 = rs_tanh ( p1 , x , prec ) <NEWLINE> t = rs_series_inversion ( <NUMBER> + const * t1 , x , prec ) <NEWLINE> return rs_mul ( const + t1 , t , x , prec ) <NEWLINE> <NEWLINE> <UNTAB> if R . ngens == <NUMBER> : <NEWLINE> <TAB> return _tanh ( p , x , prec ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return rs_fun ( p , _tanh , x , prec ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dup_sqf_list ( f , K , all = False ) : <NEWLINE> <TAB> <NEWLINE> if K . is_FiniteField : <NEWLINE> <TAB> return dup_gf_sqf_list ( f , K , all = all ) <NEWLINE> <NEWLINE> <UNTAB> if K . is_Field : <NEWLINE> <TAB> coeff = dup_LC ( f , K ) <NEWLINE> f = dup_monic ( f , K ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> coeff , f = dup_primitive ( f , K ) <NEWLINE> <NEWLINE> if K . is_negative ( dup_LC ( f , K ) ) : <NEWLINE> <TAB> f = dup_neg ( f , K ) <NEWLINE> coeff = - coeff <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if dup_degree ( f ) <= <NUMBER> : <NEWLINE> <TAB> return coeff , [ ] <NEWLINE> <NEWLINE> <UNTAB> result , i = [ ] , <NUMBER> <NEWLINE> <NEWLINE> h = dup_diff ( f , <NUMBER> , K ) <NEWLINE> g , p , q = dup_inner_gcd ( f , h , K ) <NEWLINE> <NEWLINE> while True : <NEWLINE> <TAB> d = dup_diff ( p , <NUMBER> , K ) <NEWLINE> h = dup_sub ( q , d , K ) <NEWLINE> <NEWLINE> if not h : <NEWLINE> <TAB> result . append ( ( p , i ) ) <NEWLINE> break <NEWLINE> <NEWLINE> <UNTAB> g , p , q = dup_inner_gcd ( p , h , K ) <NEWLINE> <NEWLINE> if all or dup_degree ( g ) > <NUMBER> : <NEWLINE> <TAB> result . append ( ( g , i ) ) <NEWLINE> <NEWLINE> <UNTAB> i += <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> return coeff , result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_tf ( self ) : <NEWLINE> <TAB> <NEWLINE> return TransferFunction ( * zpk2tf ( self . zeros , self . poles , self . gain ) , <NEWLINE> ** self . _dt_dict ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecation . deprecated ( None , <NEWLINE> <STRING> ) <NEWLINE> def sample_from_datasets ( datasets , weights = None , seed = None ) : <NEWLINE> <TAB> <NEWLINE> return interleave_ops . sample_from_datasets ( datasets , weights , seed ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def quantize_down_and_shrink_range ( input , input_min , input_max , out_type , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> out_type = _execute . make_type ( out_type , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , input_min = input_min , <NEWLINE> input_max = input_max , out_type = out_type , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result = _QuantizeDownAndShrinkRangeOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , <NEWLINE> input , input_min , input_max , <STRING> , out_type ) <NEWLINE> _result = _QuantizeDownAndShrinkRangeOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return quantize_down_and_shrink_range_eager_fallback ( <NEWLINE> input , input_min , input_max , out_type = out_type , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def capitalize ( self ) : <NEWLINE> <TAB> <NEWLINE> return asarray ( capitalize ( self ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def parse_command_line ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> toplevel_options = self . _get_toplevel_options ( ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . commands = [ ] <NEWLINE> parser = FancyGetopt ( toplevel_options + self . display_options ) <NEWLINE> parser . set_negative_aliases ( self . negative_opt ) <NEWLINE> parser . set_aliases ( { <STRING> : <STRING> } ) <NEWLINE> args = parser . getopt ( args = self . script_args , object = self ) <NEWLINE> option_order = parser . get_option_order ( ) <NEWLINE> log . set_verbosity ( self . verbose ) <NEWLINE> <NEWLINE> <NEWLINE> if self . handle_display_options ( option_order ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> while args : <NEWLINE> <TAB> args = self . _parse_command_opts ( parser , args ) <NEWLINE> if args is None : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if self . help : <NEWLINE> <TAB> self . _show_help ( parser , <NEWLINE> display_options = len ( self . commands ) == <NUMBER> , <NEWLINE> commands = self . commands ) <NEWLINE> return <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if not self . commands : <NEWLINE> <TAB> raise DistutilsArgError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _dist_broadcast_coalesced ( self , tensors , buffer_size ) : <NEWLINE> <TAB> <NEWLINE> for tensors in _take_tensors ( tensors , buffer_size ) : <NEWLINE> <TAB> flat_tensors = _flatten_dense_tensors ( tensors ) <NEWLINE> dist . broadcast ( flat_tensors , <NUMBER> ) <NEWLINE> for tensor , synced in zip ( tensors , <NEWLINE> _unflatten_dense_tensors ( flat_tensors , tensors ) ) : <NEWLINE> <TAB> tensor . copy_ ( synced ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def iterdir ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _closed : <NEWLINE> <TAB> self . _raise_closed ( ) <NEWLINE> <UNTAB> for name in self . _accessor . listdir ( self ) : <NEWLINE> <TAB> if name in { <STRING> , <STRING> } : <NEWLINE> <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> yield self . _make_child_relpath ( name ) <NEWLINE> if self . _closed : <NEWLINE> <TAB> self . _raise_closed ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_blocks ( self , copy = True ) : <NEWLINE> <TAB> <NEWLINE> warnings . warn ( <STRING> <NEWLINE> <STRING> , <NEWLINE> FutureWarning , stacklevel = <NUMBER> ) <NEWLINE> return self . _to_dict_of_blocks ( copy = copy ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ py_random_state ( <NUMBER> ) <NEWLINE> def greedy_branching ( G , attr = <STRING> , default = <NUMBER> , kind = <STRING> , seed = None ) : <NEWLINE> <TAB> <NEWLINE> if kind not in KINDS : <NEWLINE> <TAB> raise nx . NetworkXException ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if kind == <STRING> : <NEWLINE> <TAB> reverse = False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> reverse = True <NEWLINE> <NEWLINE> <UNTAB> if attr is None : <NEWLINE> <NEWLINE> <TAB> attr = random_string ( seed = seed ) <NEWLINE> <NEWLINE> <UNTAB> edges = [ ( u , v , data . get ( attr , default ) ) <NEWLINE> for ( u , v , data ) in G . edges ( data = True ) ] <NEWLINE> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> edges . sort ( key = itemgetter ( <NUMBER> , <NUMBER> , <NUMBER> ) , reverse = reverse ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> edges . sort ( key = itemgetter ( <NUMBER> ) , reverse = reverse ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> B = nx . DiGraph ( ) <NEWLINE> B . add_nodes_from ( G ) <NEWLINE> <NEWLINE> <NEWLINE> uf = nx . utils . UnionFind ( ) <NEWLINE> for i , ( u , v , w ) in enumerate ( edges ) : <NEWLINE> <TAB> if uf [ u ] == uf [ v ] : <NEWLINE> <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> elif B . in_degree ( v ) == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> data = { } <NEWLINE> if attr is not None : <NEWLINE> <TAB> data [ attr ] = w <NEWLINE> <UNTAB> B . add_edge ( u , v , ** data ) <NEWLINE> uf . union ( u , v ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return B <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def logn ( n , x ) : <NEWLINE> <TAB> <NEWLINE> x = _fix_real_lt_zero ( x ) <NEWLINE> n = _fix_real_lt_zero ( n ) <NEWLINE> return nx . log ( x ) / nx . log ( n ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def topk ( a , k , axis = - <NUMBER> , split_every = None ) : <NEWLINE> <TAB> <NEWLINE> axis = validate_axis ( axis , a . ndim ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> chunk_combine = partial ( chunk . topk , k = k ) <NEWLINE> <NEWLINE> <NEWLINE> aggregate = partial ( chunk . topk_aggregate , k = k ) <NEWLINE> <NEWLINE> return reduction ( <NEWLINE> a , chunk = chunk_combine , combine = chunk_combine , aggregate = aggregate , <NEWLINE> axis = axis , keepdims = True , dtype = a . dtype , split_every = split_every , <NEWLINE> output_size = abs ( k ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def printdir ( self , file = None ) : <NEWLINE> <TAB> <NEWLINE> print ( <STRING> % ( <STRING> , <STRING> , <STRING> ) , <NEWLINE> file = file ) <NEWLINE> for zinfo in self . filelist : <NEWLINE> <TAB> date = <STRING> % zinfo . date_time [ : <NUMBER> ] <NEWLINE> print ( <STRING> % ( zinfo . filename , date , zinfo . file_size ) , <NEWLINE> file = file ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def max ( self , numeric_only = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> self . check_for_ordered ( <STRING> ) <NEWLINE> if numeric_only : <NEWLINE> <TAB> good = self . _codes != - <NUMBER> <NEWLINE> pointer = self . _codes [ good ] . max ( ** kwargs ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pointer = self . _codes . max ( ** kwargs ) <NEWLINE> <UNTAB> if pointer == - <NUMBER> : <NEWLINE> <TAB> return np . nan <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . categories [ pointer ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def matrix ( name = None , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> if dtype is None : <NEWLINE> <TAB> dtype = config . floatX <NEWLINE> <UNTAB> type = TensorType ( dtype , ( False , False ) ) <NEWLINE> return type ( name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def compare_values ( self , x , y ) : <NEWLINE> <TAB> <NEWLINE> return self . impl . compare_values ( x , y ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def save ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . book . save ( self . path ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def find ( self , query , group = False ) : <NEWLINE> <TAB> <NEWLINE> query = _make_find_query ( query ) <NEWLINE> results = list ( filter ( query , preorder_traversal ( self ) ) ) <NEWLINE> <NEWLINE> if not group : <NEWLINE> <TAB> return set ( results ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> groups = { } <NEWLINE> <NEWLINE> for result in results : <NEWLINE> <TAB> if result in groups : <NEWLINE> <TAB> groups [ result ] += <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> groups [ result ] = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return groups <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_reduced ( G , ring ) : <NEWLINE> <TAB> <NEWLINE> order = ring . order <NEWLINE> domain = ring . domain <NEWLINE> <NEWLINE> G . sort ( key = lambda g : order ( g . LM ) ) <NEWLINE> <NEWLINE> for i , g in enumerate ( G ) : <NEWLINE> <TAB> if g . LC != domain . one : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> for term in g : <NEWLINE> <TAB> for h in G [ : i ] + G [ i + <NUMBER> : ] : <NEWLINE> <TAB> if monomial_divides ( h . LM , term [ <NUMBER> ] ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def parse ( self , argument ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( argument , list ) : <NEWLINE> <TAB> return argument <NEWLINE> <UNTAB> elif not argument : <NEWLINE> <TAB> return [ ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if self . _comma_compat : <NEWLINE> <TAB> argument = argument . replace ( <STRING> , <STRING> ) <NEWLINE> <UNTAB> return argument . split ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def quad_explain ( output = sys . stdout ) : <NEWLINE> <TAB> <NEWLINE> output . write ( quad . __doc__ ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _to_safe_for_reshape ( self ) : <NEWLINE> <TAB> <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_snap ( self , snap ) : <NEWLINE> <TAB> <NEWLINE> self . _snap = snap <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_sparse ( self , fill_value = None , kind = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> from pandas . core . sparse . frame import SparseDataFrame <NEWLINE> return SparseDataFrame ( self . _series , index = self . index , <NEWLINE> columns = self . columns , default_kind = kind , <NEWLINE> default_fill_value = fill_value ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def compress ( self , a , axis = None ) : <NEWLINE> <TAB> <NEWLINE> return theano . tensor . extra_ops . compress ( self , a , axis = axis ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def is_directory ( dirname ) : <NEWLINE> <TAB> <NEWLINE> status = c_api_util . ScopedTFStatus ( ) <NEWLINE> return pywrap_tensorflow . IsDirectory ( compat . as_bytes ( dirname ) , status ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ doctest_depends_on ( modules = ( <STRING> , ) ) <NEWLINE> def PygletPlot ( * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> import plot <NEWLINE> return plot . PygletPlot ( * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def randint ( self , a , b ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return self . randrange ( a , b + <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _toposort ( edges ) : <NEWLINE> <TAB> <NEWLINE> incoming_edges = reverse_dict ( edges ) <NEWLINE> incoming_edges = dict ( ( k , set ( val ) ) for k , val in incoming_edges . items ( ) ) <NEWLINE> S = set ( ( v for v in edges if v not in incoming_edges ) ) <NEWLINE> L = [ ] <NEWLINE> <NEWLINE> while S : <NEWLINE> <TAB> n = S . pop ( ) <NEWLINE> L . append ( n ) <NEWLINE> for m in edges . get ( n , ( ) ) : <NEWLINE> <TAB> assert n in incoming_edges [ m ] <NEWLINE> incoming_edges [ m ] . remove ( n ) <NEWLINE> if not incoming_edges [ m ] : <NEWLINE> <TAB> S . add ( m ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if any ( incoming_edges . get ( v , None ) for v in edges ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> return L <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _wrap_and_check_input_tensors ( tensors , field_name ) : <NEWLINE> <TAB> <NEWLINE> if tensors is None : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( field_name ) ) <NEWLINE> <UNTAB> if not isinstance ( tensors , dict ) : <NEWLINE> <TAB> tensors = { _SINGLE_TENSOR_DEFAULT_NAMES [ field_name ] : tensors } <NEWLINE> <UNTAB> for name , tensor in tensors . items ( ) : <NEWLINE> <TAB> _check_tensor_key ( name , error_label = field_name ) <NEWLINE> _check_tensor ( tensor , name , error_label = field_name ) <NEWLINE> <UNTAB> return tensors <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def apply ( self , func , axis = <STRING> , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if kwargs and not isinstance ( func , np . ufunc ) : <NEWLINE> <TAB> f = lambda x : func ( x , ** kwargs ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> f = func <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( axis , ( tuple , list ) ) and len ( axis ) == <NUMBER> : <NEWLINE> <TAB> return self . _apply_2d ( f , axis = axis ) <NEWLINE> <NEWLINE> <UNTAB> axis = self . _get_axis_number ( axis ) <NEWLINE> <NEWLINE> <NEWLINE> if isinstance ( f , np . ufunc ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> with np . errstate ( all = <STRING> ) : <NEWLINE> <TAB> result = np . apply_along_axis ( func , axis , self . values ) <NEWLINE> <UNTAB> return self . _wrap_result ( result , axis = axis ) <NEWLINE> <UNTAB> except ( AttributeError ) : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return self . _apply_1d ( f , axis = axis ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def read_eval_metrics ( eval_dir ) : <NEWLINE> <TAB> <NEWLINE> eval_metrics_dict = { } <NEWLINE> for event in _summaries ( eval_dir ) : <NEWLINE> <TAB> if not event . HasField ( <STRING> ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> metrics = { } <NEWLINE> for value in event . summary . value : <NEWLINE> <TAB> if value . HasField ( <STRING> ) : <NEWLINE> <TAB> metrics [ value . tag ] = value . simple_value <NEWLINE> <UNTAB> <UNTAB> if metrics : <NEWLINE> <TAB> eval_metrics_dict [ event . step ] = metrics <NEWLINE> <UNTAB> <UNTAB> return collections . OrderedDict ( <NEWLINE> sorted ( eval_metrics_dict . items ( ) , key = lambda t : t [ <NUMBER> ] ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def k_crust ( G , k = None , core_number = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> if core_number is None : <NEWLINE> <TAB> core_number = find_cores ( G ) <NEWLINE> <UNTAB> if k is None : <NEWLINE> <TAB> k = max ( core_number . values ( ) ) - <NUMBER> <NEWLINE> <UNTAB> nodes = ( v for v in core_number if core_number [ v ] <= k ) <NEWLINE> return G . subgraph ( nodes ) . copy ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_logdir ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . event_writer . get_logdir ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rs_cosh ( p , x , prec ) : <NEWLINE> <TAB> <NEWLINE> if rs_is_puiseux ( p , x ) : <NEWLINE> <TAB> return rs_puiseux ( rs_cosh , p , x , prec ) <NEWLINE> <UNTAB> t = rs_exp ( p , x , prec ) <NEWLINE> t1 = rs_series_inversion ( t , x , prec ) <NEWLINE> return ( t + t1 ) / <NUMBER> <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _inverse_binarize_multiclass ( y , classes ) : <NEWLINE> <TAB> <NEWLINE> classes = np . asarray ( classes ) <NEWLINE> <NEWLINE> if sp . issparse ( y ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> y = y . tocsr ( ) <NEWLINE> n_samples , n_outputs = y . shape <NEWLINE> outputs = np . arange ( n_outputs ) <NEWLINE> row_max = min_max_axis ( y , <NUMBER> ) [ <NUMBER> ] <NEWLINE> row_nnz = np . diff ( y . indptr ) <NEWLINE> <NEWLINE> y_data_repeated_max = np . repeat ( row_max , row_nnz ) <NEWLINE> <NEWLINE> y_i_all_argmax = np . flatnonzero ( y_data_repeated_max == y . data ) <NEWLINE> <NEWLINE> <NEWLINE> if row_max [ - <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> y_i_all_argmax = np . append ( y_i_all_argmax , [ len ( y . data ) ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> index_first_argmax = np . searchsorted ( y_i_all_argmax , y . indptr [ : - <NUMBER> ] ) <NEWLINE> <NEWLINE> y_ind_ext = np . append ( y . indices , [ <NUMBER> ] ) <NEWLINE> y_i_argmax = y_ind_ext [ y_i_all_argmax [ index_first_argmax ] ] <NEWLINE> <NEWLINE> y_i_argmax [ np . where ( row_nnz == <NUMBER> ) [ <NUMBER> ] ] = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> samples = np . arange ( n_samples ) [ ( row_nnz > <NUMBER> ) & <NEWLINE> ( row_max . ravel ( ) == <NUMBER> ) ] <NEWLINE> for i in samples : <NEWLINE> <TAB> ind = y . indices [ y . indptr [ i ] : y . indptr [ i + <NUMBER> ] ] <NEWLINE> y_i_argmax [ i ] = classes [ np . setdiff1d ( outputs , ind ) ] [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> return classes [ y_i_argmax ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return classes . take ( y . argmax ( axis = <NUMBER> ) , mode = <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def concat ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return self . operate ( concat_op , other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_indices ( self , names ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def get_converter ( s ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if isinstance ( s , ( Timestamp , datetime . datetime ) ) : <NEWLINE> <TAB> return lambda key : Timestamp ( key ) <NEWLINE> <UNTAB> elif isinstance ( s , np . datetime64 ) : <NEWLINE> <TAB> return lambda key : Timestamp ( key ) . asm8 <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return lambda key : key <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if len ( names ) == <NUMBER> : <NEWLINE> <TAB> return [ ] <NEWLINE> <NEWLINE> <UNTAB> if len ( self . indices ) > <NUMBER> : <NEWLINE> <TAB> index_sample = next ( iter ( self . indices ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> index_sample = None <NEWLINE> <NEWLINE> <UNTAB> name_sample = names [ <NUMBER> ] <NEWLINE> if isinstance ( index_sample , tuple ) : <NEWLINE> <TAB> if not isinstance ( name_sample , tuple ) : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> raise ValueError ( msg ) <NEWLINE> <UNTAB> if not len ( name_sample ) == len ( index_sample ) : <NEWLINE> <TAB> try : <NEWLINE> <NEWLINE> <TAB> return [ self . indices [ name ] for name in names ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> raise ValueError ( msg ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> converters = [ get_converter ( s ) for s in index_sample ] <NEWLINE> names = [ tuple ( f ( n ) for f , n in zip ( converters , name ) ) <NEWLINE> for name in names ] <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> converter = get_converter ( index_sample ) <NEWLINE> names = [ converter ( name ) for name in names ] <NEWLINE> <NEWLINE> <UNTAB> return [ self . indices . get ( name , [ ] ) for name in names ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ Substitution ( name = <STRING> ) <NEWLINE> def ngroup ( self , ascending = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> with _group_selection_context ( self ) : <NEWLINE> <TAB> index = self . _selected_obj . index <NEWLINE> result = Series ( self . grouper . group_info [ <NUMBER> ] , index ) <NEWLINE> if not ascending : <NEWLINE> <TAB> result = self . ngroups - <NUMBER> - result <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def is_mul ( var ) : <NEWLINE> <TAB> <NEWLINE> if var . owner and var . owner . op == tensor . mul : <NEWLINE> <TAB> return var . owner . inputs <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def angle_eager_fallback ( input , Tout = _dtypes . float32 , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> if Tout is None : <NEWLINE> <TAB> Tout = _dtypes . float32 <NEWLINE> <UNTAB> Tout = _execute . make_type ( Tout , <STRING> ) <NEWLINE> _attr_T , ( input , ) = _execute . args_to_matching_eager ( [ input ] , _ctx , _dtypes . complex64 ) <NEWLINE> _inputs_flat = [ input ] <NEWLINE> _attrs = ( <STRING> , _attr_T , <STRING> , Tout ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_weights ( self , weights ) : <NEWLINE> <TAB> <NEWLINE> params = self . weights <NEWLINE> if len ( params ) != len ( weights ) : <NEWLINE> <TAB> raise ValueError ( <STRING> + <NEWLINE> str ( len ( weights ) ) + <NEWLINE> <STRING> + <NEWLINE> <STRING> + str ( len ( params ) ) + <STRING> ) <NEWLINE> <UNTAB> weight_value_tuples = [ ] <NEWLINE> param_values = K . batch_get_value ( params ) <NEWLINE> for pv , p , w in zip ( param_values , params , weights ) : <NEWLINE> <TAB> if pv . shape != w . shape : <NEWLINE> <TAB> raise ValueError ( <STRING> + <NEWLINE> str ( pv . shape ) + <NEWLINE> <STRING> <NEWLINE> <STRING> + str ( w . shape ) ) <NEWLINE> <UNTAB> weight_value_tuples . append ( ( p , w ) ) <NEWLINE> <UNTAB> K . batch_set_value ( weight_value_tuples ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def Nt ( mu , sigma , limit = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return min ( max ( random . gauss ( mu , sigma ) , mu - limit * sigma ) , mu + limit * sigma ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def joined ( self , a , b ) : <NEWLINE> <TAB> <NEWLINE> self . clean ( ) <NEWLINE> return ( self . _mapping . get ( weakref . ref ( a ) , object ( ) ) <NEWLINE> is self . _mapping . get ( weakref . ref ( b ) ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def pop ( self ) : <NEWLINE> <TAB> <NEWLINE> it = iter ( self ) <NEWLINE> try : <NEWLINE> <TAB> value = next ( it ) <NEWLINE> <UNTAB> except StopIteration : <NEWLINE> <TAB> raise KeyError <NEWLINE> <UNTAB> self . discard ( value ) <NEWLINE> return value <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def hessian ( image , scale_range = ( <NUMBER> , <NUMBER> ) , scale_step = <NUMBER> , beta1 = <NUMBER> , beta2 = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> filtered , lambdas = _frangi_hessian_common_filter ( image , <NEWLINE> scale_range , scale_step , <NEWLINE> beta1 , beta2 ) <NEWLINE> filtered [ lambdas < <NUMBER> ] = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> out = np . max ( filtered , axis = <NUMBER> ) <NEWLINE> out [ out <= <NUMBER> ] = <NUMBER> <NEWLINE> return out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def predict ( self , X ) : <NEWLINE> <TAB> <NEWLINE> y = super ( OneClassSVM , self ) . predict ( X ) <NEWLINE> return np . asarray ( y , dtype = np . intp ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( <NEWLINE> <STRING> , <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> def get_default_binary_metrics_for_eval ( thresholds ) : <NEWLINE> <TAB> <NEWLINE> metrics = { } <NEWLINE> metrics [ _MetricKeys . PREDICTION_MEAN ] = _predictions_streaming_mean <NEWLINE> metrics [ _MetricKeys . TARGET_MEAN ] = _labels_streaming_mean <NEWLINE> <NEWLINE> <NEWLINE> metrics [ _MetricKeys . ACCURACY_BASELINE ] = _labels_streaming_mean <NEWLINE> <NEWLINE> metrics [ _MetricKeys . AUC ] = _streaming_auc <NEWLINE> <NEWLINE> for threshold in thresholds : <NEWLINE> <TAB> metrics [ _MetricKeys . ACCURACY_MEAN % <NEWLINE> threshold ] = _accuracy_at_threshold ( threshold ) <NEWLINE> <NEWLINE> metrics [ _MetricKeys . PRECISION_MEAN % threshold ] = _streaming_at_threshold ( <NEWLINE> metric_ops . streaming_precision_at_thresholds , threshold ) <NEWLINE> <NEWLINE> metrics [ _MetricKeys . RECALL_MEAN % threshold ] = _streaming_at_threshold ( <NEWLINE> metric_ops . streaming_recall_at_thresholds , threshold ) <NEWLINE> <NEWLINE> <UNTAB> return metrics <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _eigvalsh_to_eps ( spectrum , cond = None , rcond = None ) : <NEWLINE> <TAB> <NEWLINE> if rcond is not None : <NEWLINE> <TAB> cond = rcond <NEWLINE> <UNTAB> if cond in [ None , - <NUMBER> ] : <NEWLINE> <TAB> t = spectrum . dtype . char . lower ( ) <NEWLINE> factor = { <STRING> : <NUMBER> , <STRING> : <NUMBER> } <NEWLINE> cond = factor [ t ] * np . finfo ( t ) . eps <NEWLINE> <UNTAB> eps = cond * np . max ( abs ( spectrum ) ) <NEWLINE> return eps <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def calculate_dendrogram ( self ) : <NEWLINE> <TAB> <NEWLINE> return hierarchy . dendrogram ( self . linkage , no_plot = True , <NEWLINE> color_threshold = - np . inf ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def _get_sharding_func ( size , num_shards ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def func ( ids ) : <NEWLINE> <TAB> if num_shards == <NUMBER> : <NEWLINE> <TAB> return None , ids <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ids_per_shard = size // num_shards <NEWLINE> extras = size % num_shards <NEWLINE> assignments = math_ops . maximum ( ids // ( ids_per_shard + <NUMBER> ) , <NEWLINE> ( ids - extras ) // ids_per_shard ) <NEWLINE> new_ids = array_ops . where ( assignments < extras , <NEWLINE> ids % ( ids_per_shard + <NUMBER> ) , <NEWLINE> ( ids - extras ) % ids_per_shard ) <NEWLINE> return assignments , new_ids <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return func <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pointbiserialr ( x , y ) : <NEWLINE> <TAB> <NEWLINE> rpb , prob = pearsonr ( x , y ) <NEWLINE> return PointbiserialrResult ( rpb , prob ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ _replace_by ( <STRING> ) <NEWLINE> def unpack_ints ( data , dtype , itemsize , runlen = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if itemsize == <NUMBER> : <NEWLINE> <TAB> data = numpy . fromstring ( data , <STRING> ) <NEWLINE> data = numpy . unpackbits ( data ) <NEWLINE> if runlen % <NUMBER> : <NEWLINE> <TAB> data = data . reshape ( - <NUMBER> , runlen + ( <NUMBER> - runlen % <NUMBER> ) ) <NEWLINE> data = data [ : , : runlen ] . reshape ( - <NUMBER> ) <NEWLINE> <UNTAB> return data . astype ( dtype ) <NEWLINE> <NEWLINE> <UNTAB> dtype = numpy . dtype ( dtype ) <NEWLINE> if itemsize in ( <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> return numpy . fromstring ( data , dtype ) <NEWLINE> <UNTAB> if itemsize < <NUMBER> or itemsize > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % itemsize ) <NEWLINE> <UNTAB> if dtype . kind not in <STRING> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> itembytes = next ( i for i in ( <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ) if <NUMBER> * i >= itemsize ) <NEWLINE> if itembytes != dtype . itemsize : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if runlen == <NUMBER> : <NEWLINE> <TAB> runlen = len ( data ) // itembytes <NEWLINE> <UNTAB> skipbits = runlen * itemsize % <NUMBER> <NEWLINE> if skipbits : <NEWLINE> <TAB> skipbits = <NUMBER> - skipbits <NEWLINE> <UNTAB> shrbits = itembytes * <NUMBER> - itemsize <NEWLINE> bitmask = int ( itemsize * <STRING> + <STRING> * shrbits , <NUMBER> ) <NEWLINE> dtypestr = <STRING> + dtype . char <NEWLINE> <NEWLINE> unpack = struct . unpack <NEWLINE> l = runlen * ( len ( data ) * <NUMBER> // ( runlen * itemsize + skipbits ) ) <NEWLINE> result = numpy . empty ( ( l , ) , dtype ) <NEWLINE> bitcount = <NUMBER> <NEWLINE> for i in range ( len ( result ) ) : <NEWLINE> <TAB> start = bitcount // <NUMBER> <NEWLINE> s = data [ start : start + itembytes ] <NEWLINE> try : <NEWLINE> <TAB> code = unpack ( dtypestr , s ) [ <NUMBER> ] <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> code = unpack ( dtypestr , s + <STRING> * ( itembytes - len ( s ) ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> code <<= bitcount % <NUMBER> <NEWLINE> code &= bitmask <NEWLINE> result [ i ] = code >> shrbits <NEWLINE> bitcount += itemsize <NEWLINE> if ( i + <NUMBER> ) % runlen == <NUMBER> : <NEWLINE> <TAB> bitcount += skipbits <NEWLINE> <UNTAB> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def fractional_max_pool_grad_eager_fallback ( orig_input , orig_output , out_backprop , row_pooling_sequence , col_pooling_sequence , overlapping = False , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> if overlapping is None : <NEWLINE> <TAB> overlapping = False <NEWLINE> <UNTAB> overlapping = _execute . make_bool ( overlapping , <STRING> ) <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ orig_input , orig_output , out_backprop ] , _ctx ) <NEWLINE> ( orig_input , orig_output , out_backprop ) = _inputs_T <NEWLINE> row_pooling_sequence = _ops . convert_to_tensor ( row_pooling_sequence , _dtypes . int64 ) <NEWLINE> col_pooling_sequence = _ops . convert_to_tensor ( col_pooling_sequence , _dtypes . int64 ) <NEWLINE> _inputs_flat = [ orig_input , orig_output , out_backprop , row_pooling_sequence , col_pooling_sequence ] <NEWLINE> _attrs = ( <STRING> , overlapping , <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def primal_and_adjoint_for_tracing ( self , node ) : <NEWLINE> <TAB> <NEWLINE> primal_template = grads . primals [ tracing . Traceable ] <NEWLINE> adjoint_template = grads . adjoints [ tracing . Traceable ] <NEWLINE> <NEWLINE> <NEWLINE> to_pack = node . args <NEWLINE> target = ast_ . copy_node ( self . orig_target ) <NEWLINE> vjp = quoting . quote ( self . namer . unique ( <STRING> % node . func . id ) ) <NEWLINE> tmp = create . create_temp ( quoting . quote ( <STRING> ) , self . namer ) <NEWLINE> assert len ( node . keywords ) == <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> primal = template . replace ( <NEWLINE> primal_template , <NEWLINE> namer = self . namer , <NEWLINE> result = target , <NEWLINE> fn = node . func , <NEWLINE> tmp = tmp , <NEWLINE> vjp = vjp , <NEWLINE> args = gast . Tuple ( elts = to_pack , ctx = gast . Load ( ) ) ) <NEWLINE> <NEWLINE> <NEWLINE> dto_pack = gast . Tuple ( <NEWLINE> elts = [ create . create_temp_grad ( arg , self . namer ) for arg in to_pack ] , <NEWLINE> ctx = gast . Store ( ) ) <NEWLINE> <NEWLINE> adjoint = template . replace ( <NEWLINE> adjoint_template , <NEWLINE> namer = self . namer , <NEWLINE> result = target , <NEWLINE> vjp = vjp , <NEWLINE> dargs = dto_pack ) <NEWLINE> <NEWLINE> return primal , adjoint <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_label_or_level_values ( self , key , axis = <NUMBER> , stacklevel = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> axis = self . _get_axis_number ( axis ) <NEWLINE> other_axes = [ ax for ax in range ( self . _AXIS_LEN ) if ax != axis ] <NEWLINE> <NEWLINE> if self . ndim > <NUMBER> : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> <NEWLINE> . format ( type = type ( self ) ) ) <NEWLINE> <NEWLINE> <UNTAB> if self . _is_label_reference ( key , axis = axis ) : <NEWLINE> <TAB> self . _check_label_or_level_ambiguity ( key , axis = axis , <NEWLINE> stacklevel = stacklevel + <NUMBER> ) <NEWLINE> values = self . xs ( key , axis = other_axes [ <NUMBER> ] ) . _values <NEWLINE> <UNTAB> elif self . _is_level_reference ( key , axis = axis ) : <NEWLINE> <TAB> values = self . axes [ axis ] . get_level_values ( key ) . _values <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise KeyError ( key ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if values . ndim > <NUMBER> : <NEWLINE> <NEWLINE> <TAB> if other_axes and isinstance ( <NEWLINE> self . _get_axis ( other_axes [ <NUMBER> ] ) , MultiIndex ) : <NEWLINE> <TAB> multi_message = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> multi_message = <STRING> <NEWLINE> <NEWLINE> <UNTAB> label_axis_name = <STRING> if axis == <NUMBER> else <STRING> <NEWLINE> raise ValueError ( ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> . format ( key = key , <NEWLINE> label_axis_name = label_axis_name , <NEWLINE> multi_message = multi_message ) ) <NEWLINE> <NEWLINE> <UNTAB> return values <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def adaptive_max_pool2d ( input , output_size , return_indices = False ) : <NEWLINE> <TAB> <NEWLINE> output_size = _list_with_default ( output_size , input . size ( ) ) <NEWLINE> ret = torch . _C . _nn . adaptive_max_pool2d ( input , output_size ) <NEWLINE> return ret if return_indices else ret [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def flatten ( a ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( a , ( tuple , list , set ) ) : <NEWLINE> <TAB> l = [ ] <NEWLINE> for item in a : <NEWLINE> <TAB> l . extend ( flatten ( item ) ) <NEWLINE> <UNTAB> return l <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return [ a ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def DupFd ( fd ) : <NEWLINE> <TAB> <NEWLINE> popen_obj = get_spawning_popen ( ) <NEWLINE> if popen_obj is not None : <NEWLINE> <TAB> return popen_obj . DupFd ( popen_obj . duplicate_for_child ( fd ) ) <NEWLINE> <UNTAB> elif HAVE_SEND_HANDLE and sys . version_info [ : <NUMBER> ] > ( <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> from multiprocessing import resource_sharer <NEWLINE> return resource_sharer . DupFd ( fd ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_ZZ_python ( K1 , a , K0 ) : <NEWLINE> <TAB> <NEWLINE> return PythonRational ( a ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def masked_less ( x , value , copy = True ) : <NEWLINE> <TAB> <NEWLINE> return masked_where ( less ( x , value ) , x , copy = copy ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_cpu ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> array = self . array <NEWLINE> if array is None : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( array , cuda . ndarray ) : <NEWLINE> <NEWLINE> <TAB> self . _data = [ cuda . to_cpu ( array ) ] <NEWLINE> <UNTAB> elif isinstance ( array , intel64 . mdarray ) : <NEWLINE> <NEWLINE> <TAB> self . _data = [ numpy . array ( array ) ] <NEWLINE> <NEWLINE> <UNTAB> if self . _grad_var is not None : <NEWLINE> <TAB> self . _grad_var . to_cpu ( ) <NEWLINE> <NEWLINE> <UNTAB> node = self . _node <NEWLINE> if node . _data is not None : <NEWLINE> <TAB> node . retain_data ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def list_items ( self ) : <NEWLINE> <TAB> <NEWLINE> return list ( self . _items_to_handlers . keys ( ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_fill_indexer_searchsorted ( self , target , method , limit = None ) : <NEWLINE> <TAB> <NEWLINE> if limit is not None : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % method ) <NEWLINE> <NEWLINE> <UNTAB> side = <STRING> if method == <STRING> else <STRING> <NEWLINE> <NEWLINE> <NEWLINE> indexer = self . get_indexer ( target ) <NEWLINE> nonexact = ( indexer == - <NUMBER> ) <NEWLINE> indexer [ nonexact ] = self . _searchsorted_monotonic ( target [ nonexact ] , <NEWLINE> side ) <NEWLINE> if side == <STRING> : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> indexer [ nonexact ] -= <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> indexer [ indexer == len ( self ) ] = - <NUMBER> <NEWLINE> <UNTAB> return indexer <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_linelength ( self , linelength ) : <NEWLINE> <TAB> <NEWLINE> if linelength == self . get_linelength ( ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> lineoffset = self . get_lineoffset ( ) <NEWLINE> segments = self . get_segments ( ) <NEWLINE> pos = <NUMBER> if self . is_horizontal ( ) else <NUMBER> <NEWLINE> for segment in segments : <NEWLINE> <TAB> segment [ <NUMBER> , pos ] = lineoffset + linelength / <NUMBER> <NEWLINE> segment [ <NUMBER> , pos ] = lineoffset - linelength / <NUMBER> <NEWLINE> <UNTAB> self . set_segments ( segments ) <NEWLINE> self . _linelength = linelength <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_poly ( self , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> from sympy . polys import Poly , PolynomialError <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> poly = Poly ( self , * gens , ** args ) <NEWLINE> <NEWLINE> if not poly . is_Poly : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return poly <NEWLINE> <UNTAB> <UNTAB> except PolynomialError : <NEWLINE> <TAB> return None <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def make_variable ( self , name = None ) : <NEWLINE> <TAB> <NEWLINE> return self . Variable ( self , name = name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def execute ( self , fn , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> name = kwargs . pop ( <STRING> , None ) <NEWLINE> exclusive_resource_access = kwargs . pop ( <STRING> , True ) <NEWLINE> <NEWLINE> with ops . name_scope ( name , <STRING> , [ ] ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> lock = gen_resource_variable_ops . mutex_lock ( self . _handle ) <NEWLINE> <NEWLINE> if not context . executing_eagerly ( ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> with ops . get_default_graph ( ) . _lock : <NEWLINE> <TAB> existing_ops = ops . get_default_graph ( ) . get_operations ( ) <NEWLINE> with ops . control_dependencies ( [ lock ] ) : <NEWLINE> <TAB> r = fn ( * args , ** kwargs ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> created_ops = ( set ( ops . get_default_graph ( ) . get_operations ( ) ) <NEWLINE> . difference ( existing_ops ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> with ops . control_dependencies ( [ lock ] ) : <NEWLINE> <TAB> r = fn ( * args , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not context . executing_eagerly ( ) : <NEWLINE> <TAB> self . _add_control_dependencies_to_lock ( created_ops , lock . op ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> captured_resources = set ( [ <NEWLINE> input_ for op in created_ops <NEWLINE> for input_ in op . inputs <NEWLINE> if input_ . dtype == dtypes . resource <NEWLINE> ] ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if any ( self . _is_self_handle ( x ) for x in captured_resources ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> self . _check_multiple_access_to_resources ( <NEWLINE> captured_resources , exclusive_resource_access ) <NEWLINE> <NEWLINE> <UNTAB> r_flat = [ _identity ( x ) for x in nest . flatten ( r ) ] <NEWLINE> <NEWLINE> with ops . control_dependencies ( r_flat ) : <NEWLINE> <NEWLINE> <TAB> with ops . colocate_with ( self . _handle ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> ensure_lock_exists = gen_resource_variable_ops . consume_mutex_lock ( <NEWLINE> lock ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> r = nest . pack_sequence_as ( r , control_flow_ops . tuple ( nest . flatten ( r ) ) ) <NEWLINE> <NEWLINE> <UNTAB> with ops . control_dependencies ( [ ensure_lock_exists ] ) : <NEWLINE> <TAB> outputs = nest . map_structure ( _identity , r ) <NEWLINE> <NEWLINE> <UNTAB> if not context . executing_eagerly ( ) : <NEWLINE> <TAB> signature = _ExecutionSignature ( <NEWLINE> op = lock . op , <NEWLINE> handle = self . _handle , <NEWLINE> resources = list ( captured_resources ) , <NEWLINE> exclusive_resource_access = exclusive_resource_access ) <NEWLINE> ops . add_to_collections ( <NEWLINE> CRITICAL_SECTION_EXECUTIONS , signature ) <NEWLINE> <NEWLINE> <UNTAB> return outputs <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def copy ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . new ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def islower ( a ) : <NEWLINE> <TAB> <NEWLINE> return _vec_string ( a , bool_ , <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rectangle ( start , end = None , extent = None , shape = None ) : <NEWLINE> <TAB> <NEWLINE> if extent is not None : <NEWLINE> <TAB> end = np . array ( start ) + np . array ( extent ) <NEWLINE> <UNTAB> elif end is None : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> tl = np . minimum ( start , end ) <NEWLINE> br = np . maximum ( start , end ) <NEWLINE> if extent is None : <NEWLINE> <TAB> br += <NUMBER> <NEWLINE> <UNTAB> if shape is not None : <NEWLINE> <TAB> br = np . minimum ( shape , br ) <NEWLINE> tl = np . maximum ( np . zeros_like ( shape ) , tl ) <NEWLINE> <UNTAB> coords = np . meshgrid ( * [ np . arange ( st , en ) for st , en in zip ( tuple ( tl ) , <NEWLINE> tuple ( br ) ) ] ) <NEWLINE> return coords <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def hermite ( n , monic = False ) : <NEWLINE> <TAB> <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if n == <NUMBER> : <NEWLINE> <TAB> n1 = n + <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> n1 = n <NEWLINE> <UNTAB> x , w , mu0 = roots_hermite ( n1 , mu = True ) <NEWLINE> wfunc = lambda x : exp ( - x * x ) <NEWLINE> if n == <NUMBER> : <NEWLINE> <TAB> x , w = [ ] , [ ] <NEWLINE> <UNTAB> hn = <NUMBER> ** n * _gam ( n + <NUMBER> ) * sqrt ( pi ) <NEWLINE> kn = <NUMBER> ** n <NEWLINE> p = orthopoly1d ( x , w , hn , kn , wfunc , ( - inf , inf ) , monic , <NEWLINE> lambda x : eval_hermite ( n , x ) ) <NEWLINE> return p <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_locs ( self , locs ) : <NEWLINE> <TAB> <NEWLINE> self . locs = locs <NEWLINE> if len ( self . locs ) > <NUMBER> : <NEWLINE> <TAB> vmin , vmax = self . axis . get_view_interval ( ) <NEWLINE> d = abs ( vmax - vmin ) <NEWLINE> if self . _useOffset : <NEWLINE> <TAB> self . _compute_offset ( ) <NEWLINE> <UNTAB> self . _set_orderOfMagnitude ( d ) <NEWLINE> self . _set_format ( vmin , vmax ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _sparse_blockify ( tuples , dtype = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> new_blocks = [ ] <NEWLINE> for i , names , array in tuples : <NEWLINE> <TAB> array = _maybe_to_sparse ( array ) <NEWLINE> block = make_block ( array , klass = SparseBlock , placement = [ i ] ) <NEWLINE> new_blocks . append ( block ) <NEWLINE> <NEWLINE> <UNTAB> return new_blocks <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _onmove ( self , event ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if self . _active_handle_idx >= <NUMBER> : <NEWLINE> <TAB> idx = self . _active_handle_idx <NEWLINE> self . _xs [ idx ] , self . _ys [ idx ] = event . xdata , event . ydata <NEWLINE> <NEWLINE> <NEWLINE> if idx == <NUMBER> and self . _polygon_completed : <NEWLINE> <TAB> self . _xs [ - <NUMBER> ] , self . _ys [ - <NUMBER> ] = event . xdata , event . ydata <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif <STRING> in self . state and self . eventpress : <NEWLINE> <TAB> dx = event . xdata - self . eventpress . xdata <NEWLINE> dy = event . ydata - self . eventpress . ydata <NEWLINE> for k in range ( len ( self . _xs ) ) : <NEWLINE> <TAB> self . _xs [ k ] = self . _xs_at_press [ k ] + dx <NEWLINE> self . _ys [ k ] = self . _ys_at_press [ k ] + dy <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif ( self . _polygon_completed <NEWLINE> or <STRING> in self . state or <STRING> in self . state ) : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> x0 , y0 = self . line . get_transform ( ) . transform ( ( self . _xs [ <NUMBER> ] , <NEWLINE> self . _ys [ <NUMBER> ] ) ) <NEWLINE> v0_dist = np . sqrt ( ( x0 - event . x ) ** <NUMBER> + ( y0 - event . y ) ** <NUMBER> ) <NEWLINE> <NEWLINE> if len ( self . _xs ) > <NUMBER> and v0_dist < self . vertex_select_radius : <NEWLINE> <TAB> self . _xs [ - <NUMBER> ] , self . _ys [ - <NUMBER> ] = self . _xs [ <NUMBER> ] , self . _ys [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _xs [ - <NUMBER> ] , self . _ys [ - <NUMBER> ] = event . xdata , event . ydata <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . _draw_polygon ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def assert_raise_message ( exceptions , message , function , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> function ( * args , ** kwargs ) <NEWLINE> <UNTAB> except exceptions as e : <NEWLINE> <TAB> error_message = str ( e ) <NEWLINE> if message not in error_message : <NEWLINE> <TAB> raise AssertionError ( <STRING> <NEWLINE> <STRING> % <NEWLINE> ( message , error_message ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> if isinstance ( exceptions , tuple ) : <NEWLINE> <TAB> names = <STRING> . join ( e . __name__ for e in exceptions ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> names = exceptions . __name__ <NEWLINE> <NEWLINE> <UNTAB> raise AssertionError ( <STRING> % <NEWLINE> ( names , function . __name__ ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_period ( self , freq = None , copy = True ) : <NEWLINE> <TAB> <NEWLINE> new_values = self . _values <NEWLINE> if copy : <NEWLINE> <TAB> new_values = new_values . copy ( ) <NEWLINE> <NEWLINE> <UNTAB> new_index = self . index . to_period ( freq = freq ) <NEWLINE> return self . _constructor ( new_values , <NEWLINE> index = new_index ) . __finalize__ ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def collide_rect ( left , right ) : <NEWLINE> <TAB> <NEWLINE> return left . rect . colliderect ( right . rect ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def twiny ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> ax2 = self . _make_twin_axes ( sharey = self ) <NEWLINE> ax2 . xaxis . tick_top ( ) <NEWLINE> ax2 . xaxis . set_label_position ( <STRING> ) <NEWLINE> ax2 . set_autoscaley_on ( self . get_autoscaley_on ( ) ) <NEWLINE> self . xaxis . tick_bottom ( ) <NEWLINE> ax2 . yaxis . set_visible ( False ) <NEWLINE> ax2 . patch . set_visible ( False ) <NEWLINE> return ax2 <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def svd_compressed ( a , k , n_power_iter = <NUMBER> , seed = None ) : <NEWLINE> <TAB> <NEWLINE> comp = compression_matrix ( a , k , n_power_iter = n_power_iter , seed = seed ) <NEWLINE> a_compressed = comp . dot ( a ) <NEWLINE> v , s , u = tsqr ( a_compressed . T , compute_svd = True ) <NEWLINE> u = comp . T . dot ( u ) <NEWLINE> v = v . T <NEWLINE> u = u [ : , : k ] <NEWLINE> s = s [ : k ] <NEWLINE> v = v [ : k , : ] <NEWLINE> return u , s , v <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def from_dict ( cls , rep , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> opt = options . build_options ( gens , args ) <NEWLINE> return cls . _from_dict ( rep , opt ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def stargan_loss ( <NEWLINE> model , <NEWLINE> generator_loss_fn = tfgan_losses . stargan_generator_loss_wrapper ( <NEWLINE> tfgan_losses_impl . wasserstein_generator_loss ) , <NEWLINE> discriminator_loss_fn = tfgan_losses . stargan_discriminator_loss_wrapper ( <NEWLINE> tfgan_losses_impl . wasserstein_discriminator_loss ) , <NEWLINE> gradient_penalty_weight = <NUMBER> , <NEWLINE> gradient_penalty_epsilon = <NUMBER> , <NEWLINE> gradient_penalty_target = <NUMBER> , <NEWLINE> gradient_penalty_one_sided = False , <NEWLINE> reconstruction_loss_fn = losses . absolute_difference , <NEWLINE> reconstruction_loss_weight = <NUMBER> , <NEWLINE> classification_loss_fn = losses . softmax_cross_entropy , <NEWLINE> classification_loss_weight = <NUMBER> , <NEWLINE> classification_one_hot = True , <NEWLINE> add_summaries = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def _classification_loss_helper ( true_labels , predict_logits , scope_name ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> with ops . name_scope ( scope_name , values = ( true_labels , predict_logits ) ) : <NEWLINE> <NEWLINE> <TAB> loss = classification_loss_fn ( <NEWLINE> onehot_labels = true_labels , logits = predict_logits ) <NEWLINE> <NEWLINE> if not classification_one_hot : <NEWLINE> <TAB> loss = math_ops . reduce_sum ( loss , axis = <NUMBER> ) <NEWLINE> <UNTAB> loss = math_ops . reduce_mean ( loss ) <NEWLINE> <NEWLINE> if add_summaries : <NEWLINE> <TAB> summary . scalar ( scope_name , loss ) <NEWLINE> <NEWLINE> <UNTAB> return loss <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> model . input_data_domain_label . shape . assert_has_rank ( <NUMBER> ) <NEWLINE> model . input_data_domain_label . shape [ <NUMBER> : ] . assert_is_fully_defined ( ) <NEWLINE> <NEWLINE> <NEWLINE> generator_loss = generator_loss_fn ( model , add_summaries = add_summaries ) <NEWLINE> discriminator_loss = discriminator_loss_fn ( model , add_summaries = add_summaries ) <NEWLINE> <NEWLINE> <NEWLINE> if _use_aux_loss ( gradient_penalty_weight ) : <NEWLINE> <TAB> gradient_penalty_fn = tfgan_losses . stargan_gradient_penalty_wrapper ( <NEWLINE> tfgan_losses_impl . wasserstein_gradient_penalty ) <NEWLINE> discriminator_loss += gradient_penalty_fn ( <NEWLINE> model , <NEWLINE> epsilon = gradient_penalty_epsilon , <NEWLINE> target = gradient_penalty_target , <NEWLINE> one_sided = gradient_penalty_one_sided , <NEWLINE> add_summaries = add_summaries ) * gradient_penalty_weight <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> reconstruction_loss = reconstruction_loss_fn ( model . input_data , <NEWLINE> model . reconstructed_data ) <NEWLINE> generator_loss += reconstruction_loss * reconstruction_loss_weight <NEWLINE> if add_summaries : <NEWLINE> <TAB> summary . scalar ( <STRING> , reconstruction_loss ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> generator_loss += _classification_loss_helper ( <NEWLINE> true_labels = model . generated_data_domain_target , <NEWLINE> predict_logits = model . discriminator_generated_data_domain_predication , <NEWLINE> scope_name = <STRING> ) * classification_loss_weight <NEWLINE> discriminator_loss += _classification_loss_helper ( <NEWLINE> true_labels = model . input_data_domain_label , <NEWLINE> predict_logits = model . discriminator_input_data_domain_predication , <NEWLINE> scope_name = <STRING> <NEWLINE> ) * classification_loss_weight <NEWLINE> <NEWLINE> return namedtuples . GANLoss ( generator_loss , discriminator_loss ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def zeta ( x , q , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , x = x , q = q , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , x , q ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return zeta_eager_fallback ( <NEWLINE> x , q , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecation . deprecated ( None , <NEWLINE> <STRING> ) <NEWLINE> def prefetch_to_device ( device , buffer_size = None ) : <NEWLINE> <TAB> <NEWLINE> return prefetching_ops . prefetch_to_device ( device , buffer_size ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def from_QQ_python ( K1 , a , K0 = None ) : <NEWLINE> <TAB> <NEWLINE> if a . denominator == <NUMBER> : <NEWLINE> <TAB> return K1 . from_ZZ_python ( a . numerator ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pad_reuse ( array , pad_width , mode , * args ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if mode in [ <STRING> , <STRING> ] and <STRING> in args : <NEWLINE> <TAB> raise NotImplementedError ( <NEWLINE> <STRING> <NEWLINE> ) <NEWLINE> <NEWLINE> <UNTAB> result = np . empty ( array . ndim * ( <NUMBER> , ) , dtype = object ) <NEWLINE> for idx in np . ndindex ( result . shape ) : <NEWLINE> <TAB> select = [ ] <NEWLINE> orient = [ ] <NEWLINE> for i , s , pw in zip ( idx , array . shape , pad_width ) : <NEWLINE> <TAB> if mode == <STRING> : <NEWLINE> <TAB> pw = pw [ : : - <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> if i < <NUMBER> : <NEWLINE> <TAB> if mode == <STRING> : <NEWLINE> <TAB> select . append ( slice ( <NUMBER> , pw [ <NUMBER> ] + <NUMBER> , None ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> select . append ( slice ( None , pw [ <NUMBER> ] , None ) ) <NEWLINE> <UNTAB> <UNTAB> elif i > <NUMBER> : <NEWLINE> <TAB> if mode == <STRING> : <NEWLINE> <TAB> select . append ( slice ( s - pw [ <NUMBER> ] - <NUMBER> , s - <NUMBER> , None ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> select . append ( slice ( s - pw [ <NUMBER> ] , None , None ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> select . append ( slice ( None ) ) <NEWLINE> <NEWLINE> <UNTAB> if i != <NUMBER> and mode in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> orient . append ( slice ( None , None , - <NUMBER> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> orient . append ( slice ( None ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> select = tuple ( select ) <NEWLINE> orient = tuple ( orient ) <NEWLINE> <NEWLINE> if mode == <STRING> : <NEWLINE> <TAB> idx = tuple ( <NUMBER> - i for i in idx ) <NEWLINE> <NEWLINE> <UNTAB> result [ idx ] = array [ select ] [ orient ] <NEWLINE> <NEWLINE> <UNTAB> result = block ( result . tolist ( ) ) <NEWLINE> <NEWLINE> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def chebder ( c , m = <NUMBER> , scl = <NUMBER> , axis = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> c = np . array ( c , ndmin = <NUMBER> , copy = <NUMBER> ) <NEWLINE> if c . dtype . char in <STRING> : <NEWLINE> <TAB> c = c . astype ( np . double ) <NEWLINE> <UNTAB> cnt , iaxis = [ int ( t ) for t in [ m , axis ] ] <NEWLINE> <NEWLINE> if cnt != m : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if cnt < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if iaxis != axis : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> iaxis = normalize_axis_index ( iaxis , c . ndim ) <NEWLINE> <NEWLINE> if cnt == <NUMBER> : <NEWLINE> <TAB> return c <NEWLINE> <NEWLINE> <UNTAB> c = np . moveaxis ( c , iaxis , <NUMBER> ) <NEWLINE> n = len ( c ) <NEWLINE> if cnt >= n : <NEWLINE> <TAB> c = c [ : <NUMBER> ] * <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> for i in range ( cnt ) : <NEWLINE> <TAB> n = n - <NUMBER> <NEWLINE> c *= scl <NEWLINE> der = np . empty ( ( n , ) + c . shape [ <NUMBER> : ] , dtype = c . dtype ) <NEWLINE> for j in range ( n , <NUMBER> , - <NUMBER> ) : <NEWLINE> <TAB> der [ j - <NUMBER> ] = ( <NUMBER> * j ) * c [ j ] <NEWLINE> c [ j - <NUMBER> ] += ( j * c [ j ] ) / ( j - <NUMBER> ) <NEWLINE> <UNTAB> if n > <NUMBER> : <NEWLINE> <TAB> der [ <NUMBER> ] = <NUMBER> * c [ <NUMBER> ] <NEWLINE> <UNTAB> der [ <NUMBER> ] = c [ <NUMBER> ] <NEWLINE> c = der <NEWLINE> <UNTAB> <UNTAB> c = np . moveaxis ( c , <NUMBER> , iaxis ) <NEWLINE> return c <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_anti_symmetric ( self , simplify = True ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> simpfunc = simplify <NEWLINE> if not isinstance ( simplify , FunctionType ) : <NEWLINE> <TAB> simpfunc = _simplify if simplify else lambda x : x <NEWLINE> <NEWLINE> <UNTAB> if not self . is_square : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> return self . _eval_is_anti_symmetric ( simpfunc ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def xw_plus_b ( x , weights , biases , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ x , weights , biases ] ) as name : <NEWLINE> <TAB> x = ops . convert_to_tensor ( x , name = <STRING> ) <NEWLINE> weights = ops . convert_to_tensor ( weights , name = <STRING> ) <NEWLINE> biases = ops . convert_to_tensor ( biases , name = <STRING> ) <NEWLINE> mm = math_ops . matmul ( x , weights ) <NEWLINE> return bias_add ( mm , biases , name = name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def from_session ( cls , sess , input_tensors , output_tensors ) : <NEWLINE> <TAB> <NEWLINE> graph_def = _freeze_graph ( sess , output_tensors ) <NEWLINE> return cls ( graph_def , input_tensors , output_tensors ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def predict_xy ( self , t , params = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if params is None : <NEWLINE> <TAB> params = self . params <NEWLINE> <NEWLINE> <UNTAB> xc , yc , a , b , theta = params <NEWLINE> <NEWLINE> ct = np . cos ( t ) <NEWLINE> st = np . sin ( t ) <NEWLINE> ctheta = math . cos ( theta ) <NEWLINE> stheta = math . sin ( theta ) <NEWLINE> <NEWLINE> x = xc + a * ctheta * ct - b * stheta * st <NEWLINE> y = yc + a * stheta * ct + b * ctheta * st <NEWLINE> <NEWLINE> return np . concatenate ( ( x [ ... , None ] , y [ ... , None ] ) , axis = t . ndim ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sequence ( value ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> len ( value ) <NEWLINE> return value <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> return ( value , ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_shared_y_axes ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _shared_y_axes <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def squeeze ( self , axis = None ) : <NEWLINE> <TAB> <NEWLINE> return N . ndarray . squeeze ( self , axis = axis ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_compute_order ( graph_def , input_node_name = <STRING> , input_node_size = None ) : <NEWLINE> <TAB> <NEWLINE> name_to_node = parse_graph_nodes ( graph_def ) <NEWLINE> node_info = collections . defaultdict ( _node_info ) <NEWLINE> for each in graph_def . node : <NEWLINE> <TAB> _get_computed_nodes ( name_to_node , each . name , node_info , input_node_name , <NEWLINE> input_node_size ) <NEWLINE> <UNTAB> return node_info , name_to_node <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def type_descriptor ( cls , typeobj ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> def connected_component_subgraphs ( G , copy = True ) : <NEWLINE> <TAB> <NEWLINE> msg = <STRING> <STRING> <NEWLINE> _warnings . warn ( msg , DeprecationWarning ) <NEWLINE> for c in connected_components ( G ) : <NEWLINE> <TAB> if copy : <NEWLINE> <TAB> yield G . subgraph ( c ) . copy ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> yield G . subgraph ( c ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_zpk ( self ) : <NEWLINE> <TAB> <NEWLINE> return copy . deepcopy ( self ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def update_from ( self , other ) : <NEWLINE> <TAB> <NEWLINE> artist . Artist . update_from ( self , other ) <NEWLINE> <NEWLINE> <NEWLINE> self . _edgecolor = other . _edgecolor <NEWLINE> self . _facecolor = other . _facecolor <NEWLINE> self . _original_edgecolor = other . _original_edgecolor <NEWLINE> self . _original_facecolor = other . _original_facecolor <NEWLINE> self . _fill = other . _fill <NEWLINE> self . _hatch = other . _hatch <NEWLINE> self . _hatch_color = other . _hatch_color <NEWLINE> <NEWLINE> self . _us_dashes = other . _us_dashes <NEWLINE> self . set_linewidth ( other . _linewidth ) <NEWLINE> self . set_transform ( other . get_data_transform ( ) ) <NEWLINE> <NEWLINE> <NEWLINE> self . _transformSet = other . is_transform_set ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def summary_writer_initializer_op ( ) : <NEWLINE> <TAB> <NEWLINE> if context . executing_eagerly ( ) : <NEWLINE> <TAB> raise RuntimeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> global _SUMMARY_WRITER_INIT_OP <NEWLINE> key = ops . get_default_graph ( ) . _graph_key <NEWLINE> return _SUMMARY_WRITER_INIT_OP . setdefault ( key , [ ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def warn_unwanted_files ( ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> install_path = os . path . split ( pygame . base . __file__ ) [ <NUMBER> ] <NEWLINE> extension_ext = os . path . splitext ( pygame . base . __file__ ) [ <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> ext_to_remove = [ <STRING> ] <NEWLINE> <NEWLINE> <NEWLINE> py_to_remove = [ <STRING> ] <NEWLINE> <NEWLINE> <NEWLINE> if os . name == <STRING> : <NEWLINE> <TAB> py_to_remove = [ ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> extension_files = [ <STRING> % ( x , extension_ext ) for x in ext_to_remove ] <NEWLINE> <NEWLINE> py_files = [ <STRING> % ( x , py_ext ) <NEWLINE> for py_ext in [ <STRING> , <STRING> , <STRING> ] <NEWLINE> for x in py_to_remove ] <NEWLINE> <NEWLINE> files = py_files + extension_files <NEWLINE> <NEWLINE> unwanted_files = [ ] <NEWLINE> for f in files : <NEWLINE> <TAB> unwanted_files . append ( os . path . join ( install_path , f ) ) <NEWLINE> <NEWLINE> <UNTAB> ask_remove = [ ] <NEWLINE> for f in unwanted_files : <NEWLINE> <TAB> if os . path . exists ( f ) : <NEWLINE> <TAB> ask_remove . append ( f ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if ask_remove : <NEWLINE> <TAB> message = <STRING> <NEWLINE> <NEWLINE> for f in ask_remove : <NEWLINE> <TAB> message += <STRING> % f <NEWLINE> <UNTAB> message += <STRING> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> import warnings <NEWLINE> level = <NUMBER> <NEWLINE> warnings . warn ( message , RuntimeWarning , level ) <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> print ( message ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def push ( stack , x , op_id ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( x , numpy . ndarray ) : <NEWLINE> <TAB> x = x . copy ( ) <NEWLINE> <UNTAB> elif isinstance ( x , list ) : <NEWLINE> <TAB> x = x [ : ] <NEWLINE> <UNTAB> if __debug__ : <NEWLINE> <TAB> stack . append ( ( x , op_id ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> stack . append ( x ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def from_codes ( cls , codes , categories , ordered = False ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> codes = coerce_indexer_dtype ( np . asarray ( codes ) , categories ) <NEWLINE> <UNTAB> except ( ValueError , TypeError ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> categories = CategoricalDtype . validate_categories ( categories ) <NEWLINE> <NEWLINE> if len ( codes ) and ( codes . max ( ) >= len ( categories ) or codes . min ( ) < - <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> return cls ( codes , categories = categories , ordered = ordered , <NEWLINE> fastpath = True ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dmp_eval_tail ( f , A , u , K ) : <NEWLINE> <TAB> <NEWLINE> if not A : <NEWLINE> <TAB> return f <NEWLINE> <NEWLINE> <UNTAB> if dmp_zero_p ( f , u ) : <NEWLINE> <TAB> return dmp_zero ( u - len ( A ) ) <NEWLINE> <NEWLINE> <UNTAB> e = _rec_eval_tail ( f , <NUMBER> , A , u , K ) <NEWLINE> <NEWLINE> if u == len ( A ) - <NUMBER> : <NEWLINE> <TAB> return e <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return dmp_strip ( e , u - len ( A ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def half_per ( f , rep , kill = False ) : <NEWLINE> <TAB> <NEWLINE> lev = f . lev <NEWLINE> <NEWLINE> if kill : <NEWLINE> <TAB> if not lev : <NEWLINE> <TAB> return rep <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> lev -= <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return DMP ( rep , f . dom , lev ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def solve_triangulated ( polys , * gens , ** args ) : <NEWLINE> <TAB> <NEWLINE> G = groebner ( polys , gens , polys = True ) <NEWLINE> G = list ( reversed ( G ) ) <NEWLINE> <NEWLINE> domain = args . get ( <STRING> ) <NEWLINE> <NEWLINE> if domain is not None : <NEWLINE> <TAB> for i , g in enumerate ( G ) : <NEWLINE> <TAB> G [ i ] = g . set_domain ( domain ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> f , G = G [ <NUMBER> ] . ltrim ( - <NUMBER> ) , G [ <NUMBER> : ] <NEWLINE> dom = f . get_domain ( ) <NEWLINE> <NEWLINE> zeros = f . ground_roots ( ) <NEWLINE> solutions = set ( [ ] ) <NEWLINE> <NEWLINE> for zero in zeros : <NEWLINE> <TAB> solutions . add ( ( ( zero , ) , dom ) ) <NEWLINE> <NEWLINE> <UNTAB> var_seq = reversed ( gens [ : - <NUMBER> ] ) <NEWLINE> vars_seq = postfixes ( gens [ <NUMBER> : ] ) <NEWLINE> <NEWLINE> for var , vars in zip ( var_seq , vars_seq ) : <NEWLINE> <TAB> _solutions = set ( [ ] ) <NEWLINE> <NEWLINE> for values , dom in solutions : <NEWLINE> <TAB> H , mapping = [ ] , list ( zip ( vars , values ) ) <NEWLINE> <NEWLINE> for g in G : <NEWLINE> <TAB> _vars = ( var , ) + vars <NEWLINE> <NEWLINE> if g . has_only_gens ( * _vars ) and g . degree ( var ) != <NUMBER> : <NEWLINE> <TAB> h = g . ltrim ( var ) . eval ( dict ( mapping ) ) <NEWLINE> <NEWLINE> if g . degree ( var ) == h . degree ( ) : <NEWLINE> <TAB> H . append ( h ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> p = min ( H , key = lambda h : h . degree ( ) ) <NEWLINE> zeros = p . ground_roots ( ) <NEWLINE> <NEWLINE> for zero in zeros : <NEWLINE> <TAB> if not zero . is_Rational : <NEWLINE> <TAB> dom_zero = dom . algebraic_field ( zero ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dom_zero = dom <NEWLINE> <NEWLINE> <UNTAB> _solutions . add ( ( ( zero , ) + values , dom_zero ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> solutions = _solutions <NEWLINE> <NEWLINE> <UNTAB> solutions = list ( solutions ) <NEWLINE> <NEWLINE> for i , ( solution , _ ) in enumerate ( solutions ) : <NEWLINE> <TAB> solutions [ i ] = solution <NEWLINE> <NEWLINE> <UNTAB> return sorted ( solutions , key = default_sort_key ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def sign ( x ) : <NEWLINE> <TAB> <NEWLINE> return math_ops . sign ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_x ( self , x ) : <NEWLINE> <TAB> <NEWLINE> self . _dashx = float ( x ) <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rcollect ( expr , * vars ) : <NEWLINE> <TAB> <NEWLINE> if expr . is_Atom or not expr . has ( * vars ) : <NEWLINE> <TAB> return expr <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> expr = expr . __class__ ( * [ rcollect ( arg , * vars ) for arg in expr . args ] ) <NEWLINE> <NEWLINE> if expr . is_Add : <NEWLINE> <TAB> return collect ( expr , vars ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return expr <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def index_of ( y ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return y . index . values , y . values <NEWLINE> <UNTAB> except AttributeError : <NEWLINE> <TAB> y = _check_1d ( y ) <NEWLINE> return np . arange ( y . shape [ <NUMBER> ] , dtype = float ) , y <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def rotate ( self , angle , pt = None ) : <NEWLINE> <TAB> <NEWLINE> newargs = [ ] <NEWLINE> for a in self . args : <NEWLINE> <TAB> if isinstance ( a , GeometryEntity ) : <NEWLINE> <TAB> newargs . append ( a . rotate ( angle , pt ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> newargs . append ( a ) <NEWLINE> <UNTAB> <UNTAB> return type ( self ) ( * newargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def remove_flag_values ( self , flag_values ) : <NEWLINE> <TAB> <NEWLINE> for flag_name in flag_values : <NEWLINE> <TAB> self . __delattr__ ( flag_name ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _set_logger_verbose_level ( level_str = <STRING> , file_str = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> levelmap = { <STRING> : logging . WARNING , <STRING> : logging . INFO , <NEWLINE> <STRING> : logging . DEBUG , <STRING> : logging . DEBUG , <NEWLINE> <STRING> : logging . INFO , <STRING> : logging . WARNING } <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> newlev = levelmap [ level_str ] <NEWLINE> oldlev = _log . getEffectiveLevel ( ) <NEWLINE> if newlev < oldlev : <NEWLINE> <TAB> _log . setLevel ( newlev ) <NEWLINE> std = { <NEWLINE> <STRING> : sys . stdout , <NEWLINE> <STRING> : sys . stderr , <NEWLINE> } <NEWLINE> if file_str in std : <NEWLINE> <TAB> fileo = std [ file_str ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> fileo = sys . stdout <NEWLINE> try : <NEWLINE> <TAB> fileo = open ( file_str , <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> except IOError : <NEWLINE> <TAB> warnings . warn ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> . format ( file_str ) ) <NEWLINE> <UNTAB> <UNTAB> console = logging . StreamHandler ( fileo ) <NEWLINE> console . setLevel ( newlev ) <NEWLINE> _log . addHandler ( console ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def denoms ( eq , * symbols ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> pot = preorder_traversal ( eq ) <NEWLINE> dens = set ( ) <NEWLINE> for p in pot : <NEWLINE> <TAB> den = denom ( p ) <NEWLINE> if den is S . One : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> for d in Mul . make_args ( den ) : <NEWLINE> <TAB> dens . add ( d ) <NEWLINE> <UNTAB> <UNTAB> if not symbols : <NEWLINE> <TAB> return dens <NEWLINE> <UNTAB> elif len ( symbols ) == <NUMBER> : <NEWLINE> <TAB> if iterable ( symbols [ <NUMBER> ] ) : <NEWLINE> <TAB> symbols = symbols [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> rv = [ ] <NEWLINE> for d in dens : <NEWLINE> <TAB> free = d . free_symbols <NEWLINE> if any ( s in free for s in symbols ) : <NEWLINE> <TAB> rv . append ( d ) <NEWLINE> <UNTAB> <UNTAB> return set ( rv ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def dfs_testing_recursive ( self , v ) : <NEWLINE> <TAB> <NEWLINE> e = self . parent_edge [ v ] <NEWLINE> for w in self . ordered_adjs [ v ] : <NEWLINE> <TAB> ei = ( v , w ) <NEWLINE> self . stack_bottom [ ei ] = top_of_stack ( self . S ) <NEWLINE> if ei == self . parent_edge [ w ] : <NEWLINE> <TAB> if not self . dfs_testing_recursive ( w ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> self . lowpt_edge [ ei ] = ei <NEWLINE> self . S . append ( ConflictPair ( right = Interval ( ei , ei ) ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . lowpt [ ei ] < self . height [ v ] : <NEWLINE> <TAB> if w == self . ordered_adjs [ v ] [ <NUMBER> ] : <NEWLINE> <TAB> self . lowpt_edge [ e ] = self . lowpt_edge [ ei ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if not self . add_constraints ( ei , e ) : <NEWLINE> <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> if e is not None : <NEWLINE> <TAB> self . remove_back_edges ( e ) <NEWLINE> <UNTAB> return True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def roberts_pos_diag ( image , mask = None ) : <NEWLINE> <TAB> <NEWLINE> assert_nD ( image , <NUMBER> ) <NEWLINE> image = img_as_float ( image ) <NEWLINE> result = convolve ( image , ROBERTS_PD_WEIGHTS ) <NEWLINE> return _mask_filter_result ( result , mask ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def minimum ( x , y ) : <NEWLINE> <TAB> <NEWLINE> return tf . minimum ( x , y ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _nonlinear_2eq_order1_type2 ( x , y , t , eq ) : <NEWLINE> <TAB> <NEWLINE> C1 , C2 = get_numbered_constants ( eq , num = <NUMBER> ) <NEWLINE> n = Wild ( <STRING> , exclude = [ x ( t ) , y ( t ) ] ) <NEWLINE> f = Wild ( <STRING> ) <NEWLINE> u , v = symbols ( <STRING> ) <NEWLINE> r = eq [ <NUMBER> ] . match ( diff ( x ( t ) , t ) - exp ( n * x ( t ) ) * f ) <NEWLINE> g = ( ( diff ( y ( t ) , t ) - eq [ <NUMBER> ] ) / r [ f ] ) . subs ( y ( t ) , v ) <NEWLINE> F = r [ f ] . subs ( x ( t ) , u ) . subs ( y ( t ) , v ) <NEWLINE> n = r [ n ] <NEWLINE> if n : <NEWLINE> <TAB> phi = - <NUMBER> / n * log ( C1 - n * Integral ( <NUMBER> / g , v ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> phi = C1 + Integral ( <NUMBER> / g , v ) <NEWLINE> <UNTAB> phi = phi . doit ( ) <NEWLINE> sol2 = solve ( Integral ( <NUMBER> / ( g * F . subs ( u , phi ) ) , v ) . doit ( ) - t - C2 , v ) <NEWLINE> sol = [ ] <NEWLINE> for sols in sol2 : <NEWLINE> <TAB> sol . append ( Eq ( x ( t ) , phi . subs ( v , sols ) ) ) <NEWLINE> sol . append ( Eq ( y ( t ) , sols ) ) <NEWLINE> <UNTAB> return sol <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dark_palette ( color , n_colors = <NUMBER> , reverse = False , as_cmap = False , input = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> color = _color_to_rgb ( color , input ) <NEWLINE> gray = <STRING> <NEWLINE> colors = [ color , gray ] if reverse else [ gray , color ] <NEWLINE> return blend_palette ( colors , n_colors , as_cmap ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def refine_size ( self , dx ) : <NEWLINE> <TAB> <NEWLINE> expr = self <NEWLINE> while not ( expr . dx < dx ) : <NEWLINE> <TAB> expr = expr . _inner_refine ( ) <NEWLINE> <NEWLINE> <UNTAB> return expr <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def simps ( y , x = None , dx = <NUMBER> , axis = - <NUMBER> , even = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> y = np . asarray ( y ) <NEWLINE> nd = len ( y . shape ) <NEWLINE> N = y . shape [ axis ] <NEWLINE> last_dx = dx <NEWLINE> first_dx = dx <NEWLINE> returnshape = <NUMBER> <NEWLINE> if x is not None : <NEWLINE> <TAB> x = np . asarray ( x ) <NEWLINE> if len ( x . shape ) == <NUMBER> : <NEWLINE> <TAB> shapex = [ <NUMBER> ] * nd <NEWLINE> shapex [ axis ] = x . shape [ <NUMBER> ] <NEWLINE> saveshape = x . shape <NEWLINE> returnshape = <NUMBER> <NEWLINE> x = x . reshape ( tuple ( shapex ) ) <NEWLINE> <UNTAB> elif len ( x . shape ) != len ( y . shape ) : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if x . shape [ axis ] != N : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> if N % <NUMBER> == <NUMBER> : <NEWLINE> <TAB> val = <NUMBER> <NEWLINE> result = <NUMBER> <NEWLINE> slice1 = ( slice ( None ) , ) * nd <NEWLINE> slice2 = ( slice ( None ) , ) * nd <NEWLINE> if even not in [ <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if even in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> slice1 = tupleset ( slice1 , axis , - <NUMBER> ) <NEWLINE> slice2 = tupleset ( slice2 , axis , - <NUMBER> ) <NEWLINE> if x is not None : <NEWLINE> <TAB> last_dx = x [ slice1 ] - x [ slice2 ] <NEWLINE> <UNTAB> val += <NUMBER> * last_dx * ( y [ slice1 ] + y [ slice2 ] ) <NEWLINE> result = _basic_simps ( y , <NUMBER> , N - <NUMBER> , x , dx , axis ) <NEWLINE> <NEWLINE> <UNTAB> if even in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> slice1 = tupleset ( slice1 , axis , <NUMBER> ) <NEWLINE> slice2 = tupleset ( slice2 , axis , <NUMBER> ) <NEWLINE> if x is not None : <NEWLINE> <TAB> first_dx = x [ tuple ( slice2 ) ] - x [ tuple ( slice1 ) ] <NEWLINE> <UNTAB> val += <NUMBER> * first_dx * ( y [ slice2 ] + y [ slice1 ] ) <NEWLINE> result += _basic_simps ( y , <NUMBER> , N - <NUMBER> , x , dx , axis ) <NEWLINE> <UNTAB> if even == <STRING> : <NEWLINE> <TAB> val /= <NUMBER> <NEWLINE> result /= <NUMBER> <NEWLINE> <UNTAB> result = result + val <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result = _basic_simps ( y , <NUMBER> , N - <NUMBER> , x , dx , axis ) <NEWLINE> <UNTAB> if returnshape : <NEWLINE> <TAB> x = x . reshape ( saveshape ) <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_data ( self , x , y , A ) : <NEWLINE> <TAB> <NEWLINE> A = cbook . safe_masked_invalid ( A , copy = True ) <NEWLINE> if x is None : <NEWLINE> <TAB> x = np . arange ( <NUMBER> , A . shape [ <NUMBER> ] + <NUMBER> , dtype = np . float64 ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x = np . array ( x , np . float64 ) . ravel ( ) <NEWLINE> <UNTAB> if y is None : <NEWLINE> <TAB> y = np . arange ( <NUMBER> , A . shape [ <NUMBER> ] + <NUMBER> , dtype = np . float64 ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> y = np . array ( y , np . float64 ) . ravel ( ) <NEWLINE> <NEWLINE> <UNTAB> if A . shape [ : <NUMBER> ] != ( y . size - <NUMBER> , x . size - <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> % <NEWLINE> ( A . shape [ : <NUMBER> ] , ( y . size - <NUMBER> , x . size - <NUMBER> ) ) ) <NEWLINE> <UNTAB> if A . ndim not in [ <NUMBER> , <NUMBER> ] : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> if A . ndim == <NUMBER> and A . shape [ <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> A . shape = A . shape [ : <NUMBER> ] <NEWLINE> <UNTAB> self . is_grayscale = False <NEWLINE> if A . ndim == <NUMBER> : <NEWLINE> <TAB> if A . shape [ <NUMBER> ] in [ <NUMBER> , <NUMBER> ] : <NEWLINE> <TAB> if ( ( A [ : , : , <NUMBER> ] == A [ : , : , <NUMBER> ] ) . all ( ) and <NEWLINE> ( A [ : , : , <NUMBER> ] == A [ : , : , <NUMBER> ] ) . all ( ) ) : <NEWLINE> <TAB> self . is_grayscale = True <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if x [ - <NUMBER> ] < x [ <NUMBER> ] : <NEWLINE> <TAB> x = x [ : : - <NUMBER> ] <NEWLINE> A = A [ : , : : - <NUMBER> ] <NEWLINE> <UNTAB> if y [ - <NUMBER> ] < y [ <NUMBER> ] : <NEWLINE> <TAB> y = y [ : : - <NUMBER> ] <NEWLINE> A = A [ : : - <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> self . _A = A <NEWLINE> self . _Ax = x <NEWLINE> self . _Ay = y <NEWLINE> self . _rgbacache = None <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def sort_values ( self , inplace = False , ascending = True , na_position = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> inplace = validate_bool_kwarg ( inplace , <STRING> ) <NEWLINE> if na_position not in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise ValueError ( msg . format ( na_position = na_position ) ) <NEWLINE> <NEWLINE> <UNTAB> codes = np . sort ( self . _codes ) <NEWLINE> if not ascending : <NEWLINE> <TAB> codes = codes [ : : - <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> na_mask = ( codes == - <NUMBER> ) <NEWLINE> if na_mask . any ( ) : <NEWLINE> <TAB> n_nans = len ( codes [ na_mask ] ) <NEWLINE> if na_position == <STRING> : <NEWLINE> <NEWLINE> <TAB> new_codes = codes . copy ( ) <NEWLINE> new_codes [ <NUMBER> : n_nans ] = - <NUMBER> <NEWLINE> new_codes [ n_nans : ] = codes [ ~ na_mask ] <NEWLINE> codes = new_codes <NEWLINE> <UNTAB> elif na_position == <STRING> : <NEWLINE> <NEWLINE> <TAB> new_codes = codes . copy ( ) <NEWLINE> pos = len ( codes ) - n_nans <NEWLINE> new_codes [ <NUMBER> : pos ] = codes [ ~ na_mask ] <NEWLINE> new_codes [ pos : ] = - <NUMBER> <NEWLINE> codes = new_codes <NEWLINE> <UNTAB> <UNTAB> if inplace : <NEWLINE> <TAB> self . _codes = codes <NEWLINE> return <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . _constructor ( values = codes , categories = self . categories , <NEWLINE> ordered = self . ordered , fastpath = True ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def set_verbosity ( v ) : <NEWLINE> <TAB> <NEWLINE> _get_logger ( ) . setLevel ( v ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def einsum ( * operands , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> optimize_arg = kwargs . pop ( <STRING> , False ) <NEWLINE> <NEWLINE> <NEWLINE> if optimize_arg is False : <NEWLINE> <TAB> return c_einsum ( * operands , ** kwargs ) <NEWLINE> <NEWLINE> <UNTAB> valid_einsum_kwargs = [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> einsum_kwargs = { k : v for ( k , v ) in kwargs . items ( ) if <NEWLINE> k in valid_einsum_kwargs } <NEWLINE> <NEWLINE> <NEWLINE> valid_contract_kwargs = [ <STRING> ] + valid_einsum_kwargs <NEWLINE> unknown_kwargs = [ k for ( k , v ) in kwargs . items ( ) if <NEWLINE> k not in valid_contract_kwargs ] <NEWLINE> <NEWLINE> if len ( unknown_kwargs ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> % unknown_kwargs ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> specified_out = False <NEWLINE> out_array = einsum_kwargs . pop ( <STRING> , None ) <NEWLINE> if out_array is not None : <NEWLINE> <TAB> specified_out = True <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> operands , contraction_list = einsum_path ( * operands , optimize = optimize_arg , <NEWLINE> einsum_call = True ) <NEWLINE> <NEWLINE> handle_out = False <NEWLINE> <NEWLINE> <NEWLINE> for num , contraction in enumerate ( contraction_list ) : <NEWLINE> <TAB> inds , idx_rm , einsum_str , remaining , blas = contraction <NEWLINE> tmp_operands = [ ] <NEWLINE> for x in inds : <NEWLINE> <TAB> tmp_operands . append ( operands . pop ( x ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if specified_out and ( ( num + <NUMBER> ) == len ( contraction_list ) ) : <NEWLINE> <TAB> handle_out = True <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if blas : <NEWLINE> <NEWLINE> <TAB> input_str , results_index = einsum_str . split ( <STRING> ) <NEWLINE> input_left , input_right = input_str . split ( <STRING> ) <NEWLINE> if <NUMBER> in tmp_operands [ <NUMBER> ] . shape or <NUMBER> in tmp_operands [ <NUMBER> ] . shape : <NEWLINE> <TAB> left_dims = { dim : size for dim , size in <NEWLINE> zip ( input_left , tmp_operands [ <NUMBER> ] . shape ) } <NEWLINE> right_dims = { dim : size for dim , size in <NEWLINE> zip ( input_right , tmp_operands [ <NUMBER> ] . shape ) } <NEWLINE> <NEWLINE> if any ( left_dims [ ind ] != right_dims [ ind ] for ind in idx_rm ) : <NEWLINE> <TAB> blas = False <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if blas : <NEWLINE> <TAB> tensor_result = input_left + input_right <NEWLINE> for s in idx_rm : <NEWLINE> <TAB> tensor_result = tensor_result . replace ( s , <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> left_pos , right_pos = [ ] , [ ] <NEWLINE> for s in idx_rm : <NEWLINE> <TAB> left_pos . append ( input_left . find ( s ) ) <NEWLINE> right_pos . append ( input_right . find ( s ) ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> new_view = tensordot ( * tmp_operands , axes = ( tuple ( left_pos ) , tuple ( right_pos ) ) ) <NEWLINE> <NEWLINE> <NEWLINE> if ( tensor_result != results_index ) or handle_out : <NEWLINE> <TAB> if handle_out : <NEWLINE> <TAB> einsum_kwargs [ <STRING> ] = out_array <NEWLINE> <UNTAB> new_view = c_einsum ( tensor_result + <STRING> + results_index , new_view , ** einsum_kwargs ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> if handle_out : <NEWLINE> <TAB> einsum_kwargs [ <STRING> ] = out_array <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> new_view = c_einsum ( einsum_str , * tmp_operands , ** einsum_kwargs ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> operands . append ( new_view ) <NEWLINE> del tmp_operands , new_view <NEWLINE> <NEWLINE> <UNTAB> if specified_out : <NEWLINE> <TAB> return out_array <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return operands [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , cell , output_size , activation = None , reuse = None ) : <NEWLINE> <TAB> <NEWLINE> super ( OutputProjectionWrapper , self ) . __init__ ( _reuse = reuse ) <NEWLINE> rnn_cell_impl . assert_like_rnncell ( <STRING> , cell ) <NEWLINE> if output_size < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % output_size ) <NEWLINE> <UNTAB> self . _cell = cell <NEWLINE> self . _output_size = output_size <NEWLINE> self . _activation = activation <NEWLINE> self . _linear = None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def var ( self , df , scale ) : <NEWLINE> <TAB> <NEWLINE> dim , df , scale = self . _process_parameters ( df , scale ) <NEWLINE> out = self . _var ( dim , df , scale ) <NEWLINE> return _squeeze_output ( out ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def truncate_mod ( x , y , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , x = x , y = y , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , <NEWLINE> name , _ctx . _post_execution_callbacks , x , y ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return truncate_mod_eager_fallback ( <NEWLINE> x , y , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def has_node ( self , n ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return n in self . _node <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def zpk2sos ( z , p , k , pairing = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> valid_pairings = [ <STRING> , <STRING> ] <NEWLINE> if pairing not in valid_pairings : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> % ( valid_pairings , pairing ) ) <NEWLINE> <UNTAB> if len ( z ) == len ( p ) == <NUMBER> : <NEWLINE> <TAB> return array ( [ [ k , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> p = np . concatenate ( ( p , np . zeros ( max ( len ( z ) - len ( p ) , <NUMBER> ) ) ) ) <NEWLINE> z = np . concatenate ( ( z , np . zeros ( max ( len ( p ) - len ( z ) , <NUMBER> ) ) ) ) <NEWLINE> n_sections = ( max ( len ( p ) , len ( z ) ) + <NUMBER> ) // <NUMBER> <NEWLINE> sos = zeros ( ( n_sections , <NUMBER> ) ) <NEWLINE> <NEWLINE> if len ( p ) % <NUMBER> == <NUMBER> and pairing == <STRING> : <NEWLINE> <TAB> p = np . concatenate ( ( p , [ <NUMBER> ] ) ) <NEWLINE> z = np . concatenate ( ( z , [ <NUMBER> ] ) ) <NEWLINE> <UNTAB> assert len ( p ) == len ( z ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> z = np . concatenate ( _cplxreal ( z ) ) <NEWLINE> p = np . concatenate ( _cplxreal ( p ) ) <NEWLINE> <NEWLINE> p_sos = np . zeros ( ( n_sections , <NUMBER> ) , np . complex128 ) <NEWLINE> z_sos = np . zeros_like ( p_sos ) <NEWLINE> for si in range ( n_sections ) : <NEWLINE> <NEWLINE> <TAB> p1_idx = np . argmin ( np . abs ( <NUMBER> - np . abs ( p ) ) ) <NEWLINE> p1 = p [ p1_idx ] <NEWLINE> p = np . delete ( p , p1_idx ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if np . isreal ( p1 ) and np . isreal ( p ) . sum ( ) == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> z1_idx = _nearest_real_complex_idx ( z , p1 , <STRING> ) <NEWLINE> z1 = z [ z1_idx ] <NEWLINE> z = np . delete ( z , z1_idx ) <NEWLINE> p2 = z2 = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if not np . isreal ( p1 ) and np . isreal ( z ) . sum ( ) == <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> z1_idx = _nearest_real_complex_idx ( z , p1 , <STRING> ) <NEWLINE> assert not np . isreal ( z [ z1_idx ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> z1_idx = np . argmin ( np . abs ( p1 - z ) ) <NEWLINE> <UNTAB> z1 = z [ z1_idx ] <NEWLINE> z = np . delete ( z , z1_idx ) <NEWLINE> <NEWLINE> <NEWLINE> if not np . isreal ( p1 ) : <NEWLINE> <TAB> if not np . isreal ( z1 ) : <NEWLINE> <TAB> p2 = p1 . conj ( ) <NEWLINE> z2 = z1 . conj ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> p2 = p1 . conj ( ) <NEWLINE> z2_idx = _nearest_real_complex_idx ( z , p1 , <STRING> ) <NEWLINE> z2 = z [ z2_idx ] <NEWLINE> assert np . isreal ( z2 ) <NEWLINE> z = np . delete ( z , z2_idx ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> if not np . isreal ( z1 ) : <NEWLINE> <TAB> z2 = z1 . conj ( ) <NEWLINE> p2_idx = _nearest_real_complex_idx ( p , z1 , <STRING> ) <NEWLINE> p2 = p [ p2_idx ] <NEWLINE> assert np . isreal ( p2 ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> idx = np . where ( np . isreal ( p ) ) [ <NUMBER> ] <NEWLINE> assert len ( idx ) > <NUMBER> <NEWLINE> p2_idx = idx [ np . argmin ( np . abs ( np . abs ( p [ idx ] ) - <NUMBER> ) ) ] <NEWLINE> p2 = p [ p2_idx ] <NEWLINE> <NEWLINE> assert np . isreal ( p2 ) <NEWLINE> z2_idx = _nearest_real_complex_idx ( z , p2 , <STRING> ) <NEWLINE> z2 = z [ z2_idx ] <NEWLINE> assert np . isreal ( z2 ) <NEWLINE> z = np . delete ( z , z2_idx ) <NEWLINE> <UNTAB> p = np . delete ( p , p2_idx ) <NEWLINE> <UNTAB> <UNTAB> p_sos [ si ] = [ p1 , p2 ] <NEWLINE> z_sos [ si ] = [ z1 , z2 ] <NEWLINE> <UNTAB> assert len ( p ) == len ( z ) == <NUMBER> <NEWLINE> del p , z <NEWLINE> <NEWLINE> <NEWLINE> p_sos = np . reshape ( p_sos [ : : - <NUMBER> ] , ( n_sections , <NUMBER> ) ) <NEWLINE> z_sos = np . reshape ( z_sos [ : : - <NUMBER> ] , ( n_sections , <NUMBER> ) ) <NEWLINE> gains = np . ones ( n_sections ) <NEWLINE> gains [ <NUMBER> ] = k <NEWLINE> for si in range ( n_sections ) : <NEWLINE> <TAB> x = zpk2tf ( z_sos [ si ] , p_sos [ si ] , gains [ si ] ) <NEWLINE> sos [ si ] = np . concatenate ( x ) <NEWLINE> <UNTAB> return sos <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def current_process ( ) : <NEWLINE> <TAB> <NEWLINE> return _current_process <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def isnum ( cls , nextchar ) : <NEWLINE> <TAB> <NEWLINE> return nextchar . isdigit ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_bounds ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _bounds <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def on_mappable_changed ( self , mappable ) : <NEWLINE> <TAB> <NEWLINE> self . set_cmap ( mappable . get_cmap ( ) ) <NEWLINE> self . set_clim ( mappable . get_clim ( ) ) <NEWLINE> self . update_normal ( mappable ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _count_not_none ( * args ) : <NEWLINE> <TAB> <NEWLINE> return sum ( x is not None for x in args ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_re_compilable ( obj ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> re . compile ( obj ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tc . returns ( tc . Dict ( string_types , core . LabeledTensor ) ) <NEWLINE> @ tc . accepts ( core . LabeledTensorLike , tc . Mapping ( string_types , FixedLenFeature ) , <NEWLINE> tc . Optional ( string_types ) , object ) <NEWLINE> def parse_single_example ( serialized , features , name = None , example_names = None ) : <NEWLINE> <TAB> <NEWLINE> serialized = core . convert_to_labeled_tensor ( serialized ) <NEWLINE> unlabeled_features = _labeled_to_unlabeled_features ( features ) <NEWLINE> <NEWLINE> unlabeled_parsed = parsing_ops . parse_single_example ( <NEWLINE> serialized . tensor , unlabeled_features , name , example_names ) <NEWLINE> <NEWLINE> parsed = { } <NEWLINE> for name , parsed_feature in unlabeled_parsed . items ( ) : <NEWLINE> <TAB> parsed [ name ] = core . LabeledTensor ( parsed_feature , features [ name ] . axes ) <NEWLINE> <NEWLINE> <UNTAB> return parsed <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _local_reachability_density ( self , distances_X , neighbors_indices ) : <NEWLINE> <TAB> <NEWLINE> dist_k = self . _distances_fit_X_ [ neighbors_indices , <NEWLINE> self . n_neighbors_ - <NUMBER> ] <NEWLINE> reach_dist_array = np . maximum ( distances_X , dist_k ) <NEWLINE> <NEWLINE> <NEWLINE> return <NUMBER> / ( np . mean ( reach_dist_array , axis = <NUMBER> ) + <NUMBER> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def transform ( self , X ) : <NEWLINE> <TAB> <NEWLINE> if self . sparse : <NEWLINE> <TAB> return self . _transform ( X , fitting = False ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dtype = self . dtype <NEWLINE> vocab = self . vocabulary_ <NEWLINE> X = _tosequence ( X ) <NEWLINE> Xa = np . zeros ( ( len ( X ) , len ( vocab ) ) , dtype = dtype ) <NEWLINE> <NEWLINE> for i , x in enumerate ( X ) : <NEWLINE> <TAB> for f , v in six . iteritems ( x ) : <NEWLINE> <TAB> if isinstance ( v , six . string_types ) : <NEWLINE> <TAB> f = <STRING> % ( f , self . separator , v ) <NEWLINE> v = <NUMBER> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> Xa [ i , vocab [ f ] ] = dtype ( v ) <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> return Xa <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def pre_constant_merge ( vars ) : <NEWLINE> <TAB> <NEWLINE> seen_var = set ( ) <NEWLINE> <NEWLINE> const_sig_inv = { } <NEWLINE> if isinstance ( vars , graph . Variable ) : <NEWLINE> <TAB> vars = [ vars ] <NEWLINE> <NEWLINE> <UNTAB> def recursive_merge ( var ) : <NEWLINE> <TAB> if var in seen_var : <NEWLINE> <TAB> return var <NEWLINE> <UNTAB> if not hasattr ( var , <STRING> ) : <NEWLINE> <TAB> return var <NEWLINE> <UNTAB> if var . owner and hasattr ( var . owner , <STRING> ) : <NEWLINE> <TAB> return var <NEWLINE> <UNTAB> seen_var . add ( var ) <NEWLINE> if isinstance ( var , graph . Constant ) : <NEWLINE> <TAB> sig = var . signature ( ) <NEWLINE> try : <NEWLINE> <TAB> if sig in const_sig_inv : <NEWLINE> <TAB> return const_sig_inv [ sig ] <NEWLINE> <UNTAB> const_sig_inv [ sig ] = var <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> % var ) <NEWLINE> <NEWLINE> <NEWLINE> pass <NEWLINE> <UNTAB> return var <NEWLINE> <UNTAB> if var . owner : <NEWLINE> <TAB> for idx , inp in enumerate ( var . owner . inputs ) : <NEWLINE> <TAB> var . owner . inputs [ idx ] = recursive_merge ( inp ) <NEWLINE> <UNTAB> <UNTAB> return var <NEWLINE> <NEWLINE> <UNTAB> return list ( map ( recursive_merge , vars ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def general_source_directories_files ( top_path ) : <NEWLINE> <TAB> <NEWLINE> pruned_directories = [ <STRING> , <STRING> , <STRING> ] <NEWLINE> prune_file_pat = re . compile ( <STRING> ) <NEWLINE> for dirpath , dirnames , filenames in os . walk ( top_path , topdown = True ) : <NEWLINE> <TAB> pruned = [ d for d in dirnames if d not in pruned_directories ] <NEWLINE> dirnames [ : ] = pruned <NEWLINE> for d in dirnames : <NEWLINE> <TAB> dpath = os . path . join ( dirpath , d ) <NEWLINE> rpath = rel_path ( dpath , top_path ) <NEWLINE> files = [ ] <NEWLINE> for f in os . listdir ( dpath ) : <NEWLINE> <TAB> fn = os . path . join ( dpath , f ) <NEWLINE> if os . path . isfile ( fn ) and not prune_file_pat . search ( fn ) : <NEWLINE> <TAB> files . append ( fn ) <NEWLINE> <UNTAB> <UNTAB> yield rpath , files <NEWLINE> <UNTAB> <UNTAB> dpath = top_path <NEWLINE> rpath = rel_path ( dpath , top_path ) <NEWLINE> filenames = [ os . path . join ( dpath , f ) for f in os . listdir ( dpath ) if not prune_file_pat . search ( f ) ] <NEWLINE> files = [ f for f in filenames if os . path . isfile ( f ) ] <NEWLINE> yield rpath , files <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def perform ( self , node , inputs , output_storage , params = None ) : <NEWLINE> <TAB> <NEWLINE> raise utils . MethodNotDefined ( <NEWLINE> <STRING> , type ( self ) , self . __class__ . __name__ , <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def to_sympy ( self , a ) : <NEWLINE> <TAB> <NEWLINE> return a . as_expr ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _is_nth_color ( c ) : <NEWLINE> <TAB> <NEWLINE> return isinstance ( c , str ) and re . match ( <STRING> , c ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , name , canvas , x , y , guiEvent = None ) : <NEWLINE> <TAB> <NEWLINE> Event . __init__ ( self , name , canvas , guiEvent = guiEvent ) <NEWLINE> <NEWLINE> self . x = int ( x ) if x is not None else x <NEWLINE> <NEWLINE> self . y = int ( y ) if y is not None else y <NEWLINE> self . inaxes = None <NEWLINE> self . xdata = None <NEWLINE> self . ydata = None <NEWLINE> <NEWLINE> if x is None or y is None : <NEWLINE> <NEWLINE> <TAB> self . _update_enter_leave ( ) <NEWLINE> return <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if self . canvas . mouse_grabber is None : <NEWLINE> <TAB> axes_list = [ a for a in self . canvas . figure . get_axes ( ) <NEWLINE> if a . in_axes ( self ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> axes_list = [ self . canvas . mouse_grabber ] <NEWLINE> <NEWLINE> <UNTAB> if axes_list : <NEWLINE> <TAB> self . inaxes = cbook . _topmost_artist ( axes_list ) <NEWLINE> try : <NEWLINE> <TAB> trans = self . inaxes . transData . inverted ( ) <NEWLINE> xdata , ydata = trans . transform_point ( ( x , y ) ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . xdata = xdata <NEWLINE> self . ydata = ydata <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> self . _update_enter_leave ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sproot ( tck , mest = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> t , c , k = tck <NEWLINE> if k != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> c [ <NUMBER> ] [ <NUMBER> ] <NEWLINE> parametric = True <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> parametric = False <NEWLINE> <UNTAB> if parametric : <NEWLINE> <TAB> return list ( map ( lambda c , t = t , k = k , mest = mest : <NEWLINE> sproot ( [ t , c , k ] , mest ) , c ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if len ( t ) < <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> % len ( t ) ) <NEWLINE> <UNTAB> z , ier = _fitpack . _sproot ( t , c , k , mest ) <NEWLINE> if ier == <NUMBER> : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if ier == <NUMBER> : <NEWLINE> <TAB> return z <NEWLINE> <UNTAB> if ier == <NUMBER> : <NEWLINE> <TAB> warnings . warn ( RuntimeWarning ( <STRING> ) ) <NEWLINE> return z <NEWLINE> <UNTAB> raise TypeError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def plot ( self , ax , boxplot_kws ) : <NEWLINE> <TAB> <NEWLINE> self . draw_boxplot ( ax , boxplot_kws ) <NEWLINE> self . annotate_axes ( ax ) <NEWLINE> if self . orient == <STRING> : <NEWLINE> <TAB> ax . invert_yaxis ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _discrete_log_trial_mul ( n , a , b , order = None ) : <NEWLINE> <TAB> <NEWLINE> a %= n <NEWLINE> b %= n <NEWLINE> if order is None : <NEWLINE> <TAB> order = n <NEWLINE> <UNTAB> x = <NUMBER> <NEWLINE> k = <NUMBER> <NEWLINE> for i in range ( order ) : <NEWLINE> <TAB> if x == a : <NEWLINE> <TAB> return i <NEWLINE> <UNTAB> x = x * b % n <NEWLINE> <UNTAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def rq ( a , overwrite_a = False , lwork = None , mode = <STRING> , check_finite = True ) : <NEWLINE> <TAB> <NEWLINE> if mode not in [ <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if check_finite : <NEWLINE> <TAB> a1 = numpy . asarray_chkfinite ( a ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> a1 = numpy . asarray ( a ) <NEWLINE> <UNTAB> if len ( a1 . shape ) != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> M , N = a1 . shape <NEWLINE> overwrite_a = overwrite_a or ( _datacopied ( a1 , a ) ) <NEWLINE> <NEWLINE> gerqf , = get_lapack_funcs ( ( <STRING> , ) , ( a1 , ) ) <NEWLINE> rq , tau = safecall ( gerqf , <STRING> , a1 , lwork = lwork , <NEWLINE> overwrite_a = overwrite_a ) <NEWLINE> if not mode == <STRING> or N < M : <NEWLINE> <TAB> R = numpy . triu ( rq , N - M ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> R = numpy . triu ( rq [ - M : , - M : ] ) <NEWLINE> <NEWLINE> <UNTAB> if mode == <STRING> : <NEWLINE> <TAB> return R <NEWLINE> <NEWLINE> <UNTAB> gor_un_grq , = get_lapack_funcs ( ( <STRING> , ) , ( rq , ) ) <NEWLINE> <NEWLINE> if N < M : <NEWLINE> <TAB> Q , = safecall ( gor_un_grq , <STRING> , rq [ - N : ] , tau , lwork = lwork , <NEWLINE> overwrite_a = <NUMBER> ) <NEWLINE> <UNTAB> elif mode == <STRING> : <NEWLINE> <TAB> Q , = safecall ( gor_un_grq , <STRING> , rq , tau , lwork = lwork , <NEWLINE> overwrite_a = <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rq1 = numpy . empty ( ( N , N ) , dtype = rq . dtype ) <NEWLINE> rq1 [ - M : ] = rq <NEWLINE> Q , = safecall ( gor_un_grq , <STRING> , rq1 , tau , lwork = lwork , <NEWLINE> overwrite_a = <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> return R , Q <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def compute_batch_size ( self ) : <NEWLINE> <TAB> <NEWLINE> return <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def seek ( self , offset , whence = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if self . _offset : <NEWLINE> <TAB> if whence == <NUMBER> : <NEWLINE> <TAB> self . _fh . seek ( self . _offset + offset , whence ) <NEWLINE> return <NEWLINE> <UNTAB> elif whence == <NUMBER> and self . _size > <NUMBER> : <NEWLINE> <TAB> self . _fh . seek ( self . _offset + self . _size + offset , <NUMBER> ) <NEWLINE> return <NEWLINE> <UNTAB> <UNTAB> self . _fh . seek ( offset , whence ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def ndtr ( x ) : <NEWLINE> <TAB> <NEWLINE> return Ndtr ( ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def barrier ( group = group . WORLD ) : <NEWLINE> <TAB> <NEWLINE> assert torch . distributed . _initialized == _INITIALIZED_PG , <STRING> <NEWLINE> return torch . _C . _dist_barrier ( group ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def permute_rows ( self , swaps , direction = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> return self . permute ( swaps , orientation = <STRING> , direction = direction ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def itervaluerefs ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _pending_removals : <NEWLINE> <TAB> self . _commit_removals ( ) <NEWLINE> <UNTAB> with _IterationGuard ( self ) : <NEWLINE> <TAB> yield from self . data . values ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def to_dense ( tensor ) : <NEWLINE> <TAB> <NEWLINE> if is_sparse ( tensor ) : <NEWLINE> <TAB> return tf . sparse_tensor_to_dense ( tensor ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return tensor <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def unify ( f , g ) : <NEWLINE> <TAB> <NEWLINE> _ , per , F , G = f . _unify ( g ) <NEWLINE> return per ( F ) , per ( G ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def copy ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . __class__ ( self . coef , self . domain , self . window ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _convert_to_varsPOS ( maxterm , variables ) : <NEWLINE> <TAB> <NEWLINE> temp = [ ] <NEWLINE> for i , m in enumerate ( maxterm ) : <NEWLINE> <TAB> if m == <NUMBER> : <NEWLINE> <TAB> temp . append ( Not ( variables [ i ] ) ) <NEWLINE> <UNTAB> elif m == <NUMBER> : <NEWLINE> <TAB> temp . append ( variables [ i ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> return Or ( * temp ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _convert_freq ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> obj = self . _selected_obj <NEWLINE> index = None <NEWLINE> return obj , index <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_msvcr_replacement ( ) : <NEWLINE> <TAB> <NEWLINE> msvcr = msvc_runtime_library ( ) <NEWLINE> return [ ] if msvcr is None else [ msvcr ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def cdf ( self , value ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _name_scope_name ( self , current_variable_scope ) : <NEWLINE> <TAB> <NEWLINE> return _network_name_scope_naming ( <NEWLINE> current_variable_scope = current_variable_scope ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def compare_against_backend ( self , dialect , conn_type ) : <NEWLINE> <TAB> <NEWLINE> return None <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def bind ( self , sequence = None , func = None , add = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return self . _bind ( ( <STRING> , self . _w ) , sequence , func , add ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def roots ( p ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> p = atleast_1d ( p ) <NEWLINE> if p . ndim != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> non_zero = NX . nonzero ( NX . ravel ( p ) ) [ <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> if len ( non_zero ) == <NUMBER> : <NEWLINE> <TAB> return NX . array ( [ ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> trailing_zeros = len ( p ) - non_zero [ - <NUMBER> ] - <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> p = p [ int ( non_zero [ <NUMBER> ] ) : int ( non_zero [ - <NUMBER> ] ) + <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> if not issubclass ( p . dtype . type , ( NX . floating , NX . complexfloating ) ) : <NEWLINE> <TAB> p = p . astype ( float ) <NEWLINE> <NEWLINE> <UNTAB> N = len ( p ) <NEWLINE> if N > <NUMBER> : <NEWLINE> <NEWLINE> <TAB> A = diag ( NX . ones ( ( N - <NUMBER> , ) , p . dtype ) , - <NUMBER> ) <NEWLINE> A [ <NUMBER> , : ] = - p [ <NUMBER> : ] / p [ <NUMBER> ] <NEWLINE> roots = eigvals ( A ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> roots = NX . array ( [ ] ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> roots = hstack ( ( roots , NX . zeros ( trailing_zeros , roots . dtype ) ) ) <NEWLINE> return roots <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_derived_from ( self , fromclause ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> return fromclause in self . _cloned_set <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def ModularIntegerFactory ( _mod , _dom , _sym , parent ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> _mod = _dom . convert ( _mod ) <NEWLINE> <UNTAB> except CoercionFailed : <NEWLINE> <TAB> ok = False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ok = True <NEWLINE> <NEWLINE> <UNTAB> if not ok or _mod < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> % _mod ) <NEWLINE> <NEWLINE> <UNTAB> key = _mod , _dom , _sym <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> cls = _modular_integer_cache [ key ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> class cls ( ModularInteger ) : <NEWLINE> <TAB> mod , dom , sym = _mod , _dom , _sym <NEWLINE> _parent = parent <NEWLINE> <NEWLINE> <UNTAB> if _sym : <NEWLINE> <TAB> cls . __name__ = <STRING> % _mod <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cls . __name__ = <STRING> % _mod <NEWLINE> <NEWLINE> <UNTAB> _modular_integer_cache [ key ] = cls <NEWLINE> <NEWLINE> <UNTAB> return cls <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def radius ( G , e = None , usebounds = False ) : <NEWLINE> <TAB> <NEWLINE> if usebounds is True and e is None and not G . is_directed ( ) : <NEWLINE> <TAB> return extrema_bounding ( G , compute = <STRING> ) <NEWLINE> <UNTAB> if e is None : <NEWLINE> <TAB> e = eccentricity ( G ) <NEWLINE> <UNTAB> return min ( e . values ( ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ not_implemented_for ( <STRING> ) <NEWLINE> def number_weakly_connected_components ( G ) : <NEWLINE> <TAB> <NEWLINE> return sum ( <NUMBER> for wcc in weakly_connected_components ( G ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _min_cycle ( G , orth , weight = None ) : <NEWLINE> <TAB> <NEWLINE> T = nx . Graph ( ) <NEWLINE> <NEWLINE> nodes_idx = { node : idx for idx , node in enumerate ( G . nodes ( ) ) } <NEWLINE> idx_nodes = { idx : node for node , idx in nodes_idx . items ( ) } <NEWLINE> <NEWLINE> nnodes = len ( nodes_idx ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for u , v , data in G . edges ( data = True ) : <NEWLINE> <TAB> uidx , vidx = nodes_idx [ u ] , nodes_idx [ v ] <NEWLINE> edge_w = data . get ( weight , <NUMBER> ) <NEWLINE> if frozenset ( ( u , v ) ) in orth : <NEWLINE> <TAB> T . add_edges_from ( <NEWLINE> [ ( uidx , nnodes + vidx ) , ( nnodes + uidx , vidx ) ] , weight = edge_w ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> T . add_edges_from ( <NEWLINE> [ ( uidx , vidx ) , ( nnodes + uidx , nnodes + vidx ) ] , weight = edge_w ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> all_shortest_pathlens = dict ( nx . shortest_path_length ( T , weight = weight ) ) <NEWLINE> cross_paths_w_lens = { n : all_shortest_pathlens [ n ] [ nnodes + n ] <NEWLINE> for n in range ( nnodes ) } <NEWLINE> <NEWLINE> <NEWLINE> start = min ( cross_paths_w_lens , key = cross_paths_w_lens . get ) <NEWLINE> end = nnodes + start <NEWLINE> min_path = nx . shortest_path ( T , source = start , target = end , weight = <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> min_path_nodes = [ node if node < nnodes else node - nnodes <NEWLINE> for node in min_path ] <NEWLINE> <NEWLINE> mcycle_pruned = _path_to_cycle ( min_path_nodes ) <NEWLINE> <NEWLINE> return { frozenset ( ( idx_nodes [ u ] , idx_nodes [ v ] ) ) for u , v in mcycle_pruned } <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def visit_Name ( self , node ) : <NEWLINE> <TAB> <NEWLINE> if not self . target : <NEWLINE> <TAB> return node <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if node . id in [ <STRING> , <STRING> , <STRING> ] : <NEWLINE> <TAB> template_ = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> template_ = tangents . tangents [ node . __class__ ] <NEWLINE> <UNTAB> tangent_node = template . replace ( <NEWLINE> template = template_ , <NEWLINE> replace_grad = template . Replace . TANGENT , <NEWLINE> namer = self . namer , <NEWLINE> x = node , <NEWLINE> z = self . target ) <NEWLINE> return tangent_node <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def upsample_bilinear ( input , size = None , scale_factor = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> warnings . warn ( <STRING> ) <NEWLINE> return interpolate ( input , size , scale_factor , mode = <STRING> , align_corners = True ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _inv_call ( self , y ) : <NEWLINE> <TAB> <NEWLINE> if self . _cache_size == <NUMBER> : <NEWLINE> <TAB> return self . _inverse ( y ) <NEWLINE> <UNTAB> x_old , y_old = self . _cached_x_y <NEWLINE> if y is y_old : <NEWLINE> <TAB> return x_old <NEWLINE> <UNTAB> x = self . _inverse ( y ) <NEWLINE> self . _cached_x_y = x , y <NEWLINE> return x <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def contains ( self , mouseevent , radius = None ) : <NEWLINE> <TAB> <NEWLINE> if callable ( self . _contains ) : <NEWLINE> <TAB> return self . _contains ( self , mouseevent ) <NEWLINE> <UNTAB> radius = self . _process_radius ( radius ) <NEWLINE> inside = self . get_path ( ) . contains_point ( <NEWLINE> ( mouseevent . x , mouseevent . y ) , self . get_transform ( ) , radius ) <NEWLINE> return inside , { } <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def draw_single_observation ( self , ax , at_group , at_quant , density ) : <NEWLINE> <TAB> <NEWLINE> d_width = density * self . dwidth <NEWLINE> if self . orient == <STRING> : <NEWLINE> <TAB> ax . plot ( [ at_group - d_width , at_group + d_width ] , <NEWLINE> [ at_quant , at_quant ] , <NEWLINE> color = self . gray , <NEWLINE> linewidth = self . linewidth ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ax . plot ( [ at_quant , at_quant ] , <NEWLINE> [ at_group - d_width , at_group + d_width ] , <NEWLINE> color = self . gray , <NEWLINE> linewidth = self . linewidth ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _parse_excel ( self , <NEWLINE> sheet_name = <NUMBER> , <NEWLINE> header = <NUMBER> , <NEWLINE> names = None , <NEWLINE> index_col = None , <NEWLINE> usecols = None , <NEWLINE> squeeze = False , <NEWLINE> dtype = None , <NEWLINE> true_values = None , <NEWLINE> false_values = None , <NEWLINE> skiprows = None , <NEWLINE> nrows = None , <NEWLINE> na_values = None , <NEWLINE> verbose = False , <NEWLINE> parse_dates = False , <NEWLINE> date_parser = None , <NEWLINE> thousands = None , <NEWLINE> comment = None , <NEWLINE> skipfooter = <NUMBER> , <NEWLINE> convert_float = True , <NEWLINE> ** kwds ) : <NEWLINE> <NEWLINE> <TAB> _validate_header_arg ( header ) <NEWLINE> <NEWLINE> if <STRING> in kwds : <NEWLINE> <TAB> raise NotImplementedError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> if parse_dates is True and index_col is None : <NEWLINE> <TAB> warn ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> import xlrd <NEWLINE> from xlrd import ( xldate , XL_CELL_DATE , <NEWLINE> XL_CELL_ERROR , XL_CELL_BOOLEAN , <NEWLINE> XL_CELL_NUMBER ) <NEWLINE> <NEWLINE> epoch1904 = self . book . datemode <NEWLINE> <NEWLINE> def _parse_cell ( cell_contents , cell_typ ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if cell_typ == XL_CELL_DATE : <NEWLINE> <NEWLINE> <TAB> if xlrd_0_9_3 : <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> cell_contents = xldate . xldate_as_datetime ( cell_contents , <NEWLINE> epoch1904 ) <NEWLINE> <UNTAB> except OverflowError : <NEWLINE> <TAB> return cell_contents <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> year = ( cell_contents . timetuple ( ) ) [ <NUMBER> : <NUMBER> ] <NEWLINE> if ( ( not epoch1904 and year == ( <NUMBER> , <NUMBER> , <NUMBER> ) ) or <NEWLINE> ( epoch1904 and year == ( <NUMBER> , <NUMBER> , <NUMBER> ) ) ) : <NEWLINE> <TAB> cell_contents = time ( cell_contents . hour , <NEWLINE> cell_contents . minute , <NEWLINE> cell_contents . second , <NEWLINE> cell_contents . microsecond ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> dt = xldate . xldate_as_tuple ( cell_contents , epoch1904 ) <NEWLINE> <NEWLINE> <UNTAB> except xldate . XLDateTooLarge : <NEWLINE> <TAB> return cell_contents <NEWLINE> <NEWLINE> <UNTAB> if dt [ <NUMBER> ] < MINYEAR : <NEWLINE> <TAB> cell_contents = time ( * dt [ <NUMBER> : ] ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cell_contents = datetime ( * dt ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif cell_typ == XL_CELL_ERROR : <NEWLINE> <TAB> cell_contents = np . nan <NEWLINE> <UNTAB> elif cell_typ == XL_CELL_BOOLEAN : <NEWLINE> <TAB> cell_contents = bool ( cell_contents ) <NEWLINE> <UNTAB> elif convert_float and cell_typ == XL_CELL_NUMBER : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> val = int ( cell_contents ) <NEWLINE> if val == cell_contents : <NEWLINE> <TAB> cell_contents = val <NEWLINE> <UNTAB> <UNTAB> return cell_contents <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if LooseVersion ( xlrd . __VERSION__ ) >= LooseVersion ( <STRING> ) : <NEWLINE> <TAB> xlrd_0_9_3 = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> xlrd_0_9_3 = False <NEWLINE> <NEWLINE> <UNTAB> ret_dict = False <NEWLINE> <NEWLINE> <NEWLINE> if isinstance ( sheet_name , list ) : <NEWLINE> <TAB> sheets = sheet_name <NEWLINE> ret_dict = True <NEWLINE> <UNTAB> elif sheet_name is None : <NEWLINE> <TAB> sheets = self . sheet_names <NEWLINE> ret_dict = True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> sheets = [ sheet_name ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> sheets = list ( OrderedDict . fromkeys ( sheets ) . keys ( ) ) <NEWLINE> <NEWLINE> output = OrderedDict ( ) <NEWLINE> <NEWLINE> for asheetname in sheets : <NEWLINE> <TAB> if verbose : <NEWLINE> <TAB> print ( <STRING> . format ( sheet = asheetname ) ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( asheetname , compat . string_types ) : <NEWLINE> <TAB> sheet = self . book . sheet_by_name ( asheetname ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> sheet = self . book . sheet_by_index ( asheetname ) <NEWLINE> <NEWLINE> <UNTAB> data = [ ] <NEWLINE> should_parse = { } <NEWLINE> <NEWLINE> for i in range ( sheet . nrows ) : <NEWLINE> <TAB> row = [ ] <NEWLINE> for j , ( value , typ ) in enumerate ( zip ( sheet . row_values ( i ) , <NEWLINE> sheet . row_types ( i ) ) ) : <NEWLINE> <TAB> if usecols is not None and j not in should_parse : <NEWLINE> <TAB> should_parse [ j ] = self . _should_parse ( j , usecols ) <NEWLINE> <NEWLINE> <UNTAB> if usecols is None or should_parse [ j ] : <NEWLINE> <TAB> row . append ( _parse_cell ( value , typ ) ) <NEWLINE> <UNTAB> <UNTAB> data . append ( row ) <NEWLINE> <NEWLINE> <UNTAB> if sheet . nrows == <NUMBER> : <NEWLINE> <TAB> output [ asheetname ] = DataFrame ( ) <NEWLINE> continue <NEWLINE> <NEWLINE> <UNTAB> if is_list_like ( header ) and len ( header ) == <NUMBER> : <NEWLINE> <TAB> header = header [ <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> header_names = None <NEWLINE> if header is not None : <NEWLINE> <TAB> if is_list_like ( header ) : <NEWLINE> <TAB> header_names = [ ] <NEWLINE> control_row = [ True for x in data [ <NUMBER> ] ] <NEWLINE> for row in header : <NEWLINE> <TAB> if is_integer ( skiprows ) : <NEWLINE> <TAB> row += skiprows <NEWLINE> <NEWLINE> <UNTAB> data [ row ] , control_row = _fill_mi_header ( <NEWLINE> data [ row ] , control_row ) <NEWLINE> header_name , data [ row ] = _pop_header_name ( <NEWLINE> data [ row ] , index_col ) <NEWLINE> header_names . append ( header_name ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> data [ header ] = _trim_excel_header ( data [ header ] ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if is_list_like ( index_col ) : <NEWLINE> <NEWLINE> <TAB> if not is_list_like ( header ) : <NEWLINE> <TAB> offset = <NUMBER> + header <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> offset = <NUMBER> + max ( header ) <NEWLINE> <NEWLINE> <UNTAB> for col in index_col : <NEWLINE> <TAB> last = data [ offset ] [ col ] <NEWLINE> for row in range ( offset + <NUMBER> , len ( data ) ) : <NEWLINE> <TAB> if data [ row ] [ col ] == <STRING> or data [ row ] [ col ] is None : <NEWLINE> <TAB> data [ row ] [ col ] = last <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> last = data [ row ] [ col ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> has_index_names = is_list_like ( header ) and len ( header ) > <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> parser = TextParser ( data , <NEWLINE> header = header , <NEWLINE> index_col = index_col , <NEWLINE> has_index_names = has_index_names , <NEWLINE> squeeze = squeeze , <NEWLINE> dtype = dtype , <NEWLINE> true_values = true_values , <NEWLINE> false_values = false_values , <NEWLINE> skiprows = skiprows , <NEWLINE> nrows = nrows , <NEWLINE> na_values = na_values , <NEWLINE> parse_dates = parse_dates , <NEWLINE> date_parser = date_parser , <NEWLINE> thousands = thousands , <NEWLINE> comment = comment , <NEWLINE> skipfooter = skipfooter , <NEWLINE> ** kwds ) <NEWLINE> <NEWLINE> output [ asheetname ] = parser . read ( nrows = nrows ) <NEWLINE> if names is not None : <NEWLINE> <TAB> output [ asheetname ] . columns = names <NEWLINE> <UNTAB> if not squeeze or isinstance ( output [ asheetname ] , DataFrame ) : <NEWLINE> <TAB> output [ asheetname ] . columns = output [ <NEWLINE> asheetname ] . columns . set_names ( header_names ) <NEWLINE> <UNTAB> <UNTAB> except EmptyDataError : <NEWLINE> <NEWLINE> <TAB> output [ asheetname ] = DataFrame ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if ret_dict : <NEWLINE> <TAB> return output <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return output [ asheetname ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def supercedes ( a , b ) : <NEWLINE> <TAB> <NEWLINE> return len ( a ) == len ( b ) and all ( map ( issubclass , a , b ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __getitem__ ( self , key ) : <NEWLINE> <TAB> def asindices ( x ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> x = np . asarray ( x ) <NEWLINE> <NEWLINE> <NEWLINE> idx_dtype = get_index_dtype ( ( x , ) , check_contents = True ) <NEWLINE> if idx_dtype != x . dtype : <NEWLINE> <TAB> x = x . astype ( idx_dtype ) <NEWLINE> <UNTAB> <UNTAB> except : <NEWLINE> <TAB> raise IndexError ( <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return x <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def check_bounds ( indices , N ) : <NEWLINE> <TAB> if indices . size == <NUMBER> : <NEWLINE> <TAB> return ( <NUMBER> , <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> max_indx = indices . max ( ) <NEWLINE> if max_indx >= N : <NEWLINE> <TAB> raise IndexError ( <STRING> % max_indx ) <NEWLINE> <NEWLINE> <UNTAB> min_indx = indices . min ( ) <NEWLINE> if min_indx < - N : <NEWLINE> <TAB> raise IndexError ( <STRING> % ( N + min_indx ) ) <NEWLINE> <NEWLINE> <UNTAB> return min_indx , max_indx <NEWLINE> <NEWLINE> <UNTAB> def extractor ( indices , N ) : <NEWLINE> <TAB> <NEWLINE> indices = asindices ( indices ) . copy ( ) <NEWLINE> <NEWLINE> min_indx , max_indx = check_bounds ( indices , N ) <NEWLINE> <NEWLINE> if min_indx < <NUMBER> : <NEWLINE> <TAB> indices [ indices < <NUMBER> ] += N <NEWLINE> <NEWLINE> <UNTAB> indptr = np . arange ( len ( indices ) + <NUMBER> , dtype = indices . dtype ) <NEWLINE> data = np . ones ( len ( indices ) , dtype = self . dtype ) <NEWLINE> shape = ( len ( indices ) , N ) <NEWLINE> <NEWLINE> return csr_matrix ( ( data , indices , indptr ) , shape = shape , <NEWLINE> dtype = self . dtype , copy = False ) <NEWLINE> <NEWLINE> <UNTAB> row , col = self . _unpack_index ( key ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if isintlike ( row ) : <NEWLINE> <NEWLINE> <TAB> if isintlike ( col ) : <NEWLINE> <TAB> return self . _get_single_element ( row , col ) <NEWLINE> <NEWLINE> <UNTAB> elif isinstance ( col , slice ) : <NEWLINE> <TAB> return self . _get_row_slice ( row , col ) <NEWLINE> <NEWLINE> <UNTAB> elif issequence ( col ) : <NEWLINE> <TAB> P = extractor ( col , self . shape [ <NUMBER> ] ) . T <NEWLINE> return self [ row , : ] * P <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( row , slice ) : <NEWLINE> <NEWLINE> <TAB> if ( ( isintlike ( col ) and row . step in ( <NUMBER> , None ) ) or <NEWLINE> ( isinstance ( col , slice ) and <NEWLINE> col . step in ( <NUMBER> , None ) and <NEWLINE> row . step in ( <NUMBER> , None ) ) ) : <NEWLINE> <NEWLINE> <TAB> return self . _get_submatrix ( row , col ) <NEWLINE> <UNTAB> elif issequence ( col ) : <NEWLINE> <NEWLINE> <TAB> P = extractor ( col , self . shape [ <NUMBER> ] ) . T <NEWLINE> sliced = self <NEWLINE> if row != slice ( None , None , None ) : <NEWLINE> <TAB> sliced = sliced [ row , : ] <NEWLINE> <UNTAB> return sliced * P <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif issequence ( row ) : <NEWLINE> <NEWLINE> <TAB> if isintlike ( col ) or isinstance ( col , slice ) : <NEWLINE> <TAB> P = extractor ( row , self . shape [ <NUMBER> ] ) <NEWLINE> extracted = P * self <NEWLINE> if col == slice ( None , None , None ) : <NEWLINE> <TAB> return extracted <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return extracted [ : , col ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif ismatrix ( row ) and issequence ( col ) : <NEWLINE> <TAB> if len ( row [ <NUMBER> ] ) == <NUMBER> and isintlike ( row [ <NUMBER> ] [ <NUMBER> ] ) : <NEWLINE> <NEWLINE> <TAB> row = asindices ( row ) <NEWLINE> P_row = extractor ( row [ : , <NUMBER> ] , self . shape [ <NUMBER> ] ) <NEWLINE> P_col = extractor ( col , self . shape [ <NUMBER> ] ) . T <NEWLINE> return P_row * self * P_col <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not ( issequence ( col ) and issequence ( row ) ) : <NEWLINE> <NEWLINE> <TAB> row , col = self . _index_to_arrays ( row , col ) <NEWLINE> <NEWLINE> <UNTAB> row = asindices ( row ) <NEWLINE> col = asindices ( col ) <NEWLINE> if row . shape != col . shape : <NEWLINE> <TAB> raise IndexError ( <STRING> ) <NEWLINE> <UNTAB> assert row . ndim <= <NUMBER> <NEWLINE> <NEWLINE> num_samples = np . size ( row ) <NEWLINE> if num_samples == <NUMBER> : <NEWLINE> <TAB> return csr_matrix ( np . atleast_2d ( row ) . shape , dtype = self . dtype ) <NEWLINE> <UNTAB> check_bounds ( row , self . shape [ <NUMBER> ] ) <NEWLINE> check_bounds ( col , self . shape [ <NUMBER> ] ) <NEWLINE> <NEWLINE> val = np . empty ( num_samples , dtype = self . dtype ) <NEWLINE> csr_sample_values ( self . shape [ <NUMBER> ] , self . shape [ <NUMBER> ] , <NEWLINE> self . indptr , self . indices , self . data , <NEWLINE> num_samples , row . ravel ( ) , col . ravel ( ) , val ) <NEWLINE> if row . ndim == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> return np . asmatrix ( val ) <NEWLINE> <UNTAB> return self . __class__ ( val . reshape ( row . shape ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def query_pairs ( self , r , p = <NUMBER> , eps = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> results = set ( ) <NEWLINE> <NEWLINE> def traverse_checking ( node1 , rect1 , node2 , rect2 ) : <NEWLINE> <TAB> if rect1 . min_distance_rectangle ( rect2 , p ) > r / ( <NUMBER> + eps ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> elif rect1 . max_distance_rectangle ( rect2 , p ) < r * ( <NUMBER> + eps ) : <NEWLINE> <TAB> traverse_no_checking ( node1 , node2 ) <NEWLINE> <UNTAB> elif isinstance ( node1 , KDTree . leafnode ) : <NEWLINE> <TAB> if isinstance ( node2 , KDTree . leafnode ) : <NEWLINE> <NEWLINE> <TAB> if id ( node1 ) == id ( node2 ) : <NEWLINE> <TAB> d = self . data [ node2 . idx ] <NEWLINE> for i in node1 . idx : <NEWLINE> <TAB> for j in node2 . idx [ minkowski_distance ( d , self . data [ i ] , p ) <= r ] : <NEWLINE> <TAB> if i < j : <NEWLINE> <TAB> results . add ( ( i , j ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> d = self . data [ node2 . idx ] <NEWLINE> for i in node1 . idx : <NEWLINE> <TAB> for j in node2 . idx [ minkowski_distance ( d , self . data [ i ] , p ) <= r ] : <NEWLINE> <TAB> if i < j : <NEWLINE> <TAB> results . add ( ( i , j ) ) <NEWLINE> <UNTAB> elif j < i : <NEWLINE> <TAB> results . add ( ( j , i ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> less , greater = rect2 . split ( node2 . split_dim , node2 . split ) <NEWLINE> traverse_checking ( node1 , rect1 , node2 . less , less ) <NEWLINE> traverse_checking ( node1 , rect1 , node2 . greater , greater ) <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( node2 , KDTree . leafnode ) : <NEWLINE> <TAB> less , greater = rect1 . split ( node1 . split_dim , node1 . split ) <NEWLINE> traverse_checking ( node1 . less , less , node2 , rect2 ) <NEWLINE> traverse_checking ( node1 . greater , greater , node2 , rect2 ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> less1 , greater1 = rect1 . split ( node1 . split_dim , node1 . split ) <NEWLINE> less2 , greater2 = rect2 . split ( node2 . split_dim , node2 . split ) <NEWLINE> traverse_checking ( node1 . less , less1 , node2 . less , less2 ) <NEWLINE> traverse_checking ( node1 . less , less1 , node2 . greater , greater2 ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if id ( node1 ) != id ( node2 ) : <NEWLINE> <TAB> traverse_checking ( node1 . greater , greater1 , node2 . less , less2 ) <NEWLINE> <NEWLINE> <UNTAB> traverse_checking ( node1 . greater , greater1 , node2 . greater , greater2 ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def traverse_no_checking ( node1 , node2 ) : <NEWLINE> <TAB> if isinstance ( node1 , KDTree . leafnode ) : <NEWLINE> <TAB> if isinstance ( node2 , KDTree . leafnode ) : <NEWLINE> <NEWLINE> <TAB> if id ( node1 ) == id ( node2 ) : <NEWLINE> <TAB> for i in node1 . idx : <NEWLINE> <TAB> for j in node2 . idx : <NEWLINE> <TAB> if i < j : <NEWLINE> <TAB> results . add ( ( i , j ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for i in node1 . idx : <NEWLINE> <TAB> for j in node2 . idx : <NEWLINE> <TAB> if i < j : <NEWLINE> <TAB> results . add ( ( i , j ) ) <NEWLINE> <UNTAB> elif j < i : <NEWLINE> <TAB> results . add ( ( j , i ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> traverse_no_checking ( node1 , node2 . less ) <NEWLINE> traverse_no_checking ( node1 , node2 . greater ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if id ( node1 ) == id ( node2 ) : <NEWLINE> <TAB> traverse_no_checking ( node1 . less , node2 . less ) <NEWLINE> traverse_no_checking ( node1 . less , node2 . greater ) <NEWLINE> traverse_no_checking ( node1 . greater , node2 . greater ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> traverse_no_checking ( node1 . less , node2 ) <NEWLINE> traverse_no_checking ( node1 . greater , node2 ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> traverse_checking ( self . tree , Rectangle ( self . maxes , self . mins ) , <NEWLINE> self . tree , Rectangle ( self . maxes , self . mins ) ) <NEWLINE> return results <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def hermeval ( x , c , tensor = True ) : <NEWLINE> <TAB> <NEWLINE> c = np . array ( c , ndmin = <NUMBER> , copy = <NUMBER> ) <NEWLINE> if c . dtype . char in <STRING> : <NEWLINE> <TAB> c = c . astype ( np . double ) <NEWLINE> <UNTAB> if isinstance ( x , ( tuple , list ) ) : <NEWLINE> <TAB> x = np . asarray ( x ) <NEWLINE> <UNTAB> if isinstance ( x , np . ndarray ) and tensor : <NEWLINE> <TAB> c = c . reshape ( c . shape + ( <NUMBER> , ) * x . ndim ) <NEWLINE> <NEWLINE> <UNTAB> if len ( c ) == <NUMBER> : <NEWLINE> <TAB> c0 = c [ <NUMBER> ] <NEWLINE> c1 = <NUMBER> <NEWLINE> <UNTAB> elif len ( c ) == <NUMBER> : <NEWLINE> <TAB> c0 = c [ <NUMBER> ] <NEWLINE> c1 = c [ <NUMBER> ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> nd = len ( c ) <NEWLINE> c0 = c [ - <NUMBER> ] <NEWLINE> c1 = c [ - <NUMBER> ] <NEWLINE> for i in range ( <NUMBER> , len ( c ) + <NUMBER> ) : <NEWLINE> <TAB> tmp = c0 <NEWLINE> nd = nd - <NUMBER> <NEWLINE> c0 = c [ - i ] - c1 * ( nd - <NUMBER> ) <NEWLINE> c1 = tmp + c1 * x <NEWLINE> <UNTAB> <UNTAB> return c0 + c1 * x <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def are_concurrent ( * lines ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> common_points = Intersection ( * lines ) <NEWLINE> if common_points . is_FiniteSet and len ( common_points ) == <NUMBER> : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def evaluate ( self , env , engine , parser , term_type , eval_in_python ) : <NEWLINE> <TAB> <NEWLINE> if engine == <STRING> : <NEWLINE> <TAB> res = self ( env ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> left = self . lhs . evaluate ( env , engine = engine , parser = parser , <NEWLINE> term_type = term_type , <NEWLINE> eval_in_python = eval_in_python ) <NEWLINE> right = self . rhs . evaluate ( env , engine = engine , parser = parser , <NEWLINE> term_type = term_type , <NEWLINE> eval_in_python = eval_in_python ) <NEWLINE> <NEWLINE> <NEWLINE> if self . op in eval_in_python : <NEWLINE> <TAB> res = self . func ( left . value , right . value ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> res = pd . eval ( self , local_dict = env , engine = engine , <NEWLINE> parser = parser ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> name = env . add_tmp ( res ) <NEWLINE> return term_type ( name , env = env ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def lookup ( self , keys , name = None ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def assert_attr_equal ( attr , left , right , obj = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> left_attr = getattr ( left , attr ) <NEWLINE> right_attr = getattr ( right , attr ) <NEWLINE> <NEWLINE> if left_attr is right_attr : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> elif ( is_number ( left_attr ) and np . isnan ( left_attr ) and <NEWLINE> is_number ( right_attr ) and np . isnan ( right_attr ) ) : <NEWLINE> <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> result = left_attr == right_attr <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <NEWLINE> <TAB> result = False <NEWLINE> <UNTAB> if not isinstance ( result , bool ) : <NEWLINE> <TAB> result = result . all ( ) <NEWLINE> <NEWLINE> <UNTAB> if result : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> msg = <STRING> . format ( attr = attr ) <NEWLINE> raise_assert_detail ( obj , msg , left_attr , right_attr ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def bilinear_zpk ( z , p , k , fs ) : <NEWLINE> <TAB> <NEWLINE> z = atleast_1d ( z ) <NEWLINE> p = atleast_1d ( p ) <NEWLINE> <NEWLINE> degree = _relative_degree ( z , p ) <NEWLINE> <NEWLINE> fs2 = <NUMBER> * fs <NEWLINE> <NEWLINE> <NEWLINE> z_z = ( fs2 + z ) / ( fs2 - z ) <NEWLINE> p_z = ( fs2 + p ) / ( fs2 - p ) <NEWLINE> <NEWLINE> <NEWLINE> z_z = append ( z_z , - ones ( degree ) ) <NEWLINE> <NEWLINE> <NEWLINE> k_z = k * real ( prod ( fs2 - z ) / prod ( fs2 - p ) ) <NEWLINE> <NEWLINE> return z_z , p_z , k_z <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _evaluate_build_graph ( self , input_fn , hooks = None , checkpoint_path = None ) : <NEWLINE> <TAB> <NEWLINE> random_seed . set_random_seed ( self . _config . tf_random_seed ) <NEWLINE> self . _create_and_assert_global_step ( ops . get_default_graph ( ) ) <NEWLINE> <NEWLINE> if self . _eval_distribution : <NEWLINE> <TAB> ( scaffold , evaluation_hooks , input_hooks , update_op , eval_dict ) = ( <NEWLINE> self . _call_model_fn_eval_distributed ( input_fn , self . config ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> ( scaffold , evaluation_hooks , input_hooks , update_op , eval_dict ) = ( <NEWLINE> self . _call_model_fn_eval ( input_fn , self . config ) ) <NEWLINE> <NEWLINE> <UNTAB> global_step_tensor = training_util . get_global_step ( ops . get_default_graph ( ) ) <NEWLINE> <NEWLINE> self . _maybe_warm_start ( checkpoint_path ) <NEWLINE> <NEWLINE> if ops . GraphKeys . GLOBAL_STEP in eval_dict : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> eval_dict [ ops . GraphKeys . GLOBAL_STEP ] = global_step_tensor <NEWLINE> <NEWLINE> all_hooks = list ( input_hooks ) <NEWLINE> all_hooks . extend ( hooks ) <NEWLINE> all_hooks . extend ( list ( evaluation_hooks or [ ] ) ) <NEWLINE> <NEWLINE> <NEWLINE> if scaffold and scaffold . local_init_op : <NEWLINE> <NEWLINE> <TAB> evaluation . _get_or_create_eval_step ( ) <NEWLINE> <NEWLINE> scaffold = monitored_session . Scaffold ( <NEWLINE> local_init_op = control_flow_ops . group ( <NEWLINE> scaffold . local_init_op , <NEWLINE> monitored_session . Scaffold . default_local_init_op ( ) ) , <NEWLINE> copy_from_scaffold = scaffold <NEWLINE> ) <NEWLINE> <NEWLINE> <UNTAB> return scaffold , update_op , eval_dict , all_hooks <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _functions ( expr , x ) : <NEWLINE> <TAB> <NEWLINE> from sympy import Function <NEWLINE> return set ( e . func for e in expr . atoms ( Function ) if x in e . free_symbols ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _unevaluated_Add ( * args ) : <NEWLINE> <TAB> <NEWLINE> args = list ( args ) <NEWLINE> newargs = [ ] <NEWLINE> co = S . Zero <NEWLINE> while args : <NEWLINE> <TAB> a = args . pop ( ) <NEWLINE> if a . is_Add : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> args . extend ( a . args ) <NEWLINE> <UNTAB> elif a . is_Number : <NEWLINE> <TAB> co += a <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> newargs . append ( a ) <NEWLINE> <UNTAB> <UNTAB> _addsort ( newargs ) <NEWLINE> if co : <NEWLINE> <TAB> newargs . insert ( <NUMBER> , co ) <NEWLINE> <UNTAB> return Add . _from_args ( newargs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def real_div_eager_fallback ( x , y , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ x , y ] , _ctx ) <NEWLINE> ( x , y ) = _inputs_T <NEWLINE> _inputs_flat = [ x , y ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , attrs = _attrs , <NEWLINE> ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _fix_names ( field_spec ) : <NEWLINE> <TAB> <NEWLINE> names = field_spec [ <STRING> ] <NEWLINE> for i , name in enumerate ( names ) : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> j = <NUMBER> <NEWLINE> while True : <NEWLINE> <TAB> name = <STRING> . format ( j ) <NEWLINE> if name not in names : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> j = j + <NUMBER> <NEWLINE> <UNTAB> names [ i ] = name <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def quantized_relu6_eager_fallback ( features , min_features , max_features , out_type = _dtypes . quint8 , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> if out_type is None : <NEWLINE> <TAB> out_type = _dtypes . quint8 <NEWLINE> <UNTAB> out_type = _execute . make_type ( out_type , <STRING> ) <NEWLINE> _attr_Tinput , ( features , ) = _execute . args_to_matching_eager ( [ features ] , _ctx ) <NEWLINE> min_features = _ops . convert_to_tensor ( min_features , _dtypes . float32 ) <NEWLINE> max_features = _ops . convert_to_tensor ( max_features , _dtypes . float32 ) <NEWLINE> _inputs_flat = [ features , min_features , max_features ] <NEWLINE> _attrs = ( <STRING> , _attr_Tinput , <STRING> , out_type ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result = _QuantizedRelu6Output . _make ( _result ) <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def ode_Liouville ( eq , func , order , match ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> x = func . args [ <NUMBER> ] <NEWLINE> f = func . func <NEWLINE> r = match <NEWLINE> y = r [ <STRING> ] <NEWLINE> C1 , C2 = get_numbered_constants ( eq , num = <NUMBER> ) <NEWLINE> int = Integral ( exp ( Integral ( r [ <STRING> ] , y ) ) , ( y , None , f ( x ) ) ) <NEWLINE> sol = Eq ( int + C1 * Integral ( exp ( - Integral ( r [ <STRING> ] , x ) ) , x ) + C2 , <NUMBER> ) <NEWLINE> return sol <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _make_tensor_descriptor_array ( xs ) : <NEWLINE> <TAB> <NEWLINE> descs = [ ] <NEWLINE> for x in xs : <NEWLINE> <TAB> if x . ndim < <NUMBER> : <NEWLINE> <TAB> shape = x . shape + ( <NUMBER> , ) * ( <NUMBER> - x . ndim ) <NEWLINE> x = x . reshape ( shape ) <NEWLINE> <UNTAB> desc = cudnn . create_tensor_nd_descriptor ( x ) <NEWLINE> descs . append ( desc ) <NEWLINE> <UNTAB> return PointerArray ( [ d . value for d in descs ] , descs ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def read_config ( pkgname , dirs = None ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> return _CACHE [ pkgname ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> v = _read_config_imp ( pkg_to_filename ( pkgname ) , dirs ) <NEWLINE> _CACHE [ pkgname ] = v <NEWLINE> return v <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def get_config_hash ( ) : <NEWLINE> <TAB> <NEWLINE> all_opts = sorted ( [ c for c in _config_var_list if c . in_c_key ] , <NEWLINE> key = lambda cv : cv . fullname ) <NEWLINE> return theano . gof . utils . hash_from_code ( <STRING> . join ( <NEWLINE> [ <STRING> % ( cv . fullname , cv . __get__ ( True , None ) ) for cv in all_opts ] ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def svd_flip ( u , v , u_based_decision = True ) : <NEWLINE> <TAB> <NEWLINE> if u_based_decision : <NEWLINE> <NEWLINE> <TAB> max_abs_cols = np . argmax ( np . abs ( u ) , axis = <NUMBER> ) <NEWLINE> signs = np . sign ( u [ max_abs_cols , xrange ( u . shape [ <NUMBER> ] ) ] ) <NEWLINE> u *= signs <NEWLINE> v *= signs [ : , np . newaxis ] <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> max_abs_rows = np . argmax ( np . abs ( v ) , axis = <NUMBER> ) <NEWLINE> signs = np . sign ( v [ xrange ( v . shape [ <NUMBER> ] ) , max_abs_rows ] ) <NEWLINE> u *= signs <NEWLINE> v *= signs [ : , np . newaxis ] <NEWLINE> <UNTAB> return u , v <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def update ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> self . params . update ( * args , ** kwargs ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def dot ( self , b ) : <NEWLINE> <TAB> <NEWLINE> from . dense import Matrix <NEWLINE> <NEWLINE> if not isinstance ( b , MatrixBase ) : <NEWLINE> <TAB> if is_sequence ( b ) : <NEWLINE> <TAB> if len ( b ) != self . cols and len ( b ) != self . rows : <NEWLINE> <TAB> raise ShapeError ( <NEWLINE> <STRING> % ( <NEWLINE> self . shape , len ( b ) ) ) <NEWLINE> <UNTAB> return self . dot ( Matrix ( b ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> % <NEWLINE> type ( b ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> mat = self <NEWLINE> if ( <NUMBER> not in mat . shape ) or ( <NUMBER> not in b . shape ) : <NEWLINE> <TAB> SymPyDeprecationWarning ( <NEWLINE> feature = <STRING> , <NEWLINE> issue = <NUMBER> , <NEWLINE> deprecated_since_version = <STRING> , <NEWLINE> useinstead = <STRING> ) . warn ( ) <NEWLINE> return mat . _legacy_array_dot ( b ) <NEWLINE> <UNTAB> if len ( mat ) != len ( b ) : <NEWLINE> <TAB> raise ShapeError ( <STRING> % ( self . shape , b . shape ) ) <NEWLINE> <UNTAB> n = len ( mat ) <NEWLINE> if mat . shape != ( <NUMBER> , n ) : <NEWLINE> <TAB> mat = mat . reshape ( <NUMBER> , n ) <NEWLINE> <UNTAB> if b . shape != ( n , <NUMBER> ) : <NEWLINE> <TAB> b = b . reshape ( n , <NUMBER> ) <NEWLINE> <NEWLINE> <UNTAB> return ( mat * b ) [ <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def kendalltau_seasonal ( x ) : <NEWLINE> <TAB> <NEWLINE> x = ma . array ( x , subok = True , copy = False , ndmin = <NUMBER> ) <NEWLINE> ( n , m ) = x . shape <NEWLINE> n_p = x . count ( <NUMBER> ) <NEWLINE> <NEWLINE> S_szn = sum ( msign ( x [ i : ] - x [ i ] ) . sum ( <NUMBER> ) for i in range ( n ) ) <NEWLINE> S_tot = S_szn . sum ( ) <NEWLINE> <NEWLINE> n_tot = x . count ( ) <NEWLINE> ties = count_tied_groups ( x . compressed ( ) ) <NEWLINE> corr_ties = sum ( v * k * ( k - <NUMBER> ) for ( k , v ) in iteritems ( ties ) ) <NEWLINE> denom_tot = ma . sqrt ( <NUMBER> * n_tot * ( n_tot - <NUMBER> ) * ( n_tot * ( n_tot - <NUMBER> ) - corr_ties ) ) / <NUMBER> <NEWLINE> <NEWLINE> R = rankdata ( x , axis = <NUMBER> , use_missing = True ) <NEWLINE> K = ma . empty ( ( m , m ) , dtype = int ) <NEWLINE> covmat = ma . empty ( ( m , m ) , dtype = float ) <NEWLINE> denom_szn = ma . empty ( m , dtype = float ) <NEWLINE> for j in range ( m ) : <NEWLINE> <TAB> ties_j = count_tied_groups ( x [ : , j ] . compressed ( ) ) <NEWLINE> corr_j = sum ( v * k * ( k - <NUMBER> ) for ( k , v ) in iteritems ( ties_j ) ) <NEWLINE> cmb = n_p [ j ] * ( n_p [ j ] - <NUMBER> ) <NEWLINE> for k in range ( j , m , <NUMBER> ) : <NEWLINE> <TAB> K [ j , k ] = sum ( msign ( ( x [ i : , j ] - x [ i , j ] ) * ( x [ i : , k ] - x [ i , k ] ) ) . sum ( ) <NEWLINE> for i in range ( n ) ) <NEWLINE> covmat [ j , k ] = ( K [ j , k ] + <NUMBER> * ( R [ : , j ] * R [ : , k ] ) . sum ( ) - <NEWLINE> n * ( n_p [ j ] + <NUMBER> ) * ( n_p [ k ] + <NUMBER> ) ) / <NUMBER> <NEWLINE> K [ k , j ] = K [ j , k ] <NEWLINE> covmat [ k , j ] = covmat [ j , k ] <NEWLINE> <NEWLINE> <UNTAB> denom_szn [ j ] = ma . sqrt ( cmb * ( cmb - corr_j ) ) / <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> var_szn = covmat . diagonal ( ) <NEWLINE> <NEWLINE> z_szn = msign ( S_szn ) * ( abs ( S_szn ) - <NUMBER> ) / ma . sqrt ( var_szn ) <NEWLINE> z_tot_ind = msign ( S_tot ) * ( abs ( S_tot ) - <NUMBER> ) / ma . sqrt ( var_szn . sum ( ) ) <NEWLINE> z_tot_dep = msign ( S_tot ) * ( abs ( S_tot ) - <NUMBER> ) / ma . sqrt ( covmat . sum ( ) ) <NEWLINE> <NEWLINE> prob_szn = special . erfc ( abs ( z_szn ) / np . sqrt ( <NUMBER> ) ) <NEWLINE> prob_tot_ind = special . erfc ( abs ( z_tot_ind ) / np . sqrt ( <NUMBER> ) ) <NEWLINE> prob_tot_dep = special . erfc ( abs ( z_tot_dep ) / np . sqrt ( <NUMBER> ) ) <NEWLINE> <NEWLINE> chi2_tot = ( z_szn * z_szn ) . sum ( ) <NEWLINE> chi2_trd = m * z_szn . mean ( ) ** <NUMBER> <NEWLINE> output = { <STRING> : S_szn / denom_szn , <NEWLINE> <STRING> : S_tot / denom_tot , <NEWLINE> <STRING> : S_tot / denom_szn . sum ( ) , <NEWLINE> <STRING> : prob_szn , <NEWLINE> <STRING> : prob_tot_ind , <NEWLINE> <STRING> : prob_tot_dep , <NEWLINE> <STRING> : chi2_tot , <NEWLINE> <STRING> : chi2_trd , <NEWLINE> } <NEWLINE> return output <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ contextmanager <NEWLINE> def assuming ( * assumptions ) : <NEWLINE> <TAB> <NEWLINE> old_global_assumptions = global_assumptions . copy ( ) <NEWLINE> global_assumptions . update ( assumptions ) <NEWLINE> try : <NEWLINE> <TAB> yield <NEWLINE> <UNTAB> finally : <NEWLINE> <TAB> global_assumptions . clear ( ) <NEWLINE> global_assumptions . update ( old_global_assumptions ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def connection_pattern ( self , node ) : <NEWLINE> <TAB> <NEWLINE> if self . _connection_pattern is not None : <NEWLINE> <TAB> return self . _connection_pattern <NEWLINE> <NEWLINE> <UNTAB> inp_len = len ( self . local_inputs ) <NEWLINE> out_len = len ( self . local_outputs ) <NEWLINE> cpmat_self = io_connection_pattern ( <NEWLINE> self . local_inputs , self . local_outputs ) <NEWLINE> <NEWLINE> lop_op = self . get_lop_op ( ) <NEWLINE> cpmat_grad = io_connection_pattern ( <NEWLINE> lop_op . local_inputs [ inp_len : ] , <NEWLINE> lop_op . local_outputs ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for i , t in enumerate ( self . _lop_op_stypes_l ) : <NEWLINE> <TAB> if t is not None : <NEWLINE> <TAB> if isinstance ( t . type , DisconnectedType ) : <NEWLINE> <TAB> for o in range ( out_len ) : <NEWLINE> <TAB> cpmat_self [ i ] [ o ] = False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> for o in range ( out_len ) : <NEWLINE> <TAB> cpmat_self [ i ] [ o ] |= cpmat_grad [ o ] [ i ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return list ( map ( list , cpmat_self ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def reload_library ( ) : <NEWLINE> <TAB> <NEWLINE> global library <NEWLINE> available [ : ] = library = update_user_library ( _base_library ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def trigsimp ( self , ** args ) : <NEWLINE> <TAB> <NEWLINE> from sympy . simplify import trigsimp <NEWLINE> return trigsimp ( self , ** args ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def generic_bfs_edges ( G , source , neighbors = None , depth_limit = None ) : <NEWLINE> <TAB> <NEWLINE> visited = { source } <NEWLINE> if depth_limit is None : <NEWLINE> <TAB> depth_limit = len ( G ) <NEWLINE> <UNTAB> queue = deque ( [ ( source , depth_limit , neighbors ( source ) ) ] ) <NEWLINE> while queue : <NEWLINE> <TAB> parent , depth_now , children = queue [ <NUMBER> ] <NEWLINE> try : <NEWLINE> <TAB> child = next ( children ) <NEWLINE> if child not in visited : <NEWLINE> <TAB> yield parent , child <NEWLINE> visited . add ( child ) <NEWLINE> if depth_now > <NUMBER> : <NEWLINE> <TAB> queue . append ( ( child , depth_now - <NUMBER> , neighbors ( child ) ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> except StopIteration : <NEWLINE> <TAB> queue . popleft ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_canvas ( self , canvas ) : <NEWLINE> <TAB> <NEWLINE> self . canvas = canvas <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def _add_numeric_methods_disabled ( cls ) : <NEWLINE> <TAB> <NEWLINE> cls . __pow__ = make_invalid_op ( <STRING> ) <NEWLINE> cls . __rpow__ = make_invalid_op ( <STRING> ) <NEWLINE> cls . __mul__ = make_invalid_op ( <STRING> ) <NEWLINE> cls . __rmul__ = make_invalid_op ( <STRING> ) <NEWLINE> cls . __floordiv__ = make_invalid_op ( <STRING> ) <NEWLINE> cls . __rfloordiv__ = make_invalid_op ( <STRING> ) <NEWLINE> cls . __truediv__ = make_invalid_op ( <STRING> ) <NEWLINE> cls . __rtruediv__ = make_invalid_op ( <STRING> ) <NEWLINE> if not compat . PY3 : <NEWLINE> <TAB> cls . __div__ = make_invalid_op ( <STRING> ) <NEWLINE> cls . __rdiv__ = make_invalid_op ( <STRING> ) <NEWLINE> <UNTAB> cls . __mod__ = make_invalid_op ( <STRING> ) <NEWLINE> cls . __divmod__ = make_invalid_op ( <STRING> ) <NEWLINE> cls . __neg__ = make_invalid_op ( <STRING> ) <NEWLINE> cls . __pos__ = make_invalid_op ( <STRING> ) <NEWLINE> cls . __abs__ = make_invalid_op ( <STRING> ) <NEWLINE> cls . __inv__ = make_invalid_op ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def hilbert ( x , _cache = _cache ) : <NEWLINE> <TAB> <NEWLINE> tmp = asarray ( x ) <NEWLINE> if iscomplexobj ( tmp ) : <NEWLINE> <TAB> return hilbert ( tmp . real ) + <NUMBER> * hilbert ( tmp . imag ) <NEWLINE> <UNTAB> n = len ( x ) <NEWLINE> omega = _cache . get ( n ) <NEWLINE> if omega is None : <NEWLINE> <TAB> if len ( _cache ) > <NUMBER> : <NEWLINE> <TAB> while _cache : <NEWLINE> <TAB> _cache . popitem ( ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def kernel ( k ) : <NEWLINE> <TAB> if k > <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> elif k < <NUMBER> : <NEWLINE> <TAB> return - <NUMBER> <NEWLINE> <UNTAB> return <NUMBER> <NEWLINE> <UNTAB> omega = convolve . init_convolution_kernel ( n , kernel , d = <NUMBER> ) <NEWLINE> _cache [ n ] = omega <NEWLINE> <UNTAB> overwrite_x = _datacopied ( tmp , x ) <NEWLINE> return convolve . convolve ( tmp , omega , swap_real_imag = <NUMBER> , overwrite_x = overwrite_x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def is_bound ( self ) : <NEWLINE> <TAB> <NEWLINE> return ( hasattr ( self . context , <STRING> ) and <NEWLINE> self . context . _engine is not None ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def batch_shuffle ( index_array , batch_size ) : <NEWLINE> <TAB> <NEWLINE> batch_count = int ( len ( index_array ) / batch_size ) <NEWLINE> <NEWLINE> <NEWLINE> last_batch = index_array [ batch_count * batch_size : ] <NEWLINE> index_array = index_array [ : batch_count * batch_size ] <NEWLINE> index_array = index_array . reshape ( ( batch_count , batch_size ) ) <NEWLINE> np . random . shuffle ( index_array ) <NEWLINE> index_array = index_array . flatten ( ) <NEWLINE> return np . append ( index_array , last_batch ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _init_ipython_printing ( ip , stringify_func , use_latex , euler , forecolor , <NEWLINE> backcolor , fontsize , latex_mode , print_builtin , <NEWLINE> latex_printer , ** settings ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> from IPython . lib . latextools import latex_to_png <NEWLINE> <UNTAB> except ImportError : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> preamble = <STRING> <STRING> <STRING> <NEWLINE> if euler : <NEWLINE> <TAB> addpackages = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> addpackages = <STRING> <NEWLINE> <UNTAB> preamble = preamble % ( fontsize , addpackages ) <NEWLINE> <NEWLINE> imagesize = <STRING> <NEWLINE> offset = <STRING> <NEWLINE> resolution = <NUMBER> <NEWLINE> dvi = <STRING> % ( <NEWLINE> imagesize , resolution , backcolor , forecolor , offset ) <NEWLINE> dvioptions = dvi . split ( ) <NEWLINE> debug ( <STRING> , dvioptions ) <NEWLINE> debug ( <STRING> , preamble ) <NEWLINE> <NEWLINE> latex = latex_printer or default_latex <NEWLINE> <NEWLINE> def _print_plain ( arg , p , cycle ) : <NEWLINE> <TAB> <NEWLINE> if _can_print_latex ( arg ) : <NEWLINE> <TAB> p . text ( stringify_func ( arg ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> p . text ( IPython . lib . pretty . pretty ( arg ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def _preview_wrapper ( o ) : <NEWLINE> <TAB> exprbuffer = BytesIO ( ) <NEWLINE> try : <NEWLINE> <TAB> preview ( o , output = <STRING> , viewer = <STRING> , <NEWLINE> outputbuffer = exprbuffer , preamble = preamble , <NEWLINE> dvioptions = dvioptions ) <NEWLINE> <UNTAB> except Exception as e : <NEWLINE> <NEWLINE> <TAB> debug ( <STRING> , <STRING> , <NEWLINE> repr ( e ) ) <NEWLINE> raise <NEWLINE> <UNTAB> return exprbuffer . getvalue ( ) <NEWLINE> <NEWLINE> <UNTAB> def _matplotlib_wrapper ( o ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> o = o . replace ( <STRING> , <STRING> ) <NEWLINE> o = o . replace ( <STRING> , <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> return latex_to_png ( o ) <NEWLINE> <UNTAB> except ValueError as e : <NEWLINE> <TAB> debug ( <STRING> , repr ( e ) ) <NEWLINE> return None <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def _can_print_latex ( o ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> try : <NEWLINE> <TAB> from sympy import Basic <NEWLINE> from sympy . matrices import MatrixBase <NEWLINE> from sympy . physics . vector import Vector , Dyadic <NEWLINE> from sympy . tensor . array import NDimArray <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> builtin_types = ( list , tuple , set , frozenset ) <NEWLINE> if isinstance ( o , builtin_types ) : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if ( type ( o ) . __str__ not in ( i . __str__ for i in builtin_types ) or <NEWLINE> type ( o ) . __repr__ not in ( i . __repr__ for i in builtin_types ) ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> return all ( _can_print_latex ( i ) for i in o ) <NEWLINE> <UNTAB> elif isinstance ( o , dict ) : <NEWLINE> <TAB> return all ( _can_print_latex ( i ) and _can_print_latex ( o [ i ] ) for i in o ) <NEWLINE> <UNTAB> elif isinstance ( o , bool ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> elif isinstance ( o , ( Basic , MatrixBase , Vector , Dyadic , NDimArray ) ) : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> elif isinstance ( o , ( float , integer_types ) ) and print_builtin : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> return False <NEWLINE> <UNTAB> except RuntimeError : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def _print_latex_png ( o ) : <NEWLINE> <TAB> <NEWLINE> if _can_print_latex ( o ) : <NEWLINE> <TAB> s = latex ( o , mode = latex_mode , ** settings ) <NEWLINE> try : <NEWLINE> <TAB> return _preview_wrapper ( s ) <NEWLINE> <UNTAB> except RuntimeError as e : <NEWLINE> <TAB> debug ( <STRING> , repr ( e ) , <NEWLINE> <STRING> ) <NEWLINE> if latex_mode != <STRING> : <NEWLINE> <TAB> s = latex ( o , mode = <STRING> , ** settings ) <NEWLINE> <UNTAB> return _matplotlib_wrapper ( s ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> def _print_latex_matplotlib ( o ) : <NEWLINE> <TAB> <NEWLINE> if _can_print_latex ( o ) : <NEWLINE> <TAB> s = latex ( o , mode = <STRING> , ** settings ) <NEWLINE> return _matplotlib_wrapper ( s ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def _print_latex_text ( o ) : <NEWLINE> <TAB> <NEWLINE> if _can_print_latex ( o ) : <NEWLINE> <TAB> s = latex ( o , mode = <STRING> , ** settings ) <NEWLINE> s = s . strip ( <STRING> ) <NEWLINE> return <STRING> % s <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def _result_display ( self , arg ) : <NEWLINE> <TAB> <NEWLINE> if self . rc . pprint : <NEWLINE> <TAB> out = stringify_func ( arg ) <NEWLINE> <NEWLINE> if <STRING> in out : <NEWLINE> <TAB> print <NEWLINE> <NEWLINE> <UNTAB> print ( out ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> print ( repr ( arg ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> import IPython <NEWLINE> if V ( IPython . __version__ ) >= <STRING> : <NEWLINE> <TAB> from sympy . core . basic import Basic <NEWLINE> from sympy . matrices . matrices import MatrixBase <NEWLINE> from sympy . physics . vector import Vector , Dyadic <NEWLINE> from sympy . tensor . array import NDimArray <NEWLINE> <NEWLINE> printable_types = [ Basic , MatrixBase , float , tuple , list , set , <NEWLINE> frozenset , dict , Vector , Dyadic , NDimArray ] + list ( integer_types ) <NEWLINE> <NEWLINE> plaintext_formatter = ip . display_formatter . formatters [ <STRING> ] <NEWLINE> <NEWLINE> for cls in printable_types : <NEWLINE> <TAB> plaintext_formatter . for_type ( cls , _print_plain ) <NEWLINE> <NEWLINE> <UNTAB> png_formatter = ip . display_formatter . formatters [ <STRING> ] <NEWLINE> if use_latex in ( True , <STRING> ) : <NEWLINE> <TAB> debug ( <STRING> ) <NEWLINE> for cls in printable_types : <NEWLINE> <TAB> png_formatter . for_type ( cls , _print_latex_png ) <NEWLINE> <UNTAB> <UNTAB> elif use_latex == <STRING> : <NEWLINE> <TAB> debug ( <STRING> ) <NEWLINE> for cls in printable_types : <NEWLINE> <TAB> png_formatter . for_type ( cls , _print_latex_matplotlib ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> debug ( <STRING> ) <NEWLINE> for cls in printable_types : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if cls in png_formatter . type_printers : <NEWLINE> <TAB> png_formatter . type_printers . pop ( cls ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> latex_formatter = ip . display_formatter . formatters [ <STRING> ] <NEWLINE> if use_latex in ( True , <STRING> ) : <NEWLINE> <TAB> debug ( <STRING> ) <NEWLINE> for cls in printable_types : <NEWLINE> <TAB> latex_formatter . for_type ( cls , _print_latex_text ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> debug ( <STRING> ) <NEWLINE> for cls in printable_types : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> if cls in latex_formatter . type_printers : <NEWLINE> <TAB> latex_formatter . type_printers . pop ( cls ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> ip . set_hook ( <STRING> , _result_display ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def commit_twophase ( self , conn , commit_twophase , xid , is_prepared ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return commit_twophase ( xid , is_prepared ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def cumulative_distribution ( image , nbins = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> hist , bin_centers = histogram ( image , nbins ) <NEWLINE> img_cdf = hist . cumsum ( ) <NEWLINE> img_cdf = img_cdf / float ( img_cdf [ - <NUMBER> ] ) <NEWLINE> return img_cdf , bin_centers <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def make_session_run_hook ( self , is_chief , task_index ) : <NEWLINE> <TAB> <NEWLINE> return _ElasticAverageOptimizerHook ( self , is_chief , task_index ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def stop_on_exception ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _coord . stop_on_exception ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , estimator , X , y_true , sample_weight = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> y_pred = estimator . predict ( X ) <NEWLINE> if sample_weight is not None : <NEWLINE> <TAB> return self . _sign * self . _score_func ( y_true , y_pred , <NEWLINE> sample_weight = sample_weight , <NEWLINE> ** self . _kwargs ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return self . _sign * self . _score_func ( y_true , y_pred , <NEWLINE> ** self . _kwargs ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def dimpulse ( system , x0 = None , t = None , n = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( system , dlti ) : <NEWLINE> <TAB> system = system . _as_ss ( ) <NEWLINE> <UNTAB> elif isinstance ( system , lti ) : <NEWLINE> <TAB> raise AttributeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> system = dlti ( * system [ : - <NUMBER> ] , dt = system [ - <NUMBER> ] ) . _as_ss ( ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if n is None : <NEWLINE> <TAB> n = <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if t is None : <NEWLINE> <TAB> t = np . linspace ( <NUMBER> , n * system . dt , n , endpoint = False ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> t = np . asarray ( t ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> yout = None <NEWLINE> for i in range ( <NUMBER> , system . inputs ) : <NEWLINE> <TAB> u = np . zeros ( ( t . shape [ <NUMBER> ] , system . inputs ) ) <NEWLINE> u [ <NUMBER> , i ] = <NUMBER> <NEWLINE> <NEWLINE> one_output = dlsim ( system , u , t = t , x0 = x0 ) <NEWLINE> <NEWLINE> if yout is None : <NEWLINE> <TAB> yout = ( one_output [ <NUMBER> ] , ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> yout = yout + ( one_output [ <NUMBER> ] , ) <NEWLINE> <NEWLINE> <UNTAB> tout = one_output [ <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> return tout , yout <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def l2_normalize ( x , axis = None ) : <NEWLINE> <TAB> <NEWLINE> return nn . l2_normalize ( x , axis = axis ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def evaluate ( self , delay_secs = None , name = None ) : <NEWLINE> <TAB> <NEWLINE> if delay_secs is None : <NEWLINE> <TAB> delay_secs = self . _eval_delay_secs <NEWLINE> <NEWLINE> <UNTAB> if delay_secs : <NEWLINE> <TAB> logging . info ( <STRING> , delay_secs ) <NEWLINE> time . sleep ( delay_secs ) <NEWLINE> <NEWLINE> <UNTAB> return self . _call_evaluate ( <NEWLINE> input_fn = self . _eval_input_fn , <NEWLINE> steps = self . _eval_steps , <NEWLINE> metrics = self . _eval_metrics , <NEWLINE> name = ( name or <STRING> ) , <NEWLINE> hooks = self . _eval_hooks ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def expovariate ( self , lambd ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> return - _log ( <NUMBER> - self . random ( ) ) / lambd <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _check_info ( info , driver , positive = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if info < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> % ( - info , driver ) ) <NEWLINE> <UNTAB> if info > <NUMBER> and positive : <NEWLINE> <TAB> raise LinAlgError ( ( <STRING> + positive ) % ( driver , info , ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def sufficient_statistics ( x , axes , shift = None , keep_dims = False , name = None ) : <NEWLINE> <TAB> <NEWLINE> axes = list ( set ( axes ) ) <NEWLINE> with ops . name_scope ( name , <STRING> , [ x , shift ] ) : <NEWLINE> <TAB> x = ops . convert_to_tensor ( x , name = <STRING> ) <NEWLINE> x_shape = x . get_shape ( ) <NEWLINE> if all ( x_shape . dims [ d ] . value is not None for d in axes ) : <NEWLINE> <TAB> counts = <NUMBER> <NEWLINE> for d in axes : <NEWLINE> <TAB> counts *= x_shape . dims [ d ] . value <NEWLINE> <UNTAB> counts = constant_op . constant ( counts , dtype = x . dtype ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> x_dims = array_ops . gather ( <NEWLINE> math_ops . cast ( array_ops . shape ( x ) , x . dtype ) , axes ) <NEWLINE> counts = math_ops . reduce_prod ( x_dims , name = <STRING> ) <NEWLINE> <UNTAB> if shift is not None : <NEWLINE> <TAB> shift = ops . convert_to_tensor ( shift , name = <STRING> ) <NEWLINE> m_ss = math_ops . subtract ( x , shift ) <NEWLINE> v_ss = math_ops . squared_difference ( x , shift ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> m_ss = x <NEWLINE> v_ss = math_ops . square ( x ) <NEWLINE> <UNTAB> m_ss = math_ops . reduce_sum ( m_ss , axes , keepdims = keep_dims , name = <STRING> ) <NEWLINE> v_ss = math_ops . reduce_sum ( v_ss , axes , keepdims = keep_dims , name = <STRING> ) <NEWLINE> <UNTAB> return counts , m_ss , v_ss , shift <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _raw_hex_id ( obj ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> packed = struct . pack ( <STRING> , id ( obj ) ) <NEWLINE> return <STRING> . join ( map ( _replacer , packed ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def sparse_segment_sqrt_n_with_num_segments_eager_fallback ( data , indices , segment_ids , num_segments , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , ( data , ) = _execute . args_to_matching_eager ( [ data ] , _ctx ) <NEWLINE> _attr_Tidx , ( indices , ) = _execute . args_to_matching_eager ( [ indices ] , _ctx , _dtypes . int32 ) <NEWLINE> _attr_Tnumsegments , ( num_segments , ) = _execute . args_to_matching_eager ( [ num_segments ] , _ctx , _dtypes . int32 ) <NEWLINE> segment_ids = _ops . convert_to_tensor ( segment_ids , _dtypes . int32 ) <NEWLINE> _inputs_flat = [ data , indices , segment_ids , num_segments ] <NEWLINE> _attrs = ( <STRING> , _attr_T , <STRING> , _attr_Tidx , <STRING> , <NEWLINE> _attr_Tnumsegments ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , <NEWLINE> inputs = _inputs_flat , attrs = _attrs , ctx = _ctx , <NEWLINE> name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _check_antecedents ( g1 , g2 , x ) : <NEWLINE> <TAB> <NEWLINE> from sympy import re , Eq , Ne , cos , I , exp , sin , sign , unpolarify <NEWLINE> from sympy import arg as arg_ , unbranched_argument as arg <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> sigma , _ = _get_coeff_exp ( g1 . argument , x ) <NEWLINE> omega , _ = _get_coeff_exp ( g2 . argument , x ) <NEWLINE> s , t , u , v = S ( [ len ( g1 . bm ) , len ( g1 . an ) , len ( g1 . ap ) , len ( g1 . bq ) ] ) <NEWLINE> m , n , p , q = S ( [ len ( g2 . bm ) , len ( g2 . an ) , len ( g2 . ap ) , len ( g2 . bq ) ] ) <NEWLINE> bstar = s + t - ( u + v ) / <NUMBER> <NEWLINE> cstar = m + n - ( p + q ) / <NUMBER> <NEWLINE> rho = g1 . nu + ( u - v ) / <NUMBER> + <NUMBER> <NEWLINE> mu = g2 . nu + ( p - q ) / <NUMBER> + <NUMBER> <NEWLINE> phi = q - p - ( v - u ) <NEWLINE> eta = <NUMBER> - ( v - u ) - mu - rho <NEWLINE> psi = ( pi * ( q - m - n ) + abs ( arg ( omega ) ) ) / ( q - p ) <NEWLINE> theta = ( pi * ( v - s - t ) + abs ( arg ( sigma ) ) ) / ( v - u ) <NEWLINE> <NEWLINE> _debug ( <STRING> ) <NEWLINE> _debug ( <STRING> <NEWLINE> % ( sigma , s , t , u , v , bstar , rho ) ) <NEWLINE> _debug ( <STRING> <NEWLINE> % ( omega , m , n , p , q , cstar , mu ) ) <NEWLINE> _debug ( <STRING> % ( phi , eta , psi , theta ) ) <NEWLINE> <NEWLINE> def _c1 ( ) : <NEWLINE> <TAB> for g in [ g1 , g2 ] : <NEWLINE> <TAB> for i in g . an : <NEWLINE> <TAB> for j in g . bm : <NEWLINE> <TAB> diff = i - j <NEWLINE> if diff . is_integer and diff . is_positive : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> return True <NEWLINE> <UNTAB> c1 = _c1 ( ) <NEWLINE> c2 = And ( * [ re ( <NUMBER> + i + j ) > <NUMBER> for i in g1 . bm for j in g2 . bm ] ) <NEWLINE> c3 = And ( * [ re ( <NUMBER> + i + j ) < <NUMBER> + <NUMBER> for i in g1 . an for j in g2 . an ] ) <NEWLINE> c4 = And ( * [ ( p - q ) * re ( <NUMBER> + i - <NUMBER> ) - re ( mu ) > - S ( <NUMBER> ) / <NUMBER> for i in g1 . an ] ) <NEWLINE> c5 = And ( * [ ( p - q ) * re ( <NUMBER> + i ) - re ( mu ) > - S ( <NUMBER> ) / <NUMBER> for i in g1 . bm ] ) <NEWLINE> c6 = And ( * [ ( u - v ) * re ( <NUMBER> + i - <NUMBER> ) - re ( rho ) > - S ( <NUMBER> ) / <NUMBER> for i in g2 . an ] ) <NEWLINE> c7 = And ( * [ ( u - v ) * re ( <NUMBER> + i ) - re ( rho ) > - S ( <NUMBER> ) / <NUMBER> for i in g2 . bm ] ) <NEWLINE> c8 = ( abs ( phi ) + <NUMBER> * re ( ( rho - <NUMBER> ) * ( q - p ) + ( v - u ) * ( q - p ) + ( mu - <NEWLINE> <NUMBER> ) * ( v - u ) ) > <NUMBER> ) <NEWLINE> c9 = ( abs ( phi ) - <NUMBER> * re ( ( rho - <NUMBER> ) * ( q - p ) + ( v - u ) * ( q - p ) + ( mu - <NEWLINE> <NUMBER> ) * ( v - u ) ) > <NUMBER> ) <NEWLINE> c10 = ( abs ( arg ( sigma ) ) < bstar * pi ) <NEWLINE> c11 = Eq ( abs ( arg ( sigma ) ) , bstar * pi ) <NEWLINE> c12 = ( abs ( arg ( omega ) ) < cstar * pi ) <NEWLINE> c13 = Eq ( abs ( arg ( omega ) ) , cstar * pi ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> z0 = exp ( - ( bstar + cstar ) * pi * I ) <NEWLINE> zos = unpolarify ( z0 * omega / sigma ) <NEWLINE> zso = unpolarify ( z0 * sigma / omega ) <NEWLINE> if zos == <NUMBER> / zso : <NEWLINE> <TAB> c14 = And ( Eq ( phi , <NUMBER> ) , bstar + cstar <= <NUMBER> , <NEWLINE> Or ( Ne ( zos , <NUMBER> ) , re ( mu + rho + v - u ) < <NUMBER> , <NEWLINE> re ( mu + rho + q - p ) < <NUMBER> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> def _cond ( z ) : <NEWLINE> <TAB> <NEWLINE> return z != <NUMBER> and abs ( arg_ ( <NUMBER> - z ) ) < pi <NEWLINE> <NEWLINE> <UNTAB> c14 = And ( Eq ( phi , <NUMBER> ) , bstar - <NUMBER> + cstar <= <NUMBER> , <NEWLINE> Or ( And ( Ne ( zos , <NUMBER> ) , _cond ( zos ) ) , <NEWLINE> And ( re ( mu + rho + v - u ) < <NUMBER> , Eq ( zos , <NUMBER> ) ) ) ) <NEWLINE> <NEWLINE> c14_alt = And ( Eq ( phi , <NUMBER> ) , cstar - <NUMBER> + bstar <= <NUMBER> , <NEWLINE> Or ( And ( Ne ( zso , <NUMBER> ) , _cond ( zso ) ) , <NEWLINE> And ( re ( mu + rho + q - p ) < <NUMBER> , Eq ( zso , <NUMBER> ) ) ) ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> c14 = Or ( c14 , c14_alt ) <NEWLINE> <NEWLINE> <UNTAB> <NEWLINE> try : <NEWLINE> <TAB> lambda_c = ( q - p ) * abs ( omega ) ** ( <NUMBER> / ( q - p ) ) * cos ( psi ) + ( v - u ) * abs ( sigma ) ** ( <NUMBER> / ( v - u ) ) * cos ( theta ) <NEWLINE> <NEWLINE> if _eval_cond ( lambda_c > <NUMBER> ) != False : <NEWLINE> <TAB> c15 = ( lambda_c > <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> def lambda_s0 ( c1 , c2 ) : <NEWLINE> <TAB> return c1 * ( q - p ) * abs ( omega ) ** ( <NUMBER> / ( q - p ) ) * sin ( psi ) + c2 * ( v - u ) * abs ( sigma ) ** ( <NUMBER> / ( v - u ) ) * sin ( theta ) <NEWLINE> <UNTAB> lambda_s = Piecewise ( <NEWLINE> ( ( lambda_s0 ( + <NUMBER> , + <NUMBER> ) * lambda_s0 ( - <NUMBER> , - <NUMBER> ) ) , <NEWLINE> And ( Eq ( arg ( sigma ) , <NUMBER> ) , Eq ( arg ( omega ) , <NUMBER> ) ) ) , <NEWLINE> ( lambda_s0 ( sign ( arg ( omega ) ) , + <NUMBER> ) * lambda_s0 ( sign ( arg ( omega ) ) , - <NUMBER> ) , <NEWLINE> And ( Eq ( arg ( sigma ) , <NUMBER> ) , Ne ( arg ( omega ) , <NUMBER> ) ) ) , <NEWLINE> ( lambda_s0 ( + <NUMBER> , sign ( arg ( sigma ) ) ) * lambda_s0 ( - <NUMBER> , sign ( arg ( sigma ) ) ) , <NEWLINE> And ( Ne ( arg ( sigma ) , <NUMBER> ) , Eq ( arg ( omega ) , <NUMBER> ) ) ) , <NEWLINE> ( lambda_s0 ( sign ( arg ( omega ) ) , sign ( arg ( sigma ) ) ) , True ) ) <NEWLINE> tmp = [ lambda_c > <NUMBER> , <NEWLINE> And ( Eq ( lambda_c , <NUMBER> ) , Ne ( lambda_s , <NUMBER> ) , re ( eta ) > - <NUMBER> ) , <NEWLINE> And ( Eq ( lambda_c , <NUMBER> ) , Eq ( lambda_s , <NUMBER> ) , re ( eta ) > <NUMBER> ) ] <NEWLINE> c15 = Or ( * tmp ) <NEWLINE> <UNTAB> <UNTAB> except TypeError : <NEWLINE> <TAB> c15 = False <NEWLINE> <UNTAB> for cond , i in [ ( c1 , <NUMBER> ) , ( c2 , <NUMBER> ) , ( c3 , <NUMBER> ) , ( c4 , <NUMBER> ) , ( c5 , <NUMBER> ) , ( c6 , <NUMBER> ) , <NEWLINE> ( c7 , <NUMBER> ) , ( c8 , <NUMBER> ) , ( c9 , <NUMBER> ) , ( c10 , <NUMBER> ) , ( c11 , <NUMBER> ) , <NEWLINE> ( c12 , <NUMBER> ) , ( c13 , <NUMBER> ) , ( c14 , <NUMBER> ) , ( c15 , <NUMBER> ) ] : <NEWLINE> <TAB> _debug ( <STRING> % i , cond ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> conds = [ ] <NEWLINE> <NEWLINE> def pr ( count ) : <NEWLINE> <TAB> _debug ( <STRING> % count , conds [ - <NUMBER> ] ) <NEWLINE> <UNTAB> conds += [ And ( m * n * s * t != <NUMBER> , bstar . is_positive is True , cstar . is_positive is True , c1 , c2 , c3 , c10 , <NEWLINE> c12 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( u , v ) , Eq ( bstar , <NUMBER> ) , cstar . is_positive is True , sigma . is_positive is True , re ( rho ) < <NUMBER> , <NEWLINE> c1 , c2 , c3 , c12 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( p , q ) , Eq ( cstar , <NUMBER> ) , bstar . is_positive is True , omega . is_positive is True , re ( mu ) < <NUMBER> , <NEWLINE> c1 , c2 , c3 , c10 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( p , q ) , Eq ( u , v ) , Eq ( bstar , <NUMBER> ) , Eq ( cstar , <NUMBER> ) , <NEWLINE> sigma . is_positive is True , omega . is_positive is True , re ( mu ) < <NUMBER> , re ( rho ) < <NUMBER> , <NEWLINE> Ne ( sigma , omega ) , c1 , c2 , c3 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( p , q ) , Eq ( u , v ) , Eq ( bstar , <NUMBER> ) , Eq ( cstar , <NUMBER> ) , <NEWLINE> sigma . is_positive is True , omega . is_positive is True , re ( mu + rho ) < <NUMBER> , <NEWLINE> Ne ( omega , sigma ) , c1 , c2 , c3 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( p > q , s . is_positive is True , bstar . is_positive is True , cstar >= <NUMBER> , <NEWLINE> c1 , c2 , c3 , c5 , c10 , c13 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( p < q , t . is_positive is True , bstar . is_positive is True , cstar >= <NUMBER> , <NEWLINE> c1 , c2 , c3 , c4 , c10 , c13 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( u > v , m . is_positive is True , cstar . is_positive is True , bstar >= <NUMBER> , <NEWLINE> c1 , c2 , c3 , c7 , c11 , c12 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( u < v , n . is_positive is True , cstar . is_positive is True , bstar >= <NUMBER> , <NEWLINE> c1 , c2 , c3 , c6 , c11 , c12 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( p > q , Eq ( u , v ) , Eq ( bstar , <NUMBER> ) , cstar >= <NUMBER> , sigma . is_positive is True , <NEWLINE> re ( rho ) < <NUMBER> , c1 , c2 , c3 , c5 , c13 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( p < q , Eq ( u , v ) , Eq ( bstar , <NUMBER> ) , cstar >= <NUMBER> , sigma . is_positive is True , <NEWLINE> re ( rho ) < <NUMBER> , c1 , c2 , c3 , c4 , c13 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( p , q ) , u > v , bstar >= <NUMBER> , Eq ( cstar , <NUMBER> ) , omega . is_positive is True , <NEWLINE> re ( mu ) < <NUMBER> , c1 , c2 , c3 , c7 , c11 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( p , q ) , u < v , bstar >= <NUMBER> , Eq ( cstar , <NUMBER> ) , omega . is_positive is True , <NEWLINE> re ( mu ) < <NUMBER> , c1 , c2 , c3 , c6 , c11 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( p < q , u > v , bstar >= <NUMBER> , cstar >= <NUMBER> , <NEWLINE> c1 , c2 , c3 , c4 , c7 , c11 , c13 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( p > q , u < v , bstar >= <NUMBER> , cstar >= <NUMBER> , <NEWLINE> c1 , c2 , c3 , c5 , c6 , c11 , c13 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( p > q , u > v , bstar >= <NUMBER> , cstar >= <NUMBER> , <NEWLINE> c1 , c2 , c3 , c5 , c7 , c8 , c11 , c13 , c14 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( p < q , u < v , bstar >= <NUMBER> , cstar >= <NUMBER> , <NEWLINE> c1 , c2 , c3 , c4 , c6 , c9 , c11 , c13 , c14 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( t , <NUMBER> ) , s . is_positive is True , bstar . is_positive is True , phi . is_positive is True , c1 , c2 , c10 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( s , <NUMBER> ) , t . is_positive is True , bstar . is_positive is True , phi . is_negative is True , c1 , c3 , c10 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( n , <NUMBER> ) , m . is_positive is True , cstar . is_positive is True , phi . is_negative is True , c1 , c2 , c12 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( m , <NUMBER> ) , n . is_positive is True , cstar . is_positive is True , phi . is_positive is True , c1 , c3 , c12 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( s * t , <NUMBER> ) , bstar . is_positive is True , cstar . is_positive is True , <NEWLINE> c1 , c2 , c3 , c10 , c12 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( m * n , <NUMBER> ) , bstar . is_positive is True , cstar . is_positive is True , <NEWLINE> c1 , c2 , c3 , c10 , c12 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> mt1_exists = _check_antecedents_1 ( g1 , x , helper = True ) <NEWLINE> mt2_exists = _check_antecedents_1 ( g2 , x , helper = True ) <NEWLINE> conds += [ And ( mt2_exists , Eq ( t , <NUMBER> ) , u < s , bstar . is_positive is True , c10 , c1 , c2 , c3 ) ] <NEWLINE> pr ( <STRING> ) <NEWLINE> conds += [ And ( mt2_exists , Eq ( s , <NUMBER> ) , v < t , bstar . is_positive is True , c10 , c1 , c2 , c3 ) ] <NEWLINE> pr ( <STRING> ) <NEWLINE> conds += [ And ( mt1_exists , Eq ( n , <NUMBER> ) , p < m , cstar . is_positive is True , c12 , c1 , c2 , c3 ) ] <NEWLINE> pr ( <STRING> ) <NEWLINE> conds += [ And ( mt1_exists , Eq ( m , <NUMBER> ) , q < n , cstar . is_positive is True , c12 , c1 , c2 , c3 ) ] <NEWLINE> pr ( <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> r = Or ( * conds ) <NEWLINE> if _eval_cond ( r ) != False : <NEWLINE> <TAB> return r <NEWLINE> <NEWLINE> <UNTAB> conds += [ And ( m + n > p , Eq ( t , <NUMBER> ) , Eq ( phi , <NUMBER> ) , s . is_positive is True , bstar . is_positive is True , cstar . is_negative is True , <NEWLINE> abs ( arg ( omega ) ) < ( m + n - p + <NUMBER> ) * pi , <NEWLINE> c1 , c2 , c10 , c14 , c15 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( m + n > q , Eq ( s , <NUMBER> ) , Eq ( phi , <NUMBER> ) , t . is_positive is True , bstar . is_positive is True , cstar . is_negative is True , <NEWLINE> abs ( arg ( omega ) ) < ( m + n - q + <NUMBER> ) * pi , <NEWLINE> c1 , c3 , c10 , c14 , c15 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( p , q - <NUMBER> ) , Eq ( t , <NUMBER> ) , Eq ( phi , <NUMBER> ) , s . is_positive is True , bstar . is_positive is True , <NEWLINE> cstar >= <NUMBER> , cstar * pi < abs ( arg ( omega ) ) , <NEWLINE> c1 , c2 , c10 , c14 , c15 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( p , q + <NUMBER> ) , Eq ( s , <NUMBER> ) , Eq ( phi , <NUMBER> ) , t . is_positive is True , bstar . is_positive is True , <NEWLINE> cstar >= <NUMBER> , cstar * pi < abs ( arg ( omega ) ) , <NEWLINE> c1 , c3 , c10 , c14 , c15 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( p < q - <NUMBER> , Eq ( t , <NUMBER> ) , Eq ( phi , <NUMBER> ) , s . is_positive is True , bstar . is_positive is True , <NEWLINE> cstar >= <NUMBER> , cstar * pi < abs ( arg ( omega ) ) , <NEWLINE> abs ( arg ( omega ) ) < ( m + n - p + <NUMBER> ) * pi , <NEWLINE> c1 , c2 , c10 , c14 , c15 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( <NEWLINE> p > q + <NUMBER> , Eq ( s , <NUMBER> ) , Eq ( phi , <NUMBER> ) , t . is_positive is True , bstar . is_positive is True , cstar >= <NUMBER> , <NEWLINE> cstar * pi < abs ( arg ( omega ) ) , <NEWLINE> abs ( arg ( omega ) ) < ( m + n - q + <NUMBER> ) * pi , <NEWLINE> c1 , c3 , c10 , c14 , c15 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( n , <NUMBER> ) , Eq ( phi , <NUMBER> ) , s + t > <NUMBER> , m . is_positive is True , cstar . is_positive is True , bstar . is_negative is True , <NEWLINE> abs ( arg ( sigma ) ) < ( s + t - u + <NUMBER> ) * pi , <NEWLINE> c1 , c2 , c12 , c14 , c15 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( m , <NUMBER> ) , Eq ( phi , <NUMBER> ) , s + t > v , n . is_positive is True , cstar . is_positive is True , bstar . is_negative is True , <NEWLINE> abs ( arg ( sigma ) ) < ( s + t - v + <NUMBER> ) * pi , <NEWLINE> c1 , c3 , c12 , c14 , c15 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( n , <NUMBER> ) , Eq ( phi , <NUMBER> ) , Eq ( u , v - <NUMBER> ) , m . is_positive is True , cstar . is_positive is True , <NEWLINE> bstar >= <NUMBER> , bstar * pi < abs ( arg ( sigma ) ) , <NEWLINE> abs ( arg ( sigma ) ) < ( bstar + <NUMBER> ) * pi , <NEWLINE> c1 , c2 , c12 , c14 , c15 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( Eq ( m , <NUMBER> ) , Eq ( phi , <NUMBER> ) , Eq ( u , v + <NUMBER> ) , n . is_positive is True , cstar . is_positive is True , <NEWLINE> bstar >= <NUMBER> , bstar * pi < abs ( arg ( sigma ) ) , <NEWLINE> abs ( arg ( sigma ) ) < ( bstar + <NUMBER> ) * pi , <NEWLINE> c1 , c3 , c12 , c14 , c15 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( <NEWLINE> Eq ( n , <NUMBER> ) , Eq ( phi , <NUMBER> ) , u < v - <NUMBER> , m . is_positive is True , cstar . is_positive is True , bstar >= <NUMBER> , <NEWLINE> bstar * pi < abs ( arg ( sigma ) ) , <NEWLINE> abs ( arg ( sigma ) ) < ( s + t - u + <NUMBER> ) * pi , <NEWLINE> c1 , c2 , c12 , c14 , c15 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> conds += [ And ( <NEWLINE> Eq ( m , <NUMBER> ) , Eq ( phi , <NUMBER> ) , u > v + <NUMBER> , n . is_positive is True , cstar . is_positive is True , bstar >= <NUMBER> , <NEWLINE> bstar * pi < abs ( arg ( sigma ) ) , <NEWLINE> abs ( arg ( sigma ) ) < ( s + t - v + <NUMBER> ) * pi , <NEWLINE> c1 , c3 , c12 , c14 , c15 ) ] <NEWLINE> pr ( <NUMBER> ) <NEWLINE> <NEWLINE> return Or ( * conds ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def abs ( x ) : <NEWLINE> <TAB> <NEWLINE> return math_ops . abs ( x ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def assert_scalar_int ( tensor , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> , [ tensor ] ) as name_scope : <NEWLINE> <TAB> tensor = ops . convert_to_tensor ( tensor ) <NEWLINE> data_type = tensor . dtype <NEWLINE> if not data_type . base_dtype . is_integer : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> % ( tensor . name , data_type ) ) <NEWLINE> <UNTAB> return check_ops . assert_scalar ( tensor , name = name_scope ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ disallow ( <STRING> ) <NEWLINE> def nanargmax ( values , axis = None , skipna = True ) : <NEWLINE> <TAB> <NEWLINE> values , mask , dtype , _ = _get_values ( values , skipna , fill_value_typ = <STRING> ) <NEWLINE> result = values . argmax ( axis ) <NEWLINE> result = _maybe_arg_null_out ( result , axis , mask , skipna ) <NEWLINE> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _meijerint_definite_3 ( f , x ) : <NEWLINE> <TAB> <NEWLINE> res = _meijerint_definite_4 ( f , x ) <NEWLINE> if res and res [ <NUMBER> ] != False : <NEWLINE> <TAB> return res <NEWLINE> <UNTAB> if f . is_Add : <NEWLINE> <TAB> _debug ( <STRING> ) <NEWLINE> ress = [ _meijerint_definite_4 ( g , x ) for g in f . args ] <NEWLINE> if all ( r is not None for r in ress ) : <NEWLINE> <TAB> conds = [ ] <NEWLINE> res = S ( <NUMBER> ) <NEWLINE> for r , c in ress : <NEWLINE> <TAB> res += r <NEWLINE> conds += [ c ] <NEWLINE> <UNTAB> c = And ( * conds ) <NEWLINE> if c != False : <NEWLINE> <TAB> return res , c <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def chebroots ( c ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> [ c ] = pu . as_series ( [ c ] ) <NEWLINE> if len ( c ) < <NUMBER> : <NEWLINE> <TAB> return np . array ( [ ] , dtype = c . dtype ) <NEWLINE> <UNTAB> if len ( c ) == <NUMBER> : <NEWLINE> <TAB> return np . array ( [ - c [ <NUMBER> ] / c [ <NUMBER> ] ] ) <NEWLINE> <NEWLINE> <UNTAB> m = chebcompanion ( c ) <NEWLINE> r = la . eigvals ( m ) <NEWLINE> r . sort ( ) <NEWLINE> return r <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def batch_norm_with_global_normalization_grad ( t , m , v , gamma , backprop , variance_epsilon , scale_after_normalization , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> variance_epsilon = _execute . make_float ( variance_epsilon , <STRING> ) <NEWLINE> scale_after_normalization = _execute . make_bool ( scale_after_normalization , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , t = t , m = m , v = v , gamma = gamma , <NEWLINE> backprop = backprop , variance_epsilon = variance_epsilon , <NEWLINE> scale_after_normalization = scale_after_normalization , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result = _BatchNormWithGlobalNormalizationGradOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , t , m , v , gamma , backprop , <NEWLINE> <STRING> , variance_epsilon , <STRING> , <NEWLINE> scale_after_normalization ) <NEWLINE> _result = _BatchNormWithGlobalNormalizationGradOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return batch_norm_with_global_normalization_grad_eager_fallback ( <NEWLINE> t , m , v , gamma , backprop , variance_epsilon = variance_epsilon , <NEWLINE> scale_after_normalization = scale_after_normalization , name = name , <NEWLINE> ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_longitude_grid ( self , degrees ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> grid = np . arange ( - <NUMBER> + degrees , <NUMBER> , degrees ) <NEWLINE> self . xaxis . set_major_locator ( FixedLocator ( np . deg2rad ( grid ) ) ) <NEWLINE> self . xaxis . set_major_formatter ( self . ThetaFormatter ( degrees ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def cuthill_mckee_ordering ( G , heuristic = None ) : <NEWLINE> <TAB> <NEWLINE> for c in nx . connected_components ( G ) : <NEWLINE> <TAB> for n in connected_cuthill_mckee_ordering ( G . subgraph ( c ) , heuristic ) : <NEWLINE> <TAB> yield n <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , arg , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> super ( ColumnDefault , self ) . __init__ ( ** kwargs ) <NEWLINE> if isinstance ( arg , FetchedValue ) : <NEWLINE> <TAB> raise exc . ArgumentError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if util . callable ( arg ) : <NEWLINE> <TAB> arg = self . _maybe_wrap_callable ( arg ) <NEWLINE> <UNTAB> self . arg = arg <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def delete_folder ( folder_path , onerror = None ) : <NEWLINE> <TAB> <NEWLINE> if os . path . isdir ( folder_path ) : <NEWLINE> <TAB> if onerror is not None : <NEWLINE> <TAB> shutil . rmtree ( folder_path , False , onerror ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> err_count = <NUMBER> <NEWLINE> while True : <NEWLINE> <TAB> try : <NEWLINE> <TAB> shutil . rmtree ( folder_path , False , None ) <NEWLINE> break <NEWLINE> <UNTAB> except ( OSError , WindowsError ) : <NEWLINE> <TAB> err_count += <NUMBER> <NEWLINE> if err_count > RM_SUBDIRS_N_RETRY : <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> . format ( folder_path , RM_SUBDIRS_N_RETRY ) ) <NEWLINE> raise <NEWLINE> <UNTAB> time . sleep ( RM_SUBDIRS_RETRY_TIME ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_default_bbox_extra_artists ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> artists = self . get_children ( ) <NEWLINE> if not ( self . axison and self . _frameon ) : <NEWLINE> <NEWLINE> <TAB> for spine in self . spines . values ( ) : <NEWLINE> <TAB> artists . remove ( spine ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not self . axison : <NEWLINE> <TAB> for _axis in self . _get_axis_list ( ) : <NEWLINE> <TAB> artists . remove ( _axis ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return [ artist for artist in artists <NEWLINE> if ( artist . get_visible ( ) and artist . get_in_layout ( ) ) ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rc_params ( fail_on_error = False ) : <NEWLINE> <TAB> <NEWLINE> fname = matplotlib_fname ( ) <NEWLINE> if not os . path . exists ( fname ) : <NEWLINE> <NEWLINE> <TAB> message = <STRING> <NEWLINE> ret = RcParams ( [ ( key , default ) for key , ( default , _ ) in <NEWLINE> defaultParams . items ( ) <NEWLINE> if key not in _all_deprecated ] ) <NEWLINE> warnings . warn ( message ) <NEWLINE> return ret <NEWLINE> <NEWLINE> <UNTAB> return rc_params_from_file ( fname , fail_on_error ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def stddev ( self , name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> with self . _name_scope ( name ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> return self . _stddev ( ) <NEWLINE> <UNTAB> except NotImplementedError as original_exception : <NEWLINE> <TAB> try : <NEWLINE> <TAB> return math_ops . sqrt ( self . _variance ( ) ) <NEWLINE> <UNTAB> except NotImplementedError : <NEWLINE> <TAB> raise original_exception <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def apply_aspect ( self , position = None ) : <NEWLINE> <TAB> <NEWLINE> if position is None : <NEWLINE> <TAB> position = self . get_position ( original = True ) <NEWLINE> <NEWLINE> <UNTAB> aspect = self . get_aspect ( ) <NEWLINE> <NEWLINE> if self . name != <STRING> : <NEWLINE> <TAB> xscale , yscale = self . get_xscale ( ) , self . get_yscale ( ) <NEWLINE> if xscale == <STRING> and yscale == <STRING> : <NEWLINE> <TAB> aspect_scale_mode = <STRING> <NEWLINE> <UNTAB> elif xscale == <STRING> and yscale == <STRING> : <NEWLINE> <TAB> aspect_scale_mode = <STRING> <NEWLINE> <UNTAB> elif ( ( xscale == <STRING> and yscale == <STRING> ) or <NEWLINE> ( xscale == <STRING> and yscale == <STRING> ) ) : <NEWLINE> <TAB> if aspect != <STRING> : <NEWLINE> <TAB> warnings . warn ( <NEWLINE> <STRING> <NEWLINE> <STRING> % ( xscale , yscale ) , stacklevel = <NUMBER> ) <NEWLINE> aspect = <STRING> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> aspect_scale_mode = <STRING> <NEWLINE> <NEWLINE> <UNTAB> if aspect == <STRING> : <NEWLINE> <TAB> self . _set_position ( position , which = <STRING> ) <NEWLINE> return <NEWLINE> <NEWLINE> <UNTAB> if aspect == <STRING> : <NEWLINE> <TAB> A = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> A = aspect <NEWLINE> <NEWLINE> <UNTAB> figW , figH = self . get_figure ( ) . get_size_inches ( ) <NEWLINE> fig_aspect = figH / figW <NEWLINE> if self . _adjustable in [ <STRING> , <STRING> ] : <NEWLINE> <TAB> if self in self . _twinned_axes : <NEWLINE> <TAB> raise RuntimeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> if aspect_scale_mode == <STRING> : <NEWLINE> <TAB> box_aspect = A * self . get_data_ratio_log ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> box_aspect = A * self . get_data_ratio ( ) <NEWLINE> <UNTAB> pb = position . frozen ( ) <NEWLINE> pb1 = pb . shrunk_to_aspect ( box_aspect , pb , fig_aspect ) <NEWLINE> self . _set_position ( pb1 . anchored ( self . get_anchor ( ) , pb ) , <STRING> ) <NEWLINE> return <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> self . _set_position ( position , which = <STRING> ) <NEWLINE> <NEWLINE> xmin , xmax = self . get_xbound ( ) <NEWLINE> ymin , ymax = self . get_ybound ( ) <NEWLINE> <NEWLINE> if aspect_scale_mode == <STRING> : <NEWLINE> <TAB> xmin , xmax = math . log10 ( xmin ) , math . log10 ( xmax ) <NEWLINE> ymin , ymax = math . log10 ( ymin ) , math . log10 ( ymax ) <NEWLINE> <NEWLINE> <UNTAB> xsize = max ( abs ( xmax - xmin ) , <NUMBER> ) <NEWLINE> ysize = max ( abs ( ymax - ymin ) , <NUMBER> ) <NEWLINE> <NEWLINE> l , b , w , h = position . bounds <NEWLINE> box_aspect = fig_aspect * ( h / w ) <NEWLINE> data_ratio = box_aspect / A <NEWLINE> <NEWLINE> y_expander = ( data_ratio * xsize / ysize - <NUMBER> ) <NEWLINE> <NEWLINE> if abs ( y_expander ) < <NUMBER> : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> if aspect_scale_mode == <STRING> : <NEWLINE> <TAB> dL = self . dataLim <NEWLINE> dL_width = math . log10 ( dL . x1 ) - math . log10 ( dL . x0 ) <NEWLINE> dL_height = math . log10 ( dL . y1 ) - math . log10 ( dL . y0 ) <NEWLINE> xr = <NUMBER> * dL_width <NEWLINE> yr = <NUMBER> * dL_height <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> dL = self . dataLim <NEWLINE> xr = <NUMBER> * dL . width <NEWLINE> yr = <NUMBER> * dL . height <NEWLINE> <NEWLINE> <UNTAB> xmarg = xsize - xr <NEWLINE> ymarg = ysize - yr <NEWLINE> Ysize = data_ratio * xsize <NEWLINE> Xsize = ysize / data_ratio <NEWLINE> Xmarg = Xsize - xr <NEWLINE> Ymarg = Ysize - yr <NEWLINE> <NEWLINE> <NEWLINE> xm = <NUMBER> <NEWLINE> ym = <NUMBER> <NEWLINE> <NEWLINE> shared_x = self in self . _shared_x_axes <NEWLINE> shared_y = self in self . _shared_y_axes <NEWLINE> <NEWLINE> if shared_x and shared_y : <NEWLINE> <TAB> raise RuntimeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if shared_y : <NEWLINE> <TAB> adjust_y = False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if xmarg > xm and ymarg > ym : <NEWLINE> <TAB> adjy = ( ( Ymarg > <NUMBER> and y_expander < <NUMBER> ) or <NEWLINE> ( Xmarg < <NUMBER> and y_expander > <NUMBER> ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> adjy = y_expander > <NUMBER> <NEWLINE> <UNTAB> adjust_y = shared_x or adjy <NEWLINE> <NEWLINE> <UNTAB> if adjust_y : <NEWLINE> <TAB> yc = <NUMBER> * ( ymin + ymax ) <NEWLINE> y0 = yc - Ysize / <NUMBER> <NEWLINE> y1 = yc + Ysize / <NUMBER> <NEWLINE> if aspect_scale_mode == <STRING> : <NEWLINE> <TAB> self . set_ybound ( ( <NUMBER> ** y0 , <NUMBER> ** y1 ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . set_ybound ( ( y0 , y1 ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> xc = <NUMBER> * ( xmin + xmax ) <NEWLINE> x0 = xc - Xsize / <NUMBER> <NEWLINE> x1 = xc + Xsize / <NUMBER> <NEWLINE> if aspect_scale_mode == <STRING> : <NEWLINE> <TAB> self . set_xbound ( ( <NUMBER> ** x0 , <NUMBER> ** x1 ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . set_xbound ( ( x0 , x1 ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def map_array ( surface , array ) : <NEWLINE> <TAB> <NEWLINE> if array . ndim == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> shape = array . shape <NEWLINE> if shape [ - <NUMBER> ] != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> target = numpy_empty ( shape [ : - <NUMBER> ] , numpy . int32 ) <NEWLINE> pix_map_array ( target , array , surface ) <NEWLINE> return target <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def add ( self , column ) : <NEWLINE> <TAB> <NEWLINE> if not column . key : <NEWLINE> <TAB> raise exc . ArgumentError ( <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> self [ column . key ] = column <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def crf_unary_score ( tag_indices , sequence_lengths , inputs ) : <NEWLINE> <TAB> <NEWLINE> batch_size = array_ops . shape ( inputs ) [ <NUMBER> ] <NEWLINE> max_seq_len = array_ops . shape ( inputs ) [ <NUMBER> ] <NEWLINE> num_tags = array_ops . shape ( inputs ) [ <NUMBER> ] <NEWLINE> <NEWLINE> flattened_inputs = array_ops . reshape ( inputs , [ - <NUMBER> ] ) <NEWLINE> <NEWLINE> offsets = array_ops . expand_dims ( <NEWLINE> math_ops . range ( batch_size ) * max_seq_len * num_tags , <NUMBER> ) <NEWLINE> offsets += array_ops . expand_dims ( math_ops . range ( max_seq_len ) * num_tags , <NUMBER> ) <NEWLINE> <NEWLINE> if tag_indices . dtype == dtypes . int64 : <NEWLINE> <TAB> offsets = math_ops . to_int64 ( offsets ) <NEWLINE> <UNTAB> flattened_tag_indices = array_ops . reshape ( offsets + tag_indices , [ - <NUMBER> ] ) <NEWLINE> <NEWLINE> unary_scores = array_ops . reshape ( <NEWLINE> array_ops . gather ( flattened_inputs , flattened_tag_indices ) , <NEWLINE> [ batch_size , max_seq_len ] ) <NEWLINE> <NEWLINE> masks = array_ops . sequence_mask ( sequence_lengths , <NEWLINE> maxlen = array_ops . shape ( tag_indices ) [ <NUMBER> ] , <NEWLINE> dtype = dtypes . float32 ) <NEWLINE> <NEWLINE> unary_scores = math_ops . reduce_sum ( unary_scores * masks , <NUMBER> ) <NEWLINE> return unary_scores <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def cauchy_point ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _cauchy_point is None : <NEWLINE> <TAB> g = self . jac <NEWLINE> Bg = self . hessp ( g ) <NEWLINE> self . _cauchy_point = - ( np . dot ( g , g ) / np . dot ( g , Bg ) ) * g <NEWLINE> <UNTAB> return self . _cauchy_point <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def auto_set_font_size ( self , value = True ) : <NEWLINE> <TAB> <NEWLINE> self . _autoFontsize = value <NEWLINE> self . stale = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __truediv__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> if self . _delegate_binop ( other ) : <NEWLINE> <TAB> return NotImplemented <NEWLINE> <UNTAB> return true_divide ( self , other ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __unicode__ ( self ) : <NEWLINE> <TAB> <NEWLINE> _maxlen = <NUMBER> <NEWLINE> if len ( self . _codes ) > _maxlen : <NEWLINE> <TAB> result = self . _tidy_repr ( _maxlen ) <NEWLINE> <UNTAB> elif len ( self . _codes ) > <NUMBER> : <NEWLINE> <TAB> result = self . _get_repr ( length = len ( self ) > _maxlen ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> msg = self . _get_repr ( length = False , footer = True ) . replace ( <STRING> , <STRING> ) <NEWLINE> result = ( <STRING> . format ( repr_msg = msg ) ) <NEWLINE> <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _is_bytes_like ( obj ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> obj + <STRING> <NEWLINE> <UNTAB> except ( TypeError , ValueError ) : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> return True <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def s_poly ( cp ) : <NEWLINE> <TAB> <NEWLINE> return lbp_sub ( lbp_mul_term ( cp [ <NUMBER> ] , cp [ <NUMBER> ] ) , lbp_mul_term ( cp [ <NUMBER> ] , cp [ <NUMBER> ] ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def indices_to_mask ( indices , mask_length ) : <NEWLINE> <TAB> <NEWLINE> if mask_length <= np . max ( indices ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> mask = np . zeros ( mask_length , dtype = np . bool ) <NEWLINE> mask [ indices ] = True <NEWLINE> <NEWLINE> return mask <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_params ( self , deep = True ) : <NEWLINE> <TAB> <NEWLINE> out = dict ( ) <NEWLINE> param_names = [ name for name in self . __dict__ if not name . startswith ( <STRING> ) ] <NEWLINE> for key in param_names : <NEWLINE> <TAB> value = getattr ( self , key , None ) <NEWLINE> <NEWLINE> if isinstance ( value , collections . Callable ) : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if deep and hasattr ( value , <STRING> ) : <NEWLINE> <TAB> deep_items = value . get_params ( ) . items ( ) <NEWLINE> out . update ( ( key + <STRING> + k , val ) for k , val in deep_items ) <NEWLINE> <UNTAB> out [ key ] = value <NEWLINE> <UNTAB> return out <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _a ( n , k , prec ) : <NEWLINE> <TAB> <NEWLINE> if k == <NUMBER> : <NEWLINE> <TAB> return fone <NEWLINE> <NEWLINE> <UNTAB> k1 = k <NEWLINE> e = <NUMBER> <NEWLINE> p = _factor [ k ] <NEWLINE> while k1 % p == <NUMBER> : <NEWLINE> <TAB> k1 //= p <NEWLINE> e += <NUMBER> <NEWLINE> <UNTAB> k2 = k // k1 <NEWLINE> v = <NUMBER> - <NUMBER> * n <NEWLINE> pi = mpf_pi ( prec ) <NEWLINE> <NEWLINE> if k1 == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> if p == <NUMBER> : <NEWLINE> <TAB> mod = <NUMBER> * k <NEWLINE> v = mod + v % mod <NEWLINE> v = ( v * pow ( <NUMBER> , k - <NUMBER> , mod ) ) % mod <NEWLINE> m = _sqrt_mod_prime_power ( v , <NUMBER> , e + <NUMBER> ) [ <NUMBER> ] <NEWLINE> arg = mpf_div ( mpf_mul ( <NEWLINE> from_int ( <NUMBER> * m ) , pi , prec ) , from_int ( mod ) , prec ) <NEWLINE> return mpf_mul ( mpf_mul ( <NEWLINE> from_int ( ( - <NUMBER> ) ** e * jacobi_symbol ( m - <NUMBER> , m ) ) , <NEWLINE> mpf_sqrt ( from_int ( k ) , prec ) , prec ) , <NEWLINE> mpf_sin ( arg , prec ) , prec ) <NEWLINE> <UNTAB> if p == <NUMBER> : <NEWLINE> <TAB> mod = <NUMBER> * k <NEWLINE> v = mod + v % mod <NEWLINE> if e > <NUMBER> : <NEWLINE> <TAB> v = ( v * pow ( <NUMBER> , k // <NUMBER> - <NUMBER> , mod ) ) % mod <NEWLINE> <UNTAB> m = _sqrt_mod_prime_power ( v , <NUMBER> , e + <NUMBER> ) [ <NUMBER> ] <NEWLINE> arg = mpf_div ( mpf_mul ( from_int ( <NUMBER> * m ) , pi , prec ) , <NEWLINE> from_int ( mod ) , prec ) <NEWLINE> return mpf_mul ( mpf_mul ( <NEWLINE> from_int ( <NUMBER> * ( - <NUMBER> ) ** ( e + <NUMBER> ) * legendre_symbol ( m , <NUMBER> ) ) , <NEWLINE> mpf_sqrt ( from_int ( k // <NUMBER> ) , prec ) , prec ) , <NEWLINE> mpf_sin ( arg , prec ) , prec ) <NEWLINE> <UNTAB> v = k + v % k <NEWLINE> if v % p == <NUMBER> : <NEWLINE> <TAB> if e == <NUMBER> : <NEWLINE> <TAB> return mpf_mul ( <NEWLINE> from_int ( jacobi_symbol ( <NUMBER> , k ) ) , <NEWLINE> mpf_sqrt ( from_int ( k ) , prec ) , prec ) <NEWLINE> <UNTAB> return fzero <NEWLINE> <UNTAB> if not is_quad_residue ( v , p ) : <NEWLINE> <TAB> return fzero <NEWLINE> <UNTAB> _phi = p ** ( e - <NUMBER> ) * ( p - <NUMBER> ) <NEWLINE> v = ( v * pow ( <NUMBER> , _phi - <NUMBER> , k ) ) <NEWLINE> m = _sqrt_mod_prime_power ( v , p , e ) [ <NUMBER> ] <NEWLINE> arg = mpf_div ( <NEWLINE> mpf_mul ( from_int ( <NUMBER> * m ) , pi , prec ) , <NEWLINE> from_int ( k ) , prec ) <NEWLINE> return mpf_mul ( mpf_mul ( <NEWLINE> from_int ( <NUMBER> * jacobi_symbol ( <NUMBER> , k ) ) , <NEWLINE> mpf_sqrt ( from_int ( k ) , prec ) , prec ) , <NEWLINE> mpf_cos ( arg , prec ) , prec ) <NEWLINE> <NEWLINE> <UNTAB> if p != <NUMBER> or e >= <NUMBER> : <NEWLINE> <TAB> d1 , d2 = igcd ( k1 , <NUMBER> ) , igcd ( k2 , <NUMBER> ) <NEWLINE> e = <NUMBER> // ( d1 * d2 ) <NEWLINE> n1 = ( ( d2 * e * n + ( k2 ** <NUMBER> - <NUMBER> ) // d1 ) * <NEWLINE> pow ( e * k2 * k2 * d2 , _totient [ k1 ] - <NUMBER> , k1 ) ) % k1 <NEWLINE> n2 = ( ( d1 * e * n + ( k1 ** <NUMBER> - <NUMBER> ) // d2 ) * <NEWLINE> pow ( e * k1 * k1 * d1 , _totient [ k2 ] - <NUMBER> , k2 ) ) % k2 <NEWLINE> return mpf_mul ( _a ( n1 , k1 , prec ) , _a ( n2 , k2 , prec ) , prec ) <NEWLINE> <UNTAB> if e == <NUMBER> : <NEWLINE> <TAB> n1 = ( ( <NUMBER> * n + <NUMBER> ) * pow ( <NUMBER> , _totient [ k1 ] - <NUMBER> , k1 ) ) % k1 <NEWLINE> n2 = ( <NUMBER> + ( ( n - <NUMBER> - ( k1 ** <NUMBER> - <NUMBER> ) // <NUMBER> ) * ( k1 ** <NUMBER> ) ) % <NUMBER> ) % <NUMBER> <NEWLINE> return mpf_mul ( mpf_mul ( <NEWLINE> from_int ( - <NUMBER> ) , <NEWLINE> _a ( n1 , k1 , prec ) , prec ) , <NEWLINE> _a ( n2 , k2 , prec ) ) <NEWLINE> <UNTAB> n1 = ( ( <NUMBER> * n + <NUMBER> ) * pow ( <NUMBER> , _totient [ k1 ] - <NUMBER> , k1 ) ) % k1 <NEWLINE> n2 = ( <NUMBER> + ( n - ( k1 ** <NUMBER> - <NUMBER> ) // <NUMBER> ) % <NUMBER> ) % <NUMBER> <NEWLINE> return mpf_mul ( _a ( n1 , k1 , prec ) , _a ( n2 , k2 , prec ) , prec ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def subs ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> from sympy . core . containers import Dict <NEWLINE> from sympy . utilities import default_sort_key <NEWLINE> from sympy import Dummy , Symbol <NEWLINE> <NEWLINE> unordered = False <NEWLINE> if len ( args ) == <NUMBER> : <NEWLINE> <TAB> sequence = args [ <NUMBER> ] <NEWLINE> if isinstance ( sequence , set ) : <NEWLINE> <TAB> unordered = True <NEWLINE> <UNTAB> elif isinstance ( sequence , ( Dict , Mapping ) ) : <NEWLINE> <TAB> unordered = True <NEWLINE> sequence = sequence . items ( ) <NEWLINE> <UNTAB> elif not iterable ( sequence ) : <NEWLINE> <TAB> from sympy . utilities . misc import filldedent <NEWLINE> raise ValueError ( filldedent ( " " " 
                                       W h e n   a   s i n g l e   a r g u m e n t   i s   p a s s e d   t o   s u b s 
                                       i t   s h o u l d   b e   a   d i c t i o n a r y   o f   o l d :   n e w   p a i r s   o r   a n   i t e r a b l e 
                                       o f   ( o l d ,   n e w )   t u p l e s . " " " ) ) <NEWLINE> <UNTAB> <UNTAB> elif len ( args ) == <NUMBER> : <NEWLINE> <TAB> sequence = [ args ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> sequence = list ( sequence ) <NEWLINE> for i in range ( len ( sequence ) ) : <NEWLINE> <TAB> s = list ( sequence [ i ] ) <NEWLINE> for j , si in enumerate ( s ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> si = sympify ( si , strict = True ) <NEWLINE> <UNTAB> except SympifyError : <NEWLINE> <TAB> if type ( si ) is str : <NEWLINE> <TAB> si = Symbol ( si ) <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> sequence [ i ] = None <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> s [ j ] = si <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> sequence [ i ] = None if _aresame ( * s ) else tuple ( s ) <NEWLINE> <UNTAB> <UNTAB> sequence = list ( filter ( None , sequence ) ) <NEWLINE> <NEWLINE> if unordered : <NEWLINE> <TAB> sequence = dict ( sequence ) <NEWLINE> if not all ( k . is_Atom for k in sequence ) : <NEWLINE> <TAB> d = { } <NEWLINE> for o , n in sequence . items ( ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> ops = o . count_ops ( ) , len ( o . args ) <NEWLINE> <UNTAB> except TypeError : <NEWLINE> <TAB> ops = ( <NUMBER> , <NUMBER> ) <NEWLINE> <UNTAB> d . setdefault ( ops , [ ] ) . append ( ( o , n ) ) <NEWLINE> <UNTAB> newseq = [ ] <NEWLINE> for k in sorted ( d . keys ( ) , reverse = True ) : <NEWLINE> <TAB> newseq . extend ( <NEWLINE> sorted ( [ v [ <NUMBER> ] for v in d [ k ] ] , key = default_sort_key ) ) <NEWLINE> <UNTAB> sequence = [ ( k , sequence [ k ] ) for k in newseq ] <NEWLINE> del newseq , d <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> sequence = sorted ( [ ( k , v ) for ( k , v ) in sequence . items ( ) ] , <NEWLINE> key = default_sort_key ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if kwargs . pop ( <STRING> , False ) : <NEWLINE> <TAB> reps = { } <NEWLINE> rv = self <NEWLINE> kwargs [ <STRING> ] = True <NEWLINE> m = Dummy ( ) <NEWLINE> for old , new in sequence : <NEWLINE> <TAB> d = Dummy ( commutative = new . is_commutative ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> rv = rv . _subs ( old , d * m , ** kwargs ) <NEWLINE> if not isinstance ( rv , Basic ) : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> reps [ d ] = new <NEWLINE> <UNTAB> reps [ m ] = S . One <NEWLINE> return rv . xreplace ( reps ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rv = self <NEWLINE> for old , new in sequence : <NEWLINE> <TAB> rv = rv . _subs ( old , new , ** kwargs ) <NEWLINE> if not isinstance ( rv , Basic ) : <NEWLINE> <TAB> break <NEWLINE> <UNTAB> <UNTAB> return rv <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def compile_file ( source , globals_ = None ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( source , gast . AST ) : <NEWLINE> <TAB> source = quoting . to_source ( source ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> tempdir = tempfile . mkdtemp ( ) <NEWLINE> uuid = str ( uuid4 ( ) . hex [ : <NUMBER> ] ) <NEWLINE> tmpname = os . path . join ( tempdir , <STRING> % uuid ) <NEWLINE> with open ( tmpname , <STRING> ) as f : <NEWLINE> <TAB> f . write ( source ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> module_name = <STRING> % uuid <NEWLINE> if six . PY3 : <NEWLINE> <TAB> spec = util . spec_from_file_location ( module_name , tmpname ) <NEWLINE> m = util . module_from_spec ( spec ) <NEWLINE> spec . loader . exec_module ( m ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> m = imp . load_source ( module_name , tmpname ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if globals_ : <NEWLINE> <TAB> m . __dict__ . update ( globals_ ) <NEWLINE> <UNTAB> return m <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def checkpoint ( fun ) : <NEWLINE> <TAB> <NEWLINE> def wrapped_grad ( argnum , ans , args , kwargs ) : <NEWLINE> <TAB> return make_vjp ( fun , argnum ) ( * args , ** kwargs ) [ <NUMBER> ] <NEWLINE> <UNTAB> wrapped = primitive ( fun ) <NEWLINE> defvjp_argnum ( wrapped , wrapped_grad ) <NEWLINE> return wrapped <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def quantized_relu ( features , min_features , max_features , out_type = _dtypes . quint8 , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> if out_type is None : <NEWLINE> <TAB> out_type = _dtypes . quint8 <NEWLINE> <UNTAB> out_type = _execute . make_type ( out_type , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , features = features , min_features = min_features , <NEWLINE> max_features = max_features , out_type = out_type , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) , <STRING> , <NEWLINE> _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result = _QuantizedReluOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , features , <NEWLINE> min_features , max_features , <STRING> , out_type ) <NEWLINE> _result = _QuantizedReluOutput . _make ( _result ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return quantized_relu_eager_fallback ( <NEWLINE> features , min_features , max_features , out_type = out_type , name = name , <NEWLINE> ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def format_percentiles ( percentiles ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> percentiles = np . asarray ( percentiles ) <NEWLINE> <NEWLINE> <NEWLINE> with np . errstate ( invalid = <STRING> ) : <NEWLINE> <TAB> if not is_numeric_dtype ( percentiles ) or not np . all ( percentiles >= <NUMBER> ) or not np . all ( percentiles <= <NUMBER> ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> percentiles = <NUMBER> * percentiles <NEWLINE> int_idx = ( percentiles . astype ( int ) == percentiles ) <NEWLINE> <NEWLINE> if np . all ( int_idx ) : <NEWLINE> <TAB> out = percentiles . astype ( int ) . astype ( str ) <NEWLINE> return [ i + <STRING> for i in out ] <NEWLINE> <NEWLINE> <UNTAB> unique_pcts = np . unique ( percentiles ) <NEWLINE> to_begin = unique_pcts [ <NUMBER> ] if unique_pcts [ <NUMBER> ] > <NUMBER> else None <NEWLINE> to_end = <NUMBER> - unique_pcts [ - <NUMBER> ] if unique_pcts [ - <NUMBER> ] < <NUMBER> else None <NEWLINE> <NEWLINE> <NEWLINE> prec = - np . floor ( np . log10 ( np . min ( <NEWLINE> np . ediff1d ( unique_pcts , to_begin = to_begin , to_end = to_end ) <NEWLINE> ) ) ) . astype ( int ) <NEWLINE> prec = max ( <NUMBER> , prec ) <NEWLINE> out = np . empty_like ( percentiles , dtype = object ) <NEWLINE> out [ int_idx ] = percentiles [ int_idx ] . astype ( int ) . astype ( str ) <NEWLINE> out [ ~ int_idx ] = percentiles [ ~ int_idx ] . round ( prec ) . astype ( str ) <NEWLINE> return [ i + <STRING> for i in out ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __call__ ( self , trainer ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> observation = trainer . observation <NEWLINE> summary = self . _summary <NEWLINE> key = self . _key <NEWLINE> if key in observation : <NEWLINE> <TAB> summary . add ( { key : observation [ key ] } ) <NEWLINE> <NEWLINE> <UNTAB> if not self . _interval_trigger ( trainer ) : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> stats = summary . compute_mean ( ) <NEWLINE> value = float ( stats [ key ] ) <NEWLINE> self . _init_summary ( ) <NEWLINE> <NEWLINE> if self . _best_value is None or self . _compare ( self . _best_value , value ) : <NEWLINE> <TAB> self . _best_value = value <NEWLINE> return True <NEWLINE> <UNTAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _odd_triangle ( G , T ) : <NEWLINE> <TAB> <NEWLINE> for u in T : <NEWLINE> <TAB> if u not in G . nodes ( ) : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> % u ) <NEWLINE> <UNTAB> <UNTAB> for e in list ( combinations ( T , <NUMBER> ) ) : <NEWLINE> <TAB> if e [ <NUMBER> ] not in G . neighbors ( e [ <NUMBER> ] ) : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> % ( e [ <NUMBER> ] , e [ <NUMBER> ] ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> T_neighbors = defaultdict ( int ) <NEWLINE> for t in T : <NEWLINE> <TAB> for v in G . neighbors ( t ) : <NEWLINE> <TAB> if v not in T : <NEWLINE> <TAB> T_neighbors [ v ] += <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> for v in T_neighbors : <NEWLINE> <TAB> if T_neighbors [ v ] in [ <NUMBER> , <NUMBER> ] : <NEWLINE> <TAB> return True <NEWLINE> <UNTAB> <UNTAB> return False <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def is_nested_object ( obj ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if isinstance ( obj , ABCSeries ) and is_object_dtype ( obj ) : <NEWLINE> <NEWLINE> <TAB> if any ( isinstance ( v , ABCSeries ) for v in obj . values ) : <NEWLINE> <TAB> return True <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return False <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ classmethod <NEWLINE> def get_supported_filetypes_grouped ( cls ) : <NEWLINE> <TAB> <NEWLINE> groupings = { } <NEWLINE> for ext , name in cls . filetypes . items ( ) : <NEWLINE> <TAB> groupings . setdefault ( name , [ ] ) . append ( ext ) <NEWLINE> groupings [ name ] . sort ( ) <NEWLINE> <UNTAB> return groupings <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( None , <STRING> ) <NEWLINE> def get_rnn_model ( rnn_size , cell_type , num_layers , input_op_fn , bidirectional , <NEWLINE> target_predictor_fn , sequence_length , initial_state , <NEWLINE> attn_length , attn_size , attn_vec_size ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> def rnn_estimator ( x , y ) : <NEWLINE> <TAB> <NEWLINE> x = input_op_fn ( x ) <NEWLINE> if cell_type == <STRING> : <NEWLINE> <TAB> cell_fn = contrib_rnn . BasicRNNCell <NEWLINE> <UNTAB> elif cell_type == <STRING> : <NEWLINE> <TAB> cell_fn = contrib_rnn . GRUCell <NEWLINE> <UNTAB> elif cell_type == <STRING> : <NEWLINE> <TAB> cell_fn = functools . partial ( <NEWLINE> contrib_rnn . BasicLSTMCell , state_is_tuple = False ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise ValueError ( <STRING> . format ( cell_type ) ) <NEWLINE> <NEWLINE> <UNTAB> if bidirectional : <NEWLINE> <NEWLINE> <TAB> fw_cell = lambda : cell_fn ( rnn_size ) <NEWLINE> bw_cell = lambda : cell_fn ( rnn_size ) <NEWLINE> <NEWLINE> if attn_length is not None : <NEWLINE> <TAB> def attn_fw_cell ( ) : <NEWLINE> <TAB> return contrib_rnn . AttentionCellWrapper ( <NEWLINE> fw_cell ( ) , <NEWLINE> attn_length = attn_length , <NEWLINE> attn_size = attn_size , <NEWLINE> attn_vec_size = attn_vec_size , <NEWLINE> state_is_tuple = False ) <NEWLINE> <NEWLINE> <UNTAB> def attn_bw_cell ( ) : <NEWLINE> <TAB> return contrib_rnn . AttentionCellWrapper ( <NEWLINE> bw_cell ( ) , <NEWLINE> attn_length = attn_length , <NEWLINE> attn_size = attn_size , <NEWLINE> attn_vec_size = attn_vec_size , <NEWLINE> state_is_tuple = False ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> attn_fw_cell = fw_cell <NEWLINE> attn_bw_cell = bw_cell <NEWLINE> <NEWLINE> <UNTAB> rnn_fw_cell = contrib_rnn . MultiRNNCell ( <NEWLINE> [ attn_fw_cell ( ) for _ in range ( num_layers ) ] , state_is_tuple = False ) <NEWLINE> <NEWLINE> rnn_bw_cell = contrib_rnn . MultiRNNCell ( <NEWLINE> [ attn_bw_cell ( ) for _ in range ( num_layers ) ] , state_is_tuple = False ) <NEWLINE> <NEWLINE> _ , encoding = bidirectional_rnn ( <NEWLINE> rnn_fw_cell , <NEWLINE> rnn_bw_cell , <NEWLINE> x , <NEWLINE> dtype = dtypes . float32 , <NEWLINE> sequence_length = sequence_length , <NEWLINE> initial_state_fw = initial_state , <NEWLINE> initial_state_bw = initial_state ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rnn_cell = lambda : cell_fn ( rnn_size ) <NEWLINE> <NEWLINE> if attn_length is not None : <NEWLINE> <TAB> def attn_rnn_cell ( ) : <NEWLINE> <TAB> return contrib_rnn . AttentionCellWrapper ( <NEWLINE> rnn_cell ( ) , <NEWLINE> attn_length = attn_length , <NEWLINE> attn_size = attn_size , <NEWLINE> attn_vec_size = attn_vec_size , <NEWLINE> state_is_tuple = False ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> attn_rnn_cell = rnn_cell <NEWLINE> <NEWLINE> <UNTAB> cell = contrib_rnn . MultiRNNCell ( <NEWLINE> [ attn_rnn_cell ( ) for _ in range ( num_layers ) ] , state_is_tuple = False ) <NEWLINE> _ , encoding = contrib_rnn . static_rnn ( <NEWLINE> cell , <NEWLINE> x , <NEWLINE> dtype = dtypes . float32 , <NEWLINE> sequence_length = sequence_length , <NEWLINE> initial_state = initial_state ) <NEWLINE> <UNTAB> return target_predictor_fn ( encoding , y ) <NEWLINE> <NEWLINE> <UNTAB> return rnn_estimator <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def smoothness_p ( n , m = - <NUMBER> , power = <NUMBER> , visual = None ) : <NEWLINE> <TAB> <NEWLINE> from sympy . utilities import flatten <NEWLINE> <NEWLINE> <NEWLINE> if visual in ( <NUMBER> , <NUMBER> ) : <NEWLINE> <TAB> visual = bool ( visual ) <NEWLINE> <UNTAB> elif visual not in ( True , False ) : <NEWLINE> <TAB> visual = None <NEWLINE> <NEWLINE> <UNTAB> if type ( n ) is str : <NEWLINE> <TAB> if visual : <NEWLINE> <TAB> return n <NEWLINE> <UNTAB> d = { } <NEWLINE> for li in n . splitlines ( ) : <NEWLINE> <TAB> k , v = [ int ( i ) for i in <NEWLINE> li . split ( <STRING> ) [ <NUMBER> ] . split ( <STRING> ) [ <NUMBER> ] . split ( <STRING> ) ] <NEWLINE> d [ k ] = v <NEWLINE> <UNTAB> if visual is not True and visual is not False : <NEWLINE> <TAB> return d <NEWLINE> <UNTAB> return smoothness_p ( d , visual = False ) <NEWLINE> <UNTAB> elif type ( n ) is not tuple : <NEWLINE> <TAB> facs = factorint ( n , visual = False ) <NEWLINE> <NEWLINE> <UNTAB> if power : <NEWLINE> <TAB> k = - <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> k = <NUMBER> <NEWLINE> <UNTAB> if type ( n ) is not tuple : <NEWLINE> <TAB> rv = ( m , sorted ( [ ( f , <NEWLINE> tuple ( [ M ] + list ( smoothness ( f + m ) ) ) ) <NEWLINE> for f , M in [ i for i in facs . items ( ) ] ] , <NEWLINE> key = lambda x : ( x [ <NUMBER> ] [ k ] , x [ <NUMBER> ] ) ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> rv = n <NEWLINE> <NEWLINE> <UNTAB> if visual is False or ( visual is not True ) and ( type ( n ) in [ int , Mul ] ) : <NEWLINE> <TAB> return rv <NEWLINE> <UNTAB> lines = [ ] <NEWLINE> for dat in rv [ <NUMBER> ] : <NEWLINE> <TAB> dat = flatten ( dat ) <NEWLINE> dat . insert ( <NUMBER> , m ) <NEWLINE> lines . append ( <STRING> % tuple ( dat ) ) <NEWLINE> <UNTAB> return <STRING> . join ( lines ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def trigger ( self , sender , event , data ) : <NEWLINE> <TAB> <NEWLINE> if not self . figure . canvas . widgetlock . available ( sender ) : <NEWLINE> <TAB> return <NEWLINE> <UNTAB> if data is not None : <NEWLINE> <TAB> self . draw_rubberband ( * data ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . remove_rubberband ( ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def pow ( f , n ) : <NEWLINE> <TAB> <NEWLINE> if isinstance ( n , int ) : <NEWLINE> <TAB> if n < <NUMBER> : <NEWLINE> <TAB> F , n = dup_invert ( f . rep , f . mod , f . dom ) , - n <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> F = f . rep <NEWLINE> <NEWLINE> <UNTAB> return f . per ( dup_rem ( dup_pow ( F , n , f . dom ) , f . mod , f . dom ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> raise TypeError ( <STRING> % type ( n ) ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def add_data ( self , name , element_type , value , <NEWLINE> scope = <STRING> , <NEWLINE> default = None ) : <NEWLINE> <TAB> <NEWLINE> if element_type not in self . xml_type : <NEWLINE> <TAB> msg = <STRING> <NEWLINE> raise nx . NetworkXError ( msg % element_type ) <NEWLINE> <UNTAB> keyid = self . get_key ( name , self . xml_type [ element_type ] , scope , default ) <NEWLINE> data_element = self . myElement ( <STRING> , key = keyid ) <NEWLINE> data_element . text = make_str ( value ) <NEWLINE> return data_element <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def scan_prefix ( self , prefix , probability = None , columns = None , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> probability = _normalize_probability ( probability ) <NEWLINE> normalized = _normalize_columns ( columns , kwargs ) <NEWLINE> return _BigtableScanDataset ( self , prefix , <STRING> , <STRING> , normalized , probability ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def transform ( self , node , get_nodes = True ) : <NEWLINE> <TAB> <NEWLINE> if get_nodes and self . get_nodes is not None : <NEWLINE> <TAB> for real_node in self . get_nodes ( node ) : <NEWLINE> <TAB> if real_node == <STRING> : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> ret = self . transform ( real_node , get_nodes = False ) <NEWLINE> if ret is not False and ret is not None : <NEWLINE> <TAB> assert len ( real_node . outputs ) == len ( ret ) <NEWLINE> if self . values_eq_approx : <NEWLINE> <TAB> ret . tag . values_eq_approx = self . values_eq_approx <NEWLINE> <UNTAB> return dict ( izip ( real_node . outputs , ret ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> if node . op != self . op : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> def match ( pattern , expr , u , allow_multiple_clients = False , pdb = False ) : <NEWLINE> <NEWLINE> <TAB> def retry_with_equiv ( ) : <NEWLINE> <TAB> if not self . skip_identities_fn : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> expr_equiv = self . skip_identities_fn ( expr ) <NEWLINE> if expr_equiv is None : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> return match ( pattern , expr_equiv , u , <NEWLINE> allow_multiple_clients = allow_multiple_clients ) <NEWLINE> <NEWLINE> <UNTAB> if isinstance ( pattern , ( list , tuple ) ) : <NEWLINE> <TAB> if expr . owner is None : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> if ( not ( expr . owner . op == pattern [ <NUMBER> ] ) or <NEWLINE> ( not allow_multiple_clients and len ( expr . clients ) > <NUMBER> ) ) : <NEWLINE> <TAB> return retry_with_equiv ( ) <NEWLINE> <UNTAB> if len ( pattern ) - <NUMBER> != len ( expr . owner . inputs ) : <NEWLINE> <TAB> return retry_with_equiv ( ) <NEWLINE> <UNTAB> for p , v in zip ( pattern [ <NUMBER> : ] , expr . owner . inputs ) : <NEWLINE> <TAB> u = match ( p , v , u , self . allow_multiple_clients ) <NEWLINE> if not u : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> elif isinstance ( pattern , dict ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> real_pattern = pattern [ <STRING> ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> raise KeyError ( <NEWLINE> <STRING> <NEWLINE> % pattern ) <NEWLINE> <UNTAB> constraint = pattern . get ( <STRING> , lambda expr : True ) <NEWLINE> if constraint ( expr ) : <NEWLINE> <TAB> return match ( real_pattern , expr , u , <NEWLINE> pattern . get ( <STRING> , <NEWLINE> allow_multiple_clients ) ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return retry_with_equiv ( ) <NEWLINE> <UNTAB> <UNTAB> elif isinstance ( pattern , string_types ) : <NEWLINE> <TAB> v = unify . Var ( pattern ) <NEWLINE> if u [ v ] is not v and u [ v ] is not expr : <NEWLINE> <TAB> return retry_with_equiv ( ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> u = u . merge ( expr , v ) <NEWLINE> <UNTAB> <UNTAB> elif ( isinstance ( pattern , ( integer_types , float ) ) and <NEWLINE> isinstance ( expr , graph . Constant ) ) : <NEWLINE> <TAB> if np . all ( theano . tensor . constant ( pattern ) . value == expr . value ) : <NEWLINE> <TAB> return u <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return retry_with_equiv ( ) <NEWLINE> <UNTAB> <UNTAB> elif ( isinstance ( pattern , graph . Constant ) and <NEWLINE> isinstance ( expr , graph . Constant ) and <NEWLINE> pattern . equals ( expr ) ) : <NEWLINE> <TAB> return u <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return retry_with_equiv ( ) <NEWLINE> <UNTAB> if pdb : <NEWLINE> <TAB> import pdb <NEWLINE> pdb . set_trace ( ) <NEWLINE> <UNTAB> return u <NEWLINE> <NEWLINE> <UNTAB> u = match ( self . in_pattern , node . out , unify . Unification ( ) , True , <NEWLINE> self . pdb ) <NEWLINE> if u : <NEWLINE> <TAB> def build ( pattern , u ) : <NEWLINE> <TAB> if isinstance ( pattern , ( list , tuple ) ) : <NEWLINE> <TAB> args = [ build ( p , u ) for p in pattern [ <NUMBER> : ] ] <NEWLINE> return pattern [ <NUMBER> ] ( * args ) <NEWLINE> <UNTAB> elif isinstance ( pattern , string_types ) : <NEWLINE> <TAB> return u [ unify . Var ( pattern ) ] <NEWLINE> <UNTAB> elif isinstance ( pattern , ( integer_types , float ) ) : <NEWLINE> <TAB> return pattern <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return pattern . clone ( ) <NEWLINE> <UNTAB> <UNTAB> p = self . out_pattern <NEWLINE> ret = build ( p , u ) <NEWLINE> if self . values_eq_approx : <NEWLINE> <TAB> ret . tag . values_eq_approx = self . values_eq_approx <NEWLINE> <UNTAB> return [ ret ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def put ( self , values , name = None ) : <NEWLINE> <TAB> <NEWLINE> with ops . name_scope ( name , <STRING> % self . _name , <NEWLINE> self . _scope_vals ( values ) ) as scope : <NEWLINE> <NEWLINE> <TAB> if not isinstance ( values , ( list , tuple , dict ) ) : <NEWLINE> <TAB> values = [ values ] <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> indices = list ( six . moves . range ( len ( values ) ) ) <NEWLINE> vals , _ = self . _check_put_dtypes ( values , indices ) <NEWLINE> <NEWLINE> with ops . colocate_with ( self . _coloc_op ) : <NEWLINE> <TAB> op = gen_data_flow_ops . stage ( <NEWLINE> values = vals , <NEWLINE> shared_name = self . _name , <NEWLINE> name = scope , <NEWLINE> capacity = self . _capacity , <NEWLINE> memory_limit = self . _memory_limit ) <NEWLINE> <NEWLINE> <UNTAB> return op <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _is_sorted ( self , x ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return _path . is_sorted ( x ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def tostring ( self , fill_value = None , order = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> return self . tobytes ( fill_value , order = <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def attribute_mixing_dict ( G , attribute , nodes = None , normalized = False ) : <NEWLINE> <TAB> <NEWLINE> xy_iter = node_attribute_xy ( G , attribute , nodes ) <NEWLINE> return mixing_dict ( xy_iter , normalized = normalized ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ tf_contextlib . contextmanager <NEWLINE> def gradient_override_map ( self , op_type_map ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( op_type_map , dict ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> saved_mappings = { } <NEWLINE> <NEWLINE> for op_type , mapped_op_type in op_type_map . items ( ) : <NEWLINE> <TAB> if not ( isinstance ( op_type , six . string_types ) and <NEWLINE> isinstance ( mapped_op_type , six . string_types ) ) : <NEWLINE> <TAB> raise TypeError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> saved_mappings [ op_type ] = self . _gradient_override_map [ op_type ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> pass <NEWLINE> <UNTAB> self . _gradient_override_map [ op_type ] = mapped_op_type <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> yield <NEWLINE> <UNTAB> finally : <NEWLINE> <NEWLINE> <TAB> for op_type , mapped_op_type in op_type_map . items ( ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> self . _gradient_override_map [ op_type ] = saved_mappings [ op_type ] <NEWLINE> <UNTAB> except KeyError : <NEWLINE> <TAB> del self . _gradient_override_map [ op_type ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def bias_add_v1_eager_fallback ( value , bias , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ value , bias ] , _ctx ) <NEWLINE> ( value , bias ) = _inputs_T <NEWLINE> _inputs_flat = [ value , bias ] <NEWLINE> _attrs = ( <STRING> , _attr_T ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def conv3d_backprop_input_v2_eager_fallback ( input_sizes , filter , out_backprop , strides , padding , data_format = <STRING> , dilations = [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> if not isinstance ( strides , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % strides ) <NEWLINE> <UNTAB> strides = [ _execute . make_int ( _i , <STRING> ) for _i in strides ] <NEWLINE> padding = _execute . make_str ( padding , <STRING> ) <NEWLINE> if data_format is None : <NEWLINE> <TAB> data_format = <STRING> <NEWLINE> <UNTAB> data_format = _execute . make_str ( data_format , <STRING> ) <NEWLINE> if dilations is None : <NEWLINE> <TAB> dilations = [ <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> , <NUMBER> ] <NEWLINE> <UNTAB> if not isinstance ( dilations , ( list , tuple ) ) : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> <STRING> % dilations ) <NEWLINE> <UNTAB> dilations = [ _execute . make_int ( _i , <STRING> ) for _i in dilations ] <NEWLINE> _attr_T , _inputs_T = _execute . args_to_matching_eager ( [ filter , out_backprop ] , _ctx ) <NEWLINE> ( filter , out_backprop ) = _inputs_T <NEWLINE> _attr_Tshape , ( input_sizes , ) = _execute . args_to_matching_eager ( [ input_sizes ] , _ctx , _dtypes . int32 ) <NEWLINE> _inputs_flat = [ input_sizes , filter , out_backprop ] <NEWLINE> _attrs = ( <STRING> , _attr_T , <STRING> , strides , <STRING> , padding , <NEWLINE> <STRING> , data_format , <STRING> , dilations , <STRING> , _attr_Tshape ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_preferred_index ( self ) : <NEWLINE> <TAB> <NEWLINE> if not self . is_above_fermi : <NEWLINE> <TAB> if self . args [ <NUMBER> ] . assumptions0 . get ( <STRING> ) : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> <UNTAB> elif not self . is_below_fermi : <NEWLINE> <TAB> if self . args [ <NUMBER> ] . assumptions0 . get ( <STRING> ) : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def equalize_hist ( image , nbins = <NUMBER> , mask = None ) : <NEWLINE> <TAB> <NEWLINE> if mask is not None : <NEWLINE> <TAB> mask = np . array ( mask , dtype = bool ) <NEWLINE> cdf , bin_centers = cumulative_distribution ( image [ mask ] , nbins ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> cdf , bin_centers = cumulative_distribution ( image , nbins ) <NEWLINE> <UNTAB> out = np . interp ( image . flat , bin_centers , cdf ) <NEWLINE> return out . reshape ( image . shape ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , wait_until_step ) : <NEWLINE> <TAB> <NEWLINE> self . _wait_until_step = wait_until_step <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _eval_is_imaginary ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . index >= len ( _reals_cache [ self . poly ] ) : <NEWLINE> <TAB> ivl = self . _get_interval ( ) <NEWLINE> return ivl . ax * ivl . bx <= <NUMBER> <NEWLINE> <UNTAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def nonzero ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _values . nonzero ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def linregress ( x , y = None ) : <NEWLINE> <TAB> <NEWLINE> TINY = <NUMBER> <NEWLINE> if y is None : <NEWLINE> <TAB> x = np . asarray ( x ) <NEWLINE> if x . shape [ <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> x , y = x <NEWLINE> <UNTAB> elif x . shape [ <NUMBER> ] == <NUMBER> : <NEWLINE> <TAB> x , y = x . T <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> msg = ( <STRING> <NEWLINE> <STRING> % str ( x . shape ) ) <NEWLINE> raise ValueError ( msg ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> x = np . asarray ( x ) <NEWLINE> y = np . asarray ( y ) <NEWLINE> <NEWLINE> <UNTAB> if x . size == <NUMBER> or y . size == <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> n = len ( x ) <NEWLINE> xmean = np . mean ( x , None ) <NEWLINE> ymean = np . mean ( y , None ) <NEWLINE> <NEWLINE> <NEWLINE> ssxm , ssxym , ssyxm , ssym = np . cov ( x , y , bias = <NUMBER> ) . flat <NEWLINE> r_num = ssxym <NEWLINE> r_den = np . sqrt ( ssxm * ssym ) <NEWLINE> if r_den == <NUMBER> : <NEWLINE> <TAB> r = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> r = r_num / r_den <NEWLINE> <NEWLINE> if r > <NUMBER> : <NEWLINE> <TAB> r = <NUMBER> <NEWLINE> <UNTAB> elif r < - <NUMBER> : <NEWLINE> <TAB> r = - <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> df = n - <NUMBER> <NEWLINE> slope = r_num / ssxm <NEWLINE> intercept = ymean - slope * xmean <NEWLINE> if n == <NUMBER> : <NEWLINE> <NEWLINE> <TAB> if y [ <NUMBER> ] == y [ <NUMBER> ] : <NEWLINE> <TAB> prob = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> prob = <NUMBER> <NEWLINE> <UNTAB> sterrest = <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> t = r * np . sqrt ( df / ( ( <NUMBER> - r + TINY ) * ( <NUMBER> + r + TINY ) ) ) <NEWLINE> prob = <NUMBER> * distributions . t . sf ( np . abs ( t ) , df ) <NEWLINE> sterrest = np . sqrt ( ( <NUMBER> - r ** <NUMBER> ) * ssym / ssxm / df ) <NEWLINE> <NEWLINE> <UNTAB> return LinregressResult ( slope , intercept , r , prob , sterrest ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _remove_tool_cbk ( self , event ) : <NEWLINE> <TAB> <NEWLINE> self . remove_toolitem ( event . tool . name ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rs_hadamard_exp ( p1 , inverse = False ) : <NEWLINE> <TAB> <NEWLINE> R = p1 . ring <NEWLINE> if R . domain != QQ : <NEWLINE> <TAB> raise NotImplementedError <NEWLINE> <UNTAB> p = R . zero <NEWLINE> if not inverse : <NEWLINE> <TAB> for exp1 , v1 in p1 . items ( ) : <NEWLINE> <TAB> p [ exp1 ] = v1 / int ( ifac ( exp1 [ <NUMBER> ] ) ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> for exp1 , v1 in p1 . items ( ) : <NEWLINE> <TAB> p [ exp1 ] = v1 * int ( ifac ( exp1 [ <NUMBER> ] ) ) <NEWLINE> <UNTAB> <UNTAB> return p <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , dtype , shape , accumulator_ref ) : <NEWLINE> <TAB> <NEWLINE> self . _dtype = dtype <NEWLINE> if shape is not None : <NEWLINE> <TAB> self . _shape = tensor_shape . TensorShape ( shape ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _shape = tensor_shape . unknown_shape ( ) <NEWLINE> <UNTAB> self . _accumulator_ref = accumulator_ref <NEWLINE> if context . executing_eagerly ( ) : <NEWLINE> <TAB> self . _name = context . context ( ) . scope_name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _name = self . _accumulator_ref . op . name . split ( <STRING> ) [ - <NUMBER> ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def node_link_data ( G , attrs = None ) : <NEWLINE> <TAB> <NEWLINE> multigraph = G . is_multigraph ( ) <NEWLINE> <NEWLINE> if attrs is None : <NEWLINE> <TAB> attrs = _attrs <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> attrs . update ( { k : v for ( k , v ) in _attrs . items ( ) if k not in attrs } ) <NEWLINE> <UNTAB> name = attrs [ <STRING> ] <NEWLINE> source = attrs [ <STRING> ] <NEWLINE> target = attrs [ <STRING> ] <NEWLINE> links = attrs [ <STRING> ] <NEWLINE> <NEWLINE> key = None if not multigraph else attrs [ <STRING> ] <NEWLINE> if len ( { source , target , key } ) < <NUMBER> : <NEWLINE> <TAB> raise nx . NetworkXError ( <STRING> ) <NEWLINE> <UNTAB> data = { <STRING> : G . is_directed ( ) , <STRING> : multigraph , <STRING> : G . graph , <NEWLINE> <STRING> : [ dict ( chain ( G . nodes [ n ] . items ( ) , [ ( name , n ) ] ) ) for n in G ] } <NEWLINE> if multigraph : <NEWLINE> <TAB> data [ links ] = [ <NEWLINE> dict ( chain ( d . items ( ) , <NEWLINE> [ ( source , u ) , ( target , v ) , ( key , k ) ] ) ) <NEWLINE> for u , v , k , d in G . edges ( keys = True , data = True ) ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> data [ links ] = [ <NEWLINE> dict ( chain ( d . items ( ) , <NEWLINE> [ ( source , u ) , ( target , v ) ] ) ) <NEWLINE> for u , v , d in G . edges ( data = True ) ] <NEWLINE> <UNTAB> return data <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _inverse ( self , y ) : <NEWLINE> <TAB> <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_schema_names ( self ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if hasattr ( self . dialect , <STRING> ) : <NEWLINE> <TAB> return self . dialect . get_schema_names ( self . bind , <NEWLINE> info_cache = self . info_cache ) <NEWLINE> <UNTAB> return [ ] <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def inverse ( self , argindex = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return acoth <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def as_relational ( self , symbol ) : <NEWLINE> <TAB> <NEWLINE> if len ( self . args ) == <NUMBER> : <NEWLINE> <TAB> a , b = self . args <NEWLINE> if ( a . sup == b . inf and a . inf is S . NegativeInfinity <NEWLINE> and b . sup is S . Infinity ) : <NEWLINE> <TAB> return And ( Ne ( symbol , a . sup ) , symbol < b . sup , symbol > a . inf ) <NEWLINE> <UNTAB> <UNTAB> return Or ( * [ set . as_relational ( symbol ) for set in self . args ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def total_average ( self ) : <NEWLINE> <TAB> <NEWLINE> total_stat = FunctionEventAvg ( ) <NEWLINE> for evt in self : <NEWLINE> <TAB> total_stat += evt <NEWLINE> total_stat . key = None <NEWLINE> <UNTAB> total_stat . key = <STRING> <NEWLINE> return total_stat <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def stack ( values , axis = <NUMBER> , name = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if axis == <NUMBER> : <NEWLINE> <TAB> try : <NEWLINE> <NEWLINE> <TAB> return ops . convert_to_tensor ( values , name = name ) <NEWLINE> <UNTAB> except ( TypeError , ValueError ) : <NEWLINE> <TAB> pass <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> value_shape = ops . convert_to_tensor ( values [ <NUMBER> ] , name = name ) . _shape_tuple ( ) <NEWLINE> if value_shape is not None : <NEWLINE> <TAB> expanded_num_dims = len ( value_shape ) + <NUMBER> <NEWLINE> if axis < - expanded_num_dims or axis >= expanded_num_dims : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( axis , - expanded_num_dims , <NEWLINE> expanded_num_dims ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return gen_array_ops . pack ( values , axis = axis , name = name ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def cuda ( self , device = None ) : <NEWLINE> <TAB> <NEWLINE> return self . _apply ( lambda t : t . cuda ( device ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def with_metaclass ( meta , * bases ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> class metaclass ( meta ) : <NEWLINE> <TAB> def __new__ ( cls , name , this_bases , d ) : <NEWLINE> <TAB> return meta ( name , bases , d ) <NEWLINE> <UNTAB> <UNTAB> return type . __new__ ( metaclass , <STRING> , ( ) , { } ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_pixel_distance_along_axis ( self , where , perturb ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> trans = self . axes . transData <NEWLINE> <NEWLINE> transinv = trans . inverted ( ) <NEWLINE> pix = trans . transform_point ( ( <NUMBER> , where ) ) <NEWLINE> <NEWLINE> ptp = transinv . transform_point ( ( pix [ <NUMBER> ] , pix [ <NUMBER> ] + perturb ) ) <NEWLINE> dy = abs ( ptp [ <NUMBER> ] - where ) <NEWLINE> return dy <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def string_to_hash_bucket_fast ( input , num_buckets , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> num_buckets = _execute . make_int ( num_buckets , <STRING> ) <NEWLINE> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , input = input , num_buckets = num_buckets , <NEWLINE> name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <NEWLINE> <STRING> , name , _ctx . _post_execution_callbacks , input , <NEWLINE> <STRING> , num_buckets ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return string_to_hash_bucket_fast_eager_fallback ( <NEWLINE> input , num_buckets = num_buckets , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _to_ndimage_mode ( mode ) : <NEWLINE> <TAB> <NEWLINE> mode_translation_dict = dict ( edge = <STRING> , symmetric = <STRING> , <NEWLINE> reflect = <STRING> ) <NEWLINE> if mode in mode_translation_dict : <NEWLINE> <TAB> mode = mode_translation_dict [ mode ] <NEWLINE> <UNTAB> return mode <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def spatial_transformer_grid ( theta , output_shape , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> if kwargs : <NEWLINE> <TAB> argument . check_unexpected_kwargs ( <NEWLINE> kwargs , use_cudnn = <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> argument . assert_kwargs_empty ( kwargs ) <NEWLINE> <UNTAB> return SpatialTransformerGrid ( output_shape ) ( theta ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _add ( a , b ) : <NEWLINE> <TAB> <NEWLINE> da , db = a . denominator , b . denominator <NEWLINE> return Fraction ( a . numerator * db + b . numerator * da , <NEWLINE> da * db ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def from_float ( x , prec = <NUMBER> , rnd = round_fast ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if x != x : <NEWLINE> <TAB> return fnan <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> m , e = math . frexp ( x ) <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> if x == math_float_inf : return finf <NEWLINE> if x == - math_float_inf : return fninf <NEWLINE> return fnan <NEWLINE> <UNTAB> if x == math_float_inf : return finf <NEWLINE> if x == - math_float_inf : return fninf <NEWLINE> return from_man_exp ( int ( m * ( <NUMBER> << <NUMBER> ) ) , e - <NUMBER> , prec , rnd ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def dmp_zz_diophantine ( F , c , A , d , p , u , K ) : <NEWLINE> <TAB> <NEWLINE> if not A : <NEWLINE> <TAB> S = [ [ ] for _ in F ] <NEWLINE> n = dup_degree ( c ) <NEWLINE> <NEWLINE> for i , coeff in enumerate ( c ) : <NEWLINE> <TAB> if not coeff : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> T = dup_zz_diophantine ( F , n - i , p , K ) <NEWLINE> <NEWLINE> for j , ( s , t ) in enumerate ( zip ( S , T ) ) : <NEWLINE> <TAB> t = dup_mul_ground ( t , coeff , K ) <NEWLINE> S [ j ] = dup_trunc ( dup_add ( s , t , K ) , p , K ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> n = len ( A ) <NEWLINE> e = dmp_expand ( F , u , K ) <NEWLINE> <NEWLINE> a , A = A [ - <NUMBER> ] , A [ : - <NUMBER> ] <NEWLINE> B , G = [ ] , [ ] <NEWLINE> <NEWLINE> for f in F : <NEWLINE> <TAB> B . append ( dmp_quo ( e , f , u , K ) ) <NEWLINE> G . append ( dmp_eval_in ( f , a , n , u , K ) ) <NEWLINE> <NEWLINE> <UNTAB> C = dmp_eval_in ( c , a , n , u , K ) <NEWLINE> <NEWLINE> v = u - <NUMBER> <NEWLINE> <NEWLINE> S = dmp_zz_diophantine ( G , C , A , d , p , v , K ) <NEWLINE> S = [ dmp_raise ( s , <NUMBER> , v , K ) for s in S ] <NEWLINE> <NEWLINE> for s , b in zip ( S , B ) : <NEWLINE> <TAB> c = dmp_sub_mul ( c , s , b , u , K ) <NEWLINE> <NEWLINE> <UNTAB> c = dmp_ground_trunc ( c , p , u , K ) <NEWLINE> <NEWLINE> m = dmp_nest ( [ K . one , - a ] , n , K ) <NEWLINE> M = dmp_one ( n , K ) <NEWLINE> <NEWLINE> for k in K . map ( range ( <NUMBER> , d ) ) : <NEWLINE> <TAB> if dmp_zero_p ( c , u ) : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <UNTAB> M = dmp_mul ( M , m , u , K ) <NEWLINE> C = dmp_diff_eval_in ( c , k + <NUMBER> , a , n , u , K ) <NEWLINE> <NEWLINE> if not dmp_zero_p ( C , v ) : <NEWLINE> <TAB> C = dmp_quo_ground ( C , K . factorial ( k + <NUMBER> ) , v , K ) <NEWLINE> T = dmp_zz_diophantine ( G , C , A , d , p , v , K ) <NEWLINE> <NEWLINE> for i , t in enumerate ( T ) : <NEWLINE> <TAB> T [ i ] = dmp_mul ( dmp_raise ( t , <NUMBER> , v , K ) , M , u , K ) <NEWLINE> <NEWLINE> <UNTAB> for i , ( s , t ) in enumerate ( zip ( S , T ) ) : <NEWLINE> <TAB> S [ i ] = dmp_add ( s , t , u , K ) <NEWLINE> <NEWLINE> <UNTAB> for t , b in zip ( T , B ) : <NEWLINE> <TAB> c = dmp_sub_mul ( c , t , b , u , K ) <NEWLINE> <NEWLINE> <UNTAB> c = dmp_ground_trunc ( c , p , u , K ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> S = [ dmp_ground_trunc ( s , p , u , K ) for s in S ] <NEWLINE> <NEWLINE> <UNTAB> return S <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def c_code_helper ( self , bottom , weights , top , sub , height = None , width = None ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if height : <NEWLINE> <TAB> height = <STRING> % height <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if ( ( self . direction != <NUMBER> ) and ( self . dH != <NUMBER> ) ) or ( ( self . direction == <NUMBER> ) and ( self . padH_l == - <NUMBER> or self . padH_r == - <NUMBER> ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> height = <STRING> <NEWLINE> <UNTAB> if width : <NEWLINE> <TAB> width = <STRING> % width <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> if ( ( self . direction != <NUMBER> ) and ( self . dW != <NUMBER> ) ) or ( ( self . direction == <NUMBER> ) and ( self . padW_l == - <NUMBER> or self . padW_r == - <NUMBER> ) ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> width = <STRING> <NEWLINE> <NEWLINE> <UNTAB> return " " " 
         / /   M a n d a t o r y   a r g s 
         i n t   d i r e c t i o n   =   % ( p a r a m s ) s - > d i r e c t i o n ;     / /   f o r w a r d ,   b p r o p   w e i g h t s ,   b p r o p   i n p u t s 
 
         / /   O p t i o n a l   a r g s 
         i n t   d H   =   % ( p a r a m s ) s - > d H ; 
         i n t   d W   =   % ( p a r a m s ) s - > d W ; 
         i n t   d i l H   =   % ( p a r a m s ) s - > d i l H ; 
         i n t   d i l W   =   % ( p a r a m s ) s - > d i l W ; 
         i n t   p a d H _ l   =   % ( p a r a m s ) s - > p a d H _ l ; 
         i n t   p a d H _ r   =   % ( p a r a m s ) s - > p a d H _ r ; 
         i n t   p a d W _ l   =   % ( p a r a m s ) s - > p a d W _ l ; 
         i n t   p a d W _ r   =   % ( p a r a m s ) s - > p a d W _ r ; 
         i n t   n u m g r o u p s   =   % ( p a r a m s ) s - > n u m _ g r o u p s ; 
         i n t   u n s h a r e d   =   % ( p a r a m s ) s - > u n s h a r e d ; 
 
         P y A r r a y O b j e c t   *   b o t t o m   =   % ( b o t t o m ) s ; 
         P y A r r a y O b j e c t   *   w e i g h t s   =   % ( w e i g h t s ) s ; 
         P y A r r a y O b j e c t   *   t o p   =   % ( t o p ) s ; 
         P y A r r a y O b j e c t   *   o u t 2   =   N U L L ; 
         P y A r r a y O b j e c t   * * o u t   =   N U L L ; 
 
         s w i t c h ( % ( p a r a m s ) s - > d i r e c t i o n )   { 
                 c a s e   D I R E C T I O N _ F O R W A R D : 
                         o u t   =   & % ( t o p ) s ; 
                         b r e a k ; 
                 c a s e   D I R E C T I O N _ B A C K P R O P _ W E I G H T S : 
                         o u t   =   & % ( w e i g h t s ) s ; 
                         b r e a k ; 
                 c a s e   D I R E C T I O N _ B A C K P R O P _ I N P U T S : 
                         o u t   =   & % ( b o t t o m ) s ; 
                         b r e a k ; 
                 d e f a u l t : 
                         P y E r r _ S e t S t r i n g ( P y E x c _ V a l u e E r r o r ,   " C P U   C o r r M M :   I n v a l i d   d i r e c t i o n . " ) ; 
                         { % ( f a i l ) s } 
                         b r e a k ; 
         } 
 
         i n t   w d i m ,   o d i m ; 
         w d i m   =   u n s h a r e d   ?   6   :   4 ; 
         o d i m   =   4 ;   / / C a n   b e   s e t   t o   6   l a t e r   f o r   u n s h a r e d   b a c k p r o p   w r t   w e i g h t s 
 
         / /   O b t a i n   o r   i n f e r   k e r n e l   w i d t h   a n d   h e i g h t 
         / /   ( w e   n e e d   t o   k n o w   i t   e a r l y   t o   b e   a b l e   t o   h a n d l e   a u t o - p a d d i n g ) 
         i n t   k H ,   k W ,   d i l _ k H ,   d i l _ k W ; 
         i f   ( d i r e c t i o n   ! =   1 )   { 
                 / /   w e i g h t   i s   a n   i n p u t   v a r i a b l e ,   w e   c a n   j u s t   r e a d   i t s   s h a p e 
                 k H   =   P y A r r a y _ D I M S ( w e i g h t s ) [ w d i m - 2 ] ; 
                 k W   =   P y A r r a y _ D I M S ( w e i g h t s ) [ w d i m - 1 ] ; 
         } 
         e l s e   { 
                 i f   ( % ( h e i g h t ) s   ! =   - 1 )   { 
                         / /   k e r n e l   h e i g h t   i s   s p e c i f i e d   ( p e r h a p s   v e r t i c a l   s u b s a m p l i n g   o r   h a l f   p a d d i n g ) 
                         k H   =   % ( h e i g h t ) s ; 
                 } 
                 e l s e   i f   ( p a d H _ l   = =   - 2   | |   p a d H _ r   = =   - 2 )   { 
                         / /   v e r t i c a l   f u l l   p a d d i n g ,   w e   c a n   i n f e r   t h e   k e r n e l   h e i g h t 
                         k H   =   ( 2   -   P y A r r a y _ D I M S ( b o t t o m ) [ 2 ]   +   ( P y A r r a y _ D I M S ( t o p ) [ 2 ]   -   1 )   *   d H   -   1 ) /   d i l H   +   1 ; 
                 } 
                 e l s e   { 
                         / /   e x p l i c i t   p a d d i n g ,   w e   c a n   i n f e r   t h e   k e r n e l   h e i g h t 
                         k H   =   ( P y A r r a y _ D I M S ( b o t t o m ) [ 2 ]   +   p a d H _ l   +   p a d H _ r   -   ( P y A r r a y _ D I M S ( t o p ) [ 2 ]   -   1 )   *   d H   -   1 )   /   d i l H   + 1 ; 
                 } 
                 i f   ( % ( w i d t h ) s   ! =   - 1 )   { 
                         / /   k e r n e l   w i d t h   i s   s p e c i f i e d   ( p e r h a p s   h o r i z o n t a l   s u b s a m p l i n g   o r   h a l f   p a d d i n g ) 
                         k W   =   % ( w i d t h ) s ; 
                 } 
                 e l s e   i f   ( p a d W _ l   = =   - 2   | |   p a d W _ r   = =   - 2 )   { 
                         k W   =   ( 2   -   P y A r r a y _ D I M S ( b o t t o m ) [ 3 ]   +   ( P y A r r a y _ D I M S ( t o p ) [ 3 ]   -   1 )   *   d W   -   1 )   /   d i l W   +   1 ; 
                 } 
                 e l s e   { 
                         k W   =   ( P y A r r a y _ D I M S ( b o t t o m ) [ 3 ]   +   p a d W _ l   +   p a d W _ r   -   ( P y A r r a y _ D I M S ( t o p ) [ 3 ]   -   1 )   *   d W   -   1 )   /   d i l W   +   1 ; 
                 } 
         } 
 
         / /   I m p l i c i t   d i l a t e d   k e r n e l   s i z e 
         d i l _ k H   =   ( k H   -   1 )   *   d i l H   +   1 ; 
         d i l _ k W   =   ( k W   -   1 )   *   d i l W   +   1 ; 
 
         / /   A u t o - p a d d i n g   i f   r e q u e s t e d 
         i f   ( p a d H _ l   = =   - 1   | |   p a d H _ r   = =   - 1 )   {     / /   v e r t i c a l   h a l f   p a d d i n g 
                 p a d H _ l   =   p a d H _ r   =   d i l _ k H   /   2 ; 
         } 
         e l s e   i f   ( p a d H _ l   = =   - 2   | |   p a d H _ r   = =   - 2 )   {     / /   v e r t i c a l   f u l l   p a d d i n g 
                 p a d H _ l   =   p a d H _ r   =   d i l _ k H   -   1 ; 
         } 
         e l s e   i f   ( p a d H _ l   <   - 2   | |   p a d H _ r   <   - 2 )   { 
                 P y E r r _ S e t S t r i n g ( P y E x c _ V a l u e E r r o r ,   " B a s e C o r r M M :   p a d H _ l   a n d   p a d H _ r   m u s t   b e   > =   - 2 " ) ; 
                 % ( f a i l ) s 
         } 
         i f   ( p a d W _ l   = =   - 1   | |   p a d W _ r   = =   - 1 )   {     / /   h o r i z o n t a l   h a l f   p a d d i n g 
                 p a d W _ l   =   p a d W _ r   =   d i l _ k W   /   2 ; 
         } 
         e l s e   i f   ( p a d W _ l   = =   - 2   | |   p a d W _ r   = =   - 2 )   {     / /   h o r i z o n t a l   f u l l   p a d d i n g 
                 p a d W _ l   =   p a d W _ r   =   d i l _ k W   -   1 ; 
         } 
         e l s e   i f   ( p a d W _ l   <   - 2   | |   p a d W _ r   <   - 2 )   { 
                 P y E r r _ S e t S t r i n g ( P y E x c _ V a l u e E r r o r ,   " B a s e C o r r M M :   p a d W _ l   a n d   p a d W _ r   m u s t   b e   > =   - 2 " ) ; 
                 % ( f a i l ) s 
         } 
 
         / /   I n f e r   o u t p u t   s h a p e 
         n p y _ i n t p   o u t _ d i m [ 6 ] ; 
         o u t _ d i m [ 4 ]   =   o u t _ d i m [ 5 ]   =   0 ;   / / O n l y   u s e d   f o r   u n s h a r e d   b a c k p r o p   w r t   w e i g h t s 
         s w i t c h ( d i r e c t i o n )   { 
         c a s e   0 :     / /   f o r w a r d   p a s s 
                 / /   o u t p u t   i s   t o p :   ( b a t c h s i z e ,   n u m _ f i l t e r s ,   h e i g h t ,   w i d t h ) 
                 / /   h e i g h t   a n d   w i d t h :   t o p   =   ( b o t t o m   +   p a d _ l   +   p a d _ r   -   ( ( w e i g h t - 1 ) * d i l   +   1 ) )   /   s a m p l e   +   1 
                 o u t _ d i m [ 0 ]   =   ( n p y _ i n t p ) P y A r r a y _ D I M S ( b o t t o m ) [ 0 ] ; 
                 o u t _ d i m [ 1 ]   =   ( n p y _ i n t p ) P y A r r a y _ D I M S ( w e i g h t s ) [ 0 ] ; 
                 o u t _ d i m [ 2 ]   =   ( n p y _ i n t p ) ( ( P y A r r a y _ D I M S ( b o t t o m ) [ 2 ]   +   p a d H _ l   +   p a d H _ r   -   ( ( P y A r r a y _ D I M S ( w e i g h t s ) [ w d i m - 2 ] - 1 ) * d i l H   +   1 ) )   /   d H   +   1 ) ; 
                 o u t _ d i m [ 3 ]   =   ( n p y _ i n t p ) ( ( P y A r r a y _ D I M S ( b o t t o m ) [ 3 ]   +   p a d W _ l   +   p a d W _ r   -   ( ( P y A r r a y _ D I M S ( w e i g h t s ) [ w d i m - 1 ] - 1 ) * d i l W   +   1 ) )   /   d W   +   1 ) ; 
                 i f   ( o u t _ d i m [ 0 ]   <   0   | |   o u t _ d i m [ 1 ]   <   0   | |   o u t _ d i m [ 2 ]   < =   0   | |   o u t _ d i m [ 3 ]   < =   0 ) 
                 { 
                         i f   ( u n s h a r e d )   { 
                                 P y E r r _ F o r m a t ( P y E x c _ V a l u e E r r o r , 
                                                           " C o r r M M :   i m p o s s i b l e   o u t p u t   s h a p e \ \ n " 
                                                           "     b o t t o m   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " 
                                                           "     w e i g h t s   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " 
                                                           "     t o p   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 0 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 1 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 2 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 3 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 0 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 1 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 2 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 3 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 4 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 5 ] , 
                                                           ( l o n g   i n t ) o u t _ d i m [ 0 ] ,   ( l o n g   i n t ) o u t _ d i m [ 1 ] ,   ( l o n g   i n t ) o u t _ d i m [ 2 ] , 
                                                           ( l o n g   i n t ) o u t _ d i m [ 3 ] ) ; 
                         } 
                         e l s e   { 
                                 P y E r r _ F o r m a t ( P y E x c _ V a l u e E r r o r , 
                                                           " C o r r M M :   i m p o s s i b l e   o u t p u t   s h a p e \ \ n " 
                                                           "     b o t t o m   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " 
                                                           "     w e i g h t s   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " 
                                                           "     t o p   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 0 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 1 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 2 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 3 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 0 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 1 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 2 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 3 ] , 
                                                           ( l o n g   i n t ) o u t _ d i m [ 0 ] ,   ( l o n g   i n t ) o u t _ d i m [ 1 ] ,   ( l o n g   i n t ) o u t _ d i m [ 2 ] , 
                                                           ( l o n g   i n t ) o u t _ d i m [ 3 ] ) ; 
                         } 
                         % ( f a i l ) s 
                 } 
                 b r e a k ; 
         c a s e   1 :     / /   b a c k p r o p   w r t .   w e i g h t s 
                 / /   o u t p u t   i s   w e i g h t s :   ( n u m _ f i l t e r s ,   n u m _ c h a n n e l s ,   h e i g h t ,   w i d t h ) 
                 / /   h e i g h t   a n d   w i d t h :   w e i g h t s   =   ( b o t t o m   +   p a d _ l   +   p a d _ r   -   ( t o p   -   1 )   *   s a m p l e   -   1 )   /   d i l   +   1 
                 o u t _ d i m [ 0 ]   =   ( n p y _ i n t p ) P y A r r a y _ D I M S ( t o p ) [ 1 ] ; 
                 i f   ( u n s h a r e d ) { 
                         o d i m   =   6 ; 
                         o u t _ d i m [ 1 ]   =   ( n p y _ i n t p ) P y A r r a y _ D I M S ( t o p ) [ 2 ] ; 
                         o u t _ d i m [ 2 ]   =   ( n p y _ i n t p ) P y A r r a y _ D I M S ( t o p ) [ 3 ] ; 
                 } 
                 o u t _ d i m [ w d i m - 3 ]   =   ( n p y _ i n t p ) P y A r r a y _ D I M S ( b o t t o m ) [ 1 ]   /   n u m g r o u p s ; 
                 o u t _ d i m [ w d i m - 2 ]   =   ( n p y _ i n t p ) k H ;     / /   a l r e a d y   i n f e r r e d   f u r t h e r   a b o v e 
                 o u t _ d i m [ w d i m - 1 ]   =   ( n p y _ i n t p ) k W ;     / /   h o w   c o n v e n i e n t 
                 i f   ( u n s h a r e d )   { 
                         i f   ( o u t _ d i m [ 0 ]   <   0   | |   o u t _ d i m [ 1 ]   < =   0   | |   o u t _ d i m [ 2 ]   < =   0   | |   o u t _ d i m [ 3 ]   <   0 
                                         | |   o u t _ d i m [ 4 ]   < =   0   | |   o u t _ d i m [ 5 ]   < =   0 ) { 
                                 P y E r r _ F o r m a t ( P y E x c _ V a l u e E r r o r , 
                                                           " C o r r M M   b a c k p r o p   w r t .   w e i g h t s :   i m p o s s i b l e   o u t p u t   s h a p e \ \ n " 
                                                           "     b o t t o m   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " 
                                                           "     w e i g h t s   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " 
                                                           "     t o p   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 0 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 1 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 2 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 3 ] , 
                                                           ( l o n g   i n t ) o u t _ d i m [ 0 ] ,   ( l o n g   i n t ) o u t _ d i m [ 1 ] ,   ( l o n g   i n t ) o u t _ d i m [ 2 ] , 
                                                           ( l o n g   i n t ) o u t _ d i m [ 3 ] ,   ( l o n g   i n t ) o u t _ d i m [ 4 ] ,   ( l o n g   i n t ) o u t _ d i m [ 5 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 0 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 1 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 2 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 3 ] ) ; 
                                 % ( f a i l ) s 
                         } 
                 } 
                 e l s e   { 
                         i f   ( o u t _ d i m [ 0 ]   <   0   | |   o u t _ d i m [ 1 ]   <   0   | |   o u t _ d i m [ 2 ]   < =   0   | |   o u t _ d i m [ 3 ]   < =   0 ) 
                         { 
                                 P y E r r _ F o r m a t ( P y E x c _ V a l u e E r r o r , 
                                                           " C o r r M M   b a c k p r o p   w r t .   w e i g h t s :   i m p o s s i b l e   o u t p u t   s h a p e \ \ n " 
                                                           "     b o t t o m   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " 
                                                           "     w e i g h t s   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " 
                                                           "     t o p   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 0 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 1 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 2 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( b o t t o m ) [ 3 ] , 
                                                           ( l o n g   i n t ) o u t _ d i m [ 0 ] ,   ( l o n g   i n t ) o u t _ d i m [ 1 ] ,   ( l o n g   i n t ) o u t _ d i m [ 2 ] , 
                                                           ( l o n g   i n t ) o u t _ d i m [ 3 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 0 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 1 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 2 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 3 ] ) ; 
                                 % ( f a i l ) s 
                         } 
                 } 
                 b r e a k ; 
         c a s e   2 :     / /   b a c k p r o p   w r t .   i n p u t s 
                 / /   o u t p u t   i s   b o t t o m :   ( b a t c h s i z e ,   n u m _ c h a n n e l s ,   h e i g h t ,   w i d t h ) 
                 / /   h e i g h t   a n d   w i d t h :   b o t t o m   =   ( t o p   -   1 )   *   s a m p l e   +   ( w e i g h t s - 1 ) * d i l   +   1   -   2 * p a d 
                 o u t _ d i m [ 0 ]   =   ( n p y _ i n t p ) P y A r r a y _ D I M S ( t o p ) [ 0 ] ; 
                 o u t _ d i m [ 1 ]   =   ( n p y _ i n t p ) P y A r r a y _ D I M S ( w e i g h t s ) [ w d i m - 3 ]   *   n u m g r o u p s ; 
                 o u t _ d i m [ 2 ]   =   ( n p y _ i n t p ) ( ( % ( h e i g h t ) s   ! =   - 1 )   ?   % ( h e i g h t ) s   :   ( P y A r r a y _ D I M S ( t o p ) [ 2 ]   -   1 )   *   d H   +   ( P y A r r a y _ D I M S ( w e i g h t s ) [ w d i m - 2 ] - 1 ) * d i l H   +   1   -   p a d H _ l   -   p a d H _ r ) ; 
                 o u t _ d i m [ 3 ]   =   ( n p y _ i n t p ) ( ( % ( w i d t h ) s   ! =   - 1 )   ?   % ( w i d t h ) s   :   ( P y A r r a y _ D I M S ( t o p ) [ 3 ]   -   1 )   *   d W   +   ( P y A r r a y _ D I M S ( w e i g h t s ) [ w d i m - 1 ] - 1 ) * d i l W   +   1   -   p a d W _ l   -   p a d W _ r ) ; 
                 i f   ( u n s h a r e d )   { 
                         i f   ( o u t _ d i m [ 0 ]   <   0   | |   o u t _ d i m [ 1 ]   <   0   | |   o u t _ d i m [ 2 ]   < =   0   | |   o u t _ d i m [ 3 ]   < =   0 ) 
                         { 
                                 P y E r r _ F o r m a t ( P y E x c _ V a l u e E r r o r , 
                                                           " C o r r M M   b a c k p r o p   w r t .   i n p u t s :   i m p o s s i b l e   o u t p u t   s h a p e \ \ n " 
                                                           "     b o t t o m   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " 
                                                           "     w e i g h t s   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " 
                                                           "     t o p   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " , 
                                                           ( l o n g   i n t ) o u t _ d i m [ 0 ] ,   ( l o n g   i n t ) o u t _ d i m [ 1 ] ,   ( l o n g   i n t ) o u t _ d i m [ 2 ] , 
                                                           ( l o n g   i n t ) o u t _ d i m [ 3 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 0 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 1 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 2 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 3 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 4 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 5 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 0 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 1 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 2 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 3 ] ) ; 
                                 % ( f a i l ) s 
                         } 
                 } 
                 e l s e   { 
                         i f   ( o u t _ d i m [ 0 ]   <   0   | |   o u t _ d i m [ 1 ]   <   0   | |   o u t _ d i m [ 2 ]   < =   0   | |   o u t _ d i m [ 3 ]   < =   0 ) 
                         { 
                                 P y E r r _ F o r m a t ( P y E x c _ V a l u e E r r o r , 
                                                           " C o r r M M   b a c k p r o p   w r t .   i n p u t s :   i m p o s s i b l e   o u t p u t   s h a p e \ \ n " 
                                                           "     b o t t o m   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " 
                                                           "     w e i g h t s   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " 
                                                           "     t o p   s h a p e :   % % l d   x   % % l d   x   % % l d   x   % % l d \ \ n " , 
                                                           ( l o n g   i n t ) o u t _ d i m [ 0 ] ,   ( l o n g   i n t ) o u t _ d i m [ 1 ] ,   ( l o n g   i n t ) o u t _ d i m [ 2 ] , 
                                                           ( l o n g   i n t ) o u t _ d i m [ 3 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 0 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 1 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 2 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( w e i g h t s ) [ 3 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 0 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 1 ] , 
                                                           ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 2 ] ,   ( l o n g   i n t ) P y A r r a y _ D I M S ( t o p ) [ 3 ] ) ; 
                                 % ( f a i l ) s 
                         } 
                 } 
                 b r e a k ; 
         d e f a u l t : 
                 P y E r r _ S e t S t r i n g ( P y E x c _ V a l u e E r r o r ,   " B a s e C o r r M M :   d i r e c t i o n   m u s t   b e   0 ,   1 ,   o r   2 \ \ n " ) ; 
                 % ( f a i l ) s 
         } 
 
         / /   P r e p a r e   o u t p u t   a r r a y 
         i n t   t y p e n u m ; 
         i n t   f a i l u r e ; 
         f a i l u r e   =   ! ( * o u t 
                       & &   P y A r r a y _ N D I M ( * o u t ) = = o d i m 
                       & &   P y A r r a y _ I S _ C _ C O N T I G U O U S ( * o u t ) 
                       & &   P y A r r a y _ D I M S ( * o u t ) [ 0 ] = = o u t _ d i m [ 0 ] 
                       & &   P y A r r a y _ D I M S ( * o u t ) [ 1 ] = = o u t _ d i m [ 1 ] 
                       & &   P y A r r a y _ D I M S ( * o u t ) [ 2 ] = = o u t _ d i m [ 2 ] 
                       & &   P y A r r a y _ D I M S ( * o u t ) [ 3 ] = = o u t _ d i m [ 3 ] ) ; 
         i f   ( o d i m   = =   6 ) { 
                 f a i l u r e   =   f a i l u r e   | |   ! ( P y A r r a y _ D I M S ( * o u t ) [ 4 ] = = o u t _ d i m [ 4 ] 
                                 & &   P y A r r a y _ D I M S ( * o u t ) [ 5 ] = = o u t _ d i m [ 5 ] ) ; 
         } 
         i f   (   f a i l u r e   ) 
         { 
                 P y _ X D E C R E F ( * o u t ) ; 
                 i f   ( d i r e c t i o n   ! =   1 )   { 
                     t y p e n u m   =   P y A r r a y _ T Y P E ( w e i g h t s ) ; 
                 } 
                 e l s e   { 
                     t y p e n u m   =   P y A r r a y _ T Y P E ( b o t t o m ) ; 
                 } 
                 / / C h a n g e   t o   P y A r r a y _ Z E R O S   w h i c h   i s   f a s t e r   t h a n   P y A r r a y _ E M P T Y . 
                 * o u t   =   ( P y A r r a y O b j e c t * ) P y A r r a y _ Z E R O S ( o d i m , 
                                                                                     o u t _ d i m , 
                                                                                     t y p e n u m , 
                                                                                     0 ) ; 
                 i f   ( N U L L   = =   * o u t ) 
                 { 
                         i f   ( o d i m   = =   4 )   { 
                                 P y E r r _ F o r m a t ( P y E x c _ R u n t i m e E r r o r , 
                                                 " B a s e C o r r M M :   F a i l e d   t o   a l l o c a t e   o u t p u t   o f   % % l l d   x   % % l l d   x   % % l l d   x   % % l l d " , 
                                                 ( l o n g   l o n g ) o u t _ d i m [ 0 ] ,   ( l o n g   l o n g ) o u t _ d i m [ 1 ] ,   ( l o n g   l o n g ) o u t _ d i m [ 2 ] ,   ( l o n g   l o n g ) o u t _ d i m [ 3 ] ) ; 
                         } 
                         i f   ( o d i m   = =   6 )   { 
                                 P y E r r _ F o r m a t ( P y E x c _ R u n t i m e E r r o r , 
                                                 " B a s e C o r r M M :   F a i l e d   t o   a l l o c a t e   o u t p u t   o f   % % l l d   x   % % l l d   x   % % l l d   x   % % l l d   % % l l d   % % l l d " , 
                                                 ( l o n g   l o n g ) o u t _ d i m [ 0 ] ,   ( l o n g   l o n g ) o u t _ d i m [ 1 ] ,   ( l o n g   l o n g ) o u t _ d i m [ 2 ] ,   ( l o n g   l o n g ) o u t _ d i m [ 3 ] , 
                                                 ( l o n g   l o n g ) o u t _ d i m [ 4 ] ,   ( l o n g   l o n g ) o u t _ d i m [ 5 ] ) ; 
                         } 
                         % ( f a i l ) s 
                 } 
         } 
 
         / /   C a l l   c o r r M M   c o d e 
         o u t 2   =   c o r r M M ( % ( b o t t o m ) s ,   % ( w e i g h t s ) s ,   % ( t o p ) s ,   d i r e c t i o n ,   d H ,   d W ,   d i l H ,   d i l W , 
                                 p a d H _ l ,   p a d H _ r ,   p a d W _ l ,   p a d W _ r ,   n u m g r o u p s ,   u n s h a r e d ) ; 
         i f   ( o u t 2 = = N U L L ) { 
               % ( f a i l ) s 
         } 
         a s s e r t   ( o u t 2   = =   * o u t ) ; 
 
 " " " % dict ( bottom = bottom , weights = weights , top = top , height = height , width = width , <NEWLINE> fail = sub [ <STRING> ] , params = sub [ <STRING> ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def report ( values , observer = None ) : <NEWLINE> <TAB> <NEWLINE> if _reporters : <NEWLINE> <TAB> current = _reporters [ - <NUMBER> ] <NEWLINE> current . report ( values , observer ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __init__ ( self , tpu_cluster_resolver , steps_per_run , num_cores = None ) : <NEWLINE> <TAB> <NEWLINE> super ( TPUStrategy , self ) . __init__ ( ) <NEWLINE> <NEWLINE> self . _tpu_cluster_resolver = tpu_cluster_resolver <NEWLINE> self . _tpu_metadata = get_tpu_system_metadata ( self . _tpu_cluster_resolver ) <NEWLINE> <NEWLINE> self . _num_cores_override = num_cores <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> device_map = { d . name : i for i , d in enumerate ( self . _tpu_metadata . devices ) <NEWLINE> if <STRING> in d . name } <NEWLINE> self . _device_index = values . PerDevice ( device_map ) <NEWLINE> self . _host_device = self . get_host_cpu_device ( <NUMBER> ) <NEWLINE> self . _tpu_devices = sorted ( device_map . keys ( ) ) <NEWLINE> <NEWLINE> self . _tpu_devices = self . _tpu_devices [ : self . num_replicas ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> self . steps_per_run = steps_per_run <NEWLINE> <NEWLINE> self . _require_static_shapes = True <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def winfo_screen ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . tk . call ( <STRING> , <STRING> , self . _w ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def load_checkpoint ( filepattern ) : <NEWLINE> <TAB> <NEWLINE> filename = _get_checkpoint_filename ( filepattern ) <NEWLINE> if filename is None : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % filepattern ) <NEWLINE> <UNTAB> return train . NewCheckpointReader ( filename ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_foreground ( self , fg , isRGBA = False ) : <NEWLINE> <TAB> <NEWLINE> if self . _forced_alpha and isRGBA : <NEWLINE> <TAB> self . _rgb = fg [ : <NUMBER> ] + ( self . _alpha , ) <NEWLINE> <UNTAB> elif self . _forced_alpha : <NEWLINE> <TAB> self . _rgb = colors . to_rgba ( fg , self . _alpha ) <NEWLINE> <UNTAB> elif isRGBA : <NEWLINE> <TAB> self . _rgb = fg <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> self . _rgb = colors . to_rgba ( fg ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def sparse_segment_mean_eager_fallback ( data , indices , segment_ids , name = None , ctx = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = ctx if ctx else _context . context ( ) <NEWLINE> _attr_T , ( data , ) = _execute . args_to_matching_eager ( [ data ] , _ctx ) <NEWLINE> _attr_Tidx , ( indices , ) = _execute . args_to_matching_eager ( [ indices ] , _ctx , _dtypes . int32 ) <NEWLINE> segment_ids = _ops . convert_to_tensor ( segment_ids , _dtypes . int32 ) <NEWLINE> _inputs_flat = [ data , indices , segment_ids ] <NEWLINE> _attrs = ( <STRING> , _attr_T , <STRING> , _attr_Tidx ) <NEWLINE> _result = _execute . execute ( <STRING> , <NUMBER> , inputs = _inputs_flat , <NEWLINE> attrs = _attrs , ctx = _ctx , name = name ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def onenorm ( self ) : <NEWLINE> <TAB> <NEWLINE> if self . _A_1_norm is None : <NEWLINE> <TAB> self . _A_1_norm = _exact_1_norm ( self . _A ) <NEWLINE> <UNTAB> return self . _scale * self . _A_1_norm <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _parse_args ( self , args , known_only ) : <NEWLINE> <TAB> <NEWLINE> unparsed_names_and_args = [ ] <NEWLINE> undefok = set ( ) <NEWLINE> retired_flag_func = self . __dict__ [ <STRING> ] <NEWLINE> <NEWLINE> flag_dict = self . _flags ( ) <NEWLINE> args = iter ( args ) <NEWLINE> for arg in args : <NEWLINE> <TAB> value = None <NEWLINE> <NEWLINE> def get_value ( ) : <NEWLINE> <NEWLINE> <TAB> try : <NEWLINE> <TAB> return next ( args ) if value is None else value <NEWLINE> <UNTAB> except StopIteration : <NEWLINE> <TAB> raise _exceptions . Error ( <STRING> + arg ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if not arg . startswith ( <STRING> ) : <NEWLINE> <NEWLINE> <TAB> unparsed_names_and_args . append ( ( None , arg ) ) <NEWLINE> if self . is_gnu_getopt ( ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if arg == <STRING> : <NEWLINE> <TAB> if known_only : <NEWLINE> <TAB> unparsed_names_and_args . append ( ( None , arg ) ) <NEWLINE> <UNTAB> break <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if arg . startswith ( <STRING> ) : <NEWLINE> <TAB> arg_without_dashes = arg [ <NUMBER> : ] <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> arg_without_dashes = arg [ <NUMBER> : ] <NEWLINE> <NEWLINE> <UNTAB> if <STRING> in arg_without_dashes : <NEWLINE> <TAB> name , value = arg_without_dashes . split ( <STRING> , <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> name , value = arg_without_dashes , None <NEWLINE> <NEWLINE> <UNTAB> if not name : <NEWLINE> <NEWLINE> <TAB> unparsed_names_and_args . append ( ( None , arg ) ) <NEWLINE> if self . is_gnu_getopt ( ) : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> break <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if name == <STRING> : <NEWLINE> <TAB> value = get_value ( ) <NEWLINE> undefok . update ( v . strip ( ) for v in value . split ( <STRING> ) ) <NEWLINE> undefok . update ( <STRING> + v . strip ( ) for v in value . split ( <STRING> ) ) <NEWLINE> continue <NEWLINE> <NEWLINE> <UNTAB> flag = flag_dict . get ( name ) <NEWLINE> if flag : <NEWLINE> <TAB> if flag . boolean and value is None : <NEWLINE> <TAB> value = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> value = get_value ( ) <NEWLINE> <UNTAB> <UNTAB> elif name . startswith ( <STRING> ) and len ( name ) > <NUMBER> : <NEWLINE> <NEWLINE> <TAB> noflag = flag_dict . get ( name [ <NUMBER> : ] ) <NEWLINE> if noflag and noflag . boolean : <NEWLINE> <TAB> if value is not None : <NEWLINE> <TAB> raise ValueError ( arg + <STRING> ) <NEWLINE> <UNTAB> flag = noflag <NEWLINE> value = <STRING> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if retired_flag_func and not flag : <NEWLINE> <TAB> is_retired , is_bool = retired_flag_func ( name ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if not is_retired and name . startswith ( <STRING> ) : <NEWLINE> <TAB> is_retired , is_bool = retired_flag_func ( name [ <NUMBER> : ] ) <NEWLINE> is_retired = is_retired and is_bool <NEWLINE> <NEWLINE> <UNTAB> if is_retired : <NEWLINE> <TAB> if not is_bool and value is None : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> get_value ( ) <NEWLINE> <UNTAB> logging . error ( <STRING> <NEWLINE> <STRING> , name ) <NEWLINE> continue <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if flag : <NEWLINE> <TAB> flag . parse ( value ) <NEWLINE> flag . using_default_value = False <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> unparsed_names_and_args . append ( ( name , arg ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> unknown_flags = [ ] <NEWLINE> unparsed_args = [ ] <NEWLINE> for name , arg in unparsed_names_and_args : <NEWLINE> <TAB> if name is None : <NEWLINE> <NEWLINE> <TAB> unparsed_args . append ( arg ) <NEWLINE> <UNTAB> elif name in undefok : <NEWLINE> <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> else : <NEWLINE> <NEWLINE> <TAB> if known_only : <NEWLINE> <TAB> unparsed_args . append ( arg ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> unknown_flags . append ( ( name , arg ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> unparsed_args . extend ( list ( args ) ) <NEWLINE> return unknown_flags , unparsed_args <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _remove_redundancy_dense ( A , rhs ) : <NEWLINE> <TAB> <NEWLINE> tolapiv = <NUMBER> <NEWLINE> tolprimal = <NUMBER> <NEWLINE> status = <NUMBER> <NEWLINE> message = <STRING> <NEWLINE> inconsistent = ( <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> A , rhs , status , message = _remove_zero_rows ( A , rhs ) <NEWLINE> <NEWLINE> if status != <NUMBER> : <NEWLINE> <TAB> return A , rhs , status , message <NEWLINE> <NEWLINE> <UNTAB> m , n = A . shape <NEWLINE> <NEWLINE> v = list ( range ( m ) ) <NEWLINE> b = list ( v ) <NEWLINE> <NEWLINE> <NEWLINE> k = set ( range ( m , m + n ) ) <NEWLINE> d = [ ] <NEWLINE> lu = None <NEWLINE> perm_r = None <NEWLINE> <NEWLINE> A_orig = A <NEWLINE> A = np . hstack ( ( np . eye ( m ) , A ) ) <NEWLINE> e = np . zeros ( m ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> B = A [ : , b ] <NEWLINE> for i in v : <NEWLINE> <NEWLINE> <TAB> e [ i ] = <NUMBER> <NEWLINE> if i > <NUMBER> : <NEWLINE> <TAB> e [ i - <NUMBER> ] = <NUMBER> <NEWLINE> <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> j = b [ i - <NUMBER> ] <NEWLINE> lu = bg_update_dense ( lu , perm_r , A [ : , j ] , i - <NUMBER> ) <NEWLINE> <UNTAB> except : <NEWLINE> <TAB> lu = scipy . linalg . lu_factor ( B ) <NEWLINE> LU , p = lu <NEWLINE> perm_r = list ( range ( m ) ) <NEWLINE> for i1 , i2 in enumerate ( p ) : <NEWLINE> <TAB> perm_r [ i1 ] , perm_r [ i2 ] = perm_r [ i2 ] , perm_r [ i1 ] <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> pi = scipy . linalg . lu_solve ( lu , e , trans = <NUMBER> ) <NEWLINE> <NEWLINE> <NEWLINE> js = np . array ( list ( k - set ( b ) ) ) <NEWLINE> batch = <NUMBER> <NEWLINE> dependent = True <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> for j_index in range ( <NUMBER> , len ( js ) , batch ) : <NEWLINE> <TAB> j_indices = js [ np . arange ( j_index , min ( j_index + batch , len ( js ) ) ) ] <NEWLINE> <NEWLINE> c = abs ( A [ : , j_indices ] . transpose ( ) . dot ( pi ) ) <NEWLINE> if ( c > tolapiv ) . any ( ) : <NEWLINE> <TAB> j = js [ j_index + np . argmax ( c ) ] <NEWLINE> B [ : , i ] = A [ : , j ] <NEWLINE> b [ i ] = j <NEWLINE> dependent = False <NEWLINE> break <NEWLINE> <UNTAB> <UNTAB> if dependent : <NEWLINE> <TAB> bibar = pi . T . dot ( rhs . reshape ( - <NUMBER> , <NUMBER> ) ) <NEWLINE> bnorm = np . linalg . norm ( rhs ) <NEWLINE> if abs ( bibar ) / ( <NUMBER> + bnorm ) > tolprimal : <NEWLINE> <TAB> status = <NUMBER> <NEWLINE> message = inconsistent <NEWLINE> return A_orig , rhs , status , message <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> d . append ( i ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> <UNTAB> keep = set ( range ( m ) ) <NEWLINE> keep = list ( keep - set ( d ) ) <NEWLINE> return A_orig [ keep , : ] , rhs [ keep ] , status , message <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def copy ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> return self <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def udivisor_count ( n ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if n == <NUMBER> : <NEWLINE> <TAB> return <NUMBER> <NEWLINE> <UNTAB> return <NUMBER> ** len ( [ p for p in factorint ( n ) if p > <NUMBER> ] ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def grad_dot ( dy , x1 , x2 ) : <NEWLINE> <TAB> <NEWLINE> if len ( numpy . shape ( x1 ) ) == <NUMBER> : <NEWLINE> <TAB> dy = numpy . atleast_2d ( dy ) <NEWLINE> <UNTAB> elif len ( numpy . shape ( x2 ) ) == <NUMBER> : <NEWLINE> <TAB> dy = numpy . transpose ( numpy . atleast_2d ( dy ) ) <NEWLINE> x2 = numpy . transpose ( numpy . atleast_2d ( x2 ) ) <NEWLINE> <UNTAB> x2_t = numpy . transpose ( numpy . atleast_2d ( <NEWLINE> numpy . sum ( x2 , axis = tuple ( numpy . arange ( numpy . ndim ( x2 ) - <NUMBER> ) ) ) ) ) <NEWLINE> dy_x2 = numpy . sum ( dy , axis = tuple ( - numpy . arange ( numpy . ndim ( x2 ) - <NUMBER> ) - <NUMBER> ) ) <NEWLINE> return numpy . reshape ( numpy . dot ( dy_x2 , x2_t ) , numpy . shape ( x1 ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _height_depth_of ( self , char ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> result = [ ] <NEWLINE> for metric , name in ( ( self . _tfm . height , <STRING> ) , <NEWLINE> ( self . _tfm . depth , <STRING> ) ) : <NEWLINE> <TAB> value = metric . get ( char , None ) <NEWLINE> if value is None : <NEWLINE> <TAB> _log . debug ( <STRING> , <NEWLINE> name , char , self . texname ) <NEWLINE> result . append ( <NUMBER> ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> result . append ( _mul2012 ( value , self . _scale ) ) <NEWLINE> <UNTAB> <UNTAB> return result <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _check_matrix ( self , matrix ) : <NEWLINE> <TAB> <NEWLINE> allowed_dtypes = [ <NEWLINE> dtypes . float16 , <NEWLINE> dtypes . float32 , <NEWLINE> dtypes . float64 , <NEWLINE> dtypes . complex64 , <NEWLINE> dtypes . complex128 , <NEWLINE> ] <NEWLINE> <NEWLINE> matrix = ops . convert_to_tensor ( matrix , name = <STRING> ) <NEWLINE> <NEWLINE> dtype = matrix . dtype <NEWLINE> if dtype not in allowed_dtypes : <NEWLINE> <TAB> raise TypeError ( <NEWLINE> <STRING> <NEWLINE> % ( allowed_dtypes , dtype ) ) <NEWLINE> <NEWLINE> <UNTAB> if matrix . get_shape ( ) . ndims is not None and matrix . get_shape ( ) . ndims < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <NEWLINE> <STRING> <NEWLINE> % matrix ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def sample ( self , sample_shape = ( ) ) : <NEWLINE> <TAB> <NEWLINE> final_shape = self . batch_shape + self . event_shape <NEWLINE> if sample_shape == ( ) : <NEWLINE> <TAB> n = <NUMBER> <NEWLINE> <UNTAB> elif isinstance ( sample_shape , int ) : <NEWLINE> <TAB> n = sample_shape <NEWLINE> final_shape = ( n , ) + final_shape <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> n = <NUMBER> <NEWLINE> for shape_ in sample_shape : <NEWLINE> <TAB> n *= shape_ <NEWLINE> <UNTAB> final_shape = sample_shape + final_shape <NEWLINE> <UNTAB> samples = self . sample_n ( n ) <NEWLINE> return samples . reshape ( final_shape ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def _finger ( eq ) : <NEWLINE> <TAB> <NEWLINE> f = eq . free_symbols <NEWLINE> d = dict ( list ( zip ( f , [ [ <NUMBER> ] * <NUMBER> for fi in f ] ) ) ) <NEWLINE> for a in eq . args : <NEWLINE> <TAB> if a . is_Symbol : <NEWLINE> <TAB> d [ a ] [ <NUMBER> ] += <NUMBER> <NEWLINE> <UNTAB> elif a . is_Not : <NEWLINE> <TAB> d [ a . args [ <NUMBER> ] ] [ <NUMBER> ] += <NUMBER> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> o = len ( a . args ) + sum ( isinstance ( ai , Not ) for ai in a . args ) <NEWLINE> for ai in a . args : <NEWLINE> <TAB> if ai . is_Symbol : <NEWLINE> <TAB> d [ ai ] [ <NUMBER> ] += <NUMBER> <NEWLINE> d [ ai ] [ - <NUMBER> ] += o <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> d [ ai . args [ <NUMBER> ] ] [ <NUMBER> ] += <NUMBER> <NEWLINE> d [ ai . args [ <NUMBER> ] ] [ - <NUMBER> ] += o <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> inv = defaultdict ( list ) <NEWLINE> for k , v in ordered ( iter ( d . items ( ) ) ) : <NEWLINE> <TAB> inv [ tuple ( v ) ] . append ( k ) <NEWLINE> <UNTAB> return inv <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def array_equiv ( a1 , a2 ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> a1 , a2 = asarray ( a1 ) , asarray ( a2 ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> return False <NEWLINE> <UNTAB> try : <NEWLINE> <TAB> multiarray . broadcast ( a1 , a2 ) <NEWLINE> <UNTAB> except Exception : <NEWLINE> <TAB> return False <NEWLINE> <NEWLINE> <UNTAB> return bool ( asarray ( a1 == a2 ) . all ( ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def get_rasterization_zorder ( self ) : <NEWLINE> <TAB> <NEWLINE> return self . _rasterization_zorder <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def read_bytes ( fh , byteorder , dtype , count ) : <NEWLINE> <TAB> <NEWLINE> dtype = <STRING> if dtype [ - <NUMBER> ] == <STRING> else byteorder + dtype [ - <NUMBER> ] <NEWLINE> return fh . read_array ( dtype , count ) . tostring ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def disconnect_events ( self ) : <NEWLINE> <TAB> <NEWLINE> for c in self . cids : <NEWLINE> <TAB> self . canvas . mpl_disconnect ( c ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_reindexer ( self , target ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> <NEWLINE> lindexer = self . _engine . get_indexer ( target . left . values ) <NEWLINE> rindexer = self . _engine . get_indexer ( target . right . values ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> indexer = [ ] <NEWLINE> n = len ( self ) <NEWLINE> <NEWLINE> for i , ( lhs , rhs ) in enumerate ( zip ( lindexer , rindexer ) ) : <NEWLINE> <NEWLINE> <TAB> target_value = target [ i ] <NEWLINE> <NEWLINE> <NEWLINE> if ( lhs != - <NUMBER> and <NEWLINE> self . closed == <STRING> and <NEWLINE> target_value . left == self [ lhs ] . right ) : <NEWLINE> <TAB> lhs += <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if ( rhs != - <NUMBER> and <NEWLINE> self . closed == <STRING> and <NEWLINE> target_value . right == self [ rhs ] . left ) : <NEWLINE> <TAB> rhs -= <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if lhs == - <NUMBER> and rhs == - <NUMBER> : <NEWLINE> <TAB> indexer . append ( np . array ( [ - <NUMBER> ] ) ) <NEWLINE> <NEWLINE> <UNTAB> elif rhs == - <NUMBER> : <NEWLINE> <NEWLINE> <TAB> indexer . append ( np . arange ( lhs , n ) ) <NEWLINE> <NEWLINE> <UNTAB> elif lhs == - <NUMBER> : <NEWLINE> <NEWLINE> <NEWLINE> <TAB> value = self [ i ] <NEWLINE> <NEWLINE> <NEWLINE> if self . closed == target . closed : <NEWLINE> <TAB> if target_value . left < value . left : <NEWLINE> <TAB> indexer . append ( np . array ( [ - <NUMBER> ] ) ) <NEWLINE> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif self . closed == <STRING> : <NEWLINE> <TAB> if target_value . left <= value . left : <NEWLINE> <TAB> indexer . append ( np . array ( [ - <NUMBER> ] ) ) <NEWLINE> continue <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> elif self . closed == <STRING> : <NEWLINE> <TAB> if target_value . left <= value . left : <NEWLINE> <TAB> indexer . append ( np . array ( [ - <NUMBER> ] ) ) <NEWLINE> continue <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> indexer . append ( np . arange ( <NUMBER> , rhs + <NUMBER> ) ) <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> indexer . append ( np . arange ( lhs , rhs + <NUMBER> ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return np . concatenate ( indexer ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def choose_diverging_palette ( as_cmap = False ) : <NEWLINE> <TAB> <NEWLINE> pal = [ ] <NEWLINE> if as_cmap : <NEWLINE> <TAB> cmap = _init_mutable_colormap ( ) <NEWLINE> <NEWLINE> <UNTAB> @ interact <NEWLINE> def choose_diverging_palette ( h_neg = IntSlider ( min = <NUMBER> , <NEWLINE> max = <NUMBER> , <NEWLINE> value = <NUMBER> ) , <NEWLINE> h_pos = IntSlider ( min = <NUMBER> , <NEWLINE> max = <NUMBER> , <NEWLINE> value = <NUMBER> ) , <NEWLINE> s = IntSlider ( min = <NUMBER> , max = <NUMBER> , value = <NUMBER> ) , <NEWLINE> l = IntSlider ( min = <NUMBER> , max = <NUMBER> , value = <NUMBER> ) , <NEWLINE> sep = IntSlider ( min = <NUMBER> , max = <NUMBER> , value = <NUMBER> ) , <NEWLINE> n = ( <NUMBER> , <NUMBER> ) , <NEWLINE> center = [ <STRING> , <STRING> ] ) : <NEWLINE> <TAB> if as_cmap : <NEWLINE> <TAB> colors = diverging_palette ( h_neg , h_pos , s , l , sep , <NUMBER> , center ) <NEWLINE> _update_lut ( cmap , colors ) <NEWLINE> _show_cmap ( cmap ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> pal [ : ] = diverging_palette ( h_neg , h_pos , s , l , sep , n , center ) <NEWLINE> palplot ( pal ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> if as_cmap : <NEWLINE> <TAB> return cmap <NEWLINE> <UNTAB> return pal <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def cofactor ( self , i , j , method = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if self . rows != self . cols or self . rows < <NUMBER> : <NEWLINE> <TAB> raise NonSquareMatrixError ( ) <NEWLINE> <NEWLINE> <UNTAB> return ( - <NUMBER> ) ** ( ( i + j ) % <NUMBER> ) * self . minor ( i , j , method ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _requires_quotes ( self , value ) : <NEWLINE> <TAB> <NEWLINE> lc_value = value . lower ( ) <NEWLINE> return ( lc_value in self . reserved_words <NEWLINE> or value [ <NUMBER> ] in self . illegal_initial_characters <NEWLINE> or not self . legal_characters . match ( util . text_type ( value ) ) <NEWLINE> or ( lc_value != value ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _get_tick_bboxes ( self , ticks , renderer ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> ticklabelBoxes = [ ] <NEWLINE> ticklabelBoxes2 = [ ] <NEWLINE> <NEWLINE> for tick in ticks : <NEWLINE> <TAB> if tick . label1On and tick . label1 . get_visible ( ) : <NEWLINE> <TAB> extent = tick . label1 . get_window_extent ( renderer ) <NEWLINE> ticklabelBoxes . append ( extent ) <NEWLINE> <UNTAB> if tick . label2On and tick . label2 . get_visible ( ) : <NEWLINE> <TAB> extent = tick . label2 . get_window_extent ( renderer ) <NEWLINE> ticklabelBoxes2 . append ( extent ) <NEWLINE> <UNTAB> <UNTAB> return ticklabelBoxes , ticklabelBoxes2 <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def truncate ( self , n = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> if n is None : <NEWLINE> <TAB> return iter ( self ) <NEWLINE> <NEWLINE> <UNTAB> x , x0 = self . x , self . x0 <NEWLINE> pt_xk = self . xk . coeff ( n ) <NEWLINE> if x0 is S . NegativeInfinity : <NEWLINE> <TAB> x0 = S . Infinity <NEWLINE> <NEWLINE> <UNTAB> return self . polynomial ( n ) + Order ( pt_xk , ( x , x0 ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def set_lop_overrides ( self , lop_overrides ) : <NEWLINE> <TAB> <NEWLINE> self . _lop_op = lop_overrides <NEWLINE> self . _lop_op_is_cached = False <NEWLINE> self . _lop_type = <STRING> <NEWLINE> self . _lop_is_default = ( lop_overrides == <STRING> ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def nonzero ( self ) : <NEWLINE> <TAB> <NEWLINE> return narray ( self . filled ( <NUMBER> ) , copy = False ) . nonzero ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def _handle_usecols ( self , columns , usecols_key ) : <NEWLINE> <TAB> <NEWLINE> if self . usecols is not None : <NEWLINE> <TAB> if callable ( self . usecols ) : <NEWLINE> <TAB> col_indices = _evaluate_usecols ( self . usecols , usecols_key ) <NEWLINE> <UNTAB> elif any ( isinstance ( u , string_types ) for u in self . usecols ) : <NEWLINE> <TAB> if len ( columns ) > <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> col_indices = [ ] <NEWLINE> <NEWLINE> for col in self . usecols : <NEWLINE> <TAB> if isinstance ( col , string_types ) : <NEWLINE> <TAB> try : <NEWLINE> <TAB> col_indices . append ( usecols_key . index ( col ) ) <NEWLINE> <UNTAB> except ValueError : <NEWLINE> <TAB> _validate_usecols_names ( self . usecols , usecols_key ) <NEWLINE> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> col_indices . append ( col ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> else : <NEWLINE> <TAB> col_indices = self . usecols <NEWLINE> <NEWLINE> <UNTAB> columns = [ [ n for i , n in enumerate ( column ) if i in col_indices ] <NEWLINE> for column in columns ] <NEWLINE> self . _col_indices = col_indices <NEWLINE> <UNTAB> return columns <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def mean ( self , df , scale ) : <NEWLINE> <TAB> <NEWLINE> dim , df , scale = self . _process_parameters ( df , scale ) <NEWLINE> out = self . _mean ( dim , df , scale ) <NEWLINE> return _squeeze_output ( out ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def lookup_columns ( self , * args , ** kwargs ) : <NEWLINE> <TAB> <NEWLINE> table = self <NEWLINE> normalized = args <NEWLINE> if normalized is None : <NEWLINE> <TAB> normalized = [ ] <NEWLINE> <UNTAB> if isinstance ( normalized , tuple ) : <NEWLINE> <TAB> normalized = list ( normalized ) <NEWLINE> <UNTAB> for key , value in iteritems ( kwargs ) : <NEWLINE> <TAB> if key == <STRING> : <NEWLINE> <TAB> continue <NEWLINE> <UNTAB> if isinstance ( value , str ) : <NEWLINE> <TAB> normalized . append ( ( key , value ) ) <NEWLINE> continue <NEWLINE> <UNTAB> for col in value : <NEWLINE> <TAB> normalized . append ( ( key , col ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def _apply_fn ( dataset ) : <NEWLINE> <NEWLINE> <TAB> return _BigtableLookupDataset ( dataset , table , normalized ) <NEWLINE> <NEWLINE> <UNTAB> return _apply_fn <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def clear_execution_callbacks ( ) : <NEWLINE> <TAB> <NEWLINE> context . context ( ) . clear_post_execution_callbacks ( ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def release_zoom ( self , event ) : <NEWLINE> <TAB> <NEWLINE> for zoom_id in self . _ids_zoom : <NEWLINE> <TAB> self . canvas . mpl_disconnect ( zoom_id ) <NEWLINE> <UNTAB> self . _ids_zoom = [ ] <NEWLINE> <NEWLINE> self . remove_rubberband ( ) <NEWLINE> <NEWLINE> if not self . _xypress : <NEWLINE> <TAB> return <NEWLINE> <NEWLINE> <UNTAB> last_a = [ ] <NEWLINE> <NEWLINE> for cur_xypress in self . _xypress : <NEWLINE> <TAB> x , y = event . x , event . y <NEWLINE> lastx , lasty , a , ind , view = cur_xypress <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> if ( ( abs ( x - lastx ) < <NUMBER> and self . _zoom_mode != <STRING> ) or <NEWLINE> ( abs ( y - lasty ) < <NUMBER> and self . _zoom_mode != <STRING> ) ) : <NEWLINE> <TAB> self . _xypress = None <NEWLINE> self . release ( event ) <NEWLINE> self . draw ( ) <NEWLINE> return <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> twinx , twiny = False , False <NEWLINE> if last_a : <NEWLINE> <TAB> for la in last_a : <NEWLINE> <TAB> if a . get_shared_x_axes ( ) . joined ( a , la ) : <NEWLINE> <TAB> twinx = True <NEWLINE> <UNTAB> if a . get_shared_y_axes ( ) . joined ( a , la ) : <NEWLINE> <TAB> twiny = True <NEWLINE> <UNTAB> <UNTAB> <UNTAB> last_a . append ( a ) <NEWLINE> <NEWLINE> if self . _button_pressed == <NUMBER> : <NEWLINE> <TAB> direction = <STRING> <NEWLINE> <UNTAB> elif self . _button_pressed == <NUMBER> : <NEWLINE> <TAB> direction = <STRING> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> continue <NEWLINE> <NEWLINE> <UNTAB> a . _set_view_from_bbox ( ( lastx , lasty , x , y ) , direction , <NEWLINE> self . _zoom_mode , twinx , twiny ) <NEWLINE> <NEWLINE> <UNTAB> self . draw ( ) <NEWLINE> self . _xypress = None <NEWLINE> self . _button_pressed = None <NEWLINE> <NEWLINE> self . _zoom_mode = None <NEWLINE> <NEWLINE> self . push_current ( ) <NEWLINE> self . release ( event ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def char ( self ) : <NEWLINE> <TAB> <NEWLINE> return type ( self ) ( self . data . char ( ) , self . batch_sizes ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def flip ( x , axis ) : <NEWLINE> <TAB> <NEWLINE> return Flip ( axis ) . apply ( ( x , ) ) [ <NUMBER> ] <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> @ staticmethod <NEWLINE> def affine_rank ( * args ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> if len ( args ) == <NUMBER> : <NEWLINE> <TAB> return - <NUMBER> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> points = Point . _normalize_dimension ( * [ Point ( i ) for i in args ] ) <NEWLINE> origin = points [ <NUMBER> ] <NEWLINE> points = [ i - origin for i in points [ <NUMBER> : ] ] <NEWLINE> <NEWLINE> m = Matrix ( [ i . args for i in points ] ) <NEWLINE> return m . rank ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def rfftfreq ( n , d = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> n = operator . index ( n ) <NEWLINE> if n < <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % n ) <NEWLINE> <NEWLINE> <UNTAB> return ( arange ( <NUMBER> , n + <NUMBER> , dtype = int ) // <NUMBER> ) / float ( n * d ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ deprecated ( None , <STRING> ) <NEWLINE> def multi_head ( heads , loss_weights = None ) : <NEWLINE> <TAB> <NEWLINE> if loss_weights : <NEWLINE> <TAB> if len ( loss_weights ) != len ( heads ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def _weighted_loss_merger ( losses ) : <NEWLINE> <TAB> if loss_weights : <NEWLINE> <TAB> if len ( losses ) != len ( loss_weights ) : <NEWLINE> <TAB> raise ValueError ( <STRING> ) <NEWLINE> <UNTAB> weighted_losses = [ ] <NEWLINE> for loss , weight in zip ( losses , loss_weights ) : <NEWLINE> <TAB> weighted_losses . append ( math_ops . multiply ( loss , weight ) ) <NEWLINE> <UNTAB> return math_ops . add_n ( weighted_losses ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return math_ops . add_n ( losses ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> return _MultiHead ( heads , loss_merger = _weighted_loss_merger ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def remove_edges_from ( self , ebunch ) : <NEWLINE> <TAB> <NEWLINE> adj = self . _adj <NEWLINE> for e in ebunch : <NEWLINE> <TAB> u , v = e [ : <NUMBER> ] <NEWLINE> if u in adj and v in adj [ u ] : <NEWLINE> <TAB> del adj [ u ] [ v ] <NEWLINE> if u != v : <NEWLINE> <TAB> del adj [ v ] [ u ] <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def isfinite ( tensor ) : <NEWLINE> <TAB> <NEWLINE> if not isinstance ( tensor , torch . Tensor ) : <NEWLINE> <TAB> raise ValueError ( <STRING> , str ( tensor ) ) <NEWLINE> <UNTAB> return ( tensor == tensor ) & ( tensor . abs ( ) != inf ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _labeling_complete ( labeling , G ) : <NEWLINE> <TAB> <NEWLINE> return all ( labeling [ v ] in _most_frequent_labels ( v , labeling , G ) <NEWLINE> for v in G if len ( G [ v ] ) > <NUMBER> ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def reset_isolation_level ( self , dbapi_conn ) : <NEWLINE> <TAB> <NEWLINE> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def __eq__ ( self , other ) : <NEWLINE> <TAB> <NEWLINE> return isinstance ( other , Domain ) and self . dtype == other . dtype <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def unique_rows ( ar ) : <NEWLINE> <TAB> <NEWLINE> if ar . ndim != <NUMBER> : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> % ar . ndim ) <NEWLINE> <NEWLINE> <UNTAB> ar = np . ascontiguousarray ( ar ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> ar_row_view = ar . view ( <STRING> % ( ar . itemsize * ar . shape [ <NUMBER> ] ) ) <NEWLINE> _ , unique_row_indices = np . unique ( ar_row_view , return_index = True ) <NEWLINE> ar_out = ar [ unique_row_indices ] <NEWLINE> return ar_out <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def getargspec ( func ) : <NEWLINE> <TAB> <NEWLINE> warnings . warn ( <STRING> <NEWLINE> <STRING> , <NEWLINE> DeprecationWarning , stacklevel = <NUMBER> ) <NEWLINE> args , varargs , varkw , defaults , kwonlyargs , kwonlydefaults , ann = getfullargspec ( func ) <NEWLINE> if kwonlyargs or ann : <NEWLINE> <TAB> raise ValueError ( <STRING> <NEWLINE> <STRING> ) <NEWLINE> <UNTAB> return ArgSpec ( args , varargs , varkw , defaults ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def _cdf_distance ( p , u_values , v_values , u_weights = None , v_weights = None ) : <NEWLINE> <TAB> <NEWLINE> u_values , u_weights = _validate_distribution ( u_values , u_weights ) <NEWLINE> v_values , v_weights = _validate_distribution ( v_values , v_weights ) <NEWLINE> <NEWLINE> u_sorter = np . argsort ( u_values ) <NEWLINE> v_sorter = np . argsort ( v_values ) <NEWLINE> <NEWLINE> all_values = np . concatenate ( ( u_values , v_values ) ) <NEWLINE> all_values . sort ( kind = <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> deltas = np . diff ( all_values ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> u_cdf_indices = u_values [ u_sorter ] . searchsorted ( all_values [ : - <NUMBER> ] , <STRING> ) <NEWLINE> v_cdf_indices = v_values [ v_sorter ] . searchsorted ( all_values [ : - <NUMBER> ] , <STRING> ) <NEWLINE> <NEWLINE> <NEWLINE> if u_weights is None : <NEWLINE> <TAB> u_cdf = u_cdf_indices / u_values . size <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> u_sorted_cumweights = np . concatenate ( ( [ <NUMBER> ] , <NEWLINE> np . cumsum ( u_weights [ u_sorter ] ) ) ) <NEWLINE> u_cdf = u_sorted_cumweights [ u_cdf_indices ] / u_sorted_cumweights [ - <NUMBER> ] <NEWLINE> <NEWLINE> <UNTAB> if v_weights is None : <NEWLINE> <TAB> v_cdf = v_cdf_indices / v_values . size <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> v_sorted_cumweights = np . concatenate ( ( [ <NUMBER> ] , <NEWLINE> np . cumsum ( v_weights [ v_sorter ] ) ) ) <NEWLINE> v_cdf = v_sorted_cumweights [ v_cdf_indices ] / v_sorted_cumweights [ - <NUMBER> ] <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> if p == <NUMBER> : <NEWLINE> <TAB> return np . sum ( np . multiply ( np . abs ( u_cdf - v_cdf ) , deltas ) ) <NEWLINE> <UNTAB> if p == <NUMBER> : <NEWLINE> <TAB> return np . sqrt ( np . sum ( np . multiply ( np . square ( u_cdf - v_cdf ) , deltas ) ) ) <NEWLINE> <UNTAB> return np . power ( np . sum ( np . multiply ( np . power ( np . abs ( u_cdf - v_cdf ) , p ) , <NEWLINE> deltas ) ) , <NUMBER> / p ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def mse_loss ( input , target , size_average = None , reduce = None , reduction = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> if size_average is not None or reduce is not None : <NEWLINE> <TAB> reduction = _Reduction . legacy_get_enum ( size_average , reduce ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> reduction = _Reduction . get_enum ( reduction ) <NEWLINE> <UNTAB> return _pointwise_loss ( lambda a , b : ( a - b ) ** <NUMBER> , torch . _C . _nn . mse_loss , input , target , reduction ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def compute ( self , method ) : <NEWLINE> <NEWLINE> <TAB> from pandas import Int64Index <NEWLINE> n = self . n <NEWLINE> frame = self . obj <NEWLINE> columns = self . columns <NEWLINE> <NEWLINE> for column in columns : <NEWLINE> <TAB> dtype = frame [ column ] . dtype <NEWLINE> if not self . is_valid_dtype_n_method ( dtype ) : <NEWLINE> <TAB> raise TypeError ( ( <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> ) . format ( column = column , dtype = dtype , method = method ) ) <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> def get_indexer ( current_indexer , other_indexer ) : <NEWLINE> <TAB> <NEWLINE> if method == <STRING> : <NEWLINE> <TAB> return current_indexer . append ( other_indexer ) <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> return other_indexer . append ( current_indexer ) <NEWLINE> <NEWLINE> <NEWLINE> <UNTAB> <UNTAB> original_index = frame . index <NEWLINE> cur_frame = frame = frame . reset_index ( drop = True ) <NEWLINE> cur_n = n <NEWLINE> indexer = Int64Index ( [ ] ) <NEWLINE> <NEWLINE> for i , column in enumerate ( columns ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> series = cur_frame [ column ] <NEWLINE> values = getattr ( series , method ) ( cur_n , keep = self . keep ) <NEWLINE> is_last_column = len ( columns ) - <NUMBER> == i <NEWLINE> if is_last_column or values . nunique ( ) == series . isin ( values ) . sum ( ) : <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <TAB> indexer = get_indexer ( indexer , values . index ) <NEWLINE> break <NEWLINE> <NEWLINE> <UNTAB> duplicated_filter = series . duplicated ( keep = False ) <NEWLINE> duplicated = values [ duplicated_filter ] <NEWLINE> non_duplicated = values [ ~ duplicated_filter ] <NEWLINE> indexer = get_indexer ( indexer , non_duplicated . index ) <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> <NEWLINE> cur_frame = cur_frame [ series . isin ( duplicated ) ] <NEWLINE> cur_n = n - len ( indexer ) <NEWLINE> <NEWLINE> <UNTAB> frame = frame . take ( indexer ) <NEWLINE> <NEWLINE> <NEWLINE> frame . index = original_index . take ( indexer ) <NEWLINE> return frame <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def translate ( self , table , deletechars = None ) : <NEWLINE> <TAB> <NEWLINE> return asarray ( translate ( self , table , deletechars ) ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> def tmin ( a , lowerlimit = None , axis = <NUMBER> , inclusive = True , nan_policy = <STRING> ) : <NEWLINE> <TAB> <NEWLINE> a , axis = _chk_asarray ( a , axis ) <NEWLINE> am = _mask_to_limits ( a , ( lowerlimit , None ) , ( inclusive , False ) ) <NEWLINE> <NEWLINE> contains_nan , nan_policy = _contains_nan ( am , nan_policy ) <NEWLINE> <NEWLINE> if contains_nan and nan_policy == <STRING> : <NEWLINE> <TAB> am = ma . masked_invalid ( am ) <NEWLINE> <NEWLINE> <UNTAB> res = ma . minimum . reduce ( am , axis ) . data <NEWLINE> if res . ndim == <NUMBER> : <NEWLINE> <TAB> return res [ ( ) ] <NEWLINE> <UNTAB> return res <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def sequence_categorical_column_with_vocabulary_list ( <NEWLINE> key , vocabulary_list , dtype = None , default_value = - <NUMBER> , num_oov_buckets = <NUMBER> ) : <NEWLINE> <TAB> <NEWLINE> return fc . _SequenceCategoricalColumn ( <NEWLINE> fc . categorical_column_with_vocabulary_list ( <NEWLINE> key = key , <NEWLINE> vocabulary_list = vocabulary_list , <NEWLINE> dtype = dtype , <NEWLINE> default_value = default_value , <NEWLINE> num_oov_buckets = num_oov_buckets ) ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> <TAB> def _can_hold_identifiers_and_holds_name ( self , name ) : <NEWLINE> <TAB> <NEWLINE> if self . is_object ( ) or self . is_categorical ( ) : <NEWLINE> <TAB> return name in self <NEWLINE> <UNTAB> return False <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> <TAB> def serialize ( self , value ) : <NEWLINE> <TAB> <NEWLINE> return self . list_sep . join ( [ _helpers . str_or_unicode ( x ) for x in value ] ) <NEWLINE> <UNTAB> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> ) <NEWLINE> def load_file_system_library ( library_filename ) : <NEWLINE> <TAB> <NEWLINE> py_tf . TF_LoadLibrary ( library_filename ) <NEWLINE> <UNTAB> <END> <EoC>
<BoC> def as_int ( n ) : <NEWLINE> <TAB> <NEWLINE> try : <NEWLINE> <TAB> result = int ( n ) <NEWLINE> if result != n : <NEWLINE> <TAB> raise TypeError <NEWLINE> <UNTAB> <UNTAB> except TypeError : <NEWLINE> <TAB> raise ValueError ( <STRING> % ( n , ) ) <NEWLINE> <UNTAB> return result <NEWLINE> <UNTAB> <END> <EoC>
<BoC> @ tf_export ( <STRING> , v1 = [ <STRING> , <STRING> ] ) <NEWLINE> @ deprecated_endpoints ( <STRING> ) <NEWLINE> def expm1 ( x , name = None ) : <NEWLINE> <TAB> <NEWLINE> _ctx = _context . _context <NEWLINE> if _ctx is None or not _ctx . _eager_context . is_eager : <NEWLINE> <TAB> _ , _ , _op = _op_def_lib . _apply_op_helper ( <NEWLINE> <STRING> , x = x , name = name ) <NEWLINE> _result = _op . outputs [ : ] <NEWLINE> _inputs_flat = _op . inputs <NEWLINE> _attrs = ( <STRING> , _op . get_attr ( <STRING> ) ) <NEWLINE> _execute . record_gradient ( <NEWLINE> <STRING> , _inputs_flat , _attrs , _result , name ) <NEWLINE> _result , = _result <NEWLINE> return _result <NEWLINE> <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> try : <NEWLINE> <TAB> _result = _pywrap_tensorflow . TFE_Py_FastPathExecute ( <NEWLINE> _ctx . _context_handle , _ctx . _eager_context . device_name , <STRING> , name , <NEWLINE> _ctx . _post_execution_callbacks , x ) <NEWLINE> return _result <NEWLINE> <UNTAB> except _core . _FallbackException : <NEWLINE> <TAB> return expm1_eager_fallback ( <NEWLINE> x , name = name , ctx = _ctx ) <NEWLINE> <UNTAB> except _core . _NotOkStatusException as e : <NEWLINE> <TAB> if name is not None : <NEWLINE> <TAB> message = e . message + <STRING> + name <NEWLINE> <UNTAB> else : <NEWLINE> <TAB> message = e . message <NEWLINE> <UNTAB> _six . raise_from ( _core . _status_to_exception ( e . code , message ) , None ) <NEWLINE> <UNTAB> <UNTAB> <UNTAB> <END> <EoC>
